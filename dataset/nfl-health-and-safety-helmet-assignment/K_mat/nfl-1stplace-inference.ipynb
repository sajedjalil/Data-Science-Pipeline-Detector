{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\n\nimport pandas as pd\nfrom tqdm.auto import tqdm\nimport numpy as np\n\nSRC_PATH = '../input/nfl2solution'\nsys.path.insert(1, SRC_PATH)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load and Interporate Dataset","metadata":{}},{"cell_type":"code","source":"# Read in data files\nBASE_DIR = '../input/nfl-health-and-safety-helmet-assignment'\n\n# Labels and sample submission\nlabels = pd.read_csv(f'{BASE_DIR}/train_labels.csv')\nss = pd.read_csv(f'{BASE_DIR}/sample_submission.csv')\n\n# Player tracking data\ntr_tracking = pd.read_csv(f'{BASE_DIR}/train_player_tracking.csv')\nte_tracking = pd.read_csv(f'{BASE_DIR}/test_player_tracking.csv')\n\n# Baseline helmet detection labels\ntr_helmets = pd.read_csv(f'{BASE_DIR}/train_baseline_helmets.csv')\nte_helmets = pd.read_csv(f'{BASE_DIR}/test_baseline_helmets.csv')\n\n# Extra image labels\nimg_labels = pd.read_csv(f'{BASE_DIR}/image_labels.csv')","metadata":{"_kg_hide-input":false,"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_track_features(tracks, fps=59.94, snap_frame=10):\n    \"\"\"\n    Add column features helpful for syncing with video data.\n    \"\"\"\n    tracks = tracks.copy()\n    tracks[\"game_play\"] = (\n        tracks[\"gameKey\"].astype(\"str\")\n        + \"_\"\n        + tracks[\"playID\"].astype(\"str\").str.zfill(6)\n    )\n    tracks[\"time\"] = pd.to_datetime(tracks[\"time\"])\n    snap_dict = (\n        tracks.query('event == \"ball_snap\"')\n        .groupby(\"game_play\")[\"time\"]\n        .first()\n        .to_dict()\n    )\n    tracks[\"snap\"] = tracks[\"game_play\"].map(snap_dict)\n    tracks[\"isSnap\"] = tracks[\"snap\"] == tracks[\"time\"]\n    tracks[\"team\"] = tracks[\"player\"].str[0].replace(\"H\", \"Home\").replace(\"V\", \"Away\")\n    tracks[\"snap_offset\"] = (tracks[\"time\"] - tracks[\"snap\"]).astype(\n        \"timedelta64[ms]\"\n    ) / 1_000\n    # Estimated video frame\n    tracks[\"est_frame\"] = (\n        ((tracks[\"snap_offset\"] * fps) + snap_frame).round().astype(\"int\")\n    )\n    return tracks\n\ntr_tracking = add_track_features(tr_tracking)\nte_tracking = add_track_features(te_tracking)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_interpolated_tracking(df_tracking, df_helmet):\n    \n    df_ref_play_frame = pd.DataFrame(df_helmet[\"video_frame\"].unique())[0].str.rsplit('_', n=2, expand=True).rename(columns={0: 'game_play', 1: 'view', 2:\"frame\"}).drop(\"view\",axis=1).drop_duplicates()\n    df_ref_play_frame[\"frame\"] = df_ref_play_frame[\"frame\"].astype('int')\n    df_ref_play_frame = df_ref_play_frame.sort_values(['game_play', \"frame\"])\n    \n    df_list = []\n\n    for keys, _df_tracking in tqdm(df_tracking.groupby([\"player\", \"game_play\"])):\n        # skip because there are sideline player\n        if keys[0] == \"H00\" or keys[0] == \"V00\":\n            continue\n        _df_ref_play_frame = df_ref_play_frame[df_ref_play_frame[\"game_play\"]==keys[1]].copy()\n        _df_ref_play_frame = _df_ref_play_frame.drop(\"game_play\",axis=1)\n        \n        _df_tracking = _df_tracking.sort_values(\"est_frame\")\n        _df_tracking_copy = _df_tracking[[\"est_frame\", \"x\", \"y\"]].copy().rename(columns={\"est_frame\": \"next_est_frame\", \"x\":\"next_x\", \"y\":\"next_y\"}).shift(-1).interpolate()\n        _df_tracking_copy.iloc[-1, 0] += 1\n        _df_tracking = pd.concat([_df_tracking, _df_tracking_copy], axis=1)\n\n        # merge with frame and est_frame\n        merged_df = pd.merge_asof(\n                _df_ref_play_frame.copy(),\n                _df_tracking,\n                left_on=\"frame\",\n                right_on=\"est_frame\",\n                direction=\"backward\",#'nearest',\n            )\n        df_list.append(merged_df)\n\n    all_merged_df = pd.concat(df_list)\n    w_1 = all_merged_df[[\"x\", \"y\"]].values * ((all_merged_df[\"next_est_frame\"].values-all_merged_df[\"frame\"].values)/(all_merged_df[\"next_est_frame\"].values-all_merged_df[\"est_frame\"].values))[:,np.newaxis]\n    w_2 = all_merged_df[[\"next_x\", \"next_y\"]].values * ((all_merged_df[\"frame\"].values-all_merged_df[\"est_frame\"].values)/(all_merged_df[\"next_est_frame\"].values-all_merged_df[\"est_frame\"].values))[:,np.newaxis]\n    all_merged_df[\"x_interp\"] = w_1[:,0] + w_2[:,0]\n    all_merged_df[\"y_interp\"] = w_1[:,1] + w_2[:,1]\n    all_merged_df = all_merged_df.drop([\"next_est_frame\", \"next_x\", \"next_y\"],axis=1)\n    return all_merged_df\nprint(\"preparing interpolated dataset\")\nte_tracking = make_interpolated_tracking(te_tracking, te_helmets)\ntr_tracking = make_interpolated_tracking(tr_tracking, tr_helmets)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Main Pipeline\nFunction named \"test_predict_ensemble_batch\" is the main pipeline.\n\nEach models are defined in my dataset \"nfl2solution\".","metadata":{}},{"cell_type":"code","source":"\nimport os\nimport glob\nimport json\nimport warnings\nimport argparse\nimport sys\nimport random\nimport time\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nimport pandas as pd\n\nfrom model.model import build_model_team, build_model_map\nfrom model.model_detection import build_detection_model, soft_nms_layer\nfrom model.ICP_tf_team_batch import make_icp_inputs, random_icp_fitting, transform_points, get_nearest_distance, search_nearest_error, points2points_fitting\nfrom model.Tracker import Tracker_2_w_feature, wbf_ensemble_reassign_player_label\nfrom model.similaritymat_to_binary import similarity_matrix_to_team\n#from train_utils.evaluation import NFLAssignmentScorer\n#from train_utils.extract_img_from_video_subframes import make_rectangle, make_locations\n\n    \nclass Batch_data():\n    def __init__(self):\n        self.imgs = []\n        self.img_arrays = []\n        self.frames = []\n        self.length = 0\n    \n    def add(self, img, img_array, frame):\n        self.imgs.append(img)\n        self.img_arrays.append(img_array)\n        self.frames.append(frame)\n        self.length = len(self.frames)\n        \n    def take(self):\n        pass\n        \n    def reset(self):\n        self.imgs = []\n        self.img_arrays = []\n        self.frames = []\n\nclass HelmetSizeHist():\n    def __init__(self, update_freq=20):\n        self.update_freq = update_freq           \n        self.mean = tf.Variable(20.0)#, dtype='float32')\n        self.count = tf.Variable(0)#, dtype='int32')\n        \n    def reset(self):\n        self.mean.assign(20.0)\n        self.count.assign(0)\n        \n    def update_and_get_current(self, mean_size, num_detection):\n        mean = self.mean       \n        count = self.count         \n        if num_detection > 0:\n            c = tf.minimum(count, self.update_freq)\n            total = mean * tf.cast(c, tf.float32) + mean_size * tf.cast(num_detection, tf.float32)\n            updated_mean = total / tf.cast(c + num_detection, tf.float32)\n            updated_count = count + num_detection\n            self.mean.assign(updated_mean)\n            self.count.assign(updated_count)\n        else:\n            updated_mean = mean\n        return updated_mean\n    \n    def get_current_state(self):\n        return self.mean#.numpy(), self.count.numpy()\n        \n\nclass TeamFeaturesHolder():\n    def __init__(self, num_features, update_freq=100, add_threshold=0.2, softmax_temperature=2.):\n        self.team_h_mean = np.zeros((num_features,))\n        self.team_v_mean = np.zeros((num_features,))\n        self.count_h = 0\n        self.count_v = 0\n        #self.start_from = update_freq\n        self.update_freq = update_freq\n        self.add_threshold = add_threshold\n        self.softmax_temperature = softmax_temperature\n        self.provided = False\n        \n    def add(self, pred_label, assign_label, features):\n        if self.provided:\n            survive_mask = (np.abs(assign_label - pred_label) < self.add_threshold)\n        else:\n            survive_mask = (np.abs(assign_label - pred_label) < self.add_threshold*2)\n        pred_label = pred_label[survive_mask]\n        assign_label = assign_label[survive_mask]\n        features = features[survive_mask]\n        h_features = features[assign_label>0.5]\n        v_features = features[assign_label<0.5]\n        num_h = len(h_features)\n        num_v = len(v_features)\n        if num_h > 0:\n            if self.count_h < self.update_freq:\n                total_h = self.team_h_mean * self.count_h + np.sum(h_features, axis=0)\n                self.team_h_mean = total_h / (self.count_h + num_h)\n            else:\n                total_h = self.team_h_mean * self.update_freq + np.sum(h_features, axis=0)\n                self.team_h_mean = total_h / (self.update_freq + num_h)\n        if num_v > 0:\n            if self.count_v < self.update_freq:\n                total_v = self.team_v_mean * self.count_v + np.sum(v_features, axis=0)\n                self.team_v_mean = total_v / (self.count_v + num_v)\n            else:\n                total_v = self.team_v_mean * self.update_freq + np.sum(v_features, axis=0)\n                self.team_v_mean = total_v / (self.update_freq + num_v)\n        self.count_h += num_h\n        self.count_v += num_v\n        #print(\"COUNTER\", self.count_h, self.count_v)\n        \n    def predict(self, pred_features):\n        if (self.count_h >= self.update_freq) and (self.count_v >= self.update_freq):\n            h_sim = np.dot(pred_features, self.team_h_mean) * self.softmax_temperature\n            v_sim = np.dot(pred_features, self.team_v_mean) * self.softmax_temperature\n\n            pred_binary = np.clip(np.exp(h_sim) / (np.exp(h_sim) + np.exp(v_sim)), 0.0, 1.0)\n            self.provided = True\n        else:\n            pred_binary = None\n            \n        return pred_binary\n        \nclass NFL_Predictor():\n    def __init__(self, #num_classes=30, solo_score_thresh=0.3,\n                 input_shape=(288,288,4), \n                 output_shape=(144,144), \n                 weight_file=None, \n                 is_train_model=False,\n                 inference_batch=1):\n        \n        print(\"\\rLoading Models...\", end=\"\")\n        \n        self.input_shape = tuple(input_shape)\n        self.output_shape = tuple(output_shape)\n        self.is_train_model = is_train_model\n        self.weight_file = weight_file\n        self.inference_batch = inference_batch\n        if inference_batch>=1:\n            self.batch_run = True\n        else:\n            self.batch_run = False\n        self.load_model(weight_file, is_train_model)\n        print(\"Loading Models......Finish\")\n        \n    def load_model(self, weight_file=None, is_train_model=False):\n        \"\"\"build model and load weights\"\"\"\n\n        train_map_model_s, map_model_s, _, _, _ = build_model_map((None,None,3),#self.input_shape, \n                                         minimum_stride=self.input_shape[0]//self.output_shape[0], \n                                         is_train=self.is_train_model,\n                                         backbone=\"effv2s\",\n                                                                  from_scratch=True,\n                                         )\n        train_map_model_s.load_weights(weight_file[\"map\"])#, by_name=True)\n        map_model = [map_model_s]\n\n        det_model, _, _ = build_detection_model((704,1280,3), \n                                               minimum_stride=2, \n                                               is_train=self.is_train_model,\n                                               backbone=\"effv2s\",\n                                                from_scratch=True,\n                                               include_nms=False if self.batch_run else True)\n        det_model.load_weights(weight_file[\"det\"])\n        \n        l_det_model = []\n        for backbone, file in weight_file[\"detL\"]:            \n            l_det_model_smlxl, _, _ = build_detection_model((None,None,3), \n                                                   minimum_stride=2, \n                                                   is_train=self.is_train_model,\n                                                   backbone=backbone,\n                                                    from_scratch=True,\n                                                   include_nms=False if self.batch_run else True)\n            l_det_model_smlxl.load_weights(file)\n            l_det_model.append(l_det_model_smlxl)\n                \n        self.num_det_models = len(l_det_model)\n            \n        team_model, _,_,_ = build_model_team(input_shape=(96+32, 64+32, 3),\n                                                       #input_shape_view=(256+64,448+128,3), \n                                                       #minimum_stride=4,                                                       \n                                                       backbone=\"effv2s\",\n                                                       is_train=self.is_train_model,\n                                                        from_scratch=True,)\n        team_model.load_weights(weight_file[\"team\"])\n       \n        self.mapper, self.detector, registrator_side, registrator_end, self.prelocate = self.get_integrated_inference_model(map_model, det_model, l_det_model, team_model)\n        \n        self.registrator = {\"Sideline\": registrator_side,\n                            \"Endzone\": registrator_end}\n\n            \n    def get_integrated_inference_model(self, map_model, det_model, l_det_model=None, team_model=None):\n        self.hsh = HelmetSizeHist(update_freq=20)\n        self.hsh_select = HelmetSizeHist(update_freq=20)\n\n        self.map_shape = [512, 896]\n        self.det_shape = [704, 1280]\n        self.player_shape = [96, 64]\n        \n        @tf.function(input_signature=(tf.TensorSpec(shape=[None, 720, 1280, 3], dtype=tf.float32),\n                          tf.TensorSpec(shape=[None, None, 4], dtype=tf.float32),\n                          )\n         )\n        def mapper(input_rgb, box_tlbr):\n            map_img = tf.image.resize(input_rgb, (self.map_shape[0], self.map_shape[1]), method=\"bilinear\")\n            \n            box_tlbr = box_tlbr / tf.constant([[[720, 1280, 720, 1280]]],tf.float32)\n            \n            mean_size = self.hsh.get_current_state()\n            size_input = tf.stack([[mean_size]])\n            use_TTA = False\n            if use_TTA:\n                f_t = box_tlbr[:,:,:1]\n                f_l = 1. - box_tlbr[:,:,3:4]\n                f_b = box_tlbr[:,:,2:3]\n                f_r = 1. - box_tlbr[:,:,1:2]\n                f_box_tlbr = tf.concat([f_t,f_l,f_b,f_r], axis=-1)\n                \n                map_img_batch = tf.concat([map_img, map_img[:,:,::-1,:]], axis=0)\n                input_img_batch = tf.concat([input_rgb, input_rgb[:,:,::-1,:]], axis=0)\n                box_tlbr_batch = tf.concat([box_tlbr, f_box_tlbr], axis=0)\n                \n                preds = map_model([map_img_batch, box_tlbr_batch])\n                pred_location= (preds[0][0:1] + preds[0][1:2] * tf.constant([[[-1, 1]]],tf.float32)) / 2.0\n                pred_team = team_model([input_img_batch, box_tlbr_batch])\n                pred_simmat = (pred_team[0][0:1,...,0] + pred_team[0][1:2,...,0])/2.0\n                pred_teamvec = (pred_team[1][0:1,:,:] + pred_team[1][1:2,:,:]) / 2.0\n            \n            else:\n                preds = map_model([map_img, box_tlbr, size_input])        \n                pred_location= preds[0]\n                pred_team = team_model([input_rgb, box_tlbr, size_input])\n                pred_simmat = pred_team[0][...,0]\n                pred_teamvec = pred_team[1]\n            \n            return pred_location, pred_simmat, pred_teamvec\n\n        @tf.function(input_signature=(tf.TensorSpec(shape=[None, 720, 1280, 3], dtype=tf.float32),\n                          tf.TensorSpec(shape=[None, None, 4], dtype=tf.float32),\n                          )\n         )\n        def mapper_ensemble(input_rgb, box_tlbr):\n            map_img = tf.image.resize(input_rgb, (self.map_shape[0], self.map_shape[1]), method=\"bilinear\")\n            \n            box_tlbr = box_tlbr / tf.constant([[[720, 1280, 720, 1280]]],tf.float32)\n            mean_size = self.hsh_select.get_current_state()/tf.sqrt(720.*1280.)\n            size_input = mean_size * tf.ones((tf.shape(map_img)[0], 1), tf.float32)#tf.tile(tf.stack([[mean_size]]), [tf.shape(map_img)[0], 1])\n            \n            list_pred_location = []\n            list_pred_simmat = []\n            list_pred_teamvec = []\n            for m in map_model:\n                preds = m([map_img, box_tlbr, size_input])        \n                pred_location= preds[0]#[0]\n                pred_team = team_model([input_rgb, box_tlbr, size_input])\n                pred_simmat = pred_team[0][...,0]\n                pred_teamvec = pred_team[1]#[:,:,:]\n                list_pred_location.append(pred_location)\n                list_pred_simmat.append(pred_simmat)\n                list_pred_teamvec.append(pred_teamvec)\n            \n            return list_pred_location, list_pred_simmat, list_pred_teamvec\n        \n        @tf.function(input_signature=(tf.TensorSpec(shape=[None, 720, 1280, 3], dtype=tf.float32),\n                                      tf.TensorSpec(shape=[], dtype=tf.int32))\n         )\n        def detector2stage_ensemble_batch(input_rgbs, batch_size=1):\n            det_imgs = tf.image.resize(input_rgbs, (self.det_shape[0], self.det_shape[1]), method=\"bilinear\")\n            boxes, scores = det_model(det_imgs)\n            \n            NMS = soft_nms_layer\n            list_box, list_score, num_boxes = [], [], []\n            for j in range(self.inference_batch):\n                i = tf.minimum(j, batch_size-1)\n                nms_box, nms_score = NMS([boxes[i:(i+1)], scores[i:(i+1)]])\n                list_box.append(nms_box)\n                list_score.append(nms_score)\n                num_boxes.append(tf.shape(nms_box)[0])\n            num_boxes = tf.reduce_sum(tf.stack(num_boxes)[:batch_size])\n            box = tf.concat(list_box, axis=0)[:num_boxes]\n            score = tf.concat(list_score, axis=0)[:num_boxes]\n            \n            box = box * tf.constant([[720/self.det_shape[0],1280/self.det_shape[1],\n                                      720/self.det_shape[0],1280/self.det_shape[1]]], tf.float32)\n            box = tf.clip_by_value(box, tf.constant([0.,0.,0.,0.]), tf.constant([720.,1280.,720.,1280.]))\n            tl = box[:,:2]\n            hw = box[:,2:4] - box[:,:2]\n            tlhw = tf.concat([tl, hw], axis=-1)\n            size_normal = tf.math.sqrt(hw[:,0]*hw[:,1])\n            size_select = tf.boolean_mask(size_normal, score>0.25)\n            mean_size_normal = tf.reduce_mean(size_normal)\n            mean_size_select = tf.reduce_mean(size_select)\n            num_detection_normal = tf.shape(size_normal)[0]\n            num_detection_select = tf.shape(size_select)[0]\n            mean_size_normal = self.hsh.update_and_get_current(mean_size_normal, num_detection_normal)\n            mean_size_select = self.hsh_select.update_and_get_current(mean_size_select, num_detection_select)\n            \n            rate_to_25 = 25./mean_size_normal\n            resize_h_normal = 64*((rate_to_25 * 720)//64)\n            resize_w_normal = 64*((rate_to_25 * 1280)//64)\n            l_det_imgs_normal = tf.image.resize(input_rgbs, (int(resize_h_normal), int(resize_w_normal)), method=\"bicubic\")# \"bilinear\")# method=\"bilinear\")\n            \n            rate_to_25 = 25./mean_size_select\n            resize_h_select = 64*((rate_to_25 * 720)//64)\n            resize_w_select = 64*((rate_to_25 * 1280)//64)\n            \n            tlhw_score_each_model = []\n            \n            \n            list_box_before_nms = []\n            list_score_before_nms = []\n            for idx, m in enumerate(l_det_model):\n                ##boxes, scores = m(l_det_imgs_select)\n                ##resize_h = resize_h_select\n                ##resize_w = resize_w_select\n                ##else:\n                boxes, scores = m(l_det_imgs_normal)\n                resize_h = resize_h_normal\n                resize_w = resize_w_normal\n                list_box_before_nms.append(boxes)\n                list_score_before_nms.append(scores)\n                list_tlhw_single, list_score_single = [], []\n                for j in range(self.inference_batch):\n                    i = tf.minimum(j, batch_size-1)\n                    box, score = NMS([boxes[i:(i+1)], scores[i:(i+1)]],score_threshold = 0.08, max_output_size=30)\n                    ##box, score = NMS([boxes[i:(i+1)], scores[i:(i+1)]])\n                    box = box * tf.cast(tf.stack([[720/resize_h,1280/resize_w,720/resize_h,1280/resize_w]]), tf.float32)\n                    box = tf.clip_by_value(box, tf.constant([0.,0.,0.,0.]), tf.constant([720.,1280.,720.,1280.]))\n                    tl = box[:,:2]\n                    hw = box[:,2:4] - box[:,:2]\n                    tlhw = tf.concat([tl, hw], axis=-1)  \n                    \n                    list_tlhw_single.append(tlhw)\n                    list_score_single.append(score)\n                tlhw_score_each_model.append([list_tlhw_single, list_score_single])\n            \"\"\"\n            #averaging ensemble\n            ave_boxes = (list_box_before_nms[0] + list_box_before_nms[1] + list_box_before_nms[2] + list_box_before_nms[3])/4\n            ave_scores = (list_score_before_nms[0] + list_score_before_nms[1] + list_score_before_nms[2] + list_score_before_nms[3])/4\n            \n            list_tlhw_single, list_score_single = [], []\n            for j in range(self.inference_batch):\n                i = tf.minimum(j, batch_size-1)\n                box, score = NMS([ave_boxes[i:(i+1)], ave_scores[i:(i+1)]],score_threshold = 0.1, max_output_size=30)\n                box = box * tf.cast(tf.stack([[720/resize_h,1280/resize_w,720/resize_h,1280/resize_w]]), tf.float32)\n                box = tf.clip_by_value(box, tf.constant([0.,0.,0.,0.]), tf.constant([720.,1280.,720.,1280.]))\n                tl = box[:,:2]\n                hw = box[:,2:4] - box[:,:2]\n                tlhw = tf.concat([tl, hw], axis=-1)  \n\n                #mean_size = tf.reduce_mean(tf.math.sqrt(hw[:,0]*hw[:,1]))\n                #num_detection = tf.shape(box)[0]\n                #_ = self.hsh.update_and_get_current(mean_size, num_detection)\n\n                list_tlhw_single.append(tlhw)\n                list_score_single.append(score) \n            tlhw_score_each_model.append([list_tlhw_single, list_score_single])\n            tlhw_score_each_model = tlhw_score_each_model[::-1]\n            #\"\"\"\n            return tlhw_score_each_model\n        \n        def registrator_wrapper(view):\n            @tf.function(input_signature=(tf.TensorSpec(shape=[None, 2], dtype=tf.float32),\n                              tf.TensorSpec(shape=[None, 1], dtype=tf.float32),\n                              tf.TensorSpec(shape=[None], dtype=tf.float32),\n                              tf.TensorSpec(shape=[None, 2], dtype=tf.float32),\n                              tf.TensorSpec(shape=[None, 1], dtype=tf.float32),\n                              tf.TensorSpec(shape=[None, None], dtype=tf.float32),\n                              #tf.TensorSpec(shape=[None, 2], dtype=tf.float32),\n                              tf.TensorSpec(shape=[], dtype=tf.bool),\n                              tf.TensorSpec(shape=[], dtype=tf.bool),\n                              tf.TensorSpec(shape=[], dtype=tf.bool),\n                              tf.TensorSpec(shape=[3], dtype=tf.float32),\n                              tf.TensorSpec(shape=[3], dtype=tf.float32),\n                              tf.TensorSpec(shape=[2,3], dtype=tf.float32),\n                              tf.TensorSpec(shape=[], dtype=tf.float32),##増やした\n                              tf.TensorSpec(shape=[], dtype=tf.int32),##増やした\n                              tf.TensorSpec(shape=[], dtype=tf.int32),##増やした\n                              tf.TensorSpec(shape=[], dtype=tf.int32),##増やした\n                              )\n             )\n            def registrator(pred_location, pred_team, confidence, locations, \n                            team_labels, cost_matrix,\n                                 #motions, \n                                 team_provided, \n\n                                 use_provided_params, use_random_params,\n                                 zoom_params, rz_params, txy_params,\n                                 confidence_threshold, \n                                 num_harddrop,\n                                 num_softdrop,\n                                 num_trial):\n                results = random_icp_fitting_team_drop(locations, #target\n                                                     pred_location, #pred\n                                                     confidence,\n                                                     team_labels,\n                                                     pred_team,\n                                                     cost_matrix,\n                                                     team_provided=team_provided,\n                                                     #motions,\n                                                     #pred_motions,\n                                                     num_trial=num_trial,#120,\n                                                     num_fitting_iter=8,#8,\n                                                     use_provided_params=use_provided_params,\n                                                     use_random_params=use_random_params,\n                                                     zoom_params=zoom_params,\n                                                     rz_params=rz_params,\n                                                     txy_params=txy_params,\n                                                     confidence_threshold=confidence_threshold,\n                                                     num_harddrop=num_harddrop,\n                                                     num_softdrop=num_softdrop,\n                                                     mode=view)\n                return results\n            return registrator\n\n\n        \n        @tf.function(input_signature=(tf.TensorSpec(shape=[None, 2], dtype=tf.float32),\n                                      tf.TensorSpec(shape=[None], dtype=tf.int32),\n                                      tf.TensorSpec(shape=[None], dtype=tf.int32),\n                                      tf.TensorSpec(shape=[None, 2], dtype=tf.float32),\n                                      tf.TensorSpec(shape=[None, 2], dtype=tf.float32),\n                                     tf.TensorSpec(shape=[], dtype=tf.float32),\n                                      tf.TensorSpec(shape=[], dtype=tf.int32),\n                                     tf.TensorSpec(shape=[], dtype=tf.float32),)\n         )\n        def prelocation(pred_location, ref_box_indexs, not_ref_box_indexes, ref_locations, all_locations, l2_reg, num_iter, rot_init):\n            ref_box_pred_locations = tf.gather(pred_location, ref_box_indexs) \n            trans_sources, transmatrix, k_init, rz_init, tx_init, ty_init = points2points_fitting(ref_locations[tf.newaxis,:,:], \n                                                                                                  ref_box_pred_locations[tf.newaxis,:,:], \n                                                                                                  num_iter=num_iter,\n                                                                                                  l2_reg=l2_reg,\n                                                                                                  rot_init=rot_init)\n            trans_sources_all = transform_points(transmatrix[0], pred_location)\n            # initial parameters used for registration\n            rz_params = tf.stack([rz_init[0], 0.05, 500.])\n            zoom_params = tf.stack([k_init[0], 0.05, 20.])\n            txy_params = tf.stack([[tx_init[0], 0.05, 20.],\n                                  [ty_init[0], 0.05, 20.]])\n            init_error, assigned_targets, assignments, not_assigned_targets = search_nearest_error(trans_sources[0], all_locations)\n            not_assigned_sources = tf.gather(trans_sources_all, not_ref_box_indexes) \n            dist_to_near_targets_not_assigned, dist_to_near_sources_not_assigned = get_nearest_distance(not_assigned_sources, not_assigned_targets)\n            dist_to_near_targets, dist_to_near_sources = get_nearest_distance(trans_sources_all, all_locations)            \n            return trans_sources, trans_sources_all, transmatrix, rz_params, zoom_params, txy_params, init_error, assigned_targets, assignments, dist_to_near_targets, dist_to_near_sources, dist_to_near_targets_not_assigned\n        \n        return mapper_ensemble, detector2stage_ensemble_batch, registrator_wrapper(\"Sideline\"), registrator_wrapper(\"Endzone\"), prelocation\n            \n            \n    \n    @staticmethod\n    def draw_bbox(img, boxes, gt_boxes=None, save_only=True, save_path=\"\", save_title=\"\"):\n        from PIL import Image, ImageDraw\n        save_dir = save_path + save_title + \".jpg\"\n        pil_img = Image.fromarray((img).astype(np.uint8))\n        draw = ImageDraw.Draw(pil_img)\n        #text_w, text_h = draw.textsize(text)\n        #label_y = y if y <= text_h else y - text_h\n            #draw.rectangle((x, label_y, x+text_w, label_y+text_h), outline=bbcolor, fill=bbcolor)\n            #draw.text((x, label_y), text, fill=textcolor)\n        if gt_boxes is not None:\n            for t, l, h, w in gt_boxes:\n                draw.rectangle((int(l), int(t), int(l+w), int(t+h)), outline=\"blue\", width=3)\n        for t, l, h, w in boxes:\n            draw.rectangle((int(l), int(t), int(l+w), int(t+h)), outline=\"red\", width=3)\n        if save_only:\n            pil_img.save(save_dir)\n        else:        \n            plt.figure(figsize = (9,5))    \n            plt.imshow(pil_img)\n            plt.show()\n\n    @staticmethod\n    def draw_tracking_box(img, boxes, tracking_ids, save_only=True, save_path=\"\", save_title=\"\"):\n        from PIL import Image, ImageDraw\n        save_dir = save_path + save_title + \".jpg\"\n        cmap = plt.get_cmap(\"tab20\")\n        tracking_colors = [(int(cmap(tr_id%20)[0]*255), int(cmap(tr_id%20)[1]*255), int(cmap(tr_id%20)[2]*255)) for tr_id in tracking_ids]\n        pil_img = Image.fromarray((img).astype(np.uint8))\n        draw = ImageDraw.Draw(pil_img)\n        for [t, l, h, w], c in zip(boxes, tracking_colors):\n            draw.rectangle((int(l), int(t), int(l+w), int(t+h)), outline=c, width=3)            \n        if save_only:\n            pil_img.save(save_dir)\n        else:\n            plt.figure(figsize = (9,5))    \n            plt.imshow(pil_img)\n            plt.show() \n\n                        \n    def run_detection_ensemble_batch(self, list_img, frame, view, game_play):\n        batch_size = len(list_img)\n        batch_img = tf.concat(list_img, axis=0)\n        #list_tlhw, list_confidence\n        tlhw_score_each_model = self.detector(batch_img, batch_size)\n        tlhw_score_each_model = [[out[0][:batch_size], out[1][:batch_size]] for out in tlhw_score_each_model]\n        \n        batch_list_current_frame_helmets = [[] for _ in range(batch_size)]\n        batch_list_tlbr_boxes = [[] for _ in range(batch_size)]\n        for list_tlhw, list_confidence in tlhw_score_each_model:\n            for frame_idx, [confidence, tlhw] in enumerate(zip(list_confidence, list_tlhw)):\n                current_frame_helmets = pd.DataFrame(tlhw.numpy(), columns=[\"top\", \"left\", \"height\", \"width\"])\n                current_frame_helmets[\"conf\"] = confidence.numpy().reshape(-1)\n                current_frame_helmets[\"frame\"] = frame[frame_idx]\n                current_frame_helmets[\"view\"] = view\n                current_frame_helmets[\"game_play\"] = game_play            \n                current_frame_helmets = current_frame_helmets.sort_values('conf', ascending=False)\n                current_frame_helmets[\"bottom\"] = current_frame_helmets[\"top\"] + current_frame_helmets[\"height\"]\n                current_frame_helmets[\"right\"] = current_frame_helmets[\"left\"] + current_frame_helmets[\"width\"]\n                current_frame_helmets = current_frame_helmets[~np.round(current_frame_helmets[[\"left\", \"width\", \"top\", \"height\"]]).duplicated()]\n                current_frame_helmets = current_frame_helmets[np.round(current_frame_helmets[\"height\"])>1.]\n                current_frame_helmets = current_frame_helmets[np.round(current_frame_helmets[\"width\"])>1.]\n                tlbr_boxes = tf.cast(current_frame_helmets[[\"top\", \"left\", \"bottom\", \"right\"]].values, tf.float32)\n                #list_current_frame_helmets.append(current_frame_helmets)\n                #list_tlbr_boxes.append(tlbr_boxes)\n                batch_list_current_frame_helmets[frame_idx].append(current_frame_helmets)\n                batch_list_tlbr_boxes[frame_idx].append(tlbr_boxes) \n        \"\"\"\n        for frame_idx in range(batch_size):\n            #WBF HERE?   \n            list_current_frame_helmets = batch_list_current_frame_helmets[frame_idx]\n            list_tlbr_boxes = batch_list_tlbr_boxes[frame_idx]\n            list_boxes = [df[[\"top\", \"left\", \"bottom\", \"right\"]].values for df in list_current_frame_helmets]\n            list_confs = [df[\"conf\"].values for df in list_current_frame_helmets]\n            fusion_box, fusion_conf = wbf(list_boxes, list_confs, \n                                          #model_weights=model_weights, \n                                          iou_thresh=0.5,\n                                          mode=\"average\") \n            mask = fusion_conf > 0.03\n            fusion_box = fusion_box[mask]\n            fusion_conf = fusion_conf[mask]\n            current_frame_helmets = pd.DataFrame(fusion_box, columns=[\"top\", \"left\", \"bottom\", \"right\"])\n            current_frame_helmets[\"conf\"] = fusion_conf.reshape(-1)\n            current_frame_helmets[\"frame\"] = frame[frame_idx]\n            current_frame_helmets[\"view\"] = view\n            current_frame_helmets[\"game_play\"] = game_play            \n            current_frame_helmets = current_frame_helmets.sort_values('conf', ascending=False)\n            current_frame_helmets[\"height\"] = current_frame_helmets[\"bottom\"] - current_frame_helmets[\"top\"]\n            current_frame_helmets[\"width\"] = current_frame_helmets[\"right\"] - current_frame_helmets[\"left\"]\n            current_frame_helmets = current_frame_helmets[~np.round(current_frame_helmets[[\"left\", \"width\", \"top\", \"height\"]]).duplicated()]\n            current_frame_helmets = current_frame_helmets[np.round(current_frame_helmets[\"height\"])>1.]\n            current_frame_helmets = current_frame_helmets[np.round(current_frame_helmets[\"width\"])>1.]\n            tlbr_boxes = tf.cast(current_frame_helmets[[\"top\", \"left\", \"bottom\", \"right\"]].values, tf.float32)            \n            list_current_frame_helmets.append(current_frame_helmets)\n            list_tlbr_boxes.append(tlbr_boxes)\n            batch_list_current_frame_helmets[frame_idx] = list_current_frame_helmets\n            batch_list_tlbr_boxes[frame_idx] = list_tlbr_boxes\n        \"\"\"        \n        return batch_list_current_frame_helmets, batch_list_tlbr_boxes\n\n\n    def run_mapping_ensemble(self, img, tlbr_boxes, list_current_frame_helmets, f_columns, list_tfh, list_params_set):\n        tlbr_boxes = tf.reshape(tlbr_boxes, [1,-1,4])\n        list_pred_location, list_pred_simmat, list_pred_features = self.mapper(img, tlbr_boxes)\n        \n        \"\"\"        \n        f_t = tlbr_boxes[:,:,:1]\n        f_l = 1280. - tlbr_boxes[:,:,3:4]\n        f_b = tlbr_boxes[:,:,2:3]\n        f_r = 1280. - tlbr_boxes[:,:,1:2]\n        f_tlbr_boxes = tf.concat([f_t,f_l,f_b,f_r], axis=-1)\n        f_img = img[:,:,::-1,:]\n        f_pred_location, f_pred_simmat, f_pred_features = self.mapper(f_img, f_tlbr_boxes)\n        f_pred_location = f_pred_location * tf.constant([[[-1, 1]]],tf.float32)\n        \"\"\"\n        #list_pred_location = [pred_location]#, f_pred_location]\n        #list_pred_simmat = [pred_simmat]#, f_pred_simmat]\n        #list_pred_features = [pred_features]#, f_pred_features]\n               \n        for i, [current_frame_helmets, tfh, params_set, pred_location, pred_simmat, pred_features] in enumerate(zip(list_current_frame_helmets, list_tfh, list_params_set, list_pred_location, list_pred_simmat, list_pred_features)):\n            current_frame_helmets[[\"loc_x\", \"loc_y\"]] = pred_location[0].numpy().reshape(-1,2)#zero is batch dim\n            #current_frame_helmets[\"team\"] = pred_team.numpy().reshape(-1)\n            current_frame_helmets[f_columns] = pred_features[0].numpy()\n            binary_predict = tfh.predict(pred_features[0].numpy())\n            if binary_predict is not None:\n                params_set[\"team_provided\"] = True            \n                current_frame_helmets[\"team_pred\"] = binary_predict\n            else:\n                pred_team = tf.numpy_function(func=similarity_matrix_to_team, inp=[pred_simmat[0]], Tout=[tf.float32])\n                current_frame_helmets[\"team_pred\"] = pred_team.numpy().reshape(-1)\n                params_set[\"team_provided\"] = False\n            list_current_frame_helmets[i] = current_frame_helmets\n            list_params_set[i] = params_set  \n        return list_current_frame_helmets, list_params_set     \n    \n    \n    def preprocess_registration(self, current_frame_helmets, current_tracking, \n                                trk, params_set,\n                                game_play, view, frame,\n                                start_frame=1, view_frequency=10000, \n                               only_return_inputs=False):\n        \n        try:\n            box_idx_high_iou, ious = trk.precheck_iou(game_play, view, frame, \n                                                      current_boxes = current_frame_helmets[[\"top\", \"left\", \"bottom\", \"right\"]].values,\n                                                      iou_threshold=0.3)\n            if box_idx_high_iou is not None:\n                conf_rescore = current_frame_helmets[\"conf\"].values# - 0.1# - 0.05\n                conf_rescore[box_idx_high_iou] += 0.1#ious*0.1\n                current_frame_helmets[\"conf\"] = conf_rescore\n        except:\n            pass                \n        #print(len(box_idx_high_iou), \"in\", len(conf_rescore), \"is high iou\")\n        \n        all_locations = current_tracking[[\"x\",\"y\"]].values#make_locations(current_tracking)\n        all_players = current_tracking[\"player\"].values.tolist()\n        test_inputs, all_data = self.preprocess_inputs(all_locations, all_players)\n        if only_return_inputs:\n            return test_inputs, all_data\n        try:\n            ref_box_indexs, notrack_box_indexs, ref_locations = trk.precheck_and_get_location(game_play, view, frame, \n                                                                  current_boxes = current_frame_helmets[[\"top\", \"left\", \"bottom\", \"right\"]].values,\n                                                                  )\n        except:\n            ref_box_indexs = None\n        # default setting\n        params_set[\"random\"] = None\n        if params_set[\"lost_track_frame\"]>2:\n            params_set[\"determined\"] = None\n        \n        if ((frame-start_frame)<5) or (params_set[\"side_fixed\"]==False): # provide filtered initial\n            use_provided_params = tf.constant(False)\n            rz_params = tf.ones((3),tf.float32)\n            txy_params = tf.ones((2,3),tf.float32)\n            zoom_params = tf.ones((3),tf.float32)\n            params_set[\"random\"] = {\"use_provided_params\":use_provided_params,\n                                    \"rz_params\":rz_params,\n                                    \"txy_params\":txy_params,\n                                    \"zoom_params\":zoom_params,\n                                    \"use_random_params\":tf.constant(True),\n                                    }\n        if ((frame-start_frame)>=5):\n            if np.std(params_set[\"hist_rot_angles\"][-5:])<0.075:\n                mean_angle =np.mean(params_set[\"hist_rot_angles\"][-5:])\n                if view==\"Endzone\":\n                    if mean_angle<(np.pi/2+0.65) and mean_angle>(np.pi/2-0.65):\n                        params_set[\"side_fixed\"] = True\n                        params_set[\"base_angle\"] = mean_angle\n                    elif mean_angle<(-np.pi/2+0.65) and mean_angle>(-np.pi/2-0.65):\n                        params_set[\"side_fixed\"] = True\n                        params_set[\"base_angle\"] = mean_angle\n                        \n                else:#Sideline\n                    if mean_angle<(np.pi+0.65) and mean_angle>(np.pi-0.65):\n                        params_set[\"side_fixed\"] = True\n                        params_set[\"base_angle\"] = mean_angle\n                    elif mean_angle<0.65 and mean_angle>-0.65:\n                        params_set[\"side_fixed\"] = True\n                        params_set[\"base_angle\"] = mean_angle                                           \n\n            if params_set[\"side_fixed\"]:\n                use_provided_params = tf.constant(True)\n                #use_random_params = tf.constant(True)\n                #rz_params = tf.constant([rotation_angle_filtered, 0.10, 2000],tf.float32)\n                rz_params = tf.constant([params_set[\"base_angle\"], 0.20, 100],tf.float32)\n                #txyは今無効。num_fitting_iter=8, 1stepの動作量を1/Nにする。\n                txy_params = tf.constant([[params_set[\"xy_location_filtered\"][0], 0.10, 5],\n                                          [params_set[\"xy_location_filtered\"][1], 0.10, 5]],tf.float32)    \n                zoom_params = tf.stack([0.0, 0.5, 5.])\n                params_set[\"random\"] = {\"use_provided_params\":tf.constant(True),\n                                    \"rz_params\":rz_params,\n                                    \"txy_params\":txy_params,\n                                    \"zoom_params\":zoom_params,\n                                    \"use_random_params\":tf.constant(True),\n                                    }\n        \n        \n            if ref_box_indexs is not None and use_provided_params:\n                ##print(\"num_tracked\", len(ref_box_indexs))\n                temp_current_frame_helmets = current_frame_helmets.copy().iloc[ref_box_indexs,:]\n                success = True\n                pred_location = tf.cast(current_frame_helmets[[\"loc_x\", \"loc_y\"]].values, tf.float32)\n                rot_init = params_set[\"base_angle\"]\n                \n                try:\n                    num_iter=50\n                    l2_reg=0.1\n                    trans_sources, trans_sources_all, transmatrix, rz_params, zoom_params, txy_params, init_error, assigned_targets, assignments, dist_to_near_targets, dist_to_near_sources, dist_to_near_targets_not_assigned = self.prelocate(pred_location, \n                                   tf.cast(ref_box_indexs, tf.int32), \n                                   tf.cast(notrack_box_indexs, tf.int32),\n                                   tf.cast(ref_locations, tf.float32), \n                                   tf.cast(all_data[\"all_locations\"], tf.float32),\n                                   l2_reg,\n                                   num_iter,\n                                   rot_init)\n                except:\n                    try:\n                        num_iter=500\n                        l2_reg=1.0\n                        trans_sources, trans_sources_all, transmatrix, rz_params, zoom_params, txy_params, init_error, assigned_targets, assignments, dist_to_near_targets, dist_to_near_sources, dist_to_near_targets_not_assigned = self.prelocate(pred_location, \n                                   tf.cast(ref_box_indexs, tf.int32), \n                                   tf.cast(notrack_box_indexs, tf.int32),\n                                   tf.cast(ref_locations, tf.float32), \n                                   tf.cast(all_data[\"all_locations\"], tf.float32),\n                                   l2_reg,\n                                   num_iter,\n                                   rot_init)\n                    except:\n                        try:\n                            num_iter=500\n                            l2_reg=5.0\n                            trans_sources, trans_sources_all, transmatrix, rz_params, zoom_params, txy_params, init_error, assigned_targets, assignments, dist_to_near_targets, dist_to_near_sources, dist_to_near_targets_not_assigned = self.prelocate(pred_location, \n                                       tf.cast(ref_box_indexs, tf.int32), \n                                       tf.cast(notrack_box_indexs, tf.int32),\n                                       tf.cast(ref_locations, tf.float32), \n                                       tf.cast(all_data[\"all_locations\"], tf.float32),\n                                       l2_reg,\n                                       num_iter\n                                       )\n                        except:\n                            success = False\n                            ref_box_indexs = None\n                \n                \n                    \n                if success:    \n                    \n                    # judge out of fieald helmets. by y_location and distance to nearest target \n                    min_x = 0.05\n                    max_x = (120.0/20.0)-0.05\n                    min_y = 0.05\n                    max_y = (53.3/20.0)-0.05\n                    allowable_dist_error_0 = 0.10#レンジ外とあわせてNGにする条件\n                    allowable_dist_error_1 = 0.25#単独でNGにする条件\n                    in_field_box_x = tf.logical_and(trans_sources_all[:,0]>min_x, trans_sources_all[:,0]<max_x)\n                    in_field_box_y = tf.logical_and(trans_sources_all[:,1]>min_y, trans_sources_all[:,1]<max_y)\n                    in_field_box = tf.logical_and(in_field_box_x, in_field_box_y)\n                    in_field_box = tf.logical_or(in_field_box, dist_to_near_targets<(allowable_dist_error_0**2)).numpy()\n                    neglected_helmets_loc = trans_sources_all.numpy()[~in_field_box]\n\n                    # neglect targets far from predicted points\n                    if params_set[\"neglect_far_targets\"]:\n                        source_is_near = (dist_to_near_sources<(allowable_dist_error_1**2))\n                        neglected_helmets_from_targets = all_data[\"all_locations\"][~source_is_near.numpy()]\n                        test_inputs[\"team_labels\"] = tf.boolean_mask(test_inputs[\"team_labels\"], source_is_near, axis=0)\n                        test_inputs[\"all_locations\"] = tf.boolean_mask(test_inputs[\"all_locations\"], source_is_near, axis=0)\n                        all_data[\"all_locations\"] =  all_data[\"all_locations\"][source_is_near.numpy()]\n                        all_data[\"all_players\"] =  all_data[\"all_players\"][source_is_near.numpy()]\n                        all_data[\"team_labels\"] =  tf.boolean_mask(all_data[\"team_labels\"], source_is_near, axis=0)\n                        #print(len(neglected_helmets_from_targets), \"targets are neglected.\")\n\n                    # neglect predicted points far from targets\n                    target_is_near = (dist_to_near_targets<(allowable_dist_error_1**2)).numpy()\n                    neglected_helmets_far = trans_sources_all.numpy()[~target_is_near]\n                    ok_mask = np.logical_and(in_field_box, target_is_near)\n\n                    notrack_box_indexs = np.array(notrack_box_indexs).astype(int)\n                    if len(notrack_box_indexs) > 0:\n                        target_is_near_not_assigned = (dist_to_near_targets_not_assigned<(allowable_dist_error_1**2)).numpy()\n                        neglected_helmets_far_not_assigned = trans_sources_all.numpy()[np.array(notrack_box_indexs)][~target_is_near_not_assigned]\n                        mask_not_assigned_dist = np.array([True for _ in range(len(current_frame_helmets))])\n                        mask_not_assigned_dist[np.array(notrack_box_indexs)] = target_is_near_not_assigned\n                        drop_by_this = np.logical_and(ok_mask, ~mask_not_assigned_dist)\n                        ok_mask = np.logical_and(ok_mask, mask_not_assigned_dist)\n                    else:\n                        neglected_helmets_far_not_assigned = []\n                    current_frame_helmets = current_frame_helmets[ok_mask]\n                    \n                    if DRAW_PREREGI and frame%view_frequency==0:\n                        plt.scatter(assigned_targets[0,:,0], assigned_targets[0,:,1], color=\"blue\")\n                        plt.scatter(trans_sources[0,:,0], trans_sources[0,:,1], color=\"red\")\n                        plt.scatter(trans_sources_all[:,0], trans_sources_all[:,1], color=\"red\", alpha=0.3)\n                        if len(neglected_helmets_loc)>0:\n                            plt.scatter(neglected_helmets_loc[:,0], neglected_helmets_loc[:,1], facecolors=\"none\", edgecolors=\"green\")\n                        if len(neglected_helmets_far)>0:\n                            plt.scatter(neglected_helmets_far[:,0], neglected_helmets_far[:,1], facecolors=\"none\", edgecolors=\"gray\")\n                        if params_set[\"neglect_far_targets\"]:\n                            if len(neglected_helmets_from_targets)>0:\n                                print(len(neglected_helmets_from_targets), \"targets are neglected.\")\n                                plt.scatter(all_data[\"all_locations\"][:,0], all_data[\"all_locations\"][:,1], color=\"black\", alpha=0.15)\n                                plt.scatter(neglected_helmets_from_targets[:,0], neglected_helmets_from_targets[:,1], color=\"black\")\n                        plt.title(\"frame {} preregistration\".format(str(frame)))\n                        plt.show()\n                        \n                    if len(current_frame_helmets)>1:\n                        params_set[\"determined\"] = {\"use_provided_params\":tf.constant(True),\n                                            \"rz_params\":rz_params,\n                                            \"txy_params\":txy_params,\n                                            \"zoom_params\":zoom_params,\n                                            \"use_random_params\":tf.constant(False),\n                                            }\n                        params_set[\"lost_track_frame\"] = 0\n                    else:\n                        current_frame_helmets = temp_current_frame_helmets\n\n\n        if ref_box_indexs is None:\n            params_set[\"lost_track_frame\"] += 1\n            #params_set[\"neglect_far_targets\"] = False\n        \n        base_thresh = 0.2# minimum detection score use for registration\n        num_min_mapping = 2\n        num_detect = len(current_frame_helmets)\n        min_thresh = np.minimum(base_thresh, current_frame_helmets[\"conf\"].values[np.minimum(num_min_mapping, num_detect)-1])\n        current_frame_helmets_low_conf = current_frame_helmets[current_frame_helmets[\"conf\"]<min_thresh]\n        current_frame_helmets = current_frame_helmets[current_frame_helmets[\"conf\"]>=min_thresh]\n        if len(current_tracking) < len(current_frame_helmets):#過剰捲縮t時は\n            current_frame_helmets_low_conf = pd.concat([current_frame_helmets[len(current_tracking):], current_frame_helmets_low_conf])\n            current_frame_helmets = current_frame_helmets[:len(current_tracking)]#.sort_values('conf', ascending=False)[:len(current_tracking)]\n        \n        params_set[\"num_harddrop\"] = 0# not use\n        params_set[\"num_softdrop\"] = 0\n        \n        # change confidence threshold for drop during registration\n        conf_limit = current_frame_helmets[\"conf\"].values[-params_set[\"num_harddrop\"]] if params_set[\"num_harddrop\"]>0 else 0.0\n        params_set[\"conf_threshold\"] = np.maximum(0.4, conf_limit)\n        return current_frame_helmets, current_frame_helmets_low_conf, params_set, test_inputs, all_data\n\n\n    def run_registration(self, current_frame_helmets, current_frame_helmets_low_conf,\n                         params_set, test_inputs, all_data, \n                         tfh, f_columns,\n                         game_play, view, frame):\n\n        \n        pred_location = tf.cast(current_frame_helmets[[\"loc_x\", \"loc_y\"]].values, tf.float32)\n        pred_team = tf.cast(current_frame_helmets[\"team_pred\"].values.reshape(-1,1), tf.float32)\n        confidence = tf.cast(current_frame_helmets[\"conf\"].values, tf.float32)\n        feature_dist_mat = np.zeros((len(pred_location), len(test_inputs[\"all_locations\"])), np.float32)\n        \n        if params_set[\"determined\"] is None:# random initialized ICP    \n            icp_inputs = make_icp_inputs(targets=test_inputs[\"all_locations\"], \n                                         sources=pred_location,\n                                         targets_team=test_inputs[\"team_labels\"],\n                                         sources_team=pred_team, \n                                         team_provided=params_set[\"team_provided\"], \n                                         confidence=confidence,\n                                         confidence_threshold=params_set[\"conf_threshold\"], \n                                         num_trial=100,\n                                         is_sideline=(view==\"Sideline\"),\n                                         **params_set[\"random\"])\n            results = random_icp_fitting(*icp_inputs, \n                                         st_cost_matrix=feature_dist_mat, \n                                         num_fitting_iter=8,\n                                         num_harddrop = params_set[\"num_harddrop\"],\n                                         num_softdrop=params_set[\"num_softdrop\"],)\n                    \n        else:# use random and fixed initialized ICP\n            if params_set[\"team_provided\"]:\n                num_try_r = 40\n                num_try = 20\n            else:\n                num_try_r = 60\n                num_try = 30  \n            icp_inputs_r = make_icp_inputs(targets=test_inputs[\"all_locations\"], \n                                         sources=pred_location,\n                                         targets_team=test_inputs[\"team_labels\"],\n                                         sources_team=pred_team, \n                                         team_provided=params_set[\"team_provided\"], \n                                         confidence=confidence,\n                                         confidence_threshold=params_set[\"conf_threshold\"], \n                                         num_trial=num_try_r,\n                                         is_sideline=(view==\"Sideline\"),\n                                         **params_set[\"random\"])\n            icp_inputs = make_icp_inputs(targets=test_inputs[\"all_locations\"], \n                                         sources=pred_location,\n                                         targets_team=test_inputs[\"team_labels\"],\n                                         sources_team=pred_team, \n                                         team_provided=params_set[\"team_provided\"], \n                                         confidence=confidence,\n                                         confidence_threshold=params_set[\"conf_threshold\"], \n                                         num_trial=num_try,\n                                         is_sideline=(view==\"Sideline\"),\n                                         **params_set[\"determined\"])\n            icp_inputs = [tf.concat([x,y], axis=0) for x,y in zip(icp_inputs, icp_inputs_r)]\n            results = random_icp_fitting(*icp_inputs, \n                                         st_cost_matrix=feature_dist_mat, \n                                         num_fitting_iter=8,\n                                         num_harddrop = params_set[\"num_harddrop\"],\n                                         num_softdrop=params_set[\"num_softdrop\"],)\n\n        keys = [\"residual\", \"trans_matrix\", \"trans_sources\", \"final_assignment\", \"raw_results\", \"assigned_mask\", \"xy_residual\"]\n        results = {k:v for k,v in zip(keys, results)}\n        \n        def check_team_sign(before_team_labels, after_team_labels):\n            if len(before_team_labels)!=len(after_team_labels):\n                raise Exception(\"length of before and after is different\")\n            before = np.argmax(before_team_labels)#[-1]-before_team_labels[0])\n            after = np.argmax(after_team_labels)#[-1]-after_team_labels[0])\n            if before==after:\n                sign = 1.0\n                # before*rate = after\n                rate = after_team_labels[0]/before_team_labels[0]\n            else:\n                sign = -1.0\n                # (1-before)*rate = after\n                rate = after_team_labels[0]/(1.0-before_team_labels[0])\n            return sign, 0.1# team weight used for icp registration\n        results[\"trans_sources\"] = tf.boolean_mask(results[\"trans_sources\"], results[\"assigned_mask\"])\n        \n        pred_team_finally = results[\"trans_sources\"].numpy()[:,2]\n        team_sign, team_w = check_team_sign(pred_team.numpy()[results[\"assigned_mask\"].numpy()].reshape(-1,1), pred_team_finally)\n        \n        results_assignment = results[\"final_assignment\"].numpy()#.astype(int)\n        assigned_label = all_data[\"all_players\"][results_assignment]\n        xy_residual = results[\"xy_residual\"].numpy().reshape(-1)\n        \n        if params_set[\"num_harddrop\"]>0:\n            current_frame_helmets = current_frame_helmets[results[\"assigned_mask\"].numpy()]\n        \n        # save team features                            \n        tfh.add(pred_team_finally/team_w, \n                test_inputs[\"team_labels\"].numpy().reshape(-1)[results_assignment], \n                current_frame_helmets[f_columns].values)\n        \n        if len(current_frame_helmets) < len(all_data[\"all_players\"]):\n            # assign from remaining targets and remaining predictions(low detection score)\n            remain_idx = np.array(list(set(range(len(all_data[\"all_players\"]))) - set(results_assignment)))\n            not_assigned_targets = all_data[\"all_locations\"][remain_idx]\n            not_assigned_targets_team = team_w*test_inputs[\"team_labels\"].numpy()[remain_idx]\n            not_assigned_sources = current_frame_helmets_low_conf[[\"loc_x\", \"loc_y\"]].values\n            not_assigned_sources = transform_points(results[\"trans_matrix\"], tf.cast(not_assigned_sources, tf.float32)).numpy()\n            \n            not_assigned_sources_team = team_w*current_frame_helmets_low_conf[\"team_pred\"].values\n            not_assigned_sources_team = not_assigned_sources_team if team_sign==1.0 else  (team_w-not_assigned_sources_team)\n            \n            not_assigned_sources = np.concatenate([not_assigned_sources, not_assigned_sources_team.reshape(-1,1)], axis=-1)\n            not_assigned_targets = np.concatenate([not_assigned_targets, not_assigned_targets_team.reshape(-1,1)], axis=-1)\n            thresh_dist_add = 0.12**2\n            \n            median_assigned = np.median(xy_residual)\n            max_assigned = np.max(xy_residual)\n            #print(\"median_error: \", median_assigned)\n            #thresh_dist_add_0 = np.minimum(thresh_dist_add, median_assigned*2)\n            thresh_dist_add = np.minimum(thresh_dist_add, max_assigned)\n            \n            conf_th_for_rest_assign = 0.1\n            distmat = np.sum((not_assigned_sources[:,np.newaxis,:] - not_assigned_targets[np.newaxis,:,:])**2, axis=-1)\n            distmat_conf = distmat + (current_frame_helmets_low_conf[\"conf\"].values < conf_th_for_rest_assign).reshape(-1,1).astype(float) * 100\n            \n            #take from minimum\n            xy_redisual_add = []\n            pred_idx_add = []\n            assigned_idx_add = []\n            idx_list_s = np.arange(distmat.shape[0])\n            idx_list_t = np.arange(distmat.shape[1])\n            \n            from_high_conf = True\n            # not implemented(forget adding 100 to threshold)\n            while True:\n                num_s, num_t = distmat.shape[:2]\n                if num_s==0 or num_t==0:\n                    break\n                if from_high_conf:\n                    mat = distmat_conf\n                else:\n                    mat = distmat\n                argmin = np.argmin(mat)\n                idx_s, idx_t = argmin//num_t, argmin%num_t\n                min_value = mat[idx_s, idx_t]\n                if min_value>100.0:\n                    from_high_conf = False\n                    continue\n                if min_value>thresh_dist_add:\n                    break\n                else:\n                    pred_idx_add.append(idx_list_s[idx_s])\n                    assigned_idx_add.append(idx_list_t[idx_t])\n                    xy_redisual_add.append(min_value)\n                    distmat = np.delete(distmat, idx_s, axis=0)\n                    distmat = np.delete(distmat, idx_t, axis=1)\n                    distmat_conf = np.delete(distmat_conf, idx_s, axis=0)\n                    distmat_conf = np.delete(distmat_conf, idx_t, axis=1)\n                    idx_list_s = np.delete(idx_list_s, idx_s)\n                    idx_list_t = np.delete(idx_list_t, idx_t)\n\n            if len(pred_idx_add) > 0:\n                #print(\"NEW ASSIGN\", len(pred_idx_add))\n                HIGH_RESIDUAL = False\n                xy_redisual_add = np.array(xy_redisual_add)\n                add_helmets = current_frame_helmets_low_conf.iloc[np.array(pred_idx_add),:]\n                current_frame_helmets = pd.concat([current_frame_helmets, add_helmets], axis=0)\n                assigned_idx_add = remain_idx[np.array(assigned_idx_add)]\n                results_assignment = np.concatenate([results_assignment, assigned_idx_add], axis=0)\n                assigned_label_add = all_data[\"all_players\"][assigned_idx_add]\n                assigned_label = np.concatenate([assigned_label, assigned_label_add], axis=0)\n                xy_residual = np.concatenate([xy_residual, xy_redisual_add], axis=0)\n                \n        results[\"xy_residual\"] = xy_residual\n        results[\"final_assignment\"] = results_assignment        \n        rot = results[\"raw_results\"][1].numpy()\n        params_set[\"hist_rot_angles\"].append(rot)\n        update_ratio = 0.1\n        if params_set[\"xy_location_filtered\"] is None:\n            params_set[\"xy_location_filtered\"] = np.mean(results[\"trans_sources\"].numpy()[:,:2], axis=0)\n        else:\n            params_set[\"xy_location_filtered\"] = params_set[\"xy_location_filtered\"]*(1-update_ratio) + np.mean(results[\"trans_sources\"].numpy()[:,:2], axis=0)*update_ratio\n            \n        return results, assigned_label, params_set, current_frame_helmets\n        \n       \n        \n    def test_predict_ensemble_batch(self, test_tracking, test_helmets, video_path, labels=None, save_path=\"output/temp/\"):\n         \n        all_labels = []\n        all_game_predictions = []\n        f_columns = [\"f{}\".format(i) for i in range(128)]\n        time_measurement = False\n        view_frequency = VIEW_FREQUENCY\n        for game_play, _df_tracking in test_tracking.groupby([\"game_play\"]):\n            current_test_helmets = test_helmets[test_helmets[\"game_play\"] == game_play]\n            views = current_test_helmets[\"view\"].unique()\n            #gameKey = game_play.split(\"_\")[0]\n            \n            for view in views:\n                print(\"GAME_PLAY: \", game_play, \" VIEW:\", view, len(_df_tracking))\n\n                current_view_test_helmets = current_test_helmets[current_test_helmets[\"view\"]==view]\n                video_file = video_path + game_play + \"_\" + view + \".mp4\"\n                cap = cv2.VideoCapture(video_file)\n                frames = current_view_test_helmets[\"frame\"].unique()\n                \n                frame_scores = []\n                self.hsh.reset()\n                self.hsh_select.reset()\n\n                start_frame = 1\n                end_frame = 1e7\n                \n                # prepare params and tracker for ensemble\n                num_det_ensemble = self.num_det_models\n                num_map_ensemble = 1\n                num_ensemble = num_det_ensemble * num_map_ensemble\n                list_residuals = [[] for _ in range(num_ensemble)]\n                list_all_predictions = [[] for _ in range(num_ensemble)]\n                list_trk = [Tracker_2_w_feature(0.3) for _ in range(num_ensemble)]\n                list_previous_frame_helmets = [None for _ in range(num_ensemble)]\n                list_previous_assigned_label = [None for _ in range(num_ensemble)]\n                list_previous_results = [None for _ in range(num_ensemble)]\n                list_params_set = [{\"random\":None, \"determined\":None, \"lost_track_frame\":0, \"side_fixed\":False,\n                              \"conf_threshold\":0.4, \"num_harddrop\":0, \"num_softdrop\":0, \"base_angle\":0.0,\n                              \"hist_rot_angles\":[], \"xy_location_filtered\": None, \"team_provided\":False,\n                              \"neglect_far_targets\": False} for _ in range(num_ensemble)]\n                frame_info = {\"game_play\":game_play, \"view\":view, \"frame\":1}\n                list_tfh = [TeamFeaturesHolder(num_features=128, update_freq=100) for _ in range(num_ensemble)]                \n                batch_data = Batch_data()\n\n\n                if labels is not None:\n                    _labels = labels[labels[\"game_play\"] == frame_info[\"game_play\"]]\n                    _labels = _labels[_labels[\"view\"] == view]\n                    \n                for f in frames:\n                    frame_info[\"frame\"] = f\n                    ret, img = cap.read()\n                    \n                    img_array = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                    img = self.preprocess_rgb(img_array)\n                    \n                    batch_data.add(img, img_array, f)\n                    \n                    if not (f==frames[-1] or batch_data.length==self.inference_batch):# if batch size>1, stack inputs\n                        continue\n                    \n                    frame_info[\"frame\"] = batch_data.frames\n                    \n                    # ----- HELMETS DETECTION -----\n                    S = time.time()\n                    batch_list_current_frame_helmets, batch_list_tlbr_boxes = self.run_detection_ensemble_batch(batch_data.imgs, \n                                                                                                                **frame_info)\n                                            \n                    if time_measurement: print(\"det\", time.time()-S)\n                    S = time.time()\n                    \n                    \n                    for _list_current_frame_helmets, _list_tlbr_boxes, frame, img, img_array in zip(batch_list_current_frame_helmets, batch_list_tlbr_boxes, batch_data.frames, batch_data.imgs, batch_data.img_arrays):\n                        print(\"\\r----- predicting {}/{} -----\".format(frame, len(frames)), end=\"\")\n                        frame_info[\"frame\"] = frame\n                        current_tracking = _df_tracking[_df_tracking[\"frame\"]==frame]\n                        \n                        # copy box and df\n                        list_tlbr_boxes = []\n                        list_current_frame_helmets = []\n                        \n                        for d_idx in range(num_det_ensemble):\n                            for m_idx in range(num_map_ensemble):\n                                list_tlbr_boxes.append(_list_tlbr_boxes[d_idx])\n                                list_current_frame_helmets.append(_list_current_frame_helmets[d_idx].copy())\n\n                        # for each detection model, run mapping-registration-tracking\n                        for ensemble_idx in range(num_ensemble):\n\n                            print(\"\\r----- predicting {}/{}_{} -----\".format(frame, len(frames), ensemble_idx), end=\"\")\n                            tfh = list_tfh[ensemble_idx]\n                            trk = list_trk[ensemble_idx]\n                            #current_frame_helmets = list_current_frame_helmets[ensemble_idx]\n                            previous_results = list_previous_results[ensemble_idx]\n                            previous_frame_helmets = list_previous_frame_helmets[ensemble_idx]\n                            previous_assigned_label = list_previous_assigned_label[ensemble_idx]\n                            tlbr_boxes = list_tlbr_boxes[ensemble_idx]\n                            #params_set = list_params_set[ensemble_idx]\n                            residuals = list_residuals[ensemble_idx]\n                            all_predictions = list_all_predictions[ensemble_idx]\n\n                            # ----- MAPPING -----\n                            #current_frame_helmets, params_set = self.run_mapping(img, tlbr_boxes, current_frame_helmets, f_columns, tfh, params_set)  \n                            if len(tlbr_boxes)>0:\n                                if ensemble_idx % num_map_ensemble==0:\n                                    l_current_frame_helmets = list_current_frame_helmets[ensemble_idx:(ensemble_idx+num_map_ensemble)]\n                                    l_params_set = list_params_set[ensemble_idx:(ensemble_idx+num_map_ensemble)]\n                                    l_tfh = list_tfh[ensemble_idx:(ensemble_idx+num_map_ensemble)]\n                                    l_current_frame_helmets, l_params_set = self.run_mapping_ensemble(img, tlbr_boxes, l_current_frame_helmets, f_columns, l_tfh, l_params_set)\n                                    for j, [helmets, params] in enumerate(zip(l_current_frame_helmets, l_params_set)):\n                                        list_current_frame_helmets[ensemble_idx+j] = helmets\n                                        list_params_set[ensemble_idx+j] = params\n\n                            current_frame_helmets = list_current_frame_helmets[ensemble_idx]\n                            params_set = list_params_set[ensemble_idx]\n\n                            if time_measurement: print(\"map\", time.time()-S)\n                            S = time.time()\n\n                            #----- POINTS TO POINTS REGISTRATION -----\n                            # if few bbox, skip registration\n                            if not len(current_frame_helmets)<2:\n                                # PREPROCESS of REGISTRATION\n                                try:\n                                    with tf.device('/CPU:0'):# cpu is faster than gpu\n                                        current_frame_helmets, current_frame_helmets_low_conf, params_set, test_inputs, all_data = self.preprocess_registration(\n                                                                                 current_frame_helmets, current_tracking, \n                                                                                 trk, params_set, \n                                                                                 start_frame=start_frame, view_frequency=view_frequency, **frame_info)\n\n                                except:\n                                    return None#notfound error instead of exception\n\n                                if time_measurement: print(\"pre registration\", time.time()-S)\n                                S = time.time()\n                                \n                            if len(current_frame_helmets)<2:\n                                if (previous_frame_helmets is not None) and (previous_assigned_label is not None):\n                                    results = previous_results\n                                    current_frame_helmets = previous_frame_helmets\n                                    assigned_label = previous_assigned_label\n                                    residual = 1.0e-3\n                                    params_set[\"hist_rot_angles\"].append(params_set[\"base_angle\"])\n                                    test_inputs, all_data = self.preprocess_registration(\n                                                                                 current_frame_helmets, current_tracking, \n                                                                                 trk, params_set, \n                                                                                 start_frame=start_frame, view_frequency=view_frequency,\n                                                                                only_return_inputs=True, **frame_info)\n                            else:\n                                # MAIN REGISTRATION   \n                                try:\n                                    with tf.device('/CPU:0'):# cpu is faster than gpu\n                                        results, assigned_label, params_set, current_frame_helmets = self.run_registration(current_frame_helmets, current_frame_helmets_low_conf,\n                                                                                                           params_set, test_inputs, all_data, \n                                                                                                           tfh, f_columns,\n                                                                                                           **frame_info)\n\n                                    \n                                except:\n                                    print(\"RETRY\")\n                                    if params_set[\"random\"] is not None:\n                                        params_set[\"random\"][\"zoom_params\"] = params_set[\"random\"][\"zoom_params\"] * tf.constant([1.0,1.0,10.0], tf.float32)\n\n                                    try:\n                                        with tf.device('/CPU:0'):\n                                            results, assigned_label, params_set, current_frame_helmets = self.run_registration(current_frame_helmets, current_frame_helmets_low_conf,\n                                                                                                           params_set, test_inputs, all_data, \n                                                                                                           tfh, f_columns,\n                                                                                                           **frame_info)\n\n                                    except:\n                                        current_output = pd.concat(all_game_predictions, axis=0)\n                                        current_output[\"height\"] = 1\n                                        current_output = current_output[~current_output[[\"video_frame\",\"left\", \"width\", \"top\", \"height\"]].duplicated()]\n                                        return current_output#LOW SCORE instead of exception\n                                    \n                                if time_measurement: print(\"main registration\", time.time()-S)\n                                S = time.time()\n                                residual = results[\"residual\"].numpy()\n                                residuals.append(residual)\n                                    \n                                if DRAW_BBOX and frame%view_frequency==0:\n                                    self.draw_bbox(img_array, \n                                                   current_frame_helmets[[\"top\", \"left\", \"height\", \"width\"]].values, \n                                                   #frame_label[[\"top\", \"left\", \"height\", \"width\"]].values, \n                                                   save_only = False,\n                                                   )\n                                if DRAW_REGI and frame%view_frequency==0:\n                                    team_color_gt = all_data[\"team_labels\"].numpy().reshape(-1)\n                                    results_xy = results[\"trans_sources\"].numpy()[:,:2]\n                                    team_color = results[\"trans_sources\"].numpy()[:,2]*10\n                                    gt_loc_all = all_data[\"all_locations\"]\n                                    plt.scatter(gt_loc_all[:,0][team_color_gt<0.5], gt_loc_all[:,1][team_color_gt<0.5], c=\"blue\", alpha=0.2)\n                                    plt.scatter(results_xy[...,0][team_color<0.5], results_xy[...,1][team_color<0.5], c=\"blue\")\n                                    plt.scatter(gt_loc_all[:,0][team_color_gt>0.5], gt_loc_all[:,1][team_color_gt>0.5], c=\"red\", alpha=0.2)\n                                    plt.scatter(results_xy[...,0][team_color>0.5], results_xy[...,1][team_color>0.5], c=\"red\")\n                                    plt.title(\"ICP registration error {}\".format(residual))\n                                    plt.show()\n                                \n\n                            # make submit dataframe\n                            predictions = np.round(current_frame_helmets[[\"left\", \"width\", \"top\", \"height\"]].copy()).astype(int)\n                            predictions[\"label\"] = assigned_label\n                            predictions[\"video_frame\"] = frame_info[\"game_play\"] + \"_\" + frame_info[\"view\"] + \"_\" + str(frame_info[\"frame\"])\n                            all_predictions.append(predictions)\n\n                            #scoring for validation\n                            if labels is not None:\n                                frame_label = _labels[_labels[\"frame\"]==frame]\n                                scorer = NFLAssignmentScorer(frame_label, impact_weight=1)\n                                scorer_w = NFLAssignmentScorer(frame_label)\n                                frame_score = scorer.score(predictions)\n                                frame_score_w = scorer_w.score(predictions)\n                                if ensemble_idx==0:\n                                    all_labels.append(frame_label)\n                                frame_scores.append(frame_score)\n                                print(frame_score, frame_score_w)\n                            \n                            # ----- Accumurate data in Tracker -----\n                            try:\n                                trk.predict_and_add(assigned_player = assigned_label, \n                                                    current_boxes = current_frame_helmets[[\"top\", \"left\", \"bottom\", \"right\"]].values,\n                                                    locations = all_data[\"all_locations\"][results[\"final_assignment\"]], \n                                                    player_feature = current_frame_helmets[f_columns].values,\n                                                    weight = (-np.log(results[\"xy_residual\"])),#**2,\n                                                    icp_errors=np.log(results[\"xy_residual\"]),\n                                                    conf = current_frame_helmets[\"conf\"].values,\n                                                    **frame_info)\n                                \n                            except:\n                                current_output = pd.concat(all_game_predictions, axis=0)\n                                current_output[\"height\"] = (current_output[\"height\"].values*0.65).astype(int)\n                                current_output = current_output[~current_output[[\"video_frame\",\"left\", \"width\", \"top\", \"height\"]].duplicated()]\n                                return current_output#lowscore\n\n\n                            if time_measurement: print(\"aft registration\", time.time()-S)\n                            S = time.time()\n\n                            previous_frame_helmets = current_frame_helmets.copy()\n                            previous_assigned_label = assigned_label.copy()\n                            previous_results = results\n\n                            list_previous_frame_helmets[ensemble_idx] = previous_frame_helmets\n                            list_previous_assigned_label[ensemble_idx] = previous_assigned_label\n                            list_previous_results[ensemble_idx] = previous_results\n                            list_params_set[ensemble_idx] = params_set\n                            list_residuals[ensemble_idx] = residuals\n                            list_all_predictions[ensemble_idx] = all_predictions\n                    batch_data.reset()    \n                    if frame==end_frame:\n                        break\n                \n                end_frame = frame\n                print(\"\\r----- reassignmenting using tracking data-----\", end=\"\")\n                \n                list_df_preds = []\n                for frame in range(1,end_frame+1):\n                    frame_info[\"frame\"] = frame\n                    fusion_boxes, fusion_confs, assigned_label = wbf_ensemble_reassign_player_label(list_trk, **frame_info)\n                    predictions = pd.DataFrame(fusion_boxes, columns=[\"top\", \"left\", \"bottom\", \"right\"])\n                    predictions[\"height\"] = predictions[\"bottom\"] - predictions[\"top\"]\n                    predictions[\"width\"] = predictions[\"right\"] - predictions[\"left\"]\n                    predictions = np.round(predictions[[\"left\", \"width\", \"top\", \"height\"]].copy()).astype(int)\n                    predictions[\"label\"] = assigned_label\n                    predictions[\"video_frame\"] = game_play + \"_\" + view + \"_\" + str(frame)\n                    predictions = predictions[~predictions[[\"left\", \"width\", \"top\", \"height\"]].duplicated()]\n                    list_df_preds.append(predictions)                        \n\n                all_game_predictions.append(pd.concat(list_df_preds, axis=0))\n                print(\"----- reassignmenting finished -----\")\n                \n        if labels is None:           \n            return pd.concat(all_game_predictions, axis=0)\n        else:\n            return pd.concat(all_game_predictions, axis=0), pd.concat(all_labels, axis=0)        \n                \n    def preprocess_rgb(self, file_or_array):\n        if type(file_or_array)==str:\n            rgb = tf.io.read_file(file_or_array)\n            rgb = tf.image.decode_jpeg(rgb, channels=3)\n        else:\n            if type(file_or_array)==list:\n                rgb = tf.concat(file_or_array, axis=-1)\n            else:\n                rgb = file_or_array\n        rgb = tf.cast(rgb, tf.float32)/255.0\n        rgb = rgb[tf.newaxis,:,:,:]\n        return rgb\n        \n    def preprocess_inputs(self, \n                          all_locations, \n                          all_players, #all_motions,\n                          locations=None, # label\n                          players=None,# label\n                          img_height=720,\n                          img_width=1280,\n                          **kwargs):\n\n        all_locations = tf.cast(all_locations, tf.float32)/20.0\n        all_locations = tf.reshape(all_locations, [-1,2])\n        #all_motions = tf.cast(all_motions, tf.float32)\n        #all_motions = tf.reshape(all_motions, [-1,2])\n        \n        if locations is not None:\n            locations = tf.cast(locations, tf.float32)/20.0\n            locations = tf.reshape(locations, [-1,2])\n            gt_points = locations[tf.newaxis,:,:]\n        else:\n            gt_points = None\n\n        team_labels = tf.constant(np.array([\"H\" in p for p in all_players]).reshape(-1,1).astype(np.float32))\n\n        inputs_registration = {\n                  \"all_locations\": all_locations,\n                  \"team_labels\": team_labels}\n        \n        all_data = {\n                  \"locations\": locations,\n                  \"team_labels\": team_labels,\n                  \"players\": players,\n                  #\"all_motions\": all_motions,\n                  \"all_locations\": np.array(all_locations),\n                  \"all_players\": np.array(all_players),                  \n                  }\n        return inputs_registration, all_data\n    \n\ndef set_seeds(num=111):\n    tf.random.set_seed(num)\n    np.random.seed(num)\n    random.seed(num)\n    os.environ[\"PYTHONHASHSEED\"] = str(num)\n\ndef run_test(nfl_model):\n    \n    set_seeds(111)\n    debug=False\n    \n    conf_thresh = 0.02\n    tracking_df = te_tracking\n    helmets_df = te_helmets\n    if debug:\n        tracking_df = tr_tracking.copy()\n        helmets_df = tr_helmets.copy()\n    \n    helmets_df = helmets_df[helmets_df[\"conf\"]>conf_thresh]\n\n    split_names = helmets_df[\"video_frame\"].str.rsplit('_', n=2, expand=True).rename(columns={0: 'game_play', 1: 'view', 2:\"frame\"})\n    helmets_df = pd.concat([helmets_df, split_names], axis=1)\n    helmets_df[\"frame\"] = helmets_df[\"frame\"].astype('int')\n    helmets_df = helmets_df.sort_values(['game_play', \"frame\"])\n    \n    if len(helmets_df)<100000 and debug==False:\n        helmets_df = helmets_df[(helmets_df[\"game_play\"]==helmets_df[\"game_play\"].values[0])&(helmets_df[\"view\"]==\"Sideline\")]\n        helmets_df.to_csv('submission.csv', index=False)\n        return None\n    if debug:\n        game_play = '58005_001254'\n        view = 'Sideline'    \n        helmets_df = helmets_df[(helmets_df[\"game_play\"]==game_play)&(helmets_df[\"view\"]==view)]\n    \n    video_path = \"../input/nfl-health-and-safety-helmet-assignment/test/\"\n    if debug:\n        video_path = \"../input/nfl-health-and-safety-helmet-assignment/train/\"\n\n    results = nfl_model.test_predict_ensemble_batch(tracking_df, helmets_df, video_path)\n    if results is not None:\n        results.to_csv('submission.csv', index=False)\n    if debug:\n        scorer = NFLAssignmentScorer(labels[labels[\"video\"]==\"{}_{}.mp4\".format(game_play, view)])\n        print(scorer.score(results))\n    return results\n\n\ndef build_val_model():\n    K.clear_session()\n    set_seeds(111)\n    debug=True\n   \n    model_params = {\"input_shape\": (512, 896, 3),\n                    \"output_shape\": (128, 224),\n                    \"weight_file\": {\"map\": SRC_PATH+\"/model/weights/map/final_weights.h5\",\n                                    \"team\": SRC_PATH+\"/model/weights/team/final_weights.h5\",\n                                    \"det\": SRC_PATH+\"/model/weights/det_base/final_weights.h5\",\n                                    \"detL\": [[\"effv2s\", SRC_PATH+\"/model/weights/det_v2s/final_weights.h5\"],\n                                             [\"effv2m\", SRC_PATH+\"/model/weights/det_v2m/final_weights.h5\"],\n                                             [\"effv2l\", SRC_PATH+\"/model/weights/det_v2l/final_weights.h5\"],\n                                             [\"effv2xl\", SRC_PATH+\"/model/weights/det_v2xl/final_weights.h5\"],\n                                            ],\n                                    }, \n                    \"is_train_model\": False,\n                    \"inference_batch\": 1,\n                    }\n    if not ENSEMBLE:\n        model_params[\"weight_file\"][\"detL\"] = model_params[\"weight_file\"][\"detL\"][0:1]\n    nfl = NFL_Predictor(**model_params)\n    return nfl\n\ndef run_val(nfl_model,\n            game_play = '58005_001254',\n            view = 'Sideline',\n           ):\n    \n    #K.clear_session()\n    set_seeds(111)\n    \n    conf_thresh = 0.02\n    tracking_df = te_tracking\n    helmets_df = te_helmets\n    \n    tracking_df = tr_tracking.copy()\n    helmets_df = tr_helmets.copy()\n    \n    helmets_df = helmets_df[helmets_df[\"conf\"]>conf_thresh]\n\n    split_names = helmets_df[\"video_frame\"].str.rsplit('_', n=2, expand=True).rename(columns={0: 'game_play', 1: 'view', 2:\"frame\"})\n    helmets_df = pd.concat([helmets_df, split_names], axis=1)\n    helmets_df[\"frame\"] = helmets_df[\"frame\"].astype('int')\n    helmets_df = helmets_df.sort_values(['game_play', \"frame\"])\n        \n    \n    helmets_df = helmets_df[(helmets_df[\"game_play\"]==game_play)&(helmets_df[\"view\"]==view)]\n            \n    video_path = \"../input/nfl-health-and-safety-helmet-assignment/train/\"\n\n    ##nfl = NFL_Predictor(**model_params)#_deepsort\n    \n    temp_results = nfl_model.test_predict_ensemble_batch(tracking_df, helmets_df, video_path)\n    #temp_results = nfl_model.test_predict_2(tracking_df, helmets_df, video_path)\n    temp_results.to_csv('submission.csv', index=False)\n    \"\"\"\n    scorer = NFLAssignmentScorer(labels[labels[\"video\"]==\"{}_{}.mp4\".format(game_play, view)])\n    print(scorer.score(temp_results))\n    scorer = NFLAssignmentScorer(labels[labels[\"video\"]==\"{}_{}.mp4\".format(game_play, view)], impact_weight=1)\n    print(\"no weight score\", scorer.score(temp_results))\n    \n    scorer = NFLAssignmentScorer(labels[labels[\"video\"]==\"{}_{}.mp4\".format(game_play, view)],\n                                check_constraints=False,\n                                 impact_weight=1,\n                                 check_iou_only=True)\n    print(\"no assignment score\", scorer.score(temp_results))\n    \"\"\"\n    return temp_results","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## RUN\nHere I show sample predictions.\n\nLight scatter plots are ground truth(tracking dataset). Dark plots are predictions.","metadata":{}},{"cell_type":"code","source":"DEBUG = True\nif DEBUG:\n    # samples\n    game_play_and_views =[['57790_002792', 'Endzone'], \n                          ['57992_000350', 'Sideline'], \n                         ]\n\n    ENSEMBLE = False# if false, predict by single model\n    DRAW_PREREGI = False# show preprocessing registration results using previous frame\n    DRAW_REGI = True# show final registration results\n    DRAW_BBOX = True# show bounding boxes\n    VIEW_FREQUENCY = 20# draw outputs every N frames\n    \n    nfl_model = build_val_model()\n    for game_play, view in game_play_and_views:\n        S=time.time()\n        run_val(nfl_model, game_play, view)\n        print(time.time() - S, \"SEC / SINGLE PLAY\")\nelse:\n    ENSEMBLE = True\n    DRAW_PREREGI = False# show registration results using previous frame\n    DRAW_REGI = False\n    DRAW_BBOX = False\n    VIEW_FREQUENCY = 1e7\n    nfl_model = build_val_model()\n    run_test(nfl_model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}