{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%config Completer.use_jedi = False","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-24T01:31:02.174867Z","iopub.execute_input":"2021-10-24T01:31:02.175613Z","iopub.status.idle":"2021-10-24T01:31:02.217745Z","shell.execute_reply.started":"2021-10-24T01:31:02.175534Z","shell.execute_reply":"2021-10-24T01:31:02.215897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.mkdir('label_assignment')","metadata":{"execution":{"iopub.status.busy":"2021-10-24T01:31:02.220054Z","iopub.execute_input":"2021-10-24T01:31:02.22039Z","iopub.status.idle":"2021-10-24T01:31:02.225077Z","shell.execute_reply.started":"2021-10-24T01:31:02.220365Z","shell.execute_reply":"2021-10-24T01:31:02.223375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n!cp -r /kaggle/input/gmmreglib /kaggle/working/label_assignment/gmmreg-install\n%cd /kaggle/working/label_assignment/gmmreg-install/src\n!python setup.py install --user\n%cd /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2021-10-24T01:31:02.227104Z","iopub.execute_input":"2021-10-24T01:31:02.227404Z","iopub.status.idle":"2021-10-24T01:31:04.350459Z","shell.execute_reply.started":"2021-10-24T01:31:02.227368Z","shell.execute_reply":"2021-10-24T01:31:04.348645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -r /kaggle/input/helmet-assignment-helpers/helmet-assignment-main/helmet_assignment /kaggle/working/label_assignment/helmet_assignment","metadata":{"execution":{"iopub.status.busy":"2021-10-24T01:31:04.35348Z","iopub.execute_input":"2021-10-24T01:31:04.354081Z","iopub.status.idle":"2021-10-24T01:31:04.696961Z","shell.execute_reply.started":"2021-10-24T01:31:04.35391Z","shell.execute_reply":"2021-10-24T01:31:04.695482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Point cloud matching algorithm","metadata":{}},{"cell_type":"markdown","source":"## Main Functions","metadata":{}},{"cell_type":"code","source":"%%writefile label_assignment/__init__.py\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-24T01:31:04.69848Z","iopub.execute_input":"2021-10-24T01:31:04.698704Z","iopub.status.idle":"2021-10-24T01:31:04.70568Z","shell.execute_reply.started":"2021-10-24T01:31:04.698678Z","shell.execute_reply":"2021-10-24T01:31:04.704262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2021-10-24T01:31:04.707375Z","iopub.execute_input":"2021-10-24T01:31:04.70914Z","iopub.status.idle":"2021-10-24T01:31:04.732208Z","shell.execute_reply.started":"2021-10-24T01:31:04.709065Z","shell.execute_reply":"2021-10-24T01:31:04.729827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls label_assignment/helmet_assignment","metadata":{"execution":{"iopub.status.busy":"2021-10-24T01:31:04.734945Z","iopub.execute_input":"2021-10-24T01:31:04.735308Z","iopub.status.idle":"2021-10-24T01:31:05.040192Z","shell.execute_reply.started":"2021-10-24T01:31:04.735273Z","shell.execute_reply":"2021-10-24T01:31:05.038635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile label_assignment/all.py\n\nimport pandas as pd\nimport numpy as np\nimport os\nfrom scipy.optimize import linear_sum_assignment\nfrom scipy.spatial.distance import cdist\nfrom gmmreg._core import run_multi_level, normalize\nfrom .helmet_assignment.features import add_track_features\nfrom functools import partial\n\n\nclass DataLoader():\n    def __init__(self, preds, is_train = True, flip_y = True, top22 = False):\n        if is_train:\n            track = pd.read_csv('/kaggle/input/nfl-health-and-safety-helmet-assignment/train_player_tracking.csv')\n        else:\n            track = pd.read_csv('/kaggle/input/nfl-health-and-safety-helmet-assignment/test_player_tracking.csv')\n        track['y'] = -track['y']\n        self.track = add_track_features(track).query('est_frame > 0').reset_index()\n        self.videos = pd.Series(list(map(lambda x: splitjoin(x, ':-1'), preds['video_frame'].unique()))).sort_values().unique()\n        \n        if 'conf' not in preds.columns:\n            print('\"conf\" column missing in \"preds\" DataFrame, filling with 1...')\n            preds['conf'] = 1\n        if 'id' not in preds.columns:\n            print('\"id\" column missing in \"preds\" DataFrame, filling with unique values...')\n            preds['id'] = range(len(preds))\n        if top22:\n            preds = preds.sort_values('conf').groupby('video_frame').head(22).sort_index().reset_index(drop = True)\n\n        self.preds = preds\n        \n    def __nearest__(self, frame):\n        idx = abs(self.track_est_frames - frame).argmin()\n        frame = self.track_est_frames[idx]\n        return self.gameplay_track.set_index('est_frame').loc[frame]\n        \n    def filter_video(self, video):\n        gameplay, view = splitjoin(video, [':-1', '-1:'])\n        self.video = video\n        self.gameplay = gameplay\n        self.view = view\n        self.gameplay_track = self.track.query(f\"game_play == '{gameplay}'\")\n        self.video_preds = self.preds.query(f\"video_frame.str.contains('{video}')\", engine='python')\n        self.track_est_frames = self.gameplay_track['est_frame'].unique()\n        self.frames = (self\n                       .video_preds['video_frame']\n                       .drop_duplicates()\n                       .apply(splitjoin, keep = '-1:')\n                       .astype('int')\n                       .sort_values()\n                       .values\n                      )\n\n    def __call__(self, frame, method = 'nearest'):\n        if not hasattr(self, 'gameplay_track'):\n            raise ValueError(\"You must call 'filter_video' before calling the generator\")\n        if method == 'nearest':\n            track = self.__nearest__(frame)\n            xy_track = track[['x', 'y']].values\n            label_track = track['player'].values\n        else:\n            #todo implement interpolation on frames\n            raise ValueError(\"Only 'nearest' method is implemented so far\")\n        \n        video_frame = splitjoin(self.video_preds['video_frame'].values[0], ':-1') + f'_{frame}'\n        video_preds = self.video_preds.set_index('video_frame').loc[video_frame]\n        xy_video = ltwh2xcyc(video_preds)\n        label_video = video_preds['id'].values\n        \n        return xy_video, xy_track, label_video, label_track\n    \n    def bbox(self, frame):\n        video_frame = splitjoin(self.video_preds['video_frame'].values[0], ':-1') + f'_{frame}'\n        bbox = (self\n                .video_preds\n                .set_index('video_frame')\n                .loc[video_frame, ['left', 'width', 'top', 'height']]\n                .values)\n        return bbox\n              \ndef rotate(xy, theta):\n    t = theta * np.pi/180\n    R = np.array([[np.cos(t), -np.sin(t)],\n                  [np.sin(t),  np.cos(t)]])\n    return xy @ R\n\ndef normalize(xy):\n    return (xy - xy.mean(axis = 0))/xy.std(axis = 0)\n\ndef splitjoin(string, keep):\n    splitted = string.split('_')\n    if isinstance(keep, list):\n        joint = [f\"'_'.join(splitted[{k}])\" for k in keep]\n        joint = tuple(map(eval, joint))\n    else:\n        joint = eval(f\"'_'.join(splitted[{keep}])\")\n    return joint\n\ndef ltwh2xcyc(df):\n    xc = df['left'] + df['width']/2\n    yc = df['top'] + df['height']/2\n    xcyc = np.vstack([xc.values, yc.values]).T\n    return xcyc\n\ndef register(xy_source, xy_target, theta, n_grid, **kwargs):\n    grid = np.linspace(-2, 2, n_grid)\n    grid = np.array(np.meshgrid(grid, grid)).T.reshape(-1,2)\n    xy_target = normalize(xy_target)\n    xy_source = normalize(xy_source)\n    xy_source = rotate(xy_source, theta)\n    xy_source = run_multi_level(xy_source, xy_target, grid, **kwargs)\n    return xy_source, xy_target\n\ndef label_matrix(matrix, label_row, label_col):\n    return pd.DataFrame(matrix, index = label_row, columns = label_col)\n\ndef get_optimal_theta(xy_video, xy_tracking, thetas, **kwargs):\n    if thetas == 'Endzone':\n        thetas = [-90, 90]\n    elif thetas == 'Sideline':\n        thetas = [0, 180]\n    scores = []\n    for theta in thetas:\n        xy_video_r, xy_tracking_r = register(xy_video, xy_tracking, theta, **kwargs)\n        dist = cdist(xy_video_r, xy_tracking_r)\n        M = linear_sum_assignment(dist)\n        score = dist.mean()/dist[M].mean()\n        scores.append(score)\n    scores = np.array(scores)\n    return thetas[scores.argmax()]\n\nfrom statistics import mode\ndef estimate_theta(dl, frames = [1,21,41,61,81,101,121], **kwargs):\n    thetas = []\n    for frame in frames:\n        xy_video, xy_tracking, labels_video, labels_tracking = dl(frame)\n        theta = get_optimal_theta(xy_video, xy_tracking, dl.view, **kwargs) \n        thetas.append(theta)\n    theta = mode(thetas) \n    return theta\n\ndef match_video(dl, theta, **kwargs):\n    video_dist = []\n    for frame in dl.frames:\n        xy_video, xy_tracking, labels_video, labels_tracking = dl(frame) \n        xy_video, xy_tracking = register(xy_video, xy_tracking, theta, **kwargs)\n        dist = cdist(xy_video, xy_tracking)\n        dist = label_matrix(dist, labels_video, labels_tracking)\n        video_dist.append(dist)\n    return video_dist\n\ndef assign_labels(dl, video_agg_dist):\n    video_labels = []\n    idx_video = []\n    for frame in dl.frames:\n        _, _, labels_video, labels_tracking = dl(frame)\n        dist = video_agg_dist.loc[labels_video, labels_tracking]\n        M = linear_sum_assignment(dist)\n        video_labels.append(labels_tracking[M[1]])\n        idx_video.append(M[0])\n    return video_labels, idx_video\n\ndef build_submission_for_video(dl, labels, idx_video):\n    video_sub = []\n    for frame, label, idx in zip(dl.frames, labels, idx_video):\n        frame_sub = pd.DataFrame({\n            'video_frame': f'{dl.video}_{frame}',\n            'label': label,\n        })\n        frame_sub[['left', 'width', 'top', 'height']] = dl.bbox(frame)[idx]\n        video_sub.append(frame_sub)\n    video_sub = pd.concat(video_sub)\n    return video_sub\n\n\ndef track2sub(dl, **kwargs):\n    ## Estimate camera angle\n    ### Estimate camera angle by minimizing the matching distance and \n    ### get the mode of the best matches for multiple frames\n    theta = estimate_theta(dl, **kwargs)\n    \n    ## Generate a list of distance dataframes (named matrix)\n    ### register the point clouds for all frames and returns a list of named\n    ### distance matrix (row names are pseudo_labels and col names are tracking labels)\n    video_dist = match_video(dl, theta, **kwargs)\n\n    ## Aggregate the list of distance dataframes to a single distance dataframe\n    ### For now this is simple but could be replaced for a more complex function\n    video_agg_dist = pd.concat(video_dist).groupby(level=0).agg('mean')\n    \n    ## Label assignment based on aggregated distance\n    ### Uses hungarian algorithm to match based on the aggregated distance matrix\n    video_labels, idx_video = assign_labels(dl, video_agg_dist)\n    \n    ## Submission generation for a video\n    ### replace the labels on the original bbox dataframe\n    video_sub = build_submission_for_video(dl, video_labels, idx_video)\n    \n    return video_sub, theta\n\nclass Register():\n    def __init__(self, algo = 'gmmreg', **kwargs):\n        if algo == 'gmmreg':\n            if 'n_grid' in kwargs:\n                n_grid = kwargs.pop('n_grid')\n                grid = np.linspace(-2, 2, n_grid)\n                self.grid = np.array(np.meshgrid(grid, grid)).T.reshape(-1,2)\n            else:\n                self.grid = None\n            self.algo = partial(run_multi_level, **kwargs)\n        else:\n            raise ValueError('Only gmmreg is implemented')\n    def __call__(self, src, trg):\n        if self.grid is None: grid = src\n        else: grid = self.grid\n        return self.algo(src, trg, grid)\n    \n    \ndef match_videoV2(dl, theta, **kwargs):\n    \n    reg_gmm = Register(**kwargs)\n    video_dist = []\n    for frame in dl.frames:\n        xy_video, xy_tracking, labels_video, labels_tracking = dl(frame) \n        xy_tracking = normalize(xy_tracking)\n        xy_video = normalize(xy_video)\n        xy_video = rotate(xy_video, theta)\n        if frame == 1:\n            _xy_video = xy_tracking\n        xy_video = reg_gmm(xy_video, _xy_video)\n\n        dist = cdist(xy_video, xy_tracking)\n        M = linear_sum_assignment(dist)\n        _xy_video = xy_tracking[M[1]]\n        \n        d_m = dist[M].mean()\n        w_m = 1/(1 + np.exp(-(len(M[0])-8)/2))\n        dist = label_matrix(dist, labels_video, labels_tracking)\n        video_dist.append(dist * d_m / w_m)\n    return video_dist \n\ndef track2subV2(dl, **kwargs):\n    theta = estimate_theta(dl, **kwargs)\n    video_dist = match_videoV2(dl, theta, **kwargs)\n    video_agg_dist = pd.concat(video_dist).groupby(level=0).agg('mean')\n    video_labels, idx_video = assign_labels(dl, video_agg_dist)\n    video_sub = build_submission_for_video(dl, video_labels, idx_video)\n    return video_sub, theta","metadata":{"execution":{"iopub.status.busy":"2021-10-24T01:31:05.042684Z","iopub.execute_input":"2021-10-24T01:31:05.043745Z","iopub.status.idle":"2021-10-24T01:31:05.05919Z","shell.execute_reply.started":"2021-10-24T01:31:05.043668Z","shell.execute_reply":"2021-10-24T01:31:05.057411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile label_assignment/utils.py\ndef fix_submission(sub):\n    \n    n_na = sub.isna().any(axis = 1).sum()\n    if n_na:\n        sub = sub.dropna()\n        print(f'Dropped {n_na} lines from submission')\n        \n    n_dupe_labels = sub[[\"video_frame\", \"label\"]].duplicated().sum()\n    if n_dupe_labels:\n        sub = sub.drop_duplicates(['video_frame', 'label'])\n        print(f'Dropped {n_dupe_labels} duplicated labels')\n    \n    n_dupe_bbox = sub[[\"video_frame\", \"left\", \"width\", \"top\", \"height\"]].duplicated().sum()\n    if n_dupe_bbox:\n        sub = sub.drop_duplicates(['video_frame', 'left','width','top','height'])\n        print(f'Dropped {n_dupe_bbox} duplicated bboxes')\n    \n    n_over_22 = (sub.groupby([\"video_frame\"])[\"label\"].count() > 22).sum()\n    if n_over_22:\n        sub = sub.groupby(\"video_frame\").head(22)\n        print(f'Dropped {n_over_22} extra bboxes')\n\n    n_out_of_bounds = (\n        (sub['left'] < 0) | \n        (sub['top'] < 0) | \n        ((sub['left'] + sub['width']) > 1280) | \n        ((sub['top'] + sub['height']) > 720)\n    ).sum()\n    if n_out_of_bounds:\n        sub['right'] = sub['left'] + sub['width']\n        sub['bottom'] = sub['top'] + sub['height']\n        \n        sub['left'] = sub['left'].clip(0, 1280-1)\n        sub['right'] = sub['right'].clip(1, 1280)\n        sub['top'] = sub['top'].clip(0, 720-1)\n        sub['bottom'] = sub['bottom'].clip(1, 720)\n        \n        sub['width'] = sub['right'] - sub['left']\n        sub['height'] = sub['bottom'] - sub['top']\n        sub = sub.drop(['bottom', 'right'], axis = 1)\n        print(f'Clipped {n_out_of_bounds} bboxes')\n        \n    return sub","metadata":{"execution":{"iopub.status.busy":"2021-10-24T01:31:05.061166Z","iopub.execute_input":"2021-10-24T01:31:05.061482Z","iopub.status.idle":"2021-10-24T01:31:05.091626Z","shell.execute_reply.started":"2021-10-24T01:31:05.061442Z","shell.execute_reply":"2021-10-24T01:31:05.090774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/label_assignment\")\nfrom label_assignment.all import *","metadata":{"execution":{"iopub.status.busy":"2021-10-24T01:31:05.09459Z","iopub.execute_input":"2021-10-24T01:31:05.096452Z","iopub.status.idle":"2021-10-24T01:31:05.758314Z","shell.execute_reply.started":"2021-10-24T01:31:05.096348Z","shell.execute_reply":"2021-10-24T01:31:05.756932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/input/helmet-assignment-helpers/helmet-assignment-main\")\nfrom helmet_assignment.score import NFLAssignmentScorer\nfrom helmet_assignment.video import video_with_predictions","metadata":{"execution":{"iopub.status.busy":"2021-10-24T01:31:05.759938Z","iopub.execute_input":"2021-10-24T01:31:05.760298Z","iopub.status.idle":"2021-10-24T01:31:06.588413Z","shell.execute_reply.started":"2021-10-24T01:31:05.760264Z","shell.execute_reply":"2021-10-24T01:31:06.587256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nfrom termcolor import colored","metadata":{"execution":{"iopub.status.busy":"2021-10-24T01:31:06.592467Z","iopub.execute_input":"2021-10-24T01:31:06.59283Z","iopub.status.idle":"2021-10-24T01:31:06.694555Z","shell.execute_reply.started":"2021-10-24T01:31:06.592804Z","shell.execute_reply":"2021-10-24T01:31:06.692513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## GT Rotations\ngt_rotations = pd.read_csv('../input/nlf-helmet-safety-camera-rotations/NFL-rotations-plays.csv').set_index('play')\ngt_rotations = pd.DataFrame({\n    'video' : np.concatenate([(gt_rotations.index + '_Sideline').values, (gt_rotations.index + '_Endzone').values]),\n    'rotation' : np.concatenate([gt_rotations['Sideline'].values, gt_rotations['Endzone'].values])\n}).set_index('video').sort_index()\n\n## GT Labels\ngt_labels = pd.read_csv('/kaggle/input/nfl-health-and-safety-helmet-assignment/train_labels.csv')","metadata":{"execution":{"iopub.status.busy":"2021-10-24T01:31:06.696367Z","iopub.execute_input":"2021-10-24T01:31:06.696659Z","iopub.status.idle":"2021-10-24T01:31:09.276105Z","shell.execute_reply.started":"2021-10-24T01:31:06.696631Z","shell.execute_reply":"2021-10-24T01:31:09.274502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_VIDEOS = 6\nlabeler_cfg_Endzone = {\n    'level': 3, \n    'scales':  [1, 0.2, 0.1], \n    'lambdas': [0.1, 0.04, 0.02], \n    'iters':   [30, 20, 10],\n    'n_grid': 5\n}\nlabeler_cfg_Sideline = {\n    'level': 3, \n    'scales':  [1, 0.5, 0.25], \n    'lambdas': [1, 0.02, 0.25], \n    'iters':   [30, 20, 10],\n    'n_grid': 5\n}","metadata":{"execution":{"iopub.status.busy":"2021-10-24T01:31:09.277892Z","iopub.execute_input":"2021-10-24T01:31:09.278724Z","iopub.status.idle":"2021-10-24T01:31:09.286408Z","shell.execute_reply.started":"2021-10-24T01:31:09.278693Z","shell.execute_reply":"2021-10-24T01:31:09.284435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Testing with GT data","metadata":{}},{"cell_type":"code","source":"sorted_bboxes = pd.read_csv('/kaggle/input/nfl-health-and-safety-helmet-assignment/train_labels.csv').query('frame > 0')\nsorted_bboxes['id'] = sorted_bboxes['label']\ndl = DataLoader(sorted_bboxes)\n\nacc = []\nsub = []\nfor video in tqdm(dl.videos[:N_VIDEOS]):\n    \n    #=#=# Ground truth angle of rotation for dubugging (REMOVE ON INFERENCE) #=#=#\n    gt_theta = gt_rotations.loc[video, 'rotation']\n    #=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#   \n\n    ## Filtering the dataloader to return the data of a single video\n    dl.filter_video(video = video)\n\n    ## generating submission for a single video\n    if 'Sideline' in video:\n        video_sub, theta = track2subV2(dl, **labeler_cfg_Sideline)\n    else:\n        video_sub, theta = track2subV2(dl, **labeler_cfg_Endzone)\n\n    sub.append(video_sub)\n    \n    #=#=# Scoring for debugging (REMOVE ON INFERENCE) #=#=#\n    scorer = NFLAssignmentScorer(gt_labels.query(f'video == \"{video}.mp4\"'), impact_weight=1)\n    video_acc = scorer.score(video_sub)\n    scorer = NFLAssignmentScorer(gt_labels.query(f'video == \"{video}.mp4\"'))\n    video_score = scorer.score(video_sub)\n    #=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#\n    \n    ## Print video metrics\n    print(f'Video: {video:<21} | Acc.:',\n          colored(f'{video_acc:.3f}','green' if video_acc > 0.9 else ('yellow' if video_acc > 0.7 else 'red')),\n          '| Score:',\n          colored(f'{video_score:.3f}','green' if video_score > 0.9 else ('yellow' if video_score > 0.7 else 'red')),\n          '| Angle:',\n          colored(f'{theta:>3}째', 'green' if theta == gt_theta else 'red')\n         )\n    acc.append(video_acc)\n\nscorer = NFLAssignmentScorer(gt_labels)\nscore = scorer.score(pd.concat(sub))\nacc = np.array(acc)\n\nprint(f'Mean Accuracy: {acc.mean():.3f}')\nprint(f'Mean Score: {score:.3f}')\nplt.hist(acc);","metadata":{"execution":{"iopub.status.busy":"2021-10-24T01:31:09.288795Z","iopub.execute_input":"2021-10-24T01:31:09.289093Z","iopub.status.idle":"2021-10-24T01:33:42.595363Z","shell.execute_reply.started":"2021-10-24T01:31:09.289066Z","shell.execute_reply":"2021-10-24T01:33:42.59466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Testing with GT bboxes (no tracking)","metadata":{}},{"cell_type":"code","source":"sorted_bboxes = pd.read_csv('/kaggle/input/nfl-health-and-safety-helmet-assignment/train_labels.csv').query('frame > 0')\ndl = DataLoader(sorted_bboxes)\n\nacc = []\nsub = []\nfor video in tqdm(dl.videos[:N_VIDEOS]):\n    \n    #=#=# Ground truth angle of rotation for dubugging (REMOVE ON INFERENCE) #=#=#\n    gt_theta = gt_rotations.loc[video, 'rotation']\n    #=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#   \n\n    ## Filtering the dataloader to return the data of a single video\n    dl.filter_video(video = video)\n\n    ## generating submission for a single video\n    if 'Sideline' in video:\n        video_sub, theta = track2subV2(dl, **labeler_cfg_Sideline)\n    else:\n        video_sub, theta = track2subV2(dl, **labeler_cfg_Endzone)\n\n    sub.append(video_sub)\n    \n    #=#=# Scoring for debugging (REMOVE ON INFERENCE) #=#=#\n    scorer = NFLAssignmentScorer(gt_labels.query(f'video == \"{video}.mp4\"'), impact_weight=1)\n    video_acc = scorer.score(video_sub)\n    scorer = NFLAssignmentScorer(gt_labels.query(f'video == \"{video}.mp4\"'))\n    video_score = scorer.score(video_sub)\n    #=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#\n    \n    ## Print video metrics\n    print(f'Video: {video:<21} | Acc.:',\n          colored(f'{video_acc:.3f}','green' if video_acc > 0.9 else ('yellow' if video_acc > 0.7 else 'red')),\n          '| Score:',\n          colored(f'{video_score:.3f}','green' if video_score > 0.9 else ('yellow' if video_score > 0.7 else 'red')),\n          '| Angle:',\n          colored(f'{theta:>3}째', 'green' if theta == gt_theta else 'red')\n         )\n    acc.append(video_acc)\n\nscorer = NFLAssignmentScorer(gt_labels)\nscore = scorer.score(pd.concat(sub))\nacc = np.array(acc)\n\nprint(f'Mean Accuracy: {acc.mean():.3f}')\nprint(f'Mean Score: {score:.3f}')\nplt.hist(acc);","metadata":{"execution":{"iopub.status.busy":"2021-10-24T01:33:42.596546Z","iopub.execute_input":"2021-10-24T01:33:42.597251Z","iopub.status.idle":"2021-10-24T01:36:16.705434Z","shell.execute_reply.started":"2021-10-24T01:33:42.597216Z","shell.execute_reply":"2021-10-24T01:36:16.703912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Baseline helmets","metadata":{}},{"cell_type":"code","source":"sorted_bboxes = pd.read_csv('/kaggle/input/nfl-health-and-safety-helmet-assignment/train_baseline_helmets.csv')\ndl = DataLoader(sorted_bboxes)\n\nacc = []\nsub = []\nfor video in tqdm(dl.videos[:N_VIDEOS]):\n    \n    #=#=# Ground truth angle of rotation for dubugging (REMOVE ON INFERENCE) #=#=#\n    gt_theta = gt_rotations.loc[video, 'rotation']\n    #=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#   \n\n    ## Filtering the dataloader to return the data of a single video\n    dl.filter_video(video = video)\n\n    ## generating submission for a single video\n    if 'Sideline' in video:\n        video_sub, theta = track2subV2(dl, **labeler_cfg_Sideline)\n    else:\n        video_sub, theta = track2subV2(dl, **labeler_cfg_Endzone)\n\n    sub.append(video_sub)\n    \n    #=#=# Scoring for debugging (REMOVE ON INFERENCE) #=#=#\n    scorer = NFLAssignmentScorer(gt_labels.query(f'video == \"{video}.mp4\"'), impact_weight=1)\n    video_acc = scorer.score(video_sub)\n    scorer = NFLAssignmentScorer(gt_labels.query(f'video == \"{video}.mp4\"'))\n    video_score = scorer.score(video_sub)\n    #=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#\n    \n    ## Print video metrics\n    print(f'Video: {video:<21} | Acc.:',\n          colored(f'{video_acc:.3f}','green' if video_acc > 0.9 else ('yellow' if video_acc > 0.7 else 'red')),\n          '| Score:',\n          colored(f'{video_score:.3f}','green' if video_score > 0.9 else ('yellow' if video_score > 0.7 else 'red')),\n          '| Angle:',\n          colored(f'{theta:>3}째', 'green' if theta == gt_theta else 'red')\n         )\n    acc.append(video_acc)\n\nscorer = NFLAssignmentScorer(gt_labels)\nscore = scorer.score(pd.concat(sub))\nacc = np.array(acc)\n\nprint(f'Mean Accuracy: {acc.mean():.3f}')\nprint(f'Mean Score: {score:.3f}')\nplt.hist(acc);","metadata":{"execution":{"iopub.status.busy":"2021-10-24T01:36:16.707148Z","iopub.execute_input":"2021-10-24T01:36:16.707397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Deepsorted","metadata":{}},{"cell_type":"code","source":"sorted_bboxes = pd.read_csv('/kaggle/input/nfl-csv-dataset/tracked_detections.csv')\ndl = DataLoader(sorted_bboxes)\n\nacc = []\nsub = []\nfor video in tqdm(dl.videos[:N_VIDEOS]):\n    \n    #=#=# Ground truth angle of rotation for dubugging (REMOVE ON INFERENCE) #=#=#\n    gt_theta = gt_rotations.loc[video, 'rotation']\n    #=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#   \n\n    ## Filtering the dataloader to return the data of a single video\n    dl.filter_video(video = video)\n\n    ## generating submission for a single video\n    if 'Sideline' in video:\n        video_sub, theta = track2subV2(dl, **labeler_cfg_Sideline)\n    else:\n        video_sub, theta = track2subV2(dl, **labeler_cfg_Endzone)\n\n    sub.append(video_sub)\n    \n    #=#=# Scoring for debugging (REMOVE ON INFERENCE) #=#=#\n    scorer = NFLAssignmentScorer(gt_labels.query(f'video == \"{video}.mp4\"'), impact_weight=1)\n    video_acc = scorer.score(video_sub)\n    scorer = NFLAssignmentScorer(gt_labels.query(f'video == \"{video}.mp4\"'))\n    video_score = scorer.score(video_sub)\n    #=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#=#\n    \n    ## Print video metrics\n    print(f'Video: {video:<21} | Acc.:',\n          colored(f'{video_acc:.3f}','green' if video_acc > 0.9 else ('yellow' if video_acc > 0.7 else 'red')),\n          '| Score:',\n          colored(f'{video_score:.3f}','green' if video_score > 0.9 else ('yellow' if video_score > 0.7 else 'red')),\n          '| Angle:',\n          colored(f'{theta:>3}째', 'green' if theta == gt_theta else 'red')\n         )\n    acc.append(video_acc)\n\nscorer = NFLAssignmentScorer(gt_labels)\nscore = scorer.score(pd.concat(sub))\nacc = np.array(acc)\n\nprint(f'Mean Accuracy: {acc.mean():.3f}')\nprint(f'Mean Score: {score:.3f}')\nplt.hist(acc);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}