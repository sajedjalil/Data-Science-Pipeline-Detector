{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install helmet-assignment helper code\n!pip install ../input/helmet-assignment-helpers/helmet-assignment-main/ > /dev/null 2>&1\nfrom helmet_assignment.score import NFLAssignmentScorer, check_submission\nfrom helmet_assignment.features import add_track_features","metadata":{"execution":{"iopub.status.busy":"2021-10-01T11:19:28.625826Z","iopub.execute_input":"2021-10-01T11:19:28.626403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input as InceptionV3_preprocess_input\nfrom tensorflow.keras.applications.efficientnet import EfficientNetB0\nfrom tensorflow.keras.applications.efficientnet import preprocess_input as Efficient_preprocess_input\nfrom tensorflow.keras.applications.resnet import ResNet50\nfrom tensorflow.keras.applications.resnet import preprocess_input as ResNet50_preprocess_input\nfrom tensorflow.keras.applications.efficientnet import EfficientNetB7\nfrom tensorflow.keras.applications.vgg16 import preprocess_input as VGG_preprocess_input \nfrom tensorflow.keras.applications.vgg16 import VGG16\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.cluster import SpectralBiclustering\nimport matplotlib.pylab as plt\nfrom tqdm.auto import tqdm\nfrom PIL import Image\nimport shutil\nimport cv2\nimport os","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_test_videos = len(os.listdir('../input/nfl-health-and-safety-helmet-assignment/test/'))\n# Run in debug mode unless during submission\nif n_test_videos == 6:\n    debug = True\nelse:\n    debug = False\n# Read in the data.\nBASE_DIR = '../input/nfl-health-and-safety-helmet-assignment'\nn_debug_samples = 2\nrandom_state = 42\n\nlabels = pd.read_csv(f'{BASE_DIR}/train_labels.csv')\nif debug:\n    tracking = pd.read_csv(f'{BASE_DIR}/train_player_tracking.csv')\n    helmets = pd.read_csv(f'{BASE_DIR}/train_labels.csv')\nelse:\n    tracking = pd.read_csv(f'{BASE_DIR}/test_player_tracking.csv')\n    helmets = pd.read_csv(f'{BASE_DIR}/test_baseline_helmets.csv')\n    \ntracking = add_track_features(tracking)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_cols(df):\n    df['game_play'] = df['video_frame'].str.split('_').str[:2].str.join('_')\n    if 'video' not in df.columns:\n        df['video'] = df['video_frame'].str.split('_').str[:3].str.join('_') + '.mp4'\n    return df\n\nif debug:\n    helmets = add_cols(helmets)\n    labels = add_cols(labels)\n    # Select `n_debug_samples` worth of videos to debug with\n    sample_videos = labels['video'].drop_duplicates() \\\n        .sample(n_debug_samples, random_state=random_state)[labels['view']=='Sideline'].to_list()\n    sample_gameplays = ['_'.join(x.split('_')[:2]) for x in sample_videos]\n    tracking = tracking[tracking['game_play'].isin(sample_gameplays)]\n    helmets = helmets[helmets['video'].isin(sample_videos)]\n    labels = labels[labels['video'].isin(sample_videos)]\ntracking.shape, helmets.shape, labels.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Deepsort Postprocessing\n","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('../input/easydict-master/easydict-master/')\nsys.path.append('../input/yolov5-deepsort-pytorch/Yolov5_DeepSort_Pytorch-master/Yolov5_DeepSort_Pytorch-master/deep_sort_pytorch/')\nfrom deep_sort.deep_sort import DeepSort\nfrom utils.parser import get_config","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Deepsort config\n","metadata":{}},{"cell_type":"code","source":"%%writefile deepsort.yaml\n\nDEEPSORT:\n  REID_CKPT: \"../input/yolov5-deepsort-pytorch/ckpt.t7\"\n  MAX_DIST: 0.2\n  MIN_CONFIDENCE: 0.3\n  NMS_MAX_OVERLAP: 0.5\n  MAX_IOU_DISTANCE: 0.9\n  MAX_AGE: 15\n  N_INIT: 1\n  NN_BUDGET: 40","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nHelper functions from yolov5 to plot deepsort labels.\n\"\"\"\n\ndef compute_color_for_id(label):\n    \"\"\"\n    Simple function that adds fixed color depending on the id\n    \"\"\"\n    palette = (2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)\n\n    color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]\n    return tuple(color)\n\ndef plot_one_box(x, im, color=None, label=None, line_thickness=3):\n    # Plots one bounding box on image 'im' using OpenCV\n    assert im.data.contiguous, 'Image not contiguous. Apply np.ascontiguousarray(im) to plot_on_box() input image.'\n    tl = line_thickness or round(0.002 * (im.shape[0] + im.shape[1]) / 2) + 1  # line/font thickness\n    color = color or [random.randint(0, 255) for _ in range(3)]\n    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n    cv2.rectangle(im, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n    if label: \n        tf = max(tl - 1, 1)  # font thickness\n        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n        cv2.rectangle(im, c1, c2, color, -1, cv2.LINE_AA)  # filled\n        cv2.putText(im, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n    return im","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def deepsort_helmets(video_data,\n                     video_dir,\n                     deepsort_config='deepsort.yaml',\n                     plot=False,\n                     plot_frames=[]):\n    \n    # Setup Deepsort\n    cfg = get_config()\n    cfg.merge_from_file(deepsort_config)    \n    deepsort = DeepSort(cfg.DEEPSORT.REID_CKPT,\n                        max_dist=cfg.DEEPSORT.MAX_DIST,\n                        min_confidence=cfg.DEEPSORT.MIN_CONFIDENCE,\n                        nms_max_overlap=cfg.DEEPSORT.NMS_MAX_OVERLAP,\n                        max_iou_distance=cfg.DEEPSORT.MAX_IOU_DISTANCE,\n                        max_age=cfg.DEEPSORT.MAX_AGE,\n                        n_init=cfg.DEEPSORT.N_INIT,\n                        nn_budget=cfg.DEEPSORT.NN_BUDGET,\n                        use_cuda=True)\n    \n    # Run through frames.\n    video_data = video_data.sort_values('frame').reset_index(drop=True)\n    \n    video_file = f'{video_dir}/{myvideo}.mp4'\n    if os.path.exists('/kaggle/working/temp'):\n        shutil.rmtree('/kaggle/working/temp')\n    os.mkdir('/kaggle/working/temp')\n    !ffmpeg \\\n        -hide_banner \\\n        -loglevel fatal \\\n        -nostats \\\n        -i $video_file temp/%d.png\n    \n    ds = []\n    for frame, d in tqdm(video_data.groupby(['frame']), total=video_data['frame'].nunique()):\n        d['x'] = (d['left'] + round(d['width'] / 2))\n        d['y'] = (d['top'] + round(d['height'] / 2))\n\n        xywhs = d[['x','y','width','height']].values\n        \n        image = Image.open(f'/kaggle/working/temp/{frame}.png')\n        image = np.array(image)\n\n        confs = np.ones([len(d),])\n        clss =  np.zeros([len(d),])\n        outputs = deepsort.update(xywhs, confs, clss, image)\n\n        if (plot and frame > cfg.DEEPSORT.N_INIT) or (frame in plot_frames):\n            for j, (output, conf) in enumerate(zip(outputs, confs)): \n\n                bboxes = output[0:4]\n                id = output[4]\n                cls = output[5]\n\n                c = int(cls)  # integer class\n                label = f'{id}'\n                color = compute_color_for_id(id)\n                im = plot_one_box(bboxes, image, label=label, color=color, line_thickness=2)\n            fig, ax = plt.subplots(figsize=(15, 10))\n            video_frame = d['video_frame'].values[0]\n            ax.set_title(f'Deepsort labels: {video_frame}')\n            plt.imshow(im)\n            plt.show()\n\n        preds_df = pd.DataFrame(outputs, columns=['left','top','right','bottom','deepsort_cluster','class'])\n        if len(preds_df) > 0:\n            # TODO Fix this messy merge\n            d = pd.merge_asof(d.sort_values(['left','top']),\n                              preds_df[['left','top','deepsort_cluster']] \\\n                              .sort_values(['left','top']), on='left', suffixes=('','_deepsort'),\n                              direction='nearest')\n        ds.append(d)\n    shutil.rmtree('/kaggle/working/temp')\n    dout = pd.concat(ds)\n    return dout\n\ndef add_deepsort_team_cluster_col(out):\n    # Find the top occuring label for each deepsort_cluster\n    sortlabel_map = out.groupby('deepsort_cluster')['team_cluster'].value_counts() \\\n        .sort_values(ascending=False).to_frame() \\\n        .rename(columns={'team_cluster':'team_cluster_count'}) \\\n        .reset_index() \\\n        .groupby(['deepsort_cluster']) \\\n        .first()['team_cluster'].to_dict()\n    # Find the # of times that label appears for the deepsort_cluster.\n    sortlabelcount_map = out.groupby('deepsort_cluster')['team_cluster'].value_counts() \\\n        .sort_values(ascending=False).to_frame() \\\n        .rename(columns={'team_cluster':'team_cluster_count'}) \\\n        .reset_index() \\\n        .groupby(['deepsort_cluster']) \\\n        .first()['team_cluster_count'].to_dict()\n    \n    out['team_cluster_deepsort'] = out['deepsort_cluster'].map(sortlabel_map)\n    out['team_cluster_count_deepsort'] = out['deepsort_cluster'].map(sortlabelcount_map)\n\n    return out\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Deepsort for tream players tracking","metadata":{}},{"cell_type":"code","source":"# Add video and frame columns to submission.\nhelmets['video'] = helmets['video_frame'].str.split('_').str[:3].str.join('_')\nhelmets['frame'] = helmets['video_frame'].str.split('_').str[-1].astype('int')\n\nif debug:\n    video_dir = '../input/nfl-health-and-safety-helmet-assignment/train/'\nelse:\n    video_dir = '../input/nfl-health-and-safety-helmet-assignment/test/'\n\n# Loop through test videos and apply. If in debug mode show the score change.\nouts = []\nfor myvideo, video_data in tqdm(helmets.groupby('video'), total=helmets['video'].nunique()):\n    print(f'==== {myvideo} ====')\n    if debug:\n        # Plot deepsort labels when in debug mode.\n        out = deepsort_helmets(video_data, video_dir, plot_frames=[])\n    else:\n        out = deepsort_helmets(video_data, video_dir)        \n    outs.append(out)\nhelmets = pd.concat(outs).copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"helmets_df_list = []\n\nfor index,sample_helmets in list(helmets.groupby('video_frame')):\n    if sample_helmets['frame'].values[0] == 1:\n        sample_video = sample_helmets['video'].values[0]\n        video_frame_1 = helmets.query('video == @sample_video & frame == 3').copy()\n        video_frame_1['frame'] = 1\n        video_frame_1['video_frame'] = sample_helmets['video_frame'].values[0]\n        helmets_df_list.append(video_frame_1)\n    elif sample_helmets['frame'].values[0] == 2:\n        video_frame_2 = helmets.query('video == @sample_video & frame == 3').copy()\n        video_frame_2['frame'] = 2\n        video_frame_2['video_frame'] = sample_helmets['video_frame'].values[0]\n        helmets_df_list.append(video_frame_2)\n    else:\n        sample_video = sample_helmets['video'].values[0]\n        helmets_df_list.append(sample_helmets) \n        \nhelmets_df = pd.concat(helmets_df_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# clustering players for each team","metadata":{}},{"cell_type":"code","source":"# for loading/processing the images  \nfrom keras.preprocessing.image import load_img \nfrom keras.preprocessing.image import img_to_array \nfrom keras.applications.vgg16 import preprocess_input \n\n# models \nfrom keras.applications.vgg16 import VGG16 \nfrom keras.models import Model\n\n# clustering and dimension reduction\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\n\n# for everything else\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom random import randint\nimport pandas as pd\nimport pickle","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"video_paths = []\nif debug == True:\n    for video in helmets_df['video'].unique():\n        video_paths.append(f'../input/nfl-health-and-safety-helmet-assignment/train/'+str(video + '.mp4'))\nelse:\n    for video in helmets_df['video'].unique():\n        video_paths.append(f'../input/nfl-health-and-safety-helmet-assignment/test/'+str(video + '.mp4'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"helmets_df['team_cluster'] = 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_features(bbox_images):\n    features = []\n    #model = EfficientNetB0(weights='imagenet', include_top=False)\n    model = VGG16(weights='imagenet', include_top=False)\n    #inputs = Efficient_preprocess_input(bbox_images)\n    inputs = VGG_preprocess_input(bbox_images)\n    outputs = model.predict(inputs,batch_size=bbox_images.shape[0])\n    for x in outputs.tolist():\n        features.append(np.array(x).reshape(-1))\n    return features ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\nfrom tqdm.auto import tqdm\n\nfor video_path in video_paths:\n    all_frame_numbers = []\n    images_features = []\n    training_features = []\n    video_file = video_path\n    video_name = video_path.split('/')[-1]\n    video_name = video_name[:-4]\n    if os.path.exists('/kaggle/working/temp'):\n        shutil.rmtree('/kaggle/working/temp')\n    os.mkdir('/kaggle/working/temp')\n    !ffmpeg \\\n        -hide_banner \\\n        -loglevel fatal \\\n       -nostats \\\n        -i $video_file temp/%d.png\n    for image_path in tqdm(glob.glob('/kaggle/working/temp/*')):\n        original_image = Image.open(image_path)\n        original_image = np.array(original_image)\n        frame_number = image_path.split('/')[-1]\n        frame_number = int(frame_number[:-4])\n        all_frame_numbers.append(frame_number)\n        bbox_images = []\n        ratio = 0.01\n        image_info = helmets_df[['left','width','top','height','video','frame']].query('video == @video_name & frame == @frame_number')\n        for index,bbox in image_info.iterrows():\n            x_start = bbox['left'] + int(bbox['width']*ratio)\n            y_start = bbox['top'] + int(bbox['height']*ratio)\n            \n            x_end = bbox['left'] + int(bbox['width']*(1-ratio))\n            y_end = bbox['top'] + int(bbox['height']*(1-ratio))\n            bbox_image = original_image[y_start:y_end,x_start:x_end]\n            resized_bbox_image = cv2.resize(bbox_image,(224, 224),interpolation=cv2.INTER_AREA)\n            bbox_images.append(resized_bbox_image)\n            \n        bbox_images = np.array(bbox_images).reshape(-1,224,224,3)\n        frame_features = extract_features(bbox_images)\n        images_features.append(frame_features)\n        for bbox_features in frame_features:\n            training_features.append(np.array(bbox_features))\n    pca = PCA(n_components=1000, random_state=22)\n    pca.fit(np.array(training_features))\n    new_training_features = pca.transform(training_features) \n    clusters = SpectralBiclustering(n_clusters=2, random_state=0).fit(new_training_features)\n    i = 0\n    for n,image_features in enumerate(images_features):\n        frame_number = all_frame_numbers[n]\n        helmets_df['team_cluster'].loc[(helmets_df['video'] == video_name) & (helmets_df['frame'] == frame_number)] = clusters.row_labels_[i:i+len(image_features)]\n        i = i + len(image_features)\n    print(f'======={video_name}=========')\n    if debug == True:\n        helmets_df['ground_truth_clusters'] = helmets_df['label'].str[0]\n        helmets_df['ground_truth_clusters'] = helmets_df['ground_truth_clusters'].str.replace('V', '0')\n        helmets_df['ground_truth_clusters'] = helmets_df['ground_truth_clusters'].str.replace('H', '1')    \n        diff = [int(i) for i in helmets_df['ground_truth_clusters'].values] - helmets_df['team_cluster'].values\n        total_error_case1_without_deepsort = np.absolute(diff).sum()\n        print(f'video_name{video_name}')\n        print(f'total error case1(V:0 & H:1) without deepsort:{total_error_case1_without_deepsort}')\n        helmets_df['ground_truth_clusters'] = helmets_df['label'].str[0]\n        helmets_df['ground_truth_clusters'] = helmets_df['ground_truth_clusters'].str.replace('V', '1')\n        helmets_df['ground_truth_clusters'] = helmets_df['ground_truth_clusters'].str.replace('H', '0')    \n        diff = [int(i) for i in helmets_df['ground_truth_clusters'].values] - helmets_df['team_cluster'].values\n        total_error_case2_without_deepsort = np.absolute(diff).sum()\n        print(f'total error case2(V:1 & H:0) without deepsort:{total_error_case2_without_deepsort}')\n\n        helmets_df = add_deepsort_team_cluster_col(helmets_df)\n        helmets_df['ground_truth_clusters'] = helmets_df['label'].str[0]\n        helmets_df['ground_truth_clusters'] = helmets_df['ground_truth_clusters'].str.replace('V', '0')\n        helmets_df['ground_truth_clusters'] = helmets_df['ground_truth_clusters'].str.replace('H', '1')    \n        diff = [int(i) for i in helmets_df['ground_truth_clusters'].values] - helmets_df['team_cluster_deepsort'].values\n        total_error_case1_with_deepsort = np.absolute(diff).sum()\n        print(f'total error case1(V:0 & H:1) with deepsort:{total_error_case1_with_deepsort}')\n        helmets_df['ground_truth_clusters'] = helmets_df['label'].str[0]\n        helmets_df['ground_truth_clusters'] = helmets_df['ground_truth_clusters'].str.replace('V', '1')\n        helmets_df['ground_truth_clusters'] = helmets_df['ground_truth_clusters'].str.replace('H', '0')    \n        diff = [int(i) for i in helmets_df['ground_truth_clusters'].values] - helmets_df['team_cluster_deepsort'].values\n        total_error_case2_with_deepsort = np.absolute(diff).sum()\n        print(f'total error case2(V:1 & H:0) with deepsort:{total_error_case2_with_deepsort}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}