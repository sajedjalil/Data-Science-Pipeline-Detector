{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"33ecf6a5-3b67-69fc-654c-03c5b9d3764b"},"source":"This is the direct translation of the Matlab getting started code shared by the organizers. \nThis feature extractor was used as part of a winning solution in a past competition.\nEDIT: I have fixed the mistakes in the original Matlab code in this new version.\n\nNOTE: I just tried to translate it from the Matlab version as close as possible. \n            Use at your own risk. Correctness is not guaranteed and there might be bugs in \n            this translation and/or the original Matalb version. So, debug very well before \n            incorporating it to your pipeline.\n\nDISCLAIMER: I still haven't tried it with my training pipeline so I am not sure for correctness yet.\n                          \nGIVE BACK: Please, consider to fork and contribute back your feature additions and/or corrections."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f9a60963-6d3f-5f79-ed53-aaadd421e2bc"},"outputs":[],"source":"# translation of the Matlab feature extractor\nimport sys\nimport os\nimport numpy as np\nimport pandas as pd\nfrom math import *\nfrom scipy.io import loadmat\nfrom scipy.stats import skew, kurtosis\n#import pyeeg \n# pyeeg is the one that has very good fractal dimensions \n# computation but not installed here\n\ndef mat_to_data(path):\n    mat = loadmat(path)\n    names = mat['dataStruct'].dtype.names\n    ndata = {n: mat['dataStruct'][n][0, 0] for n in names}\n    return ndata\n\ndef corr(data,type_corr):\n    C = np.array(data.corr(type_corr))\n    C[np.isnan(C)] = 0\n    C[np.isinf(C)] = 0\n    w,v = np.linalg.eig(C)\n    #print(w)\n    x = np.sort(w)\n    x = np.real(x)\n    return x\n\ndef calculate_features(file_name):\n    f = mat_to_data(file_name)\n    fs = f['iEEGsamplingRate'][0,0]\n    eegData = f['data']\n    [nt, nc] = eegData.shape\n    print((nt, nc))\n    subsampLen = floor(fs * 60)\n    numSamps = int(floor(nt / subsampLen));      # Num of 1-min samples\n    sampIdx = range(0,(numSamps+1)*subsampLen,subsampLen)\n    #print(sampIdx)\n    feat = [] # Feature Vector\n    for i in range(1, numSamps+1):\n        print('processing file {} epoch {}'.format(file_name,i))\n        epoch = eegData[sampIdx[i-1]:sampIdx[i], :]\n\n        # compute Shannon's entropy, spectral edge and correlation matrix\n        # segments corresponding to frequency bands\n        lvl = np.array([0.1, 4, 8, 12, 30, 70, 180])  # Frequency levels in Hz\n        lseg = np.round(nt/fs*lvl).astype('int')\n        D = np.absolute(np.fft.fft(epoch, n=lseg[-1], axis=0))\n        D[0,:]=0                                # set the DC component to zero\n        D /= D.sum()                      # Normalize each channel               \n        \n        dspect = np.zeros((len(lvl)-1,nc))\n        for j in range(len(dspect)):\n            dspect[j,:] = 2*np.sum(D[lseg[j]:lseg[j+1],:], axis=0)\n\n        # Find the shannon's entropy\n        spentropy = -1*np.sum(np.multiply(dspect,np.log(dspect)), axis=0)\n\n        # Find the spectral edge frequency\n        sfreq = fs\n        tfreq = 40\n        ppow = 0.5\n\n        topfreq = int(round(nt/sfreq*tfreq))+1\n        A = np.cumsum(D[:topfreq,:])\n        B = A - (A.max()*ppow)\n        spedge = np.min(np.abs(B))\n        spedge = (spedge - 1)/(topfreq-1)*tfreq\n\n        # Calculate correlation matrix and its eigenvalues (b/w channels)\n        data = pd.DataFrame(data=epoch)\n        type_corr = 'pearson'\n        lxchannels = corr(data, type_corr)\n        \n        # Calculate correlation matrix and its eigenvalues (b/w freq)\n        data = pd.DataFrame(data=dspect)\n        lxfreqbands = corr(data, type_corr)\n        \n        # Spectral entropy for dyadic bands\n        # Find number of dyadic levels\n        ldat = int(floor(nt/2.0))\n        no_levels = int(floor(log(ldat,2.0)))\n        seg = floor(ldat/pow(2.0, no_levels-1))\n\n        # Find the power spectrum at each dyadic level\n        dspect = np.zeros((no_levels,nc))\n        for j in range(no_levels-1,-1,-1):\n            dspect[j,:] = 2*np.sum(D[int(floor(ldat/2.0))+1:ldat,:], axis=0)\n            ldat = int(floor(ldat/2.0))\n\n        # Find the Shannon's entropy\n        spentropyDyd = -1*np.sum(np.multiply(dspect,np.log(dspect)), axis=0)\n\n        # Find correlation between channels\n        data = pd.DataFrame(data=dspect)\n        lxchannelsDyd = corr(data, type_corr)\n        \n        # Fractal dimensions\n        no_channels = nc\n        #fd = np.zeros((2,no_channels))\n        #for j in range(no_channels):\n        #    fd[0,j] = pyeeg.pfd(epoch[:,j])\n        #    fd[1,j] = pyeeg.hfd(epoch[:,j],3)\n        #    fd[2,j] = pyeeg.hurst(epoch[:,j])\n\n        #[mobility[j], complexity[j]] = pyeeg.hjorth(epoch[:,j)\n        # Hjorth parameters\n        # Activity\n        activity = np.var(epoch, axis=0)\n        #print('Activity shape: {}'.format(activity.shape))\n        # Mobility\n        mobility = np.divide(\n                            np.std(np.diff(epoch, axis=0)), \n                            np.std(epoch, axis=0))\n        #print('Mobility shape: {}'.format(mobility.shape))\n        # Complexity\n        complexity = np.divide(np.divide(\n                                        # std of second derivative for each channel\n                                        np.std(np.diff(np.diff(epoch, axis=0), axis=0), axis=0),\n                                        # std of second derivative for each channel\n                                        np.std(np.diff(epoch, axis=0), axis=0))\n                               , mobility)\n        #print('Complexity shape: {}'.format(complexity.shape))\n        # Statistical properties\n        # Skewness\n        sk = skew(epoch)\n\n        # Kurtosis\n        kurt = kurtosis(epoch)\n\n        # compile all the features\n        feat = np.concatenate((feat,\n                               spentropy.ravel(),\n                               spedge.ravel(),\n                               lxchannels.ravel(),\n                               lxfreqbands.ravel(),\n                               spentropyDyd.ravel(),\n                               lxchannelsDyd.ravel(),\n                               #fd.ravel(),\n                               activity.ravel(),\n                               mobility.ravel(),\n                               complexity.ravel(),\n                               sk.ravel(),\n                               kurt.ravel()\n                                ))\n\n    return feat"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"57c4e54a-fa1d-0cac-f0e6-7249fa702ad4"},"outputs":[],"source":"feat = calculate_features('../input/train_1/1_1_1.mat')\nprint(feat)\nprint(feat.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"29a76cc8-dd41-097d-e649-a7dba57a2ba3"},"outputs":[],"source":"mat_to_data('../input/train_1/1_1_1.mat')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2b394a4b-3282-64d1-a83d-0f3540fd2ce7"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}