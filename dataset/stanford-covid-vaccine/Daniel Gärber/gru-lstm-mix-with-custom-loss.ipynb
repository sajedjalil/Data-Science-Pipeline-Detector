{"cells":[{"metadata":{},"cell_type":"markdown","source":"Reworked notebook from Aman Kumar (https://www.kaggle.com/aestheteaman01/mvan-covid-mrna-vaccine-analysis-notebook-268)\n\nCleaned some functions and added a custom loss function\n\nAlso added stratified KFold Prediction with SN_filter as the class.\n\nFeel free to give feedback or suggestions!"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#the basics\nimport pandas as pd, numpy as np\nimport math, json, gc, random, os, sys\nfrom matplotlib import pyplot as plt\nfrom tqdm import tqdm\n\n#tensorflow deep learning basics\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport tensorflow.keras.backend as K\nimport tensorflow.keras.layers as L\n\n#for model evaluation\nfrom sklearn.model_selection import train_test_split, KFold,  StratifiedKFold","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#get comp data\ntrain = pd.read_json('/kaggle/input/stanford-covid-vaccine/train.json', lines=True)\ntest = pd.read_json('/kaggle/input/stanford-covid-vaccine/test.json', lines=True)\nsample_sub = pd.read_csv(\"/kaggle/input/stanford-covid-vaccine/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#target columns\ntarget_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\n\ndef get_pair_index_structure(structure):\n    structure = np.array([struc for struc in structure], dtype=\"<U4\")\n\n    open_index = np.where(structure == \"(\")[0]\n    closed_index = np.where(structure == \")\")[0]\n\n    structure[open_index] = range(0, len(open_index))\n    structure[closed_index] = range(len(open_index)-1, -1, -1)\n    structure[structure == \".\"] = -1\n    structure = structure.astype(int)\n\n    pair_structure = np.array([-1]*len(structure))\n    for i in range(len(open_index)):\n        start, end = np.where(structure == i)[0]\n        pair_structure[start] = end\n        pair_structure[end] = start    \n        \n    return pair_structure","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type']):\n    return np.transpose(\n        np.array(\n            df[cols]\n            .applymap(lambda seq: [token2int[x] for x in seq])\n            .values\n            .tolist()\n        ),\n        (0, 2, 1)\n    )\n\ntrain_inputs_all = preprocess_inputs(train)\ntrain_labels_all = np.array(train[target_cols].values.tolist()).transpose((0, 2, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# custom loss_fnc\ndef MCRMSE(y_true, y_pred):\n    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)\n\ndef gru_layer(hidden_dim, dropout):\n    return tf.keras.layers.Bidirectional(\n                                tf.keras.layers.GRU(hidden_dim,\n                                dropout=dropout,\n                                return_sequences=True,\n                                kernel_initializer = 'orthogonal'))\n\ndef lstm_layer(hidden_dim, dropout):\n    return tf.keras.layers.Bidirectional(\n                                tf.keras.layers.LSTM(hidden_dim,\n                                dropout=dropout,\n                                return_sequences=True,\n                                kernel_initializer = 'orthogonal'))\n\ndef build_model(model_type=1,seq_len=107, pred_len=68, dropout=0.4,\n                embed_dim=100, hidden_dim=128):\n    \n    inputs = tf.keras.layers.Input(shape=(seq_len, 3))\n\n    embed = tf.keras.layers.Embedding(input_dim=len(token2int), output_dim=embed_dim)(inputs)\n    reshaped = tf.reshape(\n        embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3]))\n    \n    reshaped = tf.keras.layers.SpatialDropout1D(.2)(reshaped)\n    \n    if model_type == 0:\n        hidden = gru_layer(hidden_dim, dropout)(reshaped)\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n        \n    elif model_type == 1:\n        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n        \n    elif model_type == 2:\n        hidden = gru_layer(hidden_dim, dropout)(reshaped)\n        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n        \n    elif model_type == 3:\n        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n\n    elif model_type == 4:\n        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n    \n    #only making predictions on the first part of each sequence\n    truncated = hidden[:, :pred_len]\n\n    out = tf.keras.layers.Dense(5, activation='linear')(truncated)\n\n    model = tf.keras.Model(inputs=inputs, outputs=out)\n\n    adam = tf.optimizers.Adam()\n    model.compile(optimizer=adam, loss=MCRMSE)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_and_predict(n_folds=5, model_name=\"model\", model_type=0, epochs=90, debug=False):\n\n    print(\"Model:\", model_name)\n\n    ensemble_preds = pd.DataFrame(index=sample_sub.index, columns=target_cols).fillna(0) # test dataframe with 0 values\n    kf = KFold(n_folds, shuffle=True, random_state=42)\n    skf = StratifiedKFold(n_folds, shuffle=True, random_state=42)\n    val_losses = []\n    historys = []\n\n    for i, (train_index, val_index) in enumerate(skf.split(train_inputs_all, train['SN_filter'])):\n        print(\"Fold:\", str(i+1))\n\n        model_train = build_model(model_type=model_type)\n        model_short = build_model(model_type=model_type, seq_len=107, pred_len=107)\n        model_long = build_model(model_type=model_type, seq_len=130, pred_len=130)\n\n        train_inputs, train_labels = train_inputs_all[train_index], train_labels_all[train_index]\n        val_inputs, val_labels = train_inputs_all[val_index], train_labels_all[val_index]\n\n        checkpoint = tf.keras.callbacks.ModelCheckpoint(f'{model_name}.h5')\n\n        history = model_train.fit(\n            train_inputs , train_labels, \n            validation_data=(val_inputs,val_labels),\n            batch_size=64,\n            epochs=epochs, # changed 70\n            callbacks=[tf.keras.callbacks.ReduceLROnPlateau(), checkpoint],\n            verbose=2 if debug else 0\n        )\n\n        print(f\"{model_name} Min training loss={min(history.history['loss'])}, min validation loss={min(history.history['val_loss'])}\")\n\n        val_losses.append(min(history.history['val_loss']))\n        historys.append(history)\n\n        model_short.load_weights(f'{model_name}.h5')\n        model_long.load_weights(f'{model_name}.h5')\n\n        public_preds = model_short.predict(public_inputs)\n        private_preds = model_long.predict(private_inputs)\n\n        preds_model = []\n        for df, preds in [(public_df, public_preds), (private_df, private_preds)]:\n            for i, uid in enumerate(df.id):\n                single_pred = preds[i]\n\n                single_df = pd.DataFrame(single_pred, columns=target_cols)\n                single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n                preds_model.append(single_df)\n\n        preds_model_df = pd.concat(preds_model)\n        ensemble_preds[target_cols] += preds_model_df[target_cols].values / n_folds\n\n        if debug:\n            print(\"Intermediate ensemble result\")\n            print(ensemble_preds[target_cols].head())\n\n    ensemble_preds[\"id_seqpos\"] = preds_model_df[\"id_seqpos\"].values\n    ensemble_preds = pd.merge(sample_sub[\"id_seqpos\"], ensemble_preds, on=\"id_seqpos\", how=\"left\")\n\n    print(\"Mean Validation loss:\", str(np.mean(val_losses)))\n\n    if debug:\n        fig, ax = plt.subplots(1, 1, figsize = (10, 5))\n        for i, history in enumerate(historys):\n            ax.plot(history.history['loss'])\n            ax.plot(history.history['val_loss'])\n            ax.set_title('model_'+str(i+1))\n            ax.set_ylabel('Loss')\n            ax.set_xlabel('Epoch')\n        plt.show()\n\n    return ensemble_preds\n\n\npublic_df = test.query(\"seq_length == 107\").copy()\nprivate_df = test.query(\"seq_length == 130\").copy()\npublic_inputs = preprocess_inputs(public_df)\nprivate_inputs = preprocess_inputs(private_df)\n\nensembles = []\n\nfor i in range(5):\n    model_name = \"model_\"+str(i+1)\n\n    ensemble = train_and_predict(n_folds=5, model_name=model_name, model_type=i, epochs=100)\n    ensembles.append(ensemble)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ensemble_final = ensembles[0].copy()\nensemble_final[target_cols] = 0\n\nfor ensemble in ensembles:\n    ensemble_final[target_cols] += ensemble[target_cols].values / len(ensembles)\n\nensemble_final","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ensemble_final.to_csv('ensemble_final.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}