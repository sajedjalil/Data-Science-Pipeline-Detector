{"cells":[{"metadata":{},"cell_type":"markdown","source":"## LightGBM with Network Features\nThis notebook will demonstrate lightgbm with network features.  \nThe network features I calculated are \"betweenness centrality\", \"closeness centrality\" and \"eigenvector_centrality\".  \nThey are calculated by NetworkX."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport lightgbm as lgb\npd.options.display.max_columns = 100\n\ntrain = pd.read_json('../input/stanford-covid-vaccine/train.json',lines=True)\ntest = pd.read_json('../input/stanford-covid-vaccine/test.json', lines=True)\nsample_sub = pd.read_csv('../input/stanford-covid-vaccine/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport networkx as nx\n\nseq_ls = ['A','U','C','G']\nstr_ls = ['.','(',')']\nloop_ls = ['S','M','I','B','H','E','X']\n\n\ndef series_enc(dic):\n    def f(series):\n        y = ''\n        for s in series:\n            y += str(dic[s])\n        return y\n    return f\n\nbpps_dir = '../input/stanford-covid-vaccine/bpps/'\ntarget_cols = ['reactivity','deg_Mg_pH10','deg_pH10','deg_Mg_50C','deg_50C']\nenc = ['sequence','structure','predicted_loop_type']\ncnt_feature = ['sequence_cnt0', 'sequence_cnt1', 'sequence_cnt2', 'sequence_cnt3', 'structure_cnt0', 'structure_cnt1', 'structure_cnt2',\\\n               'predicted_loop_type_cnt0', 'predicted_loop_type_cnt1', 'predicted_loop_type_cnt2', 'predicted_loop_type_cnt3', 'predicted_loop_type_cnt4',\\\n               'predicted_loop_type_cnt5', 'predicted_loop_type_cnt6']\nx_col = ['num','bpps_num1','bpps_num2','bpps_num3','between_centers0','closeness_centrality0','eigenvector_centrality_numpy0',\\\n         'between_centers1','closeness_centrality1','eigenvector_centrality_numpy1']+enc+cnt_feature\n\ndef feature1(df,is_train=True):\n    seq_dic = dict(zip(seq_ls,list(range(len(seq_ls)))))\n    str_dic = dict(zip(str_ls,list(range(len(str_ls)))))\n    loop_dic = dict(zip(loop_ls,list(range(len(loop_ls)))))\n    seq_enc = series_enc(seq_dic)\n    str_enc = series_enc(str_dic)\n    loop_enc = series_enc(loop_dic)\n    \n    df.loc[:,'sequence_enc'] = df['sequence'].apply(seq_enc)\n    df.loc[:,'structure_enc'] = df['structure'].apply(str_enc)\n    df.loc[:,'predicted_loop_type_enc'] = df['predicted_loop_type'].apply(loop_enc)\n    cnt_feature = []\n    for i,s in enumerate(seq_ls):\n        df.loc[:,'sequence_cnt'+str(i)]=df['sequence'].apply(lambda x:list(x).count(str(s)))/df.loc[:,'seq_length']\n    for i,s in enumerate(str_ls):\n        df.loc[:,'structure_cnt'+str(i)]=df['structure'].apply(lambda x:list(x).count(str(s)))/df.loc[:,'seq_length']\n    for i,s in enumerate(loop_ls):\n        df.loc[:,'predicted_loop_type_cnt'+str(i)]=df['predicted_loop_type'].apply(lambda x:list(x).count(str(s)))/df.loc[:,'seq_length']\n\n    for i in df.index:\n        if i%100==0:\n            _dfs = make_series1(df.loc[i,:],is_train=is_train)\n        else:\n            _df = make_series1(df.loc[i,:],is_train=is_train)\n            _dfs = pd.concat([_dfs,_df],copy=False)\n        if (i%100==99) or i==df.index[-1]:\n            if i==99:\n                dfs=_dfs\n            else:\n                dfs=pd.concat([dfs,_dfs],copy=False)\n            print(i+1,end=',')\n    for c in x_col:\n        dfs.loc[:,c] = dfs[c].astype(float)\n    return dfs\n\ndef make_series1(series,is_train=True):\n    num = series['seq_scored']\n    df = pd.DataFrame(index=range(num))\n    df.loc[:,'id_seqpos'] = df.index\n    df.loc[:,'id_seqpos'] = df['id_seqpos'].apply(lambda x:series['id']+'_'+str(x))\n    df.loc[:,'id'] = series['id']\n    df.loc[:,'num'] = df.index\n    for c in cnt_feature:\n        df.loc[:,c] = series[c]\n    if is_train:\n        for c in ['signal_to_noise','SN_filter']:\n            df.loc[:,c] = series[c]\n    col = ['reactivity','deg_Mg_pH10','deg_pH10','deg_Mg_50C','deg_50C'] +\\\n          ['reactivity_error','deg_error_Mg_pH10','deg_error_pH10','deg_error_Mg_50C','deg_error_50C']\n    for c in col:\n        if is_train:\n            df.loc[:,c]=series[c]\n    enc = ['sequence','structure','predicted_loop_type']\n    for e in enc:\n        df.loc[:,e] = list(series[e+'_enc'][:num])\n        for n in range(1,6):\n            df.loc[:,e+'_n'+str(n)] = list(series[e+'_enc'][n:num+n])\n        for m in range(1,6):\n            df.loc[:,e+'_m'+str(m)] = [-1]*m+list(series[e+'_enc'][:num-m])\n    mat = np.load(bpps_dir+series['id']+'.npy')\n    df.loc[:,'bpps_sum'] = mat.sum(axis=0)[:num]/mat.shape[0]\n    mat0 = mat>0.0\n    df.loc[:,'bpps_num0'] = mat0.sum(axis=0)[:num]/mat0.shape[0]\n    mat1 = mat>0.1\n    df.loc[:,'bpps_num1'] = mat1.sum(axis=0)[:num]/mat1.shape[0]\n    mat2 = mat>0.2\n    df.loc[:,'bpps_num2'] = mat2.sum(axis=0)[:num]/mat2.shape[0]\n    mat3 = mat>0.3\n    df.loc[:,'bpps_num3'] = mat3.sum(axis=0)[:num]/mat3.shape[0]\n    \n    mat0 = mat0.astype(int)\n    for i in range(mat.shape[0]-1):\n        mat0[i,i+1]=1\n    nodes = np.array(list(range(mat.shape[0])))\n    G = nx.Graph()\n    G.add_nodes_from(nodes)\n    edges = []\n    for hi, hv  in enumerate(mat0):\n        for wi, wv in enumerate(hv):\n            if(wv): edges.append((nodes[hi], nodes[wi]))\n    G.add_edges_from(edges)\n    df.loc[:,'between_centers0'] = list((nx.betweenness_centrality(G)).values())[:num]\n    df.loc[:,'closeness_centrality0'] = list((nx.closeness_centrality(G)).values())[:num]\n    df.loc[:,'eigenvector_centrality_numpy0'] = list((nx.eigenvector_centrality_numpy(G)).values())[:num]\n    df['clustering0'] = list((nx.clustering(G).values()))[:num]\n    \n    mat1 = mat1.astype(int)\n    for i in range(mat.shape[0]-1):\n        mat1[i,i+1]=1\n    nodes = np.array(list(range(mat.shape[0])))\n    G = nx.Graph()\n    G.add_nodes_from(nodes)\n    edges = []\n    for hi, hv  in enumerate(mat1):\n        for wi, wv in enumerate(hv):\n            if(wv): edges.append((nodes[hi], nodes[wi]))\n    G.add_edges_from(edges)\n    df.loc[:,'between_centers1'] = list((nx.betweenness_centrality(G)).values())[:num]\n    df.loc[:,'closeness_centrality1'] = list((nx.closeness_centrality(G)).values())[:num]\n    df.loc[:,'eigenvector_centrality_numpy1'] = list((nx.eigenvector_centrality_numpy(G)).values())[:num]\n    #df['clustering1'] = list((nx.clustering(G).values()))[:num]\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('calculate train feature')\ndf = feature1(train.loc[:,:])\nprint('calculate test feature')\ntest_df = feature1(test.loc[:,:], is_train=False)\n\nenc = ['sequence','structure','predicted_loop_type']\ncnt_feature = ['sequence_cnt0', 'sequence_cnt1', 'sequence_cnt2', 'sequence_cnt3', 'structure_cnt0', 'structure_cnt1', 'structure_cnt2',\\\n               'predicted_loop_type_cnt0', 'predicted_loop_type_cnt1', 'predicted_loop_type_cnt2', 'predicted_loop_type_cnt3', 'predicted_loop_type_cnt4',\\\n               'predicted_loop_type_cnt5', 'predicted_loop_type_cnt6']\nx_col = ['num','bpps_num1','bpps_num2','bpps_num3','between_centers0','closeness_centrality0','eigenvector_centrality_numpy0',\\\n         'between_centers1','closeness_centrality1','eigenvector_centrality_numpy1']+enc+cnt_feature\nother_col = ['signal_to_noise','SN_filter'] + ['reactivity_error','deg_error_Mg_pH10','deg_error_pH10','deg_error_Mg_50C','deg_error_50C']\nfor i in range(1,6):\n    x_col = x_col+[x+'_n'+str(i) for x in enc]\n    x_col = x_col+[x+'_m'+str(i) for x in enc]\nfor c in x_col:\n    df[c] = df[c].astype(float)\n    test_df[c] = test_df[c].astype(float)  \ndf = df.reset_index(drop=True)\ntest_df = test_df.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LightGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"params = {\n        'task' : 'train',\n        'boosting_type' : 'gbdt',\n        'objective' : 'regression',\n        'metric' : {'l2'},\n        'num_leaves' : 101,\n        'learning_rate' : 0.005,\n        'feature_fraction' : 0.9,\n        'bagging_fraction' : 0.8,\n        'bagging_freq': 5,\n        'verbose' : 0,\n        'early_stopping_rounds': 100\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, GroupKFold\nimport lightgbm as lgb\nimport numpy as np\n\n\nscore = []\nE = 10\nfor e in range(E):\n    print(e)\n    train_id, val_id = train_test_split(train.loc[train['SN_filter']==1,'id'],train_size=0.8,random_state=e)\n    result = df.loc[df['id'].isin(val_id),:].copy()\n    for y_col in ['reactivity','deg_Mg_pH10','deg_pH10','deg_Mg_50C','deg_50C']:\n        #y_col = 'reactivity'\n        print(y_col)\n        train_x = df.loc[df['id'].isin(train_id),x_col]\n        train_y = df.loc[df['id'].isin(train_id),y_col]\n        val_x = df.loc[df['id'].isin(val_id),x_col]\n        val_y = df.loc[df['id'].isin(val_id),y_col]\n\n\n        lgb_train = lgb.Dataset(train_x,label=train_y)\n        lgb_val = lgb.Dataset(val_x, label=val_y, reference= lgb_train)\n        gbm = lgb.train(params,lgb_train,valid_sets=lgb_val,num_boost_round=100000,verbose_eval=100)\n        score.append(gbm.best_score['valid_0']['l2'])\n        if e==0:\n            test_df[y_col] = gbm.predict(test_df[x_col])/E\n        else:\n            test_df[y_col] += gbm.predict(test_df[x_col])/E\n        #result[y_col] = gbm.predict(val_x)\nprint(np.mean(score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = sample_sub.copy()[['id_seqpos']]\nsub = pd.merge(sub,test_df,on='id_seqpos',how='left').loc[:,['id_seqpos','reactivity','deg_Mg_pH10','deg_pH10','deg_Mg_50C','deg_50C']]\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = sub.fillna(0)\nsub.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}