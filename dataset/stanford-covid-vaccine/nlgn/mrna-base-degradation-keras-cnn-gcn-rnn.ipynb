{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport json\nimport os\nfrom tqdm import tqdm\n\n# sklearn\nfrom sklearn.model_selection import train_test_split\n\n# tensorflow and keras\nfrom keras.utils.vis_utils import plot_model\n\nimport tensorflow.keras.layers as L\nimport keras.backend as K\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install spektral -q","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from spektral.layers import GraphConv","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_json_path = \"/kaggle/input/stanford-covid-vaccine/train.json\"\ntest_json_path = \"/kaggle/input/stanford-covid-vaccine/test.json\"\nsample_sub_path = \"/kaggle/input/stanford-covid-vaccine/sample_submission.csv\"\n\noutput_path = \"./\"\nbpps_path = \"/kaggle/input/stanford-covid-vaccine/bpps\"\n\ntrain_df = pd.read_json(train_json_path, lines=True)\ntest_df = pd.read_json(test_json_path, lines=True)\n\n# there are 2 part of the test set, they have different seq length\npublic_df = test_df.query(\"seq_length == 107\").copy()\nprivate_df = test_df.query(\"seq_length == 130\").copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction Columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\ntrain_df[pred_cols].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y = np.array(train_df[pred_cols].values.tolist()).transpose((0, 2, 1))\ntrain_y.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sequence Features"},{"metadata":{},"cell_type":"markdown","source":"Each mRNA contains 107 bases in train:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[[\"id\", \"sequence\", \"structure\", \"predicted_loop_type\"]].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Both `sequence`, `structure` and `predicted_loop_type` are sequences data for those 107 bases, let's transform them. \n\n(2400, 3) -> (2400, 107, 3)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# label encodings for \ntoken2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\nsequence_token2int = {x:i for i, x in enumerate('AGUC')}\nstructure_token2int = {\n    '.': 0,\n    '(': 1,\n    ')': 2,\n}\nloop_token2int = {x:i for i, x in enumerate('SMIBHEX')}\ntoken2int_map = {\n    \"sequence\": sequence_token2int,\n    \"structure\": structure_token2int,\n    \"predicted_loop_type\": loop_token2int\n}\nsequence_columns = [\"sequence\", \"structure\", \"predicted_loop_type\"]\n\ndef to_seq(df):\n    return np.transpose(\n        np.array(\n            df[sequence_columns]\n            .applymap(lambda seq: [token2int[x] for x in seq])\n            .values\n            .tolist()\n        ),\n        (0, 2, 1)\n    )\n\ntrain = to_seq(train_df)\npublic = to_seq(public_df)\nprivate = to_seq(private_df)\n\ntrain.shape, public.shape, private.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's apply one-hot encoding to the data\n\n(2400, 107, 3) -> (2400, 107, 14)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_one_hot(df):\n    temp = np.transpose(\n        np.array([\n            df[col]\n            .apply(lambda seq: [token2int_map[col][x] for x in seq])\n            .values\n            .tolist()\n            for col in sequence_columns\n        ]),\n        (1, 2, 0)\n    )\n    ohe_1 = tf.keras.utils.to_categorical(temp[:,:,0], 4)\n    ohe_2 = tf.keras.utils.to_categorical(temp[:,:,1], 3)\n    ohe_3 = tf.keras.utils.to_categorical(temp[:,:,2], 7)\n    return np.concatenate([ohe_1, ohe_2, ohe_3], axis=2)\n\ntrain_ohe = to_one_hot(train_df)\npublic_ohe = to_one_hot(public_df)\nprivate_ohe = to_one_hot(private_df)\n\ntrain_ohe.shape, public_ohe.shape, private_ohe.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pair/Connectivity Features"},{"metadata":{},"cell_type":"markdown","source":"Get the adjacency matrices from the structure sequence:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_adjacency_matrix(inps):\n    As = []\n    for row in range(0, inps.shape[0]):\n        A = np.zeros((inps.shape[1], inps.shape[1]))\n        stack = []\n        opened_so_far = []\n\n        for seqpos in range(0, inps.shape[1]):\n            # A[seqpos, seqpos] = 1\n            if inps[row, seqpos, 1] == 0:\n                stack.append(seqpos)\n                opened_so_far.append(seqpos)\n            elif inps[row, seqpos, 1] == 1:\n                openpos = stack.pop()\n                A[openpos, seqpos] = 1\n                A[seqpos, openpos] = 1\n        As.append(A)\n    return np.array(As)\n\ntrain_adj = get_adjacency_matrix(train)\npublic_adj = get_adjacency_matrix(public)\nprivate_adj = get_adjacency_matrix(private)\n\ntrain_adj.shape, public_adj.shape, private_adj.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_adj.mean(), public_adj.mean(), private_adj.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get the base pair probabilities from the given bpps files"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_bpps(mRNA_ids):\n    bpps = []\n    for mRNA_id in tqdm(mRNA_ids):\n        bpps.append(\n            np.load(f\"{bpps_path}/{mRNA_id}.npy\"),\n        )\n    return np.array(bpps)\n\n\ntrain_bpps = get_bpps(train_df.id.values)\npublic_bpps = get_bpps(public_df.id.values)\nprivate_bpps = get_bpps(private_df.id.values)\n\ntrain_bpps.shape, public_bpps.shape, private_bpps.shape ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_bpps.mean(), public_bpps.mean(), private_bpps.mean() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get pair probabilities statistics for each base"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_bpps_stats = [train_bpps.mean(axis=2), train_bpps.max(axis=2)]\npublic_bpps_stats = [public_bpps.mean(axis=2), public_bpps.max(axis=2)]\nprivate_bpps_stats = [private_bpps.mean(axis=2), private_bpps.max(axis=2)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_bpps_stats = np.concatenate([stats[:,:,None] for stats in train_bpps_stats], axis=2)\npublic_bpps_stats = np.concatenate([stats[:,:,None] for stats in public_bpps_stats], axis=2)\nprivate_bpps_stats = np.concatenate([stats[:,:,None] for stats in private_bpps_stats], axis=2)\n\ntrain_bpps_stats.shape, public_bpps_stats.shape, private_bpps_stats.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{},"cell_type":"markdown","source":"![](https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F690886%2F83da03ea10245b6867febd170f6188f4%2FScreenshot%202020-10-08%20at%207.51.09%20AM.png?generation=1602114976893373&alt=media)"},{"metadata":{"trusted":true},"cell_type":"code","source":"scored_seq_length = 68\n\n# loss functions\ndef rmse(y_actual, y_pred):\n    mse = tf.keras.losses.mean_squared_error(y_actual, y_pred)\n    return K.sqrt(mse)\n\ndef mcrmse(y_actual, y_pred):\n    score = 0\n    for i in range(y_actual.shape[2]):\n        score += rmse(y_actual[:, :, i], y_pred[:, :, i]) / y_actual.shape[2]\n    return score\n    \n\ndef build_model(input_seq_len=107, output_seq_len=scored_seq_length):\n    \n    def _bi_gru_block(x, hidden_dim, dropout):\n        gru = L.Bidirectional(\n            L.GRU(hidden_dim, \n                  dropout=dropout,\n                  return_sequences=True,\n                 ),\n        )(x)\n        return gru\n\n    def _conv_block(x, adj_m, bpp_m, conv_filters, graph_channels):\n        # local 1-D convolution\n        conv = L.Conv1D(\n            conv_filters, 5,\n            padding='same',\n            activation='tanh',\n        )(x)\n        \n        # graph convolution\n        gcn_1 = GraphConv(\n            graph_channels,\n            activation='tanh',\n        )([conv, adj_m])\n        \n        gcn_2 = GraphConv(\n            graph_channels,\n            activation='tanh',\n        )([conv, bpp_m])\n\n        conv = L.Concatenate()([conv, gcn_1, gcn_2])\n        conv = L.Activation(\"relu\")(conv)\n        conv = L.SpatialDropout1D(0.1)(conv)\n        \n        return conv\n    \n    # inputs\n    one_hot_encoding_inputs = L.Input(shape=(input_seq_len, 14), name=\"onehot\")\n    # adjacency matrix about seq. connectivity\n    adj_matrix_inputs = L.Input((input_seq_len, input_seq_len), name=\"adjmatrix\")\n    # base pair proba\n    base_pair_proba_inputs = L.Input((input_seq_len, input_seq_len), name=\"pairproba\")\n    # base pair proba stats\n    base_pair_proba_stats_inputs = L.Input(shape=(input_seq_len, 2), name=\"pairprobastats\")\n    \n    merged_inputs = L.Concatenate()([one_hot_encoding_inputs, base_pair_proba_stats_inputs])\n    \n    # convolution and recurrent blocks.\n    hidden = _conv_block(merged_inputs, adj_matrix_inputs, base_pair_proba_inputs, 512, 80)\n    hidden = _bi_gru_block(hidden, 256, 0.5)\n    hidden = _conv_block(hidden, adj_matrix_inputs, base_pair_proba_inputs, 512, 80)\n    hidden = _bi_gru_block(hidden, 256, 0.5)\n    \n    out = hidden[:, :output_seq_len]\n    out = L.Dense(5, activation='linear')(out)\n    \n    model = tf.keras.Model(\n        inputs=[\n            one_hot_encoding_inputs,\n            adj_matrix_inputs,\n            base_pair_proba_inputs,\n            base_pair_proba_stats_inputs,\n        ],\n        outputs=out,\n    )\n\n    return model\n\nmodel = build_model()\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"split_results  = train_test_split(\n    train_ohe,\n    train_adj,\n    train_bpps,\n    train_bpps_stats,\n    train_y,\n    train_df.signal_to_noise,\n    train_df.SN_filter,\n    test_size=0.1,\n    random_state=42,\n)\n\n[a.shape for a in split_results]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trn_ohe, val_ohe, trn_adj, val_adj, trn_bpps, val_bpps, trn_bpps_stats, val_bpps_stats, trn_y, val_y, trn_snr, val_snr, trn_snf, val_snf = split_results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model()\nmodel.compile(tf.keras.optimizers.Adam(), loss=mcrmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trn_inputs = [trn_ohe, trn_adj, trn_bpps, trn_bpps_stats]\nval_inputs = [val_ohe, val_adj, val_bpps, val_bpps_stats]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# only validate on data with sn_filter = 1\nval_mask = np.where((val_snf==1))\nval_inputs = [val_input[val_mask] for val_input in val_inputs]\nval_y = val_y[val_mask]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_weight = np.log(trn_snr+1.11)/2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(\n    trn_inputs, trn_y,\n    validation_data = (val_inputs, val_y),\n    batch_size=64,\n    epochs=300,\n    sample_weight=sample_weight,\n    callbacks=[\n        tf.keras.callbacks.ReduceLROnPlateau(verbose=1, monitor='val_loss'),\n        tf.keras.callbacks.ModelCheckpoint(f'model.h5',save_best_only=True, verbose=0, monitor='val_loss'),\n        tf.keras.callbacks.EarlyStopping(\n            patience=20, \n            monitor='val_loss',\n            verbose=0,\n            mode=\"auto\",\n            baseline=None,\n            restore_best_weights=True,\n        ),\n    ],\n    verbose=2\n)\nprint(f\"Min validation loss history={min(history.history['val_loss'])}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights(f'model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_preds = model.predict(val_inputs)\ntf.reduce_mean(mcrmse(val_y, val_preds))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_public = build_model(107, 107)\nmodel_private = build_model(130, 130)\n\nmodel_public.load_weights(f'model.h5')\nmodel_private.load_weights(f'model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"public_inputs = [public_ohe, public_adj, public_bpps, public_bpps_stats,]\nprivate_inputs = [private_ohe, private_adj, private_bpps, private_bpps_stats,]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = [model_public.predict(public_inputs), model_private.predict(private_inputs)]\ntest_dfs = [public_df, private_df]\n\ntest_preds[0].shape, test_preds[1].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_ls = []\nfor df, preds in zip(test_dfs, test_preds):\n    for i, uid in tqdm(enumerate(df.id)):\n        single_pred = preds[i]\n        single_df = pd.DataFrame(single_pred, columns=pred_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n        preds_ls.append(single_df)\npreds_df = pd.concat(preds_ls).groupby('id_seqpos').mean().reset_index()\n\ntest_df.shape, preds_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = preds_df[['id_seqpos', 'reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']]\nsubmission.to_csv(f'submission.csv', index=False)\nprint(f'wrote to submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.shape, pd.read_csv(sample_sub_path).shape, test_df.shape","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}