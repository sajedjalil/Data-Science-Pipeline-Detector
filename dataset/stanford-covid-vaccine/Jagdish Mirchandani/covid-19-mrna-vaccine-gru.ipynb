{"cells":[{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:blue; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Introduction to the Competition : OpenVaccine: COVID-19 mRNA Vaccine Degradation Prediction\n </center></h2>\n\nCOVID 19 does not need any introduction, this virus has already killed millions of people all around the world.\n\nWinning the fight against the COVID-19 pandemic will require an effective vaccine that can be equitably and widely distributed. \n\nmRNA vaccines have taken the lead as the fastest vaccine candidates for COVID-19, but currently, they face key potential limitations. One of the biggest challenges right now is how to design super stable messenger RNA molecules (mRNA). \n\nResearchers have observed that RNA molecules have the tendency to spontaneously degrade. \n\nThis is a serious limitation--a single cut can render the mRNA vaccine useless. \n\nCurrently, little is known on the details of where in the backbone of a given RNA is most prone to being affected. \n\nImproving the stability of mRNA vaccines was a problem that was being explored before the pandemic but was expected to take many years to solve. Now, we must solve this deep scientific challenge in months, if not weeks, to accelerate mRNA vaccine research and deliver a refrigerator-stable vaccine against SARS-CoV-2, the virus behind COVID-19. \n\nThe problem we are trying to solve has eluded academic labs, industry R&D groups, and supercomputers, and now its our turn. \n\nIn this competition, we are looking to leverage the data science expertise of the Kaggle community to develop models and design rules for RNA degradation. \n\nWe need to build a model which will predict likely degradation rates at each base of an RNA molecule, trained on a subset of an Eterna dataset comprising over 3000 RNA molecules (which span a panoply of sequences and structures) and their degradation rates at each position. "},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:blue; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>What is RNA & Why Is It so much PRONE to Degradation?\n </center></h2>\n\n    \n`Ribonucleic acid / RNA`\n\nRibonucleic acid (RNA) is a `linear molecule` composed of `four types of smaller molecules` called `ribonucleotide bases`: \n\n* adenine  (A)\n* cytosine (C)\n* guanine  (G)\n* uracil   (U)\n\nRNA is often compared to a copy from a reference book, or a template, because it carries the same information as its DNA template but is not used for long-term storage.\n\nEach ribonucleotide base consists of a ribose sugar, a phosphate group, and a nitrogenous base. \n    \n`Adjacent ribose nucleotide` bases are chemically attached to one another in a chain via chemical bonds called `phosphodiester bonds`. \n    \nUnlike DNA, RNA is usually `single-stranded`. \n\nAdditionally, RNA contains ribose sugars rather than deoxyribose sugars, which makes RNA more unstable and more prone to degradation."},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:blue; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center> Import Necessary tools üõ†\n </center></h2>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import json\n\nimport pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport tensorflow.keras.layers as L\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:blue; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center> Read JSON Files ‚úî\n </center></h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = '/kaggle/input/stanford-covid-vaccine/'\ntrain = pd.read_json(data_dir + 'train.json', lines=True)\ntest = pd.read_json(data_dir + 'test.json', lines=True)\nsample_df = pd.read_csv(data_dir + 'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:blue; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Lets check the Data üìÅ\n </center></h2>\n    \n### We will check all the fields given [here](https://www.kaggle.com/c/stanford-covid-vaccine/data)"},{"metadata":{},"cell_type":"markdown","source":"### seq_scored - (68 in Train and Public Test, 91 in Private Test) \nInteger value denoting the number of positions used in scoring with predicted values. \n\nThis should match the length of `reactivity`, `deg_*` and `*_error_* `columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Unique values & no. of occurences for seq_scored in the training dataset:\\n\",train.seq_scored.value_counts())\nprint(\"\\nUnique values & no. of occurences for seq_scored in the test dataset:\\n\",test.seq_scored.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<b>Key Observatoionsüìå</b> \n\n* We have got the exact count as mentioned on the data page of the competition, all the records present in the training dataset has a value of 68 for seq_scored\n    \n* Test dataset has 2 different values, 68 for public test data and 91 for private test data\n    \n* No. of records for different values are also in synch with what is mentioned on the data page, for both train and test datasets\n</div>"},{"metadata":{},"cell_type":"markdown","source":"### Now let's verify the columns which are tightly bound with seq_scored\n* reactivity\n* deg_* \n* *_error_*"},{"metadata":{"trusted":true},"cell_type":"code","source":"# training dataset\ndeg_columns = ['reactivity','deg_error_Mg_pH10', 'deg_error_pH10','deg_error_Mg_50C', 'deg_error_50C', 'deg_Mg_pH10','deg_pH10', 'deg_Mg_50C', 'deg_50C']\n\nfor col in deg_columns:\n    length = []\n    for each in range(train.shape[0]):\n        length.append(len(train[col].iloc[each]))\n\n    print(\"Length of different values for \" + col + \" in training dataset:\",set(length))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<b>Key Observatoionsüìå</b> \n\n* What we verified above is that all the columns in question have values of length 68 for all the records in the training dataset.\nThis is in synch with the information provided by seq_scored field \n</div>"},{"metadata":{},"cell_type":"markdown","source":"### seq_length - (107 in Train and Public Test, 130 in Private Test) \nInteger values, denotes the length of sequence. Note that molecules used for the Private Test will be longer than those in the Train and Public Test data, so the size of this vector will be different."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Unique values & there occurences for seq_length in the training dataset:\\n\",train.seq_length.value_counts())\nprint(\"\\nUnique values & there occurences for seq_length in the test dataset:\\n\",test.seq_length.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<b>Key Observatoionsüìå</b> \n\n* For each record in the training dataset, sequence lenght is 107\n    \n* For test dataset, we have a mix of 130 and 107 sequence lengh which actually represents public and private test data\n\n* Data seems to be in synch with what is mentioned on the data page for both training and test dataset\n</div>"},{"metadata":{},"cell_type":"markdown","source":"### Now let's verify the column \"sequence\" which are tightly bound with seq_length"},{"metadata":{"trusted":true},"cell_type":"code","source":"# training dataset\nlength = []\nfor each in range(train.shape[0]):\n    length.append(len(train.sequence.iloc[each]))\n\nprint(\"length of different values for sequence in training dataset:\",set(length))\n\n# test dataset\nlength = []\nfor each in range(test.shape[0]):\n    length.append(len(test.sequence.iloc[each]))\n\nprint(\"\\nlength of different values for sequence in test dataset:\",set(length))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<b>Key Observatoionsüìå</b> \n\n* We have now verified that sequence has a length of 107 for each record in the training dataset\n \n* Whereas test dataset has a mix of 130 and 107 lengths which represents private and public test data\n</div>"},{"metadata":{},"cell_type":"markdown","source":"### structure - (1x107 string in Train and Public Test, 130 in Private Test) \nAn array of (, ), and . characters that describe whether a base is estimated to be paired or unpaired. Paired bases are denoted by opening and closing parentheses e.g. (....) means that base 0 is paired to base 5, and bases 1-4 are unpaired."},{"metadata":{"trusted":true},"cell_type":"code","source":"# training dataset\nlength = []\nfor each in range(train.shape[0]):\n    length.append(len(train.structure.iloc[each]))\n\nprint(\"length of different values for structure in training dataset:\",set(length))\n\n# test dataset\nlength = []\nfor each in range(test.shape[0]):\n    length.append(len(test.structure.iloc[each]))\n\nprint(\"\\nlength of different values for structure in test dataset:\",set(length))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<b>Key Observatoionsüìå</b> \n\n* We have now verified that structure has a length of 107 for each record in the training dataset\n \n* Whereas test dataset has a mix of 130 and 107 lengths which represents private and public test data\n</div>"},{"metadata":{},"cell_type":"markdown","source":"### predicted_loop_type - (1x107 string) Describes the structural context\n(also referred to as 'loop type')of each character in sequence. Loop types assigned by bpRNA from Vienna RNAfold 2 structure. From the bpRNA_documentation: S: paired \"Stem\" M: Multiloop I: Internal loop B: Bulge H: Hairpin loop E: dangling End X: eXternal loop"},{"metadata":{"trusted":true},"cell_type":"code","source":"# training dataset\nlength = []\nfor each in range(train.shape[0]):\n    length.append(len(train.predicted_loop_type.iloc[each]))\n\nprint(\"length of different values for predicted_loop_type in training dataset:\",set(length))\n\n# test dataset\nlength = []\nfor each in range(test.shape[0]):\n    length.append(len(test.predicted_loop_type.iloc[each]))\n\nprint(\"\\nlength of different values for predicted_loop_type in test dataset:\",set(length))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<b>Key Observatoionsüìå</b> \n\n* We have now verified that predicted loop has a length of 107 for each record in the training dataset\n \n* Whereas test dataset has a mix of 130 and 107 lengths which represents private and public test data\n</div>"},{"metadata":{},"cell_type":"markdown","source":"### We have now seen how the data looks like, lets move toward data pre-processing"},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:blue; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>Data Preprocessing‚úç\n </center></h2>"},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<b>Please Note:</b> \n\nAs mentioned in the additional notes on the data page:\n    \nMean signal/noise across all 5 conditions must be greater than 1.0. [Signal/noise is defined as mean( measurement value over 68 nts )/mean( statistical error in measurement value over 68 nts)]\n\nWe will filter out records with noise less than 1.0\n                                         \n</div>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# filter records with signal to noise < 1\ntrain = train.query(\"signal_to_noise >= 1\")\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Helper Variables & Functions to pre-process the input data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This function would help us converting the target variables into an array which can be fed into keras model\ndef pandas_list_to_array(df):\n    \"\"\"\n    Input: dataframe of shape (x, y), containing list of length l\n    Return: np.array of shape (x, l, y)\n    \"\"\"\n    \n    return np.transpose(\n        np.array(df.values.tolist()),\n        (0, 2, 1)\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We are defining a function here to take care of the conversion\n# df would be the training or the test dataset\n# token2int is dictionary which contains the character/integer mapping\n\ndef preprocess_inputs(df, token2int, cols=['sequence', 'structure', 'predicted_loop_type']):\n    return pandas_list_to_array(\n        df[cols].applymap(lambda seq: [token2int[x] for x in seq])\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predictor variables\npred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C', 'deg_pH10', 'deg_50C']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<b>Please Note:</b> \n\nEven though we have taken 5 predictor variables above, only 3 (reactivity, degMgpH10, and degMg50C) are going to be scored                                         \n</div>"},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<b>Please Note:</b> \n\nWe have following 3 columns with character sequence:\n  \n* sequence\n* structure \n* predicted_loop_type\n    \nwe need to convert them to integers so that we can feed them into the model.                              \n</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# we are using a dictinoary here to map each character with a unique integer\ntoken2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\n\n# calling the function defined above to apply the actual character to integer conversion\n# train_inputs is the dataframe we are going to use to feed our keras model\ntrain_inputs = preprocess_inputs(train, token2int)\n\n# call the function to reshape the predictor variables to convert into an array which can be fed into keras model\ntrain_labels = pandas_list_to_array(train[pred_cols])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# sets the random seed\ntf.random.set_seed(2020)\nnp.random.seed(2020)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This is to generate a new set of random values every time\ny_true = tf.random.normal((32, 68, 3))\ny_pred = tf.random.normal((32, 68, 3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<a id=\"10\"></a>\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:blue; border:0; color:white' role=\"tab\" aria-controls=\"home\"><center>MCRMSE - Mean Columnwise Root Mean Squared Error üî¨\n </center></h2>\n\nMCRMSE is the evaluation metric used in this competition.\n\nThe reason we are using MCRMSE in this challenges is because there are multiple outputs that we are trying to predict.\n\nNormally, we can calculate RMSE to get a single-number evaluation metric for our prediction, but if we are predicting multiple values at once‚àíin the case of the OpenVaccine competition, we need to predict degradation rates under multiple conditions‚àíwe would get multiple different RMSE values, one for each column.\n\nThe MCRMSE is simply an average across all RMSE values for each of our columns, so we can still use a single-number evaluation metric, even in the case of multiple outputs.\n\n### Lets write a helper function to implement MCRMSE."},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to calculate average across all RMSE values for each column\ndef MCRMSE(y_true, y_pred):\n    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# GRU LAYER"},{"metadata":{"trusted":true},"cell_type":"code","source":"def gru_layer(hidden_dim, dropout):\n    return L.Bidirectional(L.GRU(\n        hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer='orthogonal'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(embed_size, seq_len=107, pred_len=68, dropout=0.5, \n                sp_dropout=0.2, embed_dim=200, hidden_dim=256, n_layers=3):\n    inputs = L.Input(shape=(seq_len, 3))\n    embed = L.Embedding(input_dim=embed_size, output_dim=embed_dim)(inputs)\n    \n    reshaped = tf.reshape(\n        embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3])\n    )\n    hidden = L.SpatialDropout1D(sp_dropout)(reshaped)\n    \n    for x in range(n_layers):\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n    \n    # Since we are only making predictions on the first part of each sequence, \n    # we have to truncate it\n    truncated = hidden[:, :pred_len]\n    out = L.Dense(5, activation='linear')(truncated)\n    \n    model = tf.keras.Model(inputs=inputs, outputs=out)\n    model.compile(tf.optimizers.Adam(), loss=MCRMSE)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(\n    train_inputs, train_labels, test_size=.1, random_state=34, stratify=train.SN_filter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"public_df = test.query(\"seq_length == 107\")\nprivate_df = test.query(\"seq_length == 130\")\n\npublic_inputs = preprocess_inputs(public_df, token2int)\nprivate_inputs = preprocess_inputs(private_df, token2int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model(embed_size=len(token2int))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(\n    x_train, y_train,\n    validation_data=(x_val, y_val),\n    batch_size=32,\n    epochs=50,\n    verbose=2,\n    callbacks=[\n        tf.keras.callbacks.ReduceLROnPlateau(patience=5),\n        tf.keras.callbacks.ModelCheckpoint('model.h5')\n    ]\n)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's check how our model is doing"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.line(\n    history.history, y=['loss', 'val_loss'],\n    labels={'index': 'epoch', 'value': 'MCRMSE'}, \n    title='Training History')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Caveat: The prediction format requires the output to be the same length as the input,\n# although it's not the case for the training data.\nmodel_public = build_model(seq_len=107, pred_len=107, embed_size=len(token2int))\nmodel_private = build_model(seq_len=130, pred_len=130, embed_size=len(token2int))\n\nmodel_public.load_weights('model.h5')\nmodel_private.load_weights('model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"public_preds = model_public.predict(public_inputs)\nprivate_preds = model_private.predict(private_inputs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Post-processing and submit\n\nFor each sample, we take the predicted tensors of shape (107, 5) or (130, 5), and convert them to the long format (i.e.  629√ó107,5  or  3005√ó130,5 ):"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_ls = []\n\nfor df, preds in [(public_df, public_preds), (private_df, private_preds)]:\n    for i, uid in enumerate(df.id):\n        single_pred = preds[i]\n\n        single_df = pd.DataFrame(single_pred, columns=pred_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n        preds_ls.append(single_df)\n\npreds_df = pd.concat(preds_ls)\npreds_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = sample_df[['id_seqpos']].merge(preds_df, on=['id_seqpos'])\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}