{"cells":[{"metadata":{},"cell_type":"markdown","source":"OpenVaccine: COVID-19 mRNA Vaccine Degradation Prediction"},{"metadata":{},"cell_type":"markdown","source":"Description"},{"metadata":{},"cell_type":"markdown","source":"Winning the fight against the COVID-19 pandemic will require an effective vaccine that can be equitably and widely distributed. Building upon decades of research has allowed scientists to accelerate the search for a vaccine against COVID-19, but every day that goes by without a vaccine has enormous costs for the world nonetheless. We need new, fresh ideas from all corners of the world. Could online gaming and crowdsourcing help solve a worldwide pandemic? Pairing scientific and crowdsourced intelligence could help computational biochemists make measurable progress.\n\nmRNA vaccines have taken the lead as the fastest vaccine candidates for COVID-19, but currently, they face key potential limitations. One of the biggest challenges right now is how to design super stable messenger RNA molecules (mRNA). Conventional vaccines (like your seasonal flu shots) are packaged in disposable syringes and shipped under refrigeration around the world, but that is not currently possible for mRNA vaccines.\n\nResearchers have observed that RNA molecules have the tendency to spontaneously degrade. This is a serious limitation--a single cut can render the mRNA vaccine useless. Currently, little is known on the details of where in the backbone of a given RNA is most prone to being affected. Without this knowledge, current mRNA vaccines against COVID-19 must be prepared and shipped under intense refrigeration, and are unlikely to reach more than a tiny fraction of human beings on the planet unless they can be stabilized.\n\nThe Eterna community, led by Professor Rhiju Das, a computational biochemist at Stanford’s School of Medicine, brings together scientists and gamers to solve puzzles and invent medicine. Eterna is an online video game platform that challenges players to solve scientific problems such as mRNA design through puzzles. The solutions are synthesized and experimentally tested at Stanford by researchers to gain new insights about RNA molecules. The Eterna community has previously unlocked new scientific principles, made new diagnostics against deadly diseases, and engaged the world’s most potent intellectual resources for the betterment of the public. The Eterna community has advanced biotechnology through its contribution in over 20 publications, including advances in RNA biotechnology.\n\nIn this competition, we are looking to leverage the data science expertise of the Kaggle community to develop models and design rules for RNA degradation. Your model will predict likely degradation rates at each base of an RNA molecule, trained on a subset of an Eterna dataset comprising over 3000 RNA molecules (which span a panoply of sequences and structures) and their degradation rates at each position. We will then score your models on a second generation of RNA sequences that have just been devised by Eterna players for COVID-19 mRNA vaccines. These final test sequences are currently being synthesized and experimentally characterized at Stanford University in parallel to your modeling efforts -- Nature will score your models!\n\nImproving the stability of mRNA vaccines was a problem that was being explored before the pandemic but was expected to take many years to solve. Now, we must solve this deep scientific challenge in months, if not weeks, to accelerate mRNA vaccine research and deliver a refrigerator-stable vaccine against SARS-CoV-2, the virus behind COVID-19. The problem we are trying to solve has eluded academic labs, industry R&D groups, and supercomputers, and so we are turning to you. To help, you can join the team of video game players, scientists, and developers at Eterna to unlock the key in our fight against this devastating pandemic."},{"metadata":{},"cell_type":"markdown","source":"Data Description"},{"metadata":{},"cell_type":"markdown","source":"In this competition, you will be predicting the degradation rates at various locations along RNA sequence.\n\nThere are multiple ground truth values provided in the training data. While the submission format requires all 5 to be predicted, only the following are scored: reactivity, deg_Mg_pH10, and deg_Mg_50C.\n\nFiles\ntrain.json - the training data\ntest.json - the test set, without any columns associated with the ground truth.\nsample_submission.csv - a sample submission file in the correct format\n\nColumns\n\nid - An arbitrary identifier for each sample.\n\nseq_scored - (68 in Train and Public Test, 91 in Private Test) Integer value denoting the number of positions used in scoring with predicted values. This should match the length of reactivity, deg_* and *_error_* columns. Note that molecules used for the Private Test will be longer than those in the Train and Public Test data, so the size of this vector will be different.\n\nseq_length - (107 in Train and Public Test, 130 in Private Test) Integer values, denotes the length of sequence. Note that molecules used for the Private Test will be longer than those in the Train and Public Test data, so the size of this vector will be different.\n\nsequence - (1x107 string in Train and Public Test, 130 in Private Test) Describes the RNA sequence, a combination of A, G, U, and C for each sample. Should be 107 characters long, and the first 68 bases should correspond to the 68 positions specified in seq_scored (note: indexed starting at 0).\n\nstructure - (1x107 string in Train and Public Test, 130 in Private Test) An array of (, ), and . characters that describe whether a base is estimated to be paired or unpaired. Paired bases are denoted by opening and closing parentheses e.g. (....) means that base 0 is paired to base 5, and bases 1-4 are unpaired.\n\nreactivity - (1x68 vector in Train and Public Test, 1x91 in Private Test) An array of floating point numbers, should have the same length as seq_scored. These numbers are reactivity values for the first 68 bases as denoted in sequence, and used to determine the likely secondary structure of the RNA sample.\n\ndeg_pH10 - (1x68 vector in Train and Public Test, 1x91 in Private Test) An array of floating point numbers, should have the same length as seq_scored. These numbers are reactivity values for the first 68 bases as denoted in sequence, and used to determine the likelihood of degradation at the base/linkage after incubating without magnesium at high pH (pH 10).\n\ndeg_Mg_pH10 - (1x68 vector in Train and Public Test, 1x91 in Private Test) An array of floating point numbers, should have the same length as seq_scored. These numbers are reactivity values for the first 68 bases as denoted in sequence, and used to determine the likelihood of degradation at the base/linkage after incubating with magnesium in high pH (pH 10).\n\ndeg_50C - (1x68 vector in Train and Public Test, 1x91 in Private Test) An array of floating point numbers, should have the same length as seq_scored. These numbers are reactivity values for the first 68 bases as denoted in sequence, and used to determine the likelihood of degradation at the base/linkage after incubating without magnesium at high temperature (50 degrees Celsius).\n\ndeg_Mg_50C - (1x68 vector in Train and Public Test, 1x91 in Private Test) An array of floating point numbers, should have the same length as seq_scored. These numbers are reactivity values for the first 68 bases as denoted in sequence, and used to determine the likelihood of degradation at the base/linkage after incubating with magnesium at high temperature (50 degrees Celsius).\n\n*_error_* - An array of floating point numbers, should have the same length as the corresponding reactivity or deg_* columns, calculated errors in experimental values obtained in reactivity and deg_* columns.\n\npredicted_loop_type - (1x107 string) Describes the structural context (also referred to as 'loop type')of each character in \n\nsequence. Loop types assigned by bpRNA from Vienna RNAfold 2 structure. From the bpRNA_documentation: S: paired \"Stem\" M: Multiloop \n\nI: Internal loop B: Bulge H: Hairpin loop E: dangling End X: eXternal loop\n\nAdditional Notes\nAt the beginning of the competition, Stanford scientists have data on 3029 RNA sequences of length 107. For technical reasons, measurements cannot be carried out on the final bases of these RNA sequences, so we have experimental data (ground truth) in 5 conditions for the first 68 bases.\n\nWe have split out 629 of these 3029 sequences for a public test set to allow for continuous evaluation through the competition, on the public leaderboard. These sequences, in test.json, have been additionally filtered based on three criteria detailed below to ensure that this subset is not dominated by any large cluster of RNA molecules with poor data, which might bias the public leaderboard. The remaining 2400 sequences for which we have data are in train.json.\n\nFor our final and most important scoring (the Private Leaderbooard), Stanford scientists are carrying out measurements on 3005 new RNAs, which have somewhat longer lengths of 130 bases. For these data, we expect to have measurements for the first 91 bases, again missing the ends of the RNA. These sequences constitute another 3005 of the 3634 sequences in test.json.\n\nFor those interested in how the 629 107-base sequences in test.json were filtered, here were the steps to ensure a diverse and high quality test set for public leaderboard scoring:\n\nMinimum value across all 5 conditions must be greater than -0.5.\n\nMean signal/noise across all 5 conditions must be greater than 1.0. [Signal/noise is defined as mean( measurement value over 68 nts )/mean( statistical error in measurement value over 68 nts)]\n\nTo help ensure sequence diversity, the resulting sequences were clustered into clusters with less than 50% sequence similarity, and the 629 test set sequences were chosen from clusters with 3 or fewer members. That is, any sequence in the test set should be sequence similar to at most 2 other sequences.\nNote that these filters have not been applied to the 2400 RNAs in the public training data train.json — some of those measurements have negative values or poor signal-to-noise, or some RNA sequences have near-identical sequences in that set. But we are providing all those data in case competitors can squeeze out more signal.\n\nThe three filters noted above will also not be applied to Private Test on 3005 sequences."},{"metadata":{},"cell_type":"markdown","source":"Notebooks used for reference (Thank you to the creators of these wonderful notebooks!)\n\nhttps://www.kaggle.com/tuckerarrants/openvaccine-gru-lstm <br>\nhttps://www.kaggle.com/isaienkov/openvaccine-eda-feature-engineering-modeling <br>\nhttps://www.kaggle.com/mrkmakr/covid-ae-pretrain-gnn-attn-cnn"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import json\nimport tensorflow as tf\nfrom matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir('/kaggle/')\nos.getcwd()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Load Input Files**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_json('/kaggle/input/stanford-covid-vaccine/train.json', lines = True)\ntest_data = pd.read_json('/kaggle/input/stanford-covid-vaccine/test.json', lines = True)\nsubmission_format = pd.read_csv('/kaggle/input/stanford-covid-vaccine/sample_submission.csv', encoding = 'utf-8-sig')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**EDA**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.groupby(['SN_filter']).size()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_format.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data.shape)\nprint(test_data.shape)\nprint(submission_format.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training data:\\n',train_data['seq_scored'].value_counts())\nprint('Test data:\\n',test_data['seq_scored'].value_counts())\nlen(train_data['reactivity'].iloc[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_data['sequence'].iloc[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking if error is negative in any cell\nflag = False\nfor i in range(0,len(train_data)):\n    if(([x<0 for x in train_data['reactivity_error'].iloc[i]].count(True) > 0) |\n       ([x<0 for x in train_data['deg_error_Mg_pH10'].iloc[i]].count(True) > 0) |\n       ([x<0 for x in train_data['deg_error_pH10'].iloc[i]].count(True) > 0) |\n       ([x<0 for x in train_data['deg_error_Mg_50C'].iloc[i]].count(True) > 0) |\n       ([x<0 for x in train_data['deg_error_50C'].iloc[i]].count(True) > 0)):\n        flag = True\nprint(flag)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Checking if result is negative in any cell\nmin_reactivity_value = min(train_data['reactivity'].iloc[0])\nmin_deg_Mg_pH10_value = min(train_data['deg_Mg_pH10'].iloc[0])\nmin_deg_pH10_value = min(train_data['deg_pH10'].iloc[0])\nmin_deg_Mg_50C_value = min(train_data['deg_Mg_50C'].iloc[0])\nmin_deg_Mg_50C_value = min(train_data['deg_50C'].iloc[0])\n\nfor i in range(0,len(train_data)):\n    if(min(train_data['reactivity'].iloc[i]) < min_reactivity_value):\n        min_reactivity_value = min(train_data['reactivity'].iloc[i])   \n\n    if(min(train_data['deg_Mg_pH10'].iloc[i]) < min_deg_Mg_pH10_value):\n        min_deg_Mg_pH10_value = min(train_data['deg_Mg_pH10'].iloc[i])\n\n    if(min(train_data['deg_pH10'].iloc[i]) < min_deg_pH10_value):\n        min_deg_pH10_value = min(train_data['deg_pH10'].iloc[i])\n\n    if(min(train_data['deg_Mg_50C'].iloc[i]) < min_deg_Mg_50C_value):\n        min_deg_Mg_50C_value = min(train_data['deg_Mg_50C'].iloc[i])\n\n    if(min(train_data['deg_50C'].iloc[i]) < min_deg_Mg_50C_value):\n        min_deg_Mg_50C_value = min(train_data['deg_50C'].iloc[i])\n        \nprint(min_reactivity_value, min_deg_Mg_pH10_value, min_deg_pH10_value, min_deg_Mg_50C_value, min_deg_Mg_50C_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # subtracting errors from target cols\n# for i in range(0,len(train_data)):\n#     num_time_steps = len(train_data['reactivity'].iloc[i])\n#     for j in range(num_time_steps):\n#         train_data['reactivity'][i][j] =  train_data['reactivity'][i][j] - train_data['reactivity_error'][i][j]\n#         train_data['deg_Mg_pH10'][i][j] =  train_data['deg_Mg_pH10'][i][j] - train_data['deg_error_Mg_pH10'][i][j]\n#         train_data['deg_pH10'][i][j] =  train_data['deg_pH10'][i][j] - train_data['deg_error_pH10'][i][j]\n#         train_data['deg_Mg_50C'][i][j] =  train_data['deg_Mg_50C'][i][j] - train_data['deg_error_Mg_50C'][i][j]\n#         train_data['deg_50C'][i][j] =  train_data['deg_50C'][i][j] - train_data['deg_error_50C'][i][j]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Build Model**"},{"metadata":{},"cell_type":"markdown","source":"#### Train data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For embedding layer\ntoken2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\ntarget_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"token2int","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notebooks used for reference: \nhttps://www.kaggle.com/tuckerarrants/openvaccine-gru-lstm\nhttps://www.kaggle.com/isaienkov/openvaccine-eda-feature-engineering-modeling\nhttps://www.kaggle.com/mrkmakr/covid-ae-pretrain-gnn-attn-cnn"},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_bpps_sum(df):\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps_arr.append(np.load(f\"../input/stanford-covid-vaccine/bpps/{mol_id}.npy\").sum(axis=1))\n    return bpps_arr\n\ndef read_bpps_max(df):\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps_arr.append(np.load(f\"../input/stanford-covid-vaccine/bpps/{mol_id}.npy\").max(axis=1))\n    return bpps_arr\n\ndef read_bpps_nb(df):\n    #mean and std from https://www.kaggle.com/symyksr/openvaccine-deepergcn \n    bpps_nb_mean = 0.077522\n    bpps_nb_std = 0.08914\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps = np.load(f\"../input/stanford-covid-vaccine/bpps/{mol_id}.npy\")\n        bpps_nb = (bpps > 0).sum(axis=0) / bpps.shape[0]\n        bpps_nb = (bpps_nb - bpps_nb_mean) / bpps_nb_std\n        bpps_arr.append(bpps_nb)\n    return bpps_arr \n\nos.chdir(\"/kaggle/working/\")\ntrain_data['bpps_sum'] = read_bpps_sum(train_data)\ntest_data['bpps_sum'] = read_bpps_sum(test_data)\ntrain_data['bpps_max'] = read_bpps_max(train_data)\ntest_data['bpps_max'] = read_bpps_max(test_data)\ntrain_data['bpps_nb'] = read_bpps_nb(train_data)\ntest_data['bpps_nb'] = read_bpps_nb(test_data)\n\n#sanity check\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import plotly.express as px\nfrom collections import Counter as count\n\ndef get_bases(data):\n    bases = []\n\n    for j in range(len(data)):\n        counts = dict(count(data.iloc[j]['sequence']))\n        bases.append((\n            counts['A'] / 107,\n            counts['G'] / 107,\n            counts['C'] / 107,\n            counts['U'] / 107\n        ))\n\n    bases = pd.DataFrame(bases, columns=['A_percent', 'G_percent', 'C_percent', 'U_percent'])\n    return bases","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_pairs_rate(data):\n    pairs_rate = []\n\n    for j in range(len(data)):\n        res = dict(count(data.iloc[j]['structure']))\n        pairs_rate.append(res['('] / 53.5)\n\n    pairs_rate = pd.DataFrame(pairs_rate, columns=['pairs_rate'])\n    return pairs_rate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_pairs(data):\n    pairs = []\n    all_partners = []\n    for j in range(len(data)):\n        partners = [-1 for i in range(130)]\n        pairs_dict = {}\n        queue = []\n        for i in range(0, len(data.iloc[j]['structure'])):\n            if data.iloc[j]['structure'][i] == '(':\n                queue.append(i)\n            if data.iloc[j]['structure'][i] == ')':\n                first = queue.pop()\n                try:\n                    pairs_dict[(data.iloc[j]['sequence'][first], data.iloc[j]['sequence'][i])] += 1\n                except:\n                    pairs_dict[(data.iloc[j]['sequence'][first], data.iloc[j]['sequence'][i])] = 1\n\n                partners[first] = i\n                partners[i] = first\n\n        all_partners.append(partners)\n\n        pairs_num = 0\n        pairs_unique = [('U', 'G'), ('C', 'G'), ('U', 'A'), ('G', 'C'), ('A', 'U'), ('G', 'U')]\n        for item in pairs_dict:\n            pairs_num += pairs_dict[item]\n        add_tuple = list()\n        for item in pairs_unique:\n            try:\n                add_tuple.append(pairs_dict[item]/pairs_num)\n            except:\n                add_tuple.append(0)\n        pairs.append(add_tuple)\n\n    pairs = pd.DataFrame(pairs, columns=['U-G', 'C-G', 'U-A', 'G-C', 'A-U', 'G-U'])\n    return pairs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_loops(data):\n    loops = []\n    for j in range(len(data)):\n        counts = dict(count(data.iloc[j]['predicted_loop_type']))\n        available = ['E', 'S', 'H', 'B', 'X', 'I', 'M']\n        row = []\n        for item in available:\n            try:\n                row.append(counts[item] / 107)\n            except:\n                row.append(0)\n        loops.append(row)\n\n    loops = pd.DataFrame(loops, columns=available)\n    return loops","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm.notebook import tqdm\n\ndef get_structure_adj(train):\n    ## get adjacent matrix from structure sequence\n    \n    ## here I calculate adjacent matrix of each base pair, \n    ## but eventually ignore difference of base pair and integrate into one matrix\n    Ss = []\n    for i in tqdm(range(len(train))):\n        seq_length = train[\"seq_length\"].iloc[i]\n        structure = train[\"structure\"].iloc[i]\n        sequence = train[\"sequence\"].iloc[i]\n\n        cue = []\n        a_structures = {\n            (\"A\", \"U\") : np.zeros([seq_length, seq_length]),\n            (\"C\", \"G\") : np.zeros([seq_length, seq_length]),\n            (\"U\", \"G\") : np.zeros([seq_length, seq_length]),\n            (\"U\", \"A\") : np.zeros([seq_length, seq_length]),\n            (\"G\", \"C\") : np.zeros([seq_length, seq_length]),\n            (\"G\", \"U\") : np.zeros([seq_length, seq_length]),\n        }\n        a_structure = np.zeros([seq_length, seq_length])\n        for j in range(seq_length):\n            if structure[j] == \"(\":\n                cue.append(j)\n            elif structure[j] == \")\":\n                start = cue.pop()\n#                 a_structure[start, i] = 1\n#                 a_structure[i, start] = 1\n                a_structures[(sequence[start], sequence[j])][start, j] = 1\n                a_structures[(sequence[j], sequence[start])][j, start] = 1\n        \n        a_strc = np.stack([a for a in a_structures.values()], axis = 2)\n        a_strc = np.sum(a_strc, axis = 2, keepdims = True)\n        Ss.append(a_strc)\n    \n    Ss = np.array(Ss)\n    print(Ss.shape)\n    return Ss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"As = []\ndata = train_data[train_data['signal_to_noise'] > 1].copy()\nfor id in tqdm(data['id']):\n    a = np.load(f\"/kaggle/input/stanford-covid-vaccine/bpps/{id}.npy\")\n    As.append(a)\nAs = np.array(As)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_distance_matrix(As):\n    ## adjacent matrix based on distance on the sequence\n    ## D[i, j] = 1 / (abs(i - j) + 1) ** pow, pow = 1, 2, 4\n    \n    idx = np.arange(As.shape[1])\n    Ds = []\n    for i in range(len(idx)):\n        d = np.abs(idx[i] - idx)\n        Ds.append(d)\n\n    Ds = np.array(Ds) + 1\n    Ds = 1/Ds\n    Ds = Ds[None, :,:]\n    Ds = np.repeat(Ds, len(As), axis = 0)\n    \n    Dss = []\n    for i in [1, 2, 4]: \n        Dss.append(Ds ** i)\n    Ds = np.stack(Dss, axis = 3)\n    print(Ds.shape)\n    return Ds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type'], seq_length = 107, flag = 'train'):\n    base_fea = np.transpose(\n        np.array(\n            df[cols]\n            .applymap(lambda seq: [token2int[x] for x in seq])\n            .values\n            .tolist()\n        ),\n        (0, 2, 1)\n    )\n\n    bpps_sum_fea = np.array(df['bpps_sum'].to_list())[:,:,np.newaxis]\n    bpps_max_fea = np.array(df['bpps_max'].to_list())[:,:,np.newaxis]\n    bpps_nb_fea = np.array(df['bpps_nb'].to_list())[:,:,np.newaxis]\n\n    Ss = get_structure_adj(df)\n    Ss = Ss.sum(axis = 1)\n    \n    if flag == 'train':\n        Ds = get_distance_matrix(As)\n    elif flag == 'test_private':\n        Ds = get_distance_matrix(As_private)\n    elif flag == 'test_public':\n        Ds = get_distance_matrix(As_public)\n    Ds = Ds.sum(axis = 1)\n    \n    data = np.concatenate([base_fea,bpps_sum_fea,bpps_max_fea,bpps_nb_fea, Ss, Ds], 2)\n    \n    array_data = (np.reshape(([([list(df['A_percent'])[0]] * seq_length)]),(1,seq_length,1)))\n    for i in range(1,len(df)):\n        array_data_i = (np.reshape(([([list(df['A_percent'])[i]] * seq_length)]),(1,seq_length,1)))\n        array_data = np.concatenate([array_data,array_data_i], axis = 0)\n\n    data = np.concatenate([data, array_data], 2)\n\n    for col in ['G_percent','C_percent','U_percent','U-G','C-G','U-A','G-C','A-U','G-U',\n                'E','S','H','B','X','I','M','pairs_rate']:\n        array_data = (np.reshape(([([list(df[col])[0]] * seq_length)]),(1,seq_length,1)))\n        for i in range(1,len(df)):\n            arraydom_data_i = (np.reshape(([([list(df[col])[i]] * seq_length)]),(1,seq_length,1)))\n            array_data = np.concatenate([array_data,array_data_i], axis = 0)\n\n        data = np.concatenate([data, array_data], 2)\n\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bases = get_bases(train_data)\npairs = get_pairs(train_data)\nloops = get_loops(train_data)\npairs_rate = get_pairs_rate(train_data)\ntrain_data = pd.concat([train_data, bases, pairs, loops, pairs_rate], axis=1)\n\nbases = get_bases(test_data)\npairs = get_pairs(test_data)\nloops = get_loops(test_data)\npairs_rate = get_pairs_rate(test_data)\ntest_data = pd.concat([test_data, bases, pairs, loops, pairs_rate], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_inputs = preprocess_inputs(train_data.loc[train_data['signal_to_noise'] > 1], seq_length = 107, flag = 'train')\ntrain_labels = np.array(train_data.loc[train_data['signal_to_noise'] > 1][target_cols].values.tolist()).transpose((0, 2, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_inputs.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.losses import mean_squared_error\n\ndef root_mean_squared_error(y_true, y_pred):\n    return tf.sqrt(mean_squared_error(y_true, y_pred))\n\ndef MCRMSE(y_true, y_pred):\n    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)\n\ndef lstm_layer(hidden_dim, dropout):\n    return tf.keras.layers.Bidirectional(\n                                tf.keras.layers.LSTM(hidden_dim,\n                                dropout=dropout,\n                                return_sequences=True,\n                                kernel_initializer = 'orthogonal'))\n\ndef gru_layer(hidden_dim, dropout):\n    return tf.keras.layers.Bidirectional(\n                                tf.keras.layers.GRU(hidden_dim,\n                                dropout=dropout,\n                                return_sequences=True,\n                                kernel_initializer='orthogonal'))\n\ndef build_model(n_layers = 2, seq_len = 107, num_features = 28, embed_dim = 200, sp_dropout = 0.2, hidden_dim = 512, dropout = 0.5, pred_len = 68, gru_flag = False):\n    \n    inputs = tf.keras.layers.Input(shape=(seq_len, num_features))\n    categorical_feats = inputs[:, :, :3]\n    numerical_feats = inputs[:, :, 3:10]\n    overall_gene_feats = inputs[:, :, 10:]\n\n    embed = tf.keras.layers.Embedding(input_dim=len(token2int), output_dim=embed_dim)(categorical_feats)\n   \n    reshaped = tf.reshape(embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3]))\n    \n    reshaped_1 = tf.keras.layers.concatenate([reshaped, numerical_feats], axis=2)\n          \n    normalized_layer_1 = tf.keras.layers.BatchNormalization()(reshaped_1)\n    \n    spatial_dropout = tf.keras.layers.SpatialDropout1D(sp_dropout)(normalized_layer_1)\n  \n    if gru_flag:\n        for x in range(n_layers):\n            normalized_layer_1 = gru_layer(hidden_dim, dropout)(normalized_layer_1)\n        normalized_layer_2 = tf.keras.layers.BatchNormalization()(normalized_layer_1)\n    else:\n        for x in range(n_layers):\n            normalized_layer_1 = lstm_layer(hidden_dim, dropout)(normalized_layer_1)\n        normalized_layer_2 = tf.keras.layers.BatchNormalization()(normalized_layer_1)\n    \n    concat_layer = tf.keras.layers.concatenate([normalized_layer_2, overall_gene_feats], axis=2)\n    \n    dense_layer_1 = tf.keras.layers.Dense(100, activation = 'linear')(concat_layer)\n    normalized_layer_3 = tf.keras.layers.BatchNormalization()(dense_layer_1)\n    dropout_layer_1 = tf.keras.layers.SpatialDropout1D(sp_dropout)(normalized_layer_3)\n   \n    dense_layer_2 = tf.keras.layers.Dense(100, activation = 'linear')(dropout_layer_1)\n    normalized_layer_4 = tf.keras.layers.BatchNormalization()(dense_layer_2)\n    dropout_layer_2 = tf.keras.layers.SpatialDropout1D(sp_dropout)(normalized_layer_4)\n    \n    #only making predictions on the first part of each sequence\n    truncated = dropout_layer_2[:, :pred_len]\n\n    out = tf.keras.layers.Dense(5, activation='linear')(truncated)\n\n    model = tf.keras.Model(inputs=inputs, outputs=out)\n\n    #some optimizers\n    adam = tf.optimizers.Adam()\n\n    model.compile(optimizer = adam, loss = MCRMSE)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_inputs.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# EPOCHS = 60\n# BATCH_SIZE = 32\n\n# model_GRU_on_train_data = build_model(gru_flag = True)\n# model_GRU_on_train_data.summary()\n# model_GRU_callback = tf.keras.callbacks.ModelCheckpoint(f'GRU model.h5')\n\n# history_GRU = model_GRU_on_train_data.fit(train_inputs, train_labels,\n#                   batch_size=BATCH_SIZE,\n#                   epochs=EPOCHS,\n#                   verbose = 2,\n#                   callbacks=[model_GRU_callback])  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# EPOCHS = 60\n# BATCH_SIZE = 32\n\n# model_LSTM_on_train_data = build_model(gru_flag = False)\n# model_LSTM_on_train_data.summary()\n# model_LSTM_callback = tf.keras.callbacks.ModelCheckpoint(f'LSTM model.h5')\n\n# history_LSTM = model_LSTM_on_train_data.fit(train_inputs, train_labels,\n#                   batch_size=BATCH_SIZE,\n#                   epochs=EPOCHS,\n#                   verbose = 2,\n#                   callbacks=[model_LSTM_callback])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(f\" LSTM loss: {min(history_LSTM.history['loss'])}\")\n# print(f\" GRU loss: {min(history_GRU.history['loss'])}\")\n\n# fig, ax = plt.subplots(1, 1, figsize = (20, 10))\n\n# ax.plot(history_LSTM.history['loss'])\n# ax.plot(history_GRU.history['loss'])\n\n# ax.set_title('Model - LSTM vs GRU')\n\n# ax.set_ylabel('Loss')\n# ax.set_xlabel('Epoch')\n# ax.legend()\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"public_df = test_data.query(\"seq_length == 107\").copy()\nprivate_df = test_data.query(\"seq_length == 130\").copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"As_public = []\nfor id in tqdm(public_df[\"id\"]):\n    a = np.load(f\"/kaggle/input/stanford-covid-vaccine/bpps/{id}.npy\")\n    As_public.append(a)\nAs_public = np.array(As_public)\nAs_private = []\nfor id in tqdm(private_df[\"id\"]):\n    a = np.load(f\"/kaggle/input/stanford-covid-vaccine/bpps/{id}.npy\")\n    As_private.append(a)\nAs_private = np.array(As_private)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"public_inputs = preprocess_inputs(public_df, seq_length = 107, flag = 'test_public')\nprivate_inputs = preprocess_inputs(private_df, seq_length = 130, flag = 'test_private')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_LSTM_on_test_data_public = build_model(seq_len=107, pred_len=107, gru_flag = False)\nmodel_LSTM_on_test_data_public.load_weights('../input/openvaccine-covid-model-weights/LSTM model.h5')\npred_test_data_public_LSTM = model_LSTM_on_test_data_public.predict(public_inputs)\n\nmodel_GRU_on_test_data_public = build_model(seq_len=107, pred_len=107, gru_flag = True)\nmodel_GRU_on_test_data_public.load_weights('../input/openvaccine-covid-model-weights/GRU model (1).h5')\npred_test_data_public_GRU = model_GRU_on_test_data_public.predict(public_inputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_LSTM_on_test_data_private = build_model(seq_len=130, pred_len=130, gru_flag = False)\nmodel_LSTM_on_test_data_private.load_weights('../input/openvaccine-covid-model-weights/LSTM model.h5')\npred_test_data_private_LSTM = model_LSTM_on_test_data_private.predict(private_inputs)\n\nmodel_GRU_on_test_data_private = build_model(seq_len=130, pred_len=130, gru_flag = True)\nmodel_GRU_on_test_data_private.load_weights('../input/openvaccine-covid-model-weights/GRU model (1).h5')\npred_test_data_private_GRU = model_GRU_on_test_data_private.predict(private_inputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def format_predictions(public_preds, private_preds):\n    preds = []\n    \n    for df, preds_ in [(public_df, public_preds), (private_df, private_preds)]:\n        for i, uid in enumerate(df.id):\n            single_pred = preds_[i]\n\n            single_df = pd.DataFrame(single_pred, columns=target_cols)\n            single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n            preds.append(single_df)\n    return pd.concat(preds).reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm_preds = format_predictions(pred_test_data_public_LSTM, pred_test_data_private_LSTM)\ngru_preds = format_predictions(pred_test_data_public_GRU, pred_test_data_private_GRU)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lstm_preds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gru_preds.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_LSTM = submission_format[['id_seqpos']].merge(lstm_preds, how = 'inner', on = 'id_seqpos')\nsubmission_GRU = submission_format[['id_seqpos']].merge(gru_preds, how = 'inner', on = 'id_seqpos')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(submission_LSTM.shape)\nsubmission_LSTM.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(submission_GRU.shape)\nsubmission_GRU.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_lstm_gru_combined = submission_GRU.merge(submission_LSTM, how = 'inner', on = 'id_seqpos')\n\ngru_weight = 0.5\nlstm_weight = 0.5\nfor i in range(len(target_cols)):\n    submission_lstm_gru_combined[target_cols[i]] = submission_lstm_gru_combined[target_cols[i]+'_x']*gru_weight + submission_lstm_gru_combined[target_cols[i]+'_y']*lstm_weight","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_lstm_gru_combined = submission_lstm_gru_combined[['id_seqpos'] + target_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_lstm_gru_combined.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir(\"/kaggle/working/\")\nsubmission_LSTM.to_csv('submission_LSTM.csv', index = False)\nsubmission_GRU.to_csv('submission_GRU.csv', index = False)\nsubmission_lstm_gru_combined.to_csv('submission_lstm_gru_combined.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}