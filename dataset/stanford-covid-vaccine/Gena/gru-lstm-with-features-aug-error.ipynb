{"cells":[{"metadata":{"papermill":{"duration":0.018459,"end_time":"2020-09-21T09:16:41.239793","exception":false,"start_time":"2020-09-21T09:16:41.221334","status":"completed"},"tags":[]},"cell_type":"markdown","source":"This is a fork of https://www.kaggle.com/its7171/gru-lstm-with-feature-engineering-and-augmentation\n\n* Added error handling as a second head\n* Visualized clustered inputs using umap\n"},{"metadata":{},"cell_type":"markdown","source":"v2:\n\nadjust loss to take error into account (weighted RMSE, pay more attention to bases with good measurements and less on errorneous nucleobases)"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2020-09-21T09:16:41.283808Z","iopub.status.busy":"2020-09-21T09:16:41.282968Z","iopub.status.idle":"2020-09-21T09:16:49.375397Z","shell.execute_reply":"2020-09-21T09:16:49.37468Z"},"papermill":{"duration":8.118687,"end_time":"2020-09-21T09:16:49.375551","exception":false,"start_time":"2020-09-21T09:16:41.256864","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport json\nimport tensorflow.keras.layers as L\nimport keras.backend as K\nimport tensorflow as tf\nimport plotly.express as px\nfrom sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\nfrom sklearn.cluster import KMeans\nimport os\n\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\ndef allocate_gpu_memory(gpu_number=0):\n    physical_devices = tf.config.experimental.list_physical_devices('GPU')\n\n    if physical_devices:\n        try:\n            print(\"Found {} GPU(s)\".format(len(physical_devices)))\n            tf.config.set_visible_devices(physical_devices[gpu_number], 'GPU')\n            tf.config.experimental.set_memory_growth(physical_devices[gpu_number], True)\n            print(\"#{} GPU memory is allocated\".format(gpu_number))\n        except RuntimeError as e:\n            print(e)\n    else:\n        print(\"Not enough GPU hardware devices available\")\nallocate_gpu_memory()\n\nVer='GRU_LSTM1'\naug_data = '../input/augmented-data/aug_data1.csv'\ndebug = False","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-21T09:16:49.43636Z","iopub.status.busy":"2020-09-21T09:16:49.435576Z","iopub.status.idle":"2020-09-21T09:16:49.439099Z","shell.execute_reply":"2020-09-21T09:16:49.439656Z"},"papermill":{"duration":0.044,"end_time":"2020-09-21T09:16:49.439787","exception":false,"start_time":"2020-09-21T09:16:49.395787","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def gru_layer(hidden_dim, dropout):\n    return L.Bidirectional(L.GRU(hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer = 'orthogonal'))\n\ndef lstm_layer(hidden_dim, dropout):\n    return L.Bidirectional(L.LSTM(hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer = 'orthogonal'))\n\ndef build_model(seq_len=107, pred_len=68, dropout=0.5, embed_dim=100*2, hidden_dim=256*2, type=0):\n    inputs = L.Input(shape=(seq_len, 6))\n    \n    # split categorical and numerical features and concatenate them later.\n    categorical_feat_dim = 3\n    categorical_fea = inputs[:, :, :categorical_feat_dim]\n    numerical_fea = inputs[:, :, 3:]\n\n    embed = L.Embedding(input_dim=len(token2int), output_dim=embed_dim)(categorical_fea)\n    reshaped = tf.reshape(embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3]))\n    reshaped = L.concatenate([reshaped, numerical_fea], axis=2)\n    reshaped = L.LayerNormalization()(reshaped)\n    \n    if type == 0:\n        hidden = gru_layer(hidden_dim, dropout)(reshaped)\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n    elif type == 1:\n        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n    elif type == 2:\n        hidden = gru_layer(hidden_dim, dropout)(reshaped)\n        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n    elif type == 3:\n        hidden = lstm_layer(hidden_dim, dropout)(reshaped)\n        hidden = lstm_layer(hidden_dim, dropout)(hidden)\n    \n    truncated = hidden[:, :pred_len]\n    out = L.Dense(5, activation='linear', name='reactivity')(truncated)\n    out2 = L.Dense(5, activation='linear', name='error')(truncated)\n \n    model = tf.keras.Model(inputs=inputs, outputs=[out, out2])\n    losses = { \"reactivity\": mcrmse, \"error\": mcrmse }\n    loss_weights = {\"reactivity\": 0.95, \"error\": 0.05}\n    model.compile(tf.keras.optimizers.Adam(), loss=losses, loss_weights=loss_weights)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-21T09:16:49.489942Z","iopub.status.busy":"2020-09-21T09:16:49.488971Z","iopub.status.idle":"2020-09-21T09:16:49.492271Z","shell.execute_reply":"2020-09-21T09:16:49.492951Z"},"papermill":{"duration":0.035182,"end_time":"2020-09-21T09:16:49.493068","exception":false,"start_time":"2020-09-21T09:16:49.457886","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\n\npred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n\npred_cols_error = ['reactivity_error', 'deg_error_Mg_pH10', 'deg_error_pH10', 'deg_error_Mg_50C', 'deg_error_50C']\n\n\n# pred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C', \n#              'reactivity_error', 'deg_error_Mg_pH10', 'deg_error_pH10', 'deg_error_Mg_50C', 'deg_error_50C', ]\n\n\ndef preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type']):\n    base_fea = np.transpose(\n        np.array(\n            df[cols]\n            .applymap(lambda seq: [token2int[x] for x in seq])\n            .values\n            .tolist()\n        ),\n        (0, 2, 1)\n    )\n    bpps_sum_fea = np.array(df['bpps_sum'].to_list())[:,:,np.newaxis]\n    bpps_max_fea = np.array(df['bpps_max'].to_list())[:,:,np.newaxis]\n    bpps_nb_fea = np.array(df['bpps_nb'].to_list())[:,:,np.newaxis]\n    return np.concatenate([base_fea,bpps_sum_fea,bpps_max_fea,bpps_nb_fea], 2)\n\ndef rmse(y_actual, y_pred):\n    mse = tf.keras.losses.mean_squared_error(y_actual, y_pred)\n    return K.sqrt(mse)\n\ndef mcrmse(y_actual, y_pred, num_scored=len(pred_cols)):\n    score = 0\n    for i in range(num_scored):\n        score += rmse(y_actual[:, :, i], y_pred[:, :, i]) / num_scored\n    return score","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.017475,"end_time":"2020-09-21T09:16:49.527343","exception":false,"start_time":"2020-09-21T09:16:49.509868","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## Load and preprocess data"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-21T09:16:49.566559Z","iopub.status.busy":"2020-09-21T09:16:49.565762Z","iopub.status.idle":"2020-09-21T09:16:50.291832Z","shell.execute_reply":"2020-09-21T09:16:50.290255Z"},"lines_to_next_cell":2,"papermill":{"duration":0.747182,"end_time":"2020-09-21T09:16:50.291948","exception":false,"start_time":"2020-09-21T09:16:49.544766","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"train = pd.read_json('../input/stanford-covid-vaccine/train.json', lines=True)\ntest = pd.read_json('../input/stanford-covid-vaccine/test.json', lines=True)\n\n# CV 0.23516108889948803 0.05579603840874723 \n# LV -0.00028\n# RANDOM_SEED=46\n# RANDOM_SEED_KMEANS=110\n# KMEANS_CLUSTERS=200\n\nRANDOM_SEED=46\nRANDOM_SEED_KMEANS=110\nKMEANS_CLUSTERS=100\n\ntrain = train[train.signal_to_noise > 0.05]\n\ntrain = train.sample(random_state=RANDOM_SEED, frac=1)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-21T09:16:50.34417Z","iopub.status.busy":"2020-09-21T09:16:50.334188Z","iopub.status.idle":"2020-09-21T09:17:11.178477Z","shell.execute_reply":"2020-09-21T09:17:11.179708Z"},"papermill":{"duration":20.870377,"end_time":"2020-09-21T09:17:11.17996","exception":false,"start_time":"2020-09-21T09:16:50.309583","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# additional features\n\ndef read_bpps_sum(df):\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps_arr.append(np.load(f\"../input/stanford-covid-vaccine/bpps/{mol_id}.npy\").max(axis=1))\n    return bpps_arr\n\ndef read_bpps_max(df):\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps_arr.append(np.load(f\"../input/stanford-covid-vaccine/bpps/{mol_id}.npy\").sum(axis=1))\n    return bpps_arr\n\ndef read_bpps_nb(df):\n    # normalized non-zero number\n    # from https://www.kaggle.com/symyksr/openvaccine-deepergcn \n    bpps_nb_mean = 0.077522 # mean of bpps_nb across all training data\n    bpps_nb_std = 0.08914   # std of bpps_nb across all training data\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps = np.load(f\"../input/stanford-covid-vaccine/bpps/{mol_id}.npy\")\n        bpps_nb = (bpps > 0).sum(axis=0) / bpps.shape[0]\n        bpps_nb = (bpps_nb - bpps_nb_mean) / bpps_nb_std\n        bpps_arr.append(bpps_nb)\n    return bpps_arr \n\ntrain['bpps_sum'] = read_bpps_sum(train)\ntest['bpps_sum'] = read_bpps_sum(test)\ntrain['bpps_max'] = read_bpps_max(train)\ntest['bpps_max'] = read_bpps_max(test)\ntrain['bpps_nb'] = read_bpps_nb(train)\ntest['bpps_nb'] = read_bpps_nb(test)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-21T09:17:11.242395Z","iopub.status.busy":"2020-09-21T09:17:11.241357Z","iopub.status.idle":"2020-09-21T09:17:14.830513Z","shell.execute_reply":"2020-09-21T09:17:14.831555Z"},"papermill":{"duration":3.626176,"end_time":"2020-09-21T09:17:14.831719","exception":false,"start_time":"2020-09-21T09:17:11.205543","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# clustering for GroupKFold\n# expecting more accurate CV by putting similar RNAs into the same fold.\nkmeans_model = KMeans(n_clusters=KMEANS_CLUSTERS, random_state=RANDOM_SEED_KMEANS).fit(preprocess_inputs(train)[:,:,0])\ntrain['cluster_id'] = kmeans_model.labels_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -q umap-learn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import umap\nmapper = umap.UMAP().fit(preprocess_inputs(train)[:,:,0])\nembedding = mapper.transform(preprocess_inputs(train)[:,:,0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(15, 15))\nplt.scatter(embedding[:, 0], embedding[:, 1], c=train['cluster_id'].values, cmap='Spectral', s=5, alpha=1)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.020176,"end_time":"2020-09-21T09:17:14.872725","exception":false,"start_time":"2020-09-21T09:17:14.852549","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## Data augmentation for training and TTA(test)"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-21T09:17:14.936809Z","iopub.status.busy":"2020-09-21T09:17:14.935969Z","iopub.status.idle":"2020-09-21T09:17:15.021897Z","shell.execute_reply":"2020-09-21T09:17:15.023027Z"},"papermill":{"duration":0.120191,"end_time":"2020-09-21T09:17:15.023193","exception":false,"start_time":"2020-09-21T09:17:14.903002","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"aug_df = pd.read_csv(aug_data)\ndisplay(aug_df.head())","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.021646,"end_time":"2020-09-21T09:17:15.064557","exception":false,"start_time":"2020-09-21T09:17:15.042911","status":"completed"},"tags":[]},"cell_type":"markdown","source":"This file was created using ARNIE, ViennaRNA and bpRNA in the following way.\n\nGet candidate structures with different gamma values. \nSee last cell of [How to Use ARNIE on Kaggle Notebook](https://www.kaggle.com/its7171/how-to-use-arnie-on-kaggle-notebook).\n\nRemove the same as the original structure.\n\nGet a structure with the largest score for each sequence.\n\nGet the predicted_loop_type from the sequence and structure.\nSee [How to Generate predicted_loop_type](https://www.kaggle.com/its7171/how-to-generate-predicted-loop-type)."},{"metadata":{"execution":{"iopub.execute_input":"2020-09-21T09:17:15.118744Z","iopub.status.busy":"2020-09-21T09:17:15.117995Z","iopub.status.idle":"2020-09-21T09:17:15.189668Z","shell.execute_reply":"2020-09-21T09:17:15.189122Z"},"papermill":{"duration":0.098946,"end_time":"2020-09-21T09:17:15.189781","exception":false,"start_time":"2020-09-21T09:17:15.090835","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def add_aug_data(df):\n    target_df = df.copy()\n    new_df = aug_df[aug_df['id'].isin(target_df['id'])]\n                         \n    del target_df['structure']\n    del target_df['predicted_loop_type']\n    new_df = new_df.merge(target_df, on=['id','sequence'], how='left')\n\n    df['cnt'] = df['id'].map(new_df[['id','cnt']].set_index('id').to_dict()['cnt'])\n    df['log_gamma'] = 100\n    df['score'] = 1.0\n    df = df.append(new_df[df.columns])\n    return df\n\n# maybe remove (low probability configurations, but the actual reactivity is unknown / not measured) \n# improves LB score by 0.0042 when used\ntrain = add_aug_data(train)\ntest = add_aug_data(test)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-21T09:17:15.230204Z","iopub.status.busy":"2020-09-21T09:17:15.229625Z","iopub.status.idle":"2020-09-21T09:17:15.233748Z","shell.execute_reply":"2020-09-21T09:17:15.23311Z"},"papermill":{"duration":0.025949,"end_time":"2020-09-21T09:17:15.233875","exception":false,"start_time":"2020-09-21T09:17:15.207926","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"if debug:\n    train = train[:200]\n    test = test[:200]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Callbacks (Plot, CSV)\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom IPython.display import clear_output        \nimport seaborn as sns\nimport pathlib\n\nclass TrainingPlot(tf.keras.callbacks.Callback):\n    def __init__(self, nrows=1, ncols=2, figsize=(10, 5), title=None, save_file=None, old_logs_path=None):\n        self.nrows=nrows\n        self.ncols=ncols\n        self.figsize=figsize\n        self.title=title\n        self.old_logs_path=old_logs_path\n        self.old_logs = []\n        self.old_log_file_names = []\n\n        if self.old_logs_path is not None:\n            p = pathlib.Path(self.old_logs_path)\n            self.old_logs_files = p.parent.glob(p.name)\n\n            for f in self.old_logs_files:\n                try:\n                    self.old_logs.append(pd.read_csv(f))\n                    self.old_log_file_names.append(pathlib.Path(f).stem)\n                except:\n                    continue\n\n        if save_file:\n            self.save_file = save_file\n        \n        self.metrics = []\n        self.logs = []\n        \n    def add(self, row, col, name, color=None, vmin=None, vmax=None, show_min=False, show_max=False):\n        self.metrics.append({'row': row, 'col': col, 'name': name, 'color': color, 'vmin': vmin, 'vmax': vmax, 'show_min': show_min, 'show_max': show_max})\n    \n    def on_train_begin(self, logs={}):\n        self.logs = []\n        \n        for m in self.metrics:\n            m['values'] = []\n\n    def on_epoch_end(self, epoch, logs={}):\n        self.logs.append(logs)\n        \n        clear_output(wait=True)\n        plt.style.use(\"seaborn\")\n        # sns.set_style(\"whitegrid\")\n        fig, ax = plt.subplots(self.nrows, self.ncols, figsize=self.figsize)\n\n        if len(ax.shape) == 1:\n            ax = np.expand_dims(ax, axis=0)\n        \n        if self.title:\n            fig.suptitle(self.title)\n        \n        for m in self.metrics:\n            if logs.get(m['name']) is None:\n                v = m['values']\n                v.append(np.nan)\n                continue\n            \n            a = ax[m['row'], m['col']]\n            \n            if m['name'] == 'off':\n                a.axis('off')\n                continue\n\n            v = m['values']\n            v.append(logs.get(m['name']))\n                                \n            # old logs\n            for i, old_log in enumerate(self.old_logs):\n                if m['name'] not in old_log:\n                    continue\n                old_values = old_log[m['name']].values\n                a.plot(np.arange(len(old_values)), old_values, \n                     '-', \n                     color=m['color'], \n                    #  label=self.old_log_file_names[i], # gets crowded\n                     alpha=0.2, lw=1)\n\n            # new log\n            a.plot(np.arange(len(v)), v, '-o', color=m['color'], label=m['name'], lw=1, markersize=3)\n            a.set_xlabel('Epoch #', size=14)\n            \n            yname = m['name']\n            if yname.startswith('val_'):\n                yname = m['name'][4:]\n            a.set_ylabel(yname, size=14)\n\n            xdist = a.get_xlim()[1] - a.get_xlim()[0]\n            ydist = a.get_ylim()[1] - a.get_ylim()[0]\n            \n            if ydist is not None and xdist is not None:\n                if m['show_max']:\n                    x = np.argmax(v)\n                    y = np.max(v)\n                    a.scatter(x, y, s=200, color=m['color'], alpha=0.5)\n                    a.text(x-0.03*xdist, y-0.13*ydist, f'{round(y, 4)}', size=14)\n                if m['show_min']:\n                    x = np.argmin(v)\n                    y = np.min(v)\n                    a.scatter(x, y, s=200, color=m['color'], alpha=0.5)\n                    a.text(x-0.03*xdist, y+0.05*ydist, f'{round(y, 4)}', size=14)\n\n            if m['vmin'] is not None:\n                a.set_ylim(m['vmin'], m['vmax'])\n\n            a.legend()\n\n        plt.show()\n\n        if self.save_file:\n            fig.savefig(self.save_file)\n\ndef create_plot(label, csv_file_mask='*.csv'):\n    plot = TrainingPlot(nrows=1, ncols=2, figsize=(20, 5), title=label, \n                      save_file=f'{label}.png', \n                      old_logs_path=csv_file_mask\n            )\n\n    plot.add(0, 0, 'loss', 'green')\n    plot.add(0, 0, 'val_loss', 'red', show_min=True)\n    plot.add(0, 1, 'lr', 'black', vmin=0)\n    \n    return plot\n\ndef cvs_callback(filename):\n    return tf.keras.callbacks.CSVLogger(filename)\n\n# lr_callback = tf.keras.callbacks.ReduceLROnPlateau(factor=0.75, patience=3, min_lr=0.000001)\n","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.017944,"end_time":"2020-09-21T09:17:15.270492","exception":false,"start_time":"2020-09-21T09:17:15.252548","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## Build and train model"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-21T09:17:15.31024Z","iopub.status.busy":"2020-09-21T09:17:15.309666Z","iopub.status.idle":"2020-09-21T09:17:18.4114Z","shell.execute_reply":"2020-09-21T09:17:18.410696Z"},"papermill":{"duration":3.123525,"end_time":"2020-09-21T09:17:18.411597","exception":false,"start_time":"2020-09-21T09:17:15.288072","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"model = build_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-21T09:17:18.473586Z","iopub.status.busy":"2020-09-21T09:17:18.472319Z","iopub.status.idle":"2020-09-21T09:17:18.475796Z","shell.execute_reply":"2020-09-21T09:17:18.47518Z"},"incorrectly_encoded_metadata":"_kg_hide-output=true","papermill":{"duration":0.043776,"end_time":"2020-09-21T09:17:18.475902","exception":false,"start_time":"2020-09-21T09:17:18.432126","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"cell_type":"code","source":"def train_and_predict(type = 0, FOLD_N = 5):\n    \n    gkf = GroupKFold(n_splits=FOLD_N)\n\n    public_df = test.query(\"seq_length == 107\").copy()\n    private_df = test.query(\"seq_length == 130\").copy()\n\n    public_inputs = preprocess_inputs(public_df)\n    private_inputs = preprocess_inputs(private_df)\n\n\n    holdouts = []\n    holdout_preds = []\n\n    for cv, (tr_idx, vl_idx) in enumerate(gkf.split(train,  train['reactivity'], train['cluster_id'])):\n        trn = train.iloc[tr_idx]\n        x_trn = preprocess_inputs(trn)\n        y_trn = np.array(trn[pred_cols].values.tolist()).transpose((0, 2, 1))\n        \n        y_trn_err = np.log(np.array(trn[pred_cols_error].values.tolist()).transpose((0, 2, 1)))\n        \n        w_trn = np.log(trn.signal_to_noise+1.1)/2\n\n        val = train.iloc[vl_idx]\n        x_val_all = preprocess_inputs(val)\n        val = val[val.SN_filter == 1]\n        x_val = preprocess_inputs(val)\n        y_val = np.array(val[pred_cols].values.tolist()).transpose((0, 2, 1))\n        \n        y_val_err = np.log(np.array(val[pred_cols_error].values.tolist()).transpose((0, 2, 1)))\n\n        model = build_model(type=type)\n        model_short = build_model(seq_len=107, pred_len=107,type=type)\n        model_long = build_model(seq_len=130, pred_len=130,type=type)\n\n        history = model.fit(\n            x_trn, {\"reactivity\": y_trn, \"error\": y_trn_err},\n            validation_data = (x_val, {\"reactivity\": y_val, \"error\": y_val_err}),\n            batch_size=32,\n            epochs=90,\n            \n            sample_weight=w_trn,\n            callbacks=[\n                tf.keras.callbacks.ReduceLROnPlateau(),\n                tf.keras.callbacks.ModelCheckpoint(f'model-t{type}-v{Ver}-f{cv}.h5'),\n                create_plot(f'train-{cv}', csv_file_mask='train-*.csv'),\n                cvs_callback(f'train-{cv}.csv')\n            ]\n        )\n\n#         fig = px.line(\n#             history.history, y=['loss', 'val_loss'], \n#             labels={'index': 'epoch', 'value': 'Mean Squared Error'}, \n#             title='Training History')\n#         fig.show()\n\n        model.load_weights(f'model-t{type}-v{Ver}-f{cv}.h5')\n        model_short.load_weights(f'model-t{type}-v{Ver}-f{cv}.h5')\n        model_long.load_weights(f'model-t{type}-v{Ver}-f{cv}.h5')\n\n        holdouts.append(train.iloc[vl_idx])\n        holdout_preds.append(model.predict(x_val_all)[0])\n        if cv == 0:\n            public_preds = model_short.predict(public_inputs)[0]/FOLD_N\n            private_preds = model_long.predict(private_inputs)[0]/FOLD_N\n        else:\n            public_preds += model_short.predict(public_inputs)[0]/FOLD_N\n            private_preds += model_long.predict(private_inputs)[0]/FOLD_N\n    return holdouts, holdout_preds, public_df, public_preds, private_df, private_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm *.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_df, val_preds, test_df, test_preds = [], [], [], []\nif debug:\n    nmodel = 1\nelse:\n    nmodel = 4\nfor i in range(nmodel):\n    holdouts, holdout_preds, public_df, public_preds, private_df, private_preds = train_and_predict(i)\n    val_df += holdouts\n    val_preds += holdout_preds\n    test_df.append(public_df)\n    test_df.append(private_df)\n    test_preds.append(public_preds)\n    test_preds.append(private_preds)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":12.712813,"end_time":"2020-09-21T09:56:00.094415","exception":false,"start_time":"2020-09-21T09:55:47.381602","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## post process"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-21T09:56:26.121627Z","iopub.status.busy":"2020-09-21T09:56:26.08081Z","iopub.status.idle":"2020-09-21T09:57:04.897064Z","shell.execute_reply":"2020-09-21T09:57:04.897651Z"},"papermill":{"duration":51.76575,"end_time":"2020-09-21T09:57:04.897814","exception":false,"start_time":"2020-09-21T09:56:13.132064","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"preds_ls = []\nfor df, preds in zip(test_df, test_preds):\n    for i, uid in enumerate(df.id):\n        single_pred = preds[i]\n        single_df = pd.DataFrame(single_pred, columns=pred_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n        preds_ls.append(single_df)\npreds_df = pd.concat(preds_ls).groupby('id_seqpos').mean().reset_index()\n# .mean() is for\n# 1, Predictions from multiple models\n# 2, TTA (augmented test data)\n\npreds_ls = []\nfor df, preds in zip(val_df, val_preds):\n    for i, uid in enumerate(df.id):\n        single_pred = preds[i]\n        single_df = pd.DataFrame(single_pred, columns=pred_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n        single_df['SN_filter'] = df[df['id'] == uid].SN_filter.values[0]\n        preds_ls.append(single_df)\nholdouts_df = pd.concat(preds_ls).groupby('id_seqpos').mean().reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"holdouts_df.to_csv(f'holdouts.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-21T09:57:30.84898Z","iopub.status.busy":"2020-09-21T09:57:30.848097Z","iopub.status.idle":"2020-09-21T09:57:35.396342Z","shell.execute_reply":"2020-09-21T09:57:35.397025Z"},"papermill":{"duration":17.293127,"end_time":"2020-09-21T09:57:35.397197","exception":false,"start_time":"2020-09-21T09:57:18.10407","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"submission = preds_df[['id_seqpos', 'reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']]\nsubmission.to_csv(f'submission.csv', index=False)\nprint(f'wrote to submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":12.384864,"end_time":"2020-09-21T09:58:00.228947","exception":false,"start_time":"2020-09-21T09:57:47.844083","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## Validation"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-21T09:58:26.104504Z","iopub.status.busy":"2020-09-21T09:58:26.103111Z","iopub.status.idle":"2020-09-21T09:58:26.105315Z","shell.execute_reply":"2020-09-21T09:58:26.106353Z"},"papermill":{"duration":12.82694,"end_time":"2020-09-21T09:58:26.106501","exception":false,"start_time":"2020-09-21T09:58:13.279561","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def print_mse(prd):\n    val = pd.read_json('../input/stanford-covid-vaccine/train.json', lines=True)\n\n    val_data = []\n    for mol_id in val['id'].unique():\n        sample_data = val.loc[val['id'] == mol_id]\n        sample_seq_length = sample_data.seq_length.values[0]\n        for i in range(68):\n            sample_dict = {\n                           'id_seqpos' : sample_data['id'].values[0] + '_' + str(i),\n                           'reactivity_gt' : sample_data['reactivity'].values[0][i],\n                           'deg_Mg_pH10_gt' : sample_data['deg_Mg_pH10'].values[0][i],\n                           'deg_Mg_50C_gt' : sample_data['deg_Mg_50C'].values[0][i],\n                           }\n            val_data.append(sample_dict)\n    val_data = pd.DataFrame(val_data)\n    val_data = val_data.merge(prd, on='id_seqpos')\n\n    rmses = []\n    mses = []\n    for col in ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C']:\n        rmse = ((val_data[col] - val_data[col+'_gt']) ** 2).mean() ** .5\n        mse = ((val_data[col] - val_data[col+'_gt']) ** 2).mean()\n        rmses.append(rmse)\n        mses.append(mse)\n        print(col, rmse, mse)\n    print(np.mean(rmses), np.mean(mses))","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-21T09:58:51.307542Z","iopub.status.busy":"2020-09-21T09:58:51.306918Z","iopub.status.idle":"2020-09-21T09:59:14.103528Z","shell.execute_reply":"2020-09-21T09:59:14.105346Z"},"papermill":{"duration":35.353703,"end_time":"2020-09-21T09:59:14.105565","exception":false,"start_time":"2020-09-21T09:58:38.751862","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"print_mse(holdouts_df)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-21T09:59:39.272921Z","iopub.status.busy":"2020-09-21T09:59:39.271903Z","iopub.status.idle":"2020-09-21T09:59:46.041567Z","shell.execute_reply":"2020-09-21T09:59:46.040925Z"},"papermill":{"duration":19.171895,"end_time":"2020-09-21T09:59:46.041676","exception":false,"start_time":"2020-09-21T09:59:26.869781","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"print_mse(holdouts_df[holdouts_df.SN_filter == 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}