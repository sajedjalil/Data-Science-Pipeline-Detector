{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Graph Neural Network With Pytorch Geometric"},{"metadata":{},"cell_type":"markdown","source":"### Updates:\n\n- Copied some great ideas from kernels https://www.kaggle.com/vudangthinh/openvaccine-gcn-graphsage-gru-kfold and https://www.kaggle.com/symyksr/openvaccine-deepergcn\n\n- One of them trains on only data below a given noise level (1) and validates on all of the data.\n\n- I think the number of parameters they have used are much greater than I originally had so have upped that somewhat\n\n- Some general setup things e.g. using a config class\n\n- TODO k-fold"},{"metadata":{},"cell_type":"markdown","source":"I've wanted to learn graph neural networks for a long time after the scalar coupling competition about a year ago. https://www.kaggle.com/c/champs-scalar-coupling. This notebook is me teaching myself and perhaps others who happen to stumble on it for this competition or by googling!\n\nI remember back then that early on hengck23 posted a graphical neural network starter kit which at the time I failed to understand but I found the ideas really interesting. Without having a notebook to point at I'll point to the profile of https://www.kaggle.com/hengck23 who is always one of the first to post code and ideas.\n\nDo let me know if you notice bugs or ideas and I'll happily add them."},{"metadata":{},"cell_type":"markdown","source":"The install is a bit slow - don't worry."},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nprint(torch.__version__)\nprint(torch.version.cuda)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n!pip install torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n!pip install torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n!pip install torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n!pip install torch-geometric","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nimport shutil\n\n#the basics\nimport pandas as pd, numpy as np, seaborn as sns\nimport math, json\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mc\nfrom matplotlib import cm\nimport seaborn as sns\nimport colorsys\nfrom tqdm import tqdm\n\n#for model evaluation\nfrom sklearn.model_selection import train_test_split, KFold\n\nimport torch.nn as nn\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Forgi\nI'm also using forgi (with thanks to https://www.kaggle.com/iamleonie/openvaccine-eda-feature-engineering-with-forgi)"},{"metadata":{"trusted":true},"cell_type":"code","source":"!conda install -y -c bioconda forgi\n!conda install -y -c bioconda viennarna\n\nimport forgi.graph.bulge_graph as fgb\nimport forgi.visual.mplotlib as fvm\nimport forgi.threedee.utilities.vector as ftuv\nimport forgi\n\nimport RNA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_all(seed=42):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    \nseed_all()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class config:\n    learning_rate = 0.001\n    K = 1 # number of aggregation loop (also means number of GCN layers)\n    gcn_agg = 'mean' # aggregator function: mean, conv, lstm, pooling\n    filter_noise = True\n    seed = 1234\n    noise_threshold = 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Functions for getting connectivity\n(with thanks to https://www.kaggle.com/theoviel/generating-graph-matrices-from-the-structures)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_couples(structure):\n    \"\"\"\n    For each closing parenthesis, I find the matching opening one and store their index in the couples list.\n    The assigned list is used to keep track of the assigned opening parenthesis\n    \"\"\"\n    opened = [idx for idx, i in enumerate(structure) if i == '(']\n    closed = [idx for idx, i in enumerate(structure) if i == ')']\n\n    assert len(opened) == len(closed)\n\n\n    assigned = []\n    couples = []\n\n    for close_idx in closed:\n        for open_idx in opened:\n            if open_idx < close_idx:\n                if open_idx not in assigned:\n                    candidate = open_idx\n            else:\n                break\n        assigned.append(candidate)\n        couples.append([candidate, close_idx])\n        assigned.append(close_idx)\n        couples.append([close_idx, candidate])\n        \n    assert len(couples) == 2*len(opened)\n    \n    return couples","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_matrix(couples,size):\n    mat = np.zeros((size, size))\n    \n    for i in range(size):  # neigbouring bases are linked as well\n        if i < size - 1:\n            mat[i, i + 1] = 1\n        if i > 0:\n            mat[i, i - 1] = 1\n    \n    for i, j in couples:\n        mat[i, j] = 2\n        mat[j, i] = 2\n        \n    return mat","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Function to get features for each 'node'"},{"metadata":{"trusted":true},"cell_type":"code","source":"def seq2nodes(sequence,loops,structures):\n    type_dict={'A':0,'G':1,'U':2,'C':3}\n    loop_dict={'S':0,'M':1,'I':2,'B':3,'H':4,'E':5,'X':6}\n    struct_dict={'.':0,'(':1,')':2}\n    # 4 types, 7 structural types\n    nodes=np.zeros((len(sequence),4+7+3))\n    for i,s in enumerate(sequence):\n        nodes[i,type_dict[s]]=1\n    for i,s in enumerate(loops):\n        nodes[i,4+loop_dict[s]]=1\n    for i,s in enumerate(structures):\n        nodes[i,11+struct_dict[s]]=1\n    return nodes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data=pd.read_json('../input/stanford-covid-vaccine/train.json',lines=True)\nall_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's check out the first structure\n\nThe colours give us the type of structure. They match with 'predicted loop type'\n\nThe numbers are the number in the sequence. By the looks of it we would like to encode the ladders as a kind of connectivity in addition to the given links. TODO"},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = 0\nid_=all_data.iloc[idx].id\nsequence = all_data.iloc[idx].sequence\nstructure = all_data.iloc[idx].structure\nloops=all_data.iloc[idx].predicted_loop_type\nreactivity = all_data.iloc[idx].reactivity\nbg = fgb.BulgeGraph.from_fasta_text(f'>rna1\\n{structure}\\n{sequence}')[0]\nfig = plt.figure(figsize=(6, 6))\n\nfvm.plot_rna(bg, lighten=0.5, text_kwargs={\"fontweight\":None})\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix=build_matrix(get_couples(structure),len(sequence))\nbpps_dir='../input/stanford-covid-vaccine/bpps/'\nbpps=np.load(bpps_dir+id_+'.npy')\nedge_index=np.stack(np.where((matrix+bpps)>0))\n#adjacents=np.stack(np.where(matrix==1))\n#couples=np.stack(np.where(matrix==2))\n#probs=np.stack(np.where(bpps>0))\n#edge_index=np.hstack((adjacents,couples))\n# nodes x features\nnode_attr=seq2nodes(sequence,loops,structure)\nedge_attr=np.zeros((edge_index.shape[1],4))\nedge_attr[:,0]=(matrix==2)[edge_index[0,:],edge_index[1,:]]\nedge_attr[:,1]=(matrix==1)[edge_index[0,:],edge_index[1,:]]\nedge_attr[:,2]=(matrix==-1)[edge_index[0,:],edge_index[1,:]]\nedge_attr[:,3]=bpps[edge_index[0,:],edge_index[1,:]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pytorch Geometric Dataset\n\nNow we get serious. Pytorch geometric datasets have a number of required methods.\n\nThe reason for this specific structure is that it allows us to stack graphs together with different numbers of nodes and edges into a big sparse matrix/tensor.\n\nThe pytorch-geometric \"Data\" object has a number of default properties but we can also add some others. These are:\n\nx: node attributes (nodes x node_features)\ny: node targets (nodes x node_targets)\nedge_index: paired nodes (2 x edges)\nedge_attr: edge attributes (edges x edge_features)\n\nWe also use:\n\ntrain_mask: binary mask which we later use to ensure we only calculate errors for the correct nodes during training i.e. the first 68"},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch_geometric.data import InMemoryDataset\nfrom torch_geometric.data import Data\n\nclass MyOwnDataset(InMemoryDataset):\n    def __init__(self, root='',train=True, public=True, ids=None,filter_noise=False,transform=None, pre_transform=None):\n        try:\n            shutil.rmtree('./'+root)\n        except:\n            print(\"doesn't exist\")\n        self.train=train\n        if self.train:\n            self.data_dir = '../input/stanford-covid-vaccine/train.json'\n        else:\n            self.data_dir = '/kaggle/input/stanford-covid-vaccine/test.json'\n        self.bpps_dir='../input/stanford-covid-vaccine/bpps/'\n        self.df=pd.read_json(self.data_dir,lines=True)\n        if filter_noise:\n            self.df = self.df[self.df.SN_filter ==1]\n        if ids is not None:\n            self.df=self.df[self.df['index'].isin(ids)]\n        if public:\n            self.df=self.df.query(\"seq_length == 107\")\n        else:\n            self.df=self.df.query(\"seq_length == 130\")\n        self.target_cols = ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C','deg_pH10', 'deg_50C']\n        \n        super(MyOwnDataset, self).__init__(root,transform, pre_transform)\n        self.data, self.slices = torch.load(self.processed_paths[0])\n        \n    \n    @property\n    def raw_file_names(self):\n        return []\n\n    @property\n    def processed_file_names(self):\n        return 'data.pt'\n\n    def download(self):\n        pass\n\n    def process(self):\n        # Read data into huge `Data` list.\n        data_list = []\n        for idx in range(len(self.df)):\n            structure=self.df['structure'].iloc[idx]\n            sequence=self.df['sequence'].iloc[idx]\n            loops=self.df['predicted_loop_type'].iloc[idx]\n            # 2 x edges\n            matrix=build_matrix(get_couples(structure),len(sequence))\n            # nodes x features\n            id_=self.df['id'].iloc[idx]\n            bpps=np.load(self.bpps_dir+id_+'.npy')\n            edge_index=np.stack(np.where((matrix)!=0))\n            node_attr=seq2nodes(sequence,loops,structure)\n            node_attr=np.append(node_attr, bpps.sum(axis=1,keepdims=True), axis=1)\n            edge_attr=np.zeros((edge_index.shape[1],4))\n            edge_attr[:,0]=(matrix==2)[edge_index[0,:],edge_index[1,:]]\n            edge_attr[:,1]=(matrix==1)[edge_index[0,:],edge_index[1,:]]\n            edge_attr[:,2]=(matrix==-1)[edge_index[0,:],edge_index[1,:]]\n            edge_attr[:,3]=bpps[edge_index[0,:],edge_index[1,:]]\n            # targets\n            #padded_targets=np.zeros((130,5))\n            if self.train:\n                targets=np.stack(self.df[self.target_cols].iloc[idx]).T\n            else:\n                targets=np.zeros((130,5))\n            x = torch.from_numpy(node_attr)\n            y = torch.from_numpy(targets)\n            edge_attr=torch.from_numpy(edge_attr)\n            edge_index=torch.tensor(edge_index,dtype=torch.long)\n            data = Data(x=x, edge_index=edge_index,edge_attr=edge_attr, y=y)\n            data.train_mask = torch.zeros(data.num_nodes, dtype=torch.uint8)\n            data.train_mask[:68] = 1\n            data_list.append(data)\n\n        data, slices = self.collate(data_list)\n        torch.save((data, slices), self.processed_paths[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Set up a training and validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_ids=np.arange(len(all_data))\nnp.random.shuffle(all_ids)\ntrain_ids,val_ids=np.split(all_ids, [int(round(0.9 * len(all_ids), 0))])\n\ntrain_dataset=MyOwnDataset(ids=train_ids, root='train',filter_noise=config.filter_noise)\nval_dataset=MyOwnDataset(ids=val_ids, root='val',filter_noise=config.filter_noise)\n\nfrom torch_geometric.data import DataLoader\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=False)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model\n\nThere are a number of different graph neural network architectures. I have here the GCN from the tutorial as well as an adapted version of the MPNN."},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GCNConv\n\nclass GCNNet(torch.nn.Module):\n    def __init__(self, node_feats,channels,out_feats,edge_feats=1):\n        super(GCNNet, self).__init__()\n        self.conv1 = GCNConv(node_feats, channels)\n        self.conv2 = GCNConv(channels, channels)\n        self.conv3 = GCNConv(channels, channels)\n        self.conv4 = GCNConv(channels, channels)\n        self.conv5 = GCNConv(channels, channels)\n        self.conv9 = GCNConv(channels, out_feats)\n\n    def forward(self, data):\n        x, edge_index = data.x, data.edge_index\n        x = self.conv1(x, edge_index)\n        x = F.relu(x)\n        x = F.dropout(x, training=self.training)\n        x = self.conv2(x, edge_index)\n        x = F.relu(x)\n        x = F.dropout(x, training=self.training)\n        x = self.conv3(x, edge_index)\n        x = F.relu(x)\n        x = F.dropout(x, training=self.training)\n        x = self.conv4(x, edge_index)\n        x = F.relu(x)\n        x = F.dropout(x, training=self.training)\n        x = self.conv5(x, edge_index)\n        x = F.relu(x)\n        x = F.dropout(x, training=self.training)\n        x = self.conv9(x, edge_index)\n        return x\n    \n\nimport torch.nn.functional as F\nfrom torch.nn import Sequential, Linear, ReLU, GRU\nfrom torch_geometric.nn import NNConv, Set2Set    \n\nclass MPNNet(torch.nn.Module):\n    def __init__(self, node_feats,channels,out_feats,loops=1,edge_feats=1):\n        super(MPNNet, self).__init__()\n        self.lin0 = torch.nn.Linear(node_feats,channels)\n        self.loops=loops\n        nn = Sequential(Linear(edge_feats, channels), ReLU(), Linear(channels, channels * channels))\n        self.conv = NNConv(channels, channels, nn, aggr='mean')\n        self.gru = GRU(channels, channels)\n\n        self.lin1 = torch.nn.Linear(channels, channels)\n        self.lin2 = torch.nn.Linear(channels, out_feats)\n\n    def forward(self, data):\n        out = F.relu(self.lin0(data.x))\n        h = out.unsqueeze(0)\n\n        for i in range(self.loops):\n            m = F.relu(self.conv(out, data.edge_index, data.edge_attr))\n            out, h = self.gru(m.unsqueeze(0), h)\n            out = out.squeeze(0)\n\n        #out = self.set2set(out, data.batch)\n        out = F.relu(self.lin1(out))\n        out = self.lin2(out)\n        return out\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We also choose an adam optimizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"node_feats=train_dataset.num_node_features\nout_feats=train_dataset.num_classes\nedge_feats=train_dataset.num_edge_features\n\n\n#model = GCNNet(node_feats,256,out_feats,edge_feats=edge_feats).double().to(device)\nmodel = MPNNet(node_feats,128,out_feats,loops=10,edge_feats=edge_feats).double()\nprint(sum(p.numel() for p in model.parameters()))\n#data = dataset[0].to(device)\noptimizer = torch.optim.Adam(model.parameters())\n#loss_fn = nn.MSELoss()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{},"cell_type":"markdown","source":"### The competition metric\n\n(with thanks to https://www.kaggle.com/masashisode/pytorch-implementation-of-mcrmseloss)"},{"metadata":{"trusted":true},"cell_type":"code","source":"class MCRMSELoss(torch.nn.Module):\n    def __init__(self):\n        super(MCRMSELoss,self).__init__()\n\n    def forward(self,x,y):\n        #columnwise mean\n        x=x[:,:3]\n        y=y[:,:3]\n        msq_error=torch.mean((x-y)**2,0)\n        loss=torch.mean(torch.sqrt(msq_error))\n        return loss","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training and Validation Loop"},{"metadata":{"trusted":true},"cell_type":"code","source":"class AverageMeter:\n    \"\"\"\n    Computes and stores the average and current value\n    \"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.nn import MSELoss\nimport gc\nloss_fn = MCRMSELoss()\n#loss_fn = MSELoss()\n\ndef train(model,optimizer,train_loader):\n    model.train()\n    train_loss = AverageMeter()\n    for batch_idx,data in enumerate(train_loader):# Iterate in batches over the training dataset.\n        out = model(data.to(device))  # Perform a single forward pass.\n        loss = loss_fn(out[data.train_mask], data.y)  # Compute the loss.\n        loss.backward()  # Derive gradients.\n        optimizer.step()  # Update parameters based on gradients.\n        optimizer.zero_grad()\n        train_loss.update(loss.item())\n    return train_loss.avg\n\ndef test(model,val_loader):\n    model.eval()\n    val_loss = AverageMeter()\n    for batch_idx,data in enumerate(val_loader):  # Iterate in batches over the training/test dataset.\n        out = model(data.to(device))\n        loss=loss_fn(out[data.train_mask], data.y)\n        val_loss.update(loss.item())  # Compute the loss. # Check against ground-truth labels.\n    return val_loss.avg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_loop(model,epochs=1):\n    model.to(device)\n    optimizer = torch.optim.Adam(model.parameters(),lr=config.learning_rate)\n    train_loss = []\n    val_loss = []\n    for epoch in range(1, epochs+1):\n        train_acc = train(model,optimizer,train_loader)\n        val_acc = test(model,val_loader)\n        train_loss.append(train_acc)\n        val_loss.append(val_acc)\n        print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {val_acc:.4f}')\n    return model, train_loss, val_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model, train_loss, val_loss = train_loop(model,epochs=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Structure Prediction Plot\n\nThis once again leans on the code by (https://www.kaggle.com/iamleonie/openvaccine-eda-feature-engineering-with-forgi)\n\nBasically it allows me to graphically debug the predictions and see where information is missing. They also look amazing - thanks!"},{"metadata":{"trusted":true},"cell_type":"code","source":"def custom_plot_rna(cg, coloring, ax=None):\n    '''\n    Edited from https://github.com/ViennaRNA/forgi/blob/master/forgi/visual/mplotlib.py\n    '''\n    RNA.cvar.rna_plot_type = 1\n    coords = []\n    bp_string = cg.to_dotbracket_string()\n    if ax is None:\n        ax = plt.gca()\n    vrna_coords = RNA.get_xy_coordinates(bp_string)\n    \n    for i, _ in enumerate(bp_string):\n        coord = (vrna_coords.get(i).X, vrna_coords.get(i).Y)\n        coords.append(coord)\n    coords = np.array(coords)\n    \n    # Now plot circles\n    for i, coord in enumerate(coords):\n        if i < len(coloring):\n            c = cm.coolwarm(coloring[i])\n        else: \n            c = 'grey'\n        h,l,s = colorsys.rgb_to_hls(*mc.to_rgb(c))\n        c=colorsys.hls_to_rgb(h,l,s)\n        circle = plt.Circle((coord[0], coord[1]),color=c)\n        ax.add_artist(circle)\n\n    datalim = ((min(list(coords[:, 0]) + [ax.get_xlim()[0]]),\n                min(list(coords[:, 1]) + [ax.get_ylim()[0]])),\n               (max(list(coords[:, 0]) + [ax.get_xlim()[1]]),\n                max(list(coords[:, 1]) + [ax.get_ylim()[1]])))\n\n    width = datalim[1][0] - datalim[0][0]\n    height = datalim[1][1] - datalim[0][1]\n\n    ax.set_aspect('equal', 'datalim')\n    ax.update_datalim(datalim)\n    ax.autoscale_view()\n    ax.set_axis_off()\n\n    return (ax, coords)\n\ndef plot_structure_with_target_var(idx):\n    sequence = all_data.iloc[idx].sequence\n    structure = all_data.iloc[idx].structure\n\n    fig, ax = plt.subplots(nrows=1, ncols=5, figsize=(16, 4))\n    coloring = all_data.iloc[idx].reactivity\n    coloring = [(c-min(all_data.reactivity[idx]))/(max(all_data.reactivity[idx])-min(all_data.reactivity[idx])) for c in coloring] \n    bg = fgb.BulgeGraph.from_fasta_text(f'>rna1\\n{structure}\\n{sequence}')[0]\n    custom_plot_rna(bg, coloring, ax=ax[0])\n    ax[0].set_title('reactivity', fontsize=16)\n\n    coloring = all_data.iloc[idx].deg_Mg_pH10\n    coloring = [(c-min(all_data.deg_Mg_pH10[idx]))/(max(all_data.deg_Mg_pH10[idx])-min(all_data.deg_Mg_pH10[idx])) for c in coloring] \n    custom_plot_rna(bg, coloring, ax=ax[1])\n    ax[1].set_title('deg_Mg_pH10', fontsize=16)\n\n    coloring = all_data.iloc[idx].deg_pH10\n    coloring = [(c-min(all_data.deg_pH10[idx]))/(max(all_data.deg_pH10[idx])-min(all_data.deg_pH10[idx])) for c in coloring] \n    custom_plot_rna(bg, coloring, ax=ax[2])\n    ax[2].set_title('deg_pH10', fontsize=16)\n\n    coloring = all_data.iloc[idx].deg_Mg_50C\n    coloring = [(c-min(all_data.deg_Mg_50C[idx]))/(max(all_data.deg_Mg_50C[idx])-min(all_data.deg_Mg_50C[idx])) for c in coloring] \n    custom_plot_rna(bg, coloring, ax=ax[3])\n    ax[3].set_title('deg_Mg_50C', fontsize=16)\n\n    coloring = all_data.iloc[idx].deg_50C\n    coloring = [(c-min(all_data.deg_50C[idx]))/(max(all_data.deg_50C[idx])-min(all_data.deg_50C[idx])) for c in coloring] \n    custom_plot_rna(bg, coloring, ax=ax[4])\n    ax[4].set_title('deg_50C', fontsize=16)\n\n    plt.show()\n    \ndef plot_structure_with_predicted_var(idx):\n    sequence = all_data.iloc[idx].sequence\n    structure = all_data.iloc[idx].structure\n    try:\n        data=train_dataset[idx]\n    except:\n        data=val_dataset[idx]\n    preds = model(data.to(device)).detach().cpu().numpy()\n    fig, ax = plt.subplots(nrows=1, ncols=5, figsize=(16, 4))\n\n    coloring = preds[:,0].tolist()\n    coloring = [(c-min(all_data.reactivity[idx]))/(max(all_data.reactivity[idx])-min(all_data.reactivity[idx])) for c in coloring] \n    bg = fgb.BulgeGraph.from_fasta_text(f'>rna1\\n{structure}\\n{sequence}')[0]\n    custom_plot_rna(bg, coloring, ax=ax[0])\n    ax[0].set_title('reactivity', fontsize=16)\n\n    coloring = preds[:,1].tolist()\n    coloring = [(c-min(all_data.deg_Mg_pH10[idx]))/(max(all_data.deg_Mg_pH10[idx])-min(all_data.deg_Mg_pH10[idx])) for c in coloring] \n    custom_plot_rna(bg, coloring, ax=ax[1])\n    ax[1].set_title('deg_Mg_pH10', fontsize=16)\n\n    coloring = preds[:,2].tolist()\n    coloring = [(c-min(all_data.deg_pH10[idx]))/(max(all_data.deg_pH10[idx])-min(all_data.deg_pH10[idx])) for c in coloring] \n    custom_plot_rna(bg, coloring, ax=ax[2])\n    ax[2].set_title('deg_pH10', fontsize=16)\n\n    coloring = preds[:,3].tolist()\n    coloring = [(c-min(all_data.deg_Mg_50C[idx]))/(max(all_data.deg_Mg_50C[idx])-min(all_data.deg_Mg_50C[idx])) for c in coloring] \n    custom_plot_rna(bg, coloring, ax=ax[3])\n    ax[3].set_title('deg_Mg_50C', fontsize=16)\n\n    coloring = preds[:,4].tolist()\n    coloring = [(c-min(all_data.deg_50C[idx]))/(max(all_data.deg_50C[idx])-min(all_data.deg_50C[idx])) for c in coloring] \n    custom_plot_rna(bg, coloring, ax=ax[4])\n    ax[4].set_title('deg_50C', fontsize=16)\n\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Choose an index to look at\nidx=val_ids[0]\n\nplot_structure_with_target_var(5)\nplot_structure_with_predicted_var(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot the Losses"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(train_loss,label='train')\nplt.plot(val_loss,label='val')\nplt.title('Plot training and validation losses')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ndel train_dataset\ndel train_loader\ndel val_dataset\ndel val_loader\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Get Predictions and Submit"},{"metadata":{"trusted":true},"cell_type":"code","source":"public_leaderboard_dataset=MyOwnDataset(root='public/',train=False,public=True)\nprivate_leaderboard_dataset=MyOwnDataset(root='private/',train=False,public=False)\n\npublic_leaderboard_loader = DataLoader(public_leaderboard_dataset, batch_size=4, shuffle=False)\nprivate_leaderboard_loader = DataLoader(private_leaderboard_dataset, batch_size=4, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_preds(pred_loader,public=False):\n    model.eval()\n    batch_preds=[]\n    for batch_idx,data in enumerate(pred_loader):\n        out = model(data.to(device))\n        if public:\n            out=out\n        else:\n            out=out\n        batch_preds.append(out.cpu().detach())\n    return batch_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"public_preds=get_preds(public_leaderboard_loader,public=True)\nprivate_preds=get_preds(private_leaderboard_loader,public=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"public_preds=torch.cat(public_preds,dim=0).numpy()\nprivate_preds=torch.cat(private_preds,dim=0).numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_df=pd.read_json('/kaggle/input/stanford-covid-vaccine/test.json',lines=True)\npublic_df = all_df.query(\"seq_length == 107\")\nprivate_df = all_df.query(\"seq_length == 130\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create the submission file\n\n(with thanks to https://www.kaggle.com/xhlulu/openvaccine-simple-gru-model)"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C','deg_pH10', 'deg_50C']\npreds_ls = []\n\nfor df, preds in [(public_df, public_preds), (private_df, private_preds)]:\n    for i, uid in enumerate(df.id):\n        sequence=df.sequence.iloc[i]\n        single_pred = preds[i*len(sequence):i*len(sequence)+len(sequence),:]\n\n        single_df = pd.DataFrame(single_pred, columns=pred_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n        preds_ls.append(single_df)\n\npreds_df = pd.concat(preds_ls)\npreds_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_df = pd.read_csv('../input/stanford-covid-vaccine/sample_submission.csv')\nsubmission = sample_df[['id_seqpos']].merge(preds_df, on=['id_seqpos'])\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(submission))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion\n\nIf you found this notebook helpful please take the time to upvote.\n\nEqually if you have any ideas for further development give me a shout!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}