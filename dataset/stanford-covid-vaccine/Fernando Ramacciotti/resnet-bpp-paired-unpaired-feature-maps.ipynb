{"cells":[{"metadata":{},"cell_type":"markdown","source":"I tried to separate paired and non-paired codes into different feature maps and feed them to a Residual + LSTM net."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\n\nimport gc\n\ntfk = tf.keras\ntfkl = tfk.layers\nK = tfk.backend","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_json('../input/stanford-covid-vaccine/train.json', lines=True)\ntrain = train.loc[train.SN_filter >= 1]\n\ntest = pd.read_json('../input/stanford-covid-vaccine/test.json', lines=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 5 feature maps (1 seq paired, 1 seq unpaired, 1 loop paired, 1 loop unpaired, 1 structure)\n# e.g. sequence paired features will have the corresponding code where there is a pair and '-' (fillna) where there is not.\nfillna = '-'\nencoder = {v: i for i, v in enumerate('AGUCSMIBHEX.(' + fillna)}\n# we should treat ( and ) as the same\nencoder[')'] = encoder['(']\n\ndef get_pair_unpair_mask(struct):\n    pair_ixs = list()\n    unpair_ixs = list()\n    for ix, si in enumerate(struct):\n        if si in ['(', ')']:\n            pair_ixs.append(ix)\n        else:\n            unpair_ixs.append(ix)\n    return (pair_ixs, unpair_ixs)\n\ndef str_replacer(string, newvalue, ixs):\n    tmp = list(string)\n    for ix in ixs:\n        tmp[ix] = newvalue\n    return ''.join(tmp)\n    \n\ndef preprocess_inputs(df, encoder=encoder, fillna=fillna):\n    # get pair mask\n    pair_unpair_ixs = df.structure.apply(get_pair_unpair_mask).values\n    \n    seq = df.sequence.values.copy()\n    # sequences\n    seq_paired = seq.copy()\n    seq_unpaired = seq.copy()\n    for ix, (pair_ix, unpair_ix) in enumerate(pair_unpair_ixs):\n        # paired\n        seq_paired[ix] = str_replacer(seq_paired[ix], fillna, unpair_ix)\n        seq_paired[ix] = [encoder[si] for si in seq_paired[ix]]\n        # unpaired\n        seq_unpaired[ix] = str_replacer(seq_unpaired[ix], fillna, pair_ix)\n        seq_unpaired[ix] = [encoder[si] for si in seq_unpaired[ix]]\n    \n    loop = df.predicted_loop_type.values.copy()\n    # sequences\n    loop_paired = loop.copy()\n    loop_unpaired = loop.copy()\n    for ix, (pair_ix, unpair_ix) in enumerate(pair_unpair_ixs):\n        # paired\n        loop_paired[ix] = str_replacer(loop_paired[ix], fillna, unpair_ix)\n        loop_paired[ix] = [encoder[si] for si in loop_paired[ix]]\n        # unpaired\n        loop_unpaired[ix] = str_replacer(loop_unpaired[ix], fillna, pair_ix)\n        loop_unpaired[ix] = [encoder[si] for si in loop_unpaired[ix]]\n        \n    # structure\n    structure = df.structure.apply(lambda s: [encoder[si] for si in s]).values\n    \n    # concat all\n    X = np.vstack((seq_paired, seq_unpaired, loop_paired, loop_unpaired, structure))\n    X = np.array(X.tolist()).transpose(1, 2, 0)\n    return X\n\n\ndef get_bpp_mx(seq_ids):\n    files_list = [f'../input/stanford-covid-vaccine/bpps/{seq_id}.npy' \n                  for seq_id in seq_ids]\n    bpps = [np.load(f) for f in files_list]\n    shape = bpps[0].shape\n    return np.array(bpps).reshape(-1, shape[0], shape[1], 1)\n\n\ntarget_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\ndef preprocess_labels(df, target_cols=target_cols):\n    return np.array(df[target_cols].values.tolist()).transpose((0, 2, 1))\n\n\ndef preprocess(df, encoder=encoder, fillna=fillna, target_cols=target_cols):\n    X = preprocess_inputs(df, encoder=encoder, fillna=fillna)\n    Xbpp = get_bpp_mx(df.id.values)\n    y = preprocess_labels(df, target_cols=target_cols)\n    return (X, Xbpp, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"def MCRMSE(y_true, y_pred):\n    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# http://d2l.ai/chapter_convolutional-modern/resnet.html\nclass Residual1D(tfk.Model):  #@save\n    def __init__(self, num_channels, use_1x1conv=False, strides=1):\n        super().__init__()\n        self.conv1 = tfkl.Conv1D(num_channels, padding='same',\n                                 kernel_size=3, strides=strides)\n        self.conv2 = tfkl.Conv1D(num_channels, padding='same',\n                                 kernel_size=3)\n        self.conv3 = None\n        if use_1x1conv:\n            self.conv3 = tfkl.Conv1D(num_channels, kernel_size=1,\n                                     strides=strides)\n        self.bn1 = tfkl.BatchNormalization()\n        self.bn2 = tfkl.BatchNormalization()\n        \n    def call(self, X):\n        y = tfk.activations.relu(self.bn1(self.conv1(X)))\n        y = self.bn2(self.conv2(y))\n        if self.conv3 is not None:\n            X = self.conv3(X)\n        y += X\n        y = tfkl.LeakyReLU()(y)\n        y = tfkl.Dropout(0.5)(y)\n        return y\n    \n    def get_config(self):\n\n        config = super().get_config().copy()\n        config.update({\n            'num_channels': self.num_channels,\n            'use_1x1conv': self.use_1x1conv,\n            'strides': self.strides,\n        })\n        return config\n    \nclass ResidualBlock1D(tfkl.Layer):\n    def __init__(self, num_channels, num_residuals, first_block=False, **kwargs):\n        super(ResidualBlock1D, self).__init__(**kwargs)\n        self.num_channels = num_channels\n        self.num_residuals = num_residuals\n        self.first_block = first_block\n        \n        self.residual_layers = list()\n        for i in range(num_residuals):\n            if i == 0 and not first_block:\n                self.residual_layers.append(\n                    Residual1D(num_channels, use_1x1conv=True, strides=1))\n            else:\n                self.residual_layers.append(Residual1D(num_channels))\n                \n    def call(self, X):\n        for layer in self.residual_layers.layers:\n            X = layer(X)\n        return X\n    \n    def get_config(self):\n\n        config = super().get_config().copy()\n        config.update({\n            'num_channels': self.num_channels,\n            'num_residuals': self.num_residuals,\n            'first_block': self.first_block,\n        })\n        return config\n    \nclass Residual2D(tfk.Model):  #@save\n    def __init__(self, num_channels, use_1x1conv=False, strides=1):\n        super().__init__()\n        self.conv1 = tfkl.Conv2D(num_channels, padding='same',\n                                 kernel_size=3, strides=strides)\n        self.conv2 = tfkl.Conv2D(num_channels, padding='same',\n                                 kernel_size=3)\n        self.conv3 = None\n        if use_1x1conv:\n            self.conv3 = tfkl.Conv2D(num_channels, kernel_size=1,\n                                     strides=strides)\n        self.bn1 = tfkl.BatchNormalization()\n        self.bn2 = tfkl.BatchNormalization()\n        \n    def call(self, X):\n        y = tfk.activations.relu(self.bn1(self.conv1(X)))\n        y = self.bn2(self.conv2(y))\n        if self.conv3 is not None:\n            X = self.conv3(X)\n        y += X\n        y = tfkl.LeakyReLU()(y)\n        y = tfkl.Dropout(0.5)(y)\n        return y\n    \n    def get_config(self):\n\n        config = super().get_config().copy()\n        config.update({\n            'num_channels': self.num_channels,\n            'use_1x1conv': self.use_1x1conv,\n            'strides': self.strides,\n        })\n        return config\n    \nclass ResidualBlock2D(tfkl.Layer):\n    def __init__(self, num_channels, num_residuals, first_block=False, **kwargs):\n        super(ResidualBlock2D, self).__init__(**kwargs)\n        self.num_channels = num_channels\n        self.num_residuals = num_residuals\n        self.first_block = first_block\n        \n        self.residual_layers = list()\n        for i in range(num_residuals):\n            if i == 0 and not first_block:\n                self.residual_layers.append(\n                    Residual2D(num_channels, use_1x1conv=True, strides=2))\n            else:\n                self.residual_layers.append(Residual2D(num_channels))\n                \n    def call(self, X):\n        for layer in self.residual_layers.layers:\n            X = layer(X)\n        return X\n    \n    def get_config(self):\n\n        config = super().get_config().copy()\n        config.update({\n            'num_channels': self.num_channels,\n            'num_residuals': self.num_residuals,\n            'first_block': self.first_block,\n        })\n        return config","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model(seq_len=107, pred_len=68, channels=5, embed_dim=32, loss=MCRMSE):\n    # sequence model\n    inputs = tfk.Input(shape=(seq_len, channels))\n    # embedding\n    x = tf.keras.layers.Embedding(input_dim=len(encoder), output_dim=embed_dim)(inputs)\n    \n    # reshape\n    x = tf.reshape(\n        x, shape=(-1, x.shape[1],  x.shape[2] * x.shape[3]))\n    \n    x = tfkl.SpatialDropout1D(.2)(x)\n    \n    # start\n    x = tfkl.Conv1D(32, kernel_size=7, strides=1, padding='same')(inputs)\n    x = tfkl.BatchNormalization()(x)\n    x = tfkl.Activation('elu')(x)\n    x = tfkl.MaxPool1D(pool_size=5, strides=1, padding='same')(x)\n        \n#     # residual blocks\n    x = ResidualBlock1D(32, 2, first_block=True)(x)\n    x = ResidualBlock1D(64, 2)(x)\n    x = ResidualBlock1D(128, 2)(x)\n        \n    # sequence\n    x = tfkl.Bidirectional(tfkl.GRU(128, dropout=0.1, return_sequences=True, \n                                     kernel_initializer='orthogonal'))(x)\n    x = tfkl.Bidirectional(tfkl.GRU(128, dropout=0.1, return_sequences=True, \n                                     kernel_initializer='orthogonal'))(x)\n    x = tfkl.Bidirectional(tfkl.GRU(128, dropout=0.1, return_sequences=True, \n                                     kernel_initializer='orthogonal'))(x)\n    \n    # bpp matrix model\n    inputs_bpp = tfk.Input(shape=(seq_len, seq_len, 1))\n    xbpp = tfkl.Conv2D(32, kernel_size=7, strides=2, padding='same')(inputs_bpp)\n    xbpp = tfkl.BatchNormalization()(xbpp)\n    xbpp = tfkl.Activation('elu')(xbpp)\n    xbpp = tfkl.MaxPool2D(pool_size=3, strides=2, padding='same')(xbpp)\n        \n    # residual blocks\n    xbpp = ResidualBlock2D(32, 2, first_block=True)(xbpp)\n    xbpp = ResidualBlock2D(64, 2)(xbpp)\n    xbpp = ResidualBlock2D(128, 2)(xbpp)\n    xbpp = tfkl.GlobalAvgPool2D()(xbpp)\n    xbpp = tfkl.RepeatVector(seq_len)(xbpp)\n    \n    \n    # add\n    x = tfkl.Concatenate(axis=-1)([x, xbpp])\n    \n    # truncate\n    x = x[:, :pred_len]\n    \n    # dense\n    x = tfkl.Dropout(0.2)(x)\n    out = tfkl.Dense(5, activation='linear')(x)\n    \n    # model\n    m = tfk.Model(inputs=[inputs, inputs_bpp], outputs=out)\n    \n    #some optimizers\n    adam = tf.optimizers.Adam()\n    radam = tfa.optimizers.RectifiedAdam()\n    lookahead = tfa.optimizers.Lookahead(adam, sync_period=6)\n    ranger = tfa.optimizers.Lookahead(radam, sync_period=6)\n    \n    # compile\n    m.compile(optimizer=adam, loss=loss)\n    return m","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_model().summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfk.utils.plot_model(get_model())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndf_train, df_val = train_test_split(train, test_size=0.10, random_state=2020)\n\nX_train, Xbpp_train, y_train = preprocess(df_train)\nX_val, Xbpp_val, y_val = preprocess(df_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit\nmodel = get_model(loss=MCRMSE)\nepochs = 300\nbatch_size = 16\n\nlr = tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, min_delta=0.005,\n                                     patience=10, min_lr=0.0000001, verbose=1)\nckpt = tfk.callbacks.ModelCheckpoint('model.h5')\n\n\ngc.collect()\nhistory = model.fit((X_train, Xbpp_train), y_train,\n                    validation_data=((X_val, Xbpp_val), y_val),\n                    epochs=epochs, batch_size=batch_size,\n                    callbacks=[lr, ckpt])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"public_df = test.query(\"seq_length == 107\").copy()\nprivate_df = test.query(\"seq_length == 130\").copy()\n\npublic_inputs = preprocess_inputs(public_df)\nbpp_public = get_bpp_mx(public_df.id.values)\n\nprivate_inputs = preprocess_inputs(private_df)\nbpp_private = get_bpp_mx(private_df.id.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"private_preds = np.zeros((private_df.shape[0], 130, 5))\npublic_preds = np.zeros((public_df.shape[0], 107, 5))\n\n#load best model and predict\nmodel_short = get_model(seq_len=107, pred_len=107)\nmodel_short.load_weights('model.h5')\npublic_preds = model_short.predict((public_inputs, bpp_public))\n\nmodel_long = get_model(seq_len=130, pred_len=130)\nmodel_long.load_weights('model.h5')\nprivate_preds = model_long.predict((private_inputs, bpp_private))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_list = []\n\nfor df, preds in [(public_df, public_preds), (private_df, private_preds)]:\n    for i, uid in enumerate(df.id):\n        single_pred = preds[i]\n\n        single_df = pd.DataFrame(single_pred, columns=target_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n        preds_list.append(single_df)\n\npreds_df = pd.concat(preds_list)\npreds_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub = pd.read_csv('/kaggle/input/stanford-covid-vaccine/sample_submission.csv')\n\nsubmission = sample_sub[['id_seqpos']].merge(preds_df, on=['id_seqpos'])\n#sanity check\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)\nprint('Submission saved')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}