{"cells":[{"metadata":{},"cell_type":"markdown","source":"# [Train, infer] Catalyst + PyTorch RNN Baseline\n\n![](https://raw.githubusercontent.com/catalyst-team/catalyst-pics/master/pics/catalyst_logo.png)\n\nThis is mainly a RNN modification of MatthewMasters' CNN baseline (do have a look there and upvote it). The RNN model gives considerable improvements in CV over a CNN, and it seems the same can be said for TensorFlow given Xhlulu's brilliant kernel. This also adds a small attention component (giving 0.12 boost in local CV) but it makes the loss and metric score go yo-yo for a bit.\n\nNow the main part of this notebook is to demonstrate how Catalyst simplifies your training loop in a few ways:-\n+ Makes it much easier to train with PyTorch\n+ Inference too gets simplified drastically."},{"metadata":{},"cell_type":"markdown","source":"# Imports and helpers"},{"metadata":{},"cell_type":"markdown","source":"Typical Data science/machine learning stack for Torch with the addition of `catalyst`."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import json\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nimport torch.nn.functional as F\nimport catalyst.dl as dl\nimport catalyst.dl.utils as utils\nimport numpy as np, pandas as pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This involves defining a few basic functions: one-hot encoding, feature engineering and typical preprocessing functions."},{"metadata":{"trusted":true},"cell_type":"code","source":"def one_hot(categories, string):\n    encoding = np.zeros((len(string), len(categories)))\n    for idx, char in enumerate(string):\n        encoding[idx, categories.index(char)] = 1\n    return encoding\n\ndef featurize(entity):\n    sequence = one_hot(list('ACGU'), entity['sequence'])\n    structure = one_hot(list('.()'), entity['structure'])\n    loop_type = one_hot(list('BEHIMSX'), entity['predicted_loop_type'])\n    features = np.hstack([sequence, structure, loop_type])\n    return features \n\ndef char_encode(index, features, feature_size):\n    half_size = (feature_size - 1) // 2\n    \n    if index - half_size < 0:\n        char_features = features[:index+half_size+1]\n        padding = np.zeros((int(half_size - index), char_features.shape[1]))\n        char_features = np.vstack([padding, char_features])\n    elif index + half_size + 1 > len(features):\n        char_features = features[index-half_size:]\n        padding = np.zeros((int(half_size - (len(features) - index))+1, char_features.shape[1]))\n        char_features = np.vstack([char_features, padding])\n    else:\n        char_features = features[index-half_size:index+half_size+1]\n    \n    return char_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Setup Model and Data Processing"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def augment(X: np.array):\n    \n    X = np.vstack((X, np.flip(X, axis=1)))\n    \n    return X\n\nclass VaxDataset(Dataset):\n    def __init__(self, path, test=False):\n        self.path = path\n        self.test = test\n        self.features = []\n        self.targets = []\n        self.ids = []\n        self.load_data()\n    \n    def load_data(self):\n        with open(self.path, 'r') as text:\n            for line in text:\n                records = json.loads(line)\n                features = featurize(records)\n                \n                for char_i in range(records['seq_scored']):\n                    char_features = char_encode(char_i, features, 21)\n                    self.features.append(augment(char_features))\n                    self.ids.append('%s_%d' % (records['id'], char_i))\n                        \n                if not self.test:\n                    \n                    targets = np.stack([records['reactivity'], records['deg_Mg_pH10'], records['deg_Mg_50C']], axis=1)\n                    self.targets.extend([targets[char_i] for char_i in range(records['seq_scored'])])\n                    \n    def __len__(self):\n        return len(self.features)\n    \n    def targets(self):\n        return self.targets\n    \n    def __getitem__(self, index):\n        if self.test:\n            return self.features[index], self.ids[index]\n        else:\n            return self.features[index], self.targets[index], self.ids[index]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class Flatten(nn.Module):\n    def forward(self, x):\n        batch_size = x.shape[0]\n        return x.view(batch_size, -1)\n \nclass WaveBlock(nn.Module):\n\n    def __init__(self, in_channels, out_channels, dilation_rates, kernel_size):\n        super(WaveBlock, self).__init__()\n        self.num_rates = dilation_rates\n        self.convs = nn.ModuleList()\n        self.filter_convs = nn.ModuleList()\n        self.gate_convs = nn.ModuleList()\n\n        self.convs.append(nn.Conv1d(in_channels, out_channels, kernel_size=1))\n        dilation_rates = [2 ** i for i in range(dilation_rates)]\n        for dilation_rate in dilation_rates:\n            self.filter_convs.append(\n                nn.Conv1d(out_channels, out_channels, kernel_size=kernel_size, padding=int((dilation_rate*(kernel_size-1))/2), dilation=dilation_rate))\n            self.gate_convs.append(\n                nn.Conv1d(out_channels, out_channels, kernel_size=kernel_size, padding=int((dilation_rate*(kernel_size-1))/2), dilation=dilation_rate))\n            self.convs.append(nn.Conv1d(out_channels, out_channels, kernel_size=1))\n\n    def forward(self, x):\n        x = self.convs[0](x)\n        res = x\n        for i in range(self.num_rates):\n            x = torch.tanh(self.filter_convs[i](x)) * torch.sigmoid(self.gate_convs[i](x))\n            x = self.convs[i + 1](x)\n            res = res + x\n        return res\n\n\n\"\"\"Modified version of the SED work by Hidehisa Arai.\"\"\"\ndef init_layer(layer):\n    nn.init.xavier_uniform_(layer.weight)\n\n    if hasattr(layer, \"bias\"):\n        if layer.bias is not None:\n            layer.bias.data.fill_(0.)\n            \n\ndef init_bn(bn):\n    bn.bias.data.fill_(0.)\n    bn.weight.data.fill_(1.0)\n    \nclass AttBlock(nn.Module):\n    def __init__(self,\n                 in_features: int,\n                 out_features: int,\n                 activation=\"linear\",\n                 temperature=1.0):\n        super().__init__()\n\n        self.activation = activation\n        self.temperature = temperature\n        self.att = nn.Conv1d(\n            in_channels=in_features,\n            out_channels=out_features,\n            kernel_size=1,\n            stride=1,\n            padding=0,\n            bias=True)\n        self.cla = nn.Conv1d(\n            in_channels=in_features,\n            out_channels=out_features,\n            kernel_size=1,\n            stride=1,\n            padding=0,\n            bias=True)\n\n        self.bn_att = nn.BatchNorm1d(out_features)\n        self.init_weights()\n\n    def init_weights(self):\n        init_layer(self.att)\n        init_layer(self.cla)\n        init_bn(self.bn_att)\n\n    def forward(self, x):\n        # x: (n_samples, n_in, n_time)\n        norm_att = torch.softmax(torch.clamp(self.att(x), -10, 10), dim=-1)\n        cla = self.nonlinear_transform(self.cla(x))\n        x = torch.sum(norm_att * cla, dim=2)\n        return x\n\n    def nonlinear_transform(self, x):\n        if self.activation == 'linear':\n            return x\n        elif self.activation == 'sigmoid':\n            return torch.sigmoid(x)\n\nclass VaxModel(nn.Module):\n    def __init__(self):\n        super(VaxModel, self).__init__()\n        self.layers = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Conv1d(14, 32, 1, 1),\n            WaveBlock(32, 64, 1, 1),\n            nn.PReLU(),\n            nn.BatchNorm1d(64),\n            nn.Upsample(scale_factor=2, mode='linear'),\n            nn.Dropout(0.2),\n            nn.Conv1d(64, 1, 1, 1),\n        )\n        self.rnn1 = nn.LSTM(84, 64)\n      \n        \n        self.finalprelu = nn.PReLU()\n        self.finaldrop = nn.Dropout(0.2),\n        self.attn =  AttBlock(16,32),\n        self.final = nn.Sequential(\n        nn.PReLU(),\n        nn.Dropout(0.2),\n        nn.Linear(32, 3)\n        )\n    \n    def forward(self, features):\n        \n        features = self.layers(features)\n        features = features.permute(1, 0, 2)\n        features = self.rnn1(features)\n        features = self.finalprelu(features[0])\n        if features.size() == torch.Size([1, 16, 64]):\n            self.attn =  AttBlock(16,32).cuda().float()\n            features = self.attn(features)\n        else:\n            self.attn = AttBlock(3,32).cuda().float()\n            features = self.attn(features)\n        final = self.final(features)\n        return final","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"model = VaxModel().cuda()\noptimizer = torch.optim.SGD(model.parameters(), 0.005, momentum=0.9)\ncriterion = nn.MSELoss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train_dataset = VaxDataset('../input/stanford-covid-vaccine/train.json')\ntrain_dataloader = DataLoader(train_dataset, 16, shuffle=True, num_workers=4, pin_memory=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training loop"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CustomRunner(dl.Runner):\n\n    def predict_batch(self, batch):\n        # model inference step\n        return self.model(batch[0].to(self.device).permute(0, 2, 1).float()), batch[1]\n\n    def _handle_batch(self, batch):\n        # model train/valid step\n        x, y = batch[0], batch[1]\n        x = x.cuda().permute(0,2,1).float()\n        y = y.cuda().float().unsqueeze(0)[:, 0, :]\n        y_hat = self.model(x)\n\n        loss = criterion(y_hat, y)\n        score = mcrmse_loss(y_hat, y)\n        self.batch_metrics.update(\n            {\"loss\": loss, 'metric': score}\n        )\n\n        if self.is_train_loader:\n            loss.backward()\n            self.optimizer.step()\n            self.optimizer.zero_grad()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = utils.get_device()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mcrmse_loss(y_true, y_pred, N=3):\n    \"\"\"\n    Calculates competition eval metric\n    \"\"\"\n    y_true, y_pred = y_true.detach().cpu().numpy(), y_pred.detach().cpu().numpy()\n    assert len(y_true) == len(y_pred)\n    n = len(y_true)\n    return np.sum(np.sqrt(np.sum((y_true - y_pred)**2, axis=0)/n)) / N","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"test_dataset = VaxDataset('../input/stanford-covid-vaccine/test.json', test=True)\ntest_dataloader = DataLoader(test_dataset, 16, num_workers=4, drop_last=False, pin_memory=True)\nscheduler = torch.optim.lr_scheduler.CyclicLR(optimizer,base_lr=1e-3,max_lr=1e-2,step_size_up=2000)\n\nloaders = {\n    'train': train_dataloader,\n}\nrunner = CustomRunner(device=device)\n# model training\nrunner.train(\n    model=model,\n    optimizer=optimizer,\n    loaders=loaders,\n    logdir=\"../working\",\n    num_epochs=6,\n    scheduler=scheduler,\n    verbose=False,\n    load_best_on_end=True,\n    \n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check a few of the results post-training."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"utils.plot_metrics(\n    logdir=\"../working\", \n    # specify which metrics we want to plot\n    metrics=[\"loss\", \"metric\"]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('../input/stanford-covid-vaccine/sample_submission.csv', index_col='id_seqpos')\n\nfor predictions, ids in runner.predict_loader(loader=test_dataloader):\n    sub.loc[ids, ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C']] = predictions.detach().cpu().numpy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}