{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport json\nimport tensorflow.keras.layers as L\nimport keras.backend as K\nimport tensorflow as tf\nimport plotly.express as px\nfrom sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\nfrom sklearn.cluster import KMeans\nimport os","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Augmentation"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"!wget https://www.tbi.univie.ac.at/RNA/download/ubuntu/ubuntu_18_04/viennarna_2.4.15-1_amd64.deb\n!apt-get install ./viennarna_2.4.15-1_amd64.deb -y\n!git clone https://github.com/DasLab/arnie\n\n!/opt/conda/bin/python3.7 -m pip install --upgrade pip\n!git clone https://www.github.com/DasLab/draw_rna draw_rna_pkg\n!cd draw_rna_pkg && python setup.py install\n\n!yes '' | cpan -i Graph\n!git clone https://github.com/hendrixlab/bpRNA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\n\n!echo \"vienna_2: /usr/bin\" > arnie.conf\n!echo \"TMP: /kaggle/working/tmp\" >> arnie.conf\n!mkdir -p /kaggle/working/tmp\nos.environ[\"ARNIEFILE\"] = f\"/kaggle/working/arnie.conf\"\nsys.path.append('/kaggle/working/draw_rna_pkg/')\nsys.path.append('/kaggle/working/draw_rna_pkg/ipynb/')\npkg = 'vienna_2'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from multiprocessing import Pool\nfrom arnie.pfunc import pfunc\nfrom arnie.mea.mea import MEA\nfrom arnie.free_energy import free_energy\nfrom arnie.bpps import bpps\nfrom arnie.mfe import mfe\nimport arnie.utils as utils\nfrom tqdm.notebook import tqdm as tqdm\n\nn_candidates = 2\n# turn off for all data\ndebug = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!grep processor /proc/cpuinfo | wc -l\n\nMAX_THRE = 4\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_json('../input/stanford-covid-vaccine/train.json', lines=True)\ntest = pd.read_json('../input/stanford-covid-vaccine/test.json', lines=True)\nif debug:\n    train = train[:20]\n    test = test[:20]\ntarget_df = train.append(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Start"},{"metadata":{"trusted":true},"cell_type":"code","source":"def proc1(arg):\n    sequence = arg[0]\n    id = arg[1]\n    log_gamma = arg[2]\n    bp_matrix = bpps(sequence, package=pkg)\n    mea_mdl = MEA(bp_matrix,gamma=10**log_gamma)\n    return id, sequence, mea_mdl.structure, log_gamma, mea_mdl.score_expected()[2]\n\nli = []\nfor log_gamma in range(10):\n    for i, arr in enumerate(target_df[['sequence','id']].values):\n        li.append([arr[0], arr[1], log_gamma])\n\np = Pool(processes=MAX_THRE)\nresults = []\nfor ret in tqdm(p.imap(proc1, li),total=len(li)):\n    results.append(ret)\n    #print(f'done for {ret[0]}')\ndf = pd.DataFrame(results, columns=['id', 'sequence', 'structure', 'log_gamma', 'score'])\n\ndf_tmp = target_df[['id', 'sequence', 'structure']].copy()\ndf_tmp['log_gamma'] = 100\ndf_tmp['score'] = 100\ndf = df.append(df_tmp).sort_values('score', ascending=False).reset_index(drop=True)\n\nnew_df = pd.DataFrame()\nfor id in df['id'].unique():\n    unq_df = df[df['id'] == id].drop_duplicates('structure')\n    unq_df['cnt'] = unq_df.shape[0]\n    new_df = new_df.append(unq_df[1:min(n_candidates,len(unq_df))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir -p tmp_files\ndef get_predicted_loop_type(id, sequence, structure, debug=False):\n    structure_fixed = structure.replace('.','0').replace('(','1').replace(')','2')\n    pid = os.getpid()\n    tmp_in_file = f'tmp_files/{id}_{structure_fixed}_{pid}.dbn'\n    tmp_out_file = f'{id}_{structure_fixed}_{pid}.st'\n    !echo $sequence > $tmp_in_file\n    !echo \"$structure\" >> $tmp_in_file\n    !export PERL5LIB=/root/perl5/lib/perl5 && perl bpRNA/bpRNA.pl $tmp_in_file\n    result = [l.strip('\\n') for l in open(tmp_out_file)]\n    if debug:\n        print(sequence)\n        print(structure)\n        print(result[5])\n    else:\n        !rm $tmp_out_file $tmp_in_file\n    return id, structure, result[5]\n\ndef proc2(arg):\n    result = get_predicted_loop_type(arg[0], arg[1], arg[2], debug=False)\n    return result\n\nli = []\nfor i, arr in enumerate(new_df[['id', 'sequence', 'structure']].values):\n    li.append(arr)\n\np = Pool(processes=MAX_THRE)\nresults_loop_type = []\nfor ret in tqdm(p.imap(proc2, li),total=len(li)):\n    results_loop_type.append(ret)\n    #print(f'done for {ret[0]}')\n\nnew_df = new_df.merge(pd.DataFrame(results_loop_type, columns=('id', 'structure', 'predicted_loop_type')), on=['id','structure'], how='left')\nnew_df.to_csv('aug_data.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}