{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2020-09-21T19:46:26.083271Z","iopub.status.busy":"2020-09-21T19:46:26.082656Z","iopub.status.idle":"2020-09-21T19:46:34.560519Z","shell.execute_reply":"2020-09-21T19:46:34.561159Z"},"papermill":{"duration":8.502253,"end_time":"2020-09-21T19:46:34.561348","exception":false,"start_time":"2020-09-21T19:46:26.059095","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom collections import deque, defaultdict","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.014286,"end_time":"2020-09-21T19:46:34.685805","exception":false,"start_time":"2020-09-21T19:46:34.671519","status":"completed"},"tags":[]},"cell_type":"markdown","source":"In this notebook, I will show you how to perform feature extraction."},{"metadata":{"execution":{"iopub.execute_input":"2020-09-21T19:46:35.437738Z","iopub.status.busy":"2020-09-21T19:46:35.436867Z","iopub.status.idle":"2020-09-21T19:46:51.923641Z","shell.execute_reply":"2020-09-21T19:46:51.922727Z"},"papermill":{"duration":16.51641,"end_time":"2020-09-21T19:46:51.923748","exception":false,"start_time":"2020-09-21T19:46:35.407338","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# additional features\n\n# sum of bpps\ndef read_bpps_sum(df):\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps_arr.append(np.load(f\"../input/stanford-covid-vaccine/bpps{bpps_engine}/{mol_id}.npy\").max(axis=1))\n    return bpps_arr\n\n# sum value of bpps\ndef read_bpps_max(df):\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps_arr.append(np.load(f\"../input/stanford-covid-vaccine/bpps{bpps_engine}/{mol_id}.npy\").sum(axis=1))\n    return bpps_arr\n\n# non zero number of bpps\ndef read_bpps_nb(df, thre=0):\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps = np.load(f\"../input/stanford-covid-vaccine/bpps{bpps_engine}/{mol_id}.npy\")\n        bpps_arr.append((bpps > thre).sum(axis=0) / bpps.shape[0])\n    return bpps_arr \n\n# normalization \ndef norm_arr(train_arr, test_arr):\n    arr1 = np.array([])\n    for arr in train_arr.to_list() + test_arr.to_list():\n        arr1 = np.append(arr1,arr)\n    arr1_mean = arr1.mean()\n    arr1_std = arr1.std()\n    train_arr = (train_arr - arr1_mean) / arr1_std\n    test_arr = (test_arr - arr1_mean) / arr1_std\n    return train_arr, test_arr\n\n# calclate distance of the paired nucleotide\ndef mk_pair_distance(structure):\n    pd = np.full(len(structure), -1, dtype=int)\n    start_token_indices = []\n    for i, token in enumerate(structure):\n        if token == \"(\":\n            start_token_indices.append(i)\n        elif token == \")\":\n            j = start_token_indices.pop()\n            pd[i] = i-j\n            pd[j] = i-j\n    return pd\n\n# get position of the paired nucleotide\ndef mk_pair_map(structure):\n    pm = np.full(len(structure), -1, dtype=int)\n    start_token_indices = []\n    for i, token in enumerate(structure):\n        if token == \"(\":\n            start_token_indices.append(i)\n        elif token == \")\":\n            j = start_token_indices.pop()\n            pm[i] = j\n            pm[j] = i\n    return pm\n\n# get probability of the paired nucleotide\ndef mk_pair_prob(arr):\n    structure = arr.structure\n    mol_id = arr.id\n    pm = np.full(len(structure), -1, dtype=int)\n    start_token_indices = []\n    for i, token in enumerate(structure):\n        if token == \"(\":\n            start_token_indices.append(i)\n        elif token == \")\":\n            j = start_token_indices.pop()\n            pm[i] = j\n            pm[j] = i\n    bpps = np.load(f\"../input/stanford-covid-vaccine/bpps{bpps_engine}/{mol_id}.npy\")\n    pp = np.full(len(structure), 0, dtype=float)\n    for i in range(len(structure)):\n        j = pm[i]\n        if j >= 0:\n            pp[i] = bpps[i,j]\n    return pp\n\n# get sequence of the paired nucleotide\ndef mk_pair_acgu(arr):\n    pacgu = ['.']*len(arr.sequence)\n    start_token_indices = []\n    for i, (seq, token) in enumerate(zip(arr.sequence, arr.structure)):\n        if token == \"(\":\n            start_token_indices.append(i)\n        elif token == \")\":\n            j = start_token_indices.pop()\n            pacgu[i] = arr.sequence[j]\n            pacgu[j] = arr.sequence[i]\n    return \"\".join(pacgu)\n\n# get base of the paired nucleotide\nacgu2_dict = {}\ndef mk_pair_acgu2(arr):\n    pacgu = ['..']*len(arr.sequence)\n    start_token_indices = []\n    for i, (seq, token) in enumerate(zip(arr.sequence, arr.structure)):\n        if token == \"(\":\n            start_token_indices.append(i)\n        elif token == \")\":\n            j = start_token_indices.pop()\n            pacgu[i] = arr.sequence[i]+arr.sequence[j]\n            pacgu[j] = arr.sequence[j]+arr.sequence[i]\n            acgu2_dict[pacgu[i]] = 1\n            acgu2_dict[pacgu[j]] = 1\n    return pacgu\n\n# helper func: get idx value of the list\ndef get_list_item(sequence, idx, default='-'):\n    if idx < 0 or idx >= len(sequence):\n        return default\n    else:\n        return sequence[idx]\n\n# getting information on the neighbors of the pair\ndef add_pair_feats(df):\n    nseq = 5\n    feats_list = []\n    for idx, row in df.iterrows():\n        length = len(row[\"structure\"])\n        pair_idxs = {}\n        idx_stack = deque()\n        for i, struct in enumerate(row[\"structure\"]):\n            if struct == \"(\":\n                idx_stack.append(i)\n            elif struct == \")\":\n                start = idx_stack.pop()\n                pair_idxs[start] = i\n                pair_idxs[i] = start\n\n        feats = defaultdict(list)\n        for i in range(length):\n            pair_idx = pair_idxs.get(i)\n            if pair_idx is not None:\n                for k in range(-nseq, nseq+1):\n                    if k == 0:\n                        continue\n                    feats[f\"pair_seq_{k}\"].append(\n                        get_list_item(row[\"sequence\"], pair_idx + k)   # basically index access with default value if out of bounds\n                    )\n\n                    feats[f\"pair_strct_{k}\"].append(\n                        get_list_item(row[\"structure\"], pair_idx + k)\n                    )\n\n                    feats[f\"pair_loop_{k}\"].append(\n                        get_list_item(row[\"predicted_loop_type\"], pair_idx + k)\n                    )\n\n            else:\n                for k in range(-nseq, nseq+1):\n                    if k == 0:\n                        continue\n                    feats[f\"pair_seq_{k}\"].append(\"-\")\n                    feats[f\"pair_strct_{k}\"].append(\"-\")\n                    feats[f\"pair_loop_{k}\"].append(\"-\")\n            #feats_list.append(feats)\n        for k in feats:\n            feats[k] = \"\".join(feats[k])\n        feats_list.append(dict(feats))\n    return pd.DataFrame(feats_list)\n\ndef mk_feats(train,test):\n    # The value of bpps of the pair - the strength of the pair.\n    train['pair_pp'] = train[['id','structure']].apply(mk_pair_prob, axis=1)\n    test['pair_pp'] = test[['id','structure']].apply(mk_pair_prob, axis=1)\n    train['pair_pp'], test['pair_pp'] = norm_arr(train['pair_pp'], test['pair_pp'])\n    \n    # paired sequence\n    train['pair_acgu'] = train[['sequence','structure']].apply(mk_pair_acgu, axis=1)\n    test['pair_acgu'] = test[['sequence','structure']].apply(mk_pair_acgu, axis=1)\n    \n    # the set of the pair (CG or GU or AU or None)\n    train['pair_acgu2'] = train[['sequence','structure']].apply(mk_pair_acgu2, axis=1)\n    test['pair_acgu2'] = test[['sequence','structure']].apply(mk_pair_acgu2, axis=1)\n    \n    # sum\n    train['bpps_sum'] = read_bpps_sum(train)\n    test['bpps_sum'] = read_bpps_sum(test)\n    train['bpps_sum'], test['bpps_sum'] = norm_arr(train['bpps_sum'], test['bpps_sum'])\n    \n    # max\n    train['bpps_max'] = read_bpps_max(train)\n    test['bpps_max'] = read_bpps_max(test)\n    train['bpps_max'], test['bpps_max'] = norm_arr(train['bpps_max'], test['bpps_max'])\n    \n    # non zero number\n    train['bpps_nb'] = read_bpps_nb(train)\n    test['bpps_nb'] = read_bpps_nb(test)\n    train['bpps_nb'], test['bpps_nb'] = norm_arr(train['bpps_nb'], test['bpps_nb'])\n    \n    # more than 0.05 number\n    train['bpps_nb005'] = read_bpps_nb(train, 0.05)\n    test['bpps_nb005'] = read_bpps_nb(test, 0.05)\n    train['bpps_nb005'], test['bpps_nb005'] = norm_arr(train['bpps_nb005'], test['bpps_nb005'])\n    \n    # bpps_sum-max\n    train['bpps_sum-max'] = train['bpps_sum'] - train['bpps_max']\n    test['bpps_sum-max'] = test['bpps_sum'] - test['bpps_max']\n    train['bpps_sum-max'], test['bpps_sum-max'] = norm_arr(train['bpps_sum-max'], test['bpps_sum-max'])\n    \n    # Information on the neighbors of the pair\n    train = pd.concat([train, add_pair_feats(train)], axis=1)\n    test = pd.concat([test, add_pair_feats(test)], axis=1)\n    \n    return train, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bpps_engine = ''\ntrain = pd.read_json('../input/stanford-covid-vaccine/train.json', lines=True)\ntest = pd.read_json('../input/stanford-covid-vaccine/test.json', lines=True)\n\ntrain, test = mk_feats(train,test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(1).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}