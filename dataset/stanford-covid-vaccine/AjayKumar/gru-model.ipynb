{"cells":[{"metadata":{},"cell_type":"markdown","source":"Forked from https://www.kaggle.com/xhlulu/openvaccine-simple-gru-model/notebook?scriptVersionId=42525616"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport json\nimport tensorflow.keras.layers as L\nimport tensorflow as tf\nimport plotly.express as px","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define helper functions and useful vars"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This will tell us the columns we are predicting\npred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gru_layer(hidden_dim, dropout):\n    return L.Bidirectional(L.GRU(hidden_dim, dropout=dropout, return_sequences=True))\n\ndef build_model(seq_len=107, pred_len=68, dropout=0.5, embed_dim=100, hidden_dim=128):\n    inputs = L.Input(shape=(seq_len, 3))\n\n    embed = L.Embedding(input_dim=len(token2int), output_dim=embed_dim)(inputs)\n    reshaped = tf.reshape(\n        embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3]))\n\n    hidden = gru_layer(hidden_dim, dropout)(reshaped)\n    hidden = gru_layer(hidden_dim, dropout)(hidden)\n    hidden = gru_layer(hidden_dim, dropout)(hidden)\n    \n    # Since we are only making predictions on the first part of each sequence, we have\n    # to truncate it\n    truncated = hidden[:, :pred_len]\n    \n    out = L.Dense(5, activation='linear')(truncated)\n\n    model = tf.keras.Model(inputs=inputs, outputs=out)\n\n    model.compile(tf.keras.optimizers.Adam(), loss='mse')\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\n\ndef preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type']):\n    return np.transpose(\n        np.array(\n            df[cols]\n            .applymap(lambda seq: [token2int[x] for x in seq])\n            .values\n            .tolist()\n        ),\n        (0, 2, 1)\n    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load and preprocess data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_json('/kaggle/input/stanford-covid-vaccine/train.json', lines=True)\ntest = pd.read_json('/kaggle/input/stanford-covid-vaccine/test.json', lines=True)\nsample_df = pd.read_csv('/kaggle/input/stanford-covid-vaccine/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_inputs = preprocess_inputs(train)\ntrain_labels = np.array(train[pred_cols].values.tolist()).transpose((0, 2, 1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build and train model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# history = model.fit(\n#     train_inputs, train_labels, \n#     batch_size=64,\n#     epochs=100,\n#     callbacks=[\n#         tf.keras.callbacks.ReduceLROnPlateau(),\n#         tf.keras.callbacks.ModelCheckpoint('model.h5')\n#     ],\n#     validation_split=0.05\n# )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fig = px.line(\n#     history.history, y=['loss', 'val_loss'], \n#     labels={'index': 'epoch', 'value': 'Mean Squared Error'}, \n#     title='Training History')\n# fig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict on test set"},{"metadata":{},"cell_type":"markdown","source":"Public and private sets have different sequence lengths, so we will preprocess them separately and load models of different tensor shapes."},{"metadata":{"trusted":true},"cell_type":"code","source":"# public_df = test.query(\"seq_length == 107\").copy()\n# private_df = test.query(\"seq_length == 130\").copy()\n\n# public_inputs = preprocess_inputs(public_df)\n# private_inputs = preprocess_inputs(private_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Caveat: The prediction format requires the output to be the same length as the input,\n# # although it's not the case for the training data.\n# model_short = build_model(seq_len=107, pred_len=107)\n# model_long = build_model(seq_len=130, pred_len=130)\n\n# model_short.load_weights('model.h5')\n# model_long.load_weights('model.h5')\n\n# public_preds = model_short.predict(public_inputs)\n# private_preds = model_long.predict(private_inputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(public_preds.shape, private_preds.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Post-processing and submit"},{"metadata":{},"cell_type":"markdown","source":"For each sample, we take the predicted tensors of shape (107, 5) or (130, 5), and convert them to the long format (i.e. $629 \\times 107, 5$ or $3005 \\times 130, 5$):"},{"metadata":{"trusted":true},"cell_type":"code","source":"# preds_ls = []\n\n# for df, preds in [(public_df, public_preds), (private_df, private_preds)]:\n#     for i, uid in enumerate(df.id):\n#         single_pred = preds[i]\n\n#         single_df = pd.DataFrame(single_pred, columns=pred_cols)\n#         single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n#         preds_ls.append(single_df)\n\n# preds_df = pd.concat(preds_ls)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission = sample_df[['id_seqpos']].merge(preds_df, on=['id_seqpos'])\n# submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}