{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Uninstall fastai for solving dependence problems\n!pip uninstall fastai -y\n# Install packages without internet\n!pip install ../input/packages/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl\n!pip install ../input/packages/torchvision-0.8.2-cp37-cp37m-manylinux1_x86_64.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\nsys.path.append('../input/pytorch-optimizers/')\nsys.path.append('../input/repvgg/')\nsys.path.append('../input/repvggmodels/')\nsys.path.append('../input/bi-tempered-loss/')\n\nimport timm\nimport bi_tempered_loss\nfrom torch_optimizer.radam import RAdam\nfrom repvgg import RepVGG, create_RepVGG_B3g4, create_RepVGG_B3, repvgg_model_convert","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport cv2\nimport time\nimport copy\nimport random\nimport joblib\nimport sklearn\nimport warnings\nimport multiprocessing\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom glob import glob\nfrom tqdm import tqdm\nfrom pathlib import Path\nfrom datetime import datetime\nfrom skimage import io\nfrom sklearn import metrics\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, log_loss\nfrom IPython.display import display\nfrom catalyst.data.sampler import BalanceClassSampler\n\nimport torch\nimport torch.nn.functional as F\nimport torchvision\nfrom torch import nn\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.utils.data.sampler import SequentialSampler, RandomSampler\nfrom torch.nn.modules.loss import _WeightedLoss\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torchvision import models\nfrom torchvision import transforms\n\nfrom albumentations.pytorch import ToTensor, ToTensorV2\nfrom albumentations import (\n    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout,\n    ShiftScaleRotate, CenterCrop, Resize)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Move some weights to torch cache dir\ncache_dir = os.path.expanduser(os.path.join('~', '.cache/torch/hub/checkpoints'))\nif not os.path.exists(cache_dir):\n    os.makedirs(cache_dir)\nmodels_dir = os.path.join(cache_dir, 'models')\nif not os.path.exists(models_dir):\n    os.makedirs(models_dir)\n    \n!cp ../input/pretrained-pytorch-models/* ~/.cache/torch/hub/checkpoints/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \nseed_everything(42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CFG = {\n    'fold_num': 3,\n    'seed'    : 42,\n    'img_size': 400,\n    'epochs'  : 17,\n    'train_bs': 16,\n    'valid_bs': 32,\n    'T_0'     : 20,\n    'lr'      : 0.001,\n    'momentum': 0.9,\n    'min_lr'  : 1e-6,\n    'weight_decay'   : 1e-4,\n    'accum_iter'     : 2, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n    'early_stopping' : 10,\n    'verbose_step'   : 1,\n    'num_workers'    : multiprocessing.cpu_count(),\n    'device'         : \"cuda:0\" if torch.cuda.is_available() else \"cpu\"}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train      = pd.read_csv('../input/cassava-noised-label-data/noised_label_data.csv')\nsubmission = pd.read_csv('../input/cassava-leaf-disease-classification/sample_submission.csv')\ndisplay(train.head(2))\ndisplay(submission.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\ntrain.label.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_img(path):\n    im_bgr = cv2.imread(path)\n    im_rgb = im_bgr[:, :, ::-1]\n    return im_rgb\n\ndef show_images(names):\n    c = 4\n    r = int(np.ceil(len(names) / c))\n    fig, axes = plt.subplots(nrows=r, ncols=c, figsize=(14, len(names)-3))\n    cnt = 0\n    for i in range(r):\n        for j in range(c):\n            if len(names)<=cnt: continue\n            img = get_img(f\"../input/cassava-leaf-disease-classification/train_images/{names[cnt]}\")\n            axes[i, j].imshow(img)\n            axes[i, j].axis(\"off\")\n            cnt += 1\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_num = 8\n# Label 0 with low prob\nshow_images(list(train[train.label==0].sort_values(\"label_0\").iloc[:show_num,0]))\n# Label 0 with high prob\nshow_images(list(train[train.label==0].sort_values(\"label_0\").iloc[-show_num:,0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Label 1 with low prob\nshow_images(list(train[train.label==1].sort_values(\"label_1\").iloc[:show_num,0]))\n# Label 1 with high prob\nshow_images(list(train[train.label==1].sort_values(\"label_1\").iloc[-show_num:,0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Label 2 with low prob\nshow_images(list(train[train.label==2].sort_values(\"label_2\").iloc[:show_num,0]))\n# Label 2 with high prob\nshow_images(list(train[train.label==2].sort_values(\"label_2\").iloc[-show_num:,0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Label 3 with low prob\nshow_images(list(train[train.label==3].sort_values(\"label_3\").iloc[:show_num,0]))\n# Label 3 with high prob\nshow_images(list(train[train.label==3].sort_values(\"label_3\").iloc[-show_num:,0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Label 4 with low prob\nshow_images(list(train[train.label==4].sort_values(\"label_4\").iloc[:show_num,0]))\n# Label 4 with high prob\nshow_images(list(train[train.label==4].sort_values(\"label_4\").iloc[-show_num:,0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preparation for labels with smooth"},{"metadata":{"trusted":true},"cell_type":"code","source":"def do_label_smooth(df, label, thr):\n    df = df.copy()\n    smooth_labels    = []\n    not_target_label = np.delete(np.arange(5), label)\n    for row in np.array(df.loc[(df.label==label)&(df[f\"label_{label}\"] < thr)])[:,2:]:\n        r = row.copy()\n        d = (thr - row[label]) / 4\n        r[not_target_label] = row[not_target_label] - d\n        r[label] = thr\n        while True:\n            if 0 <= r[not_target_label].min():\n                break\n            r[not_target_label] = np.abs(r[not_target_label])\n            d = (sum(r) - 1) / 4\n            r[not_target_label] = r[not_target_label] - d\n        smooth_labels.append(r.tolist())\n    df.loc[(df.label==label)&(df[f\"label_{label}\"] < thr), [f\"label_{l}\" for l in range(5)]] = smooth_labels\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thr = 0.6\nfor label in range(5):\n    train = do_label_smooth(train, label, thr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for label in range(5):\n    train.loc[(train[\"label\"]==label)&(train[f\"label_{label}\"]>thr), f\"label_{label}\"] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thr = 0.9\nnum_classes     = 5\nlabel_smoothing = 0.1\ntarget_label    = [f\"label_{l}\" for l in range(5)]\nfor label in range(5):\n    labels = np.array(train.loc[train[f\"label_{label}\"]>thr, target_label])\n    labels = (1 - num_classes / (num_classes - 1) * label_smoothing) * labels + label_smoothing / (num_classes - 1)\n    train.loc[train[f\"label_{label}\"]>thr, target_label] = labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(14, 10))\nfor r in range(5):\n    m = round(train[train.label==r].shape[0],-2)\n    for c in range(5):\n        train[train.label==r][f\"label_{c}\"].hist(ax=axes[r,c])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train with pre-trained weights"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CassavaDataset(Dataset):\n    def __init__(self, df, data_root, \n                 transforms=None, \n                 output_label=True, \n                 one_hot_label=False,\n                 do_fmix=False, \n                 fmix_params={'alpha'      : 1., \n                              'decay_power': 3., \n                              'shape'      : (CFG['img_size'], CFG['img_size']),\n                              'max_soft'   : True, \n                              'reformulate': False},\n                 do_cutmix=False,\n                 cutmix_params={'alpha': 1}):\n        super().__init__()\n        self.df = df.reset_index(drop=True).copy()\n        self.transforms  = transforms\n        self.data_root   = data_root\n        self.do_fmix     = do_fmix\n        self.fmix_params = fmix_params\n        self.do_cutmix   = do_cutmix\n        self.cutmix_params = cutmix_params\n        self.output_label  = output_label\n        self.one_hot_label = one_hot_label\n        \n        if output_label:\n            # Get one hot labels\n            self.soft_labels = self.df[[f\"label_{l}\" for l in range(5)]].values\n            self.hard_labels = self.df.label.values\n            \n    def __len__(self):\n        return self.df.shape[0]\n    \n    def __getitem__(self, index: int):\n        \n        # get labels\n        if self.output_label:\n            soft_target = self.soft_labels[index]\n            hard_target = self.hard_labels[index]\n        img = get_img(f\"{self.data_root}/{self.df.loc[index]['image_id']}\")\n        \n        if self.transforms:\n            img = self.transforms(image=img)['image']\n        \n        if self.output_label:\n            return img, soft_target, hard_target\n        else:\n            return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_train_transforms():\n    return Compose([\n            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n            Transpose(p=0.5),\n            HorizontalFlip(p=0.5),\n            VerticalFlip(p=0.5),\n            ShiftScaleRotate(p=0.5),\n            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            CoarseDropout(p=0.5),\n            Cutout(p=0.5),\n            ToTensorV2(p=1.0)], p=1)\n  \ndef get_valid_transforms():\n    return Compose([\n            CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n            Resize(CFG['img_size'], CFG['img_size']),\n            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n            ToTensorV2(p=1.0)], p=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#backbone = models.resnet50(pretrained=False)\n#backbone.load_state_dict(torch.load(\"../input/byol-model/byol.pt\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"backbone = create_RepVGG_B3g4(deploy=False)\n#backbone.load_state_dict(torch.load('../input/repvgg/RepVGG-B3g4-200epochs-train.pth', map_location=torch.device(\"cpu\")))\nbackbone.load_state_dict(torch.load('../input/repvgg/RepVGG-B3g4-200epochs-train.pth'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class FFN(nn.Module):\n    def __init__(self):\n        super(FFN, self).__init__()\n        self.backbone = backbone\n        self.lr1      = nn.Linear(1000, 256)\n        self.relu     = nn.ReLU()\n        self.dropout  = nn.Dropout(0.5)\n        self.lr2      = nn.Linear(256, 5)\n        \n    def forward(self, x):\n        x = self.backbone(x)\n        x = self.relu(self.lr1(x))\n        x = self.dropout(x)\n        x = self.lr2(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_dataloader(df, trn_idx, val_idx, data_root='../input/cassava-leaf-disease-classification/train_images/'):\n    train_   = df.loc[trn_idx,:].reset_index(drop=True)\n    valid_   = df.loc[val_idx,:].reset_index(drop=True)\n    train_ds = CassavaDataset(train_, data_root, transforms=get_train_transforms(), output_label=True, one_hot_label=False, do_fmix=False, do_cutmix=False)\n    valid_ds = CassavaDataset(valid_, data_root, transforms=get_valid_transforms(), output_label=True)\n    train_loader = torch.utils.data.DataLoader(train_ds,\n                                               batch_size=CFG['train_bs'],\n                                               pin_memory=False,\n                                               drop_last=False,\n                                               shuffle=True,\n                                               num_workers=CFG['num_workers'])\n    val_loader = torch.utils.data.DataLoader(valid_ds,\n                                             batch_size=CFG['valid_bs'],\n                                             num_workers=CFG['num_workers'],\n                                             shuffle=False,\n                                             pin_memory=False)\n    return train_loader, val_loader","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SoftLabelLoss(nn.Module):\n    def __init__(self, dim=-1):\n        super(SoftLabelLoss, self).__init__()\n        self.dim = dim\n\n    def forward(self, pred, target):\n        pred = pred.log_softmax(dim=self.dim)\n        return torch.mean(torch.sum(-target * pred, dim=self.dim))\n    \nclass TemperedLoss(nn.Module):\n    def __init__(self, t1=1, t2=1):\n        super(TemperedLoss, self).__init__()\n        self.t1  = t1\n        self.t2  = t2\n\n    def forward(self, pred, target):\n        loss = bi_tempered_loss.bi_tempered_logistic_loss(pred, target, t1=self.t1, t2=self.t2)\n        return torch.mean(loss)\n    \ndef sgd_optimizer(model, lr, momentum, weight_decay):\n    params = []\n    for key, value in model.named_parameters():\n        if not value.requires_grad:\n            continue\n        apply_weight_decay = weight_decay\n        apply_lr = lr\n        if 'bias' in key or 'bn' in key:\n            apply_weight_decay = 0\n        if 'bias' in key:\n            apply_lr = 2 * lr       #   Just a Caffe-style common practice. Made no difference.\n        params += [{'params': [value], 'lr': apply_lr, 'weight_decay': apply_weight_decay}]\n    optimizer = torch.optim.SGD(params, lr, momentum=momentum)\n    return optimizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device, scheduler=None, schd_batch_update=False):\n    model.train()\n\n    t = time.time()\n    running_loss = None\n\n    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n    for step, (imgs, soft_labels, hard_labels) in pbar:\n        imgs = imgs.to(device).float()\n        image_labels = soft_labels.to(device).float()\n\n        with autocast():\n            image_preds = model(imgs)\n            loss = loss_fn(image_preds, image_labels)\n            scaler.scale(loss).backward()\n\n            if running_loss is None:\n                running_loss = loss.item()\n            else:\n                running_loss = running_loss * .99 + loss.item() * .01\n\n            if ((step + 1) %  CFG['accum_iter'] == 0) or ((step + 1) == len(train_loader)):\n                # may unscale_ here if desired (e.g., to allow clipping unscaled gradients)\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad() \n                if scheduler is not None and schd_batch_update:\n                    scheduler.step()\n\n            if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(train_loader)):\n                description = f'epoch {epoch} loss: {running_loss:.4f}'\n                pbar.set_description(description)\n                \n    if scheduler is not None and not schd_batch_update:\n        scheduler.step()\n        \ndef valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False):\n    model.eval()\n\n    t = time.time()\n    loss_sum   = 0\n    sample_num = 0\n    image_preds_all   = []\n    image_targets_all = []\n    \n    pbar = tqdm(enumerate(val_loader), total=len(val_loader))\n    for step, (imgs, soft_labels, hard_labels) in pbar:\n        imgs = imgs.to(device)\n        image_labels = soft_labels.to(device).float()\n        \n        image_preds = model(imgs)\n        image_preds_all   += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n        image_targets_all += [np.array(hard_labels)]\n        \n        loss = loss_fn(image_preds, image_labels)\n        loss_sum   += loss.item()*image_labels.shape[0]\n        sample_num += image_labels.shape[0]  \n\n        if ((step + 1) % CFG['verbose_step'] == 0) or ((step + 1) == len(val_loader)):\n            description = f'epoch {epoch} loss: {loss_sum/sample_num:.4f}'\n            pbar.set_description(description)\n            \n    image_preds_all   = np.concatenate(image_preds_all)\n    image_targets_all = np.concatenate(image_targets_all)\n    acc = (image_preds_all==image_targets_all).mean()\n    print('validation multi-class accuracy = {:.4f}'.format(acc))\n    \n    if scheduler is not None:\n        if schd_loss_update:\n            scheduler.step(loss_sum/sample_num)\n        else:\n            scheduler.step()\n    return acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folds = StratifiedKFold(n_splits=CFG['fold_num'], shuffle=True, random_state=CFG['seed']).split(np.arange(train.shape[0]), train.label.values)\n    \nfor fold, (trn_idx, val_idx) in enumerate(folds):\n    print('Training with {} started'.format(fold))\n    print(len(trn_idx), len(val_idx))\n    train_loader, val_loader = prepare_dataloader(train, trn_idx, val_idx, data_root='../input/cassava-leaf-disease-classification/train_images/')\n\n    not_improved_cnt = 0\n    best_acc = 0\n    device   = torch.device(CFG['device'])\n    model    = FFN()\n    \n    backbone.to(device)\n    model.to(device)\n    scaler    = GradScaler()\n    #optimizer = RAdam(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n    #optimizer = torch.optim.Adam(model.parameters(), lr=CFG['lr'], weight_decay=CFG['weight_decay'])\n    #scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CFG['T_0'], T_mult=1, eta_min=CFG['min_lr'], last_epoch=-1)\n    optimizer = sgd_optimizer(model, CFG['lr'], CFG['momentum'], CFG['weight_decay'])\n    scheduler = CosineAnnealingLR(optimizer=optimizer, T_max=CFG['T_0'])\n\n    #loss_tr = SoftLabelLoss().to(device)\n    #loss_fn = SoftLabelLoss().to(device)\n    loss_tr = TemperedLoss(t1=0.8, t2=1.2).to(device)\n    loss_fn = TemperedLoss(t1=0.8, t2=1.2).to(device)\n\n    for epoch in range(CFG['epochs']):\n        train_one_epoch(epoch, model, loss_tr, optimizer, train_loader, device, scheduler=scheduler, schd_batch_update=False)\n\n        with torch.no_grad():\n            acc = valid_one_epoch(epoch, model, loss_fn, val_loader, device, scheduler=None, schd_loss_update=False)\n\n        if best_acc < acc:\n            print('Best model will be saved to output path after completing this fold')\n            converted_model = copy.deepcopy(model)\n            best_acc = acc\n            not_improved_cnt = 0\n        elif CFG['early_stopping'] == not_improved_cnt:\n            print(\"Met early stopping.\")\n            break\n        else:\n            not_improved_cnt += 1  \n            \n    converted_model.backbone = repvgg_model_convert(converted_model.backbone, create_RepVGG_B3g4)\n    torch.save(converted_model.state_dict(), f'cnn_with_noise_label_fold_{fold}')\n    \n    del model, optimizer, train_loader, val_loader, scaler\n    torch.cuda.empty_cache()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}