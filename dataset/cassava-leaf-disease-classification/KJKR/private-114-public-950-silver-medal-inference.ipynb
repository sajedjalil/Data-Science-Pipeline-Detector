{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Version Control\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\npackage_path = '../input/pytorch-image-models/pytorch-image-models-master'\nsys.path.append(package_path)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport gc\nimport time\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport random\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2, ToTensor\nimport albumentations as alb\nimport torchvision.models as tv_models\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\nimport cv2\nimport timm\n\nimport warnings\nwarnings.simplefilter('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using %s\" % (str(device).upper()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    print(\"SEED SET TO : %d\" % seed)\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 32\nNUM_SPLITS = 5\nIMG_SIZE = (512, 512)\nEPOCHS_USED = [1, 2, 3, 4, 5]\nTARGET_SIZE = 5\nTTA = 1\nSEED = 420\nTEST_PATH = \"../input/cassava-leaf-disease-classification/test_images/\"\nseed_everything(SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/cassava-leaf-disease-classification/train.csv\")\nsample_sub = pd.read_csv(\"../input/cassava-leaf-disease-classification/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Cassava_dataset:\n    def __init__(self, df, transforms, img_size, img_path, is_train=True):\n        self.transforms = transforms\n        self.df = df\n        self.img_size = img_size\n        self.is_train = is_train\n        self.img_path = img_path\n        \n    def __getitem__(self, index):\n        img_path = self.img_path + str(self.df[\"image_id\"].loc[index])\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transforms:\n            image = self.transforms(image=image)['image']\n            \n        if self.is_train:\n            label = self.df[\"label\"].loc[index]\n            return {\n                \"image\": image,\n                \"label\": torch.tensor(label, dtype=torch.long)\n            }\n        else:\n            return {\n                \"image\": image\n            }\n        \n    def __len__(self):\n        return len(self.df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class EffNetb1(torch.nn.Module):\n    def __init__(self,):\n        super(EffNetb1, self).__init__()\n        self.model = timm.create_model(\"tf_efficientnet_b1_ns\", pretrained=False)\n        n_features = self.model.classifier.in_features\n        self.fc = nn.Linear(n_features, TARGET_SIZE)\n        self.model.classifier = nn.Identity()\n        \n    def forward(self, x):\n        x = self.model(x)\n        x = self.fc(x)\n        return x\n      \ndef res_spoon():\n    model = timm.create_model(\"resnext50_32x4d\", pretrained=False)\n    in_features = model.fc.in_features\n    model.fc = nn.Linear(in_features=in_features, out_features=TARGET_SIZE)\n    return model\n\ndef eff_spoon():\n    model = timm.create_model(\"tf_efficientnet_b3_ns\", pretrained=False)\n    in_features = model.classifier.in_features\n    model.classifier = nn.Linear(in_features=in_features, out_features=TARGET_SIZE)\n    return model\n    \nclass Resnext50(nn.Module):\n    def __init__(self, model_name='resnext50_32x4d', pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        n_features = self.model.fc.in_features\n        self.model.fc = nn.Linear(n_features, TARGET_SIZE)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x\n\nclass EffNetb3(torch.nn.Module):\n    def __init__(self):\n        super(EffNetb3, self).__init__()\n        self.model = timm.create_model(\"tf_efficientnet_b3_ns\", pretrained=False)\n        n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Sequential(\n            nn.Linear(n_features, 1000),\n            nn.Dropout(0.2),\n            nn.Linear(1000, TARGET_SIZE)\n        )\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_transforms_vanilla():\n    return alb.Compose([\n        alb.Resize(height=IMG_SIZE[0], width=IMG_SIZE[0]),\n        alb.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n        ToTensorV2(p=1.0),\n    ], p=1.)\n\ndef get_transforms_effnet():\n    return alb.Compose([\n        alb.CenterCrop(IMG_SIZE[0], IMG_SIZE[0], p=1.),\n        alb.Resize(height=IMG_SIZE[0], width=IMG_SIZE[0]),\n        alb.Transpose(p=0.5),\n        alb.HorizontalFlip(p=0.5),\n        alb.VerticalFlip(p=0.5),\n        alb.ShiftScaleRotate(p=0.5),\n        alb.HueSaturationValue(hue_shift_limit=0.3, sat_shift_limit=0.3, val_shift_limit=0.3, p=0.6),\n        alb.RandomBrightnessContrast(brightness_limit=(-0.1,0.2), contrast_limit=(-0.1, 0.2), p=0.5),\n        alb.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n        ToTensorV2(p=1.0),\n    ], p=1.)\n\ndef get_transforms_resnet50():\n    return alb.Compose([\n        alb.CenterCrop(IMG_SIZE[0], IMG_SIZE[0], p=1.),\n        alb.Resize(height=IMG_SIZE[0], width=IMG_SIZE[0]),\n        alb.Transpose(p=0.5),\n        alb.HorizontalFlip(p=0.5),\n        alb.VerticalFlip(p=0.5),\n        alb.ShiftScaleRotate(p=0.6),\n        alb.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.3, val_shift_limit=0.3, p=0.4),\n        alb.RandomBrightnessContrast(brightness_limit=(-0.1,0.2), contrast_limit=(-0.1, 0.2), p=0.5),\n        alb.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n        ToTensorV2(p=1.0),\n    ], p=1.)\n\n\ndef get_transforms_spoon_b3():\n    return alb.Compose([\n            alb.Resize(height=IMG_SIZE[0], width=IMG_SIZE[0]),\n            alb.Cutout(num_holes=1, max_h_size=50, max_w_size=50),\n            alb.Transpose(p=0.5),\n            alb.HorizontalFlip(p=0.5),\n            alb.VerticalFlip(p=0.5),\n            alb.ShiftScaleRotate(p=0.5),\n            alb.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.3, val_shift_limit=0.3, p=0.5),\n            alb.RandomBrightnessContrast(brightness_limit=(-0.1,0.2), contrast_limit=(-0.1, 0.2), p=0.5),\n            alb.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n            ToTensor(),\n        ], p=1.)\n\ndef get_transforms_spoon_r50():\n    return alb.Compose([\n            alb.Resize(height=IMG_SIZE[0], width=IMG_SIZE[0]),\n            alb.Cutout(num_holes=1, max_h_size=50, max_w_size=50),\n            alb.Transpose(p=0.5),\n            alb.HorizontalFlip(p=0.5),\n            alb.VerticalFlip(p=0.5),\n            alb.ShiftScaleRotate(p=0.5),\n            alb.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.3, val_shift_limit=0.3, p=0.5),\n            alb.RandomBrightnessContrast(brightness_limit=(-0.1,0.2), contrast_limit=(-0.1, 0.2), p=0.5),\n            alb.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n            ToTensor(),\n        ], p=1.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### NO TTA ####\ndef inference_func(model, data_loader, device):\n    \"\"\"\n    Make predictions for different models\n    \"\"\"\n    \n    model.eval()\n    image_preds_all = []\n    \n    for step, data in enumerate(data_loader):\n        x = data[\"image\"].to(device)\n        image_preds = model(x)\n        image_preds_all += [image_preds.detach().cpu().numpy()]\n        \n    image_preds_all = np.concatenate(image_preds_all, axis=0)\n    return image_preds_all","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_model_params(model, model_path, model_list, fold, contrib):\n    if contrib == \"kjs\":\n        model.load_state_dict(torch.load(model_path + model_list[fold]))\n    if contrib == \"spoon\":\n        model_back = model_list[0].split(\"-\")[0]\n        if model_back == \"tf_efficientnet_b3_ns\":\n            model.load_state_dict(torch.load(model_path + model_list[fold]))\n        else:\n            state_dict = torch.load(model_path + model_list[fold])['model']\n            state_dict = {k[13:] if k.startswith('module.model.') else k: state_dict[k] for k in state_dict.keys()}  \n            model.load_state_dict(state_dict)\n            \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def MMI(model_p, device, model_path, transforms, model_name, fold_used, model_list, contrib):\n    \"\"\"\n    Input : *args \\n\n    Ouput : N-fold predictions\n    \"\"\"\n    \n    print(\"Making prediction for %s\" % (model_name))\n    \n    model_p.to(device)\n    test_preds = []\n    \n    for fold in range(len(fold_used)):\n        test_dataset = Cassava_dataset(sample_sub,\n                                       transforms=transforms,\n                                       img_size=IMG_SIZE,\n                                       img_path=TEST_PATH,\n                                       is_train=False)\n\n        test_DataLoader = torch.utils.data.DataLoader(test_dataset,\n                                                      BATCH_SIZE,\n                                                      drop_last=False,\n                                                      num_workers=8,\n                                                      pin_memory=True,\n                                                      shuffle=False)\n        \n        model_p = load_model_params(model=model_p,\n                                    model_path=model_path,\n                                    model_list=model_list,\n                                    fold=fold,\n                                    contrib=contrib)\n        \n            \n        model_p.eval()\n        print(\"Making Inference %s\" % (model_list[fold]))\n        with torch.no_grad():\n            for i in range(TTA):\n                print(\"TTA step : %d\" % i)\n                test_preds += [inference_func(model_p, test_DataLoader, device)]\n     \n    # Garbage Collection Function\n    del model_p, test_DataLoader\n    gc.collect()\n    torch.cuda.empty_cache()\n    \n    return np.mean(test_preds, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Effnetb1\nmodel_list = [\"effnet_b1_512_seed_5_fold_%d.pth\" % (i + 1) for i in range(len(EPOCHS_USED))]\nmodel = EffNetb1()\nb1_k = MMI(model_p=model,\n          device=device,\n          model_path=\"../input/cassava-effnet-5fold-full/\",\n          transforms=get_transforms_effnet(),\n          model_name=\"Effnet-b1\",\n          fold_used=EPOCHS_USED,\n          model_list=model_list,\n          contrib=\"kjs\")\n\nprint(\"\\n\")\nprint(\"PREDS : \", b1_k[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Effnetb1\nmodel_list = [\"resnext50_32x4d-image512-fold%d_5.pth\" % (i) for i in range(len(EPOCHS_USED))]\nmodel = Resnext50()\nr50_k = MMI(model_p=model,\n          device=device,\n          model_path=\"../input/spoon-kjs-cassava-model-weights/best_kjs_cv/\",\n          transforms=get_transforms_resnet50(),\n          model_name=\"resnext50_32x4d\",\n          fold_used=EPOCHS_USED,\n          model_list=model_list,\n          contrib=\"kjs\") \n\nprint(\"\\n\")\nprint(\"PREDS : \", r50_k[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"model_list = [\"resnext50_32x4d-image512-fold%d_5.pth\" % (i) for i in range(len(EPOCHS_USED))]\nmodel = res_spoon()\nr50_p = MMI(model_p=model,\n          device=device,\n          model_path=\"../input/spoon-kjs-cassava-model-weights/best_spoon_cv/\",\n          transforms=get_transforms_vanilla(),\n          model_name=\"resnext50_32x4d\",\n          fold_used=EPOCHS_USED,\n          model_list=model_list ,\n          contrib=\"spoon\")\n\nprint(\"\\n\")\nprint(\"PREDS : \", r50_p[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_list = [\"tf_efficientnet_b3_ns-image512-fold%d_5.pth\" % (i) for i in range(len(EPOCHS_USED))]\nmodel = eff_spoon()\nb3_p = MMI(model_p=model,\n          device=device,\n          model_path=\"../input/spoon-kjs-cassava-model-weights/best_spoon_cv/\",\n          transforms=get_transforms_spoon_b3(),\n          model_name=\"tf_efficientnet_b3_ns\",\n          fold_used=EPOCHS_USED,\n          model_list=model_list ,\n          contrib=\"spoon\")\n\nprint(\"\\n\")\nprint(\"PREDS : \", b3_p[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sub = sample_sub.copy()\nensemble = (\n            (b1_k  * 0.25) +\n            (r50_k * 0.15) + \n            (b3_p  * 0.25) +\n            (r50_p * 0.35)\n           )\n\nprint(ensemble[0])\ntest_sub[\"label\"] = np.argmax(ensemble, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sub.to_csv(\"submission.csv\", index=False)\nprint(\"KERNEL RUN COMPLETED\")\ntest_sub.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}