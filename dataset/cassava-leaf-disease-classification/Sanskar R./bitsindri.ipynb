{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"work_dir=\"../input/cassava-leaf-disease-classification\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_path=\"../input/cassava-leaf-disease-classification/train_images\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport json\nimport sys\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torchvision\nfrom torch.utils.data import DataLoader,Dataset\nimport albumentations as A\nfrom PIL import Image,ImageFile\nfrom tqdm import tqdm_notebook as tqdm\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport cv2\nfrom sklearn import model_selection,metrics\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.optim.lr_scheduler as lr\nimport torchvision.models as mdl\nimport warnings\nwarnings.simplefilter(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir(work_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(work_dir+\"/label_num_to_disease_map.json\", 'r') as file:\n    class_labels = json.load(file)\n    \nclass_labels\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"../input/cassava-leaf-disease-classification/train.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**IMAGE VISUALIZATION**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\ndata_sample=df.sample(16).reset_index(drop=True)\nfor i in range(16):\n    plt.subplot(4,4,i+1)\n    img = cv2.imread(work_dir+ \"/train_images/\" + data_sample.image_id[i])\n    image = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) \n    plt.axis(\"off\")\n    plt.imshow(image)\n    plt.title(class_labels.get(str(data_sample.label[i])))\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\ndata_sample1=df[df.label==0].sample(8).reset_index(drop=True)\nfor i in range(8):\n    plt.subplot(2,4,i+1)\n    img = cv2.imread(work_dir+ \"/train_images/\" + data_sample1.image_id[i])\n    image = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) \n    plt.axis(\"off\")\n    plt.imshow(image)\n    plt.title(class_labels.get(str(data_sample1.label[i])))\nplt.tight_layout()\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\ndata_sample2=df[df.label==1].sample(8).reset_index(drop=True)\nfor i in range(8):\n    plt.subplot(2,4,i+1)\n    img = cv2.imread(work_dir+ \"/train_images/\" + data_sample2.image_id[i])\n    image = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) \n    plt.axis(\"off\")\n    plt.imshow(image)\n    plt.title(class_labels.get(str(data_sample2.label[i])))\nplt.tight_layout()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\ndata_sample3=df[df.label==2].sample(8).reset_index(drop=True)\nfor i in range(8):\n    plt.subplot(2,4,i+1)\n    img = cv2.imread(work_dir+ \"/train_images/\" + data_sample3.image_id[i])\n    image = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) \n    plt.axis(\"off\")\n    plt.imshow(image)\n    plt.title(class_labels.get(str(data_sample3.label[i])))\nplt.tight_layout()\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\ndata_sample4=df[df.label==3].sample(8).reset_index(drop=True)\nfor i in range(8):\n    plt.subplot(2,4,i+1)\n    img = cv2.imread(work_dir+ \"/train_images/\" + data_sample4.image_id[i])\n    image = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) \n    plt.axis(\"off\")\n    plt.imshow(image)\n    plt.title(class_labels.get(str(data_sample4.label[i])))\nplt.tight_layout()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\ndata_sample5=df[df.label==4].sample(8).reset_index(drop=True)\nfor i in range(8):\n    plt.subplot(2,4,i+1)\n    img = cv2.imread(work_dir+ \"/train_images/\" + data_sample5.image_id[i])\n    image = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) \n    plt.axis(\"off\")\n    plt.imshow(image)\n    plt.title(class_labels.get(str(data_sample5.label[i])))\nplt.tight_layout()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train,df_valid=model_selection.train_test_split(df,test_size=0.05,random_state=42,stratify=df.label.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape,df_valid.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train=df_train=df_train.reset_index(drop=True)\ndf_valid=df_valid.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_image_path=[os.path.join(image_path,k) for k in df_train.image_id.values]\nvalid_image_path=[os.path.join(image_path,k) for k in df_valid.image_id.values]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_image_path[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_image_path[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets=df_train.label.values\nvalid_targets=df_valid.label.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_targets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_targets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CassavaDataset(Dataset):\n    def __init__(self,image_ids,labels,dimension=None,augmentations=None):\n        super().__init__()\n        self.image_ids=image_ids\n        self.labels=labels\n        self.dim=dimension\n        self.augmentations=augmentations\n        \n    def __len__(self):\n        return len(self.image_ids)\n    \n    def __getitem__(self,idx):\n        imge=cv2.imread(self.image_ids[idx])\n        imge=cv2.cvtColor(imge,cv2.COLOR_BGR2RGB)\n        \n        if self.dim:\n            imge=cv2.resize(imge,self.dim)\n            \n        if self.augmentations:\n            aug_img=self.augmentations(image=imge)\n            imge=aug_img[\"image\"]\n            \n        return {\"image\":transforms.ToTensor()(imge),\n                \"label\":torch.tensor(self.labels[idx])}    \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_size = 256\ntrain_aug= A.Compose([A.RandomCrop(height = 500, width = 500 ) ,\n                          A.Transpose(p=0.3) , \n                          A.VerticalFlip(p=0.5),\n                          A.HorizontalFlip(p=0.5),\n                          A.RandomContrast(limit=0.05, p=0.5),\n                          A.OneOf([ A.MedianBlur(blur_limit=3),\n                                    #A.GaussianBlur(blur_limit=3),\n                                    A.GaussNoise(var_limit=(5.0, 30.0)) ,], p=0.6),\n                          A.OneOf([ A.OpticalDistortion(distort_limit=0.7), \n                                    A.GridDistortion(num_steps=2, distort_limit=0.2),\n                                    A.ElasticTransform(alpha=3),  ], p=0.7),\n                          A.CLAHE(clip_limit=4.0, p=0.7),\n                          A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5) , \n                          A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.8),\n                          A.Cutout(max_h_size=int(image_size * 0.2), max_w_size=int(image_size * 0.2), num_holes=1, p=0.5), \n                          A.Cutout(max_h_size=int(image_size * 0.1), max_w_size=int(image_size * 0.1), num_holes=3, p=0.5), \n                          A.Resize(image_size ,image_size )])\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_aug = A.Compose([A.RandomCrop(height = 500, width = 500 ) ,\n                          A.Transpose(p=0.3) , \n                          A.VerticalFlip(p=0.5),\n                          A.HorizontalFlip(p=0.5),\n                          A.RandomContrast(limit=0.05, p=0.5),\n                          A.OneOf([ A.MedianBlur(blur_limit=3),\n                                    #A.GaussianBlur(blur_limit=3),\n                                    A.GaussNoise(var_limit=(5.0, 30.0)) ,], p=0.6),\n                          A.OneOf([ A.OpticalDistortion(distort_limit=0.7), \n                                    A.GridDistortion(num_steps=2, distort_limit=0.2),\n                                    A.ElasticTransform(alpha=3),  ], p=0.7),\n                          A.CLAHE(clip_limit=4.0, p=0.7),\n                          A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5) , \n                          A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.8),\n                          A.Cutout(max_h_size=int(image_size * 0.2), max_w_size=int(image_size * 0.2), num_holes=1, p=0.5), \n                          A.Cutout(max_h_size=int(image_size * 0.1), max_w_size=int(image_size * 0.1), num_holes=3, p=0.5), \n                          A.Resize(image_size ,image_size )])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset=CassavaDataset(image_ids=train_image_path,labels=train_targets,dimension=None,augmentations=train_aug)\nvalid_dataset=CassavaDataset(image_ids=valid_image_path,labels=valid_targets,dimension=None,augmentations=valid_aug)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,15))\n\nfor i in range(16):\n    plt.subplot(4,4,i+1)\n    image,label=train_dataset[i][\"image\"],train_dataset[i][\"label\"]\n    plt.imshow(image.permute(1, 2, 0))\n    plt.axis('off')\n    plt.title(class_labels.get(str(label.item())))\n\n\nplt.tight_layout()\nplt.show()\n\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(\n                                           train_dataset,\n                                           batch_size=16,\n                                           num_workers=4,\n                                           shuffle=False,\n                                           pin_memory=False,\n                                           drop_last=False,\n                                           )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_loader = torch.utils.data.DataLoader(\n                                           valid_dataset,\n                                           batch_size=16,\n                                           num_workers=4,\n                                           shuffle=False,\n                                           pin_memory=False,\n                                           drop_last=False,\n                                           )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}