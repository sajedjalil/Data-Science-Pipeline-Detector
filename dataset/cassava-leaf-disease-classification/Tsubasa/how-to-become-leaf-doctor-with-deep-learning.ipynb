{"cells":[{"metadata":{},"cell_type":"markdown","source":"## å‚è€ƒ\nhttps://www.kaggle.com/tanulsingh077/how-to-become-leaf-doctor-with-deep-learning"},{"metadata":{},"cell_type":"markdown","source":"# ã“ã®ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã«ã¤ã„ã¦ \n\nãƒ¡ãƒ©ãƒãƒ¼ãƒã«ç¶šã„ã¦ã€ä»Šå¹´ã‚‚ã¾ãŸå¤å…¸çš„ãªã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã®åˆ†é¡å•é¡ŒãŒå‡ºé¡Œã•ã‚Œã¾ã—ãŸã€‚CV ã‚’å§‹ã‚ãŸã°ã‹ã‚Šã®äººã«ã¨ã£ã¦ã¯ã€ã“ã®ãƒ©ã‚¤ãƒ–ã‚³ãƒ³ãƒšã«æ‰‹ã‚’å‡ºã—ã¦ã¿ã¦ã€æœ€åˆã®ä¸€æ­©ã‚’è¸ã¿å‡ºã™ã“ã¨ãŒã§ãã‚‹çµ¶å¥½ã®æ©Ÿä¼šã§ã™ã€‚ã“ã®ã‚³ãƒ³ãƒ†ã‚¹ãƒˆã§ã¯ã€åˆ†é¡ã®ç²¾åº¦ãŒå•ã‚ã‚Œã¾ã™ãŒã€ãã‚ŒãŒã©ã®ãã‚‰ã„ã®é »åº¦ã§èµ·ã“ã‚‹ã®ã§ã—ã‚‡ã†ã‹ï¼Ÿ\n\né€šå¸¸ã€å®Ÿéš›ã«å¿…è¦ãªã®ã¯ã€è‘‰ã®åŒ»è€…ã«ãªã‚‹ã“ã¨ã§ã‚ã‚Šã€è¾²å®¶ãŒæ„ŸæŸ“æ€§ã®è‘‰ã‚’è­˜åˆ¥ã—ã€æ‰‹é ƒãªãƒ¬ãƒ¼ãƒˆã§ãã‚Œã‚‰ã‚’æ²»ã™ã®ã‚’åŠ©ã‘ã‚‹ã“ã¨ã§ã™ ğŸ˜› ã€‚\n \n# ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã«ã¤ã„ã¦\n\n* ã„ã¤ã‚‚ã®ã‚ˆã†ã«ã€ã“ã‚Œã¯åˆå¿ƒè€…å‘ã‘ã®ãƒãƒ¼ãƒˆã§ã€ã‚­ãƒ£ãƒƒã‚µãƒã®è‘‰ã®ç—…æ°—ã«ç‰¹åŒ–ã—ãŸè‘‰ã®åŒ»è€…ã«åŠ¹ç‡çš„ã«ãªã‚Œã‚‹æ–¹æ³•ã‚’ãŠä¼ãˆã—ã¾ã™ ğŸ˜› ãã—ã¦ã€ä¸»ãªæ–¹æ³•è«–ã¯ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã§ã™ã€‚\n\n* ç§ã¯ã‚ãªãŸãŒçŸ¥ã£ã¦ãŠãå¿…è¦ãŒã‚ã‚‹ã™ã¹ã¦ã®ã‚‚ã®ã‚’ã‚«ãƒãƒ¼ã—ã¾ã™ , å°‚é–€çŸ¥è­˜ã‹ã‚‰æ–¹æ³•è«–ã¾ã§ , ç§ã¯å•é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ææ¡ˆã™ã‚‹ã•ã¾ã–ã¾ãªã‚¢ã‚¤ãƒ‡ã‚¢ã®ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®ä¾‹ã¨ä¸€ç·’ã«\n\n* å¤šãã®æ··ä¹±ãŒãªã‘ã‚Œã°ã€ã‚ãªãŸã¯ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã«å¾“ã†ã¨ã€ã“ã‚Œã¯ã‚ãªãŸã®æœ€åˆã®CV competitionã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚\n\n* æ©Ÿæ¢°å­¦ç¿’ã¨kaggleãŒå…¨ãåˆã‚ã¦ã®æ–¹ã¯ã€ç§ãŒæ›¸ã„ãŸã“ã®[guide](https://www.kaggle.com/tanulsingh077/tackling-any-kaggle-competition-the-noob-s-way) ã‚’è¦‹ã¦ã¿ã¦ãã ã•ã„ã€‚ \n\n# Step 1 : æ‚£è€…ã®åˆ†æ\n\n* å½¼ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒè©±ã™ã“ã¨ãŒã§ããªã„ã¨ã„ã†äº‹å®Ÿã‚’è€ƒæ…®ã—ã¦ä½•ã‹ã®å‰ã«è‘‰ã®åŒ»è€…ãŒã™ã¹ãã§ã‚ã‚‹ã“ã¨ã‚’æœ€åˆã®ã‚¹ãƒ†ãƒƒãƒ—ã¯ä½•ã§ã—ã‚‡ã†ã‹ï¼Ÿç­”ãˆã¯å½“ç„¶ç°¡å˜ã§ã€æ‚£è€…ã‚’è¦‹ã¦ä½•ãŒé–“é•ã£ã¦ã„ã‚‹ã‹ã‚’åˆ†æã—ã¾ã™ã€‚\n\n* ã—ã‹ã—ã€åŒ»å¸«ã¯ãã‚Œã‚’è¦‹ã‚‹ã ã‘ã§ä½•ã‹ãŒé–“é•ã£ã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’ã©ã®ã‚ˆã†ã«ç†è§£ã—ã¦ã„ã‚‹ã®ã§ã—ã‚‡ã†ã‹ï¼ŸåŒ»å¸«ã¨ã—ã¦ã“ã®ãŸã‚ã«ã¯ã€å½¼ã¯æ­£å¸¸ãªæ‚£è€…/è‘‰ãŒã©ã®ã‚ˆã†ã«è¦‹ãˆã‚‹ã‹ã‚’çŸ¥ã£ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã—ã€æ„ŸæŸ“ã—ãŸã‚‚ã®ã‹ã‚‰å¥åº·ãªæ‚£è€…ã‚’åˆ†é›¢ã™ã‚‹ãŸã‚ã«ã€é€šå¸¸ã®å‹•ä½œã‹ã‚‰ã®é€¸è„±ï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³ã€è‰²ã€è³ªæ„Ÿãªã©ï¼‰ã‚’è¦³å¯Ÿã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ä»Šã€ã•ã‚‰ã«ç—…æ°—ã®ç‰¹å®šã®ã‚¯ãƒ©ã‚¹ã«æ„ŸæŸ“ã—ãŸã‚‚ã®ã‚’åˆ†é¡ã™ã‚‹ãŸã‚ã«ã€åŒ»å¸«ã¯ã¾ãŸã€æ‚£è€…/è‘‰ã®çŠ¶æ…‹ãŒç•°ãªã‚‹ç–¾æ‚£ã®ã‚ˆã†ã«è¦‹ãˆã‚‹æ–¹æ³•ã‚’çŸ¥ã£ã¦ãŠãå¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n\nã“ã‚Œã‚‰ã®ãƒã‚¤ãƒ³ãƒˆã‚’å¿µé ­ã«ç½®ã„ã¦ã€åŸºæœ¬çš„ãªé¦´æŸ“ã¿ã®ã‚ã‚‹ã‚‚ã®ã‹ã‚‰å§‹ã‚ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\n#ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹éš›ã«ãƒ‘ã‚¹ã‚’è¿½åŠ \nsys.path.append('../input/pytorch-image-models/pytorch-image-models-master')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Preliminaries\nimport os\nfrom pathlib import Path\nimport glob\n#ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’è¡¨ç¤ºã™ã‚‹\nfrom tqdm import tqdm\ntqdm.pandas()\nimport json\nimport pandas as pd\nimport numpy as np\n\n## Image hash\nimport imagehash\n\n# Visuals and CV2\nimport seaborn as sn\nimport matplotlib.pyplot as plt\nimport cv2\nfrom PIL import Image\n\n\n# albumentations for augs\n# ç”»åƒã®åŠ å·¥\nimport albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2\n\n# ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã€æ¬¡å…ƒå‰Šæ¸›\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\n\n# Keras and TensorFlow\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array \nfrom keras.applications.resnet50 import preprocess_input \n\n# models \nfrom keras.applications.resnet50 import ResNet50\nfrom keras.models import Model\n\n#torch\nimport torch\nimport timm\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset,DataLoader","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Utils\n\nãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ¼æ©Ÿèƒ½ã®é …"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_images(class_id, label, images_number,verbose=0):\n    '''\n    Courtesy of https://www.kaggle.com/isaienkov/cassava-leaf-disease-classification-data-analysis\n    '''\n    '''\n    ãƒ©ãƒ™ãƒ«ãŒclass_idã®ç”»åƒã‚’images_numberæšãƒ©ãƒ³ãƒ€ãƒ ã§å–å¾—ã—è¡¨ç¤º\n    '''\n    plot_list = train[train[\"label\"] == class_id].sample(images_number)['image_id'].tolist()\n    \n    # ç”»åƒã®ãƒªã‚¹ãƒˆã‚’è¡¨ç¤º\n    if verbose:\n        print(plot_list)\n        \n    labels = [label for i in range(len(plot_list))]\n    size = np.sqrt(images_number)\n    #ç”»åƒã‚’subplotã‚’ä½¿ã£ã¦è¤‡æ•°è¡¨ç¤ºã™ã‚‹ãŸã‚ã«ã€sizeã¨ã„ã†å¤‰æ•°ã‚’ã†ã¾ãè¨­å®šã—ã¦ã„ã‚‹\n    if int(size)*int(size) < images_number:\n        size = int(size) + 1\n        \n    plt.figure(figsize=(20, 20))\n    \n    for ind, (image_id, label) in enumerate(zip(plot_list, labels)):\n        plt.subplot(size, size, ind + 1)\n        image = cv2.imread(str(BASE_DIR/'train_images'/image_id))\n        #OpenCVã§ã¯ç”»åƒã‚’BGRã®é †ã§èª­ã¿è¾¼ã‚€ã®ã§å¤‰æ›ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        plt.imshow(image)\n        plt.title(label, fontsize=12)\n        plt.axis(\"off\")\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"BASE_DIR = Path('../input/cassava-leaf-disease-classification')\n\n## Reading DataFrame having Labels\ntrain = pd.read_csv(BASE_DIR/'train.csv')\n\n## Label Mappings\nwith open(BASE_DIR/'label_num_to_disease_map.json') as f:\n    mapping = json.loads(f.read())\n    mapping = {int(k): v for k,v in mapping.items()}\n\nprint(mapping)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>ã“ã®doctoeã®ã‚³ãƒ¼ã‚¹ã§ã¯ã€4ã¤ã®ç—…æ°—ã«ã¤ã„ã¦å­¦ã¶å¿…è¦ãŒã‚ã‚Šã¾ã™ãŒã€ãã®å‰ã«ã€ã“ã‚Œã‚‰ã®ç—…æ°—ã®åå‰ã‚’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ©ãƒ™ãƒ«ã«ãƒãƒƒãƒ”ãƒ³ã‚°ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ </b>"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['label_names'] = train['label'].map(mapping)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 1.1 å¥åº·ãªã‚‚ã®(Healthy)ã‚’å­¦ã¶\n\nä»Šã€ç§é”ã¯å¥åº·ãªã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’è¦‹å§‹ã‚ã€å¥åº·ãªã‚­ãƒ£ãƒƒã‚µãƒã®è‘‰ã®ç‰¹å¾´ã®ç§é”ã®ç†è§£ã‚’å½¢æˆã™ã‚‹ã“ã¨ãŒã§ãã‚‹1ã¤ã®å ´æ‰€ã§ã™ã¹ã¦ã‚’æŒã£ã¦ã„ã‚‹ã€‚`æ¬¡ã¯ Google ã‹ã‚‰ã®å¥åº·ãªã‚­ãƒ£ãƒƒã‚µãƒã®è‘‰ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã™` \n\n![ç”»åƒ](https://cdn.shortpixel.ai/client/to_avif,q_lossless,ret_img,w_795,h_532/https://organic.ng/wp-content/uploads/2017/02/CASSAVA-LEAF.jpg)\n\n* ä¸Šã®ç”»åƒã‹ã‚‰ã€å¥åº·çš„ãªã‚­ãƒ£ãƒƒã‚µãƒã®è‘‰ã®ç‰¹å¾´ã®ä¸€ã¤ã¯ã€å¤šãã®ã‚«ãƒƒãƒˆã€ãƒ†ã‚¯ã‚¹ãƒãƒ£ã®å¤‰æ›´ã€é»„è‰²ãŒã‹ã£ãŸã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã€ç­‰ãªã—ã§ã‹ãªã‚Šç·‘ã¨ç›´ç«‹ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã“ã¨ã‚’è¨€ã†ã“ã¨ãŒã§ãã¾ã™ã€‚\n\næ¬¡ã«ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¸­ã®å¥åº·ãªã‚‚ã®ã‚’è¦‹ã¦ã€ä¸Šã®ç”»åƒã¨å¯†æ¥ã«æ··ã–ã£ã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['label_names']=='Healthy']['image_id'].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 21kã®ç”»åƒã®ã†ã¡ã€2577ã ã‘ãŒå¥åº·çš„(Healthy)ãªã‚‚ã®ã§ã‚ã‚‹ã€ãƒ©ãƒ™ãƒ«ã®ä¸å‡è¡¡ã¯æ˜ã‚‰ã‹ã«ç›®ã«è¦‹ãˆã¦ã„ã‚‹"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_images(class_id=4, \n    label='Healthy',\n    images_number=6,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_images(class_id=4, \n    label='Healthy',\n    images_number=6,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ä¸Šè¨˜ã®é–¢æ•°ã‚’3ï½4å›å®Ÿè¡Œã—ã¦ã€æ¯å›æ–°ã—ã„ç”»åƒãŒè¡¨ç¤ºã•ã‚Œã‚‹ã®ã‚’æ³¨æ„æ·±ãè¦³å¯Ÿã™ã‚‹ã¨ã€æ¬¡ã®ã‚ˆã†ãªã“ã¨ã«æ°—ã¥ãã§ã—ã‚‡ã†ã€‚\n* ã™ã¹ã¦ã®ç”»åƒãŒè‘‰ã‚’ã‚¯ãƒ­ãƒ¼ã‚ºã‚¢ãƒƒãƒ—ã—ã¦ã„ã‚‹ã‚ã‘ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã—ã€äººé–“ã®ç›®ã«ã¯è‘‰ãŒã»ã¨ã‚“ã©è¦‹ãˆãªã„æœ¨å…¨ä½“ãŒå†™ã£ã¦ã„ã‚‹ç”»åƒã‚‚ã‚ã‚Šã¾ã™ã—ã€è‘‰ã‚ˆã‚Šã‚‚èŒãŒå¤šãå†™ã£ã¦ã„ã‚‹ç”»åƒã‚‚ã‚ã‚Šã¾ã™ã€‚\n* ã•ã‚‰ã«é©šãã¹ãã“ã¨ã¯ã€å¥åº·ãªè‘‰ã®ç”»åƒã®ä¸­ã«ã¯æ„ŸæŸ“ã—ã¦ã„ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã‚‚ã®ã‚‚ã‚ã‚Šã€é»„è‰²ã‚„é»„è‰²ãŒã‹ã£ãŸã‚°ãƒ©ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚ˆã†ãªè‰²ã‚’ã—ã¦ã„ã‚‹ã‚‚ã®ã‚‚ã‚ã‚Šã¾ã™ã€‚\n\n### å¤–ã‚Œå€¤ã®èª¿æŸ» :  \nãƒã‚¤ãƒ³ãƒˆ2ã‚’èª¿æŸ»ã™ã‚‹ãŸã‚ã«ã€ç§ã¯æ¬¡ã®ã‚ˆã†ãªã‚¢ã‚¤ãƒ‡ã‚¢ã‚’æŒã£ã¦ã„ã¾ã™ã€‚\n\n* ã“ã“ã§ã®ã‚¢ã‚¤ãƒ‡ã‚¢ã¯ã€å¥å…¨ãªç”»åƒã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã—ã€ãã‚Œãã‚Œã®ã‚¯ãƒ©ã‚¹ã‚¿ã‚’è¦‹ã¦ã€å¤–ã‚Œå€¤ã‚¯ãƒ©ã‚¹ã‚¿ã¨ç ´æã‚¯ãƒ©ã‚¹ã‚¿ã‚’è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒã§ãã‚‹ã‹ã©ã†ã‹ã‚’ç¢ºèªã™ã‚‹ã“ã¨ã§ã™ã€‚\n* ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã®ãŸã‚ã®ç‰¹å¾´é‡ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã« Resnet18 ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚"},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_features(image_id, model):\n    file = BASE_DIR/'train_images'/image_id\n    # load the image as a 224x224 array\n    # load_imgã¯kerasã®é–¢æ•°ã§å‡ºåŠ›ã¯PILã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹\n    img = load_img(file, target_size=(224,224))\n    # convert from 'PIL.Image.Image' to numpy array\n    img = np.array(img) \n    # reshape the data for the model reshape(num_of_samples, dim 1, dim 2, channels)\n    reshaped_img = img.reshape(1,224,224,3) \n    # prepare image for model\n    # Numpyé…åˆ—ã‚’å‰å‡¦ç†ï¼ˆãƒ¢ãƒ‡ãƒ«ã«ç”»åƒã®ãƒ‡ãƒ¼ã‚¿ã‚’å…¥ã‚Œã‚‹éš›ã«å¿…è¦ãªå‡¦ç†ã‹ï¼‰\n    imgx = preprocess_input(reshaped_img)\n    # get the feature vector\n    #å¼•æ•°ã§å®šã‚ãŸãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã™ã‚‹\n    features = model.predict(imgx, use_multiprocessing=True)\n    \n    return features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ResNet50()\nmodel = Model(inputs = model.inputs, outputs = model.layers[-2].output)\n\nhealthy = train[train['label']==4]\nhealthy['features'] = healthy['image_id'].progress_apply(lambda x:extract_features(x,model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ç”»åƒæ•°*2048\nfeatures.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = np.array(healthy['features'].values.tolist()).reshape(-1,2048)\nimage_ids = np.array(healthy['image_id'].values.tolist())\n\n# Kmeansã§ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°(healtyã®ç”»åƒã®ã¿ã§)\nkmeans = KMeans(n_clusters=5,n_jobs=-1, random_state=22)\nkmeans.fit(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã—ãŸéš›ã®ãƒ©ãƒ™ãƒ«\nkmeans.labels_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"groups = {}\nfor file, cluster in zip(image_ids,kmeans.labels_):\n    if cluster not in groups.keys():\n        #groupsã¨ã„ã†dictã«ã€keyã‚’cluster,valueã‚’ç”»åƒã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’é›†ã‚ãŸãƒªã‚¹ãƒˆã¨ã—ã¦æ ¼ç´\n        groups[cluster] = []\n        groups[cluster].append(file)\n    else:\n        groups[cluster].append(file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def view_cluster(cluster):\n    plt.figure(figsize = (25,25));\n    # gets the list of filenames for a cluster\n    files = groups[cluster]\n    # only allow up to 30 images to be shown at a time\n    if len(files) > 30:\n        print(f\"Clipping cluster size from {len(files)} to 25\")\n        start = np.random.randint(0,len(files))\n        files = files[start:start+25]\n    # plot each image in the cluster\n    for index, file in enumerate(files):\n        plt.subplot(5,5,index+1);\n        img = load_img(BASE_DIR/'train_images'/file)\n        img = np.array(img)\n        plt.imshow(img)\n        plt.title(file)\n        plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"view_cluster(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼3ã®ã»ã¨ã‚“ã©ã®å¤–ã‚Œå€¤ã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åŒ–ã™ã‚‹ã“ã¨ãŒã§ãã€ãã‚Œã‚‰ã‚’ç°¡å˜ã«å¯è¦–åŒ–ã™ã‚‹ã“ã¨ãŒã§ãã¾ã—ãŸã€‚\n\n* è‘‰ãŒå‚·ã‚“ã§ã„ãŸã‚Šã€èŒ¶è‰²ã„æ–‘ç‚¹ãŒã‚ã£ãŸã‚Šã€å¥åº·ã§ã¯ãªã„ã‚ˆã†ã«è¦‹ãˆã‚‹ã‚‚ã®ã‚‚ã‚ã‚Šã¾ã™ã€‚\n\nåŒã˜ãƒˆãƒ”ãƒƒã‚¯ã«å¯¾å‡¦ã™ã‚‹å¤šæ•°ã®è­°è«–ãŒã‚ã‚Šã¾ã™ã€‚\n* https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/198363 -- Wrong Labels\n* https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/199606 --  Quality of Labels\n\nè¨“ç·´ã‚»ãƒƒãƒˆã®ãƒã‚¤ã‚ºã‚’å¿ƒé…ã™ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ãŒã€ã—ã‹ã—ã€ã‚‚ã—ãƒã‚¤ã‚ºãŒãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã«å«ã¾ã‚Œã¦ã„ã¦ã€ãƒ©ãƒ™ãƒªãƒ³ã‚°ãŒåŒæ§˜ã«è¡Œã‚ã‚Œã¦ã„ã‚‹å ´åˆã¯ã©ã†ã§ã—ã‚‡ã†ã‹ï¼Ÿ, ãã‚Œã¯å•é¡Œã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€æˆ‘ã€…ã¯æˆ‘ã€…ãŒç¢ºä¿¡ã™ã‚‹ã¾ã§ã€è¨“ç·´ã‚»ãƒƒãƒˆã‹ã‚‰ä½•ã‹ã‚’å‰Šé™¤ã™ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“\n\n\nã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¦ç´„ã™ã‚‹ã¨\n\n` å¥åº·ãªã‚­ãƒ£ãƒƒã‚µãƒã®è‘‰ã®ç‰¹å¾´`:\n* ä¸»ã«ç·‘è‰²ã§ã€ç›´ç«‹ã—ã¦ã„ã¦ã€èŒ¶è‰²ã®æ–‘ç‚¹ãŒã»ã¨ã‚“ã©ãªã„ã€‚\n* é»„è‰²ã§ã‚‚ç·‘ã§ã‚‚è‘‰å…¨ä½“ã«å‡ä¸€ãªè³ªæ„Ÿã‚’ä¸ãˆã‚‹"},{"metadata":{"trusted":true},"cell_type":"code","source":"view_cluster(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ç—…æ°—ã‚’çŸ¥ã‚‹1ï¼šã‚­ãƒ£ãƒƒã‚µãƒèŒç—…ï¼ˆCBBï¼‰ã«ã¤ã„ã¦\n\nä»Šã€ç§ãŸã¡ã¯å¥åº·ãªã‚­ãƒ£ãƒƒã‚µãƒã®è‘‰ãŒã©ã®ã‚ˆã†ã«è¦‹ãˆã‚‹ã‹ã‚’çŸ¥ã£ã¦ã„ã‚‹ã®ã§ã€ æœ€åˆã®ç—…æ°—ã«ã¤ã„ã¦å­¦ã¶ãŸã‚ã«ç§»å‹•ã—ã¾ã—ã‚‡ã† `CBBã®ç—‡çŠ¶`:\n\n* é»’ã„è‘‰ã®æ–‘ç‚¹ã‚„ç—…æ–‘ã€è§’å¼µã£ãŸè‘‰ã®æ–‘ç‚¹ã€è‹¥è‘‰ã®èå‡‹ã«ã‚ˆã‚‹è‘‰ã®æ—©æ¯ã‚Œã‚„è„±è½ã€é‡åº¦ã®æ”»æ’ƒãªã©ãŒã‚ã‚Šã¾ã™ã€‚\n\n* æœ€åˆã¯è‘‰è„ˆã«ã‚ˆã£ã¦åˆ¶é™ã•ã‚ŒãŸè‘‰ã«è§’å¼µã£ãŸæ°´æµ¸ã—ã®æ–‘ç‚¹ãŒç™ºç”Ÿã—ã€è‘‰ã®ä¸‹ã®æ–¹ã«ã¯ã£ãã‚Šã¨è¦‹ã‚‰ã‚Œã¾ã™ã€‚æ–‘ç‚¹ã¯æ€¥é€Ÿã«æ‹¡å¤§ã—ã€ç‰¹ã«è‘‰ç¸ã«æ²¿ã£ã¦åˆæµã—ã€è¤è‰²ã§é»„è‰²ã®ç¸å–ã‚Šã‚’ã™ã‚‹ï¼ˆå›³1ï¼‰ã€‚\n\n* æ–‘ç‚¹ã®ä¸­å¿ƒéƒ¨ã«ã‚¯ãƒªãƒ¼ãƒ è‰²ã®ç™½è‰²ã®æ¶²æ»´ãŒç™ºç”Ÿã—ã€ãã®å¾Œã€é»„è‰²ã«å¤‰åŒ–ã—ã¾ã™ã€‚\n\n![å›³1](https://www.pestnet.org/fact_sheets/assets/image/cassava_bacterial_blight_173/thumbs/cassavabb_sml.jpg)\n![å›³2](https://www.pestnet.org/fact_sheets/assets/image/cassava_bacterial_blight_173/thumbs/cassavabb2_sml.jpg)\n\n\nè©³ç´°ã¯ [here](https://www.pestnet.org/fact_sheets/cassava_bacterial_blight_173.htm)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_images(class_id=0, \n    label='CBB',\n    images_number=6,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* ç—‡çŠ¶ã®çŸ¥è­˜ã‹ã‚‰ã€ã“ã‚Œã‚‰ã¯CBBç—…ã«ç½¹æ‚£ã—ã¦ã„ã‚‹ã“ã¨ã¯é–“é•ã„ã‚ã‚Šã¾ã›ã‚“ã—ã€è‘‰ãã®ã‚‚ã®ã§ã¯ãªãèŒã®ç”»åƒã‚’å–å¾—ã™ã‚‹ã“ã¨ã¯ã€ç—…æ°—ã®ä¸­ã«ã¯èŒã§åˆ¤æ–­ã§ãã‚‹ã‚‚ã®ã‚‚ã‚ã‚Šã¾ã™ã®ã§ã€èŒã®ç”»åƒã¯ãƒã‚¤ã‚ºã§ã¯ãªã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚\n\n* IMG - '1926670152.jpg'ã®ã‚ˆã†ãªç”»åƒã®ã„ãã¤ã‹ã§ã¯ã€èŒ¶è‰²ã®æ–‘ç‚¹ã¯éå¸¸ã«å°ã•ãã€è‘‰ã¯å¥åº·ãªã‚‚ã®ã®ã‚ˆã†ã«è¦‹ãˆã€å¥åº·ãªç”»åƒã®å¤šãã¯ã¾ãŸã€ãã®ã‚ˆã†ãªå°ã•ãªèŒ¶è‰²ã‚’æŒã£ã¦ãŠã‚Šã€è­˜åˆ¥ã™ã‚‹ã®ã¯é›£ã—ã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“\n\n* ã“ã®ã‚«ãƒ†ã‚´ãƒªã®ç—…æ°—ã®ç§ã®ç†è§£ã‹ã‚‰ã€ç§ã¯RandomCroppingã€ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆã®å¤‰åŒ–ã€ä»»æ„ã®ç¨®é¡ã®è‰²ã®å¤‰åŒ–ã¯è‰¯ã„ã‚¢ã‚¤ãƒ‡ã‚¢ã§ã¯ãªã„ã‹ã‚‚ã—ã‚Œãªã„ã¨è¨€ã†ã“ã¨ãŒã§ãã¾ã™ã€‚"},{"metadata":{},"cell_type":"markdown","source":"### ç—…æ°—ã«ã¤ã„ã¦å­¦ã¶2ï¼šã‚­ãƒ£ãƒƒã‚µãƒã‚°ãƒªãƒ¼ãƒ³ãƒ¢ãƒƒãƒˆï¼ˆCGM)\n\næ¬¡ã®ç—…æ°—ã€ `Symptoms of CGM`ã«ç§»ã‚Šã¾ã™\n\n* è‘‰ã«ç™½æ–‘ãŒç™ºç”Ÿã—ã€æœ€åˆã®å°ã•ãªæ–‘ç‚¹ã‹ã‚‰è‘‰å…¨ä½“ã«åºƒãŒã‚Šã€è‘‰ç·‘ç´ ãŒå¤±ã‚ã‚Œã¦ã„ãã¾ã™ã€‚è‹¥ã„è‘‰ã¯å‡¹ã¿ã€ã‹ã™ã‹ãªé»„è‰²ã®æ–‘ç‚¹ãŒç›®ç«‹ã¤ï¼ˆå›³1ï¼‰ã€‚(å›³ 1)\n\n* ã“ã®ç—…æ°—ã«ã‹ã‹ã‚‹ã¨ã€è‘‰ã«æ–‘ç‚¹çŠ¶ã®ç—‡çŠ¶ãŒç¾ã‚Œã€ã‚­ãƒ£ãƒƒã‚µãƒãƒ¢ã‚¶ã‚¤ã‚¯ç—…ï¼ˆCMDï¼‰ã®ç—‡çŠ¶ã¨æ··åŒã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚é‡åº¦ã®ãƒ€ãƒ¡ãƒ¼ã‚¸ã‚’å—ã‘ãŸè‘‰ã¯åç¸®ã—ã€ä¹¾ç‡¥ã—ã¦è½ã¡ã€ãƒ­ãƒ¼ã‚½ã‚¯è¶³ã®ã‚ˆã†ãªç‰¹å¾´çš„ãªå¤–è¦³ã«ãªã‚Šã¾ã™ã€‚(å›³2) (å›³ 2)\n\n![](https://www.pestnet.org/fact_sheets/assets/image/cassava_green_mottle_068/thumbs/cgmv2_sml.jpg)\n![](https://www.pestnet.org/fact_sheets/assets/image/cassava_green_mottle_068/thumbs/cgmv_sml.jpg)\n\nè©³ç´°ã¯ [here](https://www.pestnet.org/fact_sheets/cassava_green_mottle_068.htm)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_images(class_id=2, \n    label='CGM',\n    images_number=12,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### æ¨è«–\n\n* CGMã®ç—‡çŠ¶ã‚’èª­ã¿ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç”»åƒã‚’è¦‹ãŸå¾Œã€CGMã®è‘‰ã€CBBã®è‘‰ã€å¥åº·ãªè‘‰ã®é•ã„ã‚’æ˜ç¢ºã«ä¼ãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n* CGMã®è‘‰ã¯ãƒ“ã‚¨ãƒ³(viens)ã«æ²¿ã£ã¦è‘‰ã«ã‹ã™ã‹ã«é»„è‰²ã®æ–‘ç‚¹ãŒã‚ã‚Šã€CBBã®è‘‰ã¯èŒ¶è‰²ã®æ–‘ç‚¹ãŒã‚ã‚Šã€å¥åº·ãªè‘‰ã¯å®Œå…¨ã«ç·‘ã‹å®Œå…¨ã«é»„è‰²ã§ã‚ã‚‹ã€‚\n* ã¾ãŸã€ã“ã®ã‚¯ãƒ©ã‚¹ã§ã‚‚ã‚ã¾ã‚Šå¤–ã‚ŒãŸäººã¯ã„ã¾ã›ã‚“ã€‚\n\n\n### ç—…æ°—ã‚’çŸ¥ã‚‹3ï¼šã‚­ãƒ£ãƒƒã‚µãƒãƒ¢ã‚¶ã‚¤ã‚¯ç—…ï¼ˆCMDï¼‰ã«ã¤ã„ã¦\n\n`CMDã®ç—‡çŠ¶`:\n\n* CMDã¯ã€ãƒ¢ã‚¶ã‚¤ã‚¯ã€æ–‘å…¥ã‚Šã€è‘‰ã®å¤‰å½¢ã‚„ã­ã˜ã‚Œã€è‘‰ã‚„æ¤ç‰©ã®ã‚µã‚¤ã‚ºã®å…¨ä½“çš„ãªæ¸›å°‘ã‚’å«ã‚€æ§˜ã€…ãªè‘‰çŠ¶ã®ç—‡çŠ¶ã‚’ç”Ÿæˆã—ã¾ã™ã€‚\n\n\n* ã“ã®ç—…æ°—ã«ã‚ˆã£ã¦å½±éŸ¿ã‚’å—ã‘ãŸè‘‰ã¯ã€é€šå¸¸ã®ç·‘è‰²ã®ãƒ‘ãƒƒãƒã‚’æŒã¡ã€é‡ç—‡åº¦ã«å¿œã˜ã¦é»„è‰²ã¨ç™½ã®ç•°ãªã‚‹å‰²åˆã§æ··åˆã•ã‚Œã¦ã„ã¾ã™ã€‚"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_images(class_id=3, \n    label='CMD',\n    images_number=6,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### æ¨è«–\n\n* æˆ‘ã€…ã¯ã€CGMã¨CMDã¯éå¸¸ã«è¿‘ã„ç—‡çŠ¶ã‚’æŒã£ã¦ã„ã‚‹ã“ã¨ã‚’è¦‹ã‚‹ã“ã¨ãŒã§ãã€ã¾ãŸã€ã‹ãªã‚Šä¼¼ãŸã‚ˆã†ãªç”»åƒã‚’æŒã£ã¦ã„ã‚‹ã€å¤šãã®å ´åˆã€å°‚é–€å®¶ã¯ã€ã“ã‚Œã‚‰ã®ãƒ©ãƒ™ãƒ«ã‚’æ··ä¹±ã•ã›ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€æˆ‘ã€…ã¯ãã‚ŒãŒãƒ¢ãƒ‡ãƒ«ã®ãŸã‚ã®ã‚‚ã®ã«ãªã‚Šã¾ã™ã©ã®ã‚ˆã†ã«å¤§ããªèª²é¡Œã‚’æƒ³åƒã™ã‚‹ã“ã¨ãŒã§ãã¾ã—ãŸã€‚\n\n* ã“ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã§ã‚‚å¤–ã‚Œè€…ã¯ãªã„ã‹ã€ã‚ã‚‹ã„ã¯éå¸¸ã«å°‘ãªã„ã‚ˆã†ã«æ€ã‚ã‚Œã¾ã™ã€‚"},{"metadata":{},"cell_type":"markdown","source":"### ç—…æ°—ã‚’çŸ¥ã‚‹4ï¼šã‚­ãƒ£ãƒƒã‚µãƒè¤æ¡ç—…(CBSD)\n\nä»Šã€ç§ã¯æœ€å¾Œã«ã“ã‚Œã‚’é¸ã‚“ã ç†ç”±ã¯ã€æˆ‘ã€…ã¯ã“ã®ã‚«ãƒ†ã‚´ãƒªã®ãŸã‚ã«2ã¤ã®ç•°ãªã‚‹ç¨®é¡ã®ç”»åƒã‚’æŒã£ã¦ã„ã‚‹ãŸã‚ã§ã™ã€‚\n\n* ä¸€ã¤ã¯ã€è‘‰ã£ã±ãƒ»æ¤ç‰©ã®ç”»åƒã§ã™ã€‚\n* ã‚‚ã†ä¸€ã¤ã¯ã€çµç¯€æ€§ã®æ ¹ã®ç”»åƒã§ã™ãŒã€ã“ã‚Œã¯ã‚¸ãƒ£ã‚¬ã‚¤ãƒ¢ã‚„ãƒã‚¤ã‚ºã¨èª¤è§£ã•ã‚Œã‚„ã™ã„ã®ã§ã™ãŒã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ãƒã‚¤ã‚ºãŒå«ã¾ã‚Œã¦ã„ã‚‹ã“ã¨ã‹ã‚‰ã€ã“ã®ç—…æ°—ã®è­˜åˆ¥ã«åã‚ŠãŒå‡ºã¦ã—ã¾ã„ã¾ã™ã€‚ã—ãŸãŒã£ã¦ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å†™ã£ã¦ã„ã‚‹èŒ¶è‰²ãã¦ä¸æ°å¥½ãªã‚‚ã®ã¯ã€ã‚«ã‚µãƒ™ã®çµç¯€æ€§æ ¹ã§ã‚ã‚Šã€ã“ã®ç—…æ°—ã‚‚ã¾ãŸã€ã“ã‚Œã‚‰ã®ç”»åƒã‹ã‚‰è­˜åˆ¥ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã“ã¨ã‚’æ˜ç¢ºã«ã—ã¦ãŠãã¾ã™ã€‚\n\nä»Šã™ã `CBSDã®ç—‡çŠ¶`ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚\n\n* CBSDã®è‘‰ã®ç—‡çŠ¶ã¯ã€æ¯”è¼ƒçš„å¤§ããªé»„è‰²ã®ãƒ‘ãƒƒãƒã‚’å½¢æˆã™ã‚‹ãŸã‚ã«æ‹¡å¤§ã—ã€åˆä½“ã™ã‚‹ã‹ã‚‚ã—ã‚Œãªã„ç‰¹å¾´çš„ãªé»„è‰²ã¾ãŸã¯å£Šæ­»æ€§ã®é™è„ˆã®ãƒãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚\n* å¡Šæ ¹ã®ç—‡çŠ¶ã¯ã€å¡ŠèŒå†…ã®é»’è¤è‰²ã®å£Šæ­»é ˜åŸŸã¨æ ¹ã®ã‚µã‚¤ã‚ºã®æ¸›å°‘ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nã“ã®ã‚«ãƒ†ã‚´ãƒªã«å­˜åœ¨ã™ã‚‹2ã¤ã®ã‚¿ã‚¤ãƒ—ã®ç”»åƒã¨ã€ãã‚Œã‚‰2ã¤ã®ç•°ãªã‚‹ç”»åƒã«è¦‹ã‚‰ã‚Œã‚‹ç—‡çŠ¶ã‚’æ˜ç¢ºã«ç†è§£ã™ã‚‹ã“ã¨ãŒã§ãã¾ã—ãŸã®ã§ã€ãƒ‡ãƒ¼ã‚¿ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_images(class_id=1, \n    label='CBSD',\n    images_number=12,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* ç­’çŠ¶ã®æ ¹ã®ç”»åƒã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å–ã‚Šå‡ºã›ã‚‹ã‹è©¦ã—ã¦ã¿ã‚ˆã†"},{"metadata":{"trusted":true},"cell_type":"code","source":"CBSD = train[train['label']==1]\nCBSD['features'] = CBSD['image_id'].progress_apply(lambda x:extract_features(x,model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_cbsd = np.array(CBSD['features'].values.tolist()).reshape(-1,2048)\nimage_ids_cbsd = np.array(CBSD['image_id'].values.tolist())\n\n# Clustering\nkmeans_cbsd = KMeans(n_clusters=5,n_jobs=-1, random_state=22)\nkmeans_cbsd.fit(features_cbsd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"groups_cbsd = {}\nfor file, cluster in zip(image_ids_cbsd,kmeans_cbsd.labels_):\n    if cluster not in groups_cbsd.keys():\n        groups_cbsd[cluster] = []\n        groups_cbsd[cluster].append(file)\n    else:\n        groups_cbsd[cluster].append(file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def view_cluster(cluster):\n    plt.figure(figsize = (25,25))\n    # gets the list of filenames for a cluster\n    files = groups_cbsd[cluster]\n    # only allow up to 30 images to be shown at a time\n    if len(files) > 30:\n        print(f\"Clipping cluster size from {len(files)} to 25\")\n        start = np.random.randint(0,len(files))\n        files = files[start:start+25]\n    # plot each image in the cluster\n    for index, file in enumerate(files):\n        plt.subplot(5,5,index+1);\n        img = load_img(BASE_DIR/'train_images'/file)\n        img = np.array(img)\n        plt.imshow(img)\n        plt.title(file)\n        plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"view_cluster(4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* æˆ‘ã€…ã¯æ­£å¸¸ã«80ç”»åƒã®1ã¤ã®ã‚¯ãƒ©ã‚¹ã‚¿ã«ç®¡çŠ¶æ ¹ç”»åƒã‚’ã‚¯ãƒ©ã‚¹ã‚¿åŒ–ã™ã‚‹ã“ã¨ãŒã§ãã¾ã—ãŸã€ãã‚Œã‚†ãˆã«ä»Šã€æˆ‘ã€…ã¯ã™ã¹ã¦ã®IDSã‚’å–å¾—ã™ã‚‹ã“ã¨ãŒã§ãã€ã“ã®æƒ…å ±ã‚’ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã«ã¤ã„ã¦ã®æ§˜ã€…ãªã‚¢ã‚¤ãƒ‡ã‚¢ã‚’è€ƒãˆã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“"},{"metadata":{"trusted":true},"cell_type":"code","source":"view_cluster(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ç§ãŸã¡ã®èª¿æŸ»çµæœã®æ¦‚è¦ï¼šã‚¹ãƒ†ãƒƒãƒ—1ã®çµ‚äº†\n\næœ€åˆã®EDAã®çµæœã‚’ã¾ã¨ã‚ã¦ã¿ã¾ã—ã‚‡ã†ã€‚\n\n* å¥åº·ãªç”»åƒã¯æ­£ã—ããƒ©ãƒ™ãƒ«ä»˜ã‘ã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã€é–“é•ã£ã¦ãƒ©ãƒ™ãƒ«ä»˜ã‘ã•ã‚ŒãŸç”»åƒã¯5ã¤ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®ã†ã¡3ã¤ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã«ã‚ã‚Šã¾ã™ã€‚\n* å®Œå…¨ã«é»„è‰²ã®è‘‰ã¯ã€å¸¸ã«è‘‰ãŒæ½œåœ¨çš„ãªç—…æ°—ã‚’æŒã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n* è‘‰ã«èŒ¶è‰²ã®æ–‘ç‚¹ãŒã‚ã‚‹ã®ã¯ã€ã‚­ãƒ£ãƒƒã‚µãƒã®ãƒã‚¯ãƒ†ãƒªã‚¢ãƒ»ãƒ™ãƒˆç—…(CBB)ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ \n* ã™ã¹ã¦ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã«ç•°ãªã£ãŸèƒŒæ™¯ãŠã‚ˆã³ã‚¹ã‚±ãƒ¼ãƒ«ã®å¤‰åŒ–ãŒã‚ã‚Šã¾ã™ \n* ç”»åƒã¯ä¸€æ—¥ã®ç•°ãªã‚‹æ™‚é–“å¸¯ã«æ’®å½±ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€ç•°ãªã‚‹ç…§æ˜ã¨éœ²å‡ºã‚’æŒã£ã¦ã„ã¾ã™ã€‚\n* ã‚­ãƒ£ãƒƒã‚µãƒã‚°ãƒªãƒ¼ãƒ³ãƒ¢ãƒƒãƒˆãƒ«(CGM)ã¨ã‚­ãƒ£ãƒƒã‚µãƒãƒ¢ã‚¶ã‚¤ã‚¯ç—…(CMD)ã¯ã€ç”»åƒã¨åŒæ§˜ã«éå¸¸ã«ä¼¼ãŸç—‡çŠ¶ã‚’æŒã£ã¦ãŠã‚Šã€ç°¡å˜ã«äº’ã„ã«èª¤èªè¡¨ç¤ºã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã¾ãŸã€ã‚­ãƒ£ãƒƒã‚µãƒãƒ¢ã‚¶ã‚¤ã‚¯ç—…ã®ä¾‹ãŒ13kã‚‚ã‚ã‚‹ã®ã§ã€ãƒ¢ãƒ‡ãƒ«ãŒCGMã‚’CGMã¨ãƒ©ãƒ™ãƒ«ä»˜ã‘ã™ã‚‹éš›ã«æœ€ã‚‚ãƒŸã‚¹ãŒå¤šã„å¯èƒ½æ€§ãŒé«˜ã„ã§ã™ã€‚\n* ä¸€æšã®ç”»åƒ/ã‚­ãƒ£ãƒƒã‚µãƒã®æ¤ç‰©ã«ã¯è¤‡æ•°ã®å…±èµ·æ€§ç–¾æ‚£ãŒå«ã¾ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã¯ãƒ©ãƒ™ãƒ«ä»˜ã‘ã‚’æ··ä¹±ã•ã›ã‚‹\n* CBSDã¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¸­ã«2ç¨®é¡ã®ç”»åƒã‚’æŒã£ã¦ã„ã¾ã™ãŒã€1ã¤ã¯æ¤ç‰©/è‘‰ã®ç”»åƒã§ã€ã‚‚ã†1ã¤ã¯ã‚¸ãƒ£ã‚¬ã‚¤ãƒ¢ã‚„ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚ºã¨èª¤è§£ã•ã‚Œã‚„ã™ã„æ ¹ã®ç”»åƒã§ã™ã€‚\n\n\nãƒªãƒ¼ãƒ•ãƒ‰ã‚¯ã‚¿ãƒ¼ã«ãªã‚‹ãŸã‚ã®æœ€åˆã®ã‚¹ãƒ†ãƒƒãƒ—ãŒå®Œäº†ã—ãŸå¾Œã€æ‚£è€…ã•ã‚“ã®ã“ã¨ã‚’ç†è§£ã—ã€æ§˜ã€…ãªç—…æ°—ã®ã“ã¨ã‚’ç†è§£ã™ã‚‹ã“ã¨ãŒã§ãã¾ã—ãŸã€‚ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã¯ã€ç§ãŸã¡ã¯ã‚ˆã‚Šè‰¯ã„ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³/ãƒ—ãƒ©ãƒ³ã‚’ãƒ‡ãƒã‚¤ã‚¹ã«å½¹ç«‹ã¡ã¾ã™ã€‚\n\n<b>æ³¨ï¼šç§ã¯ã‚ˆã‚Šå¤šãã®ç™ºè¦‹ã‚’ç¶šã‘ã‚‹ã‚ˆã†ã«ã€ç§ã¯ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã‚ˆã‚Šå¤šãã®ãã®ã‚ˆã†ãªçŸ¥è¦‹ã‚’è¿½åŠ ã—ã¦ã„ãã¾ã™ã€‚</b>"},{"metadata":{},"cell_type":"markdown","source":"## ãƒ‡ãƒ¼ã‚¿ã®é‡è¤‡  æˆ‘ã€…ãŒè¦‹é€ƒã—ã¦ã„ãŸã‚‚ã®\n\nè­°è«–ã®å ´ã‚’èª¿ã¹ã¦ã„ãŸã‚‰ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¸­ã«ç”»åƒãŒé‡è¤‡ã—ã¦ã„ã‚‹å¯èƒ½æ€§ã«ã¤ã„ã¦è©±ã—ã¦ã„ã‚‹[ã“ã®](https://www.kaggle.com/c/cassava-leaf-disease-classification/discussion/198202) ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’è¦‹ã¤ã‘ã¾ã—ãŸã€‚ç”»åƒã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¸­ã«é‡è¤‡ã—ãŸç”»åƒãŒã‚ã‚‹ã¨ã„ã†è©±ã¯ã¨ã¦ã‚‚èˆˆå‘³æ·±ã„ã‚‚ã®ã§ã™ï¼\n\n* ç”»åƒã®å®Œå…¨ãªã‚³ãƒ”ãƒ¼ã«ã¤ã„ã¦è©±ã—ã¦ã„ã‚‹\n* ç§ãŸã¡ã¯ã€ç‰¹å®šã®ç”»åƒã«ä¼¼ã¦ã„ã‚‹ç”»åƒã«ã¤ã„ã¦è©±ã—ã¦ã„ã¾ã™ã€‚ä¾‹ï¼šç”»åƒ1ã¯ãƒˆãƒªãƒŸãƒ³ã‚°ã•ã‚ŒãŸã‹å›è»¢ã•ã‚Œã€ç”»åƒ2ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚\n\nã•ã¦ã€ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¸­ã‹ã‚‰é‡è¤‡ç”»åƒï¼ˆæ­£ç¢ºãªã‚³ãƒ”ãƒ¼ï¼‰ã‚„é¡ä¼¼ç”»åƒã‚’è¦‹ã¤ã‘ã¦è­˜åˆ¥ã™ã‚‹æ–¹æ³•ãŒã„ãã¤ã‹ã‚ã‚Šã¾ã™ã€‚ç§ã¯ç”»åƒãƒãƒƒã‚·ãƒ¥åŒ–ã®æ–¹æ³•ã‚’ä½¿ã„ã€ [ã“ã“](https://www.kaggle.com/appian/let-s-find-out-duplicate-images-with-imagehash) ã§è¦‹ã¤ã‘ãŸãƒãƒ¼ãƒˆã«å¾“ã£ã¦ã„ãã¾ã™ã€‚"},{"metadata":{"trusted":true},"cell_type":"code","source":"funcs = [\n        imagehash.average_hash,\n        imagehash.phash,\n        imagehash.dhash,\n        imagehash.whash,\n    ]\n\nimage_ids = []\nhashes = []\n\nfor path in tqdm(glob.glob(str(BASE_DIR/'train_images'/'*.jpg' ))):\n    image = Image.open(path)\n    image_id = os.path.basename(path)\n    image_ids.append(image_id)\n    hashes.append(np.array([f(image).hash for f in funcs]).reshape(256))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hashes_all = np.array(hashes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hashes_all.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"numpyé…åˆ—ã‚’ãƒˆãƒ¼ãƒãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›ã—ã¦é¡ä¼¼åº¦è¨ˆç®—ã‚’é«˜é€ŸåŒ–ã—ã¾ã™ã€‚"},{"metadata":{"trusted":true},"cell_type":"code","source":"hashes_all = torch.Tensor(hashes_all.astype(int)).cuda()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ã™ã¹ã¦ã®ç”»åƒãƒšã‚¢é–“ã®é¡ä¼¼åº¦ã‚’è¨ˆç®—ã—ã¾ã™ã€‚å€¤ã‚’256ã§å‰²ã£ã¦æ­£è¦åŒ–ï¼ˆ0-1ï¼‰ã—ã¾ã™ã€‚"},{"metadata":{"trusted":true},"cell_type":"code","source":"%time sims = np.array([(hashes_all[i] == hashes_all).sum(dim=1).cpu().numpy()/256 for i in range(hashes_all.shape[0])])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sims.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ã—ãã„å€¤ã®è¨­å®š"},{"metadata":{"trusted":true},"cell_type":"code","source":"indices1 = np.where(sims > 0.9)\nindices2 = np.where(indices1[0] != indices1[1])\nimage_ids1 = [image_ids[i] for i in indices1[0][indices2]]\nimage_ids2 = [image_ids[i] for i in indices1[1][indices2]]\ndups = {tuple(sorted([image_ids1,image_ids2])):True for image_ids1, image_ids2 in zip(image_ids1, image_ids2)}\nprint('found %d duplicates' % len(dups))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"é‡è¤‡ã—ãŸç”»åƒã®ãƒ—ãƒ­ãƒƒãƒˆ"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\ncode taken from https://www.kaggle.com/nakajima/duplicate-train-images?scriptVersionId=47295222\n'''\n\nduplicate_image_ids = sorted(list(dups))\n\nfig, axs = plt.subplots(2, 2, figsize=(15,15))\n\nfor row in range(2):\n        for col in range(2):\n            img_id = duplicate_image_ids[row][col]\n            img = Image.open(str(BASE_DIR/'train_images'/img_id))\n            label =str(train.loc[train['image_id'] == img_id].label.values[0])\n            axs[row, col].imshow(img)\n            axs[row, col].set_title(\"image_id : \"+ img_id + \"  label : \" + label)\n            axs[row, col].axis('off')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"é‡è¤‡ã‚’è¦‹ã¤ã‘ã‚‹æ–¹æ³•ã¯ä»–ã«ã‚‚ã‚ã‚Šã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä¸­ã«ã‚½ãƒ•ãƒˆãªé‡è¤‡ãŒã‚ã‚‹å ´åˆã«ã¯ã€ã“ã®ã‚«ãƒ¼ãƒãƒ«ã®å¾Œã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§æä¾›ã•ã‚Œã¾ã™ã€‚"},{"metadata":{},"cell_type":"markdown","source":"# ã‚¹ãƒ†ãƒƒãƒ—2ï¼šæ–¹æ³•è«–ã«ã¤ã„ã¦å­¦ã¶\n\nã“ã‚“ã«ã¡ã¯ã€åŒ»å¸«ã¯ã‚ãªãŸã®2å¹´ç›®ã¸ã‚ˆã†ã“ãã€ã‚ãªãŸã®æœ€çµ‚èª²é¡Œã‚’å®Œäº†ã™ã‚‹ãŸã‚ã«ã€ã‚ãªãŸã¯ä»Šã€ã‚ãªãŸã®å‡¦åˆ†ã§æŒã£ã¦ã„ã‚‹ãƒ„ãƒ¼ãƒ«ã‚’ç†è§£ã—ã€ãã‚Œã‚‰ã‚’ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã‚’ç†è§£ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€ä»¥ä¸‹ã¯ã€ãƒ„ãƒ¼ãƒ«ã‚’å­¦ã¶ãŸã‚ã«å¾“ã†ã¹ãã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã®ã‚¬ã‚¤ãƒ‰ã§ã™ã€‚\n\n* [Beginner Article](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/)\n* [Course By Andrew NG](https://www.coursera.org/learn/convolutional-neural-networks)\n* [Applying CNNS using Keras and tensorflow](https://www.coursera.org/learn/convolutional-neural-networks-tensorflow)\n* [Course from Fast.ai](https://course.fast.ai/videos/?lesson=1)"},{"metadata":{},"cell_type":"markdown","source":"# ã‚¹ãƒ†ãƒƒãƒ—3ï¼šæœ€çµ‚ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ§‹ç¯‰\n\n\nOhk now Docs , its time for you to build the final project . ã“ã‚Œã¯æœ€çµ‚çš„ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãªã®ã§ã€èª°ã‚‚ãŒè‡ªåˆ†è‡ªèº«ã§æ§‹ç¯‰ã™ã‚‹ã“ã¨ã‚’æ„å‘³ã—ã¦ã„ã¾ã™ãŒã€ã“ã“ã§ã¯ç§ãŒä½¿ç”¨ã—ãŸã‚‚ã®ã®è¦ç´„ã‚’æ›¸ãã€ã•ã‚‰ã«ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®æ–¹æ³•ã‚’ææ¡ˆã—ã¾ã™ã€‚\n\næœ€å¾Œã«ã€ç§ã¯ã¾ãŸã€ç«¶äº‰ã®å…¨ä½“ã®ã‚³ãƒ¼ã‚¹ã®ä¸­ã§è©¦ã™ãŸã‚ã®ã‚‚ã®/å¤–ã‚’è¦‹ã‚‹ãŸã‚ã®ã‚‚ã®ã‚’è¿½åŠ ã—ã¾ã™ã€‚\n\n`ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã®ã¾ã¨ã‚`:\n\nã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ã‚­ãƒ£ãƒƒã‚µãƒ2019å¤§ä¼šã®å„ªå‹è§£ã‚’å…ƒã«ã—ã¦ã„ã‚‹ã®ã§ã€ã§ãã‚‹ã ã‘è¿‘ã„å½¢ã§å†ç¾ã—ã¦ã¿ãŸã„ã¨æ€ã„ã¾ã™ã€‚\n\n* SE-ResNext50\n* Dimension = (384,384)\n* Epochs = 10\n* Custom LR scheduler \n* Weights saved on best loss : Categorical CrossEntropy\n* Basic Augs : HorizontalFlip,VerticalFlip,Rotate,RandomBrightness,ShiftScaleRotate,cutout,centercrop,zoom,randomscale\n* No TTAï¼ˆtestãƒ‡ãƒ¼ã‚¿ã«augumentã‚’è¡Œã‚ãªã„ï¼‰\n\n<font color ='red' >GPUã®ãŸã‚ã®kaggleã«åˆ¶é™ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€ç§ã®5ã¤æŠ˜ã‚Šãƒ¢ãƒ‡ãƒ«ã¯ã¾ã å®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹ã®ã§ã€ä»Šã®ã¨ã“ã‚ã¯SeResNext50ã®äº‹å‰å­¦ç¿’ã•ã‚ŒãŸé‡ã¿ã ã‘ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ã€ç•°ãªã‚‹è¨­å®š/ã‚¢ã‚¤ãƒ‡ã‚¢ã§æ•°å›æ›´æ–°ã•ã‚Œã¾ã™ã®ã§ã€ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ç¶­æŒã—ã¦ãã ã•ã„</color>"},{"metadata":{},"cell_type":"markdown","source":"## è¨­å®šã¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£æ©Ÿèƒ½"},{"metadata":{"trusted":true},"cell_type":"code","source":"DIM = (384,384)\n\nNUM_WORKERS = 12\nTEST_BATCH_SIZE = 16\nSEED = 2020\n\nDEVICE = \"cuda\"\n\nMEAN = [0.485, 0.456, 0.406]\nSTD = [0.229, 0.224, 0.225]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Augmentations"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_test_transforms():\n\n    return albumentations.Compose(\n        [albumentations.Normalize(MEAN, STD, max_pixel_value=255.0, always_apply=True),\n        ToTensorV2(p=1.0)\n        ]\n    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cassava Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CassavaDataset(Dataset):\n    def __init__(self,image_ids,labels,dimension=None,augmentations=None):\n        super().__init__()\n        self.image_ids = image_ids\n        self.labels = labels\n        self.dim = dimension\n        self.augmentations = augmentations\n        \n    def __len__(self):\n        # len(ä¸Šã§å®šç¾©ã—ãŸã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹)ã§è¿”ã™å€¤ã€‚\n        return len(self.image_ids)\n    \n    def __getitem__(self,idx):\n        # ä¸Šã§å®šç¾©ã—ãŸã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹[idx]ã§è¿”ã™å€¤\n        img = cv2.imread(str(BASE_DIR/'test_images'/self.image_ids[idx]))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                         \n        if self.dim:\n            img = cv2.resize(img,self.dim)\n        \n        if self.augmentations:\n            augmented = self.augmentations(image=img)\n            image = augmented['image']\n                         \n        return {\n            'image': image,\n            'target': torch.tensor(self.labels[idx],dtype=torch.float)\n        }","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model : SE_Resnext50"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CassavaModel(nn.Module):\n    def __init__(self, model_name='seresnext50_32x4d',out_features=5,pretrained=True):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        \n        #resnet50ã®ãƒ¢ãƒ‡ãƒ«ã«æœ€å¾Œå‡ºåŠ›ã®æ¬¡å…ƒã‚’æƒãˆã‚‹ãŸã‚ã«1å±¤è¿½åŠ ã—ã¦ã„ã‚‹ã€‚\n        \n        n_features = self.model.last_linear.in_features\n        self.model.last_linear = nn.Linear(n_features, out_features)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction Function Single Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_single_model(data_loader,model,device):\n    model.eval()\n    tk0 = tqdm(enumerate(data_loader), total=len(data_loader))\n    fin_out = []\n    \n    with torch.no_grad():\n        \n        for bi, d in tk0:\n            images = d['image']\n            targets = d['target']\n            \n            images = images.to(device)\n            targets = targets.to(device)\n            \n            batch_size = images.shape[0]\n            \n            outputs = model(images)\n            \n            fin_out.append(F.softmax(outputs, dim=1).detach().cpu().numpy())\n            \n    return np.concatenate(fin_out)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Engine"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub = pd.read_csv('../input/cassava-leaf-disease-classification/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(weights):\n    '''\n    weights : List of paths in case of K fold model inference\n    '''\n    pred = np.zeros((len(sample_sub),5,5))\n    \n    # Defining DataSet\n    test_dataset = CassavaDataset(\n        image_ids=sample_sub['image_id'].values,\n        labels=sample_sub['label'].values,\n        augmentations=get_test_transforms(),\n        dimension = DIM\n    )\n    \n    test_loader = torch.utils.data.DataLoader(\n        test_dataset,\n        batch_size=TEST_BATCH_SIZE,\n        num_workers=NUM_WORKERS,\n        shuffle=False,\n        pin_memory=True,\n        drop_last=False,\n    )\n    \n    # Defining Device\n    device = torch.device(\"cpu\")\n    \n    for i,weight in enumerate(weights):\n        # Defining Model for specific fold\n        model = CassavaModel(out_features=5,pretrained=True)\n        \n        # loading weights\n        #model.load_state_dict(torch.load(weight))\n        model.to(device)\n        \n        #predicting\n        pred[:,:,i] = predict_single_model(test_loader,model,device)\n    \n    return pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preparing Final Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = predict([1])\nprint(pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = pred.mean(axis=-1)\nprint('Prediction Before Argmax',pred)\npred = pred.argmax(axis=1)\nprint('Final Prediction',pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub['label'] = pred\nsample_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# çµè«–\n\nç«¶äº‰ãŒå§‹ã¾ã£ãŸã°ã‹ã‚Šãªã®ã§ã€è©¦ã—ã¦ã¿ã‚‹ã“ã¨ãŒãŸãã•ã‚“ã‚ã‚Šã¾ã™ãŒã€ç§ã¯ã“ã®ãƒãƒ¼ãƒˆã‚’æ›´æ–°ã—ã¦ã¿ã¾ã™ã€‚\n\nç§ã®ãƒãƒ¼ãƒˆã‚’èª­ã‚“ã§ãã‚Œã¦ã‚ã‚ŠãŒã¨ã† , ç§ã¯ã‚ãªãŸãŒãã‚Œã‹ã‚‰æœ‰ç”¨ãªä½•ã‹ã‚’å¾—ãŸã“ã¨ã‚’é¡˜ã£ã¦ã„ã¾ã™ã€‚"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}