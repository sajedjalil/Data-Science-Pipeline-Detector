{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport json\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import tensorflow.compat.v1.keras.backend as K\n# import tensorflow as tf\n# tf.compat.v1.disable_eager_execution()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# num = int(df[df['image_id'] == '1000015157.jpg']['label'])\n# num\n\n\n# df = df.set_index(\"image_id\")\n# int(df.loc[[\"999329392.jpg\"]]['label'])","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"\n# # ---- This works!!!! Converts jpg into array easily\n# def parse_image(file):\n    \n\n\n#     img = tf.io.read_file(file)\n#     img = tf.image.decode_jpeg(img, channels=3)\n    \n#     img = tf.image.convert_image_dtype(img, tf.float32)\n#     img = tf.image.resize(img, size=(600, 800))\n\n#     return img, image_id\n\n# dataset = tf.data.Dataset.list_files(\"/kaggle/input/cassava-leaf-disease-classification/train_images/*.jpg\")\n\n# dataset = dataset.map(parse_image)\n\n# dataset = dataset.shuffle(20)\n# dataset = dataset.batch(16)\n\n# dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ---- Need to add label\ndef parse_image(dataset_slice):\n    file = dataset_slice['image_id']\n    label = dataset_slice['label']\n    \n#     image_id = str(file).split(\".jpg\")[0][12:]\n#     #image_id = str(file).split(\"', shape\")[0][12:]\n    \n#     #int(df.loc[[image_id]]['label'])\n    \n    # now slicing tensor as a string isn't working, but using the file directly seems to be fine\n    img = tf.io.read_file(\"/kaggle/input/cassava-leaf-disease-classification/train_images/\" + file)#+ image_id + \".jpg\")\n    img = tf.image.decode_jpeg(img, channels=3)\n    \n    img = tf.image.convert_image_dtype(img, tf.float32)\n    img = tf.image.resize(img, size=(300, 400))\n    \n\n    return img, label\n\n\n\ndf = pd.read_csv(\"../input/cassava-leaf-disease-classification/train.csv\")\ndataset = tf.data.Dataset.from_tensor_slices(dict(df))\n\ndataset = dataset.map(parse_image)\n\n\n# Old way that also worked (except it didn't know the shape)\n\n# from PIL import Image\n# def parse_image(file):\n#     file = bytes.decode(file.numpy())\n    \n#     image = tf.constant(np.asarray(Image.open(file)))\n#     return image\n\n#dataset = dataset.map(lambda x: tf.py_function(parse_image, [x], [tf.uint8]))\n\n\ndataset = dataset.shuffle(20)\ndataset = dataset.batch(20)\n# for item in dataset.take(1):\n#     print(str(item['image_id']))\ndataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"next(iter(dataset))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tensor = next(iter(dataset))[0][0]\ntensor","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Creation and Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation=tf.nn.relu),\n                                    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n                                    tf.keras.layers.Dropout(.1),\n                                    \n                                    tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation=tf.nn.relu),\n                                    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n                                    tf.keras.layers.Dropout(.1),\n                                    \n#                                     tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation=tf.nn.relu),\n#                                     tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n#                                     tf.keras.layers.Dropout(.1),\n                                    tf.keras.layers.Flatten(),\n                                    \n#                                    tf.keras.layers.Dense(8192, activation=tf.nn.relu),\n                                    tf.keras.layers.Dropout(.1),\n                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n                                    tf.keras.layers.Dropout(.1),\n                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n                                    tf.keras.layers.Dropout(.1),\n                                    tf.keras.layers.Dense(5, activation=tf.nn.softmax),\n                                    \n])\nmodel.build((None, 300, 400, 3))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nhistory = model.fit(dataset, epochs=10, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -q pyyaml h5py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('simple_conv2d_cassava')\nnew_model = tf.keras.models.load_model('simple_conv2d_cassava')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-- the below was just using cpu, using GPU takes 1/10th the time\n\n### First Run\n*ETA 67 min for one epoch*\n- Batch-size = 16\n- image size was (600, 800)\n- Simple model, one conv2d, pool, flatten, and 2 dense layers\n\nMax accuracy after 2nd-3rd epoch: ~60%, loss @ 1.222 (see downloaded ss)\n\n### Second Run\nBatch-size = 32 --> OOM error\n\n### Third Run\n*ETA 47 min for one epoch*\n- Batch-size = 20\n- image size = (300, 400)\n- more complex model, 2 conv2D and pool, flatten and 3 dense layers (1024, 128, 5)\nalmost done with 5th epoch: accuracy - 94.5%, loss 0.1679\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# old attempts to use dataset\n\n\n# df = pd.read_csv(\"/kaggle/input/cassava-leaf-disease-classification/train.csv\")\n# df['image_id']\n\n# dataset = tf.data.Dataset.from_tensor_slices(dict(df))\n\n# test = dataset.map(parse_image)\n\n#training_generator = tf.keras.preprocessing.image.ImageDataGenerator(validation_split = 0.2, preprocessing_function=parse_image(dataset.take(1)))\n\n# print(dataset.take(1))\n\n# model.fit_generator(generator=training_generator, epochs=5, verbose =1)\n\n\n# fits the model on batches with real-time data augmentation:\n# model.fit(datagen.flow(x_train, y_train, batch_size=32),\n#           steps_per_epoch=len(x_train) / 32, epochs=epochs)\n\n# tf.keras.preprocessing.image.ImageDataGenerator(\n#     featurewise_center=False,\n#     samplewise_center=False,\n#     featurewise_std_normalization=False,\n#     samplewise_std_normalization=False,\n#     zca_whitening=False,\n#     zca_epsilon=1e-06,\n#     rotation_range=0,\n#     width_shift_range=0.0,\n#     height_shift_range=0.0,\n#     brightness_range=None,\n#     shear_range=0.0,\n#     zoom_range=0.0,\n#     channel_shift_range=0.0,\n#     fill_mode=\"nearest\",\n#     cval=0.0,\n#     horizontal_flip=False,\n#     vertical_flip=False,\n#     rescale=None,\n#     preprocessing_function=None,\n#     data_format=None,\n#     validation_split=0.0,\n#     dtype=None,\n# )\n\n\n\n#dataset_pixels = dataset.map(parse_image)\n\n# for image in dataset_pixels.take(2):\n#     print(image.numpy().decode('utf-8'))\n\n\n\n# ------------------------------------------------------------- #\n\n# Way to decode tensor\n# for feature_batch in dataset.take(1):\n#     print(feature_batch['image_id'].numpy())\n#     var = feature_batch['image_id'].numpy().decode('utf-8')\n#     print(var)\n    \n    \n# ------------------------------------------------------------- #\n\n    \n    \n    \n    \n    \n    \n    \n    \n    \n#     for key, value in feature_batch.items():\n\n#         print(\"  {!r:20s}: {}\".format(key, value))\n        \n        \n# dataset_process = dataset.map(parse_image)\n\n    \n# for pixels in dataset_process.take(2):\n#     print(pixels)\n        \n\n\n#df['image_id'] = df['image_id'].str.replace(r'.jpg', '')\n#print(type(df['label'][0]))\n#dataset = tf.convert_to_tensor(df, dtype=tf.int64)\n#tf.convert_to_tensor(my_np_array, dtype=tf.float32)\n\n#type(dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from PIL import Image\n\n# # converts to pixeks\n# img = np.asarray(Image.open(\"/kaggle/input/cassava-leaf-disease-classification/train_images/1578977008.jpg\"))\n# img.shape\n\n# #image_pixels = pd.Series()\n\n\n\n# def parse_image(file_name):\n#     print(file_name.numpy())\n#     print(tf.strings.as_string(file_name['image_id']))\n# #    print(file_name['image_id'].as_string())\n# #     #print(tf.io.decode_raw(file_name['image_id'], tf.uint8))\n    \n# # #     unicode_char_bytes = tf.strings.unicode_split(file_name['image_id'], \"UTF-8\")\n# # #     print(unicode_char_bytes)\n# #     unicode_values = tf.strings.unicode_decode(file_name['image_id'], \"UTF-8\")\n# #     print(unicode_values)\n\n    \n# #     #print(file_name['image_id'].decode('utf-8'))\n# #     print(bytes.decode(file_name['image_id']))\n#     # get string of filename\n#     file = file_name['image_id'].numpy().decode('utf-8')\n#     return np.asarray(Image.open(\"/kaggle/input/cassava-leaf-disease-classification/train_images/\" + str(file)))\n    \n\n# #image_data_list = parse_image(df['image_id'][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.figure(figsize=(15,10))\n\n# for i in range(1,10):\n#     plt.subplot(3,3,i)\n#     plt.tight_layout()\n\n#     plt.imshow(df1.iloc[i-1, 1])\n#     plt.title(label_dict[str(df1.iloc[i-1, 0])])\n\n#     #plt.colorbar()\n#     plt.grid(False)\n\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"convert np array to tensor: ```tf.convert_to_tensor(my_np_array, dtype=tf.float32)```\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}