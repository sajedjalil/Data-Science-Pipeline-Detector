{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"8e7c8928-62c9-0abb-781e-edb0eb38ecf3"},"source":"### Kaggle Invasive Species Monitoring: Get 0.97 accuracy with minimal effort.\nFinetune VGG16 top layers with Keras as described by Francois Chollet here:\n\nhttps://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"},{"cell_type":"markdown","metadata":{"_cell_guid":"f32bc8ff-1fba-1bec-5c28-ad76fa6302d3"},"source":"*chmaxx _ 26.5.17*"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"87c4c624-0670-cbf6-9282-d94bac780c4f"},"outputs":[],"source":"%reset\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\nfrom keras.models import Sequential, load_model, Model\nfrom keras.layers import Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D\nfrom keras.optimizers import SGD\nfrom keras.callbacks import EarlyStopping\n\nfrom keras.callbacks import TensorBoard\nfrom keras_tqdm import TQDMNotebookCallback\nfrom keras import backend as K\n\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\n\nfrom datetime import datetime\nimport os\n\nimport numpy as np\nimport pandas as pd\n\npd.options.mode.chained_assignment = None\npd.options.display.max_rows = 40"},{"cell_type":"markdown","metadata":{"_cell_guid":"97873997-b4a4-b84f-72dd-7f316a107459"},"source":"Import Labels and check distribution."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"32f2db0d-ff38-c04d-c6bd-6c0853d56bc5"},"outputs":[],"source":"file = \"D:/KI/01_keras/_kaggle/_invasiveplants/train_labels.csv\"\ndf = pd.read_csv(file, sep=\",\", error_bad_lines= True)\ndf.invasive.value_counts()"},{"cell_type":"markdown","metadata":{"_cell_guid":"b6d8979b-0339-8bee-1393-22ca3f6f4f47"},"source":"Separate Images according to their labels. Move them to either class folder **false/** or **true/**."},{"cell_type":"markdown","metadata":{"_cell_guid":"4fda719e-f6fb-7dee-4688-f12e51b42655"},"source":"After separating the images into two classes I manually moved 400 images to the validation folder (again with separate folders for the two classes)."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4aea5aea-7ed1-89d7-6787-1aa79f288df4"},"outputs":[],"source":"%cd _kaggle/_invasiveplants/_train\nnames = df.name\nlabels = df.invasive\n\nfor idx, label in enumerate(labels):\n    iname = str(names[idx]) + \".jpg\"\n    if (label == 0):\n        !mv $iname false/\n    elif (label == 1):\n        !mv $iname true/"},{"cell_type":"markdown","metadata":{"_cell_guid":"1f92cddf-7e1a-0c6b-b6ea-891594631fc7","collapsed":true},"source":"### Build the CNN\nWe use the Keras VGG16 application with weights but without top. We add an untrained DNN on top."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"62f77dcc-aae3-4ad5-b990-bb3ae70f983b","collapsed":true},"outputs":[],"source":"vgg16 = VGG16(weights='imagenet', include_top=False)\n\nx = vgg16.get_layer('block5_conv3').output\nx = GlobalAveragePooling2D()(x)\nx = Dense(256, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(1, activation='sigmoid')(x)\n\nmodel_final = Model(inputs=vgg16.input, outputs=x)"},{"cell_type":"markdown","metadata":{"_cell_guid":"535d287a-e050-69fd-dd04-7ecbd183e131"},"source":"Freeze all VGG layers and compile the model."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0f68a5aa-40f9-d6f4-8175-8e830008cfd6"},"outputs":[],"source":"for layer in vgg16.layers:\n    layer.trainable = False\n\nmodel_final.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"},{"cell_type":"markdown","metadata":{"_cell_guid":"7542214f-44a6-46ce-c902-4b391c791d5e"},"source":"### Setup the Datagenerator \nThe interesting point here is, **that we seem to be able to feed any image size to VGG16 and not only 224x224px**. This is particularly meant to improve accuracy for hard to detect images when invasive plants appear only very small in the image. "},{"cell_type":"markdown","metadata":{"_cell_guid":"5fa89f4d-5cc2-9bed-ceb6-5bb406bde105"},"source":"**Hat tip and thanks to Crequena** for that recommendation. See this thread: https://www.kaggle.com/fujisan/use-keras-pre-trained-vgg16-acc-98/comments"},{"cell_type":"markdown","metadata":{"_cell_guid":"7435eacc-1bba-e3ab-010e-377ffcdb9857"},"source":"I first trained with a small size of 300/225px until early stopping. Than I trained again with 600/450px until early stopping. Feel free to try with even bigger sizes."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7396ea9f-530e-e36b-a8d1-a40796294d83"},"outputs":[],"source":"# You need to have these three folders each with two subfolders for the two classes.\ntrain_data_dir = \"D:/KI/01_keras/_kaggle/_invasiveplants/_train\"\nvalidation_data_dir = \"D:/KI/01_keras/_kaggle/_invasiveplants/_validate\"\ntest_data_dir = \"D:/KI/01_keras/_kaggle/_invasiveplants/_test\"\n\n# 600/450 _ 500/375 _ 400/300 _ 300/225\n\nimg_width = 600  # Change image size for training here\nimg_height = 450 # Change image size for training here\n\nbatch_size = 5 # i achieved good and fast results with this small minibatch size for training\nbatch_size_val = 400 # if Tensorflow throws a memory error while validating at end of epoch, decrease validation batch size her\n\n# set data augmentation parameters here\ndatagen = ImageDataGenerator(rescale=1., \n    featurewise_center=True,\n    rotation_range=10,\n    width_shift_range=.1,\n    height_shift_range=.1,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=False,\n    fill_mode=\"reflect\")\n\n# normalization neccessary for correct image input to VGG16\ndatagen.mean=np.array([103.939, 116.779, 123.68],dtype=np.float32).reshape(1,1,3)\n\n# no data augmentation for validation and test set\nvalidgen = ImageDataGenerator(rescale=1., featurewise_center=True)\nvalidgen.mean=np.array([103.939, 116.779, 123.68],dtype=np.float32).reshape(1,1,3)\n\n\ntrain_gen = datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_height, img_width),\n        batch_size=batch_size,\n        class_mode=\"binary\",\n        shuffle=True, \n        #save_to_dir=\"_augmented_images/\", \n        #save_prefix=\"aug_\"\n        )\n\nval_gen = validgen.flow_from_directory(\n        validation_data_dir,\n        target_size=(img_height, img_width),\n        batch_size=batch_size,\n        class_mode=\"binary\",\n        shuffle=True)\n\ntest_gen = validgen.flow_from_directory(\n        test_data_dir,\n        target_size=(img_height, img_width),\n        batch_size=1,\n        class_mode=\"binary\",\n        shuffle=False)\n\ntrain_samples = len(train_gen.filenames)\nvalidation_samples = len(val_gen.filenames)\ntest_samples = len(test_gen.filenames)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8ad1c88e-b3d8-2fc1-2e88-0fdd6d366fc1"},"outputs":[],"source":"now = datetime.now()\n\n# \"_tf_logs\" is my Tensorboard folder. Change this to your setup if you want to use TB\nlogdir = \"_tf_logs/\" + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\ntb = TensorBoard(log_dir=logdir)\n\nepochs=10\n\n# I stopped training automagically with EarlyStopping after 3 consecutive epochs without improvement\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n\nmodel_final.fit_generator(train_gen, epochs=epochs, \n                          steps_per_epoch=int(train_samples/batch_size), \n                          validation_data=val_gen, \n                          validation_steps=batch_size_val, \n                          verbose=0, callbacks=[early_stopping, tb, TQDMNotebookCallback()])"},{"cell_type":"markdown","metadata":{"_cell_guid":"e1436d45-0681-c1ec-a490-2a361d8ce16c"},"source":"After doing two rounds of training until early stopping (one with a small image size, one with a larger size) we do a second round of training that now includes the last convolutional block of the VGG16, that until now was frozen."},{"cell_type":"markdown","metadata":{"_cell_guid":"4bdafad6-acfc-2807-014e-66cf690acd77"},"source":"First we printout all layers. Than we freeze all layers up to the last conv block and compile again."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d1f2acc7-b284-acf2-4389-bba96be8a57e"},"outputs":[],"source":"for i, layer in enumerate(model_final.layers):\n   print(i, layer.name)\n\nfor layer in model_final.layers[:15]:\n   layer.trainable = False\nfor layer in model_final.layers[15:]:\n   layer.trainable = True"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9f781510-b59f-a635-7036-ccd591ea8085","collapsed":true},"outputs":[],"source":"model_final.compile(optimizer=SGD(lr=0.0001, momentum=0.9, nesterov=True),  loss='binary_crossentropy', metrics=['accuracy'])"},{"cell_type":"markdown","metadata":{"_cell_guid":"11badc01-bb30-0a11-0783-17d78d3974b2"},"source":"Again I did two rounds of training in this second step: First round with a small image size until early stopping, than a second round with the large image size."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e4378335-15c7-6c83-3a81-7fc260a90729"},"outputs":[],"source":"now = datetime.now()\n\n# \"_tf_logs\" is my Tensorboard folder. Change this to your setup if you want to use TB\nlogdir = \"_tf_logs/\" + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\ntb = TensorBoard(log_dir=logdir)\n\nepochs=50\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n\nmodel_final.fit_generator(train_gen, epochs=epochs, \n                          steps_per_epoch=int(train_samples/batch_size), \n                          validation_data=val_gen, \n                          validation_steps=int(validation_samples/batch_size), \n                          verbose=0, callbacks=[early_stopping, tb, TQDMNotebookCallback()])"},{"cell_type":"markdown","metadata":{"_cell_guid":"b049cfbc-2648-f8b6-afe2-ce235f6991bf"},"source":"Make predictions for test images and save as submission CSV."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3984a18b-eda4-aa5d-f5da-b3c86dd1a2ec"},"outputs":[],"source":"preds = model_final.predict_generator(test_gen, 1531)\npreds_rounded = []\n\nfor pred in preds:\n    if (pred > .5):\n        preds_rounded.append(\"1\")\n    else:\n        preds_rounded.append(\"0\")\n\npreds_filenames = [int(x.replace(\"test\\\\\", \"\").replace(\".jpg\", \"\")) for x in test_gen.filenames]   \n\ndata = (list(zip(preds_filenames, preds_rounded)))\n\ndf_result = pd.DataFrame(data, columns=[\"name\", \"invasive\"])\ndf_result = df_result.sort_values(\"name\")\ndf_result.index = df_result[\"name\"]\ndf_result = df_result.drop([\"name\"], axis=1)\n\ndf_result.to_csv(\"_kaggle/_invasiveplants/submission_03.csv\", encoding=\"utf8\", index=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b385a71a-70ec-4922-04ef-c2767c8f4a30"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}