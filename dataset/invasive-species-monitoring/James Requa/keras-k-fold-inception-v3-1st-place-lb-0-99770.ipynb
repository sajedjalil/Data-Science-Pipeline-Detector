{"metadata":{"language_info":{"mimetype":"text/x-python","file_extension":".py","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","codemirror_mode":{"version":3,"name":"ipython"},"version":"3.6.1"},"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"_uuid":"4cf432a0d22e9e6d1d5261bfd63d9fe7ad03fe88","collapsed":true,"_cell_guid":"0d16d13f-57b1-42e6-9c75-64c7d2d7d5fe"},"source":"import cv2\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import KFold\nfrom sklearn import metrics\nimport keras\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.layers import Dense, Input, Flatten, Dropout, GlobalAveragePooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau","outputs":[],"cell_type":"code","execution_count":1},{"metadata":{"_uuid":"65653e763d41204bc764f7e1151829b735e3fb91","_cell_guid":"20db2f1a-471f-4092-8692-9ec8bd0ee1de"},"cell_type":"markdown","source":"# Load Datasets\nSince we will be using a generator we don't need to actually load in any files into memory, all we need is the filepaths :)"},{"metadata":{"_uuid":"5a87f8e975cf12b89ac6a966adee3b8b73249b52","collapsed":true,"_cell_guid":"36d7aa24-8652-4a54-9993-79e305405312"},"source":"path = \"../input/train/\"\n\ndef load_train(path):\n    train_set = pd.read_csv('../input/train_labels.csv')\n    train_label = np.array(train_set['invasive'].iloc[: ])\n    train_files = []\n    for i in range(len(train_set)):\n        train_files.append(path + str(int(train_set.iloc[i][0])) +'.jpg')\n    train_set['name'] = train_files\n    return train_files, train_set, train_label\n\ntrain_files, train_set, train_label = load_train(path)\n\ntrain_set.head()","outputs":[],"cell_type":"code","execution_count":2},{"metadata":{"_uuid":"1ef06e8b5391d5a2a8ccea97aad7cd45b6c5cef4","collapsed":true,"_cell_guid":"3acf64c8-5d75-49d7-9e4e-578067f0b29d"},"source":"path = \"../input/test/\"\n\ndef load_test(path):\n    test_set = pd.read_csv('../input/sample_submission.csv')\n    test_files = []\n    for i in range(len(test_set)):\n        test_files.append(path + str(int(test_set.iloc[i][0])) +'.jpg')\n    return test_files, test_set\n\ntest_files, test_set = load_test(path)\n\ntest_set.head()","outputs":[],"cell_type":"code","execution_count":4},{"metadata":{"_uuid":"a4e584f2db16d8ba9e58ad74437a28e488425aed","_cell_guid":"65b7adf0-65d6-4763-9442-b1da1c6b8090"},"cell_type":"markdown","source":"# Define CNN Model Architecture\n*Kaggle can't access the weights file*"},{"metadata":{"_uuid":"9fa3d8ba6655ff38a08d8742f2da53ca4abef30d","collapsed":true,"_cell_guid":"4c72959d-a413-4a8c-8caa-855f52cb292c"},"source":"img_height = 800\nimg_width = 800\nimg_channels = 3\nimg_dim = (img_height, img_width, img_channels)\n\ndef inceptionv3(img_dim=img_dim):\n    input_tensor = Input(shape=img_dim)\n    base_model = InceptionV3(include_top=False,\n                   weights='imagenet',\n                   input_shape=img_dim)\n    bn = BatchNormalization()(input_tensor)\n    x = base_model(bn)\n    x = GlobalAveragePooling2D()(x)\n    x = Dropout(0.5)(x)\n    output = Dense(1, activation='sigmoid')(x)\n    model = Model(input_tensor, output)\n    return model\n\nmodel = inceptionv3()\nmodel.summary()","outputs":[],"cell_type":"code","execution_count":null},{"metadata":{"_uuid":"13890f2f0a7066552fdab668c93cdc95ef02fb5b","_cell_guid":"7c87589b-c9e5-48ac-b674-8ee7e3daeb31"},"cell_type":"markdown","source":"# Train Model\nHere we use 5-fold cross-validation to train the model. Submission file is saved with the average of all folds. Additionally, prediction arrays are saved for each fold in case we want to hand-pick results from an individual fold."},{"metadata":{"_uuid":"09697a7318bcd523a8080dd8d4474b598a58481a","collapsed":true,"_cell_guid":"12be4cfa-0094-40e5-bbca-0f477e6ea403"},"source":"def train_model(model, batch_size, epochs, img_size, x, y, test, n_fold, kf):\n    roc_auc = metrics.roc_auc_score\n    preds_train = np.zeros(len(x), dtype = np.float)\n    preds_test = np.zeros(len(test), dtype = np.float)\n    train_scores = []; valid_scores = []\n\n    i = 1\n\n    for train_index, test_index in kf.split(x):\n        x_train = x.iloc[train_index]; x_valid = x.iloc[test_index]\n        y_train = y[train_index]; y_valid = y[test_index]\n\n        def augment(src, choice):\n            if choice == 0:\n                # Rotate 90\n                src = np.rot90(src, 1)\n            if choice == 1:\n                # flip vertically\n                src = np.flipud(src)\n            if choice == 2:\n                # Rotate 180\n                src = np.rot90(src, 2)\n            if choice == 3:\n                # flip horizontally\n                src = np.fliplr(src)\n            if choice == 4:\n                # Rotate 90 counter-clockwise\n                src = np.rot90(src, 3)\n            if choice == 5:\n                # Rotate 180 and flip horizontally\n                src = np.rot90(src, 2)\n                src = np.fliplr(src)\n            return src\n\n        def train_generator():\n            while True:\n                for start in range(0, len(x_train), batch_size):\n                    x_batch = []\n                    y_batch = []\n                    end = min(start + batch_size, len(x_train))\n                    train_batch = x_train[start:end]\n                    for filepath, tag in train_batch.values:\n                        img = cv2.imread(filepath)\n                        img = cv2.resize(img, img_size)\n                        img = augment(img, np.random.randint(6))\n                        x_batch.append(img)\n                        y_batch.append(tag)\n                    x_batch = np.array(x_batch, np.float32) / 255.\n                    y_batch = np.array(y_batch, np.uint8)\n                    yield x_batch, y_batch\n\n        def valid_generator():\n            while True:\n                for start in range(0, len(x_valid), batch_size):\n                    x_batch = []\n                    y_batch = []\n                    end = min(start + batch_size, len(x_valid))\n                    valid_batch = x_valid[start:end]\n                    for filepath, tag in valid_batch.values:\n                        img = cv2.imread(filepath)\n                        img = cv2.resize(img, img_size)\n                        img = augment(img, np.random.randint(6))\n                        x_batch.append(img)\n                        y_batch.append(tag)\n                    x_batch = np.array(x_batch, np.float32) / 255.\n                    y_batch = np.array(y_batch, np.uint8)\n                    yield x_batch, y_batch\n\n        def test_generator():\n            while True:\n                for start in range(0, len(test), batch_size):\n                    x_batch = []\n                    end = min(start + batch_size, len(test))\n                    test_batch = test[start:end]\n                    for filepath in test_batch:\n                        img = cv2.imread(filepath)\n                        img = cv2.resize(img, img_size)\n                        x_batch.append(img)\n                    x_batch = np.array(x_batch, np.float32) / 255.\n                    yield x_batch\n\n        callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=1e-4),\n             ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, cooldown=1, \n                               verbose=1, min_lr=1e-7),\n             ModelCheckpoint(filepath='inception.fold_' + str(i) + '.hdf5', verbose=1,\n                             save_best_only=True, save_weights_only=True, mode='auto')]\n\n        train_steps = len(x_train) / batch_size\n        valid_steps = len(x_valid) / batch_size\n        test_steps = len(test) / batch_size\n        \n        model = model\n\n        model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', \n                      metrics = ['accuracy'])\n\n        model.fit_generator(train_generator(), train_steps, epochs=epochs, verbose=1, \n                            callbacks=callbacks, validation_data=valid_generator(), \n                            validation_steps=valid_steps)\n\n        model.load_weights(filepath='inception.fold_' + str(i) + '.hdf5')\n\n        print('Running validation predictions on fold {}'.format(i))\n        preds_valid = model.predict_generator(generator=valid_generator(),\n                                      steps=valid_steps, verbose=1)[:, 0]\n\n        print('Running train predictions on fold {}'.format(i))\n        preds_train = model.predict_generator(generator=train_generator(),\n                                      steps=train_steps, verbose=1)[:, 0]\n\n        valid_score = roc_auc(y_valid, preds_valid)\n        train_score = roc_auc(y_train, preds_train)\n        print('Val Score:{} for fold {}'.format(valid_score, i))\n        print('Train Score: {} for fold {}'.format(train_score, i))\n\n        valid_scores.append(valid_score)\n        train_scores.append(train_score)\n        print('Avg Train Score:{0:0.5f}, Val Score:{1:0.5f} after {2:0.5f} folds'.format\n              (np.mean(train_scores), np.mean(valid_scores), i))\n\n        print('Running test predictions with fold {}'.format(i))\n\n        preds_test_fold = model.predict_generator(generator=test_generator(),\n                                              steps=test_steps, verbose=1)[:, -1]\n\n        preds_test += preds_test_fold\n\n        print('\\n\\n')\n\n        i += 1\n\n        if i <= n_fold:\n            print('Now beginning training for fold {}\\n\\n'.format(i))\n        else:\n            print('Finished training!')\n\n    preds_test /= n_fold\n\n\n    return preds_test","outputs":[],"cell_type":"code","execution_count":5},{"metadata":{"_uuid":"709a92be4fadeb381414491e1029ad03a188a385","collapsed":true,"_cell_guid":"75775f5a-2d75-4e64-88f4-b8b713393765"},"source":"batch_size = 5\nepochs = 50\nn_fold = 5\nimg_size = (img_height, img_width)\nkf = KFold(n_splits=n_fold, shuffle=True)\n\ntest_pred = train_model(model, batch_size, epochs, img_size, train_set, \n                        train_label, test_files, n_fold, kf)\n\ntest_set['invasive'] = test_pred\ntest_set.to_csv('./submission.csv', index = None)","outputs":[],"cell_type":"code","execution_count":null},{"metadata":{"_uuid":"4ce0e9ea7237b6000f5d1c4df040543bfe7763ad","collapsed":true,"_cell_guid":"4013acf0-550f-46d5-a8f8-ef404ba7204b"},"source":"","outputs":[],"cell_type":"code","execution_count":null}],"nbformat_minor":1,"nbformat":4}