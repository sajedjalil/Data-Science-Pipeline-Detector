{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"d4434c1e-1c48-444f-cc64-c1fc396b18cb"},"source":"Just try the apriori probabilities based on the trainset labels."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"03f6da41-d46e-660f-be7a-a171a5ad9625"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8c1b1bf9-c5da-c8e0-a42a-d59ad946ff6f"},"outputs":[],"source":"labels = pd.read_csv(\"../input/train_labels.csv\")\nsub = pd.read_csv(\"../input/sample_submission.csv\", index_col=0)\nsub.invasive = labels.invasive.mean()\nsub.to_csv(\"apriori.csv\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"73b54a21-929b-3ae2-82e8-ce2a50f88b88"},"source":"Update: ....and then I did indeed learn something:\n\n - This competition does not have logloss as a metric.\n - It is smart to read the evaluation metric before making a kernel!\n - And the AUC metric does not improve the leaderboard score when using apriori probabilities over 0.5. "}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}