{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"395ebcae-279b-0516-f8e1-e5f96481674d"},"source":"Use Resnet model for bottleneck feature extraction.\n---------------------------\n\nResnet pre-trained model is available [here][1].\nI have used Inception_resnet_v2 model.\n\nIf you come across this transfer learning concept first time, go through the [chapter of stanford CS231][2]. This blog will clear all your doubts about transfer learning.\n\n\n  [1]: https://github.com/tensorflow/models/tree/master/slim\n  [2]: http://cs231n.github.io/transfer-learning/"},{"cell_type":"markdown","metadata":{"_cell_guid":"ed055506-3a6c-cb70-90c2-f486007a07ce"},"source":"Import required libraries"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d73e2815-e46f-26a2-04ca-86096d638781"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport cv2\nimport math\nfrom glob import glob\nimport os\nfrom scipy.misc import imread, imresize, imshow\nfrom sklearn.model_selection import train_test_split\nimport tensorflow.contrib.slim as slim\nimport tensorflow as tf\nfrom sklearn.linear_model import LogisticRegression"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"67630f0d-4a2b-f14d-0d48-0c26811a50ef"},"outputs":[],"source":"master = pd.read_csv(\"../input/train_labels.csv\")\nmaster.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"7bed7fa4-57fa-1839-dc3c-3694f35827bb"},"source":"Function read images in batches."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d598f6a5-5c75-28be-87df-b952e40cbf0d"},"outputs":[],"source":"data_dir = \"../input/train/\"\n\ndef get_image_data_for_batch(images_in_batch):\n    batch_image_data = []#np.empty([10, 299,299,3], dtype=np.int)\n    for ix in images_in_batch:\n        temp = imread(data_dir+str(ix)+\".jpg\")\n        temp = imresize(temp, [299,299,3])\n        batch_image_data.append(temp)# - np.mean(temp)\n    return np.array(batch_image_data)"},{"cell_type":"markdown","metadata":{"_cell_guid":"8367ffb3-4b99-6ff6-7225-f11d2996fea1"},"source":"Let's declare the whole inception_resnet model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a4fb629d-591e-ee08-4d32-2a25f0b65efd"},"outputs":[],"source":"\nimport tensorflow as tf\n\nslim = tf.contrib.slim\n\n\ndef block35(net, scale=1.0, activation_fn=tf.nn.relu, scope=None, reuse=None):\n  \"\"\"Builds the 35x35 resnet block.\"\"\"\n  with tf.variable_scope(scope, 'Block35', [net], reuse=reuse):\n    with tf.variable_scope('Branch_0'):\n      tower_conv = slim.conv2d(net, 32, 1, scope='Conv2d_1x1')\n    with tf.variable_scope('Branch_1'):\n      tower_conv1_0 = slim.conv2d(net, 32, 1, scope='Conv2d_0a_1x1')\n      tower_conv1_1 = slim.conv2d(tower_conv1_0, 32, 3, scope='Conv2d_0b_3x3')\n    with tf.variable_scope('Branch_2'):\n      tower_conv2_0 = slim.conv2d(net, 32, 1, scope='Conv2d_0a_1x1')\n      tower_conv2_1 = slim.conv2d(tower_conv2_0, 48, 3, scope='Conv2d_0b_3x3')\n      tower_conv2_2 = slim.conv2d(tower_conv2_1, 64, 3, scope='Conv2d_0c_3x3')\n    mixed = tf.concat(axis=3, values=[tower_conv, tower_conv1_1, tower_conv2_2])\n    up = slim.conv2d(mixed, net.get_shape()[3], 1, normalizer_fn=None,\n                     activation_fn=None, scope='Conv2d_1x1')\n    net += scale * up\n    if activation_fn:\n      net = activation_fn(net)\n  return net\n\n\ndef block17(net, scale=1.0, activation_fn=tf.nn.relu, scope=None, reuse=None):\n  \"\"\"Builds the 17x17 resnet block.\"\"\"\n  with tf.variable_scope(scope, 'Block17', [net], reuse=reuse):\n    with tf.variable_scope('Branch_0'):\n      tower_conv = slim.conv2d(net, 192, 1, scope='Conv2d_1x1')\n    with tf.variable_scope('Branch_1'):\n      tower_conv1_0 = slim.conv2d(net, 128, 1, scope='Conv2d_0a_1x1')\n      tower_conv1_1 = slim.conv2d(tower_conv1_0, 160, [1, 7],\n                                  scope='Conv2d_0b_1x7')\n      tower_conv1_2 = slim.conv2d(tower_conv1_1, 192, [7, 1],\n                                  scope='Conv2d_0c_7x1')\n    mixed = tf.concat(axis=3, values=[tower_conv, tower_conv1_2])\n    up = slim.conv2d(mixed, net.get_shape()[3], 1, normalizer_fn=None,\n                     activation_fn=None, scope='Conv2d_1x1')\n    net += scale * up\n    if activation_fn:\n      net = activation_fn(net)\n  return net\n\n\ndef block8(net, scale=1.0, activation_fn=tf.nn.relu, scope=None, reuse=None):\n  \"\"\"Builds the 8x8 resnet block.\"\"\"\n  with tf.variable_scope(scope, 'Block8', [net], reuse=reuse):\n    with tf.variable_scope('Branch_0'):\n      tower_conv = slim.conv2d(net, 192, 1, scope='Conv2d_1x1')\n    with tf.variable_scope('Branch_1'):\n      tower_conv1_0 = slim.conv2d(net, 192, 1, scope='Conv2d_0a_1x1')\n      tower_conv1_1 = slim.conv2d(tower_conv1_0, 224, [1, 3],\n                                  scope='Conv2d_0b_1x3')\n      tower_conv1_2 = slim.conv2d(tower_conv1_1, 256, [3, 1],\n                                  scope='Conv2d_0c_3x1')\n    mixed = tf.concat(axis=3, values=[tower_conv, tower_conv1_2])\n    up = slim.conv2d(mixed, net.get_shape()[3], 1, normalizer_fn=None,\n                     activation_fn=None, scope='Conv2d_1x1')\n    net += scale * up\n    if activation_fn:\n      net = activation_fn(net)\n  return net\n\n\ndef inception_resnet_v2(inputs, num_classes=1001, is_training=True,\n                        dropout_keep_prob=0.8,\n                        reuse=None,\n                        scope='InceptionResnetV2'):\n  \"\"\"Creates the Inception Resnet V2 model.\n\n  Args:\n    inputs: a 4-D tensor of size [batch_size, height, width, 3].\n    num_classes: number of predicted classes.\n    is_training: whether is training or not.\n    dropout_keep_prob: float, the fraction to keep before final layer.\n    reuse: whether or not the network and its variables should be reused. To be\n      able to reuse 'scope' must be given.\n    scope: Optional variable_scope.\n\n  Returns:\n    logits: the logits outputs of the model.\n    end_points: the set of end_points from the inception model.\n  \"\"\"\n  end_points = {}\n\n  with tf.variable_scope(scope, 'InceptionResnetV2', [inputs], reuse=reuse):\n    with slim.arg_scope([slim.batch_norm, slim.dropout],\n                        is_training=is_training):\n      with slim.arg_scope([slim.conv2d, slim.max_pool2d, slim.avg_pool2d],\n                          stride=1, padding='SAME'):\n\n        # 149 x 149 x 32\n        net = slim.conv2d(inputs, 32, 3, stride=2, padding='VALID',\n                          scope='Conv2d_1a_3x3')\n        end_points['Conv2d_1a_3x3'] = net\n        # 147 x 147 x 32\n        net = slim.conv2d(net, 32, 3, padding='VALID',\n                          scope='Conv2d_2a_3x3')\n        end_points['Conv2d_2a_3x3'] = net\n        # 147 x 147 x 64\n        net = slim.conv2d(net, 64, 3, scope='Conv2d_2b_3x3')\n        end_points['Conv2d_2b_3x3'] = net\n        # 73 x 73 x 64\n        net = slim.max_pool2d(net, 3, stride=2, padding='VALID',\n                              scope='MaxPool_3a_3x3')\n        end_points['MaxPool_3a_3x3'] = net\n        # 73 x 73 x 80\n        net = slim.conv2d(net, 80, 1, padding='VALID',\n                          scope='Conv2d_3b_1x1')\n        end_points['Conv2d_3b_1x1'] = net\n        # 71 x 71 x 192\n        net = slim.conv2d(net, 192, 3, padding='VALID',\n                          scope='Conv2d_4a_3x3')\n        end_points['Conv2d_4a_3x3'] = net\n        # 35 x 35 x 192\n        net = slim.max_pool2d(net, 3, stride=2, padding='VALID',\n                              scope='MaxPool_5a_3x3')\n        end_points['MaxPool_5a_3x3'] = net\n\n        # 35 x 35 x 320\n        with tf.variable_scope('Mixed_5b'):\n          with tf.variable_scope('Branch_0'):\n            tower_conv = slim.conv2d(net, 96, 1, scope='Conv2d_1x1')\n          with tf.variable_scope('Branch_1'):\n            tower_conv1_0 = slim.conv2d(net, 48, 1, scope='Conv2d_0a_1x1')\n            tower_conv1_1 = slim.conv2d(tower_conv1_0, 64, 5,\n                                        scope='Conv2d_0b_5x5')\n          with tf.variable_scope('Branch_2'):\n            tower_conv2_0 = slim.conv2d(net, 64, 1, scope='Conv2d_0a_1x1')\n            tower_conv2_1 = slim.conv2d(tower_conv2_0, 96, 3,\n                                        scope='Conv2d_0b_3x3')\n            tower_conv2_2 = slim.conv2d(tower_conv2_1, 96, 3,\n                                        scope='Conv2d_0c_3x3')\n          with tf.variable_scope('Branch_3'):\n            tower_pool = slim.avg_pool2d(net, 3, stride=1, padding='SAME',\n                                         scope='AvgPool_0a_3x3')\n            tower_pool_1 = slim.conv2d(tower_pool, 64, 1,\n                                       scope='Conv2d_0b_1x1')\n          net = tf.concat(axis=3, values=[tower_conv, tower_conv1_1,\n                              tower_conv2_2, tower_pool_1])\n\n        end_points['Mixed_5b'] = net\n        net = slim.repeat(net, 10, block35, scale=0.17)\n\n        # 17 x 17 x 1088\n        with tf.variable_scope('Mixed_6a'):\n          with tf.variable_scope('Branch_0'):\n            tower_conv = slim.conv2d(net, 384, 3, stride=2, padding='VALID',\n                                     scope='Conv2d_1a_3x3')\n          with tf.variable_scope('Branch_1'):\n            tower_conv1_0 = slim.conv2d(net, 256, 1, scope='Conv2d_0a_1x1')\n            tower_conv1_1 = slim.conv2d(tower_conv1_0, 256, 3,\n                                        scope='Conv2d_0b_3x3')\n            tower_conv1_2 = slim.conv2d(tower_conv1_1, 384, 3,\n                                        stride=2, padding='VALID',\n                                        scope='Conv2d_1a_3x3')\n          with tf.variable_scope('Branch_2'):\n            tower_pool = slim.max_pool2d(net, 3, stride=2, padding='VALID',\n                                         scope='MaxPool_1a_3x3')\n          net = tf.concat(axis=3, values=[tower_conv, tower_conv1_2, tower_pool])\n\n        end_points['Mixed_6a'] = net\n        net = slim.repeat(net, 20, block17, scale=0.10)\n\n        # Auxiliary tower\n        with tf.variable_scope('AuxLogits'):\n          aux = slim.avg_pool2d(net, 5, stride=3, padding='VALID',\n                                scope='Conv2d_1a_3x3')\n          aux = slim.conv2d(aux, 128, 1, scope='Conv2d_1b_1x1')\n          aux = slim.conv2d(aux, 768, aux.get_shape()[1:3],\n                            padding='VALID', scope='Conv2d_2a_5x5')\n          aux = slim.flatten(aux)\n          aux = slim.fully_connected(aux, num_classes, activation_fn=None,\n                                     scope='Logits')\n          end_points['AuxLogits'] = aux\n\n        with tf.variable_scope('Mixed_7a'):\n          with tf.variable_scope('Branch_0'):\n            tower_conv = slim.conv2d(net, 256, 1, scope='Conv2d_0a_1x1')\n            tower_conv_1 = slim.conv2d(tower_conv, 384, 3, stride=2,\n                                       padding='VALID', scope='Conv2d_1a_3x3')\n          with tf.variable_scope('Branch_1'):\n            tower_conv1 = slim.conv2d(net, 256, 1, scope='Conv2d_0a_1x1')\n            tower_conv1_1 = slim.conv2d(tower_conv1, 288, 3, stride=2,\n                                        padding='VALID', scope='Conv2d_1a_3x3')\n          with tf.variable_scope('Branch_2'):\n            tower_conv2 = slim.conv2d(net, 256, 1, scope='Conv2d_0a_1x1')\n            tower_conv2_1 = slim.conv2d(tower_conv2, 288, 3,\n                                        scope='Conv2d_0b_3x3')\n            tower_conv2_2 = slim.conv2d(tower_conv2_1, 320, 3, stride=2,\n                                        padding='VALID', scope='Conv2d_1a_3x3')\n          with tf.variable_scope('Branch_3'):\n            tower_pool = slim.max_pool2d(net, 3, stride=2, padding='VALID',\n                                         scope='MaxPool_1a_3x3')\n          net = tf.concat(axis=3, values=[tower_conv_1, tower_conv1_1,\n                              tower_conv2_2, tower_pool])\n\n        end_points['Mixed_7a'] = net\n\n        net = slim.repeat(net, 9, block8, scale=0.20)\n        net = block8(net, activation_fn=None)\n\n        net = slim.conv2d(net, 1536, 1, scope='Conv2d_7b_1x1')\n        end_points['Conv2d_7b_1x1'] = net\n\n        with tf.variable_scope('Logits'):\n          end_points['PrePool'] = net\n          net = slim.avg_pool2d(net, net.get_shape()[1:3], padding='VALID',\n                                scope='AvgPool_1a_8x8')\n          net = slim.flatten(net)\n\n          net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\n                             scope='Dropout')\n\n          end_points['PreLogitsFlatten'] = net\n          logits = slim.fully_connected(net, num_classes, activation_fn=None,\n                                        scope='Logits')\n          end_points['Logits'] = logits\n          end_points['Predictions'] = tf.nn.softmax(logits, name='Predictions')\n\n    return logits, end_points\ninception_resnet_v2.default_image_size = 299\n\n\ndef inception_resnet_v2_arg_scope(weight_decay=0.00004,\n                                  batch_norm_decay=0.9997,\n                                  batch_norm_epsilon=0.001):\n  \"\"\"Yields the scope with the default parameters for inception_resnet_v2.\n\n  Args:\n    weight_decay: the weight decay for weights variables.\n    batch_norm_decay: decay for the moving average of batch_norm momentums.\n    batch_norm_epsilon: small float added to variance to avoid dividing by zero.\n\n  Returns:\n    a arg_scope with the parameters needed for inception_resnet_v2.\n  \"\"\"\n  # Set weight_decay for weights in conv2d and fully_connected layers.\n  with slim.arg_scope([slim.conv2d, slim.fully_connected],\n                      weights_regularizer=slim.l2_regularizer(weight_decay),\n                      biases_regularizer=slim.l2_regularizer(weight_decay)):\n\n    batch_norm_params = {\n        'decay': batch_norm_decay,\n        'epsilon': batch_norm_epsilon,\n    }\n    # Set activation_fn and parameters for batch_norm.\n    with slim.arg_scope([slim.conv2d], activation_fn=tf.nn.relu,\n                        normalizer_fn=slim.batch_norm,\n                        normalizer_params=batch_norm_params) as scope:\n      return scope\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"d0e95db7-fe77-945f-477d-f2d1ca191855"},"source":"Now we can extract bottleneck features from any layer. I am using 2nd last layer of the network."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5badd8e2-ed64-8a79-536a-e1a4e4f3e91c"},"outputs":[],"source":"X = tf.placeholder(tf.float32, shape=[None, 299,299,3])\nwith slim.arg_scope(inception_resnet_v2_arg_scope()):\n    logits, end_points = inception_resnet_v2(X, num_classes=1001,is_training=False)\npredictions = end_points[\"PreLogitsFlatten\"] #you can try with other layers too. Intermediate layers \n#may give good accuracy, but feature size for each image will be in 10k's."},{"cell_type":"markdown","metadata":{"_cell_guid":"14315839-7722-8067-2c17-dadc3cc97252"},"source":"You have to download the checkpoint for initializing the network with pre-trained weights. Link to download the checkpoint file is [here][1].  As I am unable load this checkpoint file here, further part of this notebook won't run here. But I have tested it on my machine, works well.\n\n\n  [1]: http://download.tensorflow.org/models/inception_resnet_v2_2016_08_30.tar.gz"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"002470cf-c2e8-dea3-6327-4e7ec1c250e7"},"outputs":[],"source":"X = tf.placeholder(tf.float32, shape=[None, 299,299,3])\nwith slim.arg_scope(inception_resnet_v2_arg_scope()):\n    logits, end_points = inception_resnet_v2(X, num_classes=1001,is_training=False)\npredictions = end_points[\"PreLogitsFlatten\"]\nsaver = tf.train.Saver()\nsess = tf.Session()\nsaver.restore(sess, \"PATH TO inception_resnet_v2_2016_08_30.ckpt\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"aa6779c5-e038-2665-4b3d-44cd206f1b12"},"source":"Now we can extract features from pre-trained model and use those features for applying any other algorithm."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6ccf41b9-9e7f-7f7d-3274-7f6cc9e66b2d"},"outputs":[],"source":"number_of_batches = int(np.ceil(float(len(master))/10))\nbottleneck_features_train = np.empty(shape=[0, 1536])\nfor i in range(number_of_batches):\n    batch_x = master[(i*10):(i*10)+10]['name']\n    image_data = get_image_data_for_batch(batch_x)\n    btnk_batch = sess.run(predictions, feed_dict={X:image_data})\n    bottleneck_features_train = np.concatenate([bottleneck_features_train, btnk_batch], axis=0)"},{"cell_type":"markdown","metadata":{"_cell_guid":"8b6a0028-6f14-67ca-4e21-015a5ac5f7da"},"source":"Same way, we have extract features for test images."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d3ed2dea-cd96-353b-3157-a9a9c2b6f561"},"outputs":[],"source":"data_dir = \"../input/test/\"\ntest_image_names = range(1, 1532)\nnumber_of_batches_test = int(np.ceil(1531.0/10))\nbottleneck_features_test = np.empty(shape=[0, 1536])\nfor i in range(number_of_batches_test):\n    batch_x = test_image_names[(i*10):(i*10)+10]\n    image_data = get_image_data_for_batch(batch_x)\n    btnk_batch = sess.run(predictions, feed_dict={X:image_data})\n    bottleneck_features_test = np.concatenate([bottleneck_features_test, btnk_batch], axis=0)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a9a4f451-e7a9-57c0-1ee4-3c500f2cb7a2"},"outputs":[],"source":"I have used Logistic regression from scikit learn, you can use other powerful algorithms like randomForest, xgboost etc."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cbb4d1b9-b8c8-7402-fbe0-34c5b9b0f255"},"outputs":[],"source":"model =  LogisticRegression()\nmodel.fit(bottleneck_features_train,master['invasive'])\n\npredictions = model.predict(bottleneck_features_test)\n#Read sample submission file \nsample_submission = pd.read_csv(\"../input/sample_submission.csv\")\nsample_submission['invasive'] = predictions\n\nsample_submission.to_csv(\"inception_resnet_logistic\", index=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"14c91eb1-7585-416c-055d-a1dcf147660a"},"source":"Next task will be to try different layers for bottleneck extraction, try other networks like InceptionV4, Resnet-150. Also to fine-tune these networks with our data."}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}