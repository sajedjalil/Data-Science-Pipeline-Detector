{"cells":[{"execution_count":null,"cell_type":"markdown","metadata":{"_cell_guid":"2282e0e6-bed3-4375-5b9b-05c80fe29f27","_uuid":"e1f3635fe12d8b2454a90e8644b494d817c6d38e"},"source":"use Keras pre-trained VGG16\n---------------------------\nthis is my first notebook. \n\npre-trained VGG16 is quickly and good performance.\n\nI learned from official Keras blog tutorial \n[Building powerful image classification models using very little data][1]\n\n\n  [1]: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html","outputs":[]},{"execution_count":null,"cell_type":"markdown","metadata":{"_cell_guid":"fdca4192-cf9d-1f5f-7e8f-30ae5e468db4","_uuid":"867de32f2c7aa9ac25601fc940006294e33daca1"},"source":"## resize train data and test data ##","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"aab06a15-51b8-13e2-172a-b3e62aa3738a","_uuid":"c1ebca0bdc0b5bbc4f293bc4b53a80c721595d1a"},"source":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport math\nfrom glob import glob\nimport os\n\nmaster = pd.read_csv(\"../input/train_labels.csv\")\nmaster.head()","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"e68a78fc-8470-e081-27ad-eca99e6fdd1f","_uuid":"7123c5327c0b72f3b3775fbb986c8808691ed912"},"source":"img_path = \"../input/train/\"\n\ny = []\nfile_paths = []\nfor i in range(len(master)):\n    file_paths.append( img_path + str(i+1) +'.jpg' )\n    y.append(master.iloc[i][1])\ny = np.array(y)\ny[:10]","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"34636940-b7b8-64f6-6ca7-1ad97081ea7b","_uuid":"786578085deb6df7474ef431cac853b5b2f2cb85"},"source":"#image reseize & centering & crop \n\ndef centering_image(img):\n    size = [256,256]\n    \n    img_size = img.shape[:2]\n    \n    # centering\n    row = (size[1] - img_size[0]) // 2\n    col = (size[0] - img_size[1]) // 2\n    resized = np.zeros(list(size) + [img.shape[2]], dtype=np.uint8)\n    resized[row:(row + img.shape[0]), col:(col + img.shape[1])] = img\n\n    return resized\n\n\nx = []\nfor i, file_path in enumerate(file_paths):\n    #read image\n    img = cv2.imread(file_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n    #resize\n    if(img.shape[0] > img.shape[1]):\n        tile_size = (int(img.shape[1]*256/img.shape[0]),256)\n    else:\n        tile_size = (256, int(img.shape[0]*256/img.shape[1]))\n\n    #centering\n    img = centering_image(cv2.resize(img, dsize=tile_size))\n    \n    #out put 224*224px \n    img = img[16:240, 16:240]\n    x.append(img)\n\nx = np.array(x)","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"1f371b5e-579e-cd78-51f3-bad30c864a85","_uuid":"e6bcd11e76d06e0f626d7e6817e5b41e407d2820"},"source":"sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\nimg_path = \"../input/test/\"\n\ntest_names = []\nfile_paths = []\n\nfor i in range(len(sample_submission)):\n    test_names.append(sample_submission.iloc[i][0])\n    file_paths.append( img_path + str(int(sample_submission.iloc[i][0])) +'.jpg' )\n    \ntest_names = np.array(test_names)","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"8f849642-855e-63b0-26e8-107724628353","_uuid":"a46292d10d3b4191bf17ecdcd17dca9012c297c6"},"source":"test_images = []\nfor file_path in file_paths:\n    #read image\n    img = cv2.imread(file_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n    #resize\n    if(img.shape[0] > img.shape[1]):\n        tile_size = (int(img.shape[1]*256/img.shape[0]),256)\n    else:\n        tile_size = (256, int(img.shape[0]*256/img.shape[1]))\n\n    #centering\n    img = centering_image(cv2.resize(img, dsize=tile_size))\n    \n    #out put 224*224px \n    img = img[16:240, 16:240]\n    test_images.append(img)\n    \n    path, ext = os.path.splitext( os.path.basename(file_paths[0]) )\n\ntest_images = np.array(test_images)","outputs":[]},{"execution_count":null,"cell_type":"markdown","metadata":{"_cell_guid":"9d5db4fe-b1ca-80d9-eb5a-decb9e71fa8b","_uuid":"5e8137287ac14c52c93a0ada9505f011bf8a2406"},"source":"save numpy array.\n\nUsually I separate code, data format and CNN.","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"trusted":false,"_cell_guid":"54ee247b-1228-bfb2-46c0-0b08e3455375","_uuid":"1856bed9e5c82d812aa5b70362757ef7788f5089"},"source":"#np.savez('224.npz', x=x, y=y, test_images=test_images, test_names=test_names)","outputs":[]},{"execution_count":null,"cell_type":"markdown","metadata":{"_cell_guid":"2880329f-76a5-b385-a3ba-609820535f34","_uuid":"14c05681d068cff130218a64b8d712b6643a642d"},"source":"## split train data and validation data  ##","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"aea9535d-9baa-214c-afd1-1595ae44cb0f","_uuid":"1175eff0000655ea4f3a88db9f517d5d1e186658"},"source":"data_num = len(y)\nrandom_index = np.random.permutation(data_num)\n\nx_shuffle = []\ny_shuffle = []\nfor i in range(data_num):\n    x_shuffle.append(x[random_index[i]])\n    y_shuffle.append(y[random_index[i]])\n    \nx = np.array(x_shuffle) \ny = np.array(y_shuffle)","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"3aa4f607-c45c-c738-3b99-ced4f3fa5a28","_uuid":"2b0b9ffc7af2d6b6b753c3a7b26aa4fe0645f442"},"source":"val_split_num = round(0.2*len(y))\nx_train = x[val_split_num:]\ny_train = y[val_split_num:]\nx_test = x[:val_split_num]\ny_test = y[:val_split_num]\n\nprint('x_train', x_train.shape)\nprint('y_train', y_train.shape)\nprint('x_test', x_test.shape)\nprint('y_test', y_test.shape)","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"8b6caf1c-bc20-63cb-52a3-33dc71c5529d","_uuid":"a200f1690c3a42c93ec45aaa0ba17159f9d58dc7"},"source":"# normalization\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255","outputs":[]},{"execution_count":null,"cell_type":"markdown","metadata":{"_cell_guid":"9fa975c5-3996-8f40-65c0-a49c09ec26ae","_uuid":"e2fbcc308baa0f9077da8335d86414795424ac46"},"source":"use Keras pre-trained VGG16\n---------------------------\n\nbut kaggle karnel is not run","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"18861ee9-b81b-27ef-3846-0d04aafd3560","_uuid":"c3435513a0394d37bdaaf66e65253af4e7cda3be"},"source":"from keras.models import Sequential, Model, load_model\nfrom keras import applications\nfrom keras import optimizers\nfrom keras.layers import Dropout, Flatten, Dense\n\nimg_rows, img_cols, img_channel = 224, 224, 3\n\nbase_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, img_channel))","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"trusted":false,"_cell_guid":"a7b158cf-ed3e-6ebc-868f-acddcce92344","_uuid":"0d9538b15c6e98a46fc40cbb5e93e8e56a1c0b80"},"source":"add_model = Sequential()\nadd_model.add(Flatten(input_shape=base_model.output_shape[1:]))\nadd_model.add(Dense(256, activation='relu'))\nadd_model.add(Dense(1, activation='sigmoid'))\n\nmodel = Model(inputs=base_model.input, outputs=add_model(base_model.output))\nmodel.compile(loss='binary_crossentropy', optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n              metrics=['accuracy'])\n\nmodel.summary()","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"trusted":false,"_cell_guid":"ecf8491d-cbba-505d-e5d8-fecaae32e35e","_uuid":"43116cb710a13f336ca8316289b3ba5f43ebdfc9"},"source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint\n\nbatch_size = 32\nepochs = 50\n\ntrain_datagen = ImageDataGenerator(\n        rotation_range=30, \n        width_shift_range=0.1,\n        height_shift_range=0.1, \n        horizontal_flip=True)\ntrain_datagen.fit(x_train)\n\n\nhistory = model.fit_generator(\n    train_datagen.flow(x_train, y_train, batch_size=batch_size),\n    steps_per_epoch=x_train.shape[0] // batch_size,\n    epochs=epochs,\n    validation_data=(x_test, y_test),\n    callbacks=[ModelCheckpoint('VGG16-transferlearning.model', monitor='val_acc', save_best_only=True)]\n)","outputs":[]},{"execution_count":null,"cell_type":"markdown","metadata":{"_cell_guid":"e0e5efc6-cf1a-32fb-5b2e-d1ea2b244a5d","_uuid":"1f9902f6e3abd8002d4839195b14b735c95f7e98"},"source":"## predict test data ##","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"trusted":false,"_cell_guid":"8c3ac15d-fb29-2531-cbe5-f763c35623a5","_uuid":"4f6ca7411686df49ade418f9cc95eb3133a7d2ca"},"source":"test_images = test_images.astype('float32')\ntest_images /= 255","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"trusted":false,"_cell_guid":"7740ecc9-98c6-c62b-f71e-69d8c34ed451","_uuid":"ecc8a7f8ef827ee7054bb54e0acd5aed0e9c1e75"},"source":"predictions = model.predict(test_images)","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"trusted":false,"_cell_guid":"a90d25c4-6587-a574-27db-5af5e9ff17d3","_uuid":"1e23fcb11f110d5e168ec04d7bf8cdc2d3685446"},"source":"sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n\nfor i, name in enumerate(test_names):\n    sample_submission.loc[sample_submission['name'] == name, 'invasive'] = predictions[i]\n\nsample_submission.to_csv(\"submit.csv\", index=False)","outputs":[]},{"execution_count":null,"cell_type":"markdown","metadata":{"_cell_guid":"3d36278d-01ef-c87b-3710-bf3820562913","_uuid":"d5216261177f57a0c1ac2445143d8ba86e9b8cf7"},"source":"What to do next?\n----------------\n\nI will try pre-trained ResNet, fine tune ResNet.\n\nThis idea seems to be helpful.\n\n[Dogs vs. Cats Redux Playground Competition, 3rd Place Interview][1]\n\n\n  [1]: http://blog.kaggle.com/2017/04/20/dogs-vs-cats-redux-playground-competition-3rd-place-interview-marco-lugo/","outputs":[]}],"nbformat":4,"metadata":{"_change_revision":0,"_is_fork":false,"language_info":{"name":"python","version":"3.6.1","codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python","file_extension":".py","nbconvert_exporter":"python","pygments_lexer":"ipython3"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":0}