{"nbformat_minor":1,"nbformat":4,"cells":[{"execution_count":null,"cell_type":"code","outputs":[],"source":"import pandas as pd\nimport numpy as np\nfrom PIL import Image, ImageFile\nimport time\nfrom keras import applications\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom keras.callbacks import TensorBoard, LambdaCallback, ModelCheckpoint","metadata":{"collapsed":true,"_uuid":"4f18bb6207ef27ac00169083f9e9cb70ad42d016","_cell_guid":"58dc3c9a-ecf1-4974-80c4-f4f0b68c4f8c"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"train_path = '../input/train/'\ntrain_labels = pd.read_csv('../input/train_labels.csv')\nprint(train_labels.head())","metadata":{"collapsed":true,"_uuid":"cee693c5ea2c5eef8fc4e804cd28f30648816a01","_cell_guid":"42309bbc-f3e3-4435-aa21-7cfa309c80b1"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"ImageFile.LOAD_TRUNCATED_IMAGES=True\ndef get_image(path):\n    img = Image.open(path)\n    img = img.resize((289,217))\n    return img","metadata":{"collapsed":true,"_uuid":"6732e7916f6cb16e5de393172b2d6944c7356e49","_cell_guid":"3a71bb30-595e-46ed-9555-a3b218674d87"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"x_train = np.zeros((1377,217,289,3))\nx_val = np.zeros((459,217,289,3))\ny_train = np.array(train_labels.invasive.values[0:1377]) \ny_val = np.array(train_labels.invasive.values[1377:1836])","metadata":{"collapsed":true,"_uuid":"8f5f2eea802b9b9ee0572418562133d5ffebe6a5","_cell_guid":"75aec168-82c3-40f9-92ad-2db7f0e8a850"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"for i in range(1377):\n    file_no = i+1\n    x_train[i] = get_image(train_path + str(file_no) + '.jpg')\n    if i % 100 == 0:\n        print('train pics finished: ' + str(i))\nfor i in range(459):\n    file_no = i+1378\n    x_val[i] = get_image(train_path + str(file_no) + '.jpg')\n    \n    if i % 100 == 0:\n        print('validation pics finished: ' + str(i))\n","metadata":{"collapsed":true,"_uuid":"173d969a211e53f6de882432de63c27a1eeb8555","_cell_guid":"1e65c27e-30a1-4f81-96d6-3f65183c32cf"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"train_datagen = ImageDataGenerator(\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        rescale=1./255,\n        zoom_range=0.1,\n        horizontal_flip=True,\n        fill_mode='nearest')\n\nvalid_datagen = ImageDataGenerator(\n        rescale=1./255)","metadata":{"collapsed":true,"_uuid":"802aeafc597be6df49da30cc244ee989a0728a4f","_cell_guid":"9f1c184b-8d2f-43f0-bd75-06dc0681766d"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"#Kaggle does not support downloading weights\nbase_model = applications.InceptionV3(weights='imagenet',include_top=False,input_shape=(217,289,3))","metadata":{"collapsed":true,"_uuid":"989558e045e191bcdaeac351eb4e7aeef304a558","_cell_guid":"3c6ff18d-4abf-4b15-adcb-d4b07baf06b1"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"pred = base_model.output\npred = GlobalAveragePooling2D()(pred)\npred = Dense(1024, activation='relu')(pred)\npred = Dropout(0.4)(pred)\npred = Dense(1,activation='softmax')(pred)\nmodel=Model(inputs=base_model.input, outputs=pred)","metadata":{"collapsed":true,"_uuid":"f19b30a0eda115a449397d7c1880f86582e6c5ab","_cell_guid":"e9bde67e-e722-4aa5-9769-e1be29688cb7"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"for layer in base_model.layers:\n    layer.trainable = False","metadata":{"collapsed":true,"_uuid":"e9cf0c32e305adca87574580d7885a0bf6845fc5","_cell_guid":"732f58f7-91ff-45c3-8682-15beaba22731"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])","metadata":{"collapsed":true,"_uuid":"3a8ea7acd3e9cdd9e4bd9ad9dea38efc6bc9a241","_cell_guid":"32bab09d-954f-4980-acd7-2f412a803162"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"history = model.fit_generator(train_datagen.flow(x_train,y_train, batch_size=32),\n                    steps_per_epoch = len(x_train)//32, epochs = 100,\n                    validation_data = valid_datagen.flow(x_val,y_val, batch_size=32),\n                    validation_steps = len(y_val)//32,\n                    verbose=1)","metadata":{"collapsed":true,"_uuid":"bbe71fec87bcf63f96a5d86be158604e52239cd6","_cell_guid":"cfac4391-5460-400f-9dda-ac827b0c4ef2"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"","metadata":{"collapsed":true,"_uuid":"9c0d3b5b7e4154405824d380e13ed64e3459e9e8","_cell_guid":"b8290529-86a2-49cd-bba6-6bec3c479b2f"}}],"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"pygments_lexer":"ipython3","mimetype":"text/x-python","file_extension":".py","version":"3.6.1","codemirror_mode":{"version":3,"name":"ipython"},"name":"python","nbconvert_exporter":"python"}}}