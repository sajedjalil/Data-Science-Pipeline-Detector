{"cells":[{"source":"**Objective**","cell_type":"markdown","outputs":[],"metadata":{"_uuid":"f5a163b5658ef4fed6d12f7da4788ee7047f4e65","_execution_state":"idle","collapsed":false,"_cell_guid":"55d7d507-4a1c-4ce6-9fb0-9bb57a3b78ba"},"execution_count":null},{"source":"\nIn this notebook, we are going to predict the presence of invasive species from the pictures taken in a Brazilian national forest.","cell_type":"markdown","outputs":[],"metadata":{"_uuid":"92251aeabce3f1a5da1b2346736b34b6f6b79fa9","_execution_state":"idle","collapsed":false,"_cell_guid":"c32fff1f-224c-4e57-a863-93712d17ab1a"},"execution_count":null},{"source":"Check the input files we have","cell_type":"markdown","outputs":[],"metadata":{"_uuid":"04cfb2144271e043d290eae47157ae29172eb6db","_execution_state":"idle","collapsed":false,"_cell_guid":"05b71c99-b38a-4c50-b6ac-f2492ba2a683"},"execution_count":null},{"source":"import numpy as np \nimport pandas as pd \n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","cell_type":"code","outputs":[],"metadata":{"trusted":false,"_uuid":"477a9b28e600d7db109873a614c2fc80fa571213","_execution_state":"idle","_cell_guid":"f3f07f2e-e744-417d-aa2e-01bd50735e43"},"execution_count":1},{"source":"Let's see the top 5 rows from train_label file","cell_type":"markdown","outputs":[],"metadata":{"_uuid":"0d321112e1d2e4e351983d48cd14bf3113535cf5","_execution_state":"idle","collapsed":false,"_cell_guid":"6f2e39ea-ade4-4ae5-bb08-7530123518d6"},"execution_count":null},{"source":"train_labels_df = pd.read_csv(\"../input/train_labels.csv\")\ntrain_labels_df.head()","cell_type":"code","outputs":[],"metadata":{"trusted":false,"_uuid":"53ba0a063a29ba1d1ba6d0509128f5ce2d71862f","_execution_state":"idle","collapsed":false,"_cell_guid":"0e020bc5-6ee5-4f49-bfdf-04206b89080c"},"execution_count":2},{"source":"train_labels_df.tail()","cell_type":"code","outputs":[],"metadata":{"trusted":false,"_uuid":"4e29cb8126f38b5b9c6115c5abb3bc4739473b2c","_execution_state":"idle","collapsed":false,"_cell_guid":"19340fdf-1d58-426e-beec-2683f2ece0c9"},"execution_count":3},{"source":"train_labels_df.describe() #describing train_labels_df","cell_type":"code","outputs":[],"metadata":{"trusted":false,"_uuid":"fbc380c14b16ad6acdf5e8ad67f385955887f26d","_execution_state":"idle","collapsed":false,"_cell_guid":"6bb9f50f-1a02-4666-bae5-a1adc2fc5bc1"},"execution_count":4},{"source":"train_labels_df.invasive.value_counts() #finding how many invasive and not invasive samples in train data","cell_type":"code","outputs":[],"metadata":{"trusted":false,"_uuid":"e4124c4ac830bdb791fa8effe2c680de851ea8b7","_execution_state":"idle","collapsed":false,"_cell_guid":"2e45350a-9958-40fe-a0bb-662149aaf635"},"execution_count":5},{"source":"Find how many images in both train and test folders","cell_type":"markdown","outputs":[],"metadata":{"_uuid":"b677d47e810d4ee0010dd2d57881325b6a7e0275","_execution_state":"idle","collapsed":false,"_cell_guid":"935ec0c9-48ce-4f39-97cb-c0502ff1afe1"},"execution_count":null},{"source":"#Getting image names from both train and test folders\ntrain_images_names = check_output([\"ls\", \"../input/train/\"]).decode(\"utf8\")\ntrain_images_names = train_images_names.split(\"\\n\")\ntest_images_names = check_output([\"ls\", \"../input/test/\"]).decode(\"utf8\")\ntest_images_names = test_images_names.split(\"\\n\")\nprint(\"Total train images\",len(train_images_names))\nprint(\"Total test images\",len(test_images_names))","cell_type":"code","outputs":[],"metadata":{"trusted":false,"_uuid":"d9184f428a9e506d5e0cd0fc859b48aa384c03e5","_execution_state":"idle","collapsed":false,"_cell_guid":"ed73c4d3-de6e-415e-b614-12dfddd34fa9"},"execution_count":6},{"source":"Creating test dataframe for submission using test images names","cell_type":"markdown","outputs":[],"metadata":{"_uuid":"372ee27612110a0b474430b1c2d2771fe83bc4ca","_execution_state":"idle","collapsed":false,"_cell_guid":"c58eccad-d61d-403f-b722-a0ed8e616dce"},"execution_count":null},{"source":"test_df = pd.DataFrame()\ntest_df[\"name\"] = [test_image.split(\".\")[0] for test_image in test_images_names]\ntest_df.head()","cell_type":"code","outputs":[],"metadata":{"trusted":false,"_uuid":"ab7255bfaca005e08188eb7e4c1b92edd3a56159","_execution_state":"idle","collapsed":false,"_cell_guid":"d3576861-b744-43b3-9db0-69c38cb54ab0"},"execution_count":7},{"source":"Lets see some sample images for both invasive and non-invasive now.","cell_type":"markdown","outputs":[],"metadata":{"_uuid":"a910965bbd2602e8ad0866f2b0df1353a48cc221","_execution_state":"idle","collapsed":false,"_cell_guid":"1c3a9d83-9fc2-4675-abe2-d8943875fcbc"},"execution_count":null},{"source":" **3.jpg** is invasive and **4.jpg** is non-invasive species. ","cell_type":"markdown","outputs":[],"metadata":{"_uuid":"33c02c1d7cd77b5937060eea778120e0ad40ba03","_execution_state":"idle","collapsed":false,"_cell_guid":"c21aa5ca-8eb9-45af-9ee9-a33617a49715"},"execution_count":null},{"source":"% pylab inline\nimport os\nimport random\n\nimport pandas as pd\nfrom scipy.misc import imread\nprint(\"See train images with invasive and without invasive species\")\nprint(\"3.jpg - With Invasive species\")\nimg = imread(\"../input/train/3.jpg\")\nimshow(img)","cell_type":"code","outputs":[],"metadata":{"trusted":false,"_uuid":"ee6a0166877a29099a7ff5dcc1de01e52939334f","_execution_state":"idle","collapsed":false,"_cell_guid":"297765b2-cbe2-45e4-9d60-c8382f8e9ea3"},"execution_count":8},{"source":"print(\"4.jpg - Non-Invasive species\")\nimg1 = imread(\"../input/train/4.jpg\")\nimshow(img1)","cell_type":"code","outputs":[],"metadata":{"trusted":false,"_uuid":"e219d306a235ef0d82a9213b08fe4b196b74ea46","_execution_state":"idle","collapsed":false,"_cell_guid":"3e9c84ef-08d8-4b5b-8fc5-4004ebe1708d"},"execution_count":9},{"source":"#importing all the necessary modules\n% pylab inline\nimport os\nimport random\n\nimport pandas as pd\nfrom scipy.misc import imread\n\nroot_dir = os.path.abspath('.')\ndata_dir = '../input/'","cell_type":"code","outputs":[],"metadata":{"trusted":false,"_uuid":"8fc0ea213bcfbc29cbcd5374baa785844d53b0fb","_execution_state":"idle","collapsed":false,"_cell_guid":"85c17b7f-284f-4f67-abcc-310a614899f4"},"execution_count":10},{"source":"Script to randomly select an image and printed it","cell_type":"markdown","outputs":[],"metadata":{"_uuid":"dd6bc4e73d9400c3a70982eda21478d6f3350031","_execution_state":"idle","collapsed":false,"_cell_guid":"161ff655-6ac9-487a-8cd5-7c968b02ad87"},"execution_count":null},{"source":"i = random.choice(train_labels_df.index)\n\nimg_name = str(train_labels_df.name[i])+\".jpg\"\nimg = imread(os.path.join(data_dir, 'train', img_name))\n\nimshow(img)\nprint(\"Image\",img_name)\nprint(\"Invasive\", train_labels_df.invasive[i])","cell_type":"code","outputs":[],"metadata":{"trusted":false,"_uuid":"b80d0b263b06500b6761552d86960293191d94af","_execution_state":"idle","collapsed":false,"_cell_guid":"e79b6d29-5049-4055-af26-05f608d37a59"},"execution_count":11},{"source":"All images are different in size. This may reduce the model accuracy. So we need to resize all the images to same size.","cell_type":"markdown","outputs":[],"metadata":{"_uuid":"b8d8b45118e123d9e076b8722ef272d5a7d0e085","_execution_state":"idle","collapsed":false,"_cell_guid":"9fa153ac-0ce5-416b-9dbf-a745761fe98a"},"execution_count":null},{"source":"Load all the images and resize them into a single numpy array.","cell_type":"markdown","outputs":[],"metadata":{"_uuid":"f4f4ceabbcbcdfc361a7f821e467148091c746c1","_execution_state":"idle","collapsed":false,"_cell_guid":"eadbc4f1-da91-48fe-9bbd-c5722e1e49b5"},"execution_count":null},{"source":"#Resizing train images\nfrom scipy.misc import imresize\n\ntemp = []\n\n\nfor img_name in train_labels_df.name:\n    img_path = os.path.join(data_dir, 'train', str(img_name)+\".jpg\")\n    img = imread(img_path)\n    img = imresize(img, (32, 32))\n\n    img = img.astype('float32')\n    temp.append(img)\ntrain_x = np.stack(temp)","cell_type":"code","outputs":[],"metadata":{"trusted":false,"_uuid":"5c9dec864433ef3ba0a865f6496d61cdb64e25cb","_execution_state":"idle","collapsed":false,"_cell_guid":"7cd040fa-7446-4d26-af52-c99f3b3b0643"},"execution_count":12},{"source":"print(test_df.tail()) #Last row is null\ntest_df = test_df[:-1] #So removing last row from the test dataframe\nprint(test_df.tail())","cell_type":"code","outputs":[],"metadata":{"trusted":false,"_uuid":"d8fac962c3435bda3da7efb1a52d4126732ec4ea","_execution_state":"idle","collapsed":false,"_cell_guid":"6dece268-fd2e-407f-a1b8-637ad2896000"},"execution_count":13},{"source":"#Resizing test images\ntemp = []\ni=0\nfor img_name in test_df.name:\n    img_path = os.path.join(data_dir, 'test', str(img_name)+\".jpg\")\n    try:\n        img = imread(img_path)\n        img = imresize(img, (32, 32))\n\n        img = img.astype('float32')\n        temp.append(img)\n        i=i+1\n    except:\n        continue\ntest_x = np.stack(temp)","cell_type":"code","outputs":[],"metadata":{"trusted":false,"_uuid":"07742c63d6ad2f993aecc0fbda433a4b5cb93c43","_execution_state":"idle","collapsed":false,"_cell_guid":"70370050-e66e-47d1-932b-2949dbbaf046"},"execution_count":14},{"source":"We can do one more thing that could help us build a better model; i.e. we can normalize our images. Normalizing the images will make our train faster.","cell_type":"markdown","outputs":[],"metadata":{"_uuid":"6e3540623f3254b1c9be9a3633c5797fbb55babb","_execution_state":"idle","collapsed":false,"_cell_guid":"2a0496b9-9ffe-4b45-8b68-1346e4431427"},"execution_count":null},{"source":"train_x = train_x / 255\ntest_x = test_x / 255","cell_type":"code","outputs":[],"metadata":{"trusted":false,"_uuid":"d219a9d44660d07bc67f8a85bd8d97b147458a87","_execution_state":"idle","collapsed":false,"_cell_guid":"7b28ddc9-0b8f-4ae7-a58f-bd08a5d3f28d"},"execution_count":15},{"source":"Let's see the distribution of invasive images in our data","cell_type":"markdown","outputs":[],"metadata":{"_uuid":"f221603db109847a86221bcf9e90f28bfae6a6cd","_execution_state":"idle","collapsed":false,"_cell_guid":"87a74862-b602-461f-9b46-370e63a93607"},"execution_count":null},{"source":"train_labels_df.invasive.value_counts(normalize=True)","cell_type":"code","outputs":[],"metadata":{"trusted":false,"_uuid":"89566657077ecacfc8268e04ee12bcc1e2db29a3","_execution_state":"idle","collapsed":false,"_cell_guid":"4680f68b-ec0e-460f-9971-e2e20cba06f8"},"execution_count":16},{"source":"First we should specify all the parameters we will be using in our network","cell_type":"markdown","outputs":[],"metadata":{"_uuid":"0284384acae3779f03f18bd362796c2e78f5a25e","_execution_state":"idle","collapsed":false,"_cell_guid":"59276297-0dd2-435d-8e9a-9a33e5ea0db5"},"execution_count":null},{"source":"import keras\nfrom sklearn.preprocessing import LabelEncoder\n\nlb = LabelEncoder()\ntrain_y = lb.fit_transform(train_labels_df.invasive)\ntrain_y = keras.utils.np_utils.to_categorical(train_y)\n\ninput_num_units = (32, 32, 3)\nhidden_num_units = 500\noutput_num_units = 2\n\nepochs = 5\nbatch_size = 128","cell_type":"code","outputs":[],"metadata":{"trusted":false,"_uuid":"951fd2ec99a1ee1819ccdd0aff3efd4901ca8e61","_execution_state":"idle","collapsed":false,"_cell_guid":"363e6e61-ed60-4793-90a8-edbf9ea55ba3"},"execution_count":17},{"source":"#Import the necessary keras modules\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, InputLayer\n\n#Define our network\nmodel = Sequential([\n  InputLayer(input_shape=input_num_units),\n  Flatten(),\n  Dense(units=hidden_num_units, activation='relu'),\n  Dense(units=output_num_units, activation='softmax'),\n])","cell_type":"code","outputs":[],"metadata":{"trusted":false,"_uuid":"8bbddc1e54592000e502f9dd74cb918c9d50d293","_execution_state":"idle","collapsed":false,"_cell_guid":"998c3e10-f12d-4c25-b880-d16e476e5788"},"execution_count":18},{"source":"To see how our model looks like; lets print it","cell_type":"markdown","outputs":[],"metadata":{"_uuid":"df2b446cf1439c180ba8c79535c22aedb959e860","_execution_state":"idle","collapsed":false,"_cell_guid":"79788823-a816-4b03-9a6c-bea02c5a2032"},"execution_count":null},{"source":"model.summary()","cell_type":"code","outputs":[],"metadata":{"trusted":false,"_uuid":"01985f3ddd80985a312f8cf787a490529b22c671","_execution_state":"idle","collapsed":false,"_cell_guid":"f5c3fbaf-377b-41b5-ba11-ba382aefad93"},"execution_count":19},{"source":"#Compile and train our network\nmodel.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.fit(train_x, train_y, batch_size=batch_size,epochs=epochs,verbose=1)","cell_type":"code","outputs":[],"metadata":{"trusted":false,"_uuid":"50112b9531a1e117a983fb123aeb7ae6c2347361","_execution_state":"idle","collapsed":false,"_cell_guid":"07ba8ce8-0043-471e-b01a-9304b6253525"},"execution_count":20},{"source":"Letâ€™s tweak the code a little bit to cross validate it.","cell_type":"markdown","outputs":[],"metadata":{"_uuid":"6d05d88af339d6e9e613fa486a9ce02245641566","_execution_state":"idle","collapsed":false,"_cell_guid":"a733097f-b672-4cf8-8410-8a9388f8a5a4"},"execution_count":null},{"source":"model.fit(train_x, train_y, batch_size=batch_size,epochs=epochs,verbose=1, validation_split=0.2)","cell_type":"code","outputs":[],"metadata":{"trusted":false,"_uuid":"28fa445944db59da9ffe2d2f88a9d06758aa7efc","_execution_state":"idle","collapsed":false,"_cell_guid":"403265f6-edb5-4133-908f-7f7c9d12281a"},"execution_count":21},{"source":"Let's submit the result","cell_type":"markdown","outputs":[],"metadata":{"_uuid":"8881e201641a35b9148b5f1547e4f6fd5bb21e4c","_execution_state":"idle","collapsed":false,"_cell_guid":"b7ff1e84-b378-455e-acaa-d18b92607329"},"execution_count":null},{"source":"pred = model.predict_classes(test_x)\npred = lb.inverse_transform(pred)\ntest_df['invasive'] = pred","cell_type":"code","outputs":[],"metadata":{"trusted":false,"_uuid":"99fcfd17559eca199449d93f18c59c5a017605ff","_execution_state":"idle","collapsed":false,"_cell_guid":"9af56e91-58ee-48b4-a657-0fdf79acc0e9"},"execution_count":22},{"source":"test_df['invasive'].value_counts()","cell_type":"code","outputs":[],"metadata":{"trusted":false,"_uuid":"97f21865268da0d5f3f1cb2ae5e8ac54e8d1538d","_execution_state":"idle","collapsed":false,"_cell_guid":"dc5b1a1b-366b-4e34-9479-7df91c7aea6a"},"execution_count":23},{"source":"test_df.to_csv('submission.csv', index=False)","cell_type":"code","outputs":[],"metadata":{"trusted":false,"_uuid":"0fb14548e863909c4efecc95c888192e9fa99191","_execution_state":"idle","collapsed":false,"_cell_guid":"cd0a337e-a0b3-4246-8c7d-2fcc67a9f53a"},"execution_count":24},{"source":"Let's test our model using random image","cell_type":"markdown","outputs":[],"metadata":{"_uuid":"4ea27c62561667135cf3a72bd2fc9846df073e1a","_execution_state":"idle","collapsed":false,"_cell_guid":"dbab62bb-52d2-4ba9-9dd2-0a7212127ed3"},"execution_count":23},{"source":"i = random.choice(train_labels_df.index)\nimg_name = train_labels_df.name[i]\n\nimg = imread(os.path.join(data_dir, 'train', str(img_name)+\".jpg\")).astype('float32')\nimshow(imresize(img, (128, 128)))\npred = model.predict_classes(train_x)\nprint('Original:', train_labels_df.invasive[i], 'Predicted:', lb.inverse_transform(pred[i]))","cell_type":"code","outputs":[],"metadata":{"trusted":false,"_uuid":"4fba2717467c70299a9e769113ddea38d35996de","_execution_state":"idle","collapsed":false,"_cell_guid":"a10940f2-c75f-45fb-ae70-79ca3ef8be35"},"execution_count":26},{"source":"For creating this notebook, i referred an article Solution for Age Detection Practice Problem from Analytics Vidya.","cell_type":"markdown","outputs":[],"metadata":{"_uuid":"f86d328a496b516a17cfb228920f754fa9527bd7","_execution_state":"idle","collapsed":false,"_cell_guid":"185e4b11-670d-40c6-84f8-7e3ef7caa444"},"execution_count":null},{"source":"If you really feel this is helpful for you. Please upvote it and encourage me to write more. Thanks.","cell_type":"markdown","outputs":[],"metadata":{"_uuid":"77d10afc20c22c68ebbb2bdbf8a3781cff076f73","_execution_state":"idle","collapsed":false,"_cell_guid":"23a67159-7863-43e5-9197-f2e04da65e74"},"execution_count":27},{"source":"","cell_type":"code","outputs":[],"metadata":{"trusted":false,"_uuid":"763fc2f361f5026cc04c3c9dcf8d30ceb0fb6e64","_execution_state":"idle","collapsed":false,"_cell_guid":"88c723ea-c4ff-4a50-9b61-bc019e2fe109"},"execution_count":null}],"nbformat_minor":0,"metadata":{"language_info":{"nbconvert_exporter":"python","version":"3.6.1","mimetype":"text/x-python","file_extension":".py","name":"python","codemirror_mode":{"version":3,"name":"ipython"},"pygments_lexer":"ipython3"},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"nbformat":4}