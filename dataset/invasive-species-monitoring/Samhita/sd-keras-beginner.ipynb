{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"136ac809-5871-a5fe-db13-ab8080fcce6d"},"source":"### This is a basic Keras model for newbies like me to learn. Please upvote if you find it helpful."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3fb424ed-f862-d24c-e82d-1cc1eb658ef0"},"outputs":[],"source":"import os\nimport numpy as np\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')\n\ntrainpath = '../input/train/'\ntestpath = '../input/test/'\n\nprint('# of training files: ' + str(len(os.listdir(trainpath))))\nprint('# of testing files: ' + str(len(os.listdir(testpath))))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"43da194a-26b5-109c-4c08-38ddffb9dec7"},"outputs":[],"source":"# Preview labels\ntrain_labels = pd.read_csv('../input/train_labels.csv')\nprint(train_labels.head())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c933de75-dfc9-d2fe-c097-ecb30f363663"},"outputs":[],"source":"# Preview a noninvasive plant image\nfrom skimage import io, transform\nimport matplotlib.pyplot as plt\n\nsample_image = io.imread(trainpath + '1.jpg')\nprint('Height:{0} Width:{1}'.format(sample_image.shape[0], sample_image.shape[1]))\nplt.imshow(sample_image)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"286240fa-03ba-763d-e004-a818bf1863b4"},"outputs":[],"source":"# Preview an invasive plant image\nsample_image = io.imread(trainpath + '3.jpg')\nplt.imshow(sample_image)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ed640b41-d038-522d-5d40-aa2551fed910"},"outputs":[],"source":"# There is one image in the test set that has different dimensions.\n# It may just need a rotation, but I'm going to ignore it for now.\nprint(io.imread(testpath + '1068.jpg').shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"be2200ae-9978-05ed-aa60-62659bf17abe"},"outputs":[],"source":"# Check that input_shape = (batch_size, rows, columns, channels)\nfrom keras.backend import image_data_format\nprint(image_data_format())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5afaadb9-c310-3abc-2aba-1d0b90ab60bd"},"outputs":[],"source":"# Kernel memory is limited so I'm using 100 images each for training and validation \n# and scaling them down to 150x200 pixels to keep things simple.\n\nx_train = np.empty(shape=(300, 150, 200, 3))\ny_train = np.array(train_labels.invasive.values[0:300])\nx_val = np.empty(shape=(300, 150, 200, 3))\ny_val = np.array(train_labels.invasive.values[300:600])\n\nfor i in range(300):\n    tr_im = io.imread(trainpath + str(i+1) + '.jpg')\n    x_train[i] = transform.resize(tr_im, output_shape=(150, 200, 3))\n\nfor i in range(300):\n    val_im = io.imread(trainpath + str(i+101) + '.jpg')\n    x_val[i] = transform.resize(val_im, output_shape=(150, 200, 3))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"43314562-21a3-8f30-e404-344ff13dc5f1"},"outputs":[],"source":"# Starting architecture\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\nfrom keras.layers import Flatten, Dense, Dropout\nfrom keras.optimizers import SGD\n\nmodel = Sequential()\nmodel.add(ZeroPadding2D((1, 1), input_shape=(150, 200, 3)))\n\nmodel.add(Convolution2D(64, 3, 3, activation='relu'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(64, 3, 3, activation='relu'))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(128, 3, 3, activation='relu'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(128, 3, 3, activation='relu'))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(256, 3, 3, activation='relu'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(256, 3, 3, activation='relu'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(256, 3, 3, activation='relu'))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(512, 3, 3, activation='relu'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(512, 3, 3, activation='relu'))\nmodel.add(ZeroPadding2D((1, 1)))\nmodel.add(Convolution2D(512, 3, 3, activation='relu'))\nmodel.add(MaxPooling2D((2, 2), strides=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer=SGD(lr=1e-5, momentum=0.75, nesterov=False), \n              loss='binary_crossentropy', metrics=['accuracy'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aac3ee00-0a2f-ba84-0e63-8b9ddcf8bca6"},"outputs":[],"source":"# Look at how tensors affect output shape\nprint(model.summary())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c9062a20-3811-e9bd-9be9-279cbd71eb39"},"outputs":[],"source":"# One epoch for demonstration purposes\nmodel.fit(x_train, y_train, epochs=1, batch_size=20)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"368ccc7f-0813-4a48-c3b5-80d309312911"},"outputs":[],"source":"acc = model.evaluate(x_val, y_val)[1]\nprint('Evaluation accuracy:{0}'.format(round(acc, 4)))"},{"cell_type":"markdown","metadata":{"_cell_guid":"15cd26dd-6588-89f8-1bb3-b5f90e42e8d5"},"source":"### More coming soon..."}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}