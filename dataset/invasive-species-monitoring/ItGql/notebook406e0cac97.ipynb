{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"01cd3aa6-9225-9f23-bd87-f8fdc09cfd55"},"source":"cnn code with tensorflow , 96.1% accuracy , python2.7, tensorflow1.1"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1e4306f5-d7c8-b4ca-a3b8-167f8fa9f7b5"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom skimage import io, transform\nimport os, gc, sys, glob\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\ndef read_img(img_path):\n    img = io.imread(img_path)\n    img = transform.resize(img, (128, 128))\n    return img\ntrain_set = pd.read_csv('images/train_labels.csv/train_labels.csv')\ntrain_img, test_img = [], []\nfor img_path in tqdm(train_set['name'].iloc[: ]):\n    train_img.append(read_img('images/train/' + str(img_path) + '.jpg'))\ntrain_img = np.array(train_img, np.float32)\ntrain_label = np.array(train_set['invasive'].iloc[: ])\ntrain_label = train_label.reshape([-1,1])\nval_split_num = int(round(0.2*len(train_label)))\nx_train = train_img[val_split_num:]\ny_train = train_label[val_split_num:]\nx_test = train_img[:val_split_num]\ny_test = train_label[:val_split_num]\nevaluation_data = x_test, y_test\nfrom keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(\n            # featurewise_center = True,\n            #rotation_range = 30,\n            width_shift_range = 0.2,\n            height_shift_range = 0.2,\n            # zca_whitening = True,\n            shear_range = 0.2,\n            zoom_range = 0.2,\n            horizontal_flip = True,\n            vertical_flip = True,\n            fill_mode = 'nearest')\ndatagen.fit(x_train)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"881a138d-e3a5-9dc6-6185-2a5fb5c04419"},"outputs":[],"source":"import tensorflow as tf\nclass network(object):\n    def __init__(self):\n\n        self.learning_rate = 0.001\n        self.batch_size = 64\n        self.nclasses = 1\n        self.n_input = 128*128\n        self.displaytime = 10\n        self.epoches = 1000\n        self.regularation_param = 1e-6\n        self.weights = {\n            'wc1': tf.Variable(initial_value=tf.random_uniform(shape=[3, 3, 3, 16], minval=-0.05, maxval=0.05)),\n            'wc2': tf.Variable(initial_value=tf.random_uniform(shape=[3, 3, 16, 32], minval=-0.05, maxval=0.05)),\n            'wc3': tf.Variable(initial_value=tf.random_uniform(shape=[3, 3, 32, 64], minval=-0.05, maxval=0.05)),\n            'wc4': tf.Variable(initial_value=tf.random_uniform(shape=[3, 3, 64, 128], minval=-0.05, maxval=0.05)),\n            'wd1': tf.Variable(initial_value=tf.random_uniform(shape=[12*12*128, 1024], minval=-0.05, maxval=0.05)),\n            'wd2': tf.Variable(initial_value=tf.random_uniform(shape=[1024, 512], minval=-0.05, maxval=0.05)),\n            # OOM\n            'out': tf.Variable(initial_value=tf.random_normal(shape=[512, self.nclasses]))\n\n        }\n        self.biases = {\n            'b1': tf.Variable(initial_value=tf.zeros([16])),\n            'b2': tf.Variable(initial_value=tf.zeros([32])),\n            'b3': tf.Variable(initial_value=tf.zeros([64])),\n            'b4': tf.Variable(initial_value=tf.zeros([128])),\n            'bfc1': tf.Variable(initial_value=tf.zeros([1024])),\n            'bfc2': tf.Variable(initial_value=tf.zeros([512])),\n            'out': tf.Variable(initial_value=tf.zeros([self.nclasses]))\n        }\n        self.x = tf.placeholder(tf.float32, [None, 128, 128, 3])\n        self.y = tf.placeholder(tf.float32, [None, self.nclasses])\n        self.keep_prob_1 = tf.placeholder(tf.float32)  # dropout (keep probability)\n        self.keep_prob_2 = tf.placeholder(tf.float32)  # dropout (keep probability)\n\n\n    def conv2d(self, x, W, b, strides=1):\n        output = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='VALID')\n        output = tf.nn.bias_add(output, b)\n        return tf.nn.relu(output)\n\n    def maxpool2d(self, x, k=2, strides=2):\n        output = tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, strides, strides, 1], padding='VALID')\n        return output\n\n    def convNet(self, x):\n        ## reshape x for conv layer\n        #x = tf.reshape(x, shape=[-1, 28, 28, 1])\n        conv1 = self.conv2d(x, self.weights['wc1'], self.biases['b1'])\n        pool1 = self.maxpool2d(conv1)\n        conv2 = self.conv2d(pool1, self.weights['wc2'], self.biases['b2'])\n        pool2 = self.maxpool2d(conv2)\n        conv3 = self.conv2d(pool2, self.weights['wc3'], self.biases['b3'])\n        pool3 = self.maxpool2d(conv3)\n        conv4 = self.conv2d(pool3, self.weights['wc4'], self.biases['b4'])\n        ## reshape output for fully-connected layer\n        fc1 = tf.reshape(conv4, [-1, self.weights['wd1'].get_shape().as_list()[0]])\n        fc1 = tf.add(tf.matmul(fc1, self.weights['wd1']), self.biases['bfc1'])\n        fc1 =  tf.nn.relu(fc1)\n        fc1 = tf.nn.dropout(fc1, self.keep_prob_1)\n\n        fc2 = tf.add(tf.matmul(fc1, self.weights['wd2']), self.biases['bfc2'])\n        fc2 =  tf.nn.relu(fc2)\n        fc2 = tf.nn.dropout(fc2, self.keep_prob_2)\n        \n        out = tf.add(tf.matmul(fc2, self.weights['out']), self.biases['out'])\n        #out = tf.reshape([-1,])\n        return out\n\n\n    def cost(self, logits, labels):\n        return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=labels)) \\\n     + self.regularation_param * (tf.nn.l2_loss(self.weights['wc1']) + tf.nn.l2_loss(self.weights['wc2']) + \\\n                                 tf.nn.l2_loss(self.weights['wc3']) + tf.nn.l2_loss(self.weights['wc4']) + \\\n                                 tf.nn.l2_loss(self.weights['wd1']) + tf.nn.l2_loss(self.weights['out']))\n\n    def evaluation(self, pred, labels):\n        \n        correct_pred = tf.equal(tf.round(tf.reduce_max(tf.sigmoid(pred), 1)), tf.reduce_max(labels, 1))\n        return tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n        \n    def train(self, datagen, x_train, y_train, evaluation_data):\n        pred = self.convNet(self.x)\n        cost = self.cost(pred, labels=self.y)\n        acc = self.evaluation(pred, self.y)\n        tf.summary.scalar('cost', cost)\n        optimizer = tf.train.MomentumOptimizer(learning_rate=self.learning_rate, momentum=0.8,use_nesterov=True).minimize(cost)\n        init = tf.global_variables_initializer()\n        merged = tf.summary.merge_all()\n        with tf.Session() as sess:\n            summary_writer = tf.summary.FileWriter('/home/gql/Documents/logs/', sess.graph)\n            sess.run(init)\n            for epoch in range(self.epoches):\n                print \"epoch:\", epoch\n                step = 0\n                n = len(x_train)\n                for batch_x, batch_y in datagen.flow(x_train, y_train, self.batch_size):\n                    \n                    # update mini_bacth\n                    ## bp for mini_batch and update w,b\n                    summary, _= sess.run([merged ,optimizer], feed_dict={self.x: batch_x, self.y: batch_y, self.keep_prob_1: 0.65, self.keep_prob_2: 0.55})\n                    step += 1\n                    summary_writer.add_summary(summary, step)\n                    if step % self.displaytime == 0:\n                        loss, accuracy = sess.run([cost, acc], feed_dict={self.x: batch_x, self.y: batch_y, self.keep_prob_1: 1., self.keep_prob_2: 1.})\n                        print \"Iter \" + str(step * self.batch_size) + \", Minibatch Loss= \" + \\\n                            \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n                            \"{:.5f}\".format(accuracy) + \",Testing Accuracy= \",\\\n                            sess.run(acc, feed_dict={self.x: evaluation_data[0][:256],\n                                              self.y: evaluation_data[1][:256],\n                                              self.keep_prob_1: 1., self.keep_prob_2: 1.})\n                    if step >= n / self.batch_size:\n                        break\n               \n            print 'optimization finished!'\n            print \"Testing Accuracy:\", \\\n                sess.run(acc, feed_dict={self.x: evaluation_data[0],\n                                              self.y: evaluation_data[1],\n                                              self.keep_prob_1: 1., self.keep_prob_2: 1.})\n            print x_train.shape\n            print \"training Accuracy:\", \\\n                sess.run(acc, feed_dict={self.x: x_train[:512],\n                                              self.y: y_train[:512],\n                                              self.keep_prob_1: 1., self.keep_prob_2: 1.})"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"da585cbb-a227-ff2f-f0e1-804409067bc4"},"outputs":[],"source":"net = network()\nnet.train(datagen, x_train, y_train, evaluation_data)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}