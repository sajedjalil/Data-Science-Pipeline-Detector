{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"daf4ca5e-0675-9954-652b-aef8eb9fa5e9"},"source":"This is my first kaggle competition. All suggestions are welcome.\n\nI achieved ~98% AUC using tensorflow v1.2 and pretrained VGG16 model downloaded from http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"70d2fbd1-523b-f183-8a8b-50c306375c8a"},"outputs":[],"source":"%matplotlib inline\nimport os\nimport time\n\nimport pandas\nimport numpy as np\nimport skimage.io as io\nfrom PIL import Image\n\nimport tensorflow as tf\nfrom tensorflow.contrib.slim.nets import vgg\nslim = tf.contrib.slim"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6e8cdb69-2d5d-cad8-9b2f-7812eaca4ad2"},"outputs":[],"source":"tfrecords_filename='invasive-train.tfrecords'\nim_width=224\nim_height=224\n\n#Hyper Parameter to play with\nbatch_size=32\nnum_epochs=10\n\nlr = 0.001\ndecay_rate=0.1\ndecay_per=40 #epoch"},{"cell_type":"markdown","metadata":{"_cell_guid":"18b90fae-7d34-881e-f364-232878a3475e"},"source":"### Read all the data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1da7c7f1-2bfc-a749-9a46-afb9449188b6"},"outputs":[],"source":"train_labels = pandas.read_csv('train_labels.csv')\ntest_labels = pandas.read_csv('sample_submission.csv')\n\ntrain_imgdir = 'train/'\ntest_imgdir = 'test/'\ntrain_images = os.listdir(train_imgdir)\ntest_images = os.listdir(test_imgdir)\n\nnum_iter = len(train_labels)/batch_size"},{"cell_type":"markdown","metadata":{"_cell_guid":"95880d5f-61d2-cbef-4548-84e1db7efb8c"},"source":"### Read all of the image, resize it 224x224 and write it to TFRecord"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9d9103f9-2c53-1a49-7536-d208477e580f"},"outputs":[],"source":"start_time = time.time()\n\ndef _bytes_feature(value):\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\nif os.path.exists(tfrecords_filename):\n    print tfrecords_filename, \"already exists\"\nelse:    \n    writer = tf.python_io.TFRecordWriter(tfrecords_filename)\n    print \"Saving prepocessed file to '%s'\" % tfrecords_filename\n    for img_path in train_images:\n        idx = int(img_path.split('.')[0]) - 1\n        label = train_labels.invasive[idx]\n        img = Image.open(os.path.join(train_imgdir, img_path))\n        img = np.array(img.resize((im_width,im_height), Image.ANTIALIAS))\n\n        example = tf.train.Example(features=tf.train.Features(feature={\n                    'image_raw': _bytes_feature(img.tostring()),\n                    'label': _int64_feature(label)\n                }))\n        writer.write(example.SerializeToString())\n    writer.close()\n    print(\"Preprocessing done in %s seconds\" % (time.time() - start_time))"},{"cell_type":"markdown","metadata":{"_cell_guid":"4df4b746-3c91-a70d-9326-f866cefdda5d"},"source":"### Some helper function to create tensorflow graph "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a3f92bf2-eff3-b723-f660-fa7bd532ed13"},"outputs":[],"source":"#Function to read the data from tfrecords\ndef read_and_decode(filename_queue):\n    \n    reader = tf.TFRecordReader()\n\n    _, serialized_example = reader.read(filename_queue)\n\n    features = tf.parse_single_example(\n      serialized_example,\n      features={\n        'image_raw': tf.FixedLenFeature([], tf.string),\n        'label': tf.FixedLenFeature([], tf.int64)\n        })\n    image = tf.decode_raw(features['image_raw'], tf.uint8)\n    image = tf.reshape(image, [im_height, im_width, 3])\n    label = tf.cast(features['label'], tf.int32)\n    images, labels = tf.train.shuffle_batch([image, label],\n        batch_size=batch_size, capacity=256, num_threads=2, min_after_dequeue=32)\n    return images, labels"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4f6f72a2-e058-09b1-0418-8e7aee4f9a54"},"outputs":[],"source":"def infer(inputs, is_training=True):\n    inputs = tf.cast(inputs, tf.float32)\n    inputs = ((inputs / 255.0)-0.5)*2\n    #Use Pretrained Base Model\n    with tf.variable_scope(\"vgg_16\"):\n        with slim.arg_scope(vgg.vgg_arg_scope()):\n            net = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n            net = slim.max_pool2d(net, [2, 2], scope='pool1')\n            net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n            net = slim.max_pool2d(net, [2, 2], scope='pool2')\n            net = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')\n            net = slim.max_pool2d(net, [2, 2], scope='pool3')\n            net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')\n            net = slim.max_pool2d(net, [2, 2], scope='pool4')\n            net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')\n            net = slim.max_pool2d(net, [2, 2], scope='pool5')\n    #Append fully connected layer\n    net = slim.flatten(net)\n    net = slim.fully_connected(net, 512,\n            weights_initializer=tf.contrib.layers.xavier_initializer(),\n            weights_regularizer=slim.l2_regularizer(0.0005),\n            scope='finetune/fc1')\n    net = slim.fully_connected(net, 2,\n            activation_fn=None,\n            weights_initializer=tf.contrib.layers.xavier_initializer(),\n            weights_regularizer=slim.l2_regularizer(0.0005),\n            scope='finetune/fc2')\n    return net\n\ndef losses(logits, labels):\n    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n    return loss\n        \ndef optimize(losses):\n    global_step = tf.contrib.framework.get_or_create_global_step()\n    learning_rate = tf.train.exponential_decay(lr, global_step,\n                                             num_iter*decay_per, decay_rate, staircase=True)\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n    train_op = optimizer.minimize(losses, global_step=global_step)#,\n                #var_list=slim.get_model_variables(\"finetune\"))\n    return train_op"},{"cell_type":"markdown","metadata":{"_cell_guid":"e2078a1a-fd9e-32fe-6d67-53dd7adc1924"},"source":"### Start Training"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4a192835-88ae-03f7-8352-b7b05c05cb3f"},"outputs":[],"source":"tf.reset_default_graph()\n\n#Create the training graph\nfilename_queue = tf.train.string_input_producer([tfrecords_filename], num_epochs=num_epochs)\nimage, label = read_and_decode(filename_queue)\nprediction = infer(image)\nloss = losses(prediction, label)\ntrain_op = optimize(loss)\n\nprint \"Training started\"\nwith tf.Session() as sess:\n    \n    init_op = tf.group(tf.global_variables_initializer(),\n            tf.local_variables_initializer())\n    restore = slim.assign_from_checkpoint_fn(\n               'vgg_16.ckpt',\n               slim.get_model_variables(\"vgg_16\"))\n    sess.run(init_op)\n    restore(sess)\n    coord = tf.train.Coordinator()\n    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n    \n    for e in range(num_epochs):\n        avg_loss, acc = 0, 0\n        for i in range(num_iter):\n            _, l = sess.run([train_op, loss])\n            avg_loss += l/num_iter\n        print \"Epoch%03d avg_loss: %f\" % (e+1, avg_loss)\n    \n    coord.request_stop()\n    coord.join(threads)\n    print 'Training Done'\n    saver = tf.train.Saver(slim.get_model_variables())\n    saver.save(sess, 'model.ckpt')\n    sess.close()"},{"cell_type":"markdown","metadata":{"_cell_guid":"36809fd1-c9f0-3eaf-d73d-e1032277db0e"},"source":"### Test the model, and generate submission"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"74dc006f-51b7-a535-9f1e-53f2e72e2b12"},"outputs":[],"source":"tf.reset_default_graph()\n\nim_placeholder = tf.placeholder(tf.uint8, [None, im_height, im_width, 3])\nlogits = infer(im_placeholder, is_training=False)\nprediction = tf.nn.softmax(logits)\npredicted_labels = tf.argmax(prediction, 1)\n\nwith tf.Session() as sess:\n    saver = tf.train.Saver()\n    sess.run(tf.local_variables_initializer())\n    sess.run(tf.global_variables_initializer())\n    saver.restore(sess, 'model.ckpt')\n    \n    for i, img_path in enumerate(test_images):\n        print \"\\rProcessing %d/%d\"%(i+1, len(test_images)),\n        img = Image.open(os.path.join(test_imgdir, img_path))\n        img = np.array(img.resize((im_width,im_height), Image.ANTIALIAS))\n        prob = sess.run(prediction, feed_dict={im_placeholder:np.expand_dims(img, axis=0)})\n        \n        idx = int(img_path.split('.')[0]) - 1\n        test_labels.invasive[idx] = prob[0][1]\n            \n    filename_output = \"predictionVGG.csv\"\n    test_labels.to_csv(filename_output, index=False)\n    print \"Writing result to\", filename_output\n    sess.close()"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}