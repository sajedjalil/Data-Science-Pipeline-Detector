{"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python","mimetype":"text/x-python","pygments_lexer":"ipython3","name":"python","file_extension":".py","version":"3.6.1"},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"nbformat":4,"nbformat_minor":0,"cells":[{"metadata":{"_uuid":"482663ec5ebf5246c168c90db520cf7afb9fabbb","collapsed":false,"_cell_guid":"eed45511-e357-425b-878b-f25858f9d0cc","_execution_state":"idle"},"source":"An attempt at solving a Deep learning problem","outputs":[],"cell_type":"markdown","execution_count":null},{"metadata":{"_uuid":"355173bbf0fc443eca7a5faf49a54ab03ddb9f76","trusted":false,"_cell_guid":"ad9c97ba-f92a-4efc-813a-8b836379e03b","_execution_state":"idle"},"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n\n# modules required for the learning task\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os # for environment related stuff.\nimport scipy\n\n# for visualization stuff\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# keras modules required for this notebook\n# Starting architecture\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\nfrom keras.layers import Flatten, Dense, Dropout\nfrom keras.optimizers import SGD\n\n\n%matplotlib inline\n\n# for checking the os files related stuff (executing shell commands)\nfrom subprocess import check_output","outputs":[],"cell_type":"code","execution_count":1},{"metadata":{"_uuid":"ae3a275646114eef968db95e2edffe43c9672918","collapsed":false,"trusted":false,"_cell_guid":"5324f4d2-416c-4a5c-8246-ec3d48b29b98","_execution_state":"idle"},"source":"# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n# constant path to the data source\npath = \"../input\"\n\ndef exec_command(cmd):\n    '''\n        function to execute a shell command and see it's \n        output in the python console\n        @params\n        cmd = the command to be executed along with the arguments\n              ex: ['ls', '../input']\n    '''\n    print(check_output(cmd).decode(\"utf8\"))","outputs":[],"cell_type":"code","execution_count":2},{"metadata":{"_uuid":"3f366c3fe5b25c0ff791cfa2d369b81af4cfcf35","collapsed":false,"trusted":false,"_cell_guid":"c2bff211-7e36-423c-99c8-15d9bc6da748","_execution_state":"idle"},"source":"# check the files in the data source environment:\nexec_command([\"ls\", path])","outputs":[],"cell_type":"code","execution_count":3},{"metadata":{"_uuid":"11455908b263eaf41c8c30c5278427e28d5f4e04","collapsed":false,"trusted":false,"_cell_guid":"dfe6d087-8b72-45b3-a377-6da5aaacf656","_execution_state":"idle"},"source":"# check the structure of the train_labels.csv file\nexec_command(['head', '-10', os.path.join(path, 'train_labels.csv')])","outputs":[],"cell_type":"code","execution_count":4},{"metadata":{"_uuid":"cc924882e0597aa192de6c95e903fb66653038d8","collapsed":false,"trusted":false,"_cell_guid":"8023589b-cf80-4eb5-ae37-36a1680ab4cf","_execution_state":"idle"},"source":"# load the labels from the csv dataset\nlabels_path = os.path.join(path, \"train_labels.csv\")\nlabels = pd.read_csv(labels_path).values\n\n# check the shape of the labels....\n# I am in love with the shape of you... ooo...o \nlabels.shape","outputs":[],"cell_type":"code","execution_count":5},{"metadata":{"_uuid":"f957219046491b47b229f6b097f54a01f60730b9","collapsed":false,"trusted":false,"_cell_guid":"690b1da5-9b3e-4b9b-86b5-af761b01d61f","_execution_state":"idle"},"source":"# check the skewness in the data. (No of positive examples and No. of negative examples)\npos_count = (labels[:, 1] == 1).sum()\nneg_count = (labels[:, 1] == 0).sum()\n\nprint(\"No. of positive examples: %d\" %pos_count)\nprint(\"No. of negative examples: %d\" %neg_count)\n\n# plot a bar chart for better view into the dataset\nx_axis = ['Positive', 'Negative']\ny_axis = [pos_count, neg_count]\nsns.barplot(x_axis, y_axis); # semicolon to supress the output","outputs":[],"cell_type":"code","execution_count":6},{"metadata":{"_uuid":"38811e8e7ba55b20a75dc6c252e6803061e1c2f9","collapsed":false,"_cell_guid":"607a26f9-e853-4dc4-8eba-a4c1e05744ad","_execution_state":"idle"},"source":"##Alright! So, there are only half as many negative examples as the positive examples in the original complete dataset.\n####Now we partition the dataset into train and cross validation datasets.","outputs":[],"cell_type":"markdown","execution_count":null},{"metadata":{"_uuid":"95d7b10332960faba83da78dae93f6817eb995dd","collapsed":false,"trusted":false,"_cell_guid":"5f5b9f69-d809-4bca-8982-f199d996390b","_execution_state":"idle"},"source":"# shuffle the labels in the dataset:\nnp.random.shuffle(labels)\n\npartition = int(labels.shape[0] * 0.70)\ntrain_set = labels[:partition, :]\ncv_set = labels[partition: , :]\n\nprint(\"Train Partition: %s\" %str(train_set.shape))\nprint(\"cross Validation Partition: %s\" %str(cv_set.shape))","outputs":[],"cell_type":"code","execution_count":7},{"metadata":{"_uuid":"7bc958b624b94edf94bd7278278410f79a152a60","collapsed":false,"trusted":false,"_cell_guid":"984132c9-0812-4279-b435-c7f15beadf04","_execution_state":"idle"},"source":"# now check the positive and negative distribution in the train and cross validation datatsets\np_train = (train_set[:, 1] == 1).sum()\nn_train = (train_set[:, 1] == 0).sum()\n\np_cv = (cv_set[:, 1] == 1).sum()\nn_cv = (cv_set[:, 1] == 0).sum()\n\nfig, axs = plt.subplots(ncols=2)\n\n# plot a bar chart for better view into the dataset\naxs[0].set_title(\"Training Partition\")\nx_axis = ['Positive', 'Negative']\ny_axis = [p_train, n_train]\nsns.barplot(x_axis, y_axis, ax=axs[0]); # semicolon to supress the output\n\naxs[1].set_title(\"Cross-validation Partition\")\nx_axis = ['Positive', 'Negative']\ny_axis = [p_cv, n_cv]\nsns.barplot(x_axis, y_axis, ax=axs[1]); # semicolon to supress the output","outputs":[],"cell_type":"code","execution_count":8},{"metadata":{"_uuid":"e6af29bf03880f4d820bda9bf0c3ad9b835c75db","collapsed":false,"_cell_guid":"e01e781b-b874-42f7-9d03-b9bec8059079","_execution_state":"idle"},"source":"##Since the data was randomly shuffled before partitioning, it can be observed that the data elements skew has been preserved in the two partitions.","outputs":[],"cell_type":"markdown","execution_count":null},{"metadata":{"_uuid":"98d7fc9a44ed7a5b8bf967b3730c8c5828f27827","collapsed":false,"trusted":false,"_cell_guid":"057f228d-da26-4638-8cfe-da4e578f1063","_execution_state":"idle"},"source":"# visualize a few images from the training set for the positive and negative labels\npos = (train_set[train_set[:, 1] == 1, :])\nneg = (train_set[train_set[:, 1] == 0, :])\n\n# randomly pick three images from the pos set and three images from the neg set\npos_images = pos[np.random.randint(pos.shape[0], size=3), 0]\nneg_images = neg[np.random.randint(neg.shape[0], size=3), 0]\n\n# display the pos_images:\nimages = zip(pos_images, neg_images)\n\nfig, axs = plt.subplots(ncols=2, nrows=3)\nfig.set_size_inches(20.5, 9.5)\n\naxs[0, 0].set_title(\"Positive examples\")\naxs[0, 1].set_title(\"Negative examples\")\n\ni = 0\nfor (pos_image, neg_image) in images:\n    pos_img_path = os.path.join(path, \"train\", str(pos_image) + \".jpg\")\n    neg_img_path = os.path.join(path, \"train\", str(neg_image) + \".jpg\")\n    p_image = scipy.ndimage.imread(pos_img_path)\n    n_image = scipy.ndimage.imread(neg_img_path)\n    axs[i, 0].imshow(p_image); axs[i, 1].imshow(n_image)\n    i += 1","outputs":[],"cell_type":"code","execution_count":9},{"metadata":{"_uuid":"73f2fe08b717839b914952123ae23226a9dcc83f","collapsed":false,"trusted":false,"_cell_guid":"56a3cc23-0a6e-4937-93ee-f775cab137b3","_execution_state":"idle"},"source":"# check how large are the images and resize them to a standard size.\ntest_image = scipy.misc.imresize(scipy.ndimage.imread(os.path.join(path, \"train\", str(pos_images[0]) + \".jpg\")), \n                                 [100, 100, 3])\nplt.imshow(test_image)\nprint(\"shape of the input images: %s\" %str(test_image.shape))","outputs":[],"cell_type":"code","execution_count":10},{"metadata":{"_uuid":"25da0c1bd4b44be6ec507224e3ca5dd528c2c0e3","collapsed":false,"_cell_guid":"7e0c2f46-7070-4ad1-ac5b-0ae336b58392","_execution_state":"idle"},"source":"##OK! Enough of analysis now. Let's try building a ConvNet on this data","outputs":[],"cell_type":"markdown","execution_count":null},{"metadata":{"_uuid":"bb8e0a1edb9d95d63f05c2c775d62462590f313f","collapsed":false,"trusted":false,"_cell_guid":"b3cec373-0cd9-4a76-becb-4bd93a1bf896","_execution_state":"idle"},"source":"# function to load and provide batches of input images\ndef generate_batch(start, size, source):\n    '''\n        TO load the size number of images into kernel memory and return this data sturcture\n        @Params\n        start = the start index for batch generation\n        size = number of images in the batch \n    '''\n    data = np.ndarray([size, 100, 100, 3], dtype=float) # array for the images\n    labels = np.empty([size], dtype=float) # array for the labels\n    \n    max_value = 255 # the max value of any pixel\n    \n    # traverse the train set to load the images:\n    count = 0 # start the counter from 0\n    for i in range(start, min(len(source), start + size)):\n        data[count] = scipy.misc.imresize(scipy.ndimage.imread(os.path.join(path, \"train\", \n                         str(source[i, 0]) + \".jpg\")), [100, 100, 3])\n        #data[count] /= max_value # range normalize the pixel values\n        labels[count] = source[i, 1]\n        count += 1 # increment the counter\n    \n    # load the remaining images by rollover from the source\n    for i in range(0, (start + size) - len(source)):\n        data[count] = scipy.misc.imresize(scipy.ndimage.imread(os.path.join(path, \"train\", \n                         str(source[i, 0]) + \".jpg\")), [100, 100, 3])\n        #data[count] /= max_value # range normalize the pixel values\n        labels[count] = source[i, 1]\n        count += 1 # increment the counter\n\n    return data, labels","outputs":[],"cell_type":"code","execution_count":11},{"metadata":{"_uuid":"f9c0961fb6560d6947702d7c63137c8f4305a5e0","collapsed":false,"trusted":false,"_cell_guid":"d6878498-3603-4771-a3a2-c6cda439736d","_execution_state":"idle"},"source":"# test the method defined above\n# current_data, current_labels = generate_batch(1600, 100) # checking the rollover case\n# print(current_data.shape)\n# print(current_data[3:6], current_labels[3:6]) # check the data inside a random few images\n# alright! so the data batches are getting generated quite properly.\n# test successful. So, now don't run this again since kernel memory is limited","outputs":[],"cell_type":"code","execution_count":12},{"metadata":{"_uuid":"8dfcda019979d3ce576201de8bc367475dcbaa9a","collapsed":false,"_cell_guid":"787424ff-cdb7-4664-8657-5574ad0955fa","_execution_state":"idle"},"source":"#So, I have not yet figured out if range normalizing the pixel values will be helpful or not. For now I am not range normalizing them.","outputs":[],"cell_type":"markdown","execution_count":null},{"metadata":{"_uuid":"822e77cec6d0fbb68e1862f3b1f5287757527bac","collapsed":false,"_cell_guid":"7b1b3353-fd23-4b98-bbef-07dd1e8eca36","_execution_state":"idle"},"source":"Let's create a Keras ConvNet model to test.","outputs":[],"cell_type":"markdown","execution_count":null},{"metadata":{"_uuid":"fba2a9f56d3495d7fdd5abffddaadc7ad1cf7e94","collapsed":false,"_execution_state":"idle"},"source":"def ConvBlock(model, layers, filters):\n    for i in range(layers):\n        model.add(ZeroPadding2D((1, 1)))\n        model.add(Convolution2D(filters, (3, 3), activation='relu'))\n    model.add(MaxPooling2D((2, 2), strides=(2, 2)))","outputs":[],"execution_count":null,"cell_type":"code"},{"metadata":{"_uuid":"af04a1bed451830821fc4267557df45f1cf18ad5","collapsed":false,"_execution_state":"idle"},"source":"def FCBlock(model):\n    model.add(Dense(4096, activation='relu'))\n    model.add(Dropout(0.5))\n    \ndef input_shape_definer(x):\n    # just an identity function to specify the input shape of the model\n    return x","outputs":[],"execution_count":null,"cell_type":"code"},{"metadata":{"_uuid":"fd73fb2fa7535dde535569450c883e0a80c1fdb3","collapsed":false,"_execution_state":"idle"},"source":"# model for solving the problem.\n\nfrom keras.models import Sequential, Model, load_model\nfrom keras import applications\nfrom keras import optimizers\nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras.layers.core import Lambda\n\nimg_rows, img_cols, img_channel = 100, 100, 3\n\nmodel = Sequential()\nmodel.add(Lambda(input_shape_definer, input_shape=(100, 100, 3), output_shape=(100, 100, 3)))\n\n# model for computation:\nConvBlock(model, 2, 64)\nConvBlock(model, 2, 128)\nConvBlock(model, 3, 256)\nConvBlock(model, 3, 512)\nConvBlock(model, 3, 512)\n\nmodel.add(Flatten())\nFCBlock(model)\nFCBlock(model)\nmodel.add(Dense(1, activation='sigmoid'))","outputs":[],"execution_count":null,"cell_type":"code"},{"metadata":{"_uuid":"fa6bd0b6a5666d40131db5ebf4cd4b41ec86b6f9","collapsed":false,"trusted":false,"_cell_guid":"cd7dbcb6-7645-4ee0-82ac-2604e1b5caa2","_execution_state":"idle"},"source":"# a detailed description of the model to be used\nprint(model.summary())","outputs":[],"cell_type":"code","execution_count":33},{"metadata":{"_uuid":"9aef8742a89d30f8ee55523266e2b308cc13351e","collapsed":false,"_cell_guid":"50ef87c5-b70e-4647-9890-fa504e8748ea","_execution_state":"idle"},"source":"#lets start training the model:","outputs":[],"cell_type":"markdown","execution_count":null},{"metadata":{"_uuid":"d89e1f02c8b063bf6d5b376b088066dff441817b","collapsed":false,"_execution_state":"idle"},"source":"from keras.utils.data_utils import get_file\n\n# load the pretrained VGGNet weights from the url mentioned:\nmodel.load_weights(get_file('vgg16.h5', 'http://www.platform.ai/models/vgg16.h5', cache_subdir='models'))","outputs":[],"execution_count":null,"cell_type":"code"},{"metadata":{"_uuid":"52add5369b669a151f417921dd3d1232fde1d888","collapsed":false,"trusted":false,"_cell_guid":"1a6e0e5c-cac1-4157-8beb-ac7818166469","_execution_state":"idle"},"source":"model.compile(optimizer='Adam',\n                loss='categorical_crossentropy', metrics=['accuracy'])\n\n# train the model so that it sees every element in the dataset once:\nbatch_size = 200\ntotal_dataset_size = len(train_set)\n\nsaved_path = \"./Model2\"\n\nif(os.path.isfile(saved_path)):\n    model.load_weights(saved_path)\n\n# let's go over the first 1000 images in the dataset\ncount = 0  #start the count to 0\nfor i in range(0, 15):\n    print(\"count: \" + str(i))\n    x_train, y_train = generate_batch(count, batch_size, train_set)\n    model.fit(x_train, y_train, epochs=2, batch_size=100); # suppress the print output.\n    count = (count + batch_size) % total_dataset_size\n    \n# save the weights to the filesystem\nmodel.save_weights(saved_path)","outputs":[],"cell_type":"code","execution_count":40},{"metadata":{"_uuid":"1335b954d161042cba4419e2189d4752c740a10e","collapsed":false,"trusted":false,"_cell_guid":"c7a164c2-f32d-4d3e-ba75-de3d23e51504","_execution_state":"idle"},"source":"# extract the cross_validation images from the dataset\nx_eval, y_eval = generate_batch(0, 100, cv_set)\n\nevaluation = model.evaluate(x_eval, y_eval)\nacc = evaluation[1]\nprint('Evaluation accuracy:{0}'.format(round(acc, 4)))\nprint(evaluation)","outputs":[],"cell_type":"code","execution_count":null},{"metadata":{"_uuid":"386585c3ca5d0057882f25d9883296b540f856d2","collapsed":false,"trusted":false,"_cell_guid":"5d6eb6b4-9032-4718-8fe6-4667ba67081f","_execution_state":"idle"},"source":"layer_dict = dict([(layer.name, layer) for layer in model.layers])\nprint(layer_dict)","outputs":[],"cell_type":"code","execution_count":null},{"metadata":{"_uuid":"5efa230fe48cedd88227e7029396c38809a0b787","collapsed":false,"trusted":false,"_cell_guid":"1d15e372-caac-4efd-b9fe-0f8640bf4ab0","_execution_state":"idle"},"source":"from keras import backend as K\n\ndef iterate_function_generator(layer_name, filter_index):\n    input_img  = model.input\n\n    # build a loss function that maximizes the activation\n    # of the nth filter of the layer considered\n    layer_output = layer_dict[layer_name].output\n    loss = K.mean(layer_output[:, :, :, filter_index])\n\n    # compute the gradient of the input picture wrt this loss\n    grads = K.gradients(loss, input_img)[0]\n\n\n    # normalization trick: we normalize the gradient\n    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n\n    # this function returns the loss and grads given the input picture\n    iterate = K.function([input_img], [loss, grads])\n    return iterate","outputs":[],"cell_type":"code","execution_count":null},{"metadata":{"_uuid":"d5dfae675993fdb22fc8660521df9244f0fdd9e7","collapsed":false,"trusted":false,"_cell_guid":"4b67dda6-7232-4e93-8c55-eda001617d37","_execution_state":"idle"},"source":"import numpy as np\n\ndef generate_visualizations(layer_name):\n    # find out how many filters are present:\n    #size = layer_dict[layer_name].output.shape[3]\n    \n    size = 5 # for now we only look at the first 5 filters in that layer\n    \n    # create a list of empty images\n    vizs = np.ndarray([size, 1, 100, 100, 3])\n    # create the visualization arrays\n    for i in range(size):\n        # we start from a gray image with some noise\n        vizs[i] = np.random.random((100, 100, 3)) * 20 + 128.\n       \n    print(vizs.shape)\n        \n    # set the step size for the gradient ascent\n    step = 1\n\n    for filter_index in range(size):\n        for i in range(20):\n            loss_value, grads_value = iterate_function_generator(layer_name, filter_index)([vizs[filter_index]])\n            vizs[filter_index] += grads_value * step\n        print(\"current filter: \" + str(filter_index + 1))            \n\n    return vizs","outputs":[],"cell_type":"code","execution_count":null},{"metadata":{"_uuid":"b1b00d0b70a24eec2fcf8f2354399f83f20f15a5","collapsed":false,"trusted":false,"_cell_guid":"229b9bb9-a1a1-4841-89f8-9884d02e2262","_execution_state":"idle"},"source":"# generate the visualizations for the layer number 1 (conv 2d)\nlayer1_conv_vis = generate_visualizations(model.layers[1].name)","outputs":[],"cell_type":"code","execution_count":null},{"metadata":{"_uuid":"16f387ff2f70c46b794219fdb34a82df76dd39b1","collapsed":false,"trusted":false,"_cell_guid":"5ea7b155-5882-4b1e-b0dd-e1a3721db169","_execution_state":"idle"},"source":"print(layer1_conv_vis[3, 0, :5, :5, 0])","outputs":[],"cell_type":"code","execution_count":null},{"metadata":{"_uuid":"072af017cbe93408a5b00017031161b0e8a842bc","collapsed":false,"trusted":false,"_cell_guid":"c002575a-899a-43ca-b45f-4cba8be21518","_execution_state":"idle"},"source":"fig, axs = plt.subplots(ncols= 2, nrows = 2)\nfig.set_size_inches(30, 30)\nfor i in range(2):\n    for j in range(2):\n        axs[i, j].imshow(layer1_conv_vis[(i * 2) + j][0]);","outputs":[],"cell_type":"code","execution_count":null},{"metadata":{"_uuid":"92ad51c1d24b8f51fad271332bc678f63782bdbb","collapsed":false,"_cell_guid":"2eb76aa1-6137-4f97-8c43-7d7c490db73e","_execution_state":"idle"},"source":"I require help on how to train the small model that I have constructed here and exactly what might be the problem that is causing this underfitting of the model. Would training for more time help? Suggestions are most welcome.","outputs":[],"cell_type":"markdown","execution_count":null}]}