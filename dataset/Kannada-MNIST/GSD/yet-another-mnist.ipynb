{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"## References:\n\n#https://www.kaggle.com/artgor/pytorch-whale-identifier\n#https://www.kaggle.com/josephvm/kannada-pytorch-visualizations\n#https://www.kaggle.com/bonhart/pytorch-cnn-from-scratch\n#https://www.kaggle.com/ateplyuk/aptos-pytorch-starter-rnet50","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install albumentations > /dev/null 2>&1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"###Import pytorch libraries utlis:\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torch.utils.data import DataLoader,Dataset\nfrom torchvision.transforms import transforms\nimport torch.optim as optim\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom PIL import Image\nimport tqdm\ntrain_on_gpu=True\n\nimport cv2\nimport albumentations\nfrom albumentations import pytorch as AT","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## read the dataset:\ntrain=pd.read_csv('/kaggle/input/Kannada-MNIST/train.csv')\ntest=pd.read_csv('/kaggle/input/Kannada-MNIST/test.csv')\nsample_submission=pd.read_csv('/kaggle/input/Kannada-MNIST/sample_submission.csv')\ndigits=pd.read_csv('/kaggle/input/Kannada-MNIST/Dig-MNIST.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"digits.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As per the dataset description , there is a additional dataset provided to us which we can use to validate our model before making the submission.We will use the `digits` dataset as the validation set."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'There are {train.shape[0]} training examples')\nprint(f'There are {digits.shape[0]} validation examples')\nprint(f'There are {test.shape[0]} test examples')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"digits['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### distribution of class lables in train:\n\nplt.figure(figsize=(8,8))\nsns.countplot(train['label'])\nplt.title(\"Distribution of label in train\")\nplt.xlabel('Label')\nplt.ylabel('Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,8))\nsns.countplot(digits['label'])\nplt.title(\"Distribution of label in validation\")\nplt.xlabel('Label')\nplt.ylabel('Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Transforms:\n\ntrain_transform=transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomRotation(0.3),\n    transforms.ToTensor()\n])\ntest_transform=transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.RandomRotation(0.3),\n    transforms.ToTensor()\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class KannadaMNIST(Dataset):\n    def __init__(self,images,data=None,transform=transforms.Compose([transforms.ToTensor()])):\n        self.data=data\n        self.images=images\n        self.transform=transform\n        \n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self,i):\n        item=self.images.iloc[i]\n        image=item[1:].values.astype(np.uint8).reshape(28,28,1)\n        image=self.transform(image)\n        if self.data is not None:\n            label=item[0]\n            return image,label\n        else:\n            return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset=KannadaMNIST(train,'Train',transform=train_transform)\nvalid_dataset=KannadaMNIST(digits,'Valid',transform=test_transform)\ntest_dataset=KannadaMNIST(test,transform=test_transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader=DataLoader(train_dataset,batch_size=32,shuffle=True)\nvalid_loader=DataLoader(valid_dataset,batch_size=32,shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataiter = iter(train_loader)\nimages, labels = dataiter.next()\n\nprint(f'Batch Image shape {images.shape}')\n\nprint(images[1].numpy().transpose((1,2,0)).shape)\nprint(labels[1].item())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Creating a simple nnet model:\n##https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n\ndef imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0)) ## changing the shape of the image.\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)\n    \n    \ninputs,classes=next(iter(train_loader))\nout=torchvision.utils.make_grid(inputs)\n\nimshow(out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Building the model:\n\nclass nnet(nn.Module):\n    def __init__(self):\n        super(nnet,self).__init__()\n        self.conv1=nn.Conv2d(in_channels=1,out_channels=32,kernel_size=5,padding=2) # (28,28,32)\n        self.conv1_bn=nn.BatchNorm2d(num_features=32) #\n        self.pool1=nn.MaxPool2d(kernel_size=2,stride=2) #(14,14,32)\n        \n        self.conv2=nn.Conv2d(in_channels=32,out_channels=64,kernel_size=5,padding=2) # (14,14,64)\n        self.conv2_bn=nn.BatchNorm2d(num_features=64)\n        self.conv3=nn.Conv2d(in_channels=64,out_channels=128,kernel_size=5,padding=2) #(14,14,128)\n        self.pool2=nn.AvgPool2d(kernel_size=2,stride=2) # (7,7,128)\n        \n        self.fc1=nn.Linear(in_features=7*7*128,out_features=1024)\n        self.fc1_batchnorm=nn.BatchNorm1d(num_features=1024)\n        self.dropout=nn.Dropout(0.5)\n        self.out=nn.Linear(in_features=1024,out_features=10)\n        \n    def forward(self,x):\n        x=self.pool1(F.relu(self.conv1_bn(self.conv1(x))))\n        x=self.pool2(F.relu(self.conv3(self.conv2_bn(self.conv2(x)))))\n        #print(x.shape)\n        x=x.view(-1,7*7*128)\n        x=F.relu(self.fc1_batchnorm(self.fc1(x)))\n        x=self.dropout(x)\n        x=self.out(x)\n        return(x)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=nnet().to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\noptimizer=optim.Adam(model.parameters(),lr=0.001)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_epochs = 15\nfor epoch in range(1, n_epochs+1):\n    print(time.ctime(), 'Epoch:', epoch)\n\n    train_loss = []\n\n    for batch_i, (data, target) in enumerate(train_loader):\n        #print(batch_i)\n        data, target = data.cuda(), target.cuda()\n\n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.cross_entropy(output, target)\n        train_loss.append(loss.item())\n\n        loss.backward()\n        optimizer.step()\n\n    print(f'Epoch {epoch}, train loss: {np.mean(train_loss):.4f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://www.kaggle.com/bonhart/pytorch-cnn-from-scratch\nmodel.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in valid_loader:\n        images = images.cuda()\n        labels = labels.cuda()\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n          \n    print('Test Accuracy of the model on the 10240 validation images: {} %'.format(100 * correct / total))\n\n# Save the model checkpoint\ntorch.save(model.state_dict(), 'model.ckpt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loader=DataLoader(test_dataset,shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = []\nmodel.eval() ## weighted mean and variance will be used in batch norm for test\nfor i, (data) in enumerate(test_loader):\n    data = data.cuda()\n    output = model(data)  \n    output = output.cpu().detach().numpy()    \n    predict.append(output[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['label']=np.argmax(predict,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}