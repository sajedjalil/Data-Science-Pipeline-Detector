{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ../input/detectron-05/whls/pycocotools-2.0.2/dist/pycocotools-2.0.2.tar --no-index --find-links ../input/detectron-05/whls \n!pip install ../input/detectron-05/whls/fvcore-0.1.5.post20211019/fvcore-0.1.5.post20211019 --no-index --find-links ../input/detectron-05/whls \n!pip install ../input/detectron-05/whls/antlr4-python3-runtime-4.8/antlr4-python3-runtime-4.8 --no-index --find-links ../input/detectron-05/whls \n!pip install ../input/detectron-05/whls/detectron2-0.5/detectron2 --no-index --find-links ../input/detectron-05/whls ","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-16T01:05:38.125714Z","iopub.execute_input":"2021-12-16T01:05:38.12672Z","iopub.status.idle":"2021-12-16T01:08:59.562871Z","shell.execute_reply.started":"2021-12-16T01:05:38.12661Z","shell.execute_reply":"2021-12-16T01:08:59.562044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import detectron2\nimport torch\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.config import CfgNode as CN\nfrom detectron2.modeling import build_model, DatasetMapperTTA, detector_postprocess\nfrom detectron2.modeling import GeneralizedRCNNWithTTA as _GeneralizedRCNNWithTTA\nfrom detectron2.data.detection_utils import read_image\nfrom detectron2.data.transforms import (\n    RandomFlip,\n    ResizeShortestEdge,\n    ResizeTransform,\n    apply_augmentations,\n)\nfrom detectron2.structures import ImageList, Instances, Boxes\nfrom detectron2.checkpoint import DetectionCheckpointer\nfrom fvcore.transforms import HFlipTransform, NoOpTransform\nfrom PIL import Image\nimport cv2\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom fastcore.all import *\nfrom torch import nn\nimport copy\nfrom itertools import count\nimport warnings\nwarnings.simplefilter('ignore')\nimport gc","metadata":{"execution":{"iopub.status.busy":"2021-12-16T01:08:59.565678Z","iopub.execute_input":"2021-12-16T01:08:59.565952Z","iopub.status.idle":"2021-12-16T01:09:00.730486Z","shell.execute_reply.started":"2021-12-16T01:08:59.565916Z","shell.execute_reply":"2021-12-16T01:09:00.729781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('../input/ensemble-boxes/')\nsys.path.append('../input/sartorius-utils/')\nsys.path.append('../input/yolov5-v6/yolov5-master/')\nfrom ensemble_boxes import weighted_boxes_fusion, weighted_masks_fusion\nfrom postprocess import detector_postprocess\nfrom models.common import DetectMultiBackend\nfrom utils.general import non_max_suppression","metadata":{"execution":{"iopub.status.busy":"2021-12-16T01:09:00.731677Z","iopub.execute_input":"2021-12-16T01:09:00.733633Z","iopub.status.idle":"2021-12-16T01:09:01.380014Z","shell.execute_reply.started":"2021-12-16T01:09:00.7336Z","shell.execute_reply":"2021-12-16T01:09:01.379292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataDir=Path('../input/sartorius-cell-instance-segmentation')","metadata":{"execution":{"iopub.status.busy":"2021-12-16T01:09:01.382957Z","iopub.execute_input":"2021-12-16T01:09:01.383561Z","iopub.status.idle":"2021-12-16T01:09:01.389774Z","shell.execute_reply.started":"2021-12-16T01:09:01.383525Z","shell.execute_reply":"2021-12-16T01:09:01.38896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# From https://www.kaggle.com/stainsby/fast-tested-rle\ndef rle_decode(mask_rle, shape=(520, 704)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)  # Needed to align to RLE direction\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\n#predict one image.\ndef one_predictor(im, predictor, yolo_model, pred_class):\n    yolo_boxes = yolo_get_boxes(im, yolo_model, pred_class)\n    _img = torch.from_numpy(np.ascontiguousarray(im.transpose(2, 0, 1)))\n    info_dict = [{'image': _img, 'height': 520, 'width': 704}]\n    predictor.eval()\n    with torch.no_grad():\n        pred = predictor(info_dict, yolo_boxes)[0]\n    scores = pred['instances'].scores.cpu().numpy()\n    pred_masks = pred['instances'].pred_masks.cpu().numpy()\n    pred_boxes = pred['instances'].pred_boxes.tensor.cpu().numpy()\n    \n    pred_masks = pred_masks[scores > WMF_THRESHOLDS[pred_class]]\n    pred_boxes = pred_boxes[scores > WMF_THRESHOLDS[pred_class]]\n    scores = scores[scores > WMF_THRESHOLDS[pred_class]]\n    if pred_class == 1:\n        pred_masks = pred_masks >= 0.5\n    return pred_masks, scores, pred_boxes\n\n#merge predictions of each models with WMF\ndef merge_predict(im, predictors, yolo_models, pred_class):\n    \n    for i, predictor in enumerate(predictors):\n        if i == 0:\n            pred_masks, scores, pred_boxes = one_predictor(im, predictor, yolo_models[i%5], pred_class)\n            models = [0] * len(scores)\n        else:\n            pm, sc, pb = one_predictor(im, predictor, yolo_models[i%5], pred_class)\n            models += [i] * len(sc)\n            pred_masks = np.vstack([pred_masks, pm])\n            scores = np.hstack([scores, sc])\n            pred_boxes = np.vstack([pred_boxes, pb])\n\n    sort_idx = np.argsort(-scores)\n    pred_masks = pred_masks[sort_idx]\n    pred_boxes = pred_boxes[sort_idx]\n    models = np.array(models)[sort_idx]\n    scores = scores[sort_idx]\n    \n    # ensemble models using WMF. WMF is WBF applied to mask ensemble.\n    pred_masks, scores, pred_boxes = weighted_masks_fusion(pred_masks, pred_boxes, scores, models,\n                                               skip_mask_thr=0,\n                                               conf_type='model_weight',\n                                               soft_weight=np.sum(MODEL_WEIGHTS[pred_class]),\n                                               num_models=len(predictors),\n                                               model_weights = MODEL_WEIGHTS[pred_class])\n    #rint(np.max(pred_masks))\n    pred_masks = np.array(pred_masks)\n    pred_boxes = np.array(pred_boxes)\n    scores = np.array(scores)\n    \n    sort_idx = np.argsort(-scores)\n    pred_masks = pred_masks[sort_idx]\n    pred_boxes = pred_boxes[sort_idx]\n    scores = scores[sort_idx]\n    \n    #pred_masks = pred_masks >= MASK_THRESHOLDS[pred_class]\n    \n    return pred_masks, scores, pred_boxes\n\n# If the image is shsy5y, split the image and predict each images.\ndef second_predict(im, predictors_shsy5y, yolo_models):\n    #print(im.shape)\n    scaled_im = cv2.resize(im, (im.shape[1]*2, im.shape[0]*2))\n    mask_scales = []\n    box_scales = []\n    scores_all = []\n    \n    for i in range(3):\n        del_mask = np.zeros((520, 704), dtype=np.uint8)\n        if i == 0 or i == 1:\n            del_mask[-5:, :] = 1\n        if i == 1 or i == 2:\n            del_mask[:5, :] = 1\n        for j in range(3):\n            if j == 0 or j == 1:\n                del_mask[:, -5:] = 1\n            if j == 1 or j == 2:\n                del_mask[:, :5] = 1\n            img = scaled_im[260*i:260*(i+2), 352*j:352*(j+2)]\n            pred_masks, scores, pred_boxes = merge_predict(img, predictors_shsy5y, yolo_models, 0)\n            pred_masks = pred_masks[scores >= THRESHOLDS[0]]\n            pred_boxes = pred_boxes[scores >= THRESHOLDS[0]]\n            scores = scores[scores >= THRESHOLDS[0]]\n\n            for mask, score, box in zip(pred_masks, scores, pred_boxes):\n                #print(mask.shape)  \n                if np.sum(mask * del_mask) > 0:\n                    continue\n                _mask_scale = np.zeros((img.shape[0] * 2, img.shape[1] * 2))\n                _mask_scale[260*i:260*(i+2), 352*j:352*(j+2)] = mask\n                _mask_scale = cv2.resize(_mask_scale, (img.shape[1], img.shape[0]))\n                \n                box[[0, 2]] = (box[[0, 2]] + 352 * j) // 2\n                box[[1, 3]] = (box[[1, 3]] + 260 * i) // 2\n                mask_scales.append(_mask_scale)\n                box_scales.append(box)\n                scores_all.append(score)\n                \n    #merge predicts with WMF\n    pred_masks, scores, pred_boxes = weighted_masks_fusion(np.array(mask_scales), np.array(box_scales),\n                                                           np.array(scores_all), np.zeros(len(scores_all)),\n                                                           skip_mask_thr=0,\n                                                           conf_type='max')\n    pred_masks = np.array(pred_masks)\n    scores = np.array(scores)\n    \n    sort_idx = np.argsort(-scores)\n    pred_masks = pred_masks[sort_idx]\n    scores = scores[sort_idx]\n                    \n    return pred_masks, scores\n\ndef get_masks(fn, predictors, yolo_models, pred_class):\n    \n    im = cv2.imread(str(fn))\n    \n    if pred_class == 0:\n        pred_masks, score = second_predict(im, predictors, yolo_models)\n        pred_class = 0\n        #print(0)  \n    elif pred_class == 1:\n        pred_class = 1\n        pred_masks, score, _ = merge_predict(im, predictors, yolo_models, pred_class)\n        #print(1)\n    else:\n        pred_class = 2\n        pred_masks, score, _ = merge_predict(im, predictors, yolo_models, pred_class)\n        #print(2)\n    pred_masks = pred_masks >= MASK_THRESHOLDS[pred_class]\n    pred_masks = pred_masks[score >= THRESHOLDS[pred_class]]\n    score = score[score >= THRESHOLDS[pred_class]]\n    res = []\n    scores = []\n    used = np.zeros(im.shape[:2], dtype=int)\n    \n    #remove duplication\n    for _mask, s in zip(pred_masks, score):\n        #print(mask.shape)\n        mask = _mask * (1-used)\n        if mask.sum() >= MIN_PIXELS[pred_class] and np.sum(mask) / np.sum(_mask) >= DUPL_THRESHOLDS[pred_class]: # skip predictions with small area\n            used += mask\n            res.append(mask)\n            scores.append(s)\n        \n    res_last = []\n    for r in res:\n        res_last.append(rle_encode(r))\n        \n    return res_last\n\n#classify a image\ndef classify_image(fn, predictor):\n    im = cv2.imread(str(fn))\n    pred = predictor(im)\n    pred_class = int(torch.mode(pred['instances'].pred_classes)[0].cpu())\n    return pred_class\n\n#get boxes predicted by yolov5x\ndef yolo_get_boxes(im, model, pred_class, img_sz=640, augment=[True, False, True], \n                   weight=[0.95, 0.9, 0.85]):\n    \n    with torch.no_grad():\n        model.warmup(imgsz=(1, 3, (img_sz, img_sz)), half=False)\n        img = cv2.resize(im, (img_sz, img_sz))\n        img = img.transpose((2, 0, 1))[np.newaxis]\n        img = torch.from_numpy(img).to(device)\n        #print(im)\n        img = img / 255\n        pred = model(img, augment=augment[pred_class])\n        dets = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45, max_det=2000)\n    bboxes = dets[0].cpu().numpy()\n    bboxes[:, :4] = bboxes[:, :4] / img_sz\n    bboxes[:, 4] = bboxes[:, 4] * weight[pred_class]\n\n    return bboxes\n\nclass GeneralizedRCNNWithTTA(_GeneralizedRCNNWithTTA):\n    def __call__(self, batched_inputs, yolo_boxes):\n        \"\"\"\n        Same input/output format as :meth:`GeneralizedRCNN.forward`\n        \"\"\"\n\n        def _maybe_read_image(dataset_dict):\n            ret = copy.copy(dataset_dict)\n            if \"image\" not in ret:\n                image = read_image(ret.pop(\"file_name\"), self.model.input_format)\n                image = torch.from_numpy(np.ascontiguousarray(image.transpose(2, 0, 1)))  # CHW\n                ret[\"image\"] = image\n            if \"height\" not in ret and \"width\" not in ret:\n                ret[\"height\"] = image.shape[1]\n                ret[\"width\"] = image.shape[2]\n            return ret\n\n        return [self._inference_one_image(_maybe_read_image(x), yolo_boxes) for x in batched_inputs]\n    \n    def _inference_one_image(self, input, yolo_boxes):\n        \"\"\"\n        Args:\n            input (dict): one dataset dict with \"image\" field being a CHW tensor\n        Returns:\n            dict: one output dict\n        \"\"\"\n        orig_shape = (input[\"height\"], input[\"width\"])\n        augmented_inputs, tfms = self._get_augmented_inputs(input)\n        self.device = self.model.device\n        # Detect boxes from all augmented versions\n        with self._turn_off_roi_heads([\"mask_on\", \"keypoint_on\"]):\n            # temporarily disable roi heads\n            all_boxes, all_scores, all_classes = self._get_augmented_boxes(augmented_inputs, tfms)\n        # merge all detected boxes to obtain final predictions for boxes\n        all_boxes.append(yolo_boxes[:, :4])\n        all_scores.append(yolo_boxes[:, 4].tolist())\n        all_classes.append(yolo_boxes[:, 5].tolist())\n        merged_instances = self._merge_detections(all_boxes, all_scores, all_classes, orig_shape)\n\n        if self.cfg.MODEL.MASK_ON:\n            # Use the detected boxes to obtain masks\n            augmented_instances = self._rescale_detected_boxes(\n                augmented_inputs, merged_instances, tfms\n            )\n            # run forward on the detected boxes\n            outputs = self._batch_inference(augmented_inputs, augmented_instances)\n            # Delete now useless variables to avoid being out of memory\n            del augmented_inputs, augmented_instances\n            # average the predictions\n            merged_instances.pred_masks = self._reduce_pred_masks(outputs, tfms)\n            merged_instances = detector_postprocess(merged_instances, *orig_shape, mask_threshold=-1)\n            return {\"instances\": merged_instances}\n        else:\n            return {\"instances\": merged_instances}\n        \n    def _get_augmented_boxes(self, augmented_inputs, tfms):\n        # 1: forward with all augmented images\n        outputs = self._batch_inference(augmented_inputs)\n        # 2: union the results\n        all_boxes = []\n        all_scores = []\n        all_classes = []\n        for output, tfm in zip(outputs, tfms):\n            # Need to inverse the transforms on boxes, to obtain results on original image\n            pred_boxes = output.pred_boxes.tensor\n            pred_boxes = tfm.inverse().apply_box(pred_boxes.cpu().numpy())\n            pred_boxes[:, [0, 2]] = pred_boxes[:, [0, 2]] / 704\n            pred_boxes[:, [1, 3]] = pred_boxes[:, [1, 3]] / 520\n            all_boxes.append(pred_boxes)\n\n            all_scores.append(output.scores.tolist())\n            all_classes.append(output.pred_classes.tolist())\n        return all_boxes, all_scores, all_classes    \n    \n    # merge detections with WBF\n    def _merge_detections(self, all_boxes, all_scores, all_classes, shape_hw):\n        #print(all_boxes)\n        boxes, scores, labels = weighted_boxes_fusion(all_boxes,\n                                                     all_scores,\n                                                     all_classes,\n                                                     iou_thr=self.cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST,\n                                                     skip_box_thr=1e-8,\n                                                     conf_type='max')\n        #print(scores)\n        keepk = self.cfg.TEST.DETECTIONS_PER_IMAGE\n        boxes = boxes[:keepk, :]\n        boxes[:, [0, 2]] = boxes[:, [0, 2]] * 704\n        boxes[:, [1, 3]] = boxes[:, [1, 3]] * 520\n        scores = scores[:keepk]\n        labels = labels[:keepk]\n        result = Instances(shape_hw)\n        result.pred_boxes = Boxes(torch.from_numpy(boxes).to(self.device))\n        result.scores = torch.from_numpy(scores).to(self.device)\n        result.pred_classes = torch.from_numpy(labels).to(self.device)\n        #print(result)\n        return result","metadata":{"execution":{"iopub.status.busy":"2021-12-16T01:09:01.393011Z","iopub.execute_input":"2021-12-16T01:09:01.39328Z","iopub.status.idle":"2021-12-16T01:09:01.440929Z","shell.execute_reply.started":"2021-12-16T01:09:01.39325Z","shell.execute_reply":"2021-12-16T01:09:01.44018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_names = (dataDir/'test').ls()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T01:13:51.63309Z","iopub.execute_input":"2021-12-16T01:13:51.633651Z","iopub.status.idle":"2021-12-16T01:13:51.673617Z","shell.execute_reply.started":"2021-12-16T01:13:51.633612Z","shell.execute_reply":"2021-12-16T01:13:51.672942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Initiate a Predictor from our trained model","metadata":{}},{"cell_type":"code","source":"THRESHOLDS = [.65, .6, .8]\nWMF_THRESHOLDS = [.65, .6, .55]\nMIN_PIXELS = [75, 150, 75]\nMASK_THRESHOLDS = [.5, .5, .5]\nDUPL_THRESHOLDS = [.7, .7, .7]\nMODEL_WEIGHTS = [[1] * 6, [2] * 5 + [1] * 5, [2] * 5 + [1] * 5]\n#MODEL_WEIGHTS = [[1] * 5, [1] * 10, [1] * 5]\ndevice = 'cuda'","metadata":{"execution":{"iopub.status.busy":"2021-12-16T01:13:51.998449Z","iopub.execute_input":"2021-12-16T01:13:51.998659Z","iopub.status.idle":"2021-12-16T01:13:52.003035Z","shell.execute_reply.started":"2021-12-16T01:13:51.998633Z","shell.execute_reply":"2021-12-16T01:13:52.002327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\ncfg.INPUT.MASK_FORMAT='bitmask'\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 \ncfg.MODEL.WEIGHTS = os.path.join('../input/sartorius-pretrained-model', \"best_detectron2_R101_FPN.pth\")  \ncfg.TEST.DETECTIONS_PER_IMAGE = 1000\npredictor = DefaultPredictor(cfg)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T01:13:52.203807Z","iopub.execute_input":"2021-12-16T01:13:52.204356Z","iopub.status.idle":"2021-12-16T01:13:56.935577Z","shell.execute_reply.started":"2021-12-16T01:13:52.204316Z","shell.execute_reply":"2021-12-16T01:13:56.934706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_shsy5y_model():\n    cfg = get_cfg()\n    cfg.merge_from_file(model_zoo.get_config_file(\"Misc/cascade_mask_rcnn_X_152_32x8d_FPN_IN5k_gn_dconv.yaml\"))\n    cfg.INPUT.MASK_FORMAT='bitmask'\n    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n    cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.7\n    cfg.TEST.DETECTIONS_PER_IMAGE = 1000\n    cfg.TEST.AUG = CN({\"ENABLED\": True})\n    cfg.TEST.AUG.MIN_SIZES = (640, 750, 860)\n    cfg.TEST.AUG.MAX_SIZE = 1440\n    cfg.TEST.AUG.FLIP = True\n\n    cfg.MODEL.WEIGHTS = '../input/sartorius-model-shsy5y-pseudo/best_detectron2_X152_scaled_shsy5y_pseudo_fold1.pth'\n    model_shsy5y1 = build_model(cfg)\n    DetectionCheckpointer(model_shsy5y1).load(cfg.MODEL.WEIGHTS)\n    predictor_shsy5y1 = GeneralizedRCNNWithTTA(cfg, model_shsy5y1)\n    \n    cfg.MODEL.WEIGHTS = '../input/sartorius-model-shsy5y-pseudo/best_detectron2_X152_scaled_shsy5y_pseudo_fold2.pth'\n    model_shsy5y2 = build_model(cfg)\n    DetectionCheckpointer(model_shsy5y2).load(cfg.MODEL.WEIGHTS)\n    predictor_shsy5y2 = GeneralizedRCNNWithTTA(cfg, model_shsy5y2)\n    \n    cfg.MODEL.WEIGHTS = '../input/sartorius-model-shsy5y-pseudo/best_detectron2_X152_scaled_shsy5y_pseudo_fold3.pth'\n    model_shsy5y3 = build_model(cfg)\n    DetectionCheckpointer(model_shsy5y3).load(cfg.MODEL.WEIGHTS)\n    predictor_shsy5y3 = GeneralizedRCNNWithTTA(cfg, model_shsy5y3)\n    \n    cfg.MODEL.WEIGHTS = '../input/sartorius-model-shsy5y-pseudo/best_detectron2_X152_scaled_shsy5y_pseudo_fold4.pth'\n    model_shsy5y4 = build_model(cfg)\n    DetectionCheckpointer(model_shsy5y4).load(cfg.MODEL.WEIGHTS)\n    predictor_shsy5y4 = GeneralizedRCNNWithTTA(cfg, model_shsy5y4)\n    \n    cfg.MODEL.WEIGHTS = '../input/sartorius-model-shsy5y-pseudo/best_detectron2_X152_scaled_shsy5y_pseudo.pth'\n    model_shsy5y5 = build_model(cfg)\n    DetectionCheckpointer(model_shsy5y5).load(cfg.MODEL.WEIGHTS)\n    predictor_shsy5y5 = GeneralizedRCNNWithTTA(cfg, model_shsy5y5)\n    \n    cfg.MODEL.WEIGHTS = '../input/sartorius-1class-model/best_detectron2_X152_1class.pth'\n    cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.33, 0.5, 1.0, 2.0, 3.0]]\n    model_shsy5y6 = build_model(cfg)\n    DetectionCheckpointer(model_shsy5y6).load(cfg.MODEL.WEIGHTS)\n    predictor_shsy5y6 = GeneralizedRCNNWithTTA(cfg, model_shsy5y6)\n\n    predictors_shsy5y = [predictor_shsy5y1, predictor_shsy5y2, predictor_shsy5y3, predictor_shsy5y4, predictor_shsy5y5, predictor_shsy5y6]\n    \n    model_shsy5y0 = DetectMultiBackend(weights='../input/sartorius-yolo-models/best_scaled_shsy5y.pt', device=device)\n    model_shsy5y1 = DetectMultiBackend(weights='../input/sartorius-yolo-models/best_scaled_shsy5y_fold1.pt', device=device)\n    model_shsy5y2 = DetectMultiBackend(weights='../input/sartorius-yolo-models/best_scaled_shsy5y_fold2.pt', device=device)\n    model_shsy5y3 = DetectMultiBackend(weights='../input/sartorius-yolo-models/best_scaled_shsy5y_fold3.pt', device=device)\n    model_shsy5y4 = DetectMultiBackend(weights='../input/sartorius-yolo-models/best_scaled_shsy5y_fold4.pt', device=device)\n    yolo_models_shsy5y = [model_shsy5y1, model_shsy5y2, model_shsy5y3, model_shsy5y4, model_shsy5y0]\n    \n    return predictors_shsy5y, yolo_models_shsy5y","metadata":{"execution":{"iopub.status.busy":"2021-12-16T01:13:56.938919Z","iopub.execute_input":"2021-12-16T01:13:56.93947Z","iopub.status.idle":"2021-12-16T01:13:56.952827Z","shell.execute_reply.started":"2021-12-16T01:13:56.93943Z","shell.execute_reply":"2021-12-16T01:13:56.95197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_astro_model():\n    cfg = get_cfg()\n    cfg.merge_from_file(model_zoo.get_config_file(\"Misc/cascade_mask_rcnn_X_152_32x8d_FPN_IN5k_gn_dconv.yaml\"))\n    cfg.INPUT.MASK_FORMAT='bitmask'\n    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n    cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.7\n    cfg.TEST.DETECTIONS_PER_IMAGE = 500\n    cfg.TEST.AUG = CN({\"ENABLED\": True})\n    cfg.TEST.AUG.MIN_SIZES = (640, 750, 860)\n    cfg.TEST.AUG.MAX_SIZE = 1440\n    cfg.TEST.AUG.FLIP = True\n\n    #freeze1\n    cfg.MODEL.WEIGHTS = '../input/sartorius-model-astro-pseudo/best_detectron2_X152_astro_step_freeze1_pseudo_fold1.pth'\n    model_astro1 = build_model(cfg)\n    DetectionCheckpointer(model_astro1).load(cfg.MODEL.WEIGHTS)\n    predictor_astro1 = GeneralizedRCNNWithTTA(cfg, model_astro1)\n    \n    cfg.MODEL.WEIGHTS = '../input/sartorius-model-astro-pseudo/best_detectron2_X152_astro_step_freeze1_pseudo_fold2.pth'\n    model_astro2 = build_model(cfg)\n    DetectionCheckpointer(model_astro2).load(cfg.MODEL.WEIGHTS)\n    predictor_astro2 = GeneralizedRCNNWithTTA(cfg, model_astro2)\n    \n    cfg.MODEL.WEIGHTS = '../input/sartorius-model-astro-pseudo/best_detectron2_X152_astro_step_freeze1_pseudo_fold3.pth'\n    model_astro3 = build_model(cfg)\n    DetectionCheckpointer(model_astro3).load(cfg.MODEL.WEIGHTS)\n    predictor_astro3 = GeneralizedRCNNWithTTA(cfg, model_astro3)\n    \n    cfg.MODEL.WEIGHTS = '../input/sartorius-model-astro-pseudo/best_detectron2_X152_astro_pseudo_fold4.pth'\n    model_astro4 = build_model(cfg)\n    DetectionCheckpointer(model_astro4).load(cfg.MODEL.WEIGHTS)\n    predictor_astro4 = GeneralizedRCNNWithTTA(cfg, model_astro4)\n    \n    cfg.MODEL.WEIGHTS = '../input/sartorius-model-astro-pseudo/best_detectron2_X152_astro_cereb_step_freeze1_pseudo.pth'\n    model_astro5 = build_model(cfg)\n    DetectionCheckpointer(model_astro5).load(cfg.MODEL.WEIGHTS)\n    predictor_astro5 = GeneralizedRCNNWithTTA(cfg, model_astro5)\n    \n    #freeze2\n    cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.33, 0.5, 1.0, 2.0, 3.0]]\n    \n    cfg.MODEL.WEIGHTS = '../input/sartorius-model-astro-freeze2-pseudo/best_detectron2_X152_astro_step_freeze2_pseudo_fold1.pth'\n    model_astro6 = build_model(cfg)\n    DetectionCheckpointer(model_astro6).load(cfg.MODEL.WEIGHTS)\n    predictor_astro6 = GeneralizedRCNNWithTTA(cfg, model_astro6)\n    \n    cfg.MODEL.WEIGHTS = '../input/sartorius-model-astro-freeze2-pseudo/best_detectron2_X152_astro_step_freeze2_pseudo_fold2.pth'\n    model_astro7 = build_model(cfg)\n    DetectionCheckpointer(model_astro7).load(cfg.MODEL.WEIGHTS)\n    predictor_astro7 = GeneralizedRCNNWithTTA(cfg, model_astro7)\n    \n    cfg.MODEL.WEIGHTS = '../input/sartorius-model-astro-freeze2-pseudo/best_detectron2_X152_astro_step_freeze2_pseudo_fold3.pth'\n    model_astro8 = build_model(cfg)\n    DetectionCheckpointer(model_astro8).load(cfg.MODEL.WEIGHTS)\n    predictor_astro8 = GeneralizedRCNNWithTTA(cfg, model_astro8)\n    \n    cfg.MODEL.WEIGHTS = '../input/sartorius-model-astro-freeze2-pseudo/best_detectron2_X152_astro_step_freeze2_pseudo_fold4.pth'\n    model_astro9 = build_model(cfg)\n    DetectionCheckpointer(model_astro9).load(cfg.MODEL.WEIGHTS)\n    predictor_astro9 = GeneralizedRCNNWithTTA(cfg, model_astro9)\n    \n    cfg.MODEL.WEIGHTS = '../input/sartorius-model-astro-freeze2-pseudo/best_detectron2_X152_astro_step_freeze2_pseudo.pth'\n    model_astro10 = build_model(cfg)\n    DetectionCheckpointer(model_astro10).load(cfg.MODEL.WEIGHTS)\n    predictor_astro10 = GeneralizedRCNNWithTTA(cfg, model_astro10)\n    \n    predictors_astro = [predictor_astro1, predictor_astro2, predictor_astro3, predictor_astro4, predictor_astro5,\n                       predictor_astro6, predictor_astro7, predictor_astro8, predictor_astro9, predictor_astro10]\n    \n    model_astro0 = DetectMultiBackend(weights='../input/sartorius-yolo-models/best_astro.pt', device=device)\n    model_astro1 = DetectMultiBackend(weights='../input/sartorius-yolo-models/best_astro_fold1.pt', device=device)\n    model_astro2 = DetectMultiBackend(weights='../input/sartorius-yolo-models/best_astro_fold2.pt', device=device)\n    model_astro3 = DetectMultiBackend(weights='../input/sartorius-yolo-models/best_astro_fold3.pt', device=device)\n    model_astro4 = DetectMultiBackend(weights='../input/sartorius-yolo-models/best_astro_fold4.pt', device=device)\n    yolo_models_astro = [model_astro1, model_astro2, model_astro3, model_astro4, model_astro0]\n    \n    return predictors_astro, yolo_models_astro","metadata":{"execution":{"iopub.status.busy":"2021-12-16T01:13:56.954731Z","iopub.execute_input":"2021-12-16T01:13:56.955253Z","iopub.status.idle":"2021-12-16T01:13:56.975947Z","shell.execute_reply.started":"2021-12-16T01:13:56.955214Z","shell.execute_reply":"2021-12-16T01:13:56.975084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_cort_model():\n    cfg = get_cfg()\n    cfg.merge_from_file(model_zoo.get_config_file(\"Misc/cascade_mask_rcnn_X_152_32x8d_FPN_IN5k_gn_dconv.yaml\"))\n    cfg.INPUT.MASK_FORMAT='bitmask'\n    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n    cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.7\n    cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[16, 32, 64, 128]]\n    cfg.TEST.DETECTIONS_PER_IMAGE = 650\n    cfg.TEST.AUG = CN({\"ENABLED\": True})\n    cfg.TEST.AUG.MIN_SIZES = (640, 750, 860)\n    cfg.TEST.AUG.MAX_SIZE = 1440\n    cfg.TEST.AUG.FLIP = True\n\n    #freeze2 models\n    cfg.MODEL.WEIGHTS = '../input/sartorius-model-cort-pseudo-freeze2/best_detectron2_X152_cort_step_freeze2_pseudo_fold1.pth'\n    model_cort1 = build_model(cfg)\n    DetectionCheckpointer(model_cort1).load(cfg.MODEL.WEIGHTS)\n    predictor_cort1 = GeneralizedRCNNWithTTA(cfg, model_cort1)\n    cfg.MODEL.WEIGHTS = '../input/sartorius-model-cort-pseudo-freeze2/best_detectron2_X152_cort_step_freeze2_pseudo_fold2.pth'\n    model_cort2 = build_model(cfg)\n    DetectionCheckpointer(model_cort2).load(cfg.MODEL.WEIGHTS)\n    predictor_cort2 = GeneralizedRCNNWithTTA(cfg, model_cort2)\n    cfg.MODEL.WEIGHTS = '../input/sartorius-model-cort-pseudo-freeze2/best_detectron2_X152_cort_step_freeze2_pseudo_fold3.pth'  \n    model_cort3 = build_model(cfg)\n    DetectionCheckpointer(model_cort3).load(cfg.MODEL.WEIGHTS)\n    predictor_cort3 = GeneralizedRCNNWithTTA(cfg, model_cort3)\n    cfg.MODEL.WEIGHTS = '../input/sartorius-model-cort-pseudo-freeze2/best_detectron2_X152_cort_step_freeze2_pseudo_fold4.pth'\n    model_cort4 = build_model(cfg)\n    DetectionCheckpointer(model_cort4).load(cfg.MODEL.WEIGHTS)\n    predictor_cort4 = GeneralizedRCNNWithTTA(cfg, model_cort4)\n    cfg.MODEL.WEIGHTS = '../input/sartorius-model-cort-pseudo-freeze2/best_detectron2_X152_cort_step_freeze2_pseudo.pth'\n    model_cort5 = build_model(cfg)\n    DetectionCheckpointer(model_cort5).load(cfg.MODEL.WEIGHTS)\n    predictor_cort5 = GeneralizedRCNNWithTTA(cfg, model_cort5)\n    \n    #freeze1 models\n    cfg.MODEL.WEIGHTS = '../input/sartorius-model-cort-pseudo/best_detectron2_X152_cort_step_freeze1_pseudo_fold1_2.pth'\n    model_cort6 = build_model(cfg)\n    DetectionCheckpointer(model_cort6).load(cfg.MODEL.WEIGHTS)\n    predictor_cort6 = GeneralizedRCNNWithTTA(cfg, model_cort6)\n    cfg.MODEL.WEIGHTS = '../input/sartorius-model-cort-pseudo/best_detectron2_X152_cort_step_freeze1_pseudo_fold2_2.pth'  \n    model_cort7 = build_model(cfg)\n    DetectionCheckpointer(model_cort7).load(cfg.MODEL.WEIGHTS)\n    predictor_cort7 = GeneralizedRCNNWithTTA(cfg, model_cort7)\n    cfg.MODEL.WEIGHTS = '../input/sartorius-model-cort-pseudo/best_detectron2_X152_cort_step_freeze1_pseudo_fold3_2.pth'\n    model_cort8 = build_model(cfg)\n    DetectionCheckpointer(model_cort8).load(cfg.MODEL.WEIGHTS)\n    predictor_cort8 = GeneralizedRCNNWithTTA(cfg, model_cort8)\n    cfg.MODEL.WEIGHTS = '../input/sartorius-model-cort-pseudo/best_detectron2_X152_cort_step_freeze1_pseudo_fold4_2.pth'\n    model_cort9 = build_model(cfg)\n    DetectionCheckpointer(model_cort9).load(cfg.MODEL.WEIGHTS)\n    predictor_cort9 = GeneralizedRCNNWithTTA(cfg, model_cort9)\n    cfg.MODEL.WEIGHTS = '../input/sartorius-model-cort-pseudo/best_detectron2_X152_cort_step_freeze1_pseudo2.pth'\n    model_cort10 = build_model(cfg)\n    DetectionCheckpointer(model_cort10).load(cfg.MODEL.WEIGHTS)\n    predictor_cort10 = GeneralizedRCNNWithTTA(cfg, model_cort10)\n    \n    predictors_cort = [predictor_cort1, predictor_cort2, predictor_cort3, predictor_cort4, predictor_cort5,\n                      predictor_cort6, predictor_cort7, predictor_cort8, predictor_cort9, predictor_cort10]\n    \n    model_cort0 = DetectMultiBackend(weights='../input/sartorius-yolo-models/best_cort2.pt', device=device)\n    model_cort1 = DetectMultiBackend(weights='../input/sartorius-yolo-models/best_cort_fold1.pt', device=device)\n    model_cort2 = DetectMultiBackend(weights='../input/sartorius-yolo-models/best_cort_fold2.pt', device=device)\n    model_cort3 = DetectMultiBackend(weights='../input/sartorius-yolo-models/best_cort_fold3.pt', device=device)\n    model_cort4 = DetectMultiBackend(weights='../input/sartorius-yolo-models/best_cort_fold4.pt', device=device)\n    yolo_models_cort = [model_cort1, model_cort2, model_cort3, model_cort4, model_cort0]\n    \n    return predictors_cort, yolo_models_cort","metadata":{"execution":{"iopub.status.busy":"2021-12-16T01:13:56.978325Z","iopub.execute_input":"2021-12-16T01:13:56.978712Z","iopub.status.idle":"2021-12-16T01:13:56.997494Z","shell.execute_reply.started":"2021-12-16T01:13:56.978672Z","shell.execute_reply":"2021-12-16T01:13:56.996799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_predictors(cls):\n    if cls == 0:\n        return get_shsy5y_model()\n    elif cls == 1:\n        return get_astro_model()\n    else:\n        return get_cort_model()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T01:13:57.000775Z","iopub.execute_input":"2021-12-16T01:13:57.001231Z","iopub.status.idle":"2021-12-16T01:13:57.010242Z","shell.execute_reply.started":"2021-12-16T01:13:57.001192Z","shell.execute_reply":"2021-12-16T01:13:57.009569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_classes = {0:[], 1:[], 2:[]}\nimg_ids = {0:[], 1:[], 2:[]}\nfor i, fn in enumerate(test_names):\n    cls = classify_image(fn, predictor)\n    img_classes[cls].append(fn)\n    #img_ids[cls].append(val_id[i])\ndel predictor\ntorch.cuda.empty_cache()\n#gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T01:13:57.011732Z","iopub.execute_input":"2021-12-16T01:13:57.012085Z","iopub.status.idle":"2021-12-16T01:15:19.423943Z","shell.execute_reply.started":"2021-12-16T01:13:57.012051Z","shell.execute_reply":"2021-12-16T01:15:19.422832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids = []\nmasks = []\nfor cls in range(3):\n    #cls = 2\n    predictors, yolo_models = get_predictors(cls)\n    filenames = img_classes[cls]\n    #gc.collect()\n    for i in range(len(filenames)):\n        encoded_masks = get_masks(filenames[i], predictors, yolo_models, cls)\n        for enc in encoded_masks:\n            ids.append(filenames[i].stem)\n            masks.append(enc)\n        print(cls, i)\n        torch.cuda.empty_cache()\n        #gc.collect()\n    del predictors, yolo_models\n    torch.cuda.empty_cache()\n    #gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T01:15:19.425751Z","iopub.execute_input":"2021-12-16T01:15:19.426152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame({'id':ids, 'predicted':masks}).to_csv('submission.csv', index=False)\npd.read_csv('submission.csv').head()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T01:12:39.515708Z","iopub.execute_input":"2021-12-16T01:12:39.516492Z","iopub.status.idle":"2021-12-16T01:12:39.577584Z","shell.execute_reply.started":"2021-12-16T01:12:39.516451Z","shell.execute_reply":"2021-12-16T01:12:39.576848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}