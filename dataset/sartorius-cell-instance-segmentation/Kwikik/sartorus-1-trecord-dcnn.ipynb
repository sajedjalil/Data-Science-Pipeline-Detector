{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport tensorflow as tf \nimport cv2\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport time\nimport random\nimport tensorflow_addons as tfa\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm import tqdm\n\n\nAUTO = tf.data.AUTOTUNE","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-03T15:02:18.334707Z","iopub.execute_input":"2022-02-03T15:02:18.335379Z","iopub.status.idle":"2022-02-03T15:02:26.020589Z","shell.execute_reply.started":"2022-02-03T15:02:18.335259Z","shell.execute_reply":"2022-02-03T15:02:26.019327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" semantic segmentation \n- architecture : U-net\n    \n  ","metadata":{}},{"cell_type":"markdown","source":"# ðŸŒˆ Visualization ","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/sartorius-cell-instance-segmentation/train.csv') \n\nlist = os.listdir(\"../input/sartorius-cell-instance-segmentation/train\")\n\n#transforme List ( af6ae867fe6e.png) into a list of id in the pandas dataframe (af6ae867fe6e) \nid_list = [l.replace('.png','') for l in list] \nprint(type(id_list) , \" 111\")\n\n\n\ndef rle_decode(mask_rle, shape):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)\n\n\n\n# all image in test data have the same shape\nshape = (520, 704)     \nrow = 0    \n\n\nid_ = df.loc[row, 'id']  \n\n\nprint(type(id_))\n\nUI = df[\"id\"].unique() # ALL ID\nprint(len(UI))\n    \n    \nimg_masks = df.loc[df['id']==id_, 'annotation'].to_list()\n\nprint(len(img_masks))\nall_masks = np.zeros(shape)\n\n\npx = 1/plt.rcParams['figure.dpi']\nrows = 3\nfig, axarr = plt.subplots(rows, 2, figsize=(520*px, 704*px))\ni=0\nimg = cv2.imread(\"../input/sartorius-cell-instance-segmentation/train/0030fd0e6378.png\")\nfor mask in img_masks:\n    all_masks += rle_decode(mask, shape)\n    if i <=2:\n        axarr[i,1].imshow(all_masks)\n        axarr[i,1].axis('off')\n        axarr[i,1].set_title(f'Masks {i}')\n    \n        axarr[i,0].imshow(img)\n        axarr[i,0].axis('off')\n    \n        i+=1\n\nprint(all_masks.shape)\nprint(type(all_masks))\n\nplt.tight_layout(h_pad=0.1, w_pad=0.1)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-03T15:02:26.02302Z","iopub.execute_input":"2022-02-03T15:02:26.023345Z","iopub.status.idle":"2022-02-03T15:02:27.806838Z","shell.execute_reply.started":"2022-02-03T15:02:26.02331Z","shell.execute_reply":"2022-02-03T15:02:27.80568Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸŒˆ  Other Visualization","metadata":{}},{"cell_type":"code","source":"# test : \n\nN_exemple = 2\nfig, axarr = plt.subplots(N_exemple, 2, figsize=(15, 40))\nUI = df[\"id\"].unique()        # type numpy.ndarray\n\n    \n\nfor i in range(N_exemple):\n    img_masks = df.loc[df['id']==UI[i], 'annotation'].to_list()\n    print(len(img_masks))\n    img = cv2.imread(f\"../input/sartorius-cell-instance-segmentation/train/{UI[i]}.png\")\n    all_masks = np.zeros(shape)\n    \n    for mask in img_masks:\n        all_masks += rle_decode(mask, shape)\n    \n    \n    #mask\n    axarr[i, 1].imshow(all_masks)\n    axarr[i, 1].axis('off')\n    axarr[i, 1].set_title(f'Masks {i}')\n    \n    #image originale\n    axarr[i, 0].imshow(img)\n    axarr[i, 0].axis('off')\n    axarr[i, 0].set_title(f'Masks {i}')\n    \n\n    \n    \n    \nplt.tight_layout(h_pad=0.1, w_pad=0.1)\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-03T15:02:27.808263Z","iopub.execute_input":"2022-02-03T15:02:27.808504Z","iopub.status.idle":"2022-02-03T15:02:29.004108Z","shell.execute_reply.started":"2022-02-03T15:02:27.808474Z","shell.execute_reply":"2022-02-03T15:02:29.002858Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸ“ Create TFrecord","metadata":{}},{"cell_type":"code","source":"def _bytes_feature(value):         # S/O la doc tensorflow et le livre pour convertyre en byte pour le TFRECORD\n  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n  if isinstance(value, type(tf.constant(0))):\n    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _int64_feature(value):\n  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n  \n    \n        \ndef build_tfrecord_2():\n    df = pd.read_csv('../input/sartorius-cell-instance-segmentation/train.csv')    #datafrme\n    start = time.time()\n    shape = (520, 704)     # all image in test data have the same shape\n    UI = df[\"id\"].unique() # Nombre de De photo / id differente        #606 \n    \n    df1 = df.groupby('id',as_index=False,sort=False).last()\n    lbl = LabelEncoder()\n    df1[\"cell_type\"] = lbl.fit_transform(df1[\"cell_type\"])\n    \n    option = tf.io.TFRecordOptions(compression_level=2, compression_type=\"ZLIB\")\n    \n    with tf.io.TFRecordWriter(\"Train2.tfrec\", options=option) as writer:\n        for i in tqdm(range(len(UI))):\n            img_masks = df.loc[df['id']==UI[i], 'annotation'].to_list() # all mask in 1 list \n            img = cv2.imread(f\"../input/sartorius-cell-instance-segmentation/train/{UI[i]}.png\")      # Image \n            all_masks = np.zeros(shape, dtype=np.float32)\n            img = np.true_divide(img, 255, dtype=np.float32)\n        \n            \n            for mask in img_masks:\n                all_masks += rle_decode(mask, shape) # get the mask\n            \n            all_masks[all_masks > 1] = 1   #because some mask intercepts\n            \n            data = {'image': _bytes_feature(img.tobytes()),\n                    'mask': _bytes_feature(all_masks.tobytes()),\n                    'label': _int64_feature(df1[\"cell_type\"].iloc[i]),\n                    }\n        \n            Data = tf.train.Example(features=tf.train.Features(feature=data))\n            Data = Data.SerializeToString()\n\n            writer.write(Data)\n\n    elapsed = time.time()\n    elapsed = elapsed - start\n    print(\"Time spent: \", elapsed)\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2022-02-03T15:02:29.007095Z","iopub.execute_input":"2022-02-03T15:02:29.007415Z","iopub.status.idle":"2022-02-03T15:02:29.024793Z","shell.execute_reply.started":"2022-02-03T15:02:29.007377Z","shell.execute_reply":"2022-02-03T15:02:29.024088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸ“– Read DS and data augmentation","metadata":{}},{"cell_type":"code","source":"\n\n#DS for mask\n\ndef decode_mask(image_data):\n    image = tf.io.decode_raw(image_data['image'], tf.float32)\n    image = tf.reshape(image, [520,704,3])\n    mask = tf.io.decode_raw(image_data['mask'], tf.float32)\n    mask = tf.reshape(mask, [520,704,1])\n    return (image, mask)\n\n\ndef read_mask(exemple):\n    image_feature_description = {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'label': tf.io.FixedLenFeature([], tf.int64),\n        'mask': tf.io.FixedLenFeature([], tf.string)\n    }\n    Exemple = tf.io.parse_single_example(exemple , image_feature_description)\n    return decode_mask(Exemple)\n\n\n\n# DS for label\n\n\ndef read_label(exemple):\n    image_feature_description = {\n        'image': tf.io.FixedLenFeature([], tf.string),\n        'label': tf.io.FixedLenFeature([], tf.int64),\n        'mask': tf.io.FixedLenFeature([], tf.string)\n    }\n    Exemple = tf.io.parse_single_example(exemple , image_feature_description)\n    #image, label= decode_label(Exemple) \n    return decode_label(Exemple)\n\n\ndef decode_label(image_data):\n    image = tf.io.decode_raw(image_data['image'], tf.float32)\n    image = tf.reshape(image, [520,704,3])\n    label = image_data['label']\n    return (image, label)\n\n\n\n\ndef augment3(image, mask):\n    # Make a new seed.\n    new_seed= tf.random.uniform([2], minval=0, maxval=200000, dtype=tf.dtypes.int32)\n    #new_seed = tf.random.experimental.stateless_split(seed, num=1)[0, :]\n    \n    #random rotation \n    N=tf.random.uniform([1], minval=-3, maxval=3, dtype=tf.dtypes.float32)\n    image = tfa.image.rotate( image,N[0])\n    mask = tfa.image.rotate( mask,N[0])\n   \n    #random contrast ?\n    \n    \n    # random HUE ? \n    \n    \n    \n    # Random brightness ( uniquement pour image )\n    image = tf.image.stateless_random_brightness(image, max_delta=0.3, seed=new_seed)\n    #label = tf.image.stateless_random_brightness(label, max_delta=0.5, seed=new_seed)\n    \n    # flip up down\n    image = tf.image.stateless_random_flip_up_down(image, new_seed)\n    mask =  tf.image.stateless_random_flip_up_down(mask, new_seed)\n    \n    # flip left right\n    image = tf.image.stateless_random_flip_left_right(image, new_seed)\n    mask = tf.image.stateless_random_flip_left_right(mask, new_seed)\n    \n    image = tf.clip_by_value(image, 0, 255)\n    #label = tf.clip_by_value(label, 0, 255)\n    \n    return image, mask\n\n\ndef augment3L(image ,label):\n    # Make a new seed.\n    new_seed= tf.random.uniform([2], minval=0, maxval=200000, dtype=tf.dtypes.int32)\n    #new_seed = tf.random.experimental.stateless_split(seed, num=1)[0, :]\n    \n    #random rotation \n    N=tf.random.uniform([1], minval=-3, maxval=3, dtype=tf.dtypes.float32)\n    image = tfa.image.rotate( image,N[0])\n   \n    #random contrast ?\n    \n    \n    # random HUE ? \n    \n    \n    \n    # Random brightness ( uniquement pour image )\n    image = tf.image.stateless_random_brightness(image, max_delta=0.4, seed=new_seed)\n    #label = tf.image.stateless_random_brightness(label, max_delta=0.5, seed=new_seed)\n    \n    # flip up down\n    image = tf.image.stateless_random_flip_up_down(image, new_seed)\n\n    \n    # flip left right\n    image = tf.image.stateless_random_flip_left_right(image, new_seed)\n\n    \n    image = tf.clip_by_value(image, 0, 255)\n    #label = tf.clip_by_value(label, 0, 255)\n    \n    return image, label\n\n\n\ndef load_dataset(path , Augment = False , Big = False , label=True):\n    # Label = TRUE  :  image and label\n    # Label = False : image and Mask\n    \n    \n    dataset = tf.data.TFRecordDataset(path,compression_type=\"ZLIB\", num_parallel_reads=AUTO)\n    if label:\n        dataset = dataset.map(read_label, num_parallel_calls= AUTO)\n    else:\n        dataset = dataset.map(read_mask, num_parallel_calls= AUTO)\n    if Big:\n        dataset = dataset.repeat(6)\n    if Augment :\n        if label:\n            dataset = dataset.map(augment3L,num_parallel_calls = AUTO) \n        else:\n            dataset = dataset.map(augment3,num_parallel_calls = AUTO)\n    return dataset\n\n\ndef view_dataset(path, Augment = False ,big = False, label=True ):\n    data = load_dataset(path, Augment = Augment  , Big = big, label=label)  # class 'tensorflow.python.data.ops.dataset_ops.ParallelMapDataset'   \n\n    N = 5\n    i = 0\n    \n\n    ds = data.take(N)\n    if label:\n        fig, axarr = plt.subplots(N,1, figsize=(15, 40))\n        for image ,label  in ds:\n            print(image.shape , type(image))\n            print(label.shape)\n        \n            #image \n            axarr[i].imshow(image)\n            axarr[i].axis('off')\n            axarr[i].set_title(f'Masks {label}')\n            i+=1\n    else:\n        fig, axarr = plt.subplots(N,2, figsize=(15, 40))\n        for image ,mask  in ds:\n            print(image.shape , type(image))\n            print(mask.shape)\n        \n            reshape = tf.reshape(mask ,[520*704])\n            Unique = tf.unique(reshape)\n            print(mask.shape)\n            print(Unique)\n        \n            #mask\n            axarr[i, 1].imshow(mask)\n            axarr[i, 1].axis('off')\n            axarr[i, 1].set_title(f'Masks {i}')\n    \n            #image \n            axarr[i, 0].imshow(image)\n            axarr[i, 0].axis('off')\n            axarr[i, 0].set_title(f'image {i}')\n            i+=1\n    \n    plt.tight_layout(h_pad=0.1, w_pad=0.1)\n    plt.show()\n    \n    return(data)\n    # pour afficher 1 seule image\n''' fig, axs = plt.subplots(1, 2,figsize=(20, 20))                \n    axs[0].imshow(image)\n    axs[0].axis('off')\n    axs[1].imshow(np.sum(mask, axis=-1))\n    axs[1].axis('off')'\n    plt.show()'''\n","metadata":{"execution":{"iopub.status.busy":"2022-02-03T15:02:29.026582Z","iopub.execute_input":"2022-02-03T15:02:29.026922Z","iopub.status.idle":"2022-02-03T15:02:29.075068Z","shell.execute_reply.started":"2022-02-03T15:02:29.026872Z","shell.execute_reply":"2022-02-03T15:02:29.07412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"DCNN for classification\n","metadata":{}},{"cell_type":"code","source":"def DCNN(DS):\n\n    \n    inputs = tf.keras.Input(shape=[520, 704, 3])\n    x = inputs\n    x = tf.keras.layers.Conv2D(20, kernel_size =(3, 3),strides=(1, 1) , padding=\"same\" )(x)\n    x = tf.keras.layers.MaxPooling2D( pool_size=(2, 2), strides=(2, 2))(x)\n    \n    x = tf.keras.layers.Conv2D(40, kernel_size =(3, 3),strides=(1, 1) , padding=\"same\")(x)\n    x = tf.keras.layers.MaxPooling2D( pool_size=(2, 2), strides=(2, 2))(x)\n    \n    x = tf.keras.layers.Conv2D(60, kernel_size =(3, 3),strides=(1, 1) , padding=\"same\" )(x)\n    x = tf.keras.layers.MaxPooling2D( pool_size=(2, 2), strides=(2, 2))(x)\n    \n    x = tf.keras.layers.Conv2D(80, kernel_size =(3, 3),strides=(1, 1) , padding=\"same\" )(x)\n    x = tf.keras.layers.MaxPooling2D( pool_size=(2, 2), strides=(2, 2))(x)\n    \n    \n    x = tf.keras.layers.Flatten()(x)\n    \n    x = tf.keras.layers.Dense(10, activation='elu', kernel_initializer=tf.keras.initializers.LecunNormal())(x)   # tf.nn.leaky_relu\n    x = tf.keras.layers.Dropout(rate=0.4)(x)\n    \n    x = tf.keras.layers.Dense(512, activation='elu', kernel_initializer=tf.keras.initializers.LecunNormal())(x)\n    x = tf.keras.layers.Dropout(rate=0.4)(x)\n    \n    x = tf.keras.layers.Dense(512, activation='elu', kernel_initializer=tf.keras.initializers.LecunNormal())(x)\n    x = tf.keras.layers.Dropout(rate=0.4)(x)\n    \n                               \n    outputs = tf.keras.layers.Dense(3 , activation = 'softmax')(x) \n\n                                     \n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n    \n\n    model.summary()\n\n\n\n    # model compile and fit\n    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n\n\n    start = time.time()\n    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), optimizer=optimizer, metrics=[\"accuracy\"])\n\n    history = model.fit(DS ,epochs=10 )\n\n    model.save('./Test_1.h5')\n    \n\n\n    # plot ressult\n\n    elapsed = time.time()\n    elapsed = elapsed - start\n    print(\"Time spent: \", elapsed)\n\n    pd.DataFrame(history.history).plot(figsize=(8, 5))\n    plt.grid(True)\n    plt.gca().set_ylim(0, 1)  # set the vertical range to [0-1]\n    plt.show()\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-02-03T15:02:29.076667Z","iopub.execute_input":"2022-02-03T15:02:29.07726Z","iopub.status.idle":"2022-02-03T15:02:29.100031Z","shell.execute_reply.started":"2022-02-03T15:02:29.077203Z","shell.execute_reply":"2022-02-03T15:02:29.098852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    path = \"./Train2.tfrec\"\n    \n    build_tfrecord_2()\n    #ds = view_dataset(path,Augment = True, big = True ,label=False)\n    \n    #DCNN(ds.batch(100).prefetch(AUTO))\n","metadata":{"execution":{"iopub.status.busy":"2022-02-03T15:02:29.101348Z","iopub.execute_input":"2022-02-03T15:02:29.101644Z","iopub.status.idle":"2022-02-03T15:03:36.056967Z","shell.execute_reply.started":"2022-02-03T15:02:29.101603Z","shell.execute_reply":"2022-02-03T15:03:36.0557Z"},"trusted":true},"execution_count":null,"outputs":[]}]}