{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Coco Dataset Notebook and Inference Notebook**","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/vexxingbanana/sartorius-coco-dataset-notebook\n\nhttps://www.kaggle.com/vexxingbanana/mmdetection-neuron-inference","metadata":{}},{"cell_type":"markdown","source":"# **References**","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/dschettler8845/sartorius-segmentation-eda-and-baseline\n\nhttps://www.kaggle.com/ihelon/cell-segmentation-run-length-decoding\n\nhttps://www.kaggle.com/stainsby/fast-tested-rle\n\nhttps://www.kaggle.com/paulorzp/run-length-encode-and-decode\n\nhttps://www.kaggle.com/awsaf49/sartorius-mmdetection-infer\n\nhttps://www.kaggle.com/awsaf49/sartorius-mmdetection-train\n\nhttps://www.kaggle.com/evancofsky/sartorius-torch-lightning-mask-r-cnn/notebook","metadata":{}},{"cell_type":"markdown","source":"# Notes","metadata":{}},{"cell_type":"markdown","source":"* Trying out more epochs, added more augmentations, increased batch size to 2, and using validation dataset.\n* Added mixed precision, reduced epochs back to 12, removed CLAHE augmentation.\n* Increased confidence on inference of bboxes to 0.5, removed validation.\n* Trying out more epochs, added back 5% validation, changed normalization to the dataset, changed to 3 classes.","metadata":{}},{"cell_type":"markdown","source":"Please consider upvoting if you find this helpful. :)","metadata":{}},{"cell_type":"markdown","source":"# **Install MMDetection and MMDetection-Compatible Torch**","metadata":{}},{"cell_type":"code","source":"!pip install '/kaggle/input/pytorch-170-cuda-toolkit-110221/torch-1.7.0+cu110-cp37-cp37m-linux_x86_64.whl' --no-deps\n!pip install '/kaggle/input/pytorch-170-cuda-toolkit-110221/torchvision-0.8.1+cu110-cp37-cp37m-linux_x86_64.whl' --no-deps\n!pip install '/kaggle/input/pytorch-170-cuda-toolkit-110221/torchaudio-0.7.0-cp37-cp37m-linux_x86_64.whl' --no-deps","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:54:11.298018Z","iopub.execute_input":"2021-12-15T16:54:11.29867Z","iopub.status.idle":"2021-12-15T16:56:21.908526Z","shell.execute_reply.started":"2021-12-15T16:54:11.298573Z","shell.execute_reply":"2021-12-15T16:56:21.907725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install '/kaggle/input/mmdetectionv2140/addict-2.4.0-py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/yapf-0.31.0-py2.py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/terminal-0.4.0-py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/terminaltables-3.1.0-py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/mmcv_full-1_3_8-cu110-torch1_7_0/mmcv_full-1.3.8-cp37-cp37m-manylinux1_x86_64.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/pycocotools-2.0.2/pycocotools-2.0.2' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/mmpycocotools-12.0.3/mmpycocotools-12.0.3' --no-deps\n\n!rm -rf mmdetection\n\n!cp -r /kaggle/input/mmdetectionv2140/mmdetection-2.14.0 /kaggle/working/\n!mv /kaggle/working/mmdetection-2.14.0 /kaggle/working/mmdetection\n%cd /kaggle/working/mmdetection\n!pip install -e .","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:56:21.912183Z","iopub.execute_input":"2021-12-15T16:56:21.912401Z","iopub.status.idle":"2021-12-15T16:59:52.151346Z","shell.execute_reply.started":"2021-12-15T16:56:21.912376Z","shell.execute_reply":"2021-12-15T16:59:52.150083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Import Libraries** ","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport sklearn\nimport torchvision\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport PIL\nimport json\nfrom PIL import Image, ImageEnhance\nimport albumentations as A\nimport mmdet\nimport mmcv\nfrom albumentations.pytorch import ToTensorV2\nimport seaborn as sns\nimport glob\nfrom pathlib import Path\nimport pycocotools\nfrom pycocotools import mask\nimport numpy.random\nimport random\nimport cv2\nimport re\nfrom mmdet.datasets import build_dataset\nfrom mmdet.models import build_detector\nfrom mmdet.apis import train_detector\nfrom mmdet.apis import inference_detector, init_detector, show_result_pyplot, set_random_seed","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-15T16:59:52.153089Z","iopub.execute_input":"2021-12-15T16:59:52.15346Z","iopub.status.idle":"2021-12-15T17:00:13.636755Z","shell.execute_reply.started":"2021-12-15T16:59:52.153419Z","shell.execute_reply":"2021-12-15T17:00:13.635763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd ..","metadata":{"execution":{"iopub.status.busy":"2021-12-15T17:00:13.639407Z","iopub.execute_input":"2021-12-15T17:00:13.639619Z","iopub.status.idle":"2021-12-15T17:00:13.647713Z","shell.execute_reply.started":"2021-12-15T17:00:13.639593Z","shell.execute_reply":"2021-12-15T17:00:13.646779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_WIDTH = 704\nIMG_HEIGHT = 520","metadata":{"execution":{"iopub.status.busy":"2021-12-15T17:00:13.707692Z","iopub.execute_input":"2021-12-15T17:00:13.708124Z","iopub.status.idle":"2021-12-15T17:00:13.711926Z","shell.execute_reply.started":"2021-12-15T17:00:13.708087Z","shell.execute_reply":"2021-12-15T17:00:13.711181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Helper Functions**","metadata":{}},{"cell_type":"code","source":"def rle_decode(mask_rle, shape):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\n\ndef flatten_l_o_l(nested_list):\n    \"\"\" Flatten a list of lists \"\"\"\n    return [item for sublist in nested_list for item in sublist]\n\n\ndef load_json_to_dict(json_path):\n    \"\"\" tbd \"\"\"\n    with open(json_path) as json_file:\n        data = json.load(json_file)\n    return data","metadata":{"execution":{"iopub.status.busy":"2021-12-15T17:00:13.718198Z","iopub.execute_input":"2021-12-15T17:00:13.718958Z","iopub.status.idle":"2021-12-15T17:00:13.732079Z","shell.execute_reply.started":"2021-12-15T17:00:13.718893Z","shell.execute_reply":"2021-12-15T17:00:13.731221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_img_and_mask(img_path, annotation, width, height):\n    \"\"\" Capture the relevant image array as well as the image mask \"\"\"\n    img_mask = np.zeros((height, width), dtype=np.uint8)\n    for i, annot in enumerate(annotation): \n        img_mask = np.where(rle_decode(annot, (height, width))!=0, i, img_mask)\n    img = cv2.imread(img_path)[..., ::-1]\n    return img[..., 0], img_mask\n\ndef plot_img_and_mask(img, mask, invert_img=True, boost_contrast=True):\n    \"\"\" Function to take an image and the corresponding mask and plot\n    \n    Args:\n        img (np.arr): 1 channel np arr representing the image of cellular structures\n        mask (np.arr): 1 channel np arr representing the instance masks (incrementing by one)\n        invert_img (bool, optional): Whether or not to invert the base image\n        boost_contrast (bool, optional): Whether or not to boost contrast of the base image\n        \n    Returns:\n        None; Plots the two arrays and overlays them to create a merged image\n    \"\"\"\n    plt.figure(figsize=(20,10))\n    \n    plt.subplot(1,3,1)\n    _img = np.tile(np.expand_dims(img, axis=-1), 3)\n    \n    # Flip black-->white ... white-->black\n    if invert_img:\n        _img = _img.max()-_img\n        \n    if boost_contrast:\n        _img = np.asarray(ImageEnhance.Contrast(Image.fromarray(_img)).enhance(16))\n        \n    plt.imshow(_img)\n    plt.axis(False)\n    plt.title(\"Cell Image\", fontweight=\"bold\")\n    \n    plt.subplot(1,3,2)\n    _mask = np.zeros_like(_img)\n    _mask[..., 0] = mask\n    plt.imshow(mask, cmap='rainbow')\n    plt.axis(False)\n    plt.title(\"Instance Segmentation Mask\", fontweight=\"bold\")\n    \n    merged = cv2.addWeighted(_img, 0.75, np.clip(_mask, 0, 1)*255, 0.25, 0.0,)\n    plt.subplot(1,3,3)\n    plt.imshow(merged)\n    plt.axis(False)\n    plt.title(\"Cell Image w/ Instance Segmentation Mask Overlay\", fontweight=\"bold\")\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T17:00:13.733931Z","iopub.execute_input":"2021-12-15T17:00:13.734484Z","iopub.status.idle":"2021-12-15T17:00:13.75138Z","shell.execute_reply.started":"2021-12-15T17:00:13.734444Z","shell.execute_reply":"2021-12-15T17:00:13.750479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def polygonFromMask(maskedArr, idx):\n  # adapted from https://github.com/hazirbas/coco-json-converter/blob/master/generate_coco_json.py\n  contours, _ = cv2.findContours(maskedArr, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n  segmentation = []\n  valid_poly = 0\n  for contour in contours:\n  # Valid polygons have >= 6 coordinates (3 points)\n     if contour.size >= 6:\n        segmentation.append(contour.astype(float).flatten().tolist())\n        valid_poly += 1\n  if valid_poly == 0:\n     raise ValueError(idx)\n  return [segmentation]","metadata":{"execution":{"iopub.status.busy":"2021-12-15T17:00:13.752972Z","iopub.execute_input":"2021-12-15T17:00:13.753501Z","iopub.status.idle":"2021-12-15T17:00:13.765418Z","shell.execute_reply.started":"2021-12-15T17:00:13.753464Z","shell.execute_reply":"2021-12-15T17:00:13.764555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Visualizations**","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/sartorius-cell-instance-segmentation/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-15T17:00:13.76699Z","iopub.execute_input":"2021-12-15T17:00:13.767509Z","iopub.status.idle":"2021-12-15T17:00:14.540777Z","shell.execute_reply.started":"2021-12-15T17:00:13.767472Z","shell.execute_reply":"2021-12-15T17:00:14.539949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T17:00:14.542147Z","iopub.execute_input":"2021-12-15T17:00:14.543044Z","iopub.status.idle":"2021-12-15T17:00:14.574385Z","shell.execute_reply.started":"2021-12-15T17:00:14.543006Z","shell.execute_reply":"2021-12-15T17:00:14.573729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lines = []\nfor f in train_df.itertuples():\n    lines.append('../input/sartorius-cell-instance-segmentation/train/' + f[1] + '.png')","metadata":{"execution":{"iopub.status.busy":"2021-12-15T17:00:14.575598Z","iopub.execute_input":"2021-12-15T17:00:14.576568Z","iopub.status.idle":"2021-12-15T17:00:14.824479Z","shell.execute_reply.started":"2021-12-15T17:00:14.576504Z","shell.execute_reply":"2021-12-15T17:00:14.823641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lins = pd.Series(lines, name='img_path')","metadata":{"execution":{"iopub.status.busy":"2021-12-15T17:00:14.825693Z","iopub.execute_input":"2021-12-15T17:00:14.826373Z","iopub.status.idle":"2021-12-15T17:00:14.841666Z","shell.execute_reply.started":"2021-12-15T17:00:14.826335Z","shell.execute_reply":"2021-12-15T17:00:14.840877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.concat([train_df, lins], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T17:00:14.843593Z","iopub.execute_input":"2021-12-15T17:00:14.843871Z","iopub.status.idle":"2021-12-15T17:00:14.869562Z","shell.execute_reply.started":"2021-12-15T17:00:14.843835Z","shell.execute_reply":"2021-12-15T17:00:14.868812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp_df = train_df.drop_duplicates(subset=[\"id\", \"img_path\"]).reset_index(drop=True)\ntmp_df[\"annotation\"] = train_df.groupby(\"id\")[\"annotation\"].agg(list).reset_index(drop=True)\ntrain_df = tmp_df.copy()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T17:00:14.870729Z","iopub.execute_input":"2021-12-15T17:00:14.87214Z","iopub.status.idle":"2021-12-15T17:00:14.989057Z","shell.execute_reply.started":"2021-12-15T17:00:14.872101Z","shell.execute_reply":"2021-12-15T17:00:14.988197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T17:00:14.991159Z","iopub.execute_input":"2021-12-15T17:00:14.992201Z","iopub.status.idle":"2021-12-15T17:00:15.013696Z","shell.execute_reply.started":"2021-12-15T17:00:14.992162Z","shell.execute_reply":"2021-12-15T17:00:15.012895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_mask(idx):\n    im, mk = get_img_and_mask(**train_df[[\"img_path\", \"annotation\", \"width\", \"height\"]].iloc[idx].to_dict())\n    plot_img_and_mask(im, mk)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T17:00:15.015356Z","iopub.execute_input":"2021-12-15T17:00:15.016268Z","iopub.status.idle":"2021-12-15T17:00:15.023052Z","shell.execute_reply.started":"2021-12-15T17:00:15.016136Z","shell.execute_reply":"2021-12-15T17:00:15.022136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_mask(0)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T17:00:15.024178Z","iopub.execute_input":"2021-12-15T17:00:15.024828Z","iopub.status.idle":"2021-12-15T17:00:15.957185Z","shell.execute_reply.started":"2021-12-15T17:00:15.024791Z","shell.execute_reply":"2021-12-15T17:00:15.955965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_mask(1)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T17:00:15.96948Z","iopub.execute_input":"2021-12-15T17:00:15.969809Z","iopub.status.idle":"2021-12-15T17:00:16.822785Z","shell.execute_reply.started":"2021-12-15T17:00:15.969761Z","shell.execute_reply":"2021-12-15T17:00:16.821947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_mask(2)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T17:00:16.825295Z","iopub.execute_input":"2021-12-15T17:00:16.825559Z","iopub.status.idle":"2021-12-15T17:00:17.546474Z","shell.execute_reply.started":"2021-12-15T17:00:16.825526Z","shell.execute_reply":"2021-12-15T17:00:17.545021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, val_df = train_test_split(train_df, train_size=0.95, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T17:00:17.548195Z","iopub.execute_input":"2021-12-15T17:00:17.548533Z","iopub.status.idle":"2021-12-15T17:00:17.558023Z","shell.execute_reply.started":"2021-12-15T17:00:17.548489Z","shell.execute_reply":"2021-12-15T17:00:17.557113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.reset_index(drop=True)\nval_df = val_df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T17:00:17.559825Z","iopub.execute_input":"2021-12-15T17:00:17.561847Z","iopub.status.idle":"2021-12-15T17:00:17.567398Z","shell.execute_reply.started":"2021-12-15T17:00:17.561807Z","shell.execute_reply":"2021-12-15T17:00:17.566711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile labels.txt\nshsy5y\ncort\nastro","metadata":{"execution":{"iopub.status.busy":"2021-12-15T17:00:17.569378Z","iopub.execute_input":"2021-12-15T17:00:17.570693Z","iopub.status.idle":"2021-12-15T17:00:17.578423Z","shell.execute_reply.started":"2021-12-15T17:00:17.570644Z","shell.execute_reply":"2021-12-15T17:00:17.577665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model Config**","metadata":{}},{"cell_type":"code","source":"from mmcv import Config\ncfg = Config.fromfile('/kaggle/working/mmdetection/configs/cascade_rcnn/cascade_mask_rcnn_x101_64x4d_fpn_20e_coco.py')","metadata":{"execution":{"iopub.status.busy":"2021-12-15T17:00:17.580388Z","iopub.execute_input":"2021-12-15T17:00:17.581786Z","iopub.status.idle":"2021-12-15T17:00:17.611779Z","shell.execute_reply.started":"2021-12-15T17:00:17.581746Z","shell.execute_reply":"2021-12-15T17:00:17.611032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(cfg.pretty_text)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T17:00:17.61339Z","iopub.execute_input":"2021-12-15T17:00:17.613927Z","iopub.status.idle":"2021-12-15T17:00:18.7504Z","shell.execute_reply.started":"2021-12-15T17:00:17.613866Z","shell.execute_reply":"2021-12-15T17:00:18.748584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg.dataset_type = 'CocoDataset'\ncfg.classes = '/kaggle/working/labels.txt'\ncfg.data_root = '/kaggle/working'\n\nfor head in cfg.model.roi_head.bbox_head:\n    head.num_classes = 3\n    \ncfg.model.roi_head.mask_head.num_classes=3\n\ncfg.data.test.type = 'CocoDataset'\ncfg.data.test.classes = 'labels.txt'\ncfg.data.test.data_root = '/kaggle/working'\ncfg.data.test.ann_file = '../input/k/vexxingbanana/sartorius-coco-dataset-notebook/val_dataset.json'\ncfg.data.test.img_prefix = ''\n\ncfg.data.train.type = 'CocoDataset'\ncfg.data.train.data_root = '/kaggle/working'\ncfg.data.train.ann_file = '../input/k/vexxingbanana/sartorius-coco-dataset-notebook/train_dataset.json'\ncfg.data.train.img_prefix = ''\ncfg.data.train.classes = 'labels.txt'\n\ncfg.data.val.type = 'CocoDataset'\ncfg.data.val.data_root = '/kaggle/working'\ncfg.data.val.ann_file = '../input/k/vexxingbanana/sartorius-coco-dataset-notebook/val_dataset.json'\ncfg.data.val.img_prefix = ''\ncfg.data.val.classes = 'labels.txt'\n\nalbu_train_transforms = [\n    dict(type='ShiftScaleRotate', shift_limit=0.0625,\n         scale_limit=0.15, rotate_limit=15, p=0.4),\n    dict(type='RandomBrightnessContrast', brightness_limit=0.2,\n         contrast_limit=0.2, p=0.5),\n#     dict(type='IAAAffine', shear=(-10.0, 10.0), p=0.4),\n#     dict(type='CLAHE', p=0.5),\n    dict(\n        type=\"OneOf\",\n        transforms=[\n            dict(type=\"GaussianBlur\", p=1.0, blur_limit=7),\n            dict(type=\"MedianBlur\", p=1.0, blur_limit=7),\n        ],\n        p=0.4,\n    ),\n]\n\ncfg.train_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n#     dict(type='Resize', img_scale=[(440, 596), (480, 650), (520, 704), (580, 785), (620, 839)], multiscale_mode='value', keep_ratio=True),\n#     dict(type='Resize', img_scale=[(880, 1192), (960, 130), (1040, 1408), (1160, 1570), (1240, 1678)], multiscale_mode='value', keep_ratio=True),\n    dict(type='Resize', img_scale=[(1333, 800), (1690, 960)]),\n#     dict(type='Resize', img_scale=(1333, 800)),\n    \n    \n\n    dict(type='RandomFlip', flip_ratio=0.5),\n\n    dict(\n        type='Albu',\n        transforms=albu_train_transforms,\n        bbox_params=dict(\n        type='BboxParams',\n        format='pascal_voc',\n        label_fields=['gt_labels'],\n        min_visibility=0.0,\n        filter_lost_elements=True),\n        keymap=dict(img='image', gt_bboxes='bboxes', gt_masks='masks'),\n        update_pad_shape=False,\n        skip_img_without_anno=True),\n    dict(\n        type='Normalize',\n        mean=[128, 128, 128],\n        std=[11.58, 11.58, 11.58],\n        to_rgb=True),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'), \n    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_masks', 'gt_labels'])\n]\n\ncfg.val_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n#         img_scale=[(880, 1192), (960, 130), (1040, 1408), (1160, 1570), (1240, 1678)],\n        img_scale = [(1333, 800), (1690, 960)],\n#         img_scale=(1333, 800),\n#         img_scale = (520, 704),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[128, 128, 128],\n                std=[11.58, 11.58, 11.58],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\n\n\ncfg.test_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=[(1333, 800), (1690, 960)],\n#         img_scale=(1333, 800),\n        \n#         img_scale = (520, 704),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[128, 128, 128],\n                std=[11.58, 11.58, 11.58],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\n\ncfg.data.train.pipeline = cfg.train_pipeline\ncfg.data.val.pipeline = cfg.val_pipeline\ncfg.data.test.pipeline = cfg.test_pipeline\n\n\ncfg.model.test_cfg.rcnn.max_per_img = 400\n\ncfg.load_from = '../input/cascade-mask-rcnn-mmdet/cascade_mask_rcnn_x101_64x4d_fpn_20e_coco_20200512_161033-bdb5126a.pth'\n\ncfg.work_dir = '/kaggle/working/model_output'\n\ncfg.optimizer.lr = 0.02 / 8\ncfg.lr_config = dict(\n    policy='CosineAnnealing', \n    by_epoch=False,\n    warmup='linear', \n    warmup_iters=125, \n    warmup_ratio=0.001,\n    min_lr=1e-07)\n\ncfg.data.samples_per_gpu = 1\ncfg.data.workers_per_gpu = 0\n\ncfg.evaluation.metric = 'segm'\ncfg.evaluation.interval = 1\n\ncfg.checkpoint_config.interval = 1\ncfg.runner.max_epochs = 12\ncfg.log_config.interval = 144\n\n\ncfg.model.train_cfg.rpn.sampler.num = 1024\ncfg.model.train_cfg.rpn_proposal.nms_post = 2000\nfor rcnn in cfg.model.train_cfg.rcnn:\n    rcnn.sampler.num = 3072\ncfg.model.test_cfg.rpn.nms_pre = 3000\ncfg.model.test_cfg.rpn.nms_post = 3000\n# cfg.model.test_cfg.rpn.max_num = 3000\n#edits to train and test cfg are from https://github.com/Media-Smart/SKU110K-DenseDet/blob/master/configs/SKU_fusion_bfp_x101_32x4d.py\n\ncfg.model.train_cfg.rpn_proposal.min_bbox_size = 75\ncfg.model.test_cfg.rpn.min_bbox_size = 75\n\ncfg.seed = 0\nset_random_seed(0, deterministic=False)\ncfg.gpu_ids = range(1)\ncfg.fp16 = dict(loss_scale=512.0)\nmeta = dict()\nmeta['config'] = cfg.pretty_text\n\n\n\nprint(f'Config:\\n{cfg.pretty_text}')","metadata":{"execution":{"iopub.status.busy":"2021-12-15T17:15:51.4504Z","iopub.execute_input":"2021-12-15T17:15:51.450739Z","iopub.status.idle":"2021-12-15T17:15:54.815798Z","shell.execute_reply.started":"2021-12-15T17:15:51.450707Z","shell.execute_reply":"2021-12-15T17:15:54.81497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Training**","metadata":{}},{"cell_type":"code","source":"datasets = [build_dataset(cfg.data.train)]\nmodel = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\nmodel.CLASSES = datasets[0].CLASSES\n\nmmcv.mkdir_or_exist(os.path.abspath(cfg.work_dir))\ntrain_detector(model, datasets, cfg, distributed=False, validate=True, meta=meta)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T17:00:18.842445Z","iopub.status.idle":"2021-12-15T17:00:18.843154Z","shell.execute_reply.started":"2021-12-15T17:00:18.842911Z","shell.execute_reply":"2021-12-15T17:00:18.842934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cfg.load_from = '/kaggle/working/model_output/epoch_9.pth'\n# cfg.work_dir = '/kaggle/working/finetune_output'\n# cfg.optimizer.lr = 0.02 / 32\n# cfg.lr_config = dict(\n#     policy='CosineAnnealing', \n#     by_epoch=False,\n#     warmup='linear', \n#     warmup_iters=1, \n#     warmup_ratio=0.001,\n#     min_lr=1e-09)\n# cfg.runner.max_epochs = 6\n\n# model = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n# model.CLASSES = datasets[0].CLASSES\n\n# mmcv.mkdir_or_exist(os.path.abspath(cfg.work_dir))\n# train_detector(model, datasets, cfg, distributed=False, validate=True, meta=meta)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T17:00:18.845069Z","iopub.status.idle":"2021-12-15T17:00:18.84549Z","shell.execute_reply.started":"2021-12-15T17:00:18.845268Z","shell.execute_reply":"2021-12-15T17:00:18.845289Z"},"trusted":true},"execution_count":null,"outputs":[]}]}