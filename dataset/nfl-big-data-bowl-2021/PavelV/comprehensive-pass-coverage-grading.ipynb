{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport pylab as pl\nfrom matplotlib import collections as mc\nfrom PIL import ImageColor\n\npd.options.mode.chained_assignment = None\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)\npd.set_option('display.width', 1000)\npd.options.display.max_colwidth = 400\n\n#plt.rcParams[\"font.family\"] = \"serif\"\n\nteam_colors = {\"TB\": \"#D50A0A\", \"DET\": \"#0076b6\", \"TEN\": \"#0C2340\", \"BAL\": \"#241773\",\n               \"GB\": \"#FFB612\", \"MIA\": \"#FC4C02\", \"DAL\": \"#041E42\", \"BUF\": \"#00338D\",\n               \"CLE\": \"#311D00\", \"HOU\": \"#03202f\", \"WAS\": \"#FFB612\", \"LAC\": \"#0080C6\",\n               \"CHI\": \"#c83803\", \"KC\": \"#E31837\", \"NYJ\": \"#125740\", \"PHI\": \"#004C54\",\n               \"NYG\": \"#0B2265\", \"IND\": \"#002C5F\", \"ATL\": \"#000000\", \"MIN\": \"#4F2683\",\n               \"CAR\": \"#0085CA\", \"CIN\": \"#fb4f14\", \"LA\": \"#866D4B\", \"ARI\": \"#000000\",\n               \"NE\": \"#B0B7BC\", \"SF\": \"#AA0000\", \"OAK\": \"#000000\", \"JAX\": \"#006778\",\n               \"PIT\": \"#FFB612\", \"NO\": \"#D3BC8D\", \"DEN\": \"#FB4F14\", \"SEA\": \"#69BE28\",\n               }\n\nteam_colors2 = {\"TB\": \"#FF7900\", \"DET\": \"#B0B7BC\", \"TEN\": \"#4B92DB\", \"BAL\": \"#000000\",\n                \"GB\": \"#203731\", \"MIA\": \"#008E97\", \"DAL\": \"#869397\", \"BUF\": \"#C60C30\",\n                \"CLE\": \"#ff3c00\", \"HOU\": \"#A71930\", \"WAS\": \"#773141\", \"LAC\": \"#FFC20E\",\n                \"CHI\": \"#0B162A\", \"KC\": \"#FFB81C\", \"NYJ\": \"#000000\", \"PHI\": \"#000000\",\n                \"NYG\": \"#a71930\", \"IND\": \"#A2AAAD\", \"ATL\": \"#a71930\", \"MIN\": \"#FFC62F\",\n                \"CAR\": \"#BFC0BF\", \"CIN\": \"#000000\", \"LA\": \"#002244\", \"ARI\": \"#97233F\",\n                \"NE\": \"#002244\", \"SF\": \"#B3995D\", \"OAK\": \"#A5ACAF\", \"JAX\": \"#9F792C\",\n                \"PIT\": \"#101820\", \"NO\": \"#101820\", \"DEN\": \"#002244\", \"SEA\": \"#002244\",\n                }\n\n\ndef fix_positions(test_df):\n    test_df.loc[test_df.name == \"J.C. Jackson\", 'position'] = \"CB\"\n    test_df.loc[test_df.name == \"Jimmie Ward\", 'position'] = \"CB\"\n    test_df.loc[test_df.name == \"Isaac Yiadom\", 'position'] = \"CB\"\n    return test_df\n\n\ndef rgb2hex(r, g, b):\n    return '#{:02x}{:02x}{:02x}'.format(r, g, b)\n\n\ndef season_grades(df):\n    #print(df)\n    df.loc[df.incoverage == 1, 'cpoa'] = df['cp'] - df['aycp']\n    df.loc[((df.incoverage == 1) & (df.targeted == 1)), 'cpoa_targ'] = df['cp'] - df['aycp']\n    df.loc[((df.incoverage == 1) & (df.targeted != 1)), 'cpoa_nontarg'] = df['cp'] - df['aycp']\n    df.loc[df.incoverage == 1, 'aycpoe'] =  df['outcome'] - df['aycp']\n    df.loc[((df.incoverage == 1) & (df.cpoa <= -0.15)), 'lockdown'] = 1\n    df.loc[((df.incoverage == 1) & (df.cpoa >= 0.15)), 'blown'] = 1\n    \n    df.loc[((df.sack == 1) & (df.lockdown != 1)), 'epa'] = np.nan\n    df.loc[((df.sack == 1) & (df.lockdown == 1)), 'epa'] = df['epa']\n    \n    average_grades = df.loc[()].groupby(['id', 'name'])[['aycp', 'cp', 'cpoa', 'cpoa_targ', 'cpoa_nontarg', 'cpoe', 'aycpoe', 'epa', 'lockdown', 'blown', 'incoverage', 'targeted', 'outcome']].sum()\n    average_grades = average_grades.loc[average_grades.incoverage >= 100]\n          \n    average_grades['position'] = df.loc[()].groupby(['id', 'name'])[['position']].last()\n    average_grades['compPercentage'] = average_grades['outcome'] / average_grades['targeted']\n    average_grades['targtedPercentage'] = average_grades['targeted'] / average_grades['incoverage']\n    average_grades['cpoa'] = average_grades['cpoa'] / average_grades['incoverage']\n    average_grades['cpoa_targ'] = average_grades['cpoa_targ'] / (average_grades['targeted'])\n    average_grades['cpoa_nontarg'] = average_grades['cpoa_nontarg'] / (average_grades['incoverage'] - average_grades['targeted'])\n    average_grades['cpoa_targdiff'] = average_grades['cpoa_targ'] - average_grades['cpoa_nontarg']\n    average_grades['cp'] = average_grades['cp'] / average_grades['incoverage']\n    average_grades['aycp'] = average_grades['aycp'] / average_grades['incoverage']\n    average_grades['cpoe'] = average_grades['cpoe'] / average_grades['targeted']\n    \n    average_grades['lockdown'] = average_grades['lockdown'] / average_grades['incoverage']\n    average_grades['blown'] = average_grades['blown'] / average_grades['incoverage']\n        \n    average_grades['aycpoe'] = average_grades['aycpoe'] / average_grades['targeted']\n    \n    epa_count = df.loc[()].groupby(['id', 'name'])[['epa']].mean()\n    average_grades['epa'] = epa_count['epa']\n   \n    average_grades['cpoa_norm'] = -1 * ((average_grades['cpoa'] - average_grades['cpoa'].mean()) / (average_grades['cpoa'].std()))\n    average_grades['cpoa_targ_norm'] = -1 * ((average_grades['cpoa_targ'] - average_grades['cpoa_targ'].mean()) / (average_grades['cpoa_targ'].std()))\n    average_grades['cpoa_nontarg_norm'] = -1 * ((average_grades['cpoa_nontarg'] - average_grades['cpoa_nontarg'].mean()) / (average_grades['cpoa_nontarg'].std()))\n    average_grades['cpoe_norm'] = -1 * ((average_grades['cpoe'] - average_grades['cpoe'].mean()) / (average_grades['cpoe'].std()))\n    average_grades['epa_norm'] = -1 * ((average_grades['epa'] - average_grades['epa'].mean()) / (average_grades['epa'].std()))\n    average_grades['lockdown_norm'] = 1 * ((average_grades['lockdown'] - average_grades['lockdown'].mean()) / (average_grades['lockdown'].std()))\n    average_grades['blown_norm'] = -1 * ((average_grades['blown'] - average_grades['blown'].mean()) / (average_grades['blown'].std()))\n    \n    average_grades['overall_grade'] = 0.1 * ((0.33 * average_grades['cpoa_targ_norm'] +\n                                       0.33 * average_grades['cpoe_norm'] + \n                                       0.33 * average_grades['epa_norm']) + 5.0) + 0.25\n    average_grades.sort_values('overall_grade', ascending=False, inplace=True)\n\n    #print(average_grades)\n    \n    Players = average_grades.index.values\n    average_grades_dict = average_grades.to_dict('dict')\n   \n    return Players, average_grades, average_grades_dict\n\n\ndef coverage_sacks(df):\n    maxCPperPlay = df.loc[(df.sack==1)].groupby(['playid'])[['cp', 'sack']].max()\n    meanCPperPlay = df.loc[(df.sack==1)].groupby(['playid'])[['cp', 'sack']].mean()\n    team = df.loc[(df.sack==1)].groupby(['playid'])[['defTeam']].last()\n    maxCPperPlay['defTeam'] = team['defTeam']\n    maxCPperPlay['meancp'] = meanCPperPlay['cp']\n    #print(maxCPperPlay)\n    CoverageSack = maxCPperPlay.loc[(maxCPperPlay.cp < 0.4) | (maxCPperPlay.meancp < 0.3)].groupby(['defTeam'])[['sack']].count()\n    CoverageSack.sort_values('sack', ascending=False, inplace=True)\n    return CoverageSack\n\n\ndef create_field(minY, maxY, ax, LOS, YardsToGo):\n    \n    ax.axes.get_xaxis().set_visible(False)\n    ax.axes.get_yaxis().set_visible(False)\n\n    ax.set_facecolor('#ADDDA7')\n    ax.set_alpha(0.5)\n    # Paint stripes\n    if 1:\n        for i in range(10,110,5):\n            if i < maxY and i > minY:\n                plt.axhline(i, color='white', linewidth=3, alpha=0.4, zorder=0) # y = 0\n        if minY < 10:\n            plt.axhline(0, color='white', linewidth=5, alpha=0.4, zorder=0) # y = 0\n            plt.axhline(10, color='white', linewidth=5, alpha=0.4, zorder=0) # y = 0\n        if maxY > 110:\n            plt.axhline(110, color='white', linewidth=5, alpha=0.4, zorder=0) # y = 0\n            plt.axhline(120, color='white', linewidth=5, alpha=0.4, zorder=0) # y = 0\n        if 60 > minY and 60 < maxY:\n            plt.axhline(60, color='white', linewidth=5, alpha=0.4, zorder=0) # y = 0\n    # Paint numbers\n    if 1:\n        for i in range(10,50,10):\n            if i+10 > minY and i+10 < maxY:\n                plt.text(53.3-12, i+10, str(i), color='white', fontsize=40, verticalalignment='center', alpha=0.6, horizontalalignment='center', weight='bold', rotation=90, zorder=0)\n            if 110-i > minY and 110-i < maxY:    \n                plt.text(53.3-12, 110-i, str(i), color='white', fontsize=40, verticalalignment='center', alpha=0.6, horizontalalignment='center', weight='bold', rotation=90, zorder=0)\n        if 60 < maxY and 60 > minY:\n            plt.text(53.3-12, 60, str(50), color='white', fontsize=40, verticalalignment='center', alpha=0.6, horizontalalignment='center', weight='bold', rotation=90, zorder=0)\n\n        for i in range(10,50,10):\n            if i+10 > minY and i+10 < maxY:\n                plt.text(12, i+10, str(i), color='white', fontsize=40, verticalalignment='center', alpha=0.6, horizontalalignment='center', weight='bold', rotation=270, zorder=0)\n            if 110-i > minY and 110-i < maxY:       \n                plt.text(12, 110-i, str(i), color='white', fontsize=40, verticalalignment='center', alpha=0.6, horizontalalignment='center', weight='bold', rotation=270, zorder=0)\n        if 60 < maxY and 60 > minY:\n            plt.text(12, 60, str(50), color='white', fontsize=40, verticalalignment='center', alpha=0.6, horizontalalignment='center', weight='bold', rotation=270, zorder=0)\n    if 1:\n        if minY < 10:\n            plt.text(26.5, 5, \"END ZONE\", color='white', fontsize=40, verticalalignment='center', alpha=0.6, horizontalalignment='center', weight='bold', rotation=0, zorder=0)\n        if maxY > 110:\n            plt.text(26.5, 115, \"END ZONE\", color='white', fontsize=40, verticalalignment='center', alpha=0.6, horizontalalignment='center', weight='bold', rotation=0, zorder=0)\n    # Add hash marks\n    lines = []\n    for i in range(10,110):\n        if i % 5 != 0:\n            if i > minY and i < maxY:\n                lines.append([(22.6, i), (23.6, i)])\n                lines.append([(53.3-22.6, i), (53.3-23.6, i)])\n    lc = mc.LineCollection(lines, colors='white', linewidths=2, alpha=0.6, zorder=0)\n    ax.add_collection(lc)\n    # Line of Scrimmage\n    plt.axhline(LOS, color='blue', linewidth=3, alpha=0.4, zorder=0) # y = 0\n    plt.axhline(LOS + YardsToGo, color='yellow', linewidth=3, alpha=0.4, zorder=0) # y = 0   \n\n\n\ndef plot_single(GAMES, TRACKING, PLAYERS, PLAYS, test_df, playID, Coverage_sacks):\n\n    fig, ax = pl.subplots(figsize=(14,25))\n\n    criteria = ((TRACKING.uniquePlayId==int(playID)))\n    frame = TRACKING.loc[criteria]\n\n    # Determine teams and colors\n    gameId = np.array(frame['gameId'])[0]\n    teamz = GAMES.loc[(GAMES.gameId==gameId)][['visitorTeamAbbr', 'homeTeamAbbr']].to_numpy()\n    awayteam = teamz[0,0]\n    hometeam = teamz[0,1]\n\n    if 1:\n        playz = PLAYS.loc[(PLAYS.uniquePlayId==int(playID))][['possessionTeam', 'absoluteYardlineNumber', 'yardlineNumber', 'yardsToGo']].to_numpy()\n        possessionteam = playz[0, 0]\n        LOS = playz[0, 1]\n        YardsToGo = playz[0, 3]\n\n    frame.loc[frame.team==\"home\", 'teamcolor'] = team_colors[hometeam]\n    frame.loc[frame.team==\"away\", 'teamcolor'] = team_colors[awayteam]\n    frame.loc[frame.team==\"home\", 'teamcolor2'] = team_colors2[hometeam]\n    frame.loc[frame.team==\"away\", 'teamcolor2'] = team_colors2[awayteam]\n    frame.loc[frame.team==\"football\", 'teamcolor'] = 'brown'\n    frame.loc[frame.team==\"football\", 'teamcolor2'] = 'white'\n\n    frame['jerseryNumberStr'] = frame['jerseyNumber'].astype('str')\n    frame.loc[frame.team==\"football\", 'playerweight'] = 40\n\n    playernames = frame.index.values\n    dictOnePlay = frame.to_dict('dict')\n\n    minY = 120\n    for player in playernames:\n\n        PlayerId = dictOnePlay['nflId'][player]\n        defenderId = dictOnePlay['defenderId'][player]\n\n        DisplayName = dictOnePlay['displayName'][player]\n        Position = dictOnePlay['position'][player]\n\n        CP = dictOnePlay['cp'][player]\n        CPOE = dictOnePlay['cpoe'][player]\n        epa = test_df.loc[(test_df.playid==int(playID)) & (test_df.name==DisplayName)][['epa', 'aycp']].to_numpy()\n        EPA = np.nan\n        if (epa.shape[0] > 0):\n            EPA = epa[0, 0]\n            AYCP = epa[0, 1]\n            CPOA = CP - AYCP\n\n        PlayerWeight = PLAYERS[['weight']].loc[PLAYERS.nflId==PlayerId].to_numpy()\n        if PlayerWeight.shape[0] > 0:\n            PlayerWeight = float(PlayerWeight[0,0])*1.6\n        else:\n            PlayerWeight = 40\n\n        teamcolor = dictOnePlay['teamcolor'][player]\n        teamcolor2 = dictOnePlay['teamcolor2'][player]\n\n        if DisplayName != \"Football\":\n            JerseyNumber = int(dictOnePlay['jerseyNumber'][player])\n\n        S = dictOnePlay['s'][player]\n\n        Y = dictOnePlay['x'][player]\n        X = (-1 * dictOnePlay['y'][player]) + (160/3.0)\n\n        if Position == \"QB\":\n            if Y - LOS > 0 or Y - LOS < -10:\n                LOS = 120 - LOS\n                #print(\"LOS\", LOS)\n\n        Orientation = 90 - dictOnePlay['o'][player]\n        Dir = dictOnePlay['dir'][player] - 90\n\n        # Text Color picker\n        RGB = ImageColor.getrgb(teamcolor)\n        textColor = 'white'\n        if (RGB[0]*0.299 + RGB[1]*0.587 + RGB[2]*0.114) > 150:\n            textColor = 'black'\n\n        if frame['targetedReceiver'][player] == 1:\n            teamcolor = 'red'\n            textColor = 'yellow'\n            \n        zorder = 12\n        alpha=0.8\n        #print(DisplayName)\n        if DisplayName == \"Football\":\n            zorder = 14\n            alpha = 0.6\n\n        # Plot Player\n        ax.scatter(X, Y, s=(PlayerWeight*1.5), alpha=0.9, color=teamcolor, edgecolors=teamcolor2, linewidths=1.8, zorder=zorder)\n        if DisplayName != \"Football\":\n            ax.annotate(str(JerseyNumber), # this is the text\n                                     (X, Y), # this is the point to label\n                                     textcoords=\"offset points\", # how to position the text\n                                     xytext=(0,0), # distance from text to points (x,y)\n                                     verticalalignment='center', horizontalalignment='center',\n                                     ha='center',\n                                     va='center',\n                                     fontsize=12,\n                                     color=textColor,\n                                     alpha=0.99,\n                                     weight='bold',\n                                     rotation=Orientation,\n                                     zorder=13) # horizontal alignment can be left, right or center\n        if str(CP) != \"nan\":\n            CP = np.round(CP, 2)\n            A = np.clip(CPOA*2+0.5, 0, 1)\n            grade_color = rgb2hex(int(255*A), 0, int(255*(1.0-A)))\n            if np.isnan(EPA) == 0 and CPOE == -1:\n                EPAtext =  \"EPA: \" + str(np.round(EPA, 2))\n                ax.annotate(EPAtext,\n                            (X, Y),\n                            textcoords=\"offset points\",\n                            xytext=(0,32),\n                            ha='center',\n                            va='bottom',\n                            fontsize=14,\n                            color='black',\n                            zorder=13)\n            if np.isnan(EPA) == 0 and CPOE != -1:\n                CPOEtext =  \"EPA: \" + str(np.round(EPA, 2)) + \"\\nCPOE: \" + str(np.round(CPOE, 2))\n                ax.annotate(CPOEtext, # this is the text\n                                     (X, Y), # this is the point to label\n                                     textcoords=\"offset points\", # how to position the text\n                                     xytext=(0,32), # distance from text to points (x,y)\n                                     ha='center',\n                                     va='bottom',\n                                     fontsize=14,\n                                     color='black',\n                                     zorder=13) # horizontal alignment can be left, right or center\n            if CPOA <= -0.2:\n                CP = \"CPOA: \" + str(np.round(CPOA, 2)) + ' ' + u'â˜…'\n            else:\n                CP = \"CPOA: \" + str(np.round(CPOA, 2))   \n            ax.annotate(CP, # this is the text\n                                     (X, Y), # this is the point to label\n                                     textcoords=\"offset points\", # how to position the text\n                                     xytext=(0,22), # distance from text to points (x,y)\n                                     ha='center',\n                                     va='center',\n                                     fontsize=14,\n                                     weight=\"bold\",\n                                     color=grade_color,\n                                     zorder=13) # horizontal alignment can be left, right or center\n        if str(defenderId) != \"nan\":\n            yyy = frame['x'].loc[frame.nflId==defenderId]\n            xxx = frame['y'].loc[frame.nflId==defenderId]\n            yyy = float(yyy)\n            xxx = float(xxx)\n            ystop = yyy - Y\n            xstop = ((-1 * xxx)  + (160/3.0)) - X\n            #print(X, Y, xstop, ystop)\n            plt.arrow(X, Y, xstop, ystop, head_width=0.2, width=0.02, alpha=0.5, color='red')\n\n        if Y < minY:\n            minY = Y\n\n        # Plot Speed and direction arrow\n        xstop = np.sin(Dir* np.pi/180) * S\n        ystop = np.cos(Dir* np.pi/180) * S\n        plt.arrow(X, Y, xstop, ystop, head_width=0.6, width=0.25, alpha=0.25, color=team_colors['NYG'])\n\n    #minY = int(minY / 5) * 5\n    minY = minY - 5\n    maxY = minY + 40\n    #print(minY)\n        \n    create_field(minY, maxY, ax, LOS, YardsToGo)\n    #TITLE = str(playID) + ' ' + str(PLAYS[['playDescription']].loc[PLAYS.uniquePlayId==int(playID)].to_numpy()[0])\n    #TITLE = str(playID)\n    #plt.title(TITLE, size=20)\n    \n    plt.gca().set_aspect(1)\n    plt.xlim(0, 160/3.0)\n    plt.ylim(minY, maxY)\n    #plt.ylim(0, 120)\n    #plt.tight_layout()\n    plt.text(26, minY + 1, str(PLAYS[['playDescription']].loc[PLAYS.uniquePlayId==int(playID)].to_numpy()[0]), size = 12, ha='center')\n    plt.text(1, maxY - 2, str(playID), color='white', size = 12)\n    \n    plt.show()\n    \n\n\nPATH_PLAYERS = '/kaggle/input/nfl-big-data-bowl-2021/players.csv'\nPLAYERSpd = pd.read_csv(PATH_PLAYERS)\n\nPATH_GAMES = '/kaggle/input/nfl-big-data-bowl-2021/games.csv'\nGAMES = pd.read_csv(PATH_GAMES)\n\nPATH_PLAYS = '/kaggle/input/extractfeatures/PLAYS-targetData.csv'\nPLAYS = pd.read_csv(PATH_PLAYS)\n\nPATH_TRACKING = '/kaggle/input/testmodel/TRACKING-tminus5-targetData-with-CP-CPOE.csv'\nTRACKING = pd.read_csv(PATH_TRACKING)\n\nPATH_TESTDF = '/kaggle/input/testmodel/test_df.csv'\ntest_df = pd.read_csv(PATH_TESTDF)\n\ntest_df = fix_positions(test_df)\n\nPlayers, average_grades, average_grades_dict = season_grades(test_df)\nCoverage_sacks = coverage_sacks(test_df)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ðŸˆ Comprehensive Pass Coverage Grading ðŸˆ"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"playID = '20181125023507'\nplot_single(GAMES, TRACKING, PLAYERSpd, PLAYS, test_df, playID, Coverage_sacks)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Introduction\nMy goal was to create a automatic and comprehensive method to grade pass coverage for individual pass defenders.  A comprehensive grade should encompass most, if not all, aspects of a pass defender's job.  This includes how well the defender covers before the pass is thrown (coverage skills), how well the defender plays when the ball is in the air (ball skills), forcing turnovers, and limiting yards after the catch.  A method which can objectively, automatically, and comprehensively grade pass defenders in this way would be very useful in evaluating the overall effectiveness of pass defenders.  \n\n## Approach\nI chose to approach this problem by modeling completion probability (CP).  I strategically chose to look at only one moment during the play - half of a second before the QB releases the pass, or is sacked.  I chose this particular moment because the QB still has the ball, and the pass defenders are still covering their assignment, as opposed to moving towards the intended receiver.  Therefore, we can compute a completion probability for all defenders in primary coverage at this moment during the play. \n\n**Coverage Skills -> Completion Probability Over Average (CPOA)**\n\nOne minor issue with using CP as a proxy for coverage is that the CP models are highly dependent on air yards.  We know that the further the distance the ball travels down field, generally the lower the completion probability.  Therefore, defenders that are defending deeper down the field will automatically have lower CP.  In order to account for this, I trained a second CP model using only the X and Y distance between the passer and receiver as input features.  I call this model air yard completion probablity (AYCP).  The difference between CP and AYCP produces a measure that accounts for the depth of the receiver.  I call this completion ***probability*** over average (CPOA).  CPOA in effect measures how well a defender is covering his assignment relative to other defenders at a similar depth. The values typically range from -0.3 to +0.3, where lower is better.\n\n**Ball Skills -> Completion Percentage Over Expectation (CPOE)**\n\nThe same CP model can also be utilized to measure \"ball skills\".  I use this term to refer to what the defender does between the time the ball is thrown, and the arrival of the pass to the receiver.  If a defender is targeted, how quickly does he close in on the intended receiver to break up the pass and prevent the completion?  We can create a proxy for this as well, by using the aforementioned completion percentage over expectation (CPOE).  This is simply the difference between the binary outcome of the play, and the completion probability.\n\n**Context -> Expected Points Added (EPA)**\n\nAnd finally, I incorporate expected points added (EPA).  EPA accounts for situational importance, penalties, forcing turnovers, and tackling after the catch.  It is very useful because it gives context to a play, because we know that not all plays are created equal (6 yards on 3rd and 15 is not the same as 6 gards on 3rd and 2). EPA is independent of the CP model and provided in the BDB data. \n\n**Final Grade -> Fusion of CPOA, CPOE, EPA**\n\nTo compute one final comprehensive grade, CPOA, CPOE, and EPA are normalized, averaged, scaled to fit a 0 - 1 grading system.  \n\n## Data Processing\n1. Determine the intended receiver.  For most plays this information was extracted from the play description.  On plays resulting in a sack, and in rare instances of incompletions, the description does not have an intended receiver.  For these plays CP can still be computed, but CPOE cannot.\n2. Assign a generic route for receivers on sack plays.  The data does not provide route information on plays that ended in a sack.  Offensive skill players that were a minimum distance downfield, or moving at a mininum speed were assigned a generic route.  This allowed me to incoroporate plays resulting in a sack into the grading. Intentional grounding was also treated as a sack.\n3. Assign a primary defender to each player running a route.  In order to train a CP model that measures how well a coverage defender is performing, we must first assign coverage responsibility.  The defender assignment was done using an average of the current distance between receiver and defender (tail of the arrows in figures), and the projected distance (head of the arrows in the figures). \n4. Account for penalties.  A defender can play good coverage, prevent an incompletion, and the play can still result in a positive EPA if there is a roughing the passer penalty.  In such situations, I do not count the EPA against the pass defender.  I took such penalty scenarios into account.  I did this by parsing the play descriptions.\n\n## Feature Extraction\nThe features used in this work were inspired by the winning 2020 BDB solution.  For each receiver running a route, I compute the following features:\n* X position, Y position, X and Y speed components of the route runner\n* X position, Y position, X and Y speed components of the defender\n* Relative X and Y between route runner and defender\n* Relative X and Y speed components between route runner and defender\n* Relative X and Y between route runner and quarterback\n* Distance between defender and sideline\n* One hot features indicating route runner's position (WR, TE, RB, FB)\n\nThe features were normalized to be on a similar scale.  For each route runner, I compute 18 features for the 3 nearest defenders to each potential receiver, creating a 3 x 18 feature matrix. \n\nWhy three defenders? Not all defenders on the field will influence the CP of a given route runner. Some defenders are covering a different receiver on the opposite side of the field, or even rushing the passer.  However, there are many instances where receivers are double covered, or the cornerback has safety help over the top.  In these scenarios, the secondary and possibly third defender can make an impact on the CP.  This is the reason for modeling the 3 nearest defenders, but not including all 11 defenders on the field\n\n## Completion Probability Model\nThe core of this work revolves around the completion probability model, since it's used to compute both CPOA and CPOE. The model I designed was a neural network with time distributed dense layers. Although I use *time* distributed layers, there actually is no time component. The fully connected dense layers are distributed across the three nearest defenders. This in effect mimics one dimensional convolutional layers, which were also used by the winner of BDB 2020.  Below are more details about the training of the model.\n\n* 10-fold cross validation for training models (So CPs are averaged across 10 models)\n* Dropout layers to prevent over-fitting and carefully monitored the loss\n* Batch normalization after each hidden layer\n* Sigmoid activations\n* Binary cross entropy loss\n* Adam Optimizer\n* Trained each fold for 50 epochs\n* Learning rate 0.01\n\n![Architecture](https://i.imgur.com/94x6Fk9.png)\n\n**Figure 2** : Basic model architecture.  Excluding batch normalization, dropout and activation layers for sake of simplicity\n\n## Analysis\nIn order to better visualize the method I created plots.  Although I can only show a few examples, my code will automatically generate these figures for any play in this dataset.  \n* The thin red lines between bubbles link the primary defender to receiver\n* The arrows show the magnitude and direction of player speed\n* The size of the bubble is proportional to player weight, so TEs and LBs will generally appear as bigger circles\n* The number inside each bubble corresponds to the player's jersey number.  Rotation corresponds to the orientation\n* The bubbles are color coded by team. But, the intended receiver is always red\n* The Line of scrimmage is blue and first down line is yellow\n* The numbers above the defenders are what each defender is credited on a given play in terms of CPOA, CPOE and EPA\n* CPOA is color coded. Red -> bad coverage.  Blue -> good coverage.  I plot a \"â˜†â€‹\" when a defender has a CPOA < -0.2.\n\n "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"playID = '20181223064098' # Jameis to Evans\nplot_single(GAMES, TRACKING, PLAYERSpd, PLAYS, test_df, playID, Coverage_sacks)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Figure 3** : Example of a blown coverage.  #24 of the Cowboys lets #13 of the Bucs get open in the back of the endzone resulting in an easy touchdown.  The rest of the defenders in coverage did a good job, and it is reflected in their CPOA grade on this play.  #24 is also credited for the EPA since his assignment was targeted."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"playID = '20181104022215' # Cam is sacked due to good coverage\nplot_single(GAMES, TRACKING, PLAYERSpd, PLAYS, test_df, playID, Coverage_sacks)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Figure 4** : Example of a coverage sack.  All of the receivers  on the field are tightly covered.  The quarterback has nowhere to throw the ball, and gets sacked for a loss of 9 yards. Defenders with expectional coverage on a play resulting in a sack are given credit for EPA, but it is clipped at -2.0"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\nfrom plotly.colors import n_colors\n\nCB = average_grades.loc[(average_grades.incoverage >= 300) & (average_grades.aycp < 0.59)]\ncriteria = ((CB.position == \"CB\"))\nCB = CB.loc[criteria][['cpoa', 'cpoa_targ', 'cpoe', 'epa', 'lockdown', 'blown', 'overall_grade']]\n#print(CB)\n\nplayernames = CB.index.values\nnames = []\ncolors2 = []\nfor p in playernames:\n    id, name = p\n    name = str(name)\n    name = name.replace(\"Robey-Coleman\", \"Robey-Cole\")\n    name = name.replace(\"Boddy-Calhoun\", \"Boddy-Calh\")\n    names.append(name)\n    if name == \"Stephon Gilmore\" or name == \"Xavien Howard\" or name == \"Byron Jones\" or name == \"Kyle Fuller\" or name == \"Desmond King\":\n        colors2.append('yellow')\n    elif name == \"Patrick Peterson\" or name == \"Trae Waynes\" or name == \"James Bradberry\" or name == \"Jalen Ramsey\" or name == \"Darius Slay\" or name == \"Tre'Davious White\" or name == \"Marlon Humphrey\":\n        colors2.append('lime')\n    else:\n        colors2.append('black')\n\n\ncolors = n_colors('rgb(108, 165, 212)', 'rgb(182, 96, 96)', 20, colortype='rgb')\na = CB[['cpoa_targ']].to_numpy().flatten()\nb = CB[['cpoe']].to_numpy().flatten()\nc = CB[['epa']].to_numpy().flatten()\nd = CB[['overall_grade']].to_numpy().flatten()\nanorm = ((a - np.min(a)) / (np.max(a) - np.min(a)) * 19)\nbnorm = ((b - np.min(b)) / (np.max(b) - np.min(b)) * 19)\ncnorm = ((c - np.min(c)) / (np.max(c) - np.min(c)) * 19)\ndnorm = ((d - np.min(d)) / (np.max(d) - np.min(d)) * 19)\nrank = np.arange(1, len(anorm)+1, 1)\nanorm = np.array(anorm, dtype='int')\nbnorm = np.array(bnorm, dtype='int')\ncnorm = np.array(cnorm, dtype='int')\ndnorm = 19-np.array(dnorm, dtype='int')\n\n\nfig = go.Figure(data=[go.Table(\n  columnwidth = [5,20],\n  header=dict(\n    values=['<b>Rank</b>', '<b>Player</b>', '<b>Average CPOA</b>', '<b>Average CPOE</b>', '<b>Average EPA</b>', '<b>Grade</b>'],\n    line_color='LightSteelBlue', fill_color='LightSteelBlue',\n    align='center',font=dict(color='black', size=12)\n  ),\n  cells=dict(\n    values=[rank, names, np.round(a,3), np.round(b,3), np.round(c,3), np.round(d,3)],\n    fill_color=[np.array(colors)[dnorm], np.array(colors)[dnorm], np.array(colors)[anorm], np.array(colors)[bnorm], np.array(colors)[cnorm], np.array(colors)[dnorm]],\n    line_color=[np.array(colors)[dnorm], np.array(colors)[dnorm], np.array(colors)[anorm], np.array(colors)[bnorm], np.array(colors)[cnorm], np.array(colors)[dnorm]],\n    align='center', font=dict(color=['black', colors2, 'black', 'black', 'black', 'black'], size=12)\n    ))\n])\n\nfig.update_layout(\n    autosize=False,\n    width=800,\n    height=1200,\n    margin=dict(\n        l=20,\n        r=20,\n        b=20,\n        t=50,\n        pad=20\n    ),\n    paper_bgcolor=\"LightSteelBlue\",\n)\n\nfig.update_layout(\n    title={\n        'text': \"Top Cornerbacks of 2018\",\n        'yanchor': 'top',\n        'x' : 0.5,\n        'y' : 0.99},\n    titlefont={\n        'size': 32,\n        'color' : 'black'\n    })\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Figure 5** : Comprehensive grades for cornerbacks in 2018.  Minimum 300 snaps in coverage as primary defender.\n\n[AP All Pro selections](https://apnews.com/article/2820450002) are highlighted in yellow.  2 of the top 4 CBs using this grading method were All Pro players (Gilmore, Howard).  I consider this evidence that this method is a good and comprehensive approach to grading cornerbacks.\n\n[Highest paid cornerbacks](https://overthecap.com/position/cornerback/) are highlighted in green. 4 of the top 6 CBs using this grading method are 4 of the top 10 highest paid CBs (Humphrey, Howard, Slay, White).\n\nHow about the other guys in the top 10?  Well, it is possible that they just had an isolated good year.  I did some research and found evidence that both [5. Steven Nelson](https://twitter.com/PFF_Chiefs/status/1105613988967170048/photo/1) and [7. Coty Sensabaugh](https://twitter.com/PFF/status/1112388084522459136) were good cornerbacks in 2018 by some  measure."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"CB = average_grades.loc[(average_grades.incoverage >= 200) & (average_grades.aycp >= 0.59)]\ncriteria = ((CB.position == \"CB\"))\nCB = CB.loc[criteria][['cpoa', 'cpoa_targ', 'cpoe', 'epa', 'lockdown', 'blown', 'overall_grade']]\n\nplayernames = CB.index.values\nnames = []\ncolors2 = []\nfor p in playernames:\n    id, name = p\n    name = str(name)\n    name = name.replace(\"Robey-Coleman\", \"Robey-Cole\")\n    name = name.replace(\"Boddy-Calhoun\", \"Boddy-Calh\")\n    names.append(name)\n    if name == \"Stephon Gilmore\" or name == \"Xavien Howard\" or name == \"Byron Jones\" or name == \"Kyle Fuller\" or name == \"Desmond King\":\n        colors2.append('yellow')\n    elif name == \"Trae Waynes\" or name == \"James Bradberry\" or name == \"Jalen Ramsey\" or name == \"Darius Slay\" or name == \"Patrick Peterson\" or name == \"Tre'Davious White\" or name == \"Marlon Humphrey\":\n        colors2.append('lime')\n    else:\n        colors2.append('black')\n\n\ncolors = n_colors('rgb(108, 165, 212)', 'rgb(182, 96, 96)', 20, colortype='rgb')\na = CB[['cpoa_targ']].to_numpy().flatten()\nb = CB[['cpoe']].to_numpy().flatten()\nc = CB[['epa']].to_numpy().flatten()\nd = CB[['overall_grade']].to_numpy().flatten()\nanorm = ((a - np.min(a)) / (np.max(a) - np.min(a)) * 19)\nbnorm = ((b - np.min(b)) / (np.max(b) - np.min(b)) * 19)\ncnorm = ((c - np.min(c)) / (np.max(c) - np.min(c)) * 19)\ndnorm = ((d - np.min(d)) / (np.max(d) - np.min(d)) * 19)\nrank = np.arange(1, len(anorm)+1, 1)\nanorm = np.array(anorm, dtype='int')\nbnorm = np.array(bnorm, dtype='int')\ncnorm = np.array(cnorm, dtype='int')\ndnorm = 19-np.array(dnorm, dtype='int')\n\n\nfig = go.Figure(data=[go.Table(\n  columnwidth = [5,20],\n  header=dict(\n    values=['<b>Rank</b>', '<b>Player</b>', '<b>Average CPOA</b>', '<b>Average CPOE</b>', '<b>Average EPA</b>', '<b>Grade</b>'],\n    line_color='LightSteelBlue', fill_color='LightSteelBlue',\n    align='center',font=dict(color='black', size=12)\n  ),\n  cells=dict(\n    values=[rank, names, np.round(a,3), np.round(b,3), np.round(c,3), np.round(d,3)],\n    fill_color=[np.array(colors)[dnorm], np.array(colors)[dnorm], np.array(colors)[anorm], np.array(colors)[bnorm], np.array(colors)[cnorm], np.array(colors)[dnorm]],\n    line_color=[np.array(colors)[dnorm], np.array(colors)[dnorm], np.array(colors)[anorm], np.array(colors)[bnorm], np.array(colors)[cnorm], np.array(colors)[dnorm]],\n    align='center', font=dict(color=['black', colors2, 'black', 'black', 'black', 'black'], size=12)\n    ))\n])\n\nfig.update_layout(\n    autosize=False,\n    width=800,\n    height=640,\n    margin=dict(\n        l=20,\n        r=20,\n        b=20,\n        t=50,\n        pad=20\n    ),\n    paper_bgcolor=\"LightSteelBlue\",\n)\n\nfig.update_layout(\n    title={\n        'text': \"Top Nickelbacks of 2018\",\n        'yanchor': 'top',\n        'x' : 0.5,\n        'y' : 0.99},\n    titlefont={\n        'size': 32,\n        'color' : 'black'\n    })\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Figure 6** : Comprehensive grades for nickelbacks in 2018.  Minimum 200 snaps in coverage as primary defender.  \n\nTo separate nickelbacks from cornerbacks I simply thresholded the average AYCP at 0.59 (determined emperically).  This method works because nickelbacks tend to play closer to the quarterback and line of scrimmage, therefore their AYCP is higher compared to outside corners.  \n\nDesmond King, who was third among nickelbacks in this grading system, was given AP All Pro honors for his great season for the Chargers in 2018"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"S = average_grades.loc[(average_grades.incoverage >= 100)]\ncriteria = ((S.position == \"S\") | (S.position == \"SS\") | (S.position == \"FS\") | (S.position == \"DB\"))\nS = S.loc[criteria][['cpoa', 'cpoa_targ', 'cpoe', 'epa', 'lockdown', 'blown', 'overall_grade']]\n\nplayernames = S.index.values\nnames = []\ncolors2 = []\nfor p in playernames:\n    id, name = p\n    names.append(name)\n    if name == \"Jamal Adams\" or name == \"Eddie Jackson\" or name == \"Derwin James\" or name == \"Harrison Smith\":\n        colors2.append('yellow')\n    else:\n        colors2.append('black')\n\ncolors = n_colors('rgb(108, 165, 212)', 'rgb(182, 96, 96)', 20, colortype='rgb')\na = S[['cpoa_targ']].to_numpy().flatten()\nb = S[['cpoe']].to_numpy().flatten()\nc = S[['epa']].to_numpy().flatten()\nd = S[['overall_grade']].to_numpy().flatten()\nanorm = ((a - np.min(a)) / (np.max(a) - np.min(a)) * 19)\nbnorm = ((b - np.min(b)) / (np.max(b) - np.min(b)) * 19)\ncnorm = ((c - np.min(c)) / (np.max(c) - np.min(c)) * 19)\ndnorm = ((d - np.min(d)) / (np.max(d) - np.min(d)) * 19)\nanorm = np.array(anorm, dtype='int')\nbnorm = np.array(bnorm, dtype='int')\ncnorm = np.array(cnorm, dtype='int')\ndnorm = 19-np.array(dnorm, dtype='int')\nrank = np.arange(1, len(anorm)+1, 1)\n\nfig = go.Figure(data=[go.Table(\n  columnwidth = [5,20],\n  header=dict(\n    values=['<b>Rank</b>', '<b>Player</b>', '<b>Average CPOA</b>', '<b>Average CPOE</b>', '<b>Average EPA</b>', '<b>Grade</b>'],\n    line_color=\"LightSteelBlue\", fill_color=\"LightSteelBlue\",\n    align='center',font=dict(color='black', size=12)\n  ),\n  cells=dict(\n    values=[rank, names, np.round(a,3), np.round(b,3), np.round(c,3), np.round(d,3)],\n    fill_color=[np.array(colors)[dnorm], np.array(colors)[dnorm], np.array(colors)[anorm], np.array(colors)[bnorm], np.array(colors)[cnorm], np.array(colors)[dnorm]],\n    line_color=[np.array(colors)[dnorm], np.array(colors)[dnorm], np.array(colors)[anorm], np.array(colors)[bnorm], np.array(colors)[cnorm], np.array(colors)[dnorm]],\n    align='center', font=dict(color=['black', colors2, 'black', 'black', 'black', 'black'], size=12)\n    ))\n])\n\nfig.update_layout(\n    autosize=False,\n    width=800,\n    height=1340,\n    margin=dict(\n        l=20,\n        r=20,\n        b=20,\n        t=50,\n        pad=20\n    ),\n    paper_bgcolor=\"LightSteelBlue\",\n)\n\nfig.update_layout(\n    title={\n        'text': \"Top Safeties of 2018\",\n        'yanchor': 'top',\n        'x' : 0.5,\n        'y' : 0.99},\n    titlefont={\n        'size': 32,\n        'color' : 'black'\n    })\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Figure 7** : Comprehensive grades for safeties in 2018.  Minimum 100 snaps in coverage as primary defender.  \n\nOnce again, 3 of the top 8 safeties using this grading method were AP All Pro selections.  Safeties are primary defenders in coverage far less often compared to cornerbacks, so I had to lower the mimimum snap threshold to 100.  This lower sample size makes this method a little less effective for grading safeties compared to grading cornerbacks."},{"metadata":{},"cell_type":"markdown","source":"## Final thoughts\nAs with any model, there is going to be some noise and variance.  However, any model that we use to measure player performance confirm our priors.  Using this grading method, most of the top graded defenders have a good reputation and are paid accordingly, and most of the All Pro players have high grades. This gives me confidence that this approach is viable for grading pass coverage.\n\nAlthough the purpose of this project was to grade defensive coverage, this same model can be applied to gain other interesting insight.  For example, it can be used to determine whether the QB is making the correct read, or how much risk he is willing to take.  We can also gain insight about how open receivers are getting in their routes.  However, these questions were beyond the scope of this project. Maybe this can be explored in future work.\n\n\n## Tools:\nPython | Pandas | Keras | Tensorflow | Matplotlib | Plotly\n\n"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}