{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Group 4 Indian Language Q&A (Tamil, Hindi)","metadata":{}},{"cell_type":"markdown","source":"With nearly 1.4 billion people, India is the second-most populated country in the world. Yet Indian languages, like Hindi and Tamil, are underrepresented on the web. Popular Natural Language Understanding (NLU) models perform worse with Indian languages compared to English, the effects of which lead to subpar experiences in downstream web applications for Indian users.","metadata":{}},{"cell_type":"markdown","source":"# Import packages","metadata":{}},{"cell_type":"code","source":"import os\nimport json\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nfrom termcolor import colored\n\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nimport transformers\nfrom transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline, TrainingArguments, Trainer, default_data_collator\n\nfrom datasets import Dataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-22T13:04:07.801849Z","iopub.execute_input":"2021-11-22T13:04:07.802292Z","iopub.status.idle":"2021-11-22T13:04:15.991096Z","shell.execute_reply.started":"2021-11-22T13:04:07.802187Z","shell.execute_reply":"2021-11-22T13:04:15.990405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls ../input/chaii-hindi-and-tamil-question-answering","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:04:22.440295Z","iopub.execute_input":"2021-11-22T13:04:22.441038Z","iopub.status.idle":"2021-11-22T13:04:23.115645Z","shell.execute_reply.started":"2021-11-22T13:04:22.440992Z","shell.execute_reply":"2021-11-22T13:04:23.11481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root = Path(\"../input/chaii-hindi-and-tamil-question-answering/\")\n\ntrain_df = pd.read_csv(root / \"train.csv\", encoding=\"utf8\")\ntest_df = pd.read_csv(root / \"test.csv\", encoding=\"utf8\")\nprint(\"Total training data: \", len(train_df))\nprint(\"Total test data: \", len(test_df))","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:04:36.485765Z","iopub.execute_input":"2021-11-22T13:04:36.486029Z","iopub.status.idle":"2021-11-22T13:04:36.884057Z","shell.execute_reply.started":"2021-11-22T13:04:36.485998Z","shell.execute_reply":"2021-11-22T13:04:36.883279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We remark that, given such a small amount of data for training (~1000 samples), having the right external data could be a key thing to improve the learning of models.","metadata":{}},{"cell_type":"markdown","source":"# Understanding the dataset","metadata":{}},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:04:45.326222Z","iopub.execute_input":"2021-11-22T13:04:45.327062Z","iopub.status.idle":"2021-11-22T13:04:45.356778Z","shell.execute_reply.started":"2021-11-22T13:04:45.327011Z","shell.execute_reply":"2021-11-22T13:04:45.356113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:04:48.762391Z","iopub.execute_input":"2021-11-22T13:04:48.762969Z","iopub.status.idle":"2021-11-22T13:04:48.77313Z","shell.execute_reply.started":"2021-11-22T13:04:48.762929Z","shell.execute_reply":"2021-11-22T13:04:48.77218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Therefore, For each ID in the test set, we must predict the string that best answers the provided question based on the context.","metadata":{}},{"cell_type":"code","source":"value_counts = train_df['language'].value_counts()\nlabels = value_counts.index.tolist()\nplt.pie(value_counts, labels = labels,autopct='%1.2f%%')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:04:52.592801Z","iopub.execute_input":"2021-11-22T13:04:52.593659Z","iopub.status.idle":"2021-11-22T13:04:52.708218Z","shell.execute_reply.started":"2021-11-22T13:04:52.593597Z","shell.execute_reply":"2021-11-22T13:04:52.70757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['answer_end'] = [row['answer_start'] + len(row['answer_text']) for index, row in train_df.iterrows()]\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:04:57.661295Z","iopub.execute_input":"2021-11-22T13:04:57.661981Z","iopub.status.idle":"2021-11-22T13:04:57.736788Z","shell.execute_reply.started":"2021-11-22T13:04:57.661944Z","shell.execute_reply":"2021-11-22T13:04:57.736093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploring Question and answers","metadata":{}},{"cell_type":"code","source":"len(train_df.question.unique())","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:05:03.662193Z","iopub.execute_input":"2021-11-22T13:05:03.662792Z","iopub.status.idle":"2021-11-22T13:05:03.669895Z","shell.execute_reply.started":"2021-11-22T13:05:03.662747Z","shell.execute_reply":"2021-11-22T13:05:03.669079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_df.context.unique())","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:05:09.747608Z","iopub.execute_input":"2021-11-22T13:05:09.747883Z","iopub.status.idle":"2021-11-22T13:05:09.860428Z","shell.execute_reply.started":"2021-11-22T13:05:09.747852Z","shell.execute_reply":"2021-11-22T13:05:09.859607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def color_answer(question):\n    answer_start, answer_end = question[\"answer_start\"], question[\"answer_end\"]\n    context = question[\"context\"]\n    return colored(context[:answer_start], \"white\") + \\\n    colored(context[answer_start:answer_end + 1],  'white', 'on_red') + \\\n    colored(context[answer_end + 1:], \"white\")","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:05:20.918356Z","iopub.execute_input":"2021-11-22T13:05:20.919092Z","iopub.status.idle":"2021-11-22T13:05:20.923789Z","shell.execute_reply.started":"2021-11-22T13:05:20.919055Z","shell.execute_reply":"2021-11-22T13:05:20.922999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tamil_df = train_df[train_df.language == 'tamil']\ntamil_df['con_len'] = [len(row['context']) for index,row in tamil_df.iterrows()]\nhindi_df = train_df[train_df.language == 'hindi']\nhindi_df['con_len'] = [len(row['context']) for index,row in hindi_df.iterrows()]\nprint(\"The context with minimum length in Tamil Language is:\",min(tamil_df.con_len))\nprint(\"The context with minimum length in Hindi Language is:\",min(hindi_df.con_len))","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:05:27.641099Z","iopub.execute_input":"2021-11-22T13:05:27.641881Z","iopub.status.idle":"2021-11-22T13:05:27.707724Z","shell.execute_reply.started":"2021-11-22T13:05:27.641829Z","shell.execute_reply":"2021-11-22T13:05:27.706082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tamil_df[tamil_df.con_len==446]","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:05:40.426302Z","iopub.execute_input":"2021-11-22T13:05:40.42699Z","iopub.status.idle":"2021-11-22T13:05:40.440928Z","shell.execute_reply.started":"2021-11-22T13:05:40.426952Z","shell.execute_reply":"2021-11-22T13:05:40.439946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numbers\ncount=0\nfor i in tamil_df['answer_text']:\n    if(i.isnumeric()):\n        count+=1\ncount\n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:11:39.920204Z","iopub.execute_input":"2021-11-22T13:11:39.920673Z","iopub.status.idle":"2021-11-22T13:11:39.927206Z","shell.execute_reply.started":"2021-11-22T13:11:39.920634Z","shell.execute_reply":"2021-11-22T13:11:39.92647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numbers\ncount=0\nfor i in hindi_df['answer_text']:\n    if(i.isnumeric()):\n        count+=1\ncount","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:11:56.928948Z","iopub.execute_input":"2021-11-22T13:11:56.929227Z","iopub.status.idle":"2021-11-22T13:11:56.94022Z","shell.execute_reply.started":"2021-11-22T13:11:56.929197Z","shell.execute_reply":"2021-11-22T13:11:56.939459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count=0\nfor i in tamil_df['answer_text']:\n    k=len(i.split(\" \"))\n    if(k==1):\n        count+=1\nprint(count)\n        ","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:14:33.330585Z","iopub.execute_input":"2021-11-22T13:14:33.331076Z","iopub.status.idle":"2021-11-22T13:14:33.339451Z","shell.execute_reply.started":"2021-11-22T13:14:33.331037Z","shell.execute_reply":"2021-11-22T13:14:33.338505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count=0\nfor i in hindi_df['answer_text']:\n    k=len(i.split(\" \"))\n    if(k==1):\n        count+=1\nprint(count)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:14:55.6313Z","iopub.execute_input":"2021-11-22T13:14:55.631908Z","iopub.status.idle":"2021-11-22T13:14:55.6377Z","shell.execute_reply.started":"2021-11-22T13:14:55.63187Z","shell.execute_reply":"2021-11-22T13:14:55.636908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tamil_df[tamil_df['answer_text']=='à®†à®®à®¾à®®à¯']","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:25:24.195153Z","iopub.execute_input":"2021-11-22T13:25:24.195424Z","iopub.status.idle":"2021-11-22T13:25:24.204783Z","shell.execute_reply.started":"2021-11-22T13:25:24.195382Z","shell.execute_reply":"2021-11-22T13:25:24.204115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tamil_df[tamil_df['answer_text']=='à®‡à®²à¯à®²à¯ˆ']","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:25:59.757102Z","iopub.execute_input":"2021-11-22T13:25:59.757544Z","iopub.status.idle":"2021-11-22T13:25:59.76646Z","shell.execute_reply.started":"2021-11-22T13:25:59.757502Z","shell.execute_reply":"2021-11-22T13:25:59.765781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hindi_df[hindi_df['answer_text']=='à¤¹à¤¾à¤‚']","metadata":{"execution":{"iopub.status.busy":"2021-11-22T14:28:06.491406Z","iopub.execute_input":"2021-11-22T14:28:06.492038Z","iopub.status.idle":"2021-11-22T14:28:06.505454Z","shell.execute_reply.started":"2021-11-22T14:28:06.492Z","shell.execute_reply":"2021-11-22T14:28:06.504451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hindi_df[hindi_df['answer_text']==\"à¤¨à¤¹à¥€à¤‚\"]","metadata":{"execution":{"iopub.status.busy":"2021-11-22T14:28:49.542029Z","iopub.execute_input":"2021-11-22T14:28:49.542307Z","iopub.status.idle":"2021-11-22T14:28:49.554931Z","shell.execute_reply.started":"2021-11-22T14:28:49.542275Z","shell.execute_reply":"2021-11-22T14:28:49.554055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hindi_df[hindi_df.con_len==176]","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:27:21.7793Z","iopub.execute_input":"2021-11-22T13:27:21.779794Z","iopub.status.idle":"2021-11-22T13:27:21.793199Z","shell.execute_reply.started":"2021-11-22T13:27:21.779754Z","shell.execute_reply":"2021-11-22T13:27:21.792457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_qa_pair = train_df.iloc[215]\nprint(sample_qa_pair[\"question\"])\nprint(\"Answer\", sample_qa_pair[\"answer_text\"])\nprint(\"Context:\")\nprint(color_answer(sample_qa_pair))","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:27:54.829926Z","iopub.execute_input":"2021-11-22T13:27:54.830183Z","iopub.status.idle":"2021-11-22T13:27:54.836924Z","shell.execute_reply.started":"2021-11-22T13:27:54.830152Z","shell.execute_reply":"2021-11-22T13:27:54.836138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_qa_pair = train_df.iloc[420]\nprint(sample_qa_pair[\"question\"])\nprint(\"Answer\", sample_qa_pair[\"answer_text\"])\nprint(\"Context:\")\nprint(color_answer(sample_qa_pair))","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:27:55.149134Z","iopub.execute_input":"2021-11-22T13:27:55.149539Z","iopub.status.idle":"2021-11-22T13:27:55.156833Z","shell.execute_reply.started":"2021-11-22T13:27:55.149503Z","shell.execute_reply":"2021-11-22T13:27:55.156117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Towards the XLM-Roberta model","metadata":{}},{"cell_type":"markdown","source":"Essentially, our goal is the question answering task, which is the task of extracting the answer to a question from a given context. Multilingual Transformer models pre-trained on SQUAD data are completely dominating the competition. Therefore, we look towards finetuning the XLM-Roberta model","metadata":{}},{"cell_type":"markdown","source":"> ## Tokenizer","metadata":{}},{"cell_type":"markdown","source":"Before we can feed those texts to our model, we need to preprocess them. This is done by a ðŸ¤— Transformers Tokenizer which will tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that model requires.","metadata":{}},{"cell_type":"code","source":"model_name = '../input/chaii-pretrained-models/models/deepset/xlm-roberta-large-squad2'\n\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_name)\n\nquestion, text = 'Why is model conversion important?', 'The option to convert models between FARM and transformers gives freedom to the user and let people easily switch between frameworks.'\nencoding = tokenizer(question, text, return_tensors='pt')\nprint(encoding)\n\ninput_ids = encoding['input_ids']\nattention_mask = encoding['attention_mask']\n\nstart_scores, end_scores = model(input_ids, attention_mask=attention_mask, output_attentions=False)[:2] \nall_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\nanswer = ' '.join(all_tokens[np.argmax(start_scores.detach()): np.argmax(end_scores.detach())+1])\nanswer = tokenizer.convert_tokens_to_ids(answer.split())\nanswer = tokenizer.decode(answer)\nprint(\"\\nAnswer from model: \" + answer)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:27:56.798014Z","iopub.execute_input":"2021-11-22T13:27:56.798596Z","iopub.status.idle":"2021-11-22T13:28:33.80293Z","shell.execute_reply.started":"2021-11-22T13:27:56.798551Z","shell.execute_reply":"2021-11-22T13:28:33.801855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['num_tokens_context'] = train_df['context'].apply(lambda t: len(tokenizer(t)['input_ids']))","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:28:33.804815Z","iopub.execute_input":"2021-11-22T13:28:33.805089Z","iopub.status.idle":"2021-11-22T13:29:08.026314Z","shell.execute_reply.started":"2021-11-22T13:28:33.80505Z","shell.execute_reply":"2021-11-22T13:29:08.025392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We've been warned that the context length exceeds the maxium token length of the model, so we have to divide it before processing.","metadata":{}},{"cell_type":"code","source":"train_df['num_tokens_context'].hist();","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:29:08.027779Z","iopub.execute_input":"2021-11-22T13:29:08.028181Z","iopub.status.idle":"2021-11-22T13:29:08.331932Z","shell.execute_reply.started":"2021-11-22T13:29:08.028132Z","shell.execute_reply":"2021-11-22T13:29:08.331252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ## Preparing the dataset","metadata":{}},{"cell_type":"code","source":"\nmax_length = 384 \ndoc_stride = 128 \npad_on_right = tokenizer.padding_side == \"right\" ","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:29:08.333986Z","iopub.execute_input":"2021-11-22T13:29:08.334264Z","iopub.status.idle":"2021-11-22T13:29:08.338614Z","shell.execute_reply.started":"2021-11-22T13:29:08.334221Z","shell.execute_reply":"2021-11-22T13:29:08.337846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ndef prepare_train_features(examples):\n    \n    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n    tokenized_examples = tokenizer(\n        examples[\"question\" if pad_on_right else \"context\"],\n        examples[\"context\" if pad_on_right else \"question\"],\n        truncation=\"only_second\" if pad_on_right else \"only_first\",\n        max_length=max_length,\n        stride=doc_stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n    tokenized_examples[\"start_positions\"] = []\n    tokenized_examples[\"end_positions\"] = []\n    \n    for i, offsets in enumerate(offset_mapping):\n        input_ids = tokenized_examples[\"input_ids\"][i]\n        cls_index = input_ids.index(tokenizer.cls_token_id)\n        sequence_ids = tokenized_examples.sequence_ids(i)\n        sample_index = sample_mapping[i]\n        answers = examples[\"answers\"][sample_index]\n        if len(answers[\"answer_start\"]) == 0:\n            tokenized_examples[\"start_positions\"].append(cls_index)\n            tokenized_examples[\"end_positions\"].append(cls_index)\n        else:\n            start_char = answers[\"answer_start\"][0]\n            end_char = start_char + len(answers[\"text\"][0])\n            token_start_index = 0\n            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n                token_start_index += 1\n            token_end_index = len(input_ids) - 1\n            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n                token_end_index -= 1\n            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n                tokenized_examples[\"start_positions\"].append(cls_index)\n                tokenized_examples[\"end_positions\"].append(cls_index)\n            else:\n                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n                    token_start_index += 1\n                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n                while offsets[token_end_index][1] >= end_char:\n                    token_end_index -= 1\n                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n\n    return tokenized_examples","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:29:08.340111Z","iopub.execute_input":"2021-11-22T13:29:08.340431Z","iopub.status.idle":"2021-11-22T13:29:08.640634Z","shell.execute_reply.started":"2021-11-22T13:29:08.340383Z","shell.execute_reply":"2021-11-22T13:29:08.639878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Helper function\ndef convert_answers(r):\n    start = r[0]\n    text = r[1]\n    return {\n        'answer_start': [start],\n        'text': [text]\n    }\n\ntrain_df=train_df.sample(frac=1,random_state=42)     #shuffling the dataset\ntrain_df['answers'] = train_df[['answer_start', 'answer_text']].apply(convert_answers, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:29:08.641884Z","iopub.execute_input":"2021-11-22T13:29:08.642168Z","iopub.status.idle":"2021-11-22T13:29:08.674042Z","shell.execute_reply.started":"2021-11-22T13:29:08.642131Z","shell.execute_reply":"2021-11-22T13:29:08.673338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Splitting to train and validation sets\ndf_train = train_df[:-64].reset_index(drop=True)\ndf_valid = train_df[-64:].reset_index(drop=True)\n\n#Making Dataset objects for processing\ntrain_dataset = Dataset.from_pandas(df_train)\nvalid_dataset = Dataset.from_pandas(df_valid)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:29:08.675028Z","iopub.execute_input":"2021-11-22T13:29:08.675277Z","iopub.status.idle":"2021-11-22T13:29:08.77524Z","shell.execute_reply.started":"2021-11-22T13:29:08.675231Z","shell.execute_reply":"2021-11-22T13:29:08.774431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:29:08.776558Z","iopub.execute_input":"2021-11-22T13:29:08.776924Z","iopub.status.idle":"2021-11-22T13:29:08.792303Z","shell.execute_reply.started":"2021-11-22T13:29:08.776886Z","shell.execute_reply":"2021-11-22T13:29:08.791541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We use the map method to apply the prepare_train_features, which we had earlier defined, on all the sentences. ","metadata":{}},{"cell_type":"code","source":"tokenized_train_ds = train_dataset.map(prepare_train_features, batched=True, remove_columns=train_dataset.column_names)\ntokenized_valid_ds = valid_dataset.map(prepare_train_features, batched=True, remove_columns=train_dataset.column_names)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:29:08.79399Z","iopub.execute_input":"2021-11-22T13:29:08.794508Z","iopub.status.idle":"2021-11-22T13:29:47.807315Z","shell.execute_reply.started":"2021-11-22T13:29:08.794468Z","shell.execute_reply":"2021-11-22T13:29:47.806644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_train_ds","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:29:47.809888Z","iopub.execute_input":"2021-11-22T13:29:47.810235Z","iopub.status.idle":"2021-11-22T13:29:47.818906Z","shell.execute_reply.started":"2021-11-22T13:29:47.810196Z","shell.execute_reply":"2021-11-22T13:29:47.818111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is a Tokenized dataset containing features\n\n* attention_mask\n* end_positions\n* input_ids\n* start_positions\n\nThat concludes data preparation","metadata":{}},{"cell_type":"markdown","source":"> ## Preparing the model","metadata":{}},{"cell_type":"code","source":"#Instantiating model\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:29:47.820066Z","iopub.execute_input":"2021-11-22T13:29:47.820851Z","iopub.status.idle":"2021-11-22T13:30:01.18865Z","shell.execute_reply.started":"2021-11-22T13:29:47.820813Z","shell.execute_reply":"2021-11-22T13:30:01.187882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%env WANDB_DISABLED=True","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:30:01.189968Z","iopub.execute_input":"2021-11-22T13:30:01.19022Z","iopub.status.idle":"2021-11-22T13:30:01.196048Z","shell.execute_reply.started":"2021-11-22T13:30:01.190184Z","shell.execute_reply":"2021-11-22T13:30:01.19506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size=4\n\nargs = TrainingArguments(\n    f\"chaii-qa\",\n    evaluation_strategy = \"epoch\",\n    save_strategy = \"epoch\",\n    learning_rate=3e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=1,\n    weight_decay=0.01,\n    warmup_ratio=0.1,\n    gradient_accumulation_steps=8,)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:30:01.197365Z","iopub.execute_input":"2021-11-22T13:30:01.197821Z","iopub.status.idle":"2021-11-22T13:30:01.262262Z","shell.execute_reply.started":"2021-11-22T13:30:01.19775Z","shell.execute_reply":"2021-11-22T13:30:01.261452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer=Trainer(model,\n                args,\n                train_dataset=tokenized_train_ds,\n                eval_dataset=tokenized_valid_ds,\n                data_collator=default_data_collator, # Will batch processed examples together\n                tokenizer=tokenizer,\n               )","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:30:01.263507Z","iopub.execute_input":"2021-11-22T13:30:01.263751Z","iopub.status.idle":"2021-11-22T13:30:08.305825Z","shell.execute_reply.started":"2021-11-22T13:30:01.263717Z","shell.execute_reply":"2021-11-22T13:30:08.305032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()\ntrainer.save_model(\"chaii_xlm\") ","metadata":{"execution":{"iopub.status.busy":"2021-11-22T13:30:08.307243Z","iopub.execute_input":"2021-11-22T13:30:08.307533Z","iopub.status.idle":"2021-11-22T14:03:28.032448Z","shell.execute_reply.started":"2021-11-22T13:30:08.307497Z","shell.execute_reply":"2021-11-22T14:03:28.031594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_validation_features(examples):\n    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n    tokenized_examples = tokenizer(\n        examples[\"question\" if pad_on_right else \"context\"],\n        examples[\"context\" if pad_on_right else \"question\"],\n        truncation=\"only_second\" if pad_on_right else \"only_first\",\n        max_length=max_length,\n        stride=doc_stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n    tokenized_examples[\"example_id\"] = []\n\n    for i in range(len(tokenized_examples[\"input_ids\"])):\n        sequence_ids = tokenized_examples.sequence_ids(i)\n        context_index = 1 if pad_on_right else 0\n        sample_index = sample_mapping[i]\n        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n        tokenized_examples[\"offset_mapping\"][i] = [\n            (o if sequence_ids[k] == context_index else None)\n            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n        ]\n\n    return tokenized_examples","metadata":{"execution":{"iopub.status.busy":"2021-11-22T14:09:51.003458Z","iopub.execute_input":"2021-11-22T14:09:51.003821Z","iopub.status.idle":"2021-11-22T14:09:51.020892Z","shell.execute_reply.started":"2021-11-22T14:09:51.00378Z","shell.execute_reply":"2021-11-22T14:09:51.020133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_features = valid_dataset.map(\n    prepare_validation_features,\n    batched=True,\n    remove_columns=train_dataset.column_names\n)\nvalid_dataset","metadata":{"execution":{"iopub.status.busy":"2021-11-22T14:10:43.221395Z","iopub.execute_input":"2021-11-22T14:10:43.222155Z","iopub.status.idle":"2021-11-22T14:10:47.781078Z","shell.execute_reply.started":"2021-11-22T14:10:43.222113Z","shell.execute_reply":"2021-11-22T14:10:47.7802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_feats_small = validation_features.map(lambda example: example, remove_columns=['example_id', 'offset_mapping'])\nvalid_feats_small\n","metadata":{"execution":{"iopub.status.busy":"2021-11-22T14:11:28.901376Z","iopub.execute_input":"2021-11-22T14:11:28.901909Z","iopub.status.idle":"2021-11-22T14:11:30.69016Z","shell.execute_reply.started":"2021-11-22T14:11:28.901869Z","shell.execute_reply":"2021-11-22T14:11:30.68948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_predictions = trainer.predict(valid_feats_small)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T14:11:52.657785Z","iopub.execute_input":"2021-11-22T14:11:52.658045Z","iopub.status.idle":"2021-11-22T14:12:28.26083Z","shell.execute_reply.started":"2021-11-22T14:11:52.658014Z","shell.execute_reply":"2021-11-22T14:12:28.260123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_answer_length = 30\n\nimport collections\n\nexamples = valid_dataset\nfeatures = validation_features\n\nexample_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\nfeatures_per_example = collections.defaultdict(list)\nfor i, feature in enumerate(features):\n    features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T14:12:57.95997Z","iopub.execute_input":"2021-11-22T14:12:57.960309Z","iopub.status.idle":"2021-11-22T14:12:59.417104Z","shell.execute_reply.started":"2021-11-22T14:12:57.96027Z","shell.execute_reply":"2021-11-22T14:12:59.4164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Postprocessing","metadata":{}},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\ndef postprocess_qa_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 30):\n    all_start_logits, all_end_logits = raw_predictions\n    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n    features_per_example = collections.defaultdict(list)\n    for i, feature in enumerate(features):\n        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n    predictions = collections.OrderedDict()\n\n    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n\n    for example_index, example in enumerate(tqdm(examples)):\n        feature_indices = features_per_example[example_index]\n\n        min_null_score = None \n        valid_answers = []\n        \n        context = example[\"context\"]\n        for feature_index in feature_indices:\n            start_logits = all_start_logits[feature_index]\n            end_logits = all_end_logits[feature_index]\n            offset_mapping = features[feature_index][\"offset_mapping\"]\n            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n            if min_null_score is None or min_null_score < feature_null_score:\n                min_null_score = feature_null_score\n            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n            for start_index in start_indexes:\n                for end_index in end_indexes:\n                    if (\n                        start_index >= len(offset_mapping)\n                        or end_index >= len(offset_mapping)\n                        or offset_mapping[start_index] is None\n                        or offset_mapping[end_index] is None\n                    ):\n                        continue\n                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n                        continue\n\n                    start_char = offset_mapping[start_index][0]\n                    end_char = offset_mapping[end_index][1]\n                    valid_answers.append(\n                        {\n                            \"score\": start_logits[start_index] + end_logits[end_index],\n                            \"text\": context[start_char: end_char]\n                        }\n                    )\n        \n        if len(valid_answers) > 0:\n            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n        else:\n            best_answer = {\"text\": \"\", \"score\": 0.0}\n        \n        predictions[example[\"id\"]] = best_answer[\"text\"]\n\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2021-11-22T14:14:10.125527Z","iopub.execute_input":"2021-11-22T14:14:10.125856Z","iopub.status.idle":"2021-11-22T14:14:10.144178Z","shell.execute_reply.started":"2021-11-22T14:14:10.125823Z","shell.execute_reply":"2021-11-22T14:14:10.14349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_predictions = postprocess_qa_predictions(valid_dataset, validation_features, raw_predictions.predictions)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T14:14:33.129157Z","iopub.execute_input":"2021-11-22T14:14:33.129532Z","iopub.status.idle":"2021-11-22T14:14:37.928627Z","shell.execute_reply.started":"2021-11-22T14:14:33.129494Z","shell.execute_reply":"2021-11-22T14:14:37.927921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"references = [{\"id\": ex[\"id\"], \"answer\": ex[\"answers\"]['text'][0]} for ex in valid_dataset]\nresult = pd.DataFrame(references)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T14:14:50.475402Z","iopub.execute_input":"2021-11-22T14:14:50.476155Z","iopub.status.idle":"2021-11-22T14:14:50.50418Z","shell.execute_reply.started":"2021-11-22T14:14:50.476116Z","shell.execute_reply":"2021-11-22T14:14:50.503289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def jaccard(row): \n    str1 = row[0]\n    str2 = row[1]\n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))","metadata":{"execution":{"iopub.status.busy":"2021-11-22T14:14:59.504693Z","iopub.execute_input":"2021-11-22T14:14:59.504984Z","iopub.status.idle":"2021-11-22T14:14:59.512103Z","shell.execute_reply.started":"2021-11-22T14:14:59.504947Z","shell.execute_reply":"2021-11-22T14:14:59.511297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result['prediction'] = result['id'].apply(lambda r: final_predictions[r])\nresult['jaccard'] = result[['answer', 'prediction']].apply(jaccard, axis=1)\nresult\n","metadata":{"execution":{"iopub.status.busy":"2021-11-22T14:15:09.47818Z","iopub.execute_input":"2021-11-22T14:15:09.478452Z","iopub.status.idle":"2021-11-22T14:15:09.504981Z","shell.execute_reply.started":"2021-11-22T14:15:09.478402Z","shell.execute_reply":"2021-11-22T14:15:09.504342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result.jaccard.mean()","metadata":{"execution":{"iopub.status.busy":"2021-11-22T14:15:21.777228Z","iopub.execute_input":"2021-11-22T14:15:21.777525Z","iopub.status.idle":"2021-11-22T14:15:21.784614Z","shell.execute_reply.started":"2021-11-22T14:15:21.777492Z","shell.execute_reply":"2021-11-22T14:15:21.783892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(valid_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-11-22T14:17:39.575328Z","iopub.execute_input":"2021-11-22T14:17:39.576124Z","iopub.status.idle":"2021-11-22T14:17:39.58191Z","shell.execute_reply.started":"2021-11-22T14:17:39.576079Z","shell.execute_reply":"2021-11-22T14:17:39.581084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}