{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: #B8860B;\"><b style=\"color:white;\">chaii - Hindi and Tamil Question Answering\n</b></h1></center>","metadata":{}},{"cell_type":"markdown","source":"\n![](https://drive.google.com/uc?id=1PAhaiNQMySMWuAdAtmfOrCzlixyJYI0z)\n\n                            ","metadata":{}},{"cell_type":"markdown","source":"Inspiration :\n\nhttps://www.kaggle.com/docxian/chaii-visual-first-glance\n\nhttps://www.kaggle.com/mpwolke/stanza-inltk-indic-nlp","metadata":{}},{"cell_type":"markdown","source":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: #B8860B;\"><b style=\"color:white;\">History and Orgins of Tamil Language</b></h1></center>","metadata":{}},{"cell_type":"markdown","source":"**This competition is special to me since Tamil is my mother tongue . Its important to understand the history and orgins of the language and how much spoken tamil differs from written text .**\n\nTamil (à®¤à®®à®¿à®´à¯ tamiá¸») is a classical language and one of the major languages of the Dravidian language family. Spoken predominantly by Tamils in India, Sri Lanka, Malaysia, and Singapore, it has smaller communities of speakers in many other countries.\n\n## History \n\nThe origins of Tamil, like the other Dravidian languages are unknown, but unlike most of the other established literary languages of India, are independent of Sanskrit. Tamil has the oldest literature amongst the Dravidian languages (Hart, 1975), but dating the language and the literature precisely is difficult. Literary works in India or Sri Lanka were preserved either in palm leaf manuscripts (implying repeated copying and recopying) or through oral transmission, making direct dating impossible. External chronological records and internal linguistic evidence, however, indicate that the oldest extant works were probably composed sometime in the 2nd century CE.\n\nThe earliest extant text in Tamil is the TolkÄppiyam, a work on poetics and grammar which describes the language of the classical period, the oldest portions of this book may date back to around 200 BCE (Hart, 1975). Apart from these, the earliest examples of Tamil writing we have today are rock inscriptions from the 3rd century BCE, which are written in Tamil-Brahmi, an adapted form of the Brahmi script (Mahadevan, 2003). Linguists categorise Tamil literature and language into three periods: ancient (500 BCE to 700 CE), medieval (700 CE to 1500 CE) and modern (1500 CE to the present).\n\n\n\n## Spoken and Literary Variants \n\nIn addition to its various dialects, Tamil also exhibits a rather sharp diglossia between its formal or classic variety, called centamil, and its colloquial form, called koduntamil, a broad term which traditionally referred to all spoken Tamil dialects rather than any one standard form. Diglossia has existed in the language since ancient times - the language used in early temple inscriptions differs quite significantly from the language of classical poetry. In consequence, standard centamil is not based on the speech of any one region, a fact which has helped keep the written language mostly the same across various Tamil speaking regions.\n\nIn modern times, centamil is generally used in formal writing and speech. It is, for example, the language of textbooks, of much of Tamil literature and of public speaking and debate. In recent times, however, koduntamil has been making inroads into areas that have traditionally been considered the province of centamil. Most contemporary cinema, theatre and popular entertainment on television and radio, for example, is in koduntamil, and many politicians use it to bring themselves closer to their audience.\n\nSpoken dialects did not have much prestige: Tamils believed that the grammatical rules of literary centamil had been formulated by the gods and they were therefore seen as being the only correct speech (see, for example, Kankeyar, 1840). In contrast to most European languages, therefore, Tamil did not have a standard spoken form for much of its history. In modern times, however, the increasing use of koduntamil has led to the emergence of unofficial 'standard' spoken dialects. In India, the 'standard' koduntamil is based on 'educated non-brahmin speech', rather than on any one dialect (Schiffman, 1998), but has been significantly influenced by the dialects of Thanjavur and Madurai. In Sri Lanka the standard is based on the dialect of Jaffna.\n\n![](https://drive.google.com/uc?id=1k1aZiQxli20hUMtKq9-cr2DkJmKbprjC)\n\n## Dialects\nTamil dialects are mainly differentiated from each other by the fact that they have undergone different phonological changes and sound shifts in evolving from Old Tamil. Thus the word for \"here\" - ingu in Centamil (the classic variety) - has evolved into inge in the Kongu dialect of Coimbatore, inga in the dialect of Thanjavur, ingane in the dialect of Tirunelveli, inguttu in the dialect of Ramanathapuram, ingale and ingade in various northern dialects and ingai in some dialects of Sri Lanka.\n\nAlthough most Tamil dialects do not differ very significantly in their vocabulary, there are a few exceptions. The dialects spoken in Sri Lanka retain many words that are not in everyday use in India, and use many other words slightly differently. The dialect of the Iyers of Palakkad has a large number of Malayalam loanwords,has also been influenced by Malayalam syntax and also has a distinct Malayalam accent. Finally, the Sanketi, Hebbar and Mandyam dialects, the former spoken by groups of Tamil Iyers and the latter two by Vaishnavites who migrated to Karnataka in the 11th century, retains many features of the Vaishnava paribasai, a special form of Tamil designed in the 9th and 10th centuries to reflect Vaishnavite religious and spiritual values.Bangalore also has its own version of Tamil,and is mainly spoken by the people whose mother tongue is not Tamil and infuses words from Kannada and even Hindi.\n\nTamil dialects vary according to both region and community. Several castes have their own dialects which most members of that caste traditionally used regardless of where they come from. Some of these differences have begun to fade away in recent years as a result of the anti-casteist movement, but many traces remain and it is often possible to identify a person's caste by their speech.\n\n[Source](https://www.cs.mcgill.ca/~rwest/wikispeedia/wpcd/wp/t/Tamil_language.htm)\n\n![](https://drive.google.com/uc?id=1ds8UZQdbRYPGMJ9WdcG5c1K0pRgg20U7)","metadata":{}},{"cell_type":"markdown","source":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: #B8860B;\"><b style=\"color:white;\">Problem Statement</b></h1></center>","metadata":{}},{"cell_type":"markdown","source":"ğŸ¯ **Goal:** To predict answers to questions for wikipedia articles (in Hindi and Tamil) .\n\n","metadata":{}},{"cell_type":"markdown","source":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: #B8860B;\"><b style=\"color:white;\">Data</b></h1></center>","metadata":{}},{"cell_type":"markdown","source":" \n\nChaii dataset has questions and answers in Hindi and Tamil . \n\n**Files**\n> - ``` train.csv``` - the training set, containing context, questions, and answers. Also includes the start character of the answer for disambiguation.\n> - ```test.csv``` - the test set, containing context and questions.\n> - ```sample_submission.csv``` - a sample submission file in the correct format\n\n**Columns**\n> - ```id``` - a unique identifier\n> - ```context``` - the text of the Hindi/Tamil sample from which answers should be derived\n> - ```question``` - the question, in Hindi/Tamil\n> - ```answer_text (train only)``` - the answer to the question (manual annotation) (note: for test, this is what you are attempting to predict)\n> - ```answer_start (train only)``` - the starting character in context for the answer (determined using substring match during data preparation)\n> - ```language``` - whether the text in question is in Tamil or Hindi\n\nğŸ“Œ **Note:** There is also a hidden test set.","metadata":{}},{"cell_type":"markdown","source":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: #B8860B;\"><b style=\"color:white;\">Evaluation metric</b></h1></center>","metadata":{}},{"cell_type":"markdown","source":"# Word-level Jaccard score. \n\nJaccard Distance is a measure of how dissimilar two sets are.  The lower the distance, the more similar the two strings.Jaccard Distance depends on another concept called â€œJaccard Similarity Indexâ€ which is (the number in both sets) / (the number in either set) * 100 .\n\n[Source](https://python.gotrained.com/)\n\nThe formula for the overall metric, then, is:\n\n$$score = \\frac{1}{n} \\sum_{i=1}^{n} jaccard( gt_i, dt_i )$$\n\n>where:\n> * $n$ : number of documents \n> * $jaccard$ : the compute function\n> * $gt_i$ : the ith ground truth\n> * $dt_i$ : the ith prediction\n\n","metadata":{}},{"cell_type":"code","source":"#code snippet for jaccard score calculation\n\ndef jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))","metadata":{"execution":{"iopub.status.busy":"2021-09-16T02:26:22.773221Z","iopub.execute_input":"2021-09-16T02:26:22.774196Z","iopub.status.idle":"2021-09-16T02:26:22.796634Z","shell.execute_reply.started":"2021-09-16T02:26:22.774071Z","shell.execute_reply":"2021-09-16T02:26:22.795905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<img src=\"https://camo.githubusercontent.com/dd842f7b0be57140e68b2ab9cb007992acd131c48284eaf6b1aca758bfea358b/68747470733a2f2f692e696d6775722e636f6d2f52557469567a482e706e67\">\n\n> I will be integrating W&B for visualizations and logging artifacts!\n> \n> [chaii Hindi Tamil QA Project on W&B Dashboard](https://wandb.ai/usharengaraju/ChaiiQuestionAnswering)\n> \n> - To get the API key, create an account in the [website](https://wandb.ai/site) .\n> - Use secrets to use API Keys more securely ","metadata":{}},{"cell_type":"code","source":"!pip install pyspark\n!pip install sparknlp\n\n!pip install indic-nlp-library\n# download the resource\n!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git\n    \nimport sys\nfrom indicnlp import common\n\n# The path to the local git repo for Indic NLP library\nINDIC_NLP_LIB_HOME=r\"indic_nlp_library\"\n\n# The path to the local git repo for Indic NLP Resources\nINDIC_NLP_RESOURCES=r\"indic_nlp_resources\"\n\n# Add library to Python path\nsys.path.append(r'{}\\src'.format(INDIC_NLP_LIB_HOME))\n\n# Set environment variable for resources folder\ncommon.set_resources_path(INDIC_NLP_RESOURCES)\n\nimport os\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport wandb\nimport json\nimport gc\nimport requests\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql import SparkSession\nimport pyspark.sql.functions as F\nfrom sparknlp.annotator import *\nfrom sparknlp.base import *\nimport sparknlp\nfrom sparknlp.pretrained import PretrainedPipeline\n\nimport plotly.graph_objects as go\nimport plotly.express as px\n\nfrom indicnlp import common\nfrom indicnlp import loader\nfrom urllib.parse import quote\nfrom indicnlp.tokenize import indic_tokenize\nfrom indicnlp.transliterate.unicode_transliterate import ItransTransliterator\n\n","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-16T02:26:31.813947Z","iopub.execute_input":"2021-09-16T02:26:31.814267Z","iopub.status.idle":"2021-09-16T02:26:55.832411Z","shell.execute_reply.started":"2021-09-16T02:26:31.814235Z","shell.execute_reply":"2021-09-16T02:26:55.831343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/chaii-hindi-and-tamil-question-answering/train.csv\")\ntest_df = pd.read_csv(\"../input/chaii-hindi-and-tamil-question-answering/test.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2021-09-16T02:31:27.660053Z","iopub.execute_input":"2021-09-16T02:31:27.661074Z","iopub.status.idle":"2021-09-16T02:31:28.698961Z","shell.execute_reply.started":"2021-09-16T02:31:27.661032Z","shell.execute_reply":"2021-09-16T02:31:28.693923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = go.Figure(data=[go.Table(\n    header=dict(values=list(train_df.columns),\n                fill_color='#80c8bc',\n                line_color='black',\n                align='center'),\n    cells=dict(values=[train_df.id,train_df['context'],train_df['question'],train_df['answer_text'],train_df['answer_start'],train_df['language']],\n               fill_color='#efd199',\n               line_color='black',\n               align='left'))\n])\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T08:14:08.785163Z","iopub.execute_input":"2021-09-14T08:14:08.78541Z","iopub.status.idle":"2021-09-14T08:14:08.804215Z","shell.execute_reply.started":"2021-09-14T08:14:08.785368Z","shell.execute_reply":"2021-09-14T08:14:08.803216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10, 8))\nwedgeprops = {'width':0.3, 'edgecolor':'black', 'linewidth':3}\nax.pie([746,368],labels = [\"Hindi\" , \"Tamil\"], wedgeprops=wedgeprops, startangle=90, colors=['#efd199', '#80c8bc'])\nplt.title('Language Distribution', fontsize=24, loc='left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-16T02:27:38.412431Z","iopub.execute_input":"2021-09-16T02:27:38.413114Z","iopub.status.idle":"2021-09-16T02:27:38.542669Z","shell.execute_reply.started":"2021-09-16T02:27:38.413062Z","shell.execute_reply":"2021-09-16T02:27:38.541588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (25, 11))\nsns.heatmap(train_df.isna().values[::10], cmap = ['#efd199', \n                                                      '#80c8bc'], xticklabels=train_df.columns)\nplt.title(\"Missing values in training Data\", size=20);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\napi_key = user_secrets.get_secret(\"api_key\")\n\nos.environ[\"WANDB_SILENT\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2021-09-14T08:14:08.91427Z","iopub.execute_input":"2021-09-14T08:14:08.914628Z","iopub.status.idle":"2021-09-14T08:14:09.168447Z","shell.execute_reply.started":"2021-09-14T08:14:08.914594Z","shell.execute_reply":"2021-09-14T08:14:09.167445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: #B8860B;\"><b style=\"color:white;\">W&B Artifacts</b></h1></center>","metadata":{}},{"cell_type":"markdown","source":"An artifact as a versioned folder of data.Entire datasets can be directly stored as artifacts .\n\nW&B Artifacts are used for dataset versioning, model versioning . They are also used for tracking dependencies and results across machine learning pipelines.Artifact references can be used to point to data in other systems like S3, GCP, or your own system.\n\nYou can learn more about W&B artifacts [here](https://docs.wandb.ai/guides/artifacts)","metadata":{}},{"cell_type":"markdown","source":"![](https://drive.google.com/uc?id=1JYSaIMXuEVBheP15xxuaex-32yzxgglV)","metadata":{}},{"cell_type":"code","source":"train_df[\"question\"] = train_df[\"question\"].str.replace(\"?\", \"\", regex=False).str.strip()\ntest_df[\"question\"] = test_df[\"question\"].str.replace(\"?\", \"\", regex=False).str.strip()","metadata":{"execution":{"iopub.status.busy":"2021-09-16T02:31:39.688629Z","iopub.execute_input":"2021-09-16T02:31:39.689335Z","iopub.status.idle":"2021-09-16T02:31:39.718351Z","shell.execute_reply.started":"2021-09-16T02:31:39.689291Z","shell.execute_reply":"2021-09-16T02:31:39.717285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save preprocessed train data to W&B Artifacts\n\n#run = wandb.init(project='ChaiiQuestionAnswering', name='questions_preprocessed')\n#artifact = wandb.Artifact(name='train_preprocessed',type='dataset')\n#artifact.add_file(\"train_preprocessed.csv\")\n\n#wandb.log_artifact(artifact)\n#wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2021-09-14T08:14:09.188116Z","iopub.execute_input":"2021-09-14T08:14:09.188478Z","iopub.status.idle":"2021-09-14T08:14:09.197157Z","shell.execute_reply.started":"2021-09-14T08:14:09.188433Z","shell.execute_reply":"2021-09-14T08:14:09.196138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Snapshot of the artifacts created  \n\n![](https://drive.google.com/uc?id=1gtPksosy0OAVHp08PD8ksDY6hHyu52RB)\n\n","metadata":{}},{"cell_type":"code","source":"# add a few features\ntrain_df['n_char_context'] = train_df.context.str.len()\ntrain_df['n_word_context'] = train_df.context.str.split().map(lambda x : len(x))\ntrain_df['char_per_word_context'] = train_df.n_char_context / train_df.n_word_context\n\ntrain_df['n_char_question'] = train_df.question.str.len()\ntrain_df['n_word_question'] = train_df.question.str.split().map(lambda x : len(x))\ntrain_df['char_per_word_question'] = train_df.n_char_question / train_df.n_word_question\n\ntrain_df['n_char_answer'] = train_df.answer_text.str.len()\ntrain_df['n_word_answer'] = train_df.answer_text.str.split().map(lambda x : len(x))\ntrain_df['char_per_word_answer'] = train_df.n_char_answer / train_df.n_word_answer\n\n# relative position of answer in context\ntrain_df['answer_start_rel'] = train_df.answer_start / train_df.n_char_context\n\nnew_features = ['n_char_context', 'n_word_context', 'char_per_word_context',\n                'n_char_question', 'n_word_question', 'char_per_word_question',\n                'n_char_answer', 'n_word_answer', 'char_per_word_answer',\n                'answer_start_rel']\n","metadata":{"execution":{"iopub.status.busy":"2021-09-14T08:14:09.21512Z","iopub.execute_input":"2021-09-14T08:14:09.215745Z","iopub.status.idle":"2021-09-14T08:14:09.727952Z","shell.execute_reply.started":"2021-09-14T08:14:09.215709Z","shell.execute_reply":"2021-09-14T08:14:09.726865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show basic stats of new features\ntrain_df[new_features].describe().style.background_gradient(cmap=\"cool\")","metadata":{"execution":{"iopub.status.busy":"2021-09-14T08:14:09.730457Z","iopub.execute_input":"2021-09-14T08:14:09.730716Z","iopub.status.idle":"2021-09-14T08:14:09.859391Z","shell.execute_reply.started":"2021-09-14T08:14:09.730689Z","shell.execute_reply":"2021-09-14T08:14:09.858359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def kdeplot_features(df, feature, title):\n    '''Takes a column from the dataframe and plots the distribution (after count).'''\n    \n    values = df[feature].to_numpy()\n        \n     \n    plt.figure(figsize = (18, 3))\n    \n    sns.kdeplot(values, color = \"#80c8bc\")\n    \n    plt.title(title, fontsize=15)\n    plt.show();\n    \n    del values\n    gc.collect()\n    \ndef create_wandb_hist(x_data=None, x_name=None, title=None, log=None):\n    '''Create and save histogram in W&B Environment.\n    x_data: Pandas Series containing x values\n    x_name: strings containing axis name\n    title: title of the graph\n    log: string containing name of log'''\n    \n    data = [[x] for x in x_data]\n    table = wandb.Table(data=data, columns=[x_name])\n    wandb.log({log : wandb.plot.histogram(table, x_name, title=title)})","metadata":{"execution":{"iopub.status.busy":"2021-09-14T08:14:09.861141Z","iopub.execute_input":"2021-09-14T08:14:09.8615Z","iopub.status.idle":"2021-09-14T08:14:09.86985Z","shell.execute_reply.started":"2021-09-14T08:14:09.86146Z","shell.execute_reply":"2021-09-14T08:14:09.868928Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot distributions of new features\nfor feature in new_features:\n    kdeplot_features(train_df, feature=feature, title = feature + \" distribution\")","metadata":{"execution":{"iopub.status.busy":"2021-09-14T08:14:09.87158Z","iopub.execute_input":"2021-09-14T08:14:09.871916Z","iopub.status.idle":"2021-09-14T08:14:12.799836Z","shell.execute_reply.started":"2021-09-14T08:14:09.871877Z","shell.execute_reply":"2021-09-14T08:14:12.798764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Log Plots to W&B environment\n#for feature in new_features:\n    #title = \"Distribution of \"+feature\n    #run = wandb.init(project='ChaiiQuestionAnswering', name=title)\n    #create_wandb_hist(x_data=train_df[feature],x_name=feature , title=title,log=\"hist\")\n    #wandb.finish()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create an instance of the PairGrid class.\ngrid = sns.PairGrid(data= train_df,vars = new_features)\n# Map a scatter plot to the upper triangle\ngrid = grid.map_upper(plt.scatter, color = '#80c8bc')\n# Map a histogram to the diagonal\ngrid = grid.map_diag(plt.hist, bins = 10, color = '#efd199',edgecolor = 'k')\n# Map a density plot to the lower triangle\ngrid = grid.map_lower(sns.kdeplot, color = '#80c8bc')","metadata":{"execution":{"iopub.status.busy":"2021-09-14T08:14:12.801148Z","iopub.execute_input":"2021-09-14T08:14:12.802228Z","iopub.status.idle":"2021-09-14T08:15:20.011719Z","shell.execute_reply.started":"2021-09-14T08:14:12.802186Z","shell.execute_reply":"2021-09-14T08:15:20.011008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://drive.google.com/uc?id=1pQPKmmjtnSGiVhnUVvuItYVl4vE1k47Z)","metadata":{}},{"cell_type":"markdown","source":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: #B8860B;\"><b style=\"color:white;\">Tokenization (Tamil)</b></h1></center>","metadata":{}},{"cell_type":"markdown","source":"Tokenization is the process of breaking a stream of textual content into meaningful elements called tokens. These tokens can be words, terms, symbols, etc. Generally, the process of tokenization happens at word level, but sometimes itâ€™s tough to define whatâ€™s meant by a â€˜wordâ€™. Standard tokenizers use simple heuristics like;\n\nPunctuations and whitespace may or may not be returned with the tokens.\nContiguous strings of alphabetic characters or numbers are considered as a single token.\n\nTokens are separated using whitespace characters or punctuation characters.\nTokenization is supported for Tamil by Indic NLP, this is a python based open source library.\n\n[Source](https://nivedithakarmegam.wordpress.com/2019/03/31/text-preprocessing-tools-for-tamil-language/)","metadata":{}},{"cell_type":"code","source":"\nindic_string=\"\"\"à®ªà¯†à®£à¯à®•à®³à¯ à®‡à®±à®ªà¯à®ªà®¤à¯à®®à¯, à®ªà®¿à®±à®¨à¯à®¤à®ªà®¿à®©à¯ à®•à¯à®´à®¨à¯à®¤à¯ˆà®•à®³à¯ à®‡à®±à®ªà¯à®ªà®¤à¯à®®à¯ à®šà®°à¯à®µ à®šà®¾à®¤à®¾à®°à®£à®®à¯. à®²à¯‡à®šà®¾à®© à®šà®¿à®°à®¾à®¯à¯à®ªà¯à®ªà¯à®•à®³à¯à®®à¯ à®•à¯€à®±à®²à¯à®•à®³à¯à®®à¯ à®•à¯‚à®Ÿ à®®à®°à®£à®¤à¯à®¤à®¿à®±à¯à®•à¯ à®‡à®Ÿà¯à®Ÿà¯à®šà¯ à®šà¯†à®©à¯à®±à®©. à®’à®°à¯ à®¨à¯à®£à¯à®£à¯à®¯à®¿à®°à¯ˆ à®µà¯ˆà®¤à¯à®¤à¯ à®‡à®©à¯à®©à¯Šà®©à¯à®±à¯ˆà®•à¯ à®•à¯Šà®²à¯à®²à®®à¯à®Ÿà®¿à®•à®¿à®± à®ªà¯†à®©à®¿à®¸à®¿à®²à®¿à®©à¯ à®ªà¯‹à®©à¯à®± à®¨à®šà¯à®šà¯à®®à¯à®±à®¿ à®®à®°à¯à®¨à¯à®¤à¯à®•à®³à¯ \"\"\"\n\nsentences=indic_tokenize.trivial_tokenize(indic_string)\n\n# print the sentences\nfor t in sentences:\n    print(t)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T08:15:20.013056Z","iopub.execute_input":"2021-09-14T08:15:20.014192Z","iopub.status.idle":"2021-09-14T08:15:20.025086Z","shell.execute_reply.started":"2021-09-14T08:15:20.014117Z","shell.execute_reply":"2021-09-14T08:15:20.024356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: #B8860B;\"><b style=\"color:white;\">Transliteration (Tamil)</b></h1></center>","metadata":{}},{"cell_type":"markdown","source":"\nTransliteration is defined as â€˜transcription of one alphabet to another, or replacement of letters/characters to another language with the same phonetic soundâ€™. Unlike translation which gives the meaning of a given word in a different language, transliteration represents the characters of a given script to characters of another and only gives an idea on how that word is pronounced.\n\nTransliteration is an optional module, this again depends on your system and what you are trying to achieve. A possible use case would be, when phrases which cannot be translated are encountered these are considered as Out-of-Vocabulary terms (OOV). These OOV terms are mainly Named Entity (NE) terms like names and locations, which needs to be transliterated.\n\nIndic NLP and Polyglot are two libraries which supports Tamil-English transliterations. I personally prefer the Indic NLP transliterations (seems more accurate to me), but you could test of both the packages and decide what you think is suitable. Note that Indic NLP provides two types of transliterations one is using Itrans and the other one makes use of BrahmiNet API.\n\n[Source](https://nivedithakarmegam.wordpress.com/2019/03/31/text-preprocessing-tools-for-tamil-language/)","metadata":{}},{"cell_type":"code","source":"\n# Transliteration\ninput_text = 'à®ªà¯à®¤à¯à®¤à¯à®£à®°à¯à®šà¯à®šà®¿à®¯à®¾à®© à®šà¯à®µà®¾à®šà®®à¯ à®®à®±à¯à®±à¯à®®à¯ à®ªà®³à®ªà®³à®ªà¯à®ªà®¾à®© à®ªà®±à¯à®•à®³à¯ à®¤à®™à¯à®•à®³à®¿à®©à¯ à®¤à¯‹à®±à¯à®±à®¤à¯à®¤à¯ˆ à®¨à®¿à®°à¯à®£à®¯à®¿à®•à¯à®•à®¿à®±à®¤à¯'\nlang = 'ta'\nprint('iTrans transliteration: ')\nprint(ItransTransliterator.to_itrans(input_text, lang))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-14T08:15:20.026342Z","iopub.execute_input":"2021-09-14T08:15:20.027236Z","iopub.status.idle":"2021-09-14T08:15:20.04381Z","shell.execute_reply.started":"2021-09-14T08:15:20.02719Z","shell.execute_reply":"2021-09-14T08:15:20.042697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: #B8860B;\"><b style=\"color:white;\">Stop Word Removal</b></h1></center>","metadata":{}},{"cell_type":"markdown","source":"\nOne of the major preprocessing task is filtering out unnecessary data. In Natural Language Processing (NLP) these useless terms/words are referred to as stop words. Stop words are considered as irrelevant for searching and retrieval purposed since they occur frequently and does not add any additional sense about the queryâ€™s context. In order to save both time and space, stop words are dropped during indexing and are then ignored during searches.\n\n[Source](https://nivedithakarmegam.wordpress.com/2019/03/31/text-preprocessing-tools-for-tamil-language/)","metadata":{}},{"cell_type":"code","source":"stopwords_tamil = ['à®’à®°à¯','à®à®©à¯à®±à¯','à®®à®±à¯à®±à¯à®®à¯','à®‡à®¨à¯à®¤','à®‡à®¤','à®à®©à¯à®±','à®•à¯Šà®£à¯à®Ÿà¯','à®à®©à¯à®ªà®¤à¯','à®ªà®²','à®†à®•à¯à®®à¯','à®…à®²à¯à®²à®¤à¯',\n'à®…à®µà®°à¯','à®¨à®¾à®©à¯','à®‰à®³à¯à®³','à®…à®¨à¯à®¤','à®‡à®µà®°à¯','à®à®©','à®®à¯à®¤à®²à¯','à®à®©à¯à®©','à®‡à®°à¯à®¨à¯à®¤à¯','à®šà®¿à®²','à®à®©à¯','à®ªà¯‹à®©à¯à®±','à®µà¯‡à®£à¯à®Ÿà¯à®®à¯','à®µà®¨à¯à®¤à¯',\n'à®‡à®¤à®©à¯','à®…à®¤à¯','à®…à®µà®©à¯','à®¤à®¾à®©à¯','à®ªà®²à®°à¯à®®à¯','à®à®©à¯à®©à¯à®®à¯','à®®à¯‡à®²à¯à®®à¯','à®ªà®¿à®©à¯à®©à®°à¯','à®•à¯Šà®£à¯à®Ÿ','à®‡à®°à¯à®•à¯à®•à¯à®®à¯','à®¤à®©à®¤à¯','à®‰à®³à¯à®³à®¤à¯',\n'à®ªà¯‹à®¤à¯','à®à®©à¯à®±à¯à®®à¯','à®…à®¤à®©à¯','à®¤à®©à¯','à®ªà®¿à®±à®•à¯','à®…à®µà®°à¯à®•à®³à¯','à®µà®°à¯ˆ','à®…à®µà®³à¯','à®¨à¯€','à®†à®•à®¿à®¯','à®‡à®°à¯à®¨à¯à®¤à®¤à¯','à®‰à®³à¯à®³à®©','à®µà®¨à¯à®¤',\n'à®‡à®°à¯à®¨à¯à®¤','à®®à®¿à®•à®µà¯à®®à¯','à®‡à®™à¯à®•à¯','à®®à¯€à®¤à¯','à®“à®°à¯','à®‡à®µà¯ˆ','à®‡à®¨à¯à®¤à®•à¯','à®ªà®±à¯à®±à®¿','à®µà®°à¯à®®à¯','à®µà¯‡à®±à¯','à®‡à®°à¯','à®‡à®¤à®¿à®²à¯','à®ªà¯‹à®²à¯','à®‡à®ªà¯à®ªà¯‹à®¤à¯',\n'à®…à®µà®°à®¤à¯','à®®à®Ÿà¯à®Ÿà¯à®®à¯','à®‡à®¨à¯à®¤à®ªà¯','à®à®©à¯à®®à¯','à®®à¯‡à®²à¯','à®ªà®¿à®©à¯','à®šà¯‡à®°à¯à®¨à¯à®¤','à®†à®•à®¿à®¯à¯‹à®°à¯','à®à®©à®•à¯à®•à¯','à®‡à®©à¯à®©à¯à®®à¯','à®…à®¨à¯à®¤à®ªà¯,à®…à®©à¯à®±à¯','à®’à®°à¯‡',\n'à®®à®¿à®•','à®…à®™à¯à®•à¯','à®ªà®²à¯à®µà¯‡à®±à¯','à®µà®¿à®Ÿà¯à®Ÿà¯','à®ªà¯†à®°à¯à®®à¯','à®…à®¤à¯ˆ','à®ªà®±à¯à®±à®¿à®¯','à®‰à®©à¯','à®…à®¤à®¿à®•','à®…à®¨à¯à®¤à®•à¯','à®ªà¯‡à®°à¯','à®‡à®¤à®©à®¾à®²à¯','à®…à®µà¯ˆ','à®…à®¤à¯‡',\n'à®à®©à¯','à®®à¯à®±à¯ˆ','à®¯à®¾à®°à¯','à®à®©à¯à®ªà®¤à¯ˆ','à®à®²à¯à®²à®¾à®®à¯','à®®à®Ÿà¯à®Ÿà¯à®®à¯‡','à®‡à®™à¯à®•à¯‡','à®…à®™à¯à®•à¯‡','à®‡à®Ÿà®®à¯','à®‡à®Ÿà®¤à¯à®¤à®¿à®²à¯','à®…à®¤à®¿à®²à¯','à®¨à®¾à®®à¯','à®…à®¤à®±à¯à®•à¯',\n'à®à®©à®µà¯‡','à®ªà®¿à®±','à®šà®¿à®±à¯','à®®à®±à¯à®±','à®µà®¿à®Ÿ','à®à®¨à¯à®¤','à®à®©à®µà¯à®®à¯','à®à®©à®ªà¯à®ªà®Ÿà¯à®®à¯','à®à®©à®¿à®©à¯à®®à¯','à®…à®Ÿà¯à®¤à¯à®¤','à®‡à®¤à®©à¯ˆ','à®‡à®¤à¯ˆ','à®•à¯Šà®³à¯à®³',\n'à®‡à®¨à¯à®¤à®¤à¯','à®‡à®¤à®±à¯à®•à¯','à®…à®¤à®©à®¾à®²à¯','à®¤à®µà®¿à®°','à®ªà¯‹à®²','à®µà®°à¯ˆà®¯à®¿à®²à¯','à®šà®±à¯à®±à¯','à®à®©à®•à¯']","metadata":{"execution":{"iopub.status.busy":"2021-09-14T08:15:20.045274Z","iopub.execute_input":"2021-09-14T08:15:20.046317Z","iopub.status.idle":"2021-09-14T08:15:20.056411Z","shell.execute_reply.started":"2021-09-14T08:15:20.046281Z","shell.execute_reply":"2021-09-14T08:15:20.055566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parsed = []\n\ninput_text = 'à®ªà¯à®¤à¯à®¤à¯à®£à®°à¯à®šà¯à®šà®¿à®¯à®¾à®© à®šà¯à®µà®¾à®šà®®à¯ à®®à®±à¯à®±à¯à®®à¯ à®ªà®³à®ªà®³à®ªà¯à®ªà®¾à®© à®ªà®±à¯à®•à®³à¯ à®¤à®™à¯à®•à®³à®¿à®©à¯ à®¤à¯‹à®±à¯à®±à®¤à¯à®¤à¯ˆ à®¨à®¿à®°à¯à®£à®¯à®¿à®•à¯à®•à®¿à®±à®¤à¯'\nsentences=indic_tokenize.trivial_tokenize(input_text)\n\nfor word in sentences:\n    if word[0] not in stopwords_tamil:\n        parsed.append(word)\nprint(parsed)","metadata":{"execution":{"iopub.status.busy":"2021-09-14T08:15:20.058184Z","iopub.execute_input":"2021-09-14T08:15:20.058526Z","iopub.status.idle":"2021-09-14T08:15:20.077163Z","shell.execute_reply.started":"2021-09-14T08:15:20.05849Z","shell.execute_reply":"2021-09-14T08:15:20.076226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center style=\"font-family:verdana;\"><h1 style=\"font-size:200%; padding: 10px; background: #B8860B;\"><b style=\"color:white;\">Lemmatization</b></h1></center>","metadata":{}},{"cell_type":"markdown","source":"Tamil is a morphologically rich and agglutinative language. Such a language needs deeper analysis at the word level to capture the meaning of the word from its morphemes and its categories.\n\nTamil Lemmatizer from John Snow Labs is a dictionary-based lemmatizer that assigns all forms and inflections of a word to a single root. This enables the pipeline to treat the past and present tense of a verb, for example, as the same word instead of two completely different words.","metadata":{}},{"cell_type":"code","source":"spark = sparknlp.start()","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-09-16T04:36:35.275411Z","iopub.execute_input":"2021-09-16T04:36:35.275698Z","iopub.status.idle":"2021-09-16T04:37:16.481285Z","shell.execute_reply.started":"2021-09-16T04:36:35.27566Z","shell.execute_reply":"2021-09-16T04:37:16.480292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"document_assembler = DocumentAssembler() \\\n    .setInputCol(\"text\") \\\n    .setOutputCol(\"document\")\n\ntokenizer = Tokenizer()\\\n    .setInputCols([\"document\"]) \\\n    .setOutputCol(\"token\")\n\nlemmatizer = LemmatizerModel.pretrained(\"lemma\", \"ta\") \\\n        .setInputCols([\"token\"]) \\\n        .setOutputCol(\"lemma\")\n\npipeline = Pipeline(stages=[document_assembler, tokenizer, lemmatizer])\n\nexample = spark.createDataFrame([['à®•à®Ÿà¯à®šà®¿ à®µà¯†à®±à¯à®±à®¿ à®ªà¯†à®±à¯à®±à®¤à¯‹à®Ÿà¯ à®ªà¯†à®±à¯à®±à®¤à¯ à®“à®Ÿà¯ à®†à®Ÿà¯à®šà®¿à®¯à®¿à®²à¯ à®‰à®³à¯à®³ à®•à®Ÿà¯à®šà®¿à®•à¯à®•à¯ à®’à®°à¯ à®®à®¾à®±à¯à®±à¯à®•à¯ à®•à®Ÿà¯à®šà®¿à®¯à®¾à®• à®µà®³à®°à¯à®¨à¯à®¤à¯à®³à¯à®³à®¤à¯ à®µà®³à®°à¯à®¨à¯à®¤à¯ à®‰à®³à¯à®³à®¤à¯ .']], [\"text\"])\n\nresults = pipeline.fit(example).transform(example)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-09-16T04:38:56.906818Z","iopub.execute_input":"2021-09-16T04:38:56.907142Z","iopub.status.idle":"2021-09-16T04:39:07.432283Z","shell.execute_reply.started":"2021-09-16T04:38:56.907105Z","shell.execute_reply":"2021-09-16T04:39:07.431378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lemmatization\nresults.select(F.explode(F.arrays_zip('lemma.result')).alias(\"cols\")) \\\n.select(F.expr(\"cols['0']\").alias(\"lemma\")).show(truncate=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-16T04:39:07.433937Z","iopub.execute_input":"2021-09-16T04:39:07.43422Z","iopub.status.idle":"2021-09-16T04:39:10.322304Z","shell.execute_reply.started":"2021-09-16T04:39:07.434186Z","shell.execute_reply":"2021-09-16T04:39:10.321398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Work in progress ğŸš§","metadata":{}},{"cell_type":"markdown","source":"# References:\n\nhttps://nivedithakarmegam.wordpress.com/2019/03/31/text-preprocessing-tools-for-tamil-language/\n\n","metadata":{}}]}