{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Install packages","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nsys.path.append(\"../input/segmentation-models-pytorch/segmentation_models.pytorch-0.2.1\")\nsys.path.append(\"../input/pretrainedmodels/pretrainedmodels-0.7.4\")\nsys.path.append(\"../input/efficientnet-pytorch/EfficientNet-PyTorch-master\")\n\n!pip install ../input/mmdetection/addict-2.4.0-py3-none-any.whl > /dev/null\n!pip install ../input/mmdetection/yapf-0.31.0-py2.py3-none-any.whl > /dev/null\n!pip install ../input/mmdetection/terminaltables-3.1.0-py3-none-any.whl > /dev/null\n!pip install ../input/mmdetection/einops* > /dev/null\n!pip install ../input/mmdetection/mmcv_full-1.3.17-cp37-cp37m-linux_x86_64.whl > /dev/null","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-11T06:22:33.355634Z","iopub.execute_input":"2022-05-11T06:22:33.356396Z","iopub.status.idle":"2022-05-11T06:23:22.268804Z","shell.execute_reply.started":"2022-05-11T06:22:33.356357Z","shell.execute_reply":"2022-05-11T06:23:22.267815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Install mmsegmentation \n\nThis is from my own [mmseg github repo](https://github.com/CarnoZhao/Kaggle-UWMGIT) (leave a star if you like it!)\n\nI have integrated `segmentation_models_pytorch` in this version of `mmsegmentation`. Although `segmentation_models_pytorch`'s simple Unet performs better than some models of `mmsegmentation`, anyway, `mmsegmentation` is still a good library for segmentation task when you want to compare various models in a unified training pipeline.\n\nI only hard-coded `smp.Unet` in `./mmseg/models/segmentors/smp_models.py`. You can add more `smp` models in it!","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/CarnoZhao/Kaggle-UWMGIT && cd ../input/kaggleuwmgit && pip install -e .","metadata":{"execution":{"iopub.status.busy":"2022-05-11T06:23:22.27085Z","iopub.execute_input":"2022-05-11T06:23:22.271137Z","iopub.status.idle":"2022-05-11T06:23:23.072036Z","shell.execute_reply.started":"2022-05-11T06:23:22.271097Z","shell.execute_reply":"2022-05-11T06:23:23.071187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Prepare data","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\nimport numpy as np\nimport pandas as pd\n\nimport cv2\nfrom PIL import Image\nfrom tqdm.auto import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-05-11T06:23:23.074084Z","iopub.execute_input":"2022-05-11T06:23:23.074388Z","iopub.status.idle":"2022-05-11T06:23:23.084819Z","shell.execute_reply.started":"2022-05-11T06:23:23.074348Z","shell.execute_reply":"2022-05-11T06:23:23.083956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.1 Read csv and extract meta info","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(\"../input/uw-madison-gi-tract-image-segmentation/train.csv\")\ndf_train = df_train.sort_values([\"id\", \"class\"]).reset_index(drop = True)\ndf_train[\"patient\"] = df_train.id.apply(lambda x: x.split(\"_\")[0])\ndf_train[\"days\"] = df_train.id.apply(lambda x: \"_\".join(x.split(\"_\")[:2]))\n\nall_image_files = sorted(glob.glob(\"../input/uw-madison-gi-tract-image-segmentation/train/*/*/scans/*.png\"), key = lambda x: x.split(\"/\")[5] + \"_\" + x.split(\"/\")[7])\nsize_x = [int(os.path.basename(_)[:-4].split(\"_\")[-4]) for _ in all_image_files]\nsize_y = [int(os.path.basename(_)[:-4].split(\"_\")[-3]) for _ in all_image_files]\nspacing_x = [float(os.path.basename(_)[:-4].split(\"_\")[-2]) for _ in all_image_files]\nspacing_y = [float(os.path.basename(_)[:-4].split(\"_\")[-1]) for _ in all_image_files]\ndf_train[\"image_files\"] = np.repeat(all_image_files, 3)\ndf_train[\"spacing_x\"] = np.repeat(spacing_x, 3)\ndf_train[\"spacing_y\"] = np.repeat(spacing_y, 3)\ndf_train[\"size_x\"] = np.repeat(size_x, 3)\ndf_train[\"size_y\"] = np.repeat(size_y, 3)\ndf_train[\"slice\"] = np.repeat([int(os.path.basename(_)[:-4].split(\"_\")[-5]) for _ in all_image_files], 3)\ndf_train","metadata":{"execution":{"iopub.status.busy":"2022-05-11T06:44:56.863862Z","iopub.execute_input":"2022-05-11T06:44:56.864148Z","iopub.status.idle":"2022-05-11T06:44:58.23508Z","shell.execute_reply.started":"2022-05-11T06:44:56.864115Z","shell.execute_reply":"2022-05-11T06:44:58.234115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 Make mmseg-format data (2.5D by default)\n\n\nHere, I used 2.5d data with stride=2. Thanks this good trick from [https://www.kaggle.com/code/awsaf49/uwmgi-2-5d-stride-2-data](https://www.kaggle.com/code/awsaf49/uwmgi-2-5d-stride-2-data)","metadata":{}},{"cell_type":"code","source":"def rle_decode(mask_rle, shape):\n    s = np.array(mask_rle.split(), dtype=int)\n    starts, lengths = s[0::2] - 1, s[1::2]\n    ends = starts + lengths\n    h, w = shape\n    img = np.zeros((h * w,), dtype = np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = 1\n    return img.reshape(shape)\n\n!mkdir -p ./mmseg_train/{images,labels,splits}\nfor day, group in tqdm(df_train.groupby(\"days\")):\n    patient = group.patient.iloc[0]\n    imgs = []\n    msks = []\n    file_names = []\n    for file_name in group.image_files.unique():\n        img = cv2.imread(file_name, cv2.IMREAD_ANYDEPTH)\n        segms = group.loc[group.image_files == file_name]\n        masks = {}\n        for segm, label in zip(segms.segmentation, segms[\"class\"]):\n            if not pd.isna(segm):\n                mask = rle_decode(segm, img.shape[:2])\n                masks[label] = mask\n            else:\n                masks[label] = np.zeros(img.shape[:2], dtype = np.uint8)\n        masks = np.stack([masks[k] for k in sorted(masks)], -1)\n        imgs.append(img)\n        msks.append(masks)\n        \n    imgs = np.stack(imgs, 0)\n    msks = np.stack(msks, 0)\n    for i in range(msks.shape[0]):\n        img = imgs[[max(0, i - 2), i, min(imgs.shape[0] - 1, i + 2)]].transpose(1,2,0) # 2.5d data\n        msk = msks[i]\n        new_file_name = f\"{day}_{i}.png\"\n        cv2.imwrite(f\"./mmseg_train/images/{new_file_name}\", img)\n        cv2.imwrite(f\"./mmseg_train/labels/{new_file_name}\", msk)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T06:45:28.371174Z","iopub.execute_input":"2022-05-11T06:45:28.371931Z","iopub.status.idle":"2022-05-11T06:56:18.234006Z","shell.execute_reply.started":"2022-05-11T06:45:28.371895Z","shell.execute_reply":"2022-05-11T06:56:18.233162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.3 Make fold splits","metadata":{}},{"cell_type":"code","source":"all_image_files = glob.glob(\"./mmseg_train/images/*\")\npatients = [os.path.basename(_).split(\"_\")[0] for _ in all_image_files]\n\n\nfrom sklearn.model_selection import GroupKFold\n\nsplit = list(GroupKFold(5).split(patients, groups = patients))\n\nfor fold, (train_idx, valid_idx) in enumerate(split):\n    with open(f\"./mmseg_train/splits/fold_{fold}.txt\", \"w\") as f:\n        for idx in train_idx:\n            f.write(os.path.basename(all_image_files[idx])[:-4] + \"\\n\")\n    with open(f\"./mmseg_train/splits/holdout_{fold}.txt\", \"w\") as f:\n        for idx in valid_idx:\n            f.write(os.path.basename(all_image_files[idx])[:-4] + \"\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-05-11T06:56:24.820291Z","iopub.execute_input":"2022-05-11T06:56:24.820582Z","iopub.status.idle":"2022-05-11T06:56:25.344718Z","shell.execute_reply.started":"2022-05-11T06:56:24.820547Z","shell.execute_reply":"2022-05-11T06:56:25.343958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Training\n\n## 4.1 Make config\n\nThis is only **a simple baseline**, you can change anything in it\n\nFrom my own experiment, when using larger backbone, larger image size and more augs, the public score will be easily exceed 0.865.\n\nHere, I only train for 1k iters. **More iters are required to get a valid score**.\n\nI have made a single model submission scored 0.878 using this training pipeline!","metadata":{}},{"cell_type":"code","source":"%%bash\n\ncat <<EOT >> ./Kaggle-UWMGIT/config.py\nnum_classes = 3\n\n# model settings\nnorm_cfg = dict(type='SyncBN', requires_grad=True)\nloss = [\n    dict(type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n]\nmodel = dict(\n    type='SMPUnet',\n    backbone=dict(\n        type='timm-efficientnet-b0',\n        pretrained=\"imagenet\"\n    ),\n    decode_head=dict(\n        num_classes=num_classes,\n        align_corners=False,\n        loss_decode=loss\n    ),\n    # model training and testing settings\n    train_cfg=dict(),\n    test_cfg=dict(mode=\"whole\", multi_label=True))\n\n# dataset settings\ndataset_type = 'CustomDataset'\ndata_root = '../mmseg_train/'\nclasses = ['large_bowel', 'small_bowel', 'stomach']\npalette = [[0,0,0], [128,128,128], [255,255,255]]\nimg_norm_cfg = dict(mean=[0,0,0], std=[1,1,1], to_rgb=True)\nsize = 256\nalbu_train_transforms = [\n    dict(type='RandomBrightnessContrast', p=0.5),\n]\ntrain_pipeline = [\n    dict(type='LoadImageFromFile', to_float32=True, color_type='unchanged', max_value='max'),\n    dict(type='LoadAnnotations'),\n    dict(type='Resize', img_scale=(size, size), keep_ratio=True),\n    dict(type='RandomFlip', prob=0.5, direction='horizontal'),\n    dict(type='Albu', transforms=albu_train_transforms),\n    dict(type='Normalize', **img_norm_cfg),\n    dict(type='Pad', size=(size, size), pad_val=0, seg_pad_val=255),\n    dict(type='DefaultFormatBundle'),\n    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile', to_float32=True, color_type='unchanged', max_value='max'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(size, size),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(type='Normalize', **img_norm_cfg),\n            dict(type='Pad', size=(size, size), pad_val=0, seg_pad_val=255),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img']),\n        ])\n]\ndata = dict(\n    samples_per_gpu=32,\n    workers_per_gpu=4,\n    train=dict(\n        type=dataset_type,\n        multi_label=True,\n        data_root=data_root,\n        img_dir='images',\n        ann_dir='labels',\n        img_suffix=\".png\",\n        seg_map_suffix='.png',\n        split=\"splits/fold_0.txt\",\n        classes=classes,\n        palette=palette,\n        pipeline=train_pipeline),\n    val=dict(\n        type=dataset_type,\n        multi_label=True,\n        data_root=data_root,\n        img_dir='images',\n        ann_dir='labels',\n        img_suffix=\".png\",\n        seg_map_suffix='.png',\n        split=\"splits/holdout_0.txt\",\n        classes=classes,\n        palette=palette,\n        pipeline=test_pipeline),\n    test=dict(\n        type=dataset_type,\n        multi_label=True,\n        data_root=data_root,\n        test_mode=True,\n        img_dir='test/images',\n        ann_dir='test/labels',\n        img_suffix=\".jpg\",\n        seg_map_suffix='.png',\n        classes=classes,\n        palette=palette,\n        pipeline=test_pipeline))\n\n# yapf:disable\nlog_config = dict(\n    interval=50,\n    hooks=[\n        dict(type='CustomizedTextLoggerHook', by_epoch=False),\n    ])\n# yapf:enable\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = None\nresume_from = None\nworkflow = [('train', 1)]\ncudnn_benchmark = True\n\ntotal_iters = 1\n# optimizer\noptimizer = dict(type='AdamW', lr=1e-3, betas=(0.9, 0.999), weight_decay=0.05)\noptimizer_config = dict(type='Fp16OptimizerHook', loss_scale='dynamic')\n# learning policy\nlr_config = dict(policy='poly',\n                 warmup='linear',\n                 warmup_iters=500,\n                 warmup_ratio=1e-6,\n                 power=1.0, min_lr=0.0, by_epoch=False)\n# runtime settings\nfind_unused_parameters=True\nrunner = dict(type='IterBasedRunner', max_iters=int(total_iters * 1000))\ncheckpoint_config = dict(by_epoch=False, interval=int(total_iters * 1000), save_optimizer=False)\nevaluation = dict(by_epoch=False, interval=min(5000, int(total_iters * 1000)), metric=['imDice', 'mDice'], pre_eval=True)\nfp16 = dict()\n\nwork_dir = f'./work_dirs/tract/baseline'\nEOT","metadata":{"execution":{"iopub.status.busy":"2022-05-11T06:56:28.318492Z","iopub.execute_input":"2022-05-11T06:56:28.31903Z","iopub.status.idle":"2022-05-11T06:56:28.384409Z","shell.execute_reply.started":"2022-05-11T06:56:28.318993Z","shell.execute_reply":"2022-05-11T06:56:28.383402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.2 Let's start training","metadata":{}},{"cell_type":"code","source":"# reinstall for inner bash usage\n!cp -r ../input/segmentation-models-pytorch/segmentation_models.pytorch-0.2.1 ./ && cd segmentation_models.pytorch-0.2.1  && pip install -e .\n!cp -r ../input/timm-pytorch-image-models/pytorch-image-models-master ./ && cd pytorch-image-models-master  && pip install -e .","metadata":{"execution":{"iopub.status.busy":"2022-05-11T06:34:16.40537Z","iopub.execute_input":"2022-05-11T06:34:16.405656Z","iopub.status.idle":"2022-05-11T06:34:49.029437Z","shell.execute_reply.started":"2022-05-11T06:34:16.405614Z","shell.execute_reply":"2022-05-11T06:34:49.028538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cd Kaggle-UWMGIT && python ./tools/train.py ./config.py --gpu-ids 0","metadata":{"execution":{"iopub.status.busy":"2022-05-11T06:56:34.750962Z","iopub.execute_input":"2022-05-11T06:56:34.751609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Inferencing\n\n## 5.1 Load trained models","metadata":{}},{"cell_type":"code","source":"sys.path.append('./Kaggle-UWMGIT')\nfrom mmseg.apis import init_segmentor, inference_segmentor\nfrom mmcv.utils import config\n\ncfgs = [\n    \"./Kaggle-UWMGIT/work_dirs/tract/baseline/config.py\",\n]\n\nckpts = [\n    \"./Kaggle-UWMGIT/work_dirs/tract/baseline/latest.pth\",\n]\n\nmodels = []\nfor cfg, ckpt in zip(cfgs, ckpts):\n    cfg = config.Config.fromfile(cfg)\n    cfg.model.backbone.pretrained = None\n    cfg.model.test_cfg.logits = True\n    cfg.data.test.pipeline[1].transforms.insert(2, dict(type=\"Normalize\", mean=[0,0,0], std=[1,1,1], to_rgb=False))\n\n    model = init_segmentor(cfg, ckpt)\n    models.append(model)","metadata":{"execution":{"iopub.status.busy":"2022-05-11T06:42:59.96318Z","iopub.execute_input":"2022-05-11T06:42:59.965228Z","iopub.status.idle":"2022-05-11T06:43:19.159493Z","shell.execute_reply.started":"2022-05-11T06:42:59.965168Z","shell.execute_reply":"2022-05-11T06:43:19.158284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.2 Make test submission csv","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport glob\nfrom tqdm.auto import tqdm\nfrom scipy.ndimage import binary_closing, binary_opening, measurements\n\ndef rle_encode(img):\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\nclasses = ['large_bowel', 'small_bowel', 'stomach']\ndata_dir = \"../input/uw-madison-gi-tract-image-segmentation/\"\ntest_dir = os.path.join(data_dir, \"test\")\nsub = pd.read_csv(os.path.join(data_dir, \"sample_submission.csv\"))\ntest_images = glob.glob(os.path.join(test_dir, \"**\", \"*.png\"), recursive = True)\n\nif len(test_images) == 0:\n    test_dir = os.path.join(data_dir, \"train\")\n    sub = pd.read_csv(os.path.join(data_dir, \"train.csv\"))[[\"id\", \"class\"]].iloc[:100 * 3]\n    sub[\"predicted\"] = \"\"\n    test_images = glob.glob(os.path.join(test_dir, \"**\", \"*.png\"), recursive = True)\n    \nid2img = {_.rsplit(\"/\", 4)[2] + \"_\" + \"_\".join(_.rsplit(\"/\", 4)[4].split(\"_\")[:2]): _ for _ in test_images}\nsub[\"file_name\"] = sub.id.map(id2img)\nsub[\"days\"] = sub.id.apply(lambda x: \"_\".join(x.split(\"_\")[:2]))\nfname2index = {f + c: i for f, c, i in zip(sub.file_name, sub[\"class\"], sub.index)}\nsub","metadata":{"execution":{"iopub.status.busy":"2022-05-11T06:43:19.161016Z","iopub.status.idle":"2022-05-11T06:43:19.161426Z","shell.execute_reply.started":"2022-05-11T06:43:19.161193Z","shell.execute_reply":"2022-05-11T06:43:19.16123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.3 Start Inferencing","metadata":{}},{"cell_type":"code","source":"subs = []\nfor day, group in tqdm(sub.groupby(\"days\")):\n    imgs = []\n    for file_name in group.file_name.unique():\n        img = cv2.imread(file_name, cv2.IMREAD_ANYDEPTH)\n        old_size = img.shape[:2]\n        s = int(os.path.basename(file_name).split(\"_\")[1])\n        file_names = [file_name.replace(f\"slice_{s:04d}\", f\"slice_{s + i:04d}\") for i in range(-2, 3)]\n        file_names = [_ for _ in file_names if os.path.exists(_)]\n        imgs = [cv2.imread(file_names[0], cv2.IMREAD_ANYDEPTH)] + [img] + [cv2.imread(file_names[-1], cv2.IMREAD_ANYDEPTH)]\n        \n        new_img = np.stack(imgs, -1)\n        new_img = new_img.astype(np.float32) / new_img.max()\n\n        res = [inference_segmentor(model, new_img)[0] for model in models]\n        res = (sum(res) / len(res)).round().astype(np.uint8)\n        res = cv2.resize(res, old_size[::-1], interpolation = cv2.INTER_NEAREST)\n        for j in range(3):\n            rle = rle_encode(res[...,j])\n            index = fname2index[file_name + classes[j]]\n            sub.loc[index, \"predicted\"] = rle","metadata":{"execution":{"iopub.status.busy":"2022-05-11T06:43:19.162734Z","iopub.status.idle":"2022-05-11T06:43:19.163333Z","shell.execute_reply.started":"2022-05-11T06:43:19.163086Z","shell.execute_reply":"2022-05-11T06:43:19.163112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.4 Format submission","metadata":{}},{"cell_type":"code","source":"sub = sub[[\"id\", \"class\", \"predicted\"]]\nsub.to_csv(\"submission.csv\", index = False)\nsub","metadata":{"execution":{"iopub.status.busy":"2022-05-11T06:43:19.164493Z","iopub.status.idle":"2022-05-11T06:43:19.165095Z","shell.execute_reply.started":"2022-05-11T06:43:19.164814Z","shell.execute_reply":"2022-05-11T06:43:19.164851Z"},"trusted":true},"execution_count":null,"outputs":[]}]}