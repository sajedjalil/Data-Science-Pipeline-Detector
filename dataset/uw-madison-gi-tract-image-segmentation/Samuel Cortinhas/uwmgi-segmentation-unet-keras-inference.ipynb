{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction","metadata":{}},{"cell_type":"markdown","source":"In this notebook, we perform **GI tract semantic image segmentation** using U-Net.","metadata":{}},{"cell_type":"markdown","source":"* Part 1: [UWMGI Segmentation - UNet, keras [Train]](https://www.kaggle.com/code/samuelcortinhas/uwmgi-segmentation-unet-keras-train) \n* Part 2: [UWMGI Segmentation - UNet, keras [Inference]](https://www.kaggle.com/code/samuelcortinhas/uwmgi-segmentation-unet-keras-inference)\n* Trained weights: [UWMGI - Trained UNet model](https://www.kaggle.com/datasets/samuelcortinhas/uwmgi-trained-unet-model)","metadata":{}},{"cell_type":"markdown","source":"**Libraries**","metadata":{}},{"cell_type":"code","source":"# Core\nimport pandas as pd\nimport numpy as np\nimport os\nimport cv2\nimport gc\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm\nfrom datetime import datetime\nimport json,itertools\nfrom typing import Optional\nfrom glob import glob\nimport time\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold\nimport matplotlib.gridspec as gridspec\nimport matplotlib.patches as mpatches\nimport matplotlib as mpl\n\n# keras\nfrom tensorflow import keras\nimport tensorflow as tf\nimport keras\nfrom keras import backend as K\nfrom keras.models import Model\nfrom keras.layers import Input\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.losses import binary_crossentropy\nfrom keras.callbacks import Callback, ModelCheckpoint, EarlyStopping\nfrom keras.models import load_model","metadata":{"execution":{"iopub.status.busy":"2022-06-16T10:22:18.788778Z","iopub.execute_input":"2022-06-16T10:22:18.789078Z","iopub.status.idle":"2022-06-16T10:22:18.799898Z","shell.execute_reply.started":"2022-06-16T10:22:18.789047Z","shell.execute_reply":"2022-06-16T10:22:18.798804Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"markdown","source":"**Config**","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 16\nim_width = 320\nim_height = 320","metadata":{"execution":{"iopub.status.busy":"2022-06-16T10:22:18.811113Z","iopub.execute_input":"2022-06-16T10:22:18.811451Z","iopub.status.idle":"2022-06-16T10:22:18.816717Z","shell.execute_reply.started":"2022-06-16T10:22:18.811417Z","shell.execute_reply":"2022-06-16T10:22:18.81594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train set**","metadata":{}},{"cell_type":"code","source":"# Train set\ntrain_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/train.csv')\nprint(train_df.shape)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T10:22:18.830469Z","iopub.execute_input":"2022-06-16T10:22:18.830941Z","iopub.status.idle":"2022-06-16T10:22:19.141677Z","shell.execute_reply.started":"2022-06-16T10:22:18.830908Z","shell.execute_reply":"2022-06-16T10:22:19.140522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Test set**","metadata":{}},{"cell_type":"code","source":"# Test set\ntest_df = pd.read_csv('../input/uw-madison-gi-tract-image-segmentation/sample_submission.csv')\n\nif len(test_df)==0:\n    DEBUG=True\n    test_df = train_df.iloc[:10*16*3,:]\n    test_df[\"segmentation\"]=''\n    test_df=test_df.rename(columns={\"segmentation\":\"predicted\"})\nelse:\n    DEBUG=False\n\nsubmission=test_df.copy()\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T10:22:19.143577Z","iopub.execute_input":"2022-06-16T10:22:19.144068Z","iopub.status.idle":"2022-06-16T10:22:19.164885Z","shell.execute_reply.started":"2022-06-16T10:22:19.144033Z","shell.execute_reply":"2022-06-16T10:22:19.163602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"markdown","source":"**Metadata**","metadata":{}},{"cell_type":"code","source":"# Metadata\ndef preprocessing(df, subset=\"train\"):\n    #--------------------------------------------------------------------------\n    df[\"case\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\")[0].replace(\"case\", \"\")))\n    df[\"day\"] = df[\"id\"].apply(lambda x: int(x.split(\"_\")[1].replace(\"day\", \"\")))\n    df[\"slice\"] = df[\"id\"].apply(lambda x: x.split(\"_\")[3])\n    #--------------------------------------------------------------------------\n    if (subset==\"train\") or (DEBUG):\n        DIR=\"../input/uw-madison-gi-tract-image-segmentation/train\"\n    else:\n        DIR=\"../input/uw-madison-gi-tract-image-segmentation/test\"\n    \n    all_images = glob(os.path.join(DIR, \"**\", \"*.png\"), recursive=True)\n    x = all_images[0].rsplit(\"/\", 4)[0] ## ../input/uw-madison-gi-tract-image-segmentation/train\n\n    path_partial_list = []\n    for i in range(0, df.shape[0]):\n        path_partial_list.append(os.path.join(x,\n                              \"case\"+str(df[\"case\"].values[i]),\n                              \"case\"+str(df[\"case\"].values[i])+\"_\"+ \"day\"+str(df[\"day\"].values[i]),\n                              \"scans\",\n                              \"slice_\"+str(df[\"slice\"].values[i])))\n    df[\"path_partial\"] = path_partial_list\n    #--------------------------------------------------------------------------\n    path_partial_list = []\n    for i in range(0, len(all_images)):\n        path_partial_list.append(str(all_images[i].rsplit(\"_\",4)[0]))\n\n    tmp_df = pd.DataFrame()\n    tmp_df['path_partial'] = path_partial_list\n    tmp_df['path'] = all_images\n\n    #--------------------------------------------------------------------------\n    df = df.merge(tmp_df, on=\"path_partial\").drop(columns=[\"path_partial\"])\n    #--------------------------------------------------------------------------\n    df[\"width\"] = df[\"path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[1]))\n    df[\"height\"] = df[\"path\"].apply(lambda x: int(x[:-4].rsplit(\"_\",4)[2]))\n    #--------------------------------------------------------------------------\n    del x, path_partial_list, tmp_df\n    #--------------------------------------------------------------------------\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-06-16T10:22:19.168062Z","iopub.execute_input":"2022-06-16T10:22:19.168521Z","iopub.status.idle":"2022-06-16T10:22:19.186335Z","shell.execute_reply.started":"2022-06-16T10:22:19.168472Z","shell.execute_reply":"2022-06-16T10:22:19.185035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = preprocessing(train_df, subset=\"train\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T10:22:19.1885Z","iopub.execute_input":"2022-06-16T10:22:19.189224Z","iopub.status.idle":"2022-06-16T10:22:24.517315Z","shell.execute_reply.started":"2022-06-16T10:22:19.189147Z","shell.execute_reply":"2022-06-16T10:22:24.516158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df=preprocessing(test_df, subset=\"test\")\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T10:22:24.520034Z","iopub.execute_input":"2022-06-16T10:22:24.520365Z","iopub.status.idle":"2022-06-16T10:22:25.545837Z","shell.execute_reply.started":"2022-06-16T10:22:24.520333Z","shell.execute_reply":"2022-06-16T10:22:25.544839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Restructure df**","metadata":{}},{"cell_type":"code","source":"# Restructure\ndef restructure(df, subset=\"train\"):\n    # RESTRUCTURE  DATAFRAME\n    df_out = pd.DataFrame({'id': df['id'][::3]})\n\n    if subset==\"train\":\n        df_out['large_bowel'] = df['segmentation'][::3].values\n        df_out['small_bowel'] = df['segmentation'][1::3].values\n        df_out['stomach'] = df['segmentation'][2::3].values\n\n    df_out['path'] = df['path'][::3].values\n    df_out['case'] = df['case'][::3].values\n    df_out['day'] = df['day'][::3].values\n    df_out['slice'] = df['slice'][::3].values\n    df_out['width'] = df['width'][::3].values\n    df_out['height'] = df['height'][::3].values\n\n    df_out=df_out.reset_index(drop=True)\n    df_out=df_out.fillna('')\n    if subset==\"train\":\n        df_out['count'] = np.sum(df_out.iloc[:,1:4]!='',axis=1).values\n    \n    return df_out","metadata":{"execution":{"iopub.status.busy":"2022-06-16T10:22:25.547362Z","iopub.execute_input":"2022-06-16T10:22:25.547896Z","iopub.status.idle":"2022-06-16T10:22:25.558391Z","shell.execute_reply.started":"2022-06-16T10:22:25.547863Z","shell.execute_reply":"2022-06-16T10:22:25.557229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df=restructure(train_df, subset=\"train\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T10:22:25.559969Z","iopub.execute_input":"2022-06-16T10:22:25.560333Z","iopub.status.idle":"2022-06-16T10:22:25.658297Z","shell.execute_reply.started":"2022-06-16T10:22:25.560287Z","shell.execute_reply":"2022-06-16T10:22:25.657474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df=restructure(test_df, subset=\"test\")\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T10:22:25.659776Z","iopub.execute_input":"2022-06-16T10:22:25.660015Z","iopub.status.idle":"2022-06-16T10:22:25.680278Z","shell.execute_reply.started":"2022-06-16T10:22:25.659985Z","shell.execute_reply":"2022-06-16T10:22:25.679259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Remove mislabeled data**","metadata":{}},{"cell_type":"code","source":"# Remove mislabeled training data\ntrain_df = train_df[(train_df['case']!=7)|(train_df['day']!=0)]\ntrain_df = train_df[(train_df['case']!=81)|(train_df['day']!=30)]","metadata":{"execution":{"iopub.status.busy":"2022-06-16T10:22:25.68183Z","iopub.execute_input":"2022-06-16T10:22:25.682412Z","iopub.status.idle":"2022-06-16T10:22:25.714124Z","shell.execute_reply.started":"2022-06-16T10:22:25.682364Z","shell.execute_reply":"2022-06-16T10:22:25.713251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Garbage collection\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T10:22:25.715407Z","iopub.execute_input":"2022-06-16T10:22:25.715627Z","iopub.status.idle":"2022-06-16T10:22:26.770813Z","shell.execute_reply.started":"2022-06-16T10:22:25.715598Z","shell.execute_reply":"2022-06-16T10:22:26.769249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper functions","metadata":{}},{"cell_type":"markdown","source":"**RLE encoding**","metadata":{}},{"cell_type":"code","source":"# Run-length encoding\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    \n    return ' '.join(str(x) for x in runs)\n\ndef rle_decode(mask_rle, shape, color=1):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return\n    Returns numpy array, 1 - mask, 0 - background\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros((shape[0] * shape[1], shape[2]), dtype=np.float32)\n    for lo, hi in zip(starts, ends):\n        img[lo : hi] = color\n    return img.reshape(shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T10:22:26.772557Z","iopub.execute_input":"2022-06-16T10:22:26.772908Z","iopub.status.idle":"2022-06-16T10:22:26.784907Z","shell.execute_reply.started":"2022-06-16T10:22:26.772874Z","shell.execute_reply":"2022-06-16T10:22:26.783769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Metrics**","metadata":{}},{"cell_type":"code","source":"# Metrics\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef iou_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n    return iou\n\ndef dice_loss(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = y_true_f * y_pred_f\n    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n    return 1. - score\n\ndef bce_dice_loss(y_true, y_pred):\n    return binary_crossentropy(tf.cast(y_true, tf.float32), y_pred) + dice_loss(tf.cast(y_true, tf.float32), y_pred)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T10:22:26.786671Z","iopub.execute_input":"2022-06-16T10:22:26.787072Z","iopub.status.idle":"2022-06-16T10:22:26.805988Z","shell.execute_reply.started":"2022-06-16T10:22:26.787012Z","shell.execute_reply":"2022-06-16T10:22:26.805005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data generator**","metadata":{}},{"cell_type":"code","source":"# Images reshaped to (im_height,im_width)\nclass DataGenerator(tf.keras.utils.Sequence):\n    def __init__(self, df, batch_size = BATCH_SIZE, subset=\"train\", shuffle=False):\n        super().__init__()\n        self.df = df\n        self.shuffle = shuffle\n        self.subset = subset\n        self.batch_size = batch_size\n        self.indexes = np.arange(len(df))\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(np.floor(len(self.df) / self.batch_size))\n    \n    def on_epoch_end(self):\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n    \n    def __getitem__(self, index):\n        X = np.empty((self.batch_size,im_height,im_width,3))\n        y = np.empty((self.batch_size,im_height,im_width,3))\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        for i, img_path in enumerate(self.df['path'].iloc[indexes]):\n            w=self.df['width'].iloc[indexes[i]]\n            h=self.df['height'].iloc[indexes[i]]\n            img = self.__load_grayscale(img_path)  # shape: (im_height,im_width,1)\n            X[i,] = img   # broadcast to shape: (im_height,im_width,3)\n            if self.subset == 'train':\n                for k,j in enumerate([\"large_bowel\",\"small_bowel\",\"stomach\"]):\n                    rles = self.df[j].iloc[indexes[i]]\n                    mask = rle_decode(rles, shape=(h, w, 1))\n                    mask = cv2.resize(mask, (im_height,im_width))\n                    y[i,:,:,k] = mask\n        if self.subset == 'train':\n            return X, y\n        else: \n            return X\n        \n        # To do: add data augmentation\n        \n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_ANYDEPTH)\n        dsize = (im_height,im_width)\n        img = cv2.resize(img, dsize)\n        img = img.astype(np.float32) / 255.\n        img = np.expand_dims(img, axis=-1)\n        return img","metadata":{"execution":{"iopub.status.busy":"2022-06-16T10:22:26.807549Z","iopub.execute_input":"2022-06-16T10:22:26.807983Z","iopub.status.idle":"2022-06-16T10:22:26.827508Z","shell.execute_reply.started":"2022-06-16T10:22:26.807948Z","shell.execute_reply":"2022-06-16T10:22:26.826617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test set predictions","metadata":{}},{"cell_type":"markdown","source":"**Load trained model**","metadata":{}},{"cell_type":"code","source":"# Load trained model\ncustom_objects = custom_objects={\n    'dice_coef': dice_coef,\n    'iou_coef': iou_coef,\n    'bce_dice_loss': bce_dice_loss\n}\n\nmodel = load_model('../input/uwmgi-trained-unet-model/UNET_model', custom_objects=custom_objects)\ngc.collect()","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-06-16T10:22:26.83001Z","iopub.execute_input":"2022-06-16T10:22:26.830487Z","iopub.status.idle":"2022-06-16T10:23:27.82786Z","shell.execute_reply.started":"2022-06-16T10:22:26.83043Z","shell.execute_reply":"2022-06-16T10:23:27.826936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Test set predictions**","metadata":{}},{"cell_type":"code","source":"#gcd(80,144)=16=BATCH_SIZE\npred_batches = DataGenerator(test_df, batch_size = BATCH_SIZE, subset=\"test\", shuffle=False)\nnum_batches = int(len(test_df)/BATCH_SIZE)\n\nfor i in range(num_batches):\n    # Predict\n    preds = model.predict(pred_batches[i],verbose=0)     # shape: (16,im_height,im_width,3)\n    \n    # Rle encode\n    for j in range(BATCH_SIZE):\n        for k in range(3):\n            pred_img = cv2.resize(preds[j,:,:,k], (test_df.loc[i*BATCH_SIZE+j,\"width\"], test_df.loc[i*BATCH_SIZE+j,\"height\"]), interpolation=cv2.INTER_NEAREST) # resize probabilities to original shape\n            pred_img = (pred_img>0.5).astype(dtype='uint8')    # classify\n            submission.loc[3*(i*BATCH_SIZE+j)+k,'predicted'] = rle_encode(pred_img)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T10:23:27.838815Z","iopub.execute_input":"2022-06-16T10:23:27.839275Z","iopub.status.idle":"2022-06-16T10:23:53.278425Z","shell.execute_reply.started":"2022-06-16T10:23:27.839244Z","shell.execute_reply":"2022-06-16T10:23:53.277384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Save predictions**","metadata":{}},{"cell_type":"code","source":"submission.to_csv('submission.csv',index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T10:23:53.279812Z","iopub.execute_input":"2022-06-16T10:23:53.280133Z","iopub.status.idle":"2022-06-16T10:23:53.295267Z","shell.execute_reply.started":"2022-06-16T10:23:53.280078Z","shell.execute_reply":"2022-06-16T10:23:53.294398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Acknowledgements:**\n* [UWM - GI Tract Image Segmentation - EDA](https://www.kaggle.com/code/dschettler8845/uwm-gi-tract-image-segmentation-eda) by [Darien Schettler](https://www.kaggle.com/dschettler8845).\n* [UWMGI: UNet Keras [Train] with EDA](https://www.kaggle.com/code/ammarnassanalhajali/uwmgi-unet-keras-train-with-eda) by [Ammar Alhaj Ali\n](https://www.kaggle.com/ammarnassanalhajali).","metadata":{}}]}