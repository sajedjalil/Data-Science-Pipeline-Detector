{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Coco Dataset Notebook**","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/vexxingbanana/sartorius-coco-dataset-notebook","metadata":{}},{"cell_type":"markdown","source":"# **References**","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/dschettler8845/sartorius-segmentation-eda-and-baseline\n\nhttps://www.kaggle.com/ihelon/cell-segmentation-run-length-decoding\n\nhttps://www.kaggle.com/stainsby/fast-tested-rle\n\nhttps://www.kaggle.com/paulorzp/run-length-encode-and-decode\n\nhttps://www.kaggle.com/awsaf49/sartorius-mmdetection-infer\n\nhttps://www.kaggle.com/awsaf49/sartorius-mmdetection-train\n\nhttps://www.kaggle.com/evancofsky/sartorius-torch-lightning-mask-r-cnn/notebook","metadata":{}},{"cell_type":"markdown","source":"Please consider upvoting if you find this helpful. :)","metadata":{}},{"cell_type":"markdown","source":"**Note: This notebook uses an older environment so if you want to use this code, you need to fork this notebook. There were some problems with package versions when I tried to use the latest environment due to cuda version upgrading from 11.0 to 11.1**","metadata":{}},{"cell_type":"markdown","source":"# **Install MMDetection and MMDetection-Compatible Torch**","metadata":{}},{"cell_type":"code","source":"!pip install '/kaggle/input/pytorch-170-cuda-toolkit-110221/torch-1.7.0+cu110-cp37-cp37m-linux_x86_64.whl' --no-deps\n!pip install '/kaggle/input/pytorch-170-cuda-toolkit-110221/torchvision-0.8.1+cu110-cp37-cp37m-linux_x86_64.whl' --no-deps\n!pip install '/kaggle/input/pytorch-170-cuda-toolkit-110221/torchaudio-0.7.0-cp37-cp37m-linux_x86_64.whl' --no-deps","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-16T14:56:16.857656Z","iopub.execute_input":"2022-04-16T14:56:16.858438Z","iopub.status.idle":"2022-04-16T14:57:15.479262Z","shell.execute_reply.started":"2022-04-16T14:56:16.858345Z","shell.execute_reply":"2022-04-16T14:57:15.478406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install '/kaggle/input/mmdetectionv2140/addict-2.4.0-py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/yapf-0.31.0-py2.py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/terminal-0.4.0-py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/terminaltables-3.1.0-py3-none-any.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/mmcv_full-1_3_8-cu110-torch1_7_0/mmcv_full-1.3.8-cp37-cp37m-manylinux1_x86_64.whl' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/pycocotools-2.0.2/pycocotools-2.0.2' --no-deps\n!pip install '/kaggle/input/mmdetectionv2140/mmpycocotools-12.0.3/mmpycocotools-12.0.3' --no-deps\n\n!rm -rf mmdetection\n\n!cp -r /kaggle/input/mmdetectionv2140/mmdetection-2.14.0 /kaggle/working/\n!mv /kaggle/working/mmdetection-2.14.0 /kaggle/working/mmdetection\n%cd /kaggle/working/mmdetection\n!pip install -e .","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-16T14:57:15.482927Z","iopub.execute_input":"2022-04-16T14:57:15.483153Z","iopub.status.idle":"2022-04-16T14:58:07.79942Z","shell.execute_reply.started":"2022-04-16T14:57:15.483123Z","shell.execute_reply":"2022-04-16T14:58:07.798525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Import Libraries** ","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport sklearn\nimport torchvision\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport PIL\nimport json\nfrom PIL import Image, ImageEnhance\nimport albumentations as A\nimport mmdet\nimport mmcv\nfrom albumentations.pytorch import ToTensorV2\nimport seaborn as sns\nimport glob\nfrom pathlib import Path\nimport pycocotools\nfrom pycocotools import mask\nimport numpy.random\nimport random\nimport cv2\nimport re\nfrom mmdet.datasets import build_dataset\nfrom mmdet.models import build_detector\nfrom mmdet.apis import train_detector\nfrom mmdet.apis import inference_detector, init_detector, show_result_pyplot, set_random_seed","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-16T14:58:07.801832Z","iopub.execute_input":"2022-04-16T14:58:07.802325Z","iopub.status.idle":"2022-04-16T14:58:28.586268Z","shell.execute_reply.started":"2022-04-16T14:58:07.802278Z","shell.execute_reply":"2022-04-16T14:58:28.585435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd ..","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:58:28.58842Z","iopub.execute_input":"2022-04-16T14:58:28.588695Z","iopub.status.idle":"2022-04-16T14:58:28.594462Z","shell.execute_reply.started":"2022-04-16T14:58:28.588657Z","shell.execute_reply":"2022-04-16T14:58:28.593789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_WIDTH = 704\nIMG_HEIGHT = 520","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:58:28.595664Z","iopub.execute_input":"2022-04-16T14:58:28.596072Z","iopub.status.idle":"2022-04-16T14:58:28.605747Z","shell.execute_reply.started":"2022-04-16T14:58:28.596025Z","shell.execute_reply":"2022-04-16T14:58:28.60501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Helper Functions**","metadata":{}},{"cell_type":"code","source":"def rle_decode(mask_rle, shape):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)\n\ndef rle_encode(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = img.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\n\ndef flatten_l_o_l(nested_list):\n    \"\"\" Flatten a list of lists \"\"\"\n    return [item for sublist in nested_list for item in sublist]\n\n\ndef load_json_to_dict(json_path):\n    \"\"\" tbd \"\"\"\n    with open(json_path) as json_file:\n        data = json.load(json_file)\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:58:28.607066Z","iopub.execute_input":"2022-04-16T14:58:28.60736Z","iopub.status.idle":"2022-04-16T14:58:28.620134Z","shell.execute_reply.started":"2022-04-16T14:58:28.607326Z","shell.execute_reply":"2022-04-16T14:58:28.619357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_img_and_mask(img_path, annotation, width, height):\n    \"\"\" Capture the relevant image array as well as the image mask \"\"\"\n    img_mask = np.zeros((height, width), dtype=np.uint8)\n    for i, annot in enumerate(annotation): \n        img_mask = np.where(rle_decode(annot, (height, width))!=0, i, img_mask)\n    img = cv2.imread(img_path)[..., ::-1]\n    return img[..., 0], img_mask\n\ndef plot_img_and_mask(img, mask, invert_img=True, boost_contrast=True):\n    \"\"\" Function to take an image and the corresponding mask and plot\n    \n    Args:\n        img (np.arr): 1 channel np arr representing the image of cellular structures\n        mask (np.arr): 1 channel np arr representing the instance masks (incrementing by one)\n        invert_img (bool, optional): Whether or not to invert the base image\n        boost_contrast (bool, optional): Whether or not to boost contrast of the base image\n        \n    Returns:\n        None; Plots the two arrays and overlays them to create a merged image\n    \"\"\"\n    plt.figure(figsize=(20,10))\n    \n    plt.subplot(1,3,1)\n    _img = np.tile(np.expand_dims(img, axis=-1), 3)\n    \n    # Flip black-->white ... white-->black\n    if invert_img:\n        _img = _img.max()-_img\n        \n    if boost_contrast:\n        _img = np.asarray(ImageEnhance.Contrast(Image.fromarray(_img)).enhance(16))\n        \n    plt.imshow(_img)\n    plt.axis(False)\n    plt.title(\"Cell Image\", fontweight=\"bold\")\n    \n    plt.subplot(1,3,2)\n    _mask = np.zeros_like(_img)\n    _mask[..., 0] = mask\n    plt.imshow(mask, cmap='rainbow')\n    plt.axis(False)\n    plt.title(\"Instance Segmentation Mask\", fontweight=\"bold\")\n    \n    merged = cv2.addWeighted(_img, 0.75, np.clip(_mask, 0, 1)*255, 0.25, 0.0,)\n    plt.subplot(1,3,3)\n    plt.imshow(merged)\n    plt.axis(False)\n    plt.title(\"Cell Image w/ Instance Segmentation Mask Overlay\", fontweight=\"bold\")\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:58:28.621436Z","iopub.execute_input":"2022-04-16T14:58:28.621937Z","iopub.status.idle":"2022-04-16T14:58:28.635136Z","shell.execute_reply.started":"2022-04-16T14:58:28.621902Z","shell.execute_reply":"2022-04-16T14:58:28.634353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def polygonFromMask(maskedArr, idx):\n  # adapted from https://github.com/hazirbas/coco-json-converter/blob/master/generate_coco_json.py\n  contours, _ = cv2.findContours(maskedArr, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n  segmentation = []\n  valid_poly = 0\n  for contour in contours:\n  # Valid polygons have >= 6 coordinates (3 points)\n     if contour.size >= 6:\n        segmentation.append(contour.astype(float).flatten().tolist())\n        valid_poly += 1\n  if valid_poly == 0:\n     raise ValueError(idx)\n  return [segmentation]","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:58:28.636074Z","iopub.execute_input":"2022-04-16T14:58:28.638314Z","iopub.status.idle":"2022-04-16T14:58:28.647411Z","shell.execute_reply.started":"2022-04-16T14:58:28.638275Z","shell.execute_reply":"2022-04-16T14:58:28.646587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Model Config**","metadata":{}},{"cell_type":"code","source":"%%writefile labels.txt\nlarge_bowel\nsmall_bowel\nstomach","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:58:28.648701Z","iopub.execute_input":"2022-04-16T14:58:28.649176Z","iopub.status.idle":"2022-04-16T14:58:28.660395Z","shell.execute_reply.started":"2022-04-16T14:58:28.649139Z","shell.execute_reply":"2022-04-16T14:58:28.659583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mmcv import Config\ncfg = Config.fromfile('/kaggle/working/mmdetection/configs/cascade_rcnn/cascade_mask_rcnn_r50_fpn_20e_coco.py')","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:58:28.663109Z","iopub.execute_input":"2022-04-16T14:58:28.663955Z","iopub.status.idle":"2022-04-16T14:58:28.687349Z","shell.execute_reply.started":"2022-04-16T14:58:28.663918Z","shell.execute_reply":"2022-04-16T14:58:28.68672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(cfg.pretty_text)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:58:28.688523Z","iopub.execute_input":"2022-04-16T14:58:28.688793Z","iopub.status.idle":"2022-04-16T14:58:29.267049Z","shell.execute_reply.started":"2022-04-16T14:58:28.688762Z","shell.execute_reply":"2022-04-16T14:58:29.265123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg.dataset_type = 'CocoDataset'\ncfg.classes = '/kaggle/working/labels.txt'\ncfg.data_root = '/kaggle/working'\n\nfor head in cfg.model.roi_head.bbox_head:\n    head.num_classes = 3\n    \ncfg.model.roi_head.mask_head.num_classes=3\n\ncfg.data.test.type = 'CocoDataset'\ncfg.data.test.classes = 'labels.txt'\ncfg.data.test.data_root = '/kaggle/working'\ncfg.data.test.ann_file = '../input/gi-tract-coco-2d-dataset/val_dataset_fold_1.json'\ncfg.data.test.img_prefix = ''\n\ncfg.data.train.type = 'CocoDataset'\ncfg.data.train.data_root = '/kaggle/working'\ncfg.data.train.ann_file = '../input/gi-tract-coco-2d-dataset/train_dataset_fold_1.json'\ncfg.data.train.img_prefix = ''\ncfg.data.train.classes = 'labels.txt'\n\ncfg.data.val.type = 'CocoDataset'\ncfg.data.val.data_root = '/kaggle/working'\ncfg.data.val.ann_file = '../input/gi-tract-coco-2d-dataset/val_dataset_fold_1.json'\ncfg.data.val.img_prefix = ''\ncfg.data.val.classes = 'labels.txt'\n\nalbu_train_transforms = [\n    dict(type='ShiftScaleRotate', shift_limit=0.0625,\n         scale_limit=0.15, rotate_limit=15, p=0.4),\n    dict(type='RandomBrightnessContrast', brightness_limit=0.2,\n         contrast_limit=0.2, p=0.5),\n#     dict(type='IAAAffine', shear=(-10.0, 10.0), p=0.4),\n    dict(type='CLAHE', p=0.5),\n    dict(\n        type=\"OneOf\",\n        transforms=[\n            dict(type=\"GaussianBlur\", p=1.0, blur_limit=7),\n            dict(type=\"MedianBlur\", p=1.0, blur_limit=7),\n        ],\n        p=0.4,\n    ),\n]\n\ncfg.train_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n#     dict(type='Resize', img_scale=[(440, 596), (480, 650), (520, 704), (580, 785), (620, 839)], multiscale_mode='value', keep_ratio=True),\n#     dict(type='Resize', img_scale=[(880, 1192), (960, 130), (1040, 1408), (1160, 1570), (1240, 1678)], multiscale_mode='value', keep_ratio=True),\n    dict(type='Resize', img_scale=[(1333, 800), (1690, 960)]),\n#     dict(type='Resize', img_scale=(1333, 800)),\n    \n    \n\n    dict(type='RandomFlip', flip_ratio=0.5),\n\n    dict(\n        type='Albu',\n        transforms=albu_train_transforms,\n        bbox_params=dict(\n        type='BboxParams',\n        format='pascal_voc',\n        label_fields=['gt_labels'],\n        min_visibility=0.0,\n        filter_lost_elements=True),\n        keymap=dict(img='image', gt_bboxes='bboxes', gt_masks='masks'),\n        update_pad_shape=False,\n        skip_img_without_anno=True),\n    dict(\n        type='Normalize',\n        mean=[128, 128, 128],\n        std=[11.58, 11.58, 11.58],\n        to_rgb=True),\n    dict(type='Pad', size_divisor=32),\n    dict(type='DefaultFormatBundle'), \n    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_masks', 'gt_labels'])\n]\n\ncfg.val_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n#         img_scale=[(880, 1192), (960, 130), (1040, 1408), (1160, 1570), (1240, 1678)],\n        img_scale = [(1333, 800), (1690, 960)],\n#         img_scale=(1333, 800),\n#         img_scale = (520, 704),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[128, 128, 128],\n                std=[11.58, 11.58, 11.58],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\n\n\ncfg.test_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=[(1333, 800), (1690, 960)],\n#         img_scale=(1333, 800),\n        \n#         img_scale = (520, 704),\n        flip=False,\n        transforms=[\n            dict(type='Resize', keep_ratio=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[128, 128, 128],\n                std=[11.58, 11.58, 11.58],\n                to_rgb=True),\n            dict(type='Pad', size_divisor=32),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\n\ncfg.data.train.pipeline = cfg.train_pipeline\ncfg.data.val.pipeline = cfg.val_pipeline\ncfg.data.test.pipeline = cfg.test_pipeline\n\n\n# cfg.model.test_cfg.rcnn.max_per_img = 400\n\ncfg.load_from = '../input/cascade-mask-rcnn-r50/cascade_mask_rcnn_r50_fpn_20e_coco_bbox_mAP-0.419__segm_mAP-0.365_20200504_174711-4af8e66e.pth'\n\ncfg.work_dir = '/kaggle/working/model_output'\n\ncfg.optimizer.lr = 0.02 / 8\ncfg.lr_config = dict(\n    policy='CosineAnnealing', \n    by_epoch=False,\n    warmup='linear', \n    warmup_iters=125, \n    warmup_ratio=0.001,\n    min_lr=1e-07)\n\ncfg.data.samples_per_gpu = 2\ncfg.data.workers_per_gpu = 2\n\ncfg.evaluation.metric = 'segm'\ncfg.evaluation.interval = 1\n\ncfg.checkpoint_config.interval = 1\ncfg.runner.max_epochs = 4\ncfg.log_config.interval = 500\n\ncfg.seed = 0\nset_random_seed(0, deterministic=False)\ncfg.gpu_ids = range(1)\ncfg.fp16 = dict(loss_scale=512.0)\nmeta = dict()\nmeta['config'] = cfg.pretty_text\n\n\n\nprint(f'Config:\\n{cfg.pretty_text}')","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:58:29.26846Z","iopub.execute_input":"2022-04-16T14:58:29.268734Z","iopub.status.idle":"2022-04-16T14:58:30.935236Z","shell.execute_reply.started":"2022-04-16T14:58:29.268698Z","shell.execute_reply":"2022-04-16T14:58:30.934506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Training**","metadata":{}},{"cell_type":"code","source":"datasets = [build_dataset(cfg.data.train)]\nmodel = build_detector(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\nmodel.CLASSES = datasets[0].CLASSES\n\nmmcv.mkdir_or_exist(os.path.abspath(cfg.work_dir))\ntrain_detector(model, datasets, cfg, distributed=False, validate=True, meta=meta)","metadata":{"execution":{"iopub.status.busy":"2022-04-16T14:58:30.936308Z","iopub.execute_input":"2022-04-16T14:58:30.936944Z","iopub.status.idle":"2022-04-16T15:04:32.107897Z","shell.execute_reply.started":"2022-04-16T14:58:30.936901Z","shell.execute_reply":"2022-04-16T15:04:32.106621Z"},"trusted":true},"execution_count":null,"outputs":[]}]}