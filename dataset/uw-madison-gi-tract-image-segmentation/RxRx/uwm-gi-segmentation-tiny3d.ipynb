{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **[Gastro intestinal tract image segmentation](https://www.kaggle.com/competitions/uw-madison-gi-tract-image-segmentation/)**\n## **Author: [Dr. Rahul Remanan](https://www.linkedin.com/in/rahulremanan/)**\n## **CEO, [Moad Computer](http://www.moad.computer/)**","metadata":{"id":"06ec3b7f","papermill":{"duration":0.027838,"end_time":"2022-06-22T11:14:11.488261","exception":false,"start_time":"2022-06-22T11:14:11.460423","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Configuration","metadata":{"id":"af4fca0e","papermill":{"duration":0.025016,"end_time":"2022-06-22T11:14:11.59941","exception":false,"start_time":"2022-06-22T11:14:11.574394","status":"completed"},"tags":[]}},{"cell_type":"code","source":"ROOT_DIR = './'\nUPDATE_WEIGHTS = False # True # \nCLOUD_DIR = '/content/drive/'","metadata":{"id":"d462f91a","papermill":{"duration":0.039871,"end_time":"2022-06-22T11:14:11.664467","exception":false,"start_time":"2022-06-22T11:14:11.624596","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CONFIG():\n  ##############################################################################\n    \n  #--------------------------- Change settings below --------------------------#\n\n  ##############################################################################\n  KAGGLE_USERNAME = 'remananr' # Your Kaggle username\n\n  GCS_BUCKET = 'gs://kds-f4db3021aead4b633448e4d13a5b9b4df91491bdf9bb3e61b37890f8' # Set the latest GCS bucket address\n\n  SYNC_DIR = 'uwm-gi-segmentation-external-weights' # Your Kaggle sync dataset\n  SYNC_ID = 'uwm gi segmentation external weights'  # Your Kaggle sync dataset title\n\n  WEIGHTS_DIR = 'uwm-gi-segmentation-external-weights'\n  # WEIGHTS_DIR = 'uwm-gi-tiny3d-segmentation-weights'\n\n  GCP_TPU_WORKER = 'tpu_name'      # Your GCP worker address\n  GCP_ZONE = 'us-east1-b'          # Your GCP zone\n  GCP_PROJECT = 'gcp_project_name' # Your GCP project name\n\n  ##############################################################################\n\n  KAGGLE_KERNEL = False\n  COLAB_KERNEL = False\n\n  NOTEBOOK_ID = 'uw-madison-gi-tract-image-segmentation'\n\n  SEED = 239 # 384 # 246 #\n\n  ENABLE_TRAINING = True # False #\n  TRAIN_BACKBONE = True\n\n  TRAIN_VAL_SPLIT = True\n\n  FOLD_SELECTION = 1 # None #\n\n  SAVE_MASKS = False\n\n  VERBOSE = False\n  TF_VERBOSITY = '3'\n\n  DEBUG = False\n\n  DATA_DIR = f'{ROOT_DIR}/{NOTEBOOK_ID}'\n  TRAIN_DIR = 'train'\n  TEST_DIR = 'test'\n\n  TRAIN_CSV = 'train.csv'\n  SUBMISSION_CSV = 'sample_submission.csv'\n\n  CUDA_MALLOC = 'cuda_malloc_async'\n\n  TPU = None\n  USE_GCP_TPU = False\n    \n  REPLICA_FACTOR = 4\n\n  GOOGLE_DRIVE = f'{CLOUD_DIR}/MyDrive/Kaggle/{NOTEBOOK_ID}'\n  ENABLE_GOOGLE_DRIVE_CHECKPOINT = True\n\n  USE_JIT = False\n\n  CLASSES = ['Large Bowel', 'Small Bowel', 'Stomach']\n  SHORTFORM_CLASSES = ['lb', 'sb', 'st']\n\n  STYLE = 'multiclass'\n\n  IMAGE_SIZE = (128, 128) # (256, 256) # (512, 512) # (576, 576) # \n  MASK_SIZE  = IMAGE_SIZE # (512, 512) # (256, 256) # (576, 576) # \n    \n  STRIDES = [2, -2]  \n\n  BATCH_SIZE = 128 # 32 # 8 # 16 # 24 # 3 # 4 # 64 # 96 # 256 # \n  DEBUG_BATCH_SIZE = 3\n  TEST_BATCH_SIZE = 3\n\n  SHUFFLE_BUFFER = max(BATCH_SIZE*25, 500)\n  OPTIMUM_SHUFFLE = False # True # \n\n  FLIP_HORIZONTAL = False # True #\n  FLIP_VERTICAL = False # True #\n  RANDOM_BRIGHTNESS = False # True #\n  RANDOM_CONTRAST = False # True #\n  RANDOM_GAMMA = False\n  RANDOM_HUE = False # True #\n  RANDOM_SATURATION = False # True #\n\n  NUM_FOLDS = 3\n\n  EPOCHS = 6 # 1 # 8 # 12 # 32 #\n  OPTIMIZER ='Adam' # 'Adagrad' # \n  LEARNING_RATE = 7.5e-4 # 7.5e-3 # 1e-4 # 1e-3 # 1e-8 # 1e-5 # 7.5e-5 # 1.5e-5 # \n\n  EVAL_FUNCTION = 'val_loss' # 'val_iou_coef' 'val_acc'  # \n  EVAL_FUNCTION_MODE = 'min' # 'max' #\n\n  METRICS = ['acc']\n  IOU_METRICS = True\n  IOU_LOSS = False\n\n  DTYPE = 'float32'\n  \n  PRETRAINED_WEIGHTS_DIR = f'{ROOT_DIR}/{SYNC_DIR}/no_top'\n  PRETRAINED_WEIGHTS = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n  DEFAULT_PRETRAINED_WEIGHTS = None # 'imagenet' #\n\n  MODEL_SUMMARY = 'summary' # 'plot' #\n\n  MODEL_DIM = f'{IMAGE_SIZE[0]}x{IMAGE_SIZE[1]}x3'\n  MODEL_ID = 'tiny3d'\n    \n  MODEL_NAME = f'{MODEL_ID}_{MODEL_DIM}_{STYLE}'   \n  \n  SAVED_WEIGHTS_DIR = f'{ROOT_DIR}/{WEIGHTS_DIR}/'  \n  SAVED_WEIGHTS = f'{MODEL_NAME}'\n\n  SPEED_SUB = True\n  SPEED_SUB_SAMPLES = BATCH_SIZE\n    \n  ENABLE_TTA = False\n    \n  CLEANUP_FREQUENCY = 250","metadata":{"id":"95574f9f","papermill":{"duration":0.053174,"end_time":"2022-06-22T11:14:11.743378","exception":false,"start_time":"2022-06-22T11:14:11.690204","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CONFIG.BATCH_SIZE = CONFIG.BATCH_SIZE if CONFIG.ENABLE_TRAINING else \\\n                    CONFIG.DEBUG_BATCH_SIZE if CONFIG.DEBUG else 1\nif CONFIG.VERBOSE: print(f'Setting batch size to: {CONFIG.BATCH_SIZE}')","metadata":{"id":"8c13b76d","papermill":{"duration":0.03568,"end_time":"2022-06-22T11:14:11.804817","exception":false,"start_time":"2022-06-22T11:14:11.769137","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setup functions","metadata":{"id":"afbad815","papermill":{"duration":0.025697,"end_time":"2022-06-22T11:14:11.857051","exception":false,"start_time":"2022-06-22T11:14:11.831354","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os, psutil\ndef auto_environment():\n  kaggle_kernel, colab_kernel = False, False\n  try:\n    from kaggle_datasets import KaggleDatasets\n    kaggle_kernel=True\n    print('Running in Kaggle kernel mode ...')\n    root_dir = '/kaggle/input/'\n  except:\n    kaggle_kernel=False\n    root_dir = './'\n  try:\n    import google.colab\n    colab_kernel=True\n    print('Running in Google Colab mode ...')\n    root_dir = '/content/'\n  except:\n    colab_kernel=False\n  return kaggle_kernel, colab_kernel, root_dir\n\ndef auto_setup():\n  try:\n    import tensorflow_addons as tfa\n    print('Skipping setup ...')\n    return False\n  except:\n    return True\n\ndef auto_data_download(google_drive:str, notebook_id:str):\n  if os.path.exists(os.path.join(google_drive, f'{notebook_id}.zip')):\n    print('Skipping data download ...')\n    return False\n  else:\n    print('Configured to download raw data from Kaggle ...')\n    return True    \n\ndef mount_google_drive(mount_dir:str='/content/drive/'):\n  from google.colab import drive\n  drive.mount(mount_dir)\n\ndef linux_shell(cmd_list:list, verbose:bool=False):\n  for cmd in cmd_list:\n    if verbose:\n      print(f'Executing linux command: {cmd}')\n    os.system(cmd)\n    \ndef clear_memory(num_tries:int=2, clear_session:bool=True):\n  for i in range(num_tries):\n    _ = gc.collect()\n  if clear_session: tf.keras.backend.clear_session()\n  _ = gc.collect()\n\ndef list_global_var():\n  for var in globals(): print(str(var))\n\nclass Dict_to_Class:\n  def __init__(self, **entries):\n    self.__dict__.update(entries)\n\ndef memory_utilization():\n  print('Current memory utilization: {}% ...'.format(psutil.virtual_memory().percent))\n\ndef save_pickle(var, file:str='file.pkl', protocol=-1, \n                compression:bool=True, \n                delete:bool=True, \n                verbose:bool=False):\n  if verbose: print(f'Memory utilization: \\n{memory_utilization()}')\n  #==Create Pickle dump===\n  if compression:\n     with gzip.open(file, 'wb') as f:\n       pickle.dump(var, f, protocol)\n  else:\n    pickle.dump(var, open(file,'wb'))\n  if verbose: print(f'Memory utilization: \\n{memory_utilization()}')\n  #===Delete the unused variable from memory===\n  if delete:\n    del var\n    _ = gc.collect()\n    if verbose: print(f'Memory utilization after deletion: \\n{memory_utilization()}')\n\ndef load_pickle(file:str, compression:bool=True):\n  if compression:\n    with gzip.open(file, 'rb') as f:\n      return pickle.load(f)\n  else:\n    return pickle.load(open(file, 'rb'))","metadata":{"id":"0e9741c7","papermill":{"duration":0.058644,"end_time":"2022-06-22T11:14:11.949294","exception":false,"start_time":"2022-06-22T11:14:11.89065","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Autodetect kernel environment","metadata":{"id":"ce3c1465","papermill":{"duration":0.025325,"end_time":"2022-06-22T11:14:12.009671","exception":false,"start_time":"2022-06-22T11:14:11.984346","status":"completed"},"tags":[]}},{"cell_type":"code","source":"CONFIG.KAGGLE_KERNEL, CONFIG.COLAB_KERNEL, ROOT_DIR = auto_environment()\nCONFIG.DATA_DIR = f'{ROOT_DIR}/{CONFIG.NOTEBOOK_ID}'  \nCONFIG.PRETRAINED_WEIGHTS_DIR = f'{ROOT_DIR}/{CONFIG.SYNC_DIR}/no_top'  \nCONFIG.SAVED_WEIGHTS_DIR = f'{ROOT_DIR}/{CONFIG.WEIGHTS_DIR}'\nif not CONFIG.KAGGLE_KERNEL and CONFIG.COLAB_KERNEL:\n  mount_google_drive(mount_dir=CLOUD_DIR)","metadata":{"id":"b5d6069b","papermill":{"duration":0.041852,"end_time":"2022-06-22T11:14:12.078397","exception":false,"start_time":"2022-06-22T11:14:12.036545","status":"completed"},"tags":[],"outputId":"995fe6e6-b74e-47d5-e6b8-c02e10db43ee","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SETUP, DOWNLOAD_RAW_DATA = False, False  \nif not CONFIG.KAGGLE_KERNEL:\n  SETUP, DOWNLOAD_RAW_DATA = auto_setup(), auto_data_download(CONFIG.GOOGLE_DRIVE, \n                                                              CONFIG.NOTEBOOK_ID)","metadata":{"id":"84e9fa81","papermill":{"duration":0.035049,"end_time":"2022-06-22T11:14:12.14068","exception":false,"start_time":"2022-06-22T11:14:12.105631","status":"completed"},"tags":[],"outputId":"342fc645-8587-4100-f72b-18ccae50aa6f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup and data management outside Kaggle","metadata":{"id":"662b835f","papermill":{"duration":0.025188,"end_time":"2022-06-22T11:14:12.192547","exception":false,"start_time":"2022-06-22T11:14:12.167359","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import json\nif (not CONFIG.KAGGLE_KERNEL) and SETUP:\n  if not os.path.exists(f'{ROOT_DIR}/dataset-metadata.json'):\n    print('Auto generating Kaggle sync folder metadata ...')\n    print(f'title : {CONFIG.SYNC_ID} ...')\n    print(f'id    : {CONFIG.KAGGLE_USERNAME}/{CONFIG.SYNC_DIR} ...')\n    with open(f'{ROOT_DIR}/dataset-metadata.json', 'w') as f:\n      json.dump({'title' : CONFIG.SYNC_ID,\n                 'id'    : f'{CONFIG.KAGGLE_USERNAME}/{CONFIG.SYNC_DIR}'}, f)","metadata":{"id":"c78bc8d7","papermill":{"duration":0.034736,"end_time":"2022-06-22T11:14:12.252816","exception":false,"start_time":"2022-06-22T11:14:12.21808","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nif (not CONFIG.KAGGLE_KERNEL) and SETUP:\n  !mkdir ~/.kaggle/  \n  dir_list = [f'{ROOT_DIR}/{CONFIG.NOTEBOOK_ID}/',\n              f'{ROOT_DIR}/{CONFIG.SYNC_DIR}/',\n              f'{ROOT_DIR}/{CONFIG.WEIGHTS_DIR}/']\n  for dir in dir_list: os.makedirs(dir, exist_ok=True)\n\n  setup_cmds = ['cp ./kaggle.json ~/.kaggle/kaggle.json',\n                'chmod 600 ~/.kaggle/kaggle.json',\n                'python3 -m pip uninstall -q -y kaggle',\n                'python3 -m pip install -q kaggle==1.5.12']\n\n  if DOWNLOAD_RAW_DATA:\n    setup_cmds.extend(\n      [f'kaggle competitions download -c {CONFIG.NOTEBOOK_ID} --force -p {ROOT_DIR}',\n       f'unzip {ROOT_DIR}/{CONFIG.NOTEBOOK_ID}.zip -d {ROOT_DIR}/{CONFIG.NOTEBOOK_ID}']\n      )\n    if CONFIG.COLAB_KERNEL:\n      setup_cmds.extend(\n        [f'mkdir {CLOUD_DIR}/MyDrive/Kaggle/{CONFIG.NOTEBOOK_ID}',\n         f'cp {ROOT_DIR}/{CONFIG.NOTEBOOK_ID}.zip {CONFIG.GOOGLE_DRIVE}']\n         )\n    setup_cmds.append(f'rm {ROOT_DIR}/{CONFIG.NOTEBOOK_ID}.zip')\n  elif CONFIG.COLAB_KERNEL:\n    zip_file = f'{CONFIG.GOOGLE_DRIVE}/{CONFIG.NOTEBOOK_ID}.zip'\n    setup_cmds.append(\n        f'unzip {zip_file} -d {ROOT_DIR}/{CONFIG.NOTEBOOK_ID}'\n        )\n\n  if UPDATE_WEIGHTS or DOWNLOAD_RAW_DATA: \n    if CONFIG.SYNC_DIR is not None:\n      kaggle_sync_ds = f'{CONFIG.KAGGLE_USERNAME}/{CONFIG.SYNC_DIR}'  \n      setup_cmds.extend(\n        [f'kaggle datasets download -d {kaggle_sync_ds} --force -p {ROOT_DIR}',\n         f'unzip -q {ROOT_DIR}/{CONFIG.SYNC_DIR}.zip -d {ROOT_DIR}/{CONFIG.SYNC_DIR}']\n         )\n    if CONFIG.COLAB_KERNEL:\n      setup_cmds.append(\n        f'cp {ROOT_DIR}/{CONFIG.SYNC_DIR}.zip {CONFIG.GOOGLE_DRIVE}'\n        )  \n    setup_cmds.append(f'rm {ROOT_DIR}/{CONFIG.SYNC_DIR}.zip')  \n    if CONFIG.WEIGHTS_DIR is not None:\n      kaggle_wt_ds = f'{CONFIG.KAGGLE_USERNAME}/{CONFIG.WEIGHTS_DIR}'  \n      setup_cmds.extend(\n        [f'kaggle datasets download -d {kaggle_wt_ds} --force -p {ROOT_DIR}',\n         f'unzip -q {ROOT_DIR}/{CONFIG.WEIGHTS_DIR}.zip -d {ROOT_DIR}/{CONFIG.WEIGHTS_DIR}']\n         )\n      if CONFIG.COLAB_KERNEL:\n        setup_cmds.append(\n          f'cp {ROOT_DIR}/{CONFIG.WEIGHTS_DIR}.zip {CONFIG.GOOGLE_DRIVE}'\n          )\n      setup_cmds.append(f'rm {ROOT_DIR}/{CONFIG.WEIGHTS_DIR}.zip')\n  if os.path.exists(f'{ROOT_DIR}/kaggle.json'):\n    linux_shell(setup_cmds)\n  else:\n    raise OSError(\n      f'Kaggle config JSON not found. Upload kaggle.json to: {ROOT_DIR} ...'\n      )","metadata":{"id":"da5a723d","papermill":{"duration":0.04423,"end_time":"2022-06-22T11:14:12.323289","exception":false,"start_time":"2022-06-22T11:14:12.279059","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nif SETUP and not CONFIG.KAGGLE_KERNEL:\n  metadata_file = f'{ROOT_DIR}/dataset-metadata.json'\n  sync_dir = f'{ROOT_DIR}/{CONFIG.SYNC_DIR}'\n  if not os.path.exists(metadata_file):\n    metadata_warnings = [f'\\n\\tMetadata file: {metadata_file} not found ...',\n                         f'\\n\\tUnable to sync {sync_dir} to Kaggle ...',\n                         f'\\n\\tCreate {metadata_file} to enable sync to Kaggle ...']\n    warnings.warn(''.join(metadata_warnings))\n  upload_dir_cmds = [f'kaggle datasets init -p {sync_dir}',\n                     f'rm {sync_dir}/dataset-metadata.json',\n                     f'cp {metadata_file} {sync_dir}']\n  linux_shell(upload_dir_cmds)","metadata":{"id":"a195a9d7","papermill":{"duration":0.034992,"end_time":"2022-06-22T11:14:12.384113","exception":false,"start_time":"2022-06-22T11:14:12.349121","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import libraries","metadata":{"id":"b218b9fa","papermill":{"duration":0.026741,"end_time":"2022-06-22T11:14:12.437147","exception":false,"start_time":"2022-06-22T11:14:12.410406","status":"completed"},"tags":[]}},{"cell_type":"code","source":"try:\n  from kaggle_datasets import KaggleDatasets\n  CONFIG.KAGGLE_KERNEL = True\nexcept:\n  print('Running outside of Kaggle ...')\n  print('Ensure data and dependent libraries are already setup ...')\n  CONFIG.KAGGLE_KERNEL = False","metadata":{"id":"27e14c8d","papermill":{"duration":0.035219,"end_time":"2022-06-22T11:14:12.49877","exception":false,"start_time":"2022-06-22T11:14:12.463551","status":"completed"},"tags":[],"outputId":"db4835a6-ee8c-4293-ba7b-62caf3df3bc3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re, gc, os, io, sys, ast, gzip, time, math, json, string, shutil, random, logging, \\\n       urllib, pickle, zipfile, sklearn, IPython, imageio, hashlib, requests, warnings\n\nfrom glob import glob\nfrom pathlib import Path\nfrom datetime import datetime\nfrom collections import Counter\nfrom json import JSONDecodeError\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold\nfrom sklearn.preprocessing import RobustScaler, PolynomialFeatures","metadata":{"id":"a3421ac5","papermill":{"duration":1.346157,"end_time":"2022-06-22T11:14:13.870703","exception":false,"start_time":"2022-06-22T11:14:12.524546","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n  from pandarallel import pandarallel; pandarallel.initialize();\nexcept:\n  print('Not importing pandarallel ...')","metadata":{"id":"5ff9fc44","papermill":{"duration":0.102184,"end_time":"2022-06-22T11:14:13.99848","exception":false,"start_time":"2022-06-22T11:14:13.896296","status":"completed"},"tags":[],"outputId":"ec1806d8-70db-458d-ad8d-70c04f84a9c9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Set CUDA malloc environment variable","metadata":{"id":"9fd0b02f","papermill":{"duration":0.025426,"end_time":"2022-06-22T11:14:14.050097","exception":false,"start_time":"2022-06-22T11:14:14.024671","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def set_cuda_malloc_env(malloc):\n  os.environ['TF_GPU_ALLOCATOR']=malloc\n\ndef set_tf_verbosity(verbose):\n  os.environ['AUTOGRAPH_VERBOSITY'] = '0'  \n  os.environ['TF_CPP_MIN_LOG_LEVEL'] = verbose  \n  logging.getLogger('tensorflow').setLevel(logging.FATAL)\n  logging.getLogger('tensorflow').disabled = True  \n  import tensorflow as tf\n  tf.autograph.set_verbosity(0)\n  tf.get_logger().setLevel(logging.FATAL)  \n  tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.FATAL)  # or any {DEBUG, INFO, WARN, ERROR, FATAL}  \n\nset_cuda_malloc_env(CONFIG.CUDA_MALLOC)\nset_tf_verbosity(CONFIG.TF_VERBOSITY)","metadata":{"id":"5af0c527","papermill":{"duration":8.719264,"end_time":"2022-06-22T11:14:22.796209","exception":false,"start_time":"2022-06-22T11:14:14.076945","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Machine learning imports","metadata":{"id":"d4116357","papermill":{"duration":0.025909,"end_time":"2022-06-22T11:14:22.848296","exception":false,"start_time":"2022-06-22T11:14:22.822387","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if SETUP and not CONFIG.KAGGLE_KERNEL: \n  linux_shell(['python3 -m pip install tensorflow-addons'])","metadata":{"id":"1b24386d","papermill":{"duration":0.042748,"end_time":"2022-06-22T11:14:22.920634","exception":false,"start_time":"2022-06-22T11:14:22.877886","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn, numpy as np, pandas as pd, tensorflow as tf, \\\n       tensorflow_hub as tfhub, tensorflow_addons as tfa\npd.options.mode.chained_assignment = None\n\nfrom tensorflow.keras import backend as K\nfrom tensorflow.python.autograph.impl.api import tf_convert\nfrom tensorflow.python.autograph.core.ag_ctx import control_status_ctx","metadata":{"id":"7ca548d0","papermill":{"duration":1.757648,"end_time":"2022-06-22T11:14:24.714465","exception":false,"start_time":"2022-06-22T11:14:22.956817","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Image processing and visualization imports","metadata":{"id":"d51cf768","papermill":{"duration":0.025185,"end_time":"2022-06-22T11:14:24.765296","exception":false,"start_time":"2022-06-22T11:14:24.740111","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import cv2, PIL, plotly,matplotlib,           \\\n       seaborn as sns,                        \\\n       plotly.express as px,                  \\\n       matplotlib.pyplot as plt,              \\\n       plotly.graph_objects as go,            \\\n       matplotlib.patches as patches,         \\\n       plotly.io as pio; print(pio.renderers)\n\nfrom PIL import Image, ImageEnhance\nfrom tqdm.notebook import tqdm; tqdm.pandas()\nfrom matplotlib.patches import Rectangle\nfrom matplotlib.colors import ListedColormap\nfrom matplotlib import animation, rc; rc('animation', html='jshtml')","metadata":{"id":"4fbdbab5","papermill":{"duration":1.674563,"end_time":"2022-06-22T11:14:26.465295","exception":false,"start_time":"2022-06-22T11:14:24.790732","status":"completed"},"tags":[],"outputId":"69bd27b2-1d70-4087-e73b-13a8cfe5330c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Version info for machine learning libraries","metadata":{"id":"70faf4af","papermill":{"duration":0.026282,"end_time":"2022-06-22T11:14:26.518896","exception":false,"start_time":"2022-06-22T11:14:26.492614","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class mlLibs_info():\n  def __init__(self, ml_libs_info):\n    self.ml_libs_info = ml_libs_info\n  def _formatter(self, k, v):\n    return '\\n\\t\\tâ€“ {:>30} version: {} {:>8}'.format(k,' ',v)\n  def _mlLibs_info(self):\n    for k in self.ml_libs_info:\n      print(self._formatter(k, self.ml_libs_info[k]))\n  def __call__(self):\n    self._mlLibs_info()\n\nmlLibs_info( {'Numpy'             : np.__version__,\n              'SKLearn'           : sklearn.__version__,\n              'MatPlotLib'        : matplotlib.__version__,\n              'Tensorflow'        :  tf.__version__,\n              'Tensorflow Hub'    : tfhub.__version__,\n              'Tensorflow Addons' : tfa.__version__} )()","metadata":{"id":"17edd933","papermill":{"duration":0.039118,"end_time":"2022-06-22T11:14:26.586406","exception":false,"start_time":"2022-06-22T11:14:26.547288","status":"completed"},"tags":[],"outputId":"0350ad4f-6c4e-47e6-d552-962410b9b8fb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setting seed value for reproducibility","metadata":{"id":"89ecb589","papermill":{"duration":0.025321,"end_time":"2022-06-22T11:14:26.639124","exception":false,"start_time":"2022-06-22T11:14:26.613803","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def set_seed(seed:int):\n  ''' Setting seeds for reproducibility '''\n  print(f'\\n... Setting seeds using: {seed} ...')\n  os.environ['PYTHONHASHSEED'] = str(seed)\n  random.seed(seed)\n  np.random.seed(seed)\n  tf.random.set_seed(seed)\n\nset_seed(CONFIG.SEED)","metadata":{"id":"5a9b1ec9","papermill":{"duration":0.03608,"end_time":"2022-06-22T11:14:26.700891","exception":false,"start_time":"2022-06-22T11:14:26.664811","status":"completed"},"tags":[],"outputId":"c3ee7aec-82d2-49d2-b72d-ffe46f2d119e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Heterogeneous compute","metadata":{"id":"8c865af2","papermill":{"duration":0.025342,"end_time":"2022-06-22T11:14:26.751834","exception":false,"start_time":"2022-06-22T11:14:26.726492","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def gcp_tpu_setup():\n  return tf.distribute.cluster_resolver.TPUClusterResolver(\n           tpu=CONFIG.GCP_TPU_WORKER, \n           zone=CONFIG.GCP_ZONE, \n           project=CONFIG.GCP_PROJECT\n           )","metadata":{"id":"da53e20d","papermill":{"duration":0.034183,"end_time":"2022-06-22T11:14:26.812026","exception":false,"start_time":"2022-06-22T11:14:26.777843","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def heterogeneous_compute(TPU):\n  tpu, gpu, cpu = False, False, True\n\n  if TPU is not None and TPU:\n    print(f'\\n... Heterogeneous compute using TPU - {TPU.master()}...')\n    try:\n      tf.config.experimental_connect_to_cluster(TPU)\n      tf.tpu.experimental.initialize_tpu_system(TPU)\n      strategy = tf.distribute.TPUStrategy(TPU)\n      tpu = True\n    except:\n      tpu = False\n      strategy = tf.distribute.get_strategy()\n  else:\n    try:\n      physical_devices = tf.config.list_physical_devices('GPU')\n    except:\n      physical_devices = []\n    if len(physical_devices) >= 1:\n      print(f'\\n... Heterogeneous compute using GPU ...')\n      gpu = True\n    else:\n      print(f'\\n... Running on CPU ...')\n      cpu = True\n    try:\n      tf.config.experimental.set_memory_growth(physical_devices[0], True)\n    except:\n      warnings.warn('\\nFailed to set device memory growth ...')  \n    strategy = tf.distribute.get_strategy()\n\n  num_replicas = strategy.num_replicas_in_sync  \n  print(f'... Number of replicas: {num_replicas} ...\\n')\n  print(f'\\n... Heterogeneous computation setup finished ...\\n')\n\n  return tpu, gpu, cpu, strategy","metadata":{"id":"8663bd12","papermill":{"duration":0.037537,"end_time":"2022-06-22T11:14:26.87527","exception":false,"start_time":"2022-06-22T11:14:26.837733","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if (CONFIG.KAGGLE_KERNEL and CONFIG.TPU is None) or CONFIG.COLAB_KERNEL:\n  try:\n    CONFIG.TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  \n  except:\n    CONFIG.TPU = None\nelif CONFIG.USE_GCP_TPU:\n  CONFIG.TPU = gcp_tpu_setup()\n\ntpu, gpu, cpu, strategy = heterogeneous_compute(CONFIG.TPU)","metadata":{"id":"4c035df6","papermill":{"duration":0.050363,"end_time":"2022-06-22T11:14:26.952066","exception":false,"start_time":"2022-06-22T11:14:26.901703","status":"completed"},"tags":[],"outputId":"92300a61-1464-49bf-c29c-bce292d35fe4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dynamically allocate batch size","metadata":{"id":"b467fa14","papermill":{"duration":0.02558,"end_time":"2022-06-22T11:14:27.003412","exception":false,"start_time":"2022-06-22T11:14:26.977832","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def batch_size_alloc(batch_size, strategy, replica_factor=4, verbose=True):\n  num_replicas = strategy.num_replicas_in_sync\n  opt_batch_size = num_replicas * replica_factor\n  \n  if batch_size%num_replicas==0:\n    batch_size = batch_size\n  elif batch_size < opt_batch_size and batch_size > num_replicas:\n    batch_size = (batch_size // num_replicas) * replica_factor\n  elif batch_size < num_replicas:\n    batch_size = num_replicas\n  else:\n    batch_size = (batch_size // num_replicas) * num_replicas\n    \n  if verbose:\n    print(f'Setting batch size to: {batch_size} ...')\n    \n  return batch_size   ","metadata":{"id":"6eb9edc5","papermill":{"duration":0.03554,"end_time":"2022-06-22T11:14:27.065031","exception":false,"start_time":"2022-06-22T11:14:27.029491","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if tpu:\n  CONFIG.BATCH_SIZE = batch_size_alloc(CONFIG.BATCH_SIZE, strategy, \n                                       replica_factor=CONFIG.REPLICA_FACTOR,\n                                       verbose=CONFIG.VERBOSE)\n  print(f'Setting batch size to {CONFIG.BATCH_SIZE} ...')","metadata":{"id":"97085a99","papermill":{"duration":0.033963,"end_time":"2022-06-22T11:14:27.125745","exception":false,"start_time":"2022-06-22T11:14:27.091782","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setting-up storage bucket","metadata":{"id":"891c21c2","papermill":{"duration":0.026057,"end_time":"2022-06-22T11:14:27.177929","exception":false,"start_time":"2022-06-22T11:14:27.151872","status":"completed"},"tags":[]}},{"cell_type":"code","source":"try:\n  GCS_BUCKET = KaggleDatasets().get_gcs_path(CONFIG.NOTEBOOK_ID)\n  print(f'... GCS bucket address: {GCS_BUCKET} ...')\nexcept:\n  GCS_BUCKET = CONFIG.GCS_BUCKET  \nif tpu:\n  CONFIG.DATA_DIR = GCS_BUCKET  \n  save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n  load_locally = tf.saved_model.LoadOptions(experimental_io_device='/job:localhost')\nelse:\n  save_locally, load_locally = None, None\n\nprint(f'\\n... Data directory:\\n\\t--> {CONFIG.DATA_DIR}')\nprint(f'\\n... Directory listing:')\nfiles = tf.io.gfile.glob(os.path.join(CONFIG.DATA_DIR, '*'))\nif len(files)==0: raise OSError('Unable to read training files. Try updating \"CONFIG.GCS_BUCKET\" address ...')\nfor file in files: print(f'\\t--> {file}')","metadata":{"id":"3e40f66f","papermill":{"duration":20.082531,"end_time":"2022-06-22T11:14:47.286732","exception":false,"start_time":"2022-06-22T11:14:27.204201","status":"completed"},"tags":[],"outputId":"0e95f103-7be6-4f51-8152-16a9a13d7168","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## JIT settings","metadata":{"id":"5c63c50b","papermill":{"duration":0.026273,"end_time":"2022-06-22T11:14:47.339536","exception":false,"start_time":"2022-06-22T11:14:47.313263","status":"completed"},"tags":[]}},{"cell_type":"code","source":"try:\n  tf.config.optimizer.set_jit(CONFIG.USE_JIT)\nexcept:\n  print('Failed to set TF JIT values ...')","metadata":{"id":"4c128383","papermill":{"duration":0.034497,"end_time":"2022-06-22T11:14:47.400749","exception":false,"start_time":"2022-06-22T11:14:47.366252","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read training data","metadata":{"id":"0829b969","papermill":{"duration":0.025586,"end_time":"2022-06-22T11:14:47.452827","exception":false,"start_time":"2022-06-22T11:14:47.427241","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_dir = os.path.join(CONFIG.DATA_DIR, CONFIG.TRAIN_DIR)\ntrain_csv = os.path.join(CONFIG.DATA_DIR, CONFIG.TRAIN_CSV)\ntest_dir  = os.path.join(CONFIG.DATA_DIR, CONFIG.TEST_DIR)\nsub_csv   = os.path.join(CONFIG.DATA_DIR, CONFIG.SUBMISSION_CSV)","metadata":{"id":"918d300a","papermill":{"duration":0.034496,"end_time":"2022-06-22T11:14:47.513239","exception":false,"start_time":"2022-06-22T11:14:47.478743","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get train and test image file-paths","metadata":{"id":"76283dff","papermill":{"duration":0.025629,"end_time":"2022-06-22T11:14:47.564956","exception":false,"start_time":"2022-06-22T11:14:47.539327","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if tpu and CONFIG.ENABLE_TRAINING:\n  all_train_images = tf.io.gfile.glob(f'{train_dir}/*/*/*/*.png')\n  all_test_images = tf.io.gfile.glob(f'{test_dir}/*/*/*/*.png')\nelse:\n  all_train_images = glob(os.path.join(train_dir, '**', '*.png'), recursive=True)\n  all_test_images = glob(os.path.join(test_dir, '**', '*.png'), recursive=True)\nprint(len(all_train_images), len(all_test_images))","metadata":{"id":"cd7bf59f","papermill":{"duration":4.373366,"end_time":"2022-06-22T11:14:51.964434","exception":false,"start_time":"2022-06-22T11:14:47.591068","status":"completed"},"tags":[],"outputId":"69878bec-3081-4107-e837-52aed8f63257","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Determine whether the environment contains test data","metadata":{"id":"6812f183","papermill":{"duration":0.026349,"end_time":"2022-06-22T11:14:52.018161","exception":false,"start_time":"2022-06-22T11:14:51.991812","status":"completed"},"tags":[]}},{"cell_type":"code","source":"CONFIG.DEBUG = CONFIG.DEBUG or len(all_test_images)==0","metadata":{"id":"e235d1df","papermill":{"duration":0.035156,"end_time":"2022-06-22T11:14:52.079492","exception":false,"start_time":"2022-06-22T11:14:52.044336","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read train and submission files","metadata":{"id":"9c37c1d7","papermill":{"duration":0.026027,"end_time":"2022-06-22T11:14:52.131865","exception":false,"start_time":"2022-06-22T11:14:52.105838","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if not CONFIG.KAGGLE_KERNEL and SETUP:\n  linux_shell(['python3 -m pip install fsspec gcsfs'])","metadata":{"id":"328b829a","papermill":{"duration":0.034499,"end_time":"2022-06-22T11:14:52.192381","exception":false,"start_time":"2022-06-22T11:14:52.157882","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG.KAGGLE_KERNEL:\n  if CONFIG.ENABLE_TRAINING or CONFIG.DEBUG:\n    train_df = pd.read_csv(train_csv)\n  sub_df = pd.read_csv(sub_csv)\nelse:\n  train_df = pd.read_csv(os.path.join(ROOT_DIR, CONFIG.NOTEBOOK_ID, CONFIG.TRAIN_CSV))\n  sub_df = pd.read_csv(os.path.join(ROOT_DIR, CONFIG.NOTEBOOK_ID, CONFIG.SUBMISSION_CSV))","metadata":{"id":"3d919396","papermill":{"duration":0.598566,"end_time":"2022-06-22T11:14:52.81706","exception":false,"start_time":"2022-06-22T11:14:52.218494","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG.VERBOSE:\n  if CONFIG.ENABLE_TRAINING or CONFIG.DEBUG:\n    print('\\n .. Train file ...')\n    display(train_df.head())\n  print('\\n .. Submission file ...')\n  display(sub_df.head())","metadata":{"id":"905fcd3b","papermill":{"duration":0.035541,"end_time":"2022-06-22T11:14:52.879342","exception":false,"start_time":"2022-06-22T11:14:52.843801","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Simulate submission using training files","metadata":{"id":"eb0d3822","papermill":{"duration":0.025472,"end_time":"2022-06-22T11:14:52.93084","exception":false,"start_time":"2022-06-22T11:14:52.905368","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if CONFIG.DEBUG:\n  test_dir = train_dir\n  all_test_images = all_train_images\n  first_50_cases = train_df.id.apply(lambda x: x.split('_', 1)[0]).unique()[:50]\n  sub_df = train_df[train_df.id.apply(lambda x: x.split('_', 1)[0]).isin(first_50_cases)]\n  sub_df = sub_df[['id', 'class']]\n  sub_df['predicted'] = ''\n\n  print('\\n\\n\\n... Submission data-frame ... \\n')\n  display(sub_df)","metadata":{"id":"bafdf90f","papermill":{"duration":0.161061,"end_time":"2022-06-22T11:14:53.117809","exception":false,"start_time":"2022-06-22T11:14:52.956748","status":"completed"},"tags":[],"outputId":"5126ab51-acfc-46ba-adfc-4dcdda12d2c7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = CONFIG.CLASSES\nsf_classes = CONFIG.SHORTFORM_CLASSES\nSF2LF = {_sf:_lf for _sf,_lf in zip(sf_classes, classes)}\nLF2SF = {_lf:_sf for _sf,_lf in zip(sf_classes, classes)}","metadata":{"id":"5c3fb54a","papermill":{"duration":0.036433,"end_time":"2022-06-22T11:14:53.180636","exception":false,"start_time":"2022-06-22T11:14:53.144203","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pre-processing","metadata":{"id":"67360067","papermill":{"duration":0.025864,"end_time":"2022-06-22T11:14:53.232883","exception":false,"start_time":"2022-06-22T11:14:53.207019","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_filepath_from_partial_identifier(_ident, file_list):\n  return [x for x in file_list if _ident in x][0]\n\ndef df_preprocessing(df, globbed_file_list, is_test:bool=False):\n  ''' The preprocessing steps applied to get column information '''\n  # 1. Get Case-ID as a column (str and int)\n  df['case_id_str'] = df['id'].apply(lambda x: x.split('_', 2)[0])\n  try:\n    df['case_id'] = df['id'].apply(lambda x: int(x.split('_', 2)[0].replace('case', '')))\n  except:\n    df['case_id'] = df['case_id_str']\n\n  # 2. Get Day as a column\n  df['day_num_str'] = df['id'].apply(lambda x: x.split('_', 2)[1])\n  try:\n    df['day_num'] = df['id'].apply(lambda x: int(x.split('_', 2)[1].replace('day', '')))\n  except:\n    df['day_num'] = df['day_num_str']\n\n  # 3. Get Slice Identifier as a column\n  df['slice_id'] = df['id'].apply(lambda x: x.split('_', 2)[2])\n\n  # 4. Get full file paths for the representative scans\n  df['_partial_ident'] = (globbed_file_list[0].rsplit('/', 4)[0]+'/'+                            \n                          df['case_id_str']+'/'+\n                          df['case_id_str']+'_'+ \n                          df['day_num_str']+ \n                          '/scans/'+\n                          df['slice_id'])\n  _tmp_merge_df = pd.DataFrame(\n      {'_partial_ident':[x.rsplit('_',4)[0] for x in globbed_file_list], \n         'f_path':globbed_file_list})\n  df = df.merge(_tmp_merge_df, on='_partial_ident').drop(columns=['_partial_ident'])\n\n  # 5. Get slice dimensions from filepath (int in pixels)\n  df['slice_h'] = df['f_path'].apply(lambda x: int(x[:-4].rsplit('_',4)[1]))\n  df['slice_w'] = df['f_path'].apply(lambda x: int(x[:-4].rsplit('_',4)[2]))\n\n  # 6. Pixel spacing from filepath (float in mm)\n  df['px_spacing_h'] = df['f_path'].apply(lambda x: float(x[:-4].rsplit('_',4)[3]))\n  df['px_spacing_w'] = df['f_path'].apply(lambda x: float(x[:-4].rsplit('_',4)[4]))\n\n  if not is_test:\n    # 7. Merge 3 rows into a single row \n    # Segmentation-RLE is the only unique information across those rows\n    l_bowel_df = df[df['class']=='large_bowel'][['id', 'segmentation']].rename(\n        columns={'segmentation':'lb_seg_rle'})\n    s_bowel_df = df[df['class']=='small_bowel'][['id', 'segmentation']].rename(\n        columns={'segmentation':'sb_seg_rle'})\n    stomach_df = df[df['class']=='stomach'][['id', 'segmentation']].rename(\n        columns={'segmentation':'st_seg_rle'})\n    \n    df = df.merge(l_bowel_df, on='id', how='left')\n    df = df.merge(s_bowel_df, on='id', how='left')\n    df = df.merge(stomach_df, on='id', how='left')\n    \n    df = df.drop_duplicates(subset=['id',]).reset_index(drop=True)\n    \n    df['lb_seg_flag'] = df['lb_seg_rle'].apply(lambda x: not pd.isna(x))\n    df['sb_seg_flag'] = df['sb_seg_rle'].apply(lambda x: not pd.isna(x))\n    df['st_seg_flag'] = df['st_seg_rle'].apply(lambda x: not pd.isna(x))\n    \n    df['n_segs'] = (df['lb_seg_flag'].astype(int)+\n                    df['sb_seg_flag'].astype(int)+\n                    df['st_seg_flag'].astype(int))\n\n  # 8. Reorder columns to the a new ordering \n  # (drops class and segmentation as no longer necessary)\n  new_col_order = ['id', 'f_path', 'n_segs',\n                   'lb_seg_rle', 'lb_seg_flag',\n                   'sb_seg_rle', 'sb_seg_flag', \n                   'st_seg_rle', 'st_seg_flag',\n                   'slice_h', 'slice_w', 'px_spacing_h', \n                   'px_spacing_w', 'case_id_str', 'case_id', \n                   'day_num_str', 'day_num', 'slice_id', 'predicted']\n  if is_test: new_col_order.insert(1, 'class')\n  new_col_order = [_c for _c in new_col_order if _c in df.columns]\n  df = df[new_col_order]\n\n  return df\n\ndef df_stack(df, strides=[2, -2]):\n  stack_size = len(strides) + 1  \n  df[f'f_path_{0:02}'] = df.groupby(\n                           ['case_id', 'day_num']\n                           )['f_path'].fillna(method='ffill')  \n  for i, stride in enumerate(strides):\n    df[f'f_path_{i+1:02}'] = df.groupby(\n                             ['case_id', 'day_num']\n                             )['f_path'].shift(stride).fillna(\n                               method='bfill' if stride>0 else 'ffill')\n\n  df['f_paths'] = df[[f'f_path_{i:02d}' for i in range(stack_size)]].values.tolist()\n  return df","metadata":{"id":"81982bc1","papermill":{"duration":0.054668,"end_time":"2022-06-22T11:14:53.313812","exception":false,"start_time":"2022-06-22T11:14:53.259144","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def df_debug_stack(df, strides=[2, -2]):\n  stack_size = len(strides) + 1  \n  df[f'f_path_{0:02}'] = df.groupby(\n                           ['case_id', 'day_num']\n                           )['f_path'].fillna(method='ffill')  \n  for i, stride in enumerate(strides):\n    df[f'f_path_{i+1:02}'] = df[f'f_path_{0:02}']\n\n  df['f_paths'] = df[[f'f_path_{i:02d}' for i in range(stack_size)]].values.tolist()\n  return df","metadata":{"id":"db95f310","papermill":{"duration":0.035934,"end_time":"2022-06-22T11:14:53.376417","exception":false,"start_time":"2022-06-22T11:14:53.340483","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG.DEBUG or CONFIG.ENABLE_TRAINING:\n  train_df = df_preprocessing(train_df, all_train_images)\n  train_df = df_stack(train_df, strides=CONFIG.STRIDES)\nsub_df = df_preprocessing(sub_df, all_test_images, is_test=True)\nsub_df = df_stack(sub_df, strides=CONFIG.STRIDES)","metadata":{"id":"d3ea1ec9","papermill":{"duration":2.58219,"end_time":"2022-06-22T11:14:55.985004","exception":false,"start_time":"2022-06-22T11:14:53.402814","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## [Removing improperly annotated masks](https://www.kaggle.com/competitions/uw-madison-gi-tract-image-segmentation/discussion/321979)","metadata":{"id":"ce687966","papermill":{"duration":0.026861,"end_time":"2022-06-22T11:14:56.039286","exception":false,"start_time":"2022-06-22T11:14:56.012425","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def df_string_match(row:'Pandas dataframe row', \n                    input_list:list)->bool:\n  for i in input_list: \n    if i in row: return True\n  return False\n\ndef df_filter_masks(df:'Pandas dataframe', \n                    exclusion_list:list, \n                    match_column:str='id', \n                    verbose:bool=False)->'Pandas dataframe':\n  exclude_idx = []\n  for row in df.iterrows():\n    if df_string_match(df[match_column].iloc[row[0]], exclusion_list):\n      exclude_idx.append(row[0])\n  print(f'Total items removed: {len(exclude_idx)}')  \n  if verbose:\n    print('List of indices removed: ', exclude_idx)  \n  return df.drop(exclude_idx)","metadata":{"id":"08006b2f","papermill":{"duration":0.037012,"end_time":"2022-06-22T11:14:56.103308","exception":false,"start_time":"2022-06-22T11:14:56.066296","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG.ENABLE_TRAINING:\n  exclusion_list = ['case7_day0', 'case81_day30', 'case138_day0']\n  train_df = df_filter_masks(train_df, exclusion_list)","metadata":{"id":"5635cd1e","papermill":{"duration":0.034701,"end_time":"2022-06-22T11:14:56.164907","exception":false,"start_time":"2022-06-22T11:14:56.130206","status":"completed"},"tags":[],"outputId":"e3b9bcfd-cc0b-4614-87e2-3913fbd8a731","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG.VERBOSE:\n  if CONFIG.DEBUG or CONFIG.ENABLE_TRAINING:\n    print('\\n ... Pre-processed train file ...\\n')\n    display(train_df.head())\n  print('\\n ... Pre-processed submission file ...\\n')   \n  display(sub_df.head())","metadata":{"id":"e25dad65","papermill":{"duration":0.035196,"end_time":"2022-06-22T11:14:56.226366","exception":false,"start_time":"2022-06-22T11:14:56.19117","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper functions","metadata":{"id":"73d19a47","papermill":{"duration":0.026605,"end_time":"2022-06-22T11:14:56.279399","exception":false,"start_time":"2022-06-22T11:14:56.252794","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Handle run-length-encoding using NumPy","metadata":{"id":"0b75d11d","papermill":{"duration":0.025877,"end_time":"2022-06-22T11:14:56.331617","exception":false,"start_time":"2022-06-22T11:14:56.30574","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n# modified from: https://www.kaggle.com/inversion/run-length-decoding-quick-start\ndef rle_decode(mask_rle, shape, color:int=1):\n  ''' \n  Args:\n      mask_rle (str): run-length as string formated (start length)\n      shape (tuple of ints): (height,width) of array to return \n    \n  Returns: \n      Mask (np.array)\n          - 1 indicating mask\n          - 0 indicating background\n\n  '''\n  # Split the string by space, then convert it into a integer array\n  s = np.array(mask_rle.split(), dtype=int)\n\n  # Every even value is the start, every odd value is the \"run\" length\n  starts = s[0::2] - 1\n  lengths = s[1::2]\n  ends = starts + lengths\n\n  # The image image is actually flattened since RLE is a 1D \"run\"\n  if len(shape)==3:\n    h, w, d = shape\n    img = np.zeros((h * w, d), dtype=np.float32)\n  else:\n    h, w = shape\n    img = np.zeros((h * w,), dtype=np.float32)\n\n  # The color here is actually just any integer you want!\n  for lo, hi in zip(starts, ends):\n    img[lo : hi] = color\n\n  # Don't forget to change the image back to the original shape\n  return img.reshape(shape)\n\n# https://www.kaggle.com/namgalielei/which-reshape-is-used-in-rle\ndef rle_decode_top_to_bot_first(mask_rle, shape):\n  '''\n  Args:\n      mask_rle (str): run-length as string formated (start length)\n      shape (tuple of ints): (height,width) of array to return \n    \n  Returns:\n      Mask (np.array)\n          - 1 indicating mask\n          - 0 indicating background\n  '''\n  s = mask_rle.split()\n  starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n  starts -= 1\n  ends = starts + lengths\n  img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n  for lo, hi in zip(starts, ends):\n    img[lo:hi] = 1\n  return img.reshape((shape[1], shape[0]), order='F').T  # Reshape from top -> bottom first\n\n# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\ndef rle_encode(img):\n  '''\n  Args:\n      img (np.array): \n          - 1 indicating mask\n          - 0 indicating background\n    \n  Returns: \n      run length as string formated\n  '''\n  pixels = img.flatten()\n  pixels = np.concatenate([[0], pixels, [0]])\n  runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n  runs[1::2] -= runs[::2]\n  return ' '.join(str(x) for x in runs)","metadata":{"id":"69bc1fcc","papermill":{"duration":0.042217,"end_time":"2022-06-22T11:14:56.400247","exception":false,"start_time":"2022-06-22T11:14:56.35803","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def flatten_l_o_l(nested_list):\n  '''Flatten a list of lists'''\n  return [item for sublist in nested_list for item in sublist]\n\ndef load_json_to_dict(json_path):\n  with open(json_path) as json_file:\n    data = json.load(json_file)\n  return data\n\ndef open_gray16(_path, normalize:bool=True, to_rgb:bool=False):\n  '''Helper to open files'''\n  if normalize:\n    if to_rgb:\n      return np.tile(np.expand_dims(\n               cv2.imread(_path, cv2.IMREAD_ANYDEPTH)/65535., axis=-1), 3)\n    else:\n      return cv2.imread(_path, cv2.IMREAD_ANYDEPTH)/65535.\n  else:\n    if to_rgb:\n      return np.tile(np.expand_dims(\n               cv2.imread(_path, cv2.IMREAD_ANYDEPTH), axis=-1), 3)\n    else:\n      return cv2.imread(_path, cv2.IMREAD_ANYDEPTH)","metadata":{"id":"adaf88f4","papermill":{"duration":0.037432,"end_time":"2022-06-22T11:14:56.465467","exception":false,"start_time":"2022-06-22T11:14:56.428035","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataframe functions","metadata":{"id":"7cdcce12","papermill":{"duration":0.025793,"end_time":"2022-06-22T11:14:56.517577","exception":false,"start_time":"2022-06-22T11:14:56.491784","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def df_process(input_df):\n  input_df['which_segs'] = input_df.lb_seg_flag.astype(int).astype(str) + \\\n                           input_df.sb_seg_flag.astype(int).astype(str) + \\\n                           input_df.st_seg_flag.astype(int).astype(str)\n  return input_df\n \ndef df_generator(df):\n  return df['id'], df['which_segs'], df['case_id']\n\ndef df_indexer(df, idxs):\n  proc_df=df.iloc[idxs]\n  num_samples = len(proc_df)\n  proc_df=proc_df.sample(num_samples).reset_index(drop=True)  \n  return proc_df\n\ndef df_dropna(df):\n  df.lb_seg_rle.fillna('', inplace=True)\n  df.sb_seg_rle.fillna('', inplace=True)\n  df.st_seg_rle.fillna('', inplace=True)  \n  return df\n\ndef df_make_masks(df, image_size:tuple=(256, 256), \n                  mode:str='multiclass', output_dir:str='./'):\n  _masks_dir = f'{output_dir}/{mode}/npy_files'\n  if not os.path.isdir(_masks_dir): os.makedirs(_masks_dir, exist_ok=True)\n  df[f'{mode}_mask_path'] = df.progress_apply(lambda _row: make_seg_mask(\n                              _row, _masks_dir, resize_to=image_size), axis=1)\n  del _masks_dir\n  return df\n\ndef df_mask_paths(df, proc_df, mode:str='multiclass'):\n  return proc_df.merge(df[['id', f'{mode}_mask_path']], on='id')","metadata":{"id":"fe5e4e43","papermill":{"duration":0.039379,"end_time":"2022-06-22T11:14:56.582957","exception":false,"start_time":"2022-06-22T11:14:56.543578","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tensorflow functions for handling images and masks","metadata":{"id":"ef273566","papermill":{"duration":0.026381,"end_time":"2022-06-22T11:14:56.635661","exception":false,"start_time":"2022-06-22T11:14:56.60928","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def tf_load_png(img_path, channels:int=3, dtype=tf.uint16):\n  with warnings.catch_warnings(record=True):  \n    img_bytes = tf.io.read_file(img_path)\n  return tf.image.decode_png(img_bytes, channels=channels, dtype=dtype)\n\ndef tf_normalize(img:tf.Tensor, \n                 dtype=tf.float32, \n                 epsilon:float=1e-16)->tf.Tensor:\n  img = tf.cast(img, dtype=dtype)\n  return ((img-tf.reduce_min(img)) / \n          (tf.reduce_max(img)-tf.reduce_min(img)+epsilon))\n\ndef tf_img_resize(img:tf.Tensor, image_size:tuple=(512,512))->tf.Tensor:\n  return tf.image.resize(\n           img, (tf.constant(image_size[0]), tf.constant(image_size[1]))\n           )\n\ndef tf_flip_left_right(imgs:tf.Tensor, mask:tf.Tensor)->tf.Tensor:\n  return (tf.image.flip_left_right(imgs), \n          tf.image.flip_left_right(mask))\n\ndef tf_flip_up_down(imgs:tf.Tensor, mask:tf.Tensor)->tf.Tensor:\n  return (tf.image.flip_left_right(imgs),\n          tf.image.flip_up_down(mask))\n\ndef tf_rle_decode(mask_rle, shape):\n  shape = tf.convert_to_tensor(shape, tf.int64)\n  size = tf.math.reduce_prod(shape)\n\n  # Split string\n  s = tf.strings.split(mask_rle)\n  s = tf.strings.to_number(s, tf.int64)\n\n  # Get starts and lengths\n  starts = s[::2] - 1\n  lens = s[1::2]\n\n  # Make ones to be scattered\n  total_ones = tf.reduce_sum(lens)\n  ones = tf.ones([total_ones], tf.uint8)\n\n  # Make scattering indices\n  r = tf.range(total_ones)\n  lens_cum = tf.math.cumsum(lens)\n  s = tf.searchsorted(lens_cum, r, 'right')\n  idx = r + tf.gather(starts - tf.pad(lens_cum[:-1], [(1, 0)]), s)\n    \n  # Scatter ones into flattened mask\n  mask_flat = tf.scatter_nd(tf.expand_dims(idx, 1), ones, [size])\n\n  # Reshape into mask\n  return tf.reshape(mask_flat, shape)","metadata":{"id":"94296193","papermill":{"duration":0.042769,"end_time":"2022-06-22T11:14:56.70466","exception":false,"start_time":"2022-06-22T11:14:56.661891","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Track and manage memory usage","metadata":{"id":"b91d371c","papermill":{"duration":0.026014,"end_time":"2022-06-22T11:14:56.757286","exception":false,"start_time":"2022-06-22T11:14:56.731272","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class mem_profiler():\n  def __init__(self, suffix:str='B', divisor:float=1024,\n               units:list=['','Ki','Mi','Gi','Ti','Pi','Ei','Zi','Yi']):\n    self.suffix = suffix\n    self.units = units\n    self.divisor = divisor  \n  def _num_formatter(self, inp_num):\n    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n    for unit in self.units[:-1]:\n      if abs(inp_num) < self.divisor:\n        return \"%3.1f %s%s\" % (inp_num, unit, self.suffix)\n      inp_num /= self.divisor\n    return \"%.1f %s%s\" % (inp_num, self.units[-1], self.suffix)\n  def __call__(self):\n    memory_utilization()\n    _mem_usage = {}\n    print('\\n---- Global memory usage ---\\n')\n    for name, size in sorted(((name, \n      sys.getsizeof(value)) for name, value in globals().items()),\n        key= lambda x: -x[1])[:10]:\n      print('{:>30}: {:>8}'.format(name, self._num_formatter(size)))\n      _mem_usage.update({name: size})\n    print('\\n---- Local memory usage ---\\n')  \n    for name, size in sorted(((name, \n      sys.getsizeof(value)) for name, value in locals().items()),\n        key= lambda x: -x[1])[:10]:\n      print('{:>30}: {:>8}'.format(name, self._num_formatter(size)))\n      _mem_usage.update({name: size})\n    return _mem_usage\n\ndef mem_cleaner(var_list:list, num_tries:int=2, verbose:bool=False): \n  for var in var_list:\n    try:\n      del globals()[var]\n      clear_memory(4)\n    except Exception as e:\n      if verbose:\n        print(f'Failed to clear in-memory variables due to: {e} ...')\n      clear_memory(4)\n    \ndef housekeeping(verbose:bool=False)->None:\n  if verbose: print('---Memory usage before housekeeping---\\n'); _ = mem_usage()\n  mem_cleaner(\n    ['auto_environment', 'auto_setup', 'auto_data_download', 'mlLibs_info',\n     'mount_google_drive', 'set_cuda_malloc_env', 'set_tf_verbosity', 'set_seed',\n     'gcp_tpu_setup', 'heterogeneous_compute', 'tiny3d', 'train_dir', 'train_csv', \n     'train_ds', 'val_ds', 'all_train_images', 'train_df', 'first_50_cases', \n     'classes', 'sf_classes', 'SF2LF', 'LF2SF',  'plot_history',\n     'get_filepath_from_partial_identifier', 'df_preprocessing',\n     'df_process', 'df_generator', 'df_indexer', 'df_dropna', 'df_make_masks', \n     'df_mask_paths', 'tf_flip_left_right', 'tf_flip_up_down', 'tf_rle_decode',\n     'split_val_df', 'make_seg_mask', 'tf_load_mask', 'tf_pair_augment', \n     'tf_image_mask_pair', 'tf_image_mask_aug_pair',\n     'preprocess_train', 'make_train_dataset',  'GarbageCollection',\n     'iou_coef', 'LossFunctionWrapper', 'IoU_Loss', 'get_callbacks', \n     'get_metrics', 'model_train', 'i', 'j', 'df_idx', 'img_batch']\n     )\n  clear_memory(4)\n  if verbose: print('\\n---Memory usage after housekeeping---\\n'); _ = mem_usage()\n\ntry:\n  mem_usage = mem_profiler()\nexcept:\n  mem_usage = None","metadata":{"id":"9a8733a1","papermill":{"duration":0.0487,"end_time":"2022-06-22T11:14:56.832122","exception":false,"start_time":"2022-06-22T11:14:56.783422","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG.ENABLE_TRAINING and CONFIG.TRAIN_VAL_SPLIT:\n  gkf =  GroupKFold(n_splits=CONFIG.NUM_FOLDS)  \n  train_df = df_process(train_df) \n  # train_df = train_df[train_df.n_segs>0].reset_index(drop=True)\n  df1, df2, df3 = df_generator(train_df)\n  for train_idxs, val_idxs in gkf.split(df1, df2, df3):\n    split_train_df = df_dropna(df_indexer(train_df, train_idxs))\n    split_val_df = df_dropna(df_indexer(train_df, val_idxs))\n    break\nelif CONFIG.ENABLE_TRAINING:\n  split_train_df, split_val_df = df_dropna(train_df), df_dropna(train_df)\nelif CONFIG.DEBUG:\n  split_val_df = df_dropna(train_df)\n\nif CONFIG.VERBOSE:\n  if CONFIG.ENABLE_TRAINING:\n    print('\\nFold 1: train data-frame \\n\\n')\n    display(split_train_df)\n\n  print('\\n\\n\\n\\nFold 1: validation data-frame \\n\\n')\n  display(split_val_df)","metadata":{"id":"d14142c1","papermill":{"duration":0.049704,"end_time":"2022-06-22T11:14:56.908241","exception":false,"start_time":"2022-06-22T11:14:56.858537","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save segmentation masks from run-length-encoded labels","metadata":{"id":"b9f5008c","papermill":{"duration":0.025856,"end_time":"2022-06-22T11:14:56.961134","exception":false,"start_time":"2022-06-22T11:14:56.935278","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def make_seg_mask(row, output_dir, resize_to):\n  _output_style = 'multiclass' if 'multiclass' in output_dir else 'multilabel'\n  _slice_shape = (row.slice_w, row.slice_h)\n\n  if not pd.isna(row.lb_seg_rle):\n    lb_mask = rle_decode(row.lb_seg_rle, _slice_shape, )\n  else:\n    lb_mask = np.zeros(_slice_shape)\n\n  if not pd.isna(row.sb_seg_rle):\n    sb_mask = rle_decode(row.sb_seg_rle, _slice_shape)\n  else:\n    sb_mask = np.zeros(_slice_shape)\n\n  if not pd.isna(row.st_seg_rle):\n    st_mask = rle_decode(row.st_seg_rle, _slice_shape)\n  else:\n    st_mask = np.zeros(_slice_shape)\n\n  if _output_style=='multiclass':\n    mask_arr = st_mask*3                         # stomach     = 3\n    mask_arr = np.where(sb_mask==1, 2, mask_arr) # small bowel = 2\n    mask_arr = np.where(lb_mask==1, 1, mask_arr) # large bowel = 1\n  else:\n    mask_arr = np.stack([lb_mask, sb_mask, st_mask], axis=-1)\n\n  mask_arr = cv2.resize(\n        mask_arr, resize_to, interpolation=cv2.INTER_NEAREST).astype(np.uint8)\n  mask_path = os.path.join(output_dir, f'{row.id}_mask')\n  np.save(mask_path, mask_arr)\n  return mask_path+'.npy'","metadata":{"id":"4e085a69","papermill":{"duration":0.039852,"end_time":"2022-06-22T11:14:57.027029","exception":false,"start_time":"2022-06-22T11:14:56.987177","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG.SAVE_MASKS:\n  train_df = df_make_masks(\n               train_df, \n               image_size=CONFIG.IMAGE_SIZE, \n               mode=CONFIG.STYLE, \n               output_dir=CONFIG.OUTPUT_DIR\n               )\n  split_train_df = df_mask_paths(train_df, split_train_df, mode=CONFIG.STYLE)\n  split_val_df = df_mask_paths(train_df, split_val_df, mode=CONFIG.STYLE)","metadata":{"id":"98e83ac9","papermill":{"duration":0.034705,"end_time":"2022-06-22T11:14:57.088047","exception":false,"start_time":"2022-06-22T11:14:57.053342","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Functions for creating datasets","metadata":{"id":"177b994b","papermill":{"duration":0.025699,"end_time":"2022-06-22T11:14:57.139966","exception":false,"start_time":"2022-06-22T11:14:57.114267","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def tf_load_image(paths:str, \n                  dtype=tf.float32, \n                  epsilon:float=1e-16, \n                  normalize:bool=True)->tf.Tensor:\n  '''\n  Load an image with the correct shape using only TF\n    \n  Args:\n      path (tf.string): Path to the image to be loaded\n      resize_to (tuple, optional): Size to reshape image\n    \n  Returns:\n      3 channel tf.Constant image ready for training/inference\n  '''\n  with warnings.catch_warnings(record=True):\n    imgs = []    \n    for i in range(len(CONFIG.STRIDES)+1):\n      img = tf_load_png(paths[i], channels=3, dtype=tf.uint16)\n      if normalize:\n        img = 255*tf_normalize(img, dtype=dtype, epsilon=epsilon)\n      img = tf_img_resize(img, image_size=CONFIG.IMAGE_SIZE)\n      imgs.append(img)\n    return tf.cast(imgs, dtype=dtype)\n\ndef tf_load_mask(rle_strs, \n                 root_shape, \n                 dtype=tf.uint8, \n                 style:str='multiclass')->tf.Tensor:\n  tf_masks = [tf.cast(\n                tf.image.resize(\n                  tf.expand_dims(\n                    tf_rle_decode(rle_str, root_shape), axis=-1), \n                  size=(\n                    tf.constant(CONFIG.MASK_SIZE[0]), \n                    tf.constant(CONFIG.MASK_SIZE[1])\n                  ), \n                  method=tf.image.ResizeMethod.NEAREST_NEIGHBOR\n                ), \n                dtype\n                ) for rle_str in rle_strs]\n\n  if style=='multilabel':\n    return tf.concat(tf_masks, axis=-1)\n  else:        \n    _tf_masks = tf.zeros((*CONFIG.MASK_SIZE, 1), dtype=dtype)\n    _tf_masks = tf.where(tf_masks[2]==tf.constant(\n        1, dtype=dtype), tf.constant(3, dtype=dtype), _tf_masks) # small bowel = 3\n    _tf_masks = tf.where(tf_masks[1]==tf.constant(\n        1, dtype=dtype), tf.constant(2, dtype=dtype), _tf_masks) # small bowel = 2\n    _tf_masks = tf.where(tf_masks[0]==tf.constant(\n        1, dtype=dtype), tf.constant(1, dtype=dtype), _tf_masks) # large bowel = 1\n    return tf.cast(_tf_masks, dtype=dtype)\n\ndef tf_pair(imgs:list, mask:tf.Tensor)->tf.Tensor:\n  return imgs, mask\n\ndef tf_img(imgs:tf.Tensor)->tf.Tensor:\n  return imgs\n\ndef tf_pair_cond(imgs:list, mask:tf.Tensor, aug_fn)->tf.Tensor:\n  p = tf.random.uniform([])<=tf.constant(0.5)\n  out_imgs = []\n  for i in range(len(CONFIG.STRIDES)+1):\n    img, mask = tf.cond(\n                  p, \n                  lambda: aug_fn(imgs[i], mask), \n                  lambda: tf_pair(imgs[i], mask)\n                  )\n    out_imgs.append(img)\n  return out_imgs, mask\n\ndef tf_pair_augment(imgs:list, mask:tf.Tensor)->tf.Tensor:\n  # Image-mask pairwise augmentation\n  if CONFIG.FLIP_HORIZONTAL:\n    imgs, mask  = tf_pair_cond(\n                   imgs, \n                   mask,\n                   tf_flip_left_right\n                   )\n  if CONFIG.FLIP_VERTICAL:\n    imgs, mask  = tf_pair_cond(\n                   imgs, \n                   mask,\n                   tf_flip_up_down\n                   )\n  \n  if CONFIG.RANDOM_BRIGHTNESS:\n    p = tf.random.uniform([])<=tf.constant(0.5)\n    out_imgs = []\n    for i in range(len(CONFIG.STRIDES)+1):\n      img = tf.cond(\n             p, \n             lambda: tf.image.random_brightness(imgs[i], 0.05), \n             lambda: tf_img(imgs[i])\n             )\n      out_imgs.append(img)\n    imgs = out_imgs\n  if CONFIG.RANDOM_CONTRAST:\n    p = tf.random.uniform([])<=tf.constant(0.5)\n    out_imgs = []\n    for i in range(len(CONFIG.STRIDES)+1):\n      img = tf.cond(\n             p, \n             lambda: tf.image.random_contrast(imgs[i], 0.05, 0.1), \n             lambda: tf_img(imgs[i])\n             )\n      out_imgs.append(img)\n    imgs = out_imgs\n  if CONFIG.RANDOM_GAMMA:\n    p = tf.random.uniform([])<=tf.constant(0.5)\n    out_imgs = []\n    for i in range(len(CONFIG.STRIDES)+1):\n      img = tf.cond(\n              p, \n              lambda: tf.image.adjust_gamma(imgs[i], 1e-6), \n              lambda: tf_img(imgs[i])\n              )\n      out_imgs.append(img)\n    imgs = out_imgs\n  if CONFIG.RANDOM_HUE:\n    p = tf.random.uniform([])<=tf.constant(0.5)\n    out_imgs = []\n    for i in range(len(CONFIG.STRIDES)+1):\n      img = tf.cond(\n              p, \n              lambda: tf.image.random_hue(imgs[i], 0.05), \n              lambda: tf_img(imgs[i])\n              )\n      out_imgs.append(img)\n    imgs = out_imgs\n  if CONFIG.RANDOM_SATURATION:\n    p = tf.random.uniform([])<=tf.constant(0.5)\n    out_imgs = []\n    for i in range(len(CONFIG.STRIDES)+1):\n      img = tf.cond(\n              p, \n              lambda: tf.image.random_saturation(imgs[i], 0.475, 0.525), \n              lambda: tf_img(imgs[i])\n              )\n      out_imgs.append(img)\n    imgs = out_imgs\n  return imgs, mask\n\ndef tf_image_mask_pair(paths,\n                       rle_strs,\n                       root_shape,\n                       dtype:'Tensorflow dtype'=tf.uint8,\n                       epsilon:float=1e-16,\n                       style:str='multiclass',\n                       normalize:bool=True)->tf.Tensor:\n  imgs  = tf_load_image(paths, dtype=dtype, epsilon=epsilon,normalize=normalize)\n  mask = tf_load_mask(rle_strs, root_shape, dtype=dtype, style=style)\n  imgs, mask = tf.cast(imgs, dtype=dtype), tf.cast(mask, dtype=dtype)\n  return imgs, mask\n\ndef tf_image_mask_aug_pair(paths, \n                           rle_strs, \n                           root_shape, \n                           dtype=tf.uint8, \n                           epsilon:float=1e-16, \n                           style:str='multiclass', \n                           normalize:bool=True)->tf.Tensor:\n  imgs, mask = tf_image_mask_pair(paths, rle_strs, root_shape, dtype=dtype, \n                                  epsilon=epsilon, style=style, normalize=normalize)\n  imgs, mask = tf_pair_augment(imgs, mask)\n  imgs, mask = tf.cast(imgs, dtype=dtype), tf.cast(mask, dtype=dtype)  \n  return imgs, mask\n\ndef preprocess_train(img_batch:tf.Tensor, mask_batch:tf.Tensor)->tf.Tensor:\n  dtype      = getattr(tf, CONFIG.DTYPE)  \n  img_batch  = img_batch/tf.constant(127.5)-tf.constant(1.0)\n  img_batch  = tf.cast(img_batch, dtype=dtype)  \n  mask_batch = tf.cast(mask_batch, dtype=dtype)\n  return img_batch, mask_batch\n\ndef preprocess_test(img_batch:tf.Tensor)->tf.Tensor:\n  with warnings.catch_warnings(record=True):  \n    dtype     = getattr(tf, CONFIG.DTYPE)\n    img_batch = img_batch/tf.constant(127.5)-tf.constant(1.0)\n    img_batch = tf.cast(img_batch, dtype=dtype) \n  return img_batch","metadata":{"id":"fa8dd9ad","papermill":{"duration":0.06038,"end_time":"2022-06-22T11:14:57.226458","exception":false,"start_time":"2022-06-22T11:14:57.166078","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create training and validation dataset","metadata":{"id":"7658884e","papermill":{"duration":0.025832,"end_time":"2022-06-22T11:14:57.279156","exception":false,"start_time":"2022-06-22T11:14:57.253324","status":"completed"},"tags":[]}},{"cell_type":"code","source":"try:\n  AUTOTUNE = tf.data.AUTOTUNE\nexcept:\n  AUTOTUNE = None","metadata":{"id":"c5b6e62e","papermill":{"duration":0.033738,"end_time":"2022-06-22T11:14:57.338816","exception":false,"start_time":"2022-06-22T11:14:57.305078","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_train_dataset(input_df, batch_size:int=1, mode:str='train'):\n  data_tuple = ()\n  for i in range(len(CONFIG.STRIDES)+1):\n    df_ = getattr(input_df, f'f_path_{i:02}')\n    data_tuple += (df_,)\n  ds = tf.data.Dataset.from_tensor_slices(\n         (\n            data_tuple, \n            (\n              input_df.lb_seg_rle,\n              input_df.sb_seg_rle,\n              input_df.st_seg_rle\n              ), \n            (\n              input_df.slice_w, \n              input_df.slice_h\n              )\n            )\n          )\n\n  dtype = getattr(tf, CONFIG.DTYPE)\n\n  shuffle_buffer = len(input_df) if CONFIG.OPTIMUM_SHUFFLE else CONFIG.SHUFFLE_BUFFER\n\n  if mode =='train':\n    ds = ds.map(\n           lambda x,y,z:(\n             tf_image_mask_aug_pair(x,y,z, style=CONFIG.STYLE, dtype=dtype)\n             ), num_parallel_calls=AUTOTUNE\n           )\n    ds = ds.shuffle(shuffle_buffer)                            \\\n           .batch(batch_size, drop_remainder=True)             \\\n           .map(preprocess_train, num_parallel_calls=AUTOTUNE) \\\n           .prefetch(AUTOTUNE)\n  elif mode =='val' or mode=='valid' or mode=='validation':\n    ds = ds.map(\n           lambda x,y,z:(\n             tf_image_mask_pair(x,y,z, style=CONFIG.STYLE, dtype=dtype)\n             ), num_parallel_calls=AUTOTUNE\n           )\n    ds = ds.shuffle(shuffle_buffer)                            \\\n           .batch(CONFIG.BATCH_SIZE, drop_remainder=True)      \\\n           .map(preprocess_train, num_parallel_calls=AUTOTUNE) \\\n           .prefetch(AUTOTUNE)\n  else:\n    raise ValueError('Unknown dataset creation mode. Options: \"train\", \"val\" ...')\n  return ds\n\ndef make_test_dataset(input_df, batch_size:int=1):\n  dtype = getattr(tf, CONFIG.DTYPE)\n  data_tuple = ()\n  for i in range(len(CONFIG.STRIDES)+1):\n    df_ = getattr(input_df.iloc[::3], f'f_path_{i:02}')\n    data_tuple += (df_,)\n  ds = tf.data.Dataset.from_tensor_slices(\n         (\n            data_tuple,\n            ) \n         )\n  ds = ds.map(\n         lambda x:tf_load_image(x, dtype=dtype), num_parallel_calls=AUTOTUNE\n         )\n  ds = ds.batch(batch_size)                \\\n         .map(preprocess_test, \n              num_parallel_calls=AUTOTUNE) \\\n         .prefetch(AUTOTUNE)\n  return ds","metadata":{"id":"b81aaf76","papermill":{"duration":0.043519,"end_time":"2022-06-22T11:14:57.408972","exception":false,"start_time":"2022-06-22T11:14:57.365453","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\ntrain_ds, val_ds = None, None\nif CONFIG.ENABLE_TRAINING  or CONFIG.DEBUG:\n  if CONFIG.ENABLE_TRAINING and CONFIG.VERBOSE:\n    train_ds = make_train_dataset(split_train_df, batch_size=CONFIG.BATCH_SIZE)\n  if not CONFIG.TRAIN_VAL_SPLIT:\n    val_ds = make_train_dataset(split_train_df, batch_size=CONFIG.BATCH_SIZE, mode='val')","metadata":{"id":"a3b553b4","papermill":{"duration":0.036338,"end_time":"2022-06-22T11:14:57.471621","exception":false,"start_time":"2022-06-22T11:14:57.435283","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualize training data","metadata":{"id":"0e938b09","papermill":{"duration":0.026195,"end_time":"2022-06-22T11:14:57.524079","exception":false,"start_time":"2022-06-22T11:14:57.497884","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if CONFIG.ENABLE_TRAINING and CONFIG.VERBOSE:\n  for _img_batch, _mask_batch in train_ds.take(1):\n    print(_img_batch.shape, _mask_batch.shape)\n    _mask = _mask_batch[0]\n    if len(_mask.shape)==3 and _mask.shape[-1]==1:\n      _mask = np.squeeze(_mask, axis=-1)\n    del _mask_batch; _ = gc.collect()\n    plt.figure(figsize=(15,5))\n    plt.subplot(1,len(CONFIG.STRIDES)+2,1)\n    plt.imshow(tf.cast(_mask, tf.float32))\n    for i in range(len(CONFIG.STRIDES)+1):\n      _img =  _img_batch[0][i]\n      plt.subplot(1,len(CONFIG.STRIDES)+2,i+2)\n      plt.imshow(tf.cast((_img+1)*127.5, tf.uint8))\n    del _img_batch; _ = gc.collect()\n\n    plt.tight_layout()\n    plt.show()","metadata":{"id":"6e6b7be3","papermill":{"duration":0.038387,"end_time":"2022-06-22T11:14:57.588667","exception":false,"start_time":"2022-06-22T11:14:57.55028","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tiny3D","metadata":{}},{"cell_type":"code","source":"def model_2d(inp:tf.Tensor,\n             input_size:tuple=(256, 256),\n             fc_dim:tuple=(4, 4, 3),\n             dropout:float=0.2,\n             name:str='model2d',\n             enable_bayesian_inference:bool=False)->tf.Tensor:\n  x = tf.keras.layers.Conv2D(16, (3,3), \n                             name=f'Conv2D_{name}_input',\n                             activation='swish')(inp)\n  x = tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2),\n                                   name=f'MaxPool2D_{name}_input')(x)\n  x = tf.keras.layers.Dropout(dropout, name=f'maxpool_dropout_{name}')(\n        x, \n        training=enable_bayesian_inference\n        )\n  #x = tf.keras.layers.Conv2D(32, (3,3), name='Conv2D_feature', activation='swish')(x)\n  x = tf.keras.layers.Flatten(name=f'Flatten_{name}')(x)\n\n  x = tf.keras.layers.Dense(\n        fc_dim[0]*fc_dim[1]*fc_dim[2], \n        name=f'fc_{name}_dense'\n        )(x)\n  x = tf.keras.layers.Dropout(dropout/2, name=f'fc_{name}_dense_dropout')(\n        x,\n        training=enable_bayesian_inference\n        )  \n  x = tf.keras.layers.Reshape(fc_dim, name=f'fc_{name}_resize')(x)\n\n  x = tf.keras.layers.UpSampling2D(size=(input_size[0]//x.shape[1], \n                                         input_size[1]//x.shape[2]), \n                                   interpolation='bilinear', \n                                   name=f'fc_{name}_upsample_2D')(x)\n  x = tf.keras.layers.Dropout(dropout/2, name=f'fc_{name}_upsample_dropout')(\n        x,\n        training=enable_bayesian_inference\n        )\n  x = tf.keras.layers.UpSampling2D(size=(input_size[0]//x.shape[1], \n                                         input_size[1]//x.shape[2]), \n                                   interpolation='bilinear', \n                                   name=f'out_{name}_upsample_2D')(x)\n  return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Tiny3D(num_classes:int=4,\n           input_size:tuple=(256,256),\n           dropout:float=0.2,\n           fc_dim:tuple=(4, 4, 3),\n           enable_bayesian_inference:bool=False):\n  inputs = tf.keras.layers.Input((3, *input_size, 3))\n  x_out = []\n  for i in range(len(CONFIG.STRIDES)+1):\n    _inp = tf.keras.layers.Lambda(lambda x: x[:,i,:,:,:])(inputs)\n    x = model_2d(_inp, input_size=input_size, fc_dim=fc_dim, name=i)\n    x_out.append(x)\n  xo = tf.keras.layers.Concatenate(axis=-1)(x_out)\n  outputs = tf.keras.layers.Conv2D(num_classes, kernel_size=(1, 1), \n                                   padding='same', name='conv_preds')(xo)\n  return tf.keras.Model(inputs=inputs, outputs=outputs)","metadata":{"id":"a4d4c11a","papermill":{"duration":0.059252,"end_time":"2022-06-22T11:15:01.470456","exception":false,"start_time":"2022-06-22T11:15:01.411204","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build model","metadata":{"id":"c3d20ba8","papermill":{"duration":0.025942,"end_time":"2022-06-22T11:15:01.522767","exception":false,"start_time":"2022-06-22T11:15:01.496825","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_tiny3d_model():\n  return Tiny3D(\n           num_classes=4,\n           input_size=CONFIG.IMAGE_SIZE\n           )\n\ndef get_segmentation_model():\n  return get_tiny3d_model()\n\ntiny3d = get_segmentation_model()","metadata":{"id":"2d9c4c34","papermill":{"duration":8.135684,"end_time":"2022-06-22T11:15:09.685586","exception":false,"start_time":"2022-06-22T11:15:01.549902","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG.MODEL_SUMMARY=='plot':\n  display(tf.keras.utils.plot_model(tiny3d))\nelif CONFIG.MODEL_SUMMARY=='summary' and CONFIG.VERBOSE:\n  print(tiny3d.summary())","metadata":{"id":"5c9703b9","papermill":{"duration":0.036022,"end_time":"2022-06-22T11:15:09.748825","exception":false,"start_time":"2022-06-22T11:15:09.712803","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Custom callbacks","metadata":{"id":"36806eb0","papermill":{"duration":0.027086,"end_time":"2022-06-22T11:15:09.802895","exception":false,"start_time":"2022-06-22T11:15:09.775809","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class GarbageCollection(tf.keras.callbacks.Callback):\n  def __init__(self, clear_session:bool=False)->None:\n    self.clear_session = clear_session\n  def on_epoch_end(self, epoch, logs=None)->None:\n    _ =  gc.collect()\n    if self.clear_session: tf.keras.backend.clear_session()","metadata":{"id":"45dca086","papermill":{"duration":0.038497,"end_time":"2022-06-22T11:15:09.870484","exception":false,"start_time":"2022-06-22T11:15:09.831987","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_history(history, fold_num:str='1', metrics:list=['acc',]):\n  fig = px.line(history.history, \n                x=range(len(history.history['loss'])), y=['loss', 'val_loss'],\n                labels={'value':'Loss (log-axis)', 'x':'Epoch #'},\n                title=f'<b>FOLD {fold_num} MODEL - LOSS</b>', log_y=True)\n  fig.show()\n\n  for _m in metrics:\n    fig = px.line(history.history, \n                  x=range(len(history.history[_m])), y=[_m, f'val_{_m}'],\n                  labels={'value':f'{_m} (log-axis)', 'x':'Epoch #'},\n                  title=f'<b>FOLD {fold_num} MODEL - {_m}</b>', log_y=True)\n  fig.show()","metadata":{"id":"abecdae4","papermill":{"duration":0.037467,"end_time":"2022-06-22T11:15:09.935838","exception":false,"start_time":"2022-06-22T11:15:09.898371","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# IoU metrics","metadata":{"id":"554974ad","papermill":{"duration":0.026909,"end_time":"2022-06-22T11:15:09.989097","exception":false,"start_time":"2022-06-22T11:15:09.962188","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class iou_coef():\n  def __init__(self, \n               dtype=tf.float32, \n               smooth:float=1, \n               epsilon:float=1e-16, \n               name:str='iouCoef')->None:\n    self.dtype, self.smooth, self.epsilon = dtype, smooth, epsilon\n    self.name, self.__name__ = name, name\n  @tf.function \n  def _iou_coef(self, _y_true:tf.Tensor, _y_pred:tf.Tensor)->tf.Tensor:\n    _y_true = tf.cast(_y_true, dtype=self.dtype)\n    _y_pred = tf.cast(_y_pred, dtype=self.dtype)\n    _intersection = K.sum(K.abs(_y_true * _y_pred), axis=[1,2,3])\n    _union = K.sum(_y_true, [1,2,3]) + K.sum(_y_pred, [1,2,3]) - _intersection\n    _iou = K.mean(\n            (_intersection + self.smooth) /\n            (_union + self.smooth + self.epsilon), \n            axis=0\n            )\n    return _iou\n  @tf.function\n  def __call__(self, y_true:tf.Tensor, y_pred:tf.Tensor)->tf.Tensor:\n    return self._iou_coef(y_true, y_pred)\n\nclass iou_loss():\n  def __init__(self, \n               dtype=tf.float32, \n               smooth:float=1, \n               epsilon:float=1e-16, \n               name:str='iouLoss',\n               **kwargs)->None:      \n    self.dtype, self.smooth, self.epsilon = dtype, smooth, epsilon\n    self.name, self.__name__ = name, name\n  @tf.function\n  def _iou_loss(self, _y_true:tf.Tensor, _y_pred:tf.Tensor)->tf.Tensor:\n    _iou_coef = iou_coef(\n                  dtype=self.dtype, smooth=self.smooth, epsilon=self.epsilon\n                  )\n    _iou = _iou_coef(_y_true, _y_pred)\n    return tf.math.exp(K.abs(1 - _iou) + self.epsilon)\n  @tf.function\n  def __call__(self, y_true:tf.Tensor, y_pred:tf.Tensor)->tf.Tensor:\n    return self._iou_loss(y_true, y_pred)","metadata":{"id":"e377f7f1","papermill":{"duration":0.04487,"end_time":"2022-06-22T11:15:10.060576","exception":false,"start_time":"2022-06-22T11:15:10.015706","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loss function -- Tensorflow wrapper\nTensorflow wrapper for integrating custom loss functions","metadata":{"id":"6b77dc52","papermill":{"duration":0.025681,"end_time":"2022-06-22T11:15:10.113191","exception":false,"start_time":"2022-06-22T11:15:10.08751","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def is_extension_type(tensor):\n  '''Adapted from https://github.com/keras-team/keras/blob/master/keras/utils/tf_utils.py'''\n  return isinstance(tensor, tf.__internal__.CompositeTensor)\n\ndef is_tensor_or_extension_type(x):\n  '''Adapted from https://github.com/keras-team/keras/blob/master/keras/utils/tf_utils.py'''\n  return tf.is_tensor(x) or is_extension_type(x)\n\ndef remove_squeezable_dimensions(labels, predictions, expected_rank_diff=0, name=None):\n  with tf.keras.backend.name_scope(name or 'remove_squeezable_dimensions'):\n    if not is_tensor_or_extension_type(predictions):\n      predictions = tf.convert_to_tensor(predictions)\n    if not is_tensor_or_extension_type(labels):\n      labels = tf.convert_to_tensor(labels)\n    predictions_shape = predictions.shape\n    predictions_rank = predictions_shape.ndims\n    labels_shape = labels.shape\n    labels_rank = labels_shape.ndims\n    if (labels_rank is not None) and (predictions_rank is not None):\n      # Use static rank.\n      rank_diff = predictions_rank - labels_rank\n      if (rank_diff == expected_rank_diff + 1 and\n          predictions_shape.dims[-1].is_compatible_with(1)):\n        predictions = tf.squeeze(predictions, [-1])\n      elif (rank_diff == expected_rank_diff - 1 and\n            labels_shape.dims[-1].is_compatible_with(1)):\n        labels = tf.squeeze(labels, [-1])\n      return labels, predictions\n\ndef squeeze_or_expand_dimensions(y_pred, y_true=None, sample_weight=None):\n  y_pred_shape = y_pred.shape\n  y_pred_rank = y_pred_shape.ndims\n  if y_true is not None:\n    # If sparse matrix is provided as `y_true`, the last dimension in `y_pred`\n    # may be > 1. Eg: y_true = [0, 1, 2] (shape=(3,)),\n    # y_pred = [[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]] (shape=(3, 3))\n    # In this case, we should not try to remove squeezable dimension.\n    y_true_shape = y_true.shape\n    y_true_rank = y_true_shape.ndims\n    if (y_true_rank is not None) and (y_pred_rank is not None):\n      # Use static rank for `y_true` and `y_pred`.\n      if (y_pred_rank - y_true_rank != 1) or y_pred_shape[-1] == 1:\n        y_true, y_pred = remove_squeezable_dimensions(\n            y_true, y_pred)\n    else:\n      # Use dynamic rank.\n      rank_diff = tf.rank(y_pred) - tf.rank(y_true)\n      squeeze_dims = lambda: remove_squeezable_dimensions(  # pylint: disable=g-long-lambda\n          y_true, y_pred)\n      is_last_dim_1 = tf.equal(1, tf.shape(y_pred)[-1])\n      maybe_squeeze_dims = lambda: tf.cond(  # pylint: disable=g-long-lambda\n          is_last_dim_1, squeeze_dims, lambda: (y_true, y_pred))\n      y_true, y_pred = tf.cond(\n          tf.equal(1, rank_diff), maybe_squeeze_dims, squeeze_dims)\n\n  if sample_weight is None:\n    return y_pred, y_true\n\n  weights_shape = sample_weight.shape\n  weights_rank = weights_shape.ndims\n  if weights_rank == 0:  # If weights is scalar, do nothing.\n    return y_pred, y_true, sample_weight\n\n  if (y_pred_rank is not None) and (weights_rank is not None):\n    # Use static rank.\n    if weights_rank - y_pred_rank == 1:\n      sample_weight = tf.squeeze(sample_weight, [-1])\n    elif y_pred_rank - weights_rank == 1:\n      sample_weight = tf.expand_dims(sample_weight, [-1])\n    return y_pred, y_true, sample_weight\n\n  # Use dynamic rank.\n  weights_rank_tensor = tf.rank(sample_weight)\n  rank_diff = weights_rank_tensor - tf.rank(y_pred)\n  maybe_squeeze_weights = lambda: tf.squeeze(sample_weight, [-1])\n\n  def _maybe_expand_weights():\n    expand_weights = lambda: tf.expand_dims(sample_weight, [-1])\n    return tf.cond(tf.equal(rank_diff, -1), expand_weights, lambda: sample_weight)\n\n  def _maybe_adjust_weights():\n    return tf.cond(tf.equal(rank_diff, 1), maybe_squeeze_weights,\n             _maybe_expand_weights)\n\n  # squeeze or expand last dim of `sample_weight` if its rank differs by 1\n  # from the new rank of `y_pred`.\n  sample_weight = tf.cond(tf.equal(weights_rank_tensor, 0), lambda: sample_weight,\n                    _maybe_adjust_weights)\n  return y_pred, y_true, sample_weight\n\ndef get(identifier):\n  if identifier is None:\n    return None\n  if isinstance(identifier, str):\n    return deserialize(str(identifier))\n  if isinstance(identifier, dict):\n    return deserialize(identifier)\n  if callable(identifier):\n    return identifier\n  raise ValueError(\n      f'Could not interpret loss function identifier: {identifier}')\n\nclass LossFunctionWrapper(tf.keras.losses.Loss):\n  ''' Adapted from https://github.com/keras-team/keras/blob/master/keras/losses.py '''\n  def __init__(self, fn, name:str=None, reduction=tf.keras.losses.Reduction, **kwargs)->None:\n    super().__init__(reduction=reduction, name=name)\n    self.fn = fn\n    self._fn_kwargs = kwargs\n\n  def call(self, y_true, y_pred):\n    if tf.is_tensor(y_pred) and tf.is_tensor(y_true):\n      y_pred, y_true = squeeze_or_expand_dimensions(y_pred, y_true)\n\n    try:\n      ag_fn = tf.__internal__.autograph.tf_convert(\n        self.fn, tf.__internal__.autograph.control_status_ctx())\n    except AttributeError:\n      ag_fn = tf_convert(self.fn, control_status_ctx())\n    return ag_fn(y_true, y_pred, **self._fn_kwargs)\n\n  def get_config(self):\n    config = {}\n    for k, v in self._fn_kwargs.items():\n      config[k] = tf.keras.backend.eval(v) if tf.keras.utils.is_tensor_or_variable(v) else v\n\n    if tf.keras.saving.experimental.saving_lib._ENABLED:  # pylint: disable=protected-access\n      config['fn'] = tf.keras.utils.generic_utils.get_registered_name(self.fn)\n\n    base_config = super().get_config()\n    return dict(list(base_config.items()) + list(config.items()))\n\n  @classmethod\n  def from_config(cls, config):\n    if tf.keras.saving.experimental.saving_lib._ENABLED:  # pylint: disable=protected-access\n      fn_name = config.pop('fn', None)\n      if fn_name and cls is LossFunctionWrapper:\n        config['fn'] = get(fn_name)\n    return cls(**config)","metadata":{"id":"54a8e6ac","papermill":{"duration":0.057822,"end_time":"2022-06-22T11:15:10.19739","exception":false,"start_time":"2022-06-22T11:15:10.139568","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class IoU_Loss(LossFunctionWrapper):\n  def __init__(self, \n               name:str='IoU_Loss', \n               dtype=tf.float32, \n               smooth:float=1, \n               epsilon:float=1e-16,\n               reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE)->None:\n    self.name, self.__name__ = name, name\n    super().__init__(iou_loss(dtype=dtype, smooth=smooth, epsilon=epsilon), \n                     name=name, reduction=reduction)","metadata":{"id":"441b11c0","papermill":{"duration":0.037051,"end_time":"2022-06-22T11:15:10.260756","exception":false,"start_time":"2022-06-22T11:15:10.223705","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train model","metadata":{"id":"daa2f2b0","papermill":{"duration":0.026297,"end_time":"2022-06-22T11:15:10.313814","exception":false,"start_time":"2022-06-22T11:15:10.287517","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Load pre-trained model weights","metadata":{"id":"6b28facf","papermill":{"duration":0.026525,"end_time":"2022-06-22T11:15:10.36774","exception":false,"start_time":"2022-06-22T11:15:10.341215","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def model_loader(wt, model=None, tpu:bool=False, custom_objects=None):\n  try:\n    if tpu:\n      localhost_load_option = tf.saved_model.LoadOptions(\n          experimental_io_device='/job:localhost')\n      model = tf.keras.models.load_model(wt, options=localhost_load_option,\n                                         custom_objects=custom_objects)\n    else:  \n      model = tf.keras.models.load_model(wt, custom_objects=custom_objects)\n    print(f'Loaded model: {wt}')\n    return model\n  except Exception as e:\n    print(f'Model loading failed due to: {e} ...')\n    if model is not None:\n      print(f'Attempting to load weights from : {wt} instead ....')\n      try:\n        if tpu:\n          localhost_load_option = tf.saved_model.LoadOptions(\n            experimental_io_device='/job:localhost')\n          model.load_weights(wt, options=localhost_load_option)\n        else:\n          model.load_weights(wt)  \n        print(f'Loaded model weights: {wt}')\n        return model\n      except:\n        raise ValueError('... Unable to load any model ...')","metadata":{"id":"73518af7","papermill":{"duration":0.037238,"end_time":"2022-06-22T11:15:10.432213","exception":false,"start_time":"2022-06-22T11:15:10.394975","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_weights(wt_file:str, model=None, custom_objects=None, tpu:bool=False):\n  if model is None:\n    model = get_segmentation_model()\n\n  if wt_file is None: return model\n    \n  if os.path.exists(f'{wt_file}.h5'):  \n    try:\n      model.load_weights(f'{wt_file}.h5')\n    except:\n      model.load_weights(f'{wt_file}.h5', by_name=True)  \n    print(f'Loaded weights from: {wt_file}.h5 ...')\n  elif os.path.exists(f'{wt_file}.index') or os.path.exists(wt_file):\n    try:\n      if tpu:\n        localhost_load_option = tf.saved_model.LoadOptions(\n            experimental_io_device='/job:localhost')\n        model.load_weights(wt_file, options=localhost_load_option)\n      else:\n        model.load_weights(wt_file)  \n      if CONFIG.VERBOSE:\n        print(f'Loaded weights: {wt_file} ...')\n    except Exception as e:\n      if CONFIG.VERBOSE:\n        print(f'Retry loading models due to: \\n\\t\\t{e} ...')\n      model = model_loader(\n                Path(wt_file), \n                model, \n                tpu=tpu, \n                custom_objects=custom_objects\n                )\n  return model","metadata":{"id":"551fe13c","papermill":{"duration":0.039219,"end_time":"2022-06-22T11:15:10.497765","exception":false,"start_time":"2022-06-22T11:15:10.458546","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define training callbacks","metadata":{"id":"082a5857","papermill":{"duration":0.025821,"end_time":"2022-06-22T11:15:10.549769","exception":false,"start_time":"2022-06-22T11:15:10.523948","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_callbacks(ckpt:str, ckpt_dir:str=None, tpu:bool=False):\n  lr_cb = tf.keras.callbacks.ReduceLROnPlateau(\n            monitor=CONFIG.EVAL_FUNCTION, \n            factor=0.75, \n            patience=2, \n            verbose=1,\n            mode=CONFIG.EVAL_FUNCTION_MODE\n            )\n  \n  es_cb = tf.keras.callbacks.EarlyStopping(\n            monitor=CONFIG.EVAL_FUNCTION, \n            patience=4, \n            mode=CONFIG.EVAL_FUNCTION_MODE,\n            verbose=1, \n            restore_best_weights=True\n            )\n  \n  ckpt_dir = './'\n  if CONFIG.COLAB_KERNEL and CONFIG.ENABLE_GOOGLE_DRIVE_CHECKPOINT: \n    ckpt_dir = CONFIG.GOOGLE_DRIVE  \n  ckpt_cb = tf.keras.callbacks.ModelCheckpoint(\n              f'{ckpt_dir}/{ckpt}.h5', \n              monitor=CONFIG.EVAL_FUNCTION, \n              mode=CONFIG.EVAL_FUNCTION_MODE, \n              save_weights_only=CONFIG.IOU_LOSS, \n              save_best_only=True, \n              options=None if CONFIG.IOU_LOSS else save_locally\n              )\n  \n  if CONFIG.IOU_METRICS:\n    iou_ckpt_cb = tf.keras.callbacks.ModelCheckpoint(\n      f'{ckpt_dir}/{ckpt}_'+'{val_iouLoss:.2f}.h5',\n      monitor='val_iouLoss', \n      mode='min', \n      save_weights_only=CONFIG.IOU_LOSS,\n      save_best_only=True, \n      options=save_locally\n      )\n    \n  gc_cb = GarbageCollection(clear_session=tpu)\n\n  cb = [lr_cb, es_cb, ckpt_cb, gc_cb]\n  if CONFIG.IOU_METRICS: cb.append(iou_ckpt_cb)\n  return cb","metadata":{"id":"0a573078","papermill":{"duration":0.038014,"end_time":"2022-06-22T11:15:10.613961","exception":false,"start_time":"2022-06-22T11:15:10.575947","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define training metrics","metadata":{"id":"71df162f","papermill":{"duration":0.026157,"end_time":"2022-06-22T11:15:10.666902","exception":false,"start_time":"2022-06-22T11:15:10.640745","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_metrics(metrics, \n                smooth:float=1, \n                epsilon:float=1e-16, \n                enable_iou_metrics:bool=False):\n  dtype = getattr(tf, CONFIG.DTYPE)\n  if enable_iou_metrics: metrics.extend(\n                           [\n                            #iou_coef(dtype=dtype), \n                            iou_loss(\n                              dtype=dtype, \n                              smooth=smooth, \n                              epsilon=epsilon\n                              )\n                            ]\n                           )\n  return metrics","metadata":{"id":"f748b835","papermill":{"duration":0.035628,"end_time":"2022-06-22T11:15:10.728803","exception":false,"start_time":"2022-06-22T11:15:10.693175","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_custom_objects():\n  _custom_objects = None\n  if CONFIG.IOU_METRICS: \n    _custom_objects = {#'iou_coef':iou_coef, \n                       'iou_loss':iou_loss}\n    if CONFIG.IOU_LOSS: _custom_objects.update({'loss':iou_loss})\n  return _custom_objects","metadata":{"id":"f23c0f40","papermill":{"duration":0.037248,"end_time":"2022-06-22T11:15:10.792189","exception":false,"start_time":"2022-06-22T11:15:10.754941","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training function","metadata":{"id":"92c65898","papermill":{"duration":0.026398,"end_time":"2022-06-22T11:15:10.846067","exception":false,"start_time":"2022-06-22T11:15:10.819669","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def model_train(train_ds, \n                val_ds, \n                wt_file:str, \n                metrics:list, \n                callbacks:list, \n                model=None, \n                custom_objects=None, \n                tpu:bool=False, \n                verbose:bool=False):\n  opt = getattr(tf.keras.optimizers, CONFIG.OPTIMIZER)(CONFIG.LEARNING_RATE)\n\n  if CONFIG.IOU_LOSS:\n    loss = IoU_Loss(dtype=CONFIG.DTYPE, epsilon=1e-24)\n  elif CONFIG.STYLE=='multiclass':\n    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n  else:\n    loss = tfa.losses.SigmoidFocalCrossEntropy(from_logits=True)\n   \n  model = load_weights(wt_file, model, custom_objects=custom_objects, tpu=tpu)\n\n  model.compile(optimizer=opt, loss=loss, metrics=metrics)\n    \n  if verbose:\n    print('Memory usage at training start ...')\n    _ = mem_usage(); del _\n  if tpu:\n    model.fit(\n      train_ds, \n      validation_data=val_ds, \n      epochs=CONFIG.EPOCHS, \n      callbacks=callbacks\n      )\n    print('\\n... Finished training on TPU ...')\n  else:\n    history = model.fit(\n                train_ds, \n                validation_data=val_ds, \n                epochs=CONFIG.EPOCHS, \n                callbacks=cb\n                )\n    plot_history(history, metrics=metrics)\n  if verbose:\n    print('Memory usage at training end ...')\n    _ = mem_usage(); del _\n  return model","metadata":{"id":"d903b85b","papermill":{"duration":0.039239,"end_time":"2022-06-22T11:15:10.912688","exception":false,"start_time":"2022-06-22T11:15:10.873449","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_weights_file(fold:int=0, wt_filename:str='model.h5', wt_dir:str='./'):\n  if CONFIG.COLAB_KERNEL and not UPDATE_WEIGHTS: \n    wt_dir = CONFIG.GOOGLE_DRIVE\n  if fold is not None:\n    fold_wt_file = os.path.join(wt_dir, f'{wt_filename}-fold_{fold:02d}')\n    if os.path.exists(f'{fold_wt_file}.h5'): return f'{fold_wt_file}.h5'\n    elif os.path.exists(fold_wt_file): return fold_wt_file\n  elif UPDATE_WEIGHTS:\n    wt_file = f'{wt_dir}/{wt_filename}.h5'\n    if not(os.path.exists(wt_file)): wt_dir = './'\n  wt_file = os.path.join(wt_dir, wt_filename)\n  if os.path.exists(wt_file): return wt_file","metadata":{"id":"e5432714","papermill":{"duration":0.037566,"end_time":"2022-06-22T11:15:10.976604","exception":false,"start_time":"2022-06-22T11:15:10.939038","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def download_kaggle_weights():\n  cmds=[f'kaggle datasets download -d remananr/{CONFIG.WEIGHTS_DIR}',\n        f'mkdir ./{CONFIG.WEIGHTS_DIR}',\n        f'unzip ./{CONFIG.WEIGHTS_DIR}.zip -d ./{CONFIG.WEIGHTS_DIR}']\n  linux_shell(cmds)","metadata":{"id":"5488ead9","papermill":{"duration":0.034956,"end_time":"2022-06-22T11:15:11.03854","exception":false,"start_time":"2022-06-22T11:15:11.003584","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model training","metadata":{"id":"58b6cb14","papermill":{"duration":0.027683,"end_time":"2022-06-22T11:15:11.094404","exception":false,"start_time":"2022-06-22T11:15:11.066721","status":"completed"},"tags":[]}},{"cell_type":"code","source":"get_weights_file(\n  fold=1, \n  wt_filename=CONFIG.SAVED_WEIGHTS, \n  wt_dir=CONFIG.SAVED_WEIGHTS_DIR\n  )","metadata":{"id":"ylQnUs9gO--o","outputId":"69751eab-b925-483c-921a-493492186477","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG.ENABLE_TRAINING and CONFIG.TRAIN_VAL_SPLIT:\n  train_ds, val_ds = None, None\n  gkf = GroupKFold(n_splits=CONFIG.NUM_FOLDS)\n  train_df = df_process(train_df)\n  df1, df2, df3 = df_generator(train_df)\n  fold = 0\n  for train_idxs, val_idxs in gkf.split(df1, df2, df3):\n    print(f'\\n... Training fold: {fold} ...')  \n    split_train_df = df_dropna(df_indexer(train_df, train_idxs))\n    split_val_df = df_dropna(df_indexer(train_df, val_idxs))\n    if CONFIG.FOLD_SELECTION is None or (CONFIG.FOLD_SELECTION == fold):\n      try:\n        with strategy.scope():\n          wt_file = get_weights_file(\n                      fold=fold, \n                      wt_filename=CONFIG.SAVED_WEIGHTS, \n                      wt_dir=CONFIG.SAVED_WEIGHTS_DIR\n                      )\n          if (wt_file is None or \n              (UPDATE_WEIGHTS and \n               not os.path.exists(wt_file))) and \\\n               not CONFIG.KAGGLE_KERNEL:\n            download_kaggle_weights()\n\n          if not CONFIG.KAGGLE_KERNEL and wt_file is not None:\n            os.makedirs(\n              get_weights_file(\n                fold=1, wt_filename=CONFIG.SAVED_WEIGHTS, \n                wt_dir=CONFIG.SAVED_WEIGHTS_DIR\n                ).replace(CONFIG.SAVED_WEIGHTS,''),\n              exist_ok=True\n              )\n\n          tiny3d = get_segmentation_model()\n          \n          ckpt = f'{CONFIG.MODEL_NAME}-fold_{fold:02d}'\n          cb = get_callbacks(ckpt=ckpt, ckpt_dir='./', tpu=tpu)\n        \n          metrics = get_metrics(\n                      metrics=CONFIG.METRICS, \n                      enable_iou_metrics=CONFIG.IOU_METRICS\n                      )\n\n          custom_objects = get_custom_objects()\n\n          train_ds = make_train_dataset(\n                       split_train_df, \n                       batch_size=CONFIG.BATCH_SIZE\n                       )\n          val_ds = make_train_dataset(\n                     split_train_df, \n                     batch_size=CONFIG.BATCH_SIZE, mode='val'\n                     )\n          fold+=1\n          with warnings.catch_warnings(record=True):\n            tiny3d = model_train(\n                     train_ds, \n                     val_ds, \n                     wt_file=wt_file, \n                     metrics=metrics, \n                     callbacks=cb, \n                     model=tiny3d, \n                     custom_objects=custom_objects,\n                     tpu=tpu, \n                     verbose=CONFIG.VERBOSE\n                     )\n            if tpu and CONFIG.IOU_LOSS:\n              tiny3d.save_weights(f'{ckpt}.h5')\n\n          del train_ds, val_ds, tiny3d, split_train_df, split_val_df, \\\n              metrics, cb, custom_objects\n          clear_memory(clear_session=True)\n      except Exception as e:\n        print(f'Training encountered the following error: \\n\\n{e}')\n    else:\n      fold+=1    \nelif CONFIG.ENABLE_TRAINING:\n  with strategy.scope():\n    wt_file = os.path.join(CONFIG.SAVED_WEIGHTS_DIR, CONFIG.SAVED_WEIGHTS)\n    if CONFIG.COLAB_KERNEL and not UPDATE_WEIGHTS: \n      if not os.path.exists(wt_file):\n        wt_file = f'./{CONFIG.SAVED_WEIGHTS}'\n      if not os.path.exists(wt_file):\n        wt_file=os.path.join(CONFIG.GOOGLE_DRIVE, CONFIG.SAVED_WEIGHTS)\n\n    tiny3d = get_segmentation_model()\n    metrics = get_metrics(\n                metrics=CONFIG.METRICS,\n                enable_iou_metrics=CONFIG.IOU_METRICS\n                )\n    cb = get_callbacks(ckpt=CONFIG.SAVED_WEIGHTS, ckpt_dir='./', tpu=tpu)\n\n    model_train(\n      train_ds,\n      val_ds,\n      wt_file=wt_file,\n      metrics=metrics,\n      callbacks=cb,\n      model=tiny3d,\n      tpu=tpu,\n      custom_objects=get_custom_objects(),\n      verbose=CONFIG.VERBOSE\n      )","metadata":{"id":"1b8dddb5","papermill":{"duration":0.048896,"end_time":"2022-06-22T11:15:11.16953","exception":false,"start_time":"2022-06-22T11:15:11.120634","status":"completed"},"tags":[],"outputId":"aa478fcf-e957-46e0-b055-677f7c50b9f7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create test dataset","metadata":{"id":"baf134ba","papermill":{"duration":0.025951,"end_time":"2022-06-22T11:15:11.222366","exception":false,"start_time":"2022-06-22T11:15:11.196415","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test_ds = make_test_dataset(\n            sub_df, batch_size=CONFIG.TEST_BATCH_SIZE\n            )","metadata":{"id":"1161a36e","papermill":{"duration":0.442544,"end_time":"2022-06-22T11:15:11.691229","exception":false,"start_time":"2022-06-22T11:15:11.248685","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create model for inference","metadata":{"id":"ae6990dc","papermill":{"duration":0.026016,"end_time":"2022-06-22T11:15:11.743719","exception":false,"start_time":"2022-06-22T11:15:11.717703","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_inference_model(tpu):\n  wt_file = get_weights_file(\n              fold=CONFIG.FOLD_SELECTION,\n              wt_filename=CONFIG.SAVED_WEIGHTS,\n              wt_dir=CONFIG.SAVED_WEIGHTS_DIR\n              )\n  print(f'Loading weights from: {wt_file} ...')\n  custom_objects = get_custom_objects()\n  model = get_segmentation_model()\n  model = load_weights(\n            wt_file, model, custom_objects=custom_objects, tpu=tpu\n            )\n  return model","metadata":{"id":"569d9346","papermill":{"duration":0.038929,"end_time":"2022-06-22T11:15:11.810051","exception":false,"start_time":"2022-06-22T11:15:11.771122","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG.ENABLE_TRAINING and CONFIG.VERBOSE:\n  tiny3d = get_inference_model(tpu)","metadata":{"id":"ef2149dc","papermill":{"duration":0.036456,"end_time":"2022-06-22T11:15:11.874503","exception":false,"start_time":"2022-06-22T11:15:11.838047","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create predictions","metadata":{"id":"39215877","papermill":{"duration":0.026742,"end_time":"2022-06-22T11:15:11.929591","exception":false,"start_time":"2022-06-22T11:15:11.902849","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def tta_predictions(img, output_shape, model, img_aug_fn, mask_aug_fn):\n  tta_preds = np.zeros(output_shape)\n\n  for i in range(int(img.shape[0])):\n    aug_img = np.zeros(\n                (\n                   img.shape[1],\n                   img.shape[2],\n                   img.shape[3],\n                   img.shape[4]\n                   )\n                )\n\n    for j in range(img.shape[1]):\n      aug_img[j,:,:,:] = img_aug_fn(\n                              img[i,j,:,:,:]\n                              )\n    aug_img = tf.expand_dims(aug_img, axis=0)\n    aug_preds = model(aug_img)\n    aug_preds = tf.squeeze(aug_preds, axis=0)\n\n    for k in range(int(aug_preds.shape[2])):\n      tta_preds[i,:,:,k] = tf.squeeze(\n                             mask_aug_fn(\n                               tf.expand_dims(\n                                 aug_preds[:,:,k], axis=-1)\n                                 ), \n                               axis=-1\n                               )\n  return tta_preds\n\ndef get_predictions(img:tf.Tensor, model, style:str='multilabel', tta:bool=False):\n  _preds = model(img)\n  if tta:\n    tta_preds = tta_predictions(\n                  img, \n                  _preds.shape,\n                  model,\n                  tf.image.flip_left_right,\n                  tf.image.flip_left_right\n                  )\n    _preds = (tta_preds + _preds)/2                         \n  if style=='multilabel':\n    _preds = np.where(tf.nn.sigmoid(_preds)>=0.1, 1.0, 0.0)\n  else:\n    _preds = np.argmax(_preds, axis=-1)\n  return _preds","metadata":{"id":"7a2ccc54","papermill":{"duration":0.041866,"end_time":"2022-06-22T11:15:12.050879","exception":false,"start_time":"2022-06-22T11:15:12.009013","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot predictions","metadata":{"id":"e8cdcec3","papermill":{"duration":0.02674,"end_time":"2022-06-22T11:15:12.105737","exception":false,"start_time":"2022-06-22T11:15:12.078997","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_overlay(img, mask, alpha:float=0.999, beta:float=0.45, gamma:float=0):\n  img = (img/img.max()).astype(np.float32)\n  if len(mask.shape)!=3:\n    mask_rgb = np.zeros_like(img, dtype=np.float32)\n    mask_rgb[..., 2] = np.where(mask==3, 1.0, 0.0)\n    mask_rgb[..., 1] = np.where(mask==2, 1.0, 0.0)\n    mask_rgb[..., 0] = np.where(mask==1, 1.0, 0.0)\n  else:\n    mask_rgb=mask.astype(np.float32)\n  seg_overlay = cv2.addWeighted(src1=img, alpha=alpha, \n                                src2=mask_rgb, beta=beta, gamma=gamma)\n  return seg_overlay\n\ndef get_miss_overlay(gt_mask, pred_mask, _alpha:float=0.9, \n                     _beta:float=0.25, _gamma:float=0):\n  miss_rgb = np.zeros((*pred_mask.shape[:2],3), dtype=np.float32)\n  if len(pred_mask.shape)==2:\n    miss_rgb[..., 1] = np.where((gt_mask==pred_mask)&(gt_mask!=0), 0.8, 0.0)\n    miss_rgb[..., 0] = np.where((gt_mask!=pred_mask), 0.8, 0.0)\n  else:\n    miss_rgb = np.where((gt_mask==pred_mask) & (gt_mask!=0.0), \n                        (0.0,0.8,0.0), (0.0,0.0,0.0))\n    miss_rgb = np.where((gt_mask!=pred_mask), (0.8,0.0,0.0), miss_rgb)\n  return miss_rgb\n\ndef plot_preds(imgs, pred_mask, gt_mask):\n  img = imgs[0]  \n  gt_overlay = get_overlay(img, gt_mask)\n  pred_overlay = get_overlay(img, pred_mask)\n  miss_overlay = get_miss_overlay(gt_mask, pred_mask)\n\n  plt.figure(figsize=(20,12))\n\n  for i, (_desc, _img) in enumerate(zip(['Original', \n                                         'Prediction Mask', \n                                         'Ground-Truth Mask', \n                                         'Miss Mask'], \n                                        \n                                        [img, \n                                         pred_overlay, \n                                         gt_overlay, \n                                         miss_overlay])):        \n    plt.subplot(1,len(CONFIG.STRIDES)+4,i+1)\n    plt.imshow(_img)\n    plt.title(f'{_desc} Image', fontweight='bold')        \n    plt.axis(False)\n\n    if i in [1,2]:\n      handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), \n                                                           (0.0,0.667,0.0), \n                                                           (0.0,0.0,0.667)]]\n      labels = ['Large bowel segmentation map', \n                'Small bowel segmentation map', \n                'Stomach segmentation map']\n      plt.legend(handles,labels)\n    elif i==3:\n      handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.0, 0.8, 0.0), \n                                                           (0.8, 0.0, 0.0), \n                                                           (0.0, 0.0, 0.0)]]\n      labels = ['Agreement', 'Disagreement', 'Background']\n      plt.legend(handles,labels)\n\n  for i in range(len(CONFIG.STRIDES)):\n    _img = imgs[i+1]\n    plt.subplot(1,len(CONFIG.STRIDES)+4,4+i+1)\n    plt.imshow(_img)\n\n  plt.tight_layout()\n  plt.show()","metadata":{"id":"5bf78f70","papermill":{"duration":0.047006,"end_time":"2022-06-22T11:15:12.179324","exception":false,"start_time":"2022-06-22T11:15:12.132318","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sample predictions using training data","metadata":{"id":"4050c8c9","papermill":{"duration":0.027913,"end_time":"2022-06-22T11:15:12.234153","exception":false,"start_time":"2022-06-22T11:15:12.20624","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if CONFIG.VERBOSE:\n  tiny3d = get_inference_model(tpu)\n  if val_ds is None:\n    val_ds = make_train_dataset(\n               split_train_df if CONFIG.ENABLE_TRAINING else split_val_df, \n               batch_size=10, \n               mode='val'\n               )  \n  for _img_batch, _mask_batch in val_ds.take(1):\n    _pred_batch = get_predictions(_img_batch, tiny3d, style=CONFIG.STYLE)\n    _img_batch = ((_img_batch+1)*127.5).numpy().astype(np.int32)\n    _mask_batch = _mask_batch.numpy().squeeze().astype(np.float32)\n    break\n\n  for _img, _pred, _mask in zip(_img_batch, _pred_batch, _mask_batch):\n    plot_preds(_img, _pred, _mask)\n    del _img, _pred, _mask\n  del _img_batch, _pred_batch, _mask_batch","metadata":{"id":"78683c76","papermill":{"duration":0.038399,"end_time":"2022-06-22T11:15:12.299548","exception":false,"start_time":"2022-06-22T11:15:12.261149","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Housekeeping","metadata":{"id":"beeb28b8","papermill":{"duration":0.026107,"end_time":"2022-06-22T11:15:12.352241","exception":false,"start_time":"2022-06-22T11:15:12.326134","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if CONFIG.KAGGLE_KERNEL:\n  !rm -rf ./multi*\nelse:\n  !rm -rf {ROOT_DIR}/multi*\n\nhousekeeping()","metadata":{"id":"c435c8ca","papermill":{"duration":70.303318,"end_time":"2022-06-22T11:16:22.682429","exception":false,"start_time":"2022-06-22T11:15:12.379111","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{"id":"e63f2bf6","papermill":{"duration":0.026749,"end_time":"2022-06-22T11:16:22.736473","exception":false,"start_time":"2022-06-22T11:16:22.709724","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def pred_2_rle(pred_arr, root_shape):\n  # Get correct size pred array based on initial slice size\n  pred_arr = cv2.resize(pred_arr, root_shape, interpolation=cv2.INTER_NEAREST)\n    \n  # Get individual segmentation masks\n  lb_mask = np.where(pred_arr==1,1,0)\n  sb_mask = np.where(pred_arr==2,1,0)\n  st_mask = np.where(pred_arr==3,1,0)\n    \n  return rle_encode(lb_mask), rle_encode(sb_mask), rle_encode(st_mask)","metadata":{"id":"5f9906fb","papermill":{"duration":0.036651,"end_time":"2022-06-22T11:16:22.80039","exception":false,"start_time":"2022-06-22T11:16:22.763739","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_TEST_STEPS = int(np.ceil((len(sub_df)//3) / CONFIG.TEST_BATCH_SIZE))\nprint(f'Number of test steps: {NUM_TEST_STEPS} ...')","metadata":{"id":"726184d9","papermill":{"duration":0.037652,"end_time":"2022-06-22T11:16:22.865722","exception":false,"start_time":"2022-06-22T11:16:22.82807","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, img_batch in tqdm(enumerate(test_ds), total=NUM_TEST_STEPS):\n  if CONFIG.VERBOSE:\n    print(f'Memory usage at inference batch: {i} start ...')\n    _ = mem_usage(); del _; _ = gc.collect()\n\n  if i%CONFIG.CLEANUP_FREQUENCY==0:\n    clear_memory(clear_session=False)\n    if i==0: \n      mem_cleaner(['tiny3d']); clear_memory(clear_session=False); tiny3d=None \n      with strategy.scope():\n        tiny3d = get_inference_model(tpu)\n      if tiny3d is None:\n        raise ValueError(\n                '... No inference model found. Nothing to do here!!! ...'\n                )  \n    print(f'Processed test steps: {i}/{NUM_TEST_STEPS} ...')\n\n  if CONFIG.DEBUG and CONFIG.SPEED_SUB and i>=CONFIG.SPEED_SUB_SAMPLES: break\n\n  with strategy.scope():\n    pred_batch = get_predictions(\n                   img_batch, \n                   tiny3d, \n                   style=CONFIG.STYLE,\n                   tta=CONFIG.ENABLE_TTA\n                   )\n    if CONFIG.VERBOSE:\n      img_batch = ((img_batch+1)*127.5).numpy().astype(np.int32)\n    \n\n      for _img, _pred in zip(img_batch, pred_batch):\n        plot_preds(_img, _pred, _pred*0)\n        del _img, _pred\n  del img_batch\n\n  # Loop over prediction and determine submission dataframe index \n  # (3*individual-count because of reduced inference size)\n  for j, _pred in enumerate(pred_batch):\n    df_idx = 3*(i*CONFIG.TEST_BATCH_SIZE+j)\n    pred_rles = pred_2_rle(_pred, (sub_df.iloc[df_idx]['slice_h'], \n                                   sub_df.iloc[df_idx]['slice_w']))\n    del _pred\n\n    # Loop over rles and assign the correct row of the submission dataframe\n    for k, pred_rle in enumerate(pred_rles):\n      sub_df.loc[df_idx+k, 'predicted'] = pred_rle\n      del pred_rle\n    del pred_rles, df_idx\n  del pred_batch\n\n  if CONFIG.VERBOSE:\n    print(f'Memory usage at inference batch: {i} end ...')\n    _ = mem_usage(); del _; _ = gc.collect()\n\nmem_cleaner(['test_ds', 'tiny3d']); clear_memory(4, clear_session=True)","metadata":{"id":"333c356c","papermill":{"duration":29.816967,"end_time":"2022-06-22T11:16:52.711396","exception":false,"start_time":"2022-06-22T11:16:22.894429","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{"id":"f718b568","papermill":{"duration":0.027225,"end_time":"2022-06-22T11:16:52.766998","exception":false,"start_time":"2022-06-22T11:16:52.739773","status":"completed"},"tags":[]}},{"cell_type":"code","source":"sub_df = sub_df[['id', 'class', 'predicted']]\nsub_df.to_csv('submission.csv', index=False)\nif CONFIG.VERBOSE: display(sub_df)","metadata":{"id":"7c1fe7b6","papermill":{"duration":0.170144,"end_time":"2022-06-22T11:16:52.964837","exception":false,"start_time":"2022-06-22T11:16:52.794693","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Folder sync","metadata":{"id":"6d099569","papermill":{"duration":0.0273,"end_time":"2022-06-22T11:16:53.019781","exception":false,"start_time":"2022-06-22T11:16:52.992481","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if CONFIG.KAGGLE_KERNEL:\n  if not CONFIG.ENABLE_TRAINING:\n    wild_card_wt = os.path.join(CONFIG.SAVED_WEIGHTS_DIR, 'Eff*')\n    linux_shell([f'cp -r {wild_card_wt} ./', 'rm -rf ./multi*'])\nelse:\n  if CONFIG.ENABLE_TRAINING:\n    saved_wts = CONFIG.SAVED_WEIGHTS\n    if CONFIG.ENABLE_GOOGLE_DRIVE_CHECKPOINT:\n      saved_wts = os.path.join(CONFIG.GOOGLE_DRIVE, CONFIG.SAVED_WEIGHTS)\n      \n    if os.path.exists(f'{ROOT_DIR}/{CONFIG.SYNC_DIR}'):\n      linux_shell([f'cp -r {saved_wts}* {ROOT_DIR}/{CONFIG.SYNC_DIR}/'])\n    else:\n      os.makedirs(f'{ROOT_DIR}/{CONFIG.SYNC_DIR}', exist_ok=True)\n      linux_shell([f'cp -r {saved_wts}* {ROOT_DIR}/{CONFIG.SYNC_DIR}/'])\n  for dir in os.listdir(f'{ROOT_DIR}/{CONFIG.SYNC_DIR}'):\n    if os.path.isdir(f'{ROOT_DIR}/{CONFIG.SYNC_DIR}/{dir}'):\n      linux_shell(\n        [f'cd {ROOT_DIR}/{CONFIG.SYNC_DIR}/; zip -r ./{dir}.zip ./{dir}; cd ../',\n         f'rm -r {ROOT_DIR}/{CONFIG.SYNC_DIR}/{dir}/']\n        )\n  update_msg = 'Synced external directory ...' \n  linux_shell(\n    [f'kaggle datasets version -p {ROOT_DIR}/{CONFIG.SYNC_DIR} -m \"{update_msg}\"']\n    )","metadata":{"id":"201a9641","papermill":{"duration":7.580763,"end_time":"2022-06-22T11:17:00.628319","exception":false,"start_time":"2022-06-22T11:16:53.047556","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# References:\n**1. This notebook is forked and modified from the [original code notebook by @dschettler8845](https://www.kaggle.com/code/dschettler8845/uwmgit-deeplabv3-w-se-aspp-tf-e2e-pipeline)**\n\n**2. [University of Wisconsin-Madison gastro intestinal cancer segmentation dataset on Kaggle](https://www.kaggle.com/competitions/uw-madison-gi-tract-image-segmentation)**","metadata":{"id":"07620b7f","papermill":{"duration":0.029906,"end_time":"2022-06-22T11:17:00.688215","exception":false,"start_time":"2022-06-22T11:17:00.658309","status":"completed"},"tags":[]}},{"cell_type":"code","source":"","metadata":{"id":"26921157","papermill":{"duration":0.027225,"end_time":"2022-06-22T11:17:00.935899","exception":false,"start_time":"2022-06-22T11:17:00.908674","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}