{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **[Gastro intestinal tract image segmentation](https://www.kaggle.com/competitions/uw-madison-gi-tract-image-segmentation/)**\n## **Author: [Dr. Rahul Remanan](https://www.linkedin.com/in/rahulremanan/)**\n## **CEO, [Moad Computer](http://www.moad.computer/)**","metadata":{"id":"mBRP4u9FnnVT"}},{"cell_type":"markdown","source":"# Configuration","metadata":{"id":"eIRDAGvqnnWN"}},{"cell_type":"code","source":"ROOT_DIR = './'\nUPDATE_WEIGHTS = False\nCLOUD_DIR = '/content/drive/'","metadata":{"id":"OGqxWqYZnnWV","execution":{"iopub.status.busy":"2022-05-28T04:59:44.396808Z","iopub.execute_input":"2022-05-28T04:59:44.397632Z","iopub.status.idle":"2022-05-28T04:59:44.419052Z","shell.execute_reply.started":"2022-05-28T04:59:44.397541Z","shell.execute_reply":"2022-05-28T04:59:44.418365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CONFIG():\n  ##################################################################################\n    \n  #----------------------------- Change settings below ----------------------------#\n\n  ##################################################################################\n  KAGGLE_USERNAME = 'remananr'     # Your Kaggle username\n\n  GCS_BUCKET = 'gs://kds-5cfbc058b17caa8a1bd8982b1193f1c5381f45c742948f2a940c250d' # Set the latest GCS bucket address\n\n  SYNC_DIR = 'uwm-gi-segmentation-external-weights' # Your Kaggle sync dataset that receives the outputs from this notebook\n  SYNC_ID = 'uwm gi segmentation external weights' # Your Kaggle sync dataset title\n  WEIGHTS_DIR = 'uwm-gi-segmentation-keras-fcnnet-output' # Your Kaggle saved weights dataset \n  # WEIGHTS_DIR = 'uwm-gi-segmentation-external-weights'\n\n  GCP_TPU_WORKER = 'tpu_name'      # Your GCP worker address\n  GCP_ZONE = 'us-east1-b'          # Your GCP zone\n  GCP_PROJECT = 'gcp_project_name' # Your GCP project name\n\n  ################################################################################## \n\n  KAGGLE_KERNEL = False\n  COLAB_KERNEL = False\n\n  NOTEBOOK_ID = 'uw-madison-gi-tract-image-segmentation'\n\n  SEED = 246\n\n  ENABLE_TRAINING = False\n  TRAIN_BACKBONE = True\n\n  TRAIN_VAL_SPLIT = True\n\n  FOLD_SELECTION = 1 # None\n\n  SAVE_MASKS = False\n\n  VERBOSE = False\n  TF_VERBOSITY = '3'\n\n  DEBUG = False\n\n  DATA_DIR = f'{ROOT_DIR}/{NOTEBOOK_ID}'\n  TRAIN_DIR = 'train'\n  TEST_DIR = 'test'\n\n  TRAIN_CSV = 'train.csv'\n  SUBMISSION_CSV = 'sample_submission.csv'\n\n  CUDA_MALLOC = 'cuda_malloc_async'\n\n  TPU = None\n  USE_GCP_TPU = False\n\n  GOOGLE_DRIVE = f'{CLOUD_DIR}/MyDrive/Kaggle/{NOTEBOOK_ID}'\n\n  USE_JIT = False\n\n  CLASSES = ['Large Bowel', 'Small Bowel', 'Stomach']\n  SHORTFORM_CLASSES = ['lb', 'sb', 'st']\n\n  STYLE = 'multiclass'\n\n  BACKBONE = 'EfficientNetB3' # 'EfficientNetB7' # 'EfficientNetV2L' # \n\n  IMAGE_SIZE = (256, 256) # (512, 512) # (576, 576) # (640, 640) # (768, 768) # \n  MASK_SIZE  = IMAGE_SIZE\n\n  BATCH_SIZE =  24 # 3 # 4 # 8 # 16 # 96 # 128 # 64 # 256 # \n  DEBUG_BATCH_SIZE = 2\n  TEST_BATCH_SIZE = 2\n    \n  SHUFFLE_BUFFER = max(BATCH_SIZE*25, 500)\n  OPTIMUM_SHUFFLE = False\n    \n  FLIP_HORIZONTAL = True\n  FLIP_VERTICAL = True\n  RANDOM_BRIGHTNESS = True\n  RANDOM_CONTRAST = True\n  RANDOM_GAMMA = False\n  RANDOM_HUE = True\n  RANDOM_SATURATION = True\n  \n  NUM_FOLDS = 3\n\n  EPOCHS = 32             # 1 # 6 # 16 #\n  OPTIMIZER = 'Adam'      # 'Adagrad'  # \n  LEARNING_RATE = 7.5e-3  # 7.5e-4  # 1e-8 #\n\n  EVAL_FUNCTION = 'val_loss' # 'val_iou_coef' 'val_acc'  # \n  EVAL_FUNCTION_MODE = 'min' # 'max' # \n\n  FC_DIM = (64, 64, 3)\n\n  METRICS = ['acc']\n  IOU_METRICS = True\n  IOU_LOSS = False\n\n  DTYPE = 'float32'\n  \n  PRETRAINED_WEIGHTS_DIR = f'{ROOT_DIR}/{SYNC_DIR}/no_top'\n  PRETRAINED_WEIGHTS = 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n  DEFAULT_PRETRAINED_WEIGHTS = None # 'imagenet' #\n\n  MODEL_SUMMARY = 'summary' # 'plot' #\n\n  FC_DIM_ID = f'{FC_DIM[0]}x{FC_DIM[1]}x{FC_DIM[2]}'\n  MODEL_ID = f'{BACKBONE}_{FC_DIM_ID}'\n  MODEL_NAME = f'{MODEL_ID}_{IMAGE_SIZE[0]}x{IMAGE_SIZE[1]}x3_{STYLE}'\n  \n  SAVED_WEIGHTS_DIR = f'{ROOT_DIR}/{WEIGHTS_DIR}/'  \n  SAVED_WEIGHTS = f'{MODEL_NAME}'\n\n  SPEED_SUB = True\n  SPEED_SUB_SAMPLES = BATCH_SIZE # 200 #\n    \n  CLEANUP_FREQUENCY = 25  ","metadata":{"id":"Olvi_HJEnnWg","execution":{"iopub.status.busy":"2022-05-28T04:59:45.1968Z","iopub.execute_input":"2022-05-28T04:59:45.197562Z","iopub.status.idle":"2022-05-28T04:59:45.210671Z","shell.execute_reply.started":"2022-05-28T04:59:45.197526Z","shell.execute_reply":"2022-05-28T04:59:45.209939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CONFIG.BATCH_SIZE = CONFIG.BATCH_SIZE if CONFIG.ENABLE_TRAINING else \\\n                    CONFIG.DEBUG_BATCH_SIZE if CONFIG.DEBUG else 1\nif CONFIG.VERBOSE: print(f'Setting batch size to: {CONFIG.BATCH_SIZE}')","metadata":{"id":"tdCYINDEnnWw","outputId":"a2940bf2-be26-4bc5-f5d4-01550a21cbf7","execution":{"iopub.status.busy":"2022-05-28T04:59:45.212738Z","iopub.execute_input":"2022-05-28T04:59:45.213308Z","iopub.status.idle":"2022-05-28T04:59:45.226925Z","shell.execute_reply.started":"2022-05-28T04:59:45.21327Z","shell.execute_reply":"2022-05-28T04:59:45.226038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setup functions","metadata":{"id":"S4PPSttWPDZ9"}},{"cell_type":"code","source":"import os, psutil\ndef auto_environment():\n  kaggle_kernel, colab_kernel = False, False\n  try:\n    from kaggle_datasets import KaggleDatasets\n    kaggle_kernel=True\n    print('Running in Kaggle kernel mode ...')\n    root_dir = '/kaggle/input/'\n  except:\n    kaggle_kernel=False\n    root_dir = './'\n  try:\n    import google.colab\n    colab_kernel=True\n    print('Running in Google Colab mode ...')\n    root_dir = '/content/'\n  except:\n    colab_kernel=False\n  return kaggle_kernel, colab_kernel, root_dir\n\ndef auto_setup():\n  try:\n    import tensorflow_addons as tfa\n    print('Skipping setup ...')\n    return False\n  except:\n    return True\n\ndef auto_data_download(google_drive:str, notebook_id:str):\n  if os.path.exists(os.path.join(google_drive, f'{notebook_id}.zip')):\n    print('Skipping data download ...')\n    return False\n  else:\n    print('Configured to download raw data from Kaggle ...')\n    return True    \n\ndef mount_google_drive(mount_dir:str='/content/drive/'):\n  from google.colab import drive\n  drive.mount(mount_dir)\n\ndef linux_shell(cmd_list:list, verbose:bool=False):\n  for cmd in cmd_list:\n    if verbose:\n      print(f'Executing linux command: {cmd}')\n    os.system(cmd)\n    \ndef clear_memory(num_tries:int=2, clear_session:bool=False):\n  for i in range(num_tries):\n    _ = gc.collect()\n  if clear_session: tf.keras.backend.clear_session()\n  _ = gc.collect()\n\ndef memory_utilization():\n  print('Current memory utilization: {}% ...'.format(psutil.virtual_memory().percent))\n\ndef save_pickle(var, file:str='file.pkl', protocol=-1, \n                compression:bool=True, \n                delete:bool=True, \n                verbose:bool=False):\n  if verbose: print(f'Memory utilization: \\n{memory_utilization()}')\n  #==Create Pickle dump===\n  if compression:\n     with gzip.open(file, 'wb') as f:\n       pickle.dump(var, f, protocol)\n  else:\n    pickle.dump(var, open(file,'wb'))\n  if verbose: print(f'Memory utilization: \\n{memory_utilization()}')\n  #===Delete the unused variable from memory===\n  if delete:\n    del var\n    _ = gc.collect()\n    if verbose: print(f'Memory utilization after deletion: \\n{memory_utilization()}')\n\ndef load_pickle(file:str, compression:bool=True):\n  if compression:\n    with gzip.open(file, 'rb') as f:\n      return pickle.load(f)\n  else:\n    return pickle.load(open(file, 'rb'))","metadata":{"id":"R8PuUx6fn2t2","execution":{"iopub.status.busy":"2022-05-28T04:59:45.228684Z","iopub.execute_input":"2022-05-28T04:59:45.229053Z","iopub.status.idle":"2022-05-28T04:59:45.245731Z","shell.execute_reply.started":"2022-05-28T04:59:45.229018Z","shell.execute_reply":"2022-05-28T04:59:45.244904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Autodetect kernel environment","metadata":{"id":"eHP_G0pBPDaL"}},{"cell_type":"code","source":"CONFIG.KAGGLE_KERNEL, CONFIG.COLAB_KERNEL, ROOT_DIR = auto_environment()\nCONFIG.DATA_DIR = f'{ROOT_DIR}/{CONFIG.NOTEBOOK_ID}'  \nCONFIG.PRETRAINED_WEIGHTS_DIR = f'{ROOT_DIR}/{CONFIG.SYNC_DIR}/no_top'  \nCONFIG.SAVED_WEIGHTS_DIR = f'{ROOT_DIR}/{CONFIG.WEIGHTS_DIR}'\nif not CONFIG.KAGGLE_KERNEL and CONFIG.COLAB_KERNEL:\n  mount_google_drive(mount_dir=CLOUD_DIR)","metadata":{"id":"Gb-LJe3Cn3r3","outputId":"0e309536-736f-4d1a-db38-d1b48e631248","execution":{"iopub.status.busy":"2022-05-28T04:59:45.247245Z","iopub.execute_input":"2022-05-28T04:59:45.247808Z","iopub.status.idle":"2022-05-28T04:59:45.26096Z","shell.execute_reply.started":"2022-05-28T04:59:45.247771Z","shell.execute_reply":"2022-05-28T04:59:45.259882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SETUP, DOWNLOAD_RAW_DATA = False, False  \nif not CONFIG.KAGGLE_KERNEL:\n  SETUP, DOWNLOAD_RAW_DATA = auto_setup(), auto_data_download(CONFIG.GOOGLE_DRIVE, \n                                                              CONFIG.NOTEBOOK_ID)","metadata":{"id":"SIirhTNfaVBD","outputId":"7a9e869a-037d-4ee4-9e22-571db838e90c","execution":{"iopub.status.busy":"2022-05-28T04:59:45.26331Z","iopub.execute_input":"2022-05-28T04:59:45.263749Z","iopub.status.idle":"2022-05-28T04:59:45.273938Z","shell.execute_reply.started":"2022-05-28T04:59:45.26371Z","shell.execute_reply":"2022-05-28T04:59:45.273142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup and data management outside Kaggle","metadata":{"id":"EtUbT2IcPDad"}},{"cell_type":"code","source":"import json\nif (not CONFIG.KAGGLE_KERNEL) and SETUP:\n  with open(f'{ROOT_DIR}/dataset-metadata.json', 'w') as f:\n    json.dump({'title' : CONFIG.SYNC_ID,\n               'id'    : f'{CONFIG.KAGGLE_USERNAME}/{CONFIG.SYNC_DIR}'}, f)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T04:59:45.334836Z","iopub.execute_input":"2022-05-28T04:59:45.335668Z","iopub.status.idle":"2022-05-28T04:59:45.343535Z","shell.execute_reply.started":"2022-05-28T04:59:45.335612Z","shell.execute_reply":"2022-05-28T04:59:45.342557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nif (not CONFIG.KAGGLE_KERNEL) and SETUP:\n  setup_cmds = ['mkdir ~/.kaggle/',\n                'cp ./kaggle.json ~/.kaggle/kaggle.json',\n                'chmod 600 ~/.kaggle/kaggle.json',\n                'python3 -m pip uninstall -q -y kaggle',\n                'python3 -m pip install -q kaggle==1.5.12',\n                f'mkdir {ROOT_DIR}/{CONFIG.NOTEBOOK_ID}',\n                f'mkdir {ROOT_DIR}/{CONFIG.SYNC_DIR}',\n                f'mkdir {ROOT_DIR}/{CONFIG.WEIGHTS_DIR}',]\n  if DOWNLOAD_RAW_DATA:\n    setup_cmds.extend([\n        f'kaggle competitions download -c {CONFIG.NOTEBOOK_ID} --force -p {ROOT_DIR}',\n        f'unzip {ROOT_DIR}/{CONFIG.NOTEBOOK_ID}.zip -d {ROOT_DIR}/{CONFIG.NOTEBOOK_ID}'])\n    if CONFIG.COLAB_KERNEL:\n      setup_cmds.extend([\n        f'mkdir {CLOUD_DIR}/MyDrive/Kaggle/{CONFIG.NOTEBOOK_ID}',\n        f'cp {ROOT_DIR}/{CONFIG.NOTEBOOK_ID}.zip {CONFIG.GOOGLE_DRIVE}'])\n    setup_cmds.append(f'rm {ROOT_DIR}/{CONFIG.NOTEBOOK_ID}.zip')\n  elif CONFIG.COLAB_KERNEL:\n    zip_file = f'{CONFIG.GOOGLE_DRIVE}/{CONFIG.NOTEBOOK_ID}.zip'\n    setup_cmds.append(\n        f'unzip {zip_file} -d {ROOT_DIR}/{CONFIG.NOTEBOOK_ID}')\n\n  if UPDATE_WEIGHTS or DOWNLOAD_RAW_DATA: \n    if CONFIG.SYNC_DIR is not None:\n      kaggle_sync_ds = f'{CONFIG.KAGGLE_USERNAME}/{CONFIG.SYNC_DIR}'  \n      setup_cmds.extend([\n        f'kaggle datasets download -d {kaggle_sync_ds} --force -p {ROOT_DIR}',\n        f'unzip -q {ROOT_DIR}/{CONFIG.SYNC_DIR}.zip -d {ROOT_DIR}/{CONFIG.SYNC_DIR}'])\n    if CONFIG.COLAB_KERNEL:\n      setup_cmds.append(\n          f'cp {ROOT_DIR}/{CONFIG.SYNC_DIR}.zip {CONFIG.GOOGLE_DRIVE}')  \n    setup_cmds.append(f'rm {ROOT_DIR}/{CONFIG.SYNC_DIR}.zip')  \n    if CONFIG.WEIGHTS_DIR is not None:\n      kaggle_wt_ds = f'{CONFIG.KAGGLE_USERNAME}/{CONFIG.WEIGHTS_DIR}'  \n      setup_cmds.extend([\n        f'kaggle datasets download -d {kaggle_wt_ds} --force -p {ROOT_DIR}',\n        f'unzip -q {ROOT_DIR}/{CONFIG.WEIGHTS_DIR}.zip -d {ROOT_DIR}/{CONFIG.WEIGHTS_DIR}'])\n      if CONFIG.COLAB_KERNEL:\n        setup_cmds.append(\n          f'cp {ROOT_DIR}/{CONFIG.WEIGHTS_DIR}.zip {CONFIG.GOOGLE_DRIVE}')\n      setup_cmds.append(f'rm {ROOT_DIR}/{CONFIG.WEIGHTS_DIR}.zip')\n  if os.path.exists(f'{ROOT_DIR}/kaggle.json'):\n    linux_shell(setup_cmds)\n  else:\n    raise ValueError(\n      f'Kaggle config JSON not found. Upload kaggle.json to: {ROOT_DIR} ...')","metadata":{"id":"-rKqteR2oh_l","execution":{"iopub.status.busy":"2022-05-28T04:59:45.477728Z","iopub.execute_input":"2022-05-28T04:59:45.478116Z","iopub.status.idle":"2022-05-28T04:59:45.489411Z","shell.execute_reply.started":"2022-05-28T04:59:45.478085Z","shell.execute_reply":"2022-05-28T04:59:45.488333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nif SETUP and not CONFIG.KAGGLE_KERNEL:\n  metadata_file = f'{ROOT_DIR}/dataset-metadata.json'\n  sync_dir = f'{ROOT_DIR}/{CONFIG.SYNC_DIR}'\n  if not os.path.exists(metadata_file):\n    metadata_warnings = [f'\\n\\tMetadata file: {metadata_file} not found ...',\n                         f'\\n\\tUnable to sync {sync_dir} to Kaggle ...',\n                         f'\\n\\tCreate {metadata_file} to enable sync to Kaggle ...']\n    warnings.warn(''.join(metadata_warnings))\n  upload_dir_cmds = [f'kaggle datasets init -p {sync_dir}',\n                     f'rm {sync_dir}/dataset-metadata.json',\n                     f'cp {metadata_file} {sync_dir}']\n  linux_shell(upload_dir_cmds)","metadata":{"id":"ZOXHB1y8JbDT","execution":{"iopub.status.busy":"2022-05-28T04:59:45.524835Z","iopub.execute_input":"2022-05-28T04:59:45.525133Z","iopub.status.idle":"2022-05-28T04:59:45.530401Z","shell.execute_reply.started":"2022-05-28T04:59:45.525108Z","shell.execute_reply":"2022-05-28T04:59:45.529468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import libraries","metadata":{"id":"Z_y-FICXnnW1"}},{"cell_type":"code","source":"try:\n  from kaggle_datasets import KaggleDatasets\n  CONFIG.KAGGLE_KERNEL = True\nexcept:\n  print('Running outside of Kaggle ...')\n  print('Ensure data and dependent libraries are already setup ...')\n  CONFIG.KAGGLE_KERNEL = False","metadata":{"id":"SmJDWXgjnnW4","outputId":"c105245c-3131-400d-aa6a-8ea9b70cbd11","execution":{"iopub.status.busy":"2022-05-28T04:59:45.679287Z","iopub.execute_input":"2022-05-28T04:59:45.681158Z","iopub.status.idle":"2022-05-28T04:59:45.685391Z","shell.execute_reply.started":"2022-05-28T04:59:45.681113Z","shell.execute_reply":"2022-05-28T04:59:45.684561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re, gc, os, io, sys, ast, gzip, time, math, json, string, shutil, random, logging, \\\n       urllib, pickle, zipfile, sklearn, IPython, imageio, hashlib, requests, warnings\n\nfrom glob import glob\nfrom pathlib import Path\nfrom datetime import datetime\nfrom collections import Counter\nfrom json import JSONDecodeError\nfrom sklearn.model_selection import GroupKFold, StratifiedKFold\nfrom sklearn.preprocessing import RobustScaler, PolynomialFeatures","metadata":{"id":"v6y5h-hmnnXB","execution":{"iopub.status.busy":"2022-05-28T04:59:45.765015Z","iopub.execute_input":"2022-05-28T04:59:45.765959Z","iopub.status.idle":"2022-05-28T04:59:46.796754Z","shell.execute_reply.started":"2022-05-28T04:59:45.765901Z","shell.execute_reply":"2022-05-28T04:59:46.794335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n  from pandarallel import pandarallel; pandarallel.initialize();\nexcept:\n  print('Not importing pandarallel ...')","metadata":{"id":"7KydJGGuK74q","outputId":"e16382dc-5df8-4d1d-fa1a-6e3d464709e1","execution":{"iopub.status.busy":"2022-05-28T04:59:46.80008Z","iopub.execute_input":"2022-05-28T04:59:46.800476Z","iopub.status.idle":"2022-05-28T04:59:46.834677Z","shell.execute_reply.started":"2022-05-28T04:59:46.800437Z","shell.execute_reply":"2022-05-28T04:59:46.833805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Set CUDA malloc environment variable","metadata":{"id":"bvhubvXqnnXO"}},{"cell_type":"code","source":"def set_cuda_malloc_env(malloc:str):\n  os.environ['TF_GPU_ALLOCATOR']=malloc\n\ndef set_tf_verbosity(verbose:bool):\n  os.environ['AUTOGRAPH_VERBOSITY'] = '0'  \n  os.environ['TF_CPP_MIN_LOG_LEVEL'] = verbose  \n  logging.getLogger('tensorflow').setLevel(logging.FATAL)\n  logging.getLogger('tensorflow').disabled = True  \n  import tensorflow as tf\n  tf.autograph.set_verbosity(0)\n  tf.get_logger().setLevel(logging.FATAL)  \n  tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.FATAL)  # or any {DEBUG, INFO, WARN, ERROR, FATAL}\n    \ndef set_python_warnings_verbosity(verbose:bool):\n  if not verbose:\n    warnings.filterwarnings('ignore')\n\nset_cuda_malloc_env(CONFIG.CUDA_MALLOC)\nset_tf_verbosity(CONFIG.TF_VERBOSITY)\nset_python_warnings_verbosity(CONFIG.VERBOSE)","metadata":{"id":"sRtazAZennXU","execution":{"iopub.status.busy":"2022-05-28T04:59:46.836362Z","iopub.execute_input":"2022-05-28T04:59:46.836936Z","iopub.status.idle":"2022-05-28T04:59:50.921912Z","shell.execute_reply.started":"2022-05-28T04:59:46.836895Z","shell.execute_reply":"2022-05-28T04:59:50.921111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Machine learning imports","metadata":{"id":"C9NZfVm-nnXZ"}},{"cell_type":"code","source":"if SETUP and not CONFIG.KAGGLE_KERNEL: \n  linux_shell(['python3 -m pip install tensorflow-addons'])","metadata":{"id":"uV1o4tPSLWFQ","execution":{"iopub.status.busy":"2022-05-28T04:59:50.923878Z","iopub.execute_input":"2022-05-28T04:59:50.92414Z","iopub.status.idle":"2022-05-28T04:59:50.929061Z","shell.execute_reply.started":"2022-05-28T04:59:50.924115Z","shell.execute_reply":"2022-05-28T04:59:50.927631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn, numpy as np, pandas as pd, tensorflow as tf, \\\n       tensorflow_hub as tfhub, tensorflow_addons as tfa\npd.options.mode.chained_assignment = None\n\nfrom tensorflow.keras import backend as K\nfrom tensorflow.python.autograph.impl.api import tf_convert\nfrom tensorflow.python.autograph.core.ag_ctx import control_status_ctx","metadata":{"id":"dZm56RVdnnXd","execution":{"iopub.status.busy":"2022-05-28T04:59:50.930385Z","iopub.execute_input":"2022-05-28T04:59:50.931026Z","iopub.status.idle":"2022-05-28T04:59:52.369657Z","shell.execute_reply.started":"2022-05-28T04:59:50.93099Z","shell.execute_reply":"2022-05-28T04:59:52.368844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Image processing and visualization imports","metadata":{"id":"34ScskgNnnXi"}},{"cell_type":"code","source":"import cv2, PIL, plotly,matplotlib,           \\\n       seaborn as sns,                        \\\n       plotly.express as px,                  \\\n       matplotlib.pyplot as plt,              \\\n       plotly.graph_objects as go,            \\\n       matplotlib.patches as patches,         \\\n       plotly.io as pio; print(pio.renderers)\n\nfrom PIL import Image, ImageEnhance\nfrom tqdm.notebook import tqdm; tqdm.pandas()\nfrom matplotlib.patches import Rectangle\nfrom matplotlib.colors import ListedColormap\nfrom matplotlib import animation, rc; rc('animation', html='jshtml')","metadata":{"id":"V49PawgAnnXl","outputId":"ad8ce259-3a32-42b5-983e-86a97cd80a60","execution":{"iopub.status.busy":"2022-05-28T04:59:52.371649Z","iopub.execute_input":"2022-05-28T04:59:52.371924Z","iopub.status.idle":"2022-05-28T04:59:55.088088Z","shell.execute_reply.started":"2022-05-28T04:59:52.371899Z","shell.execute_reply":"2022-05-28T04:59:55.087269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Version info for machine learning libraries","metadata":{"id":"mjKzfwktnnXp"}},{"cell_type":"code","source":"class mlLibs_info():\n  def __init__(self, ml_libs_info):\n    self.ml_libs_info = ml_libs_info\n  def _formatter(self, k, v):\n    return '\\n\\t\\tâ€“ {:>30} version: {} {:>8}'.format(k,' ',v)\n  def _mlLibs_info(self):\n    for k in self.ml_libs_info:\n      print(self._formatter(k, self.ml_libs_info[k]))\n  def __call__(self):\n    self._mlLibs_info()\n\nmlLibs_info( {'Numpy'             : np.__version__,\n              'SKLearn'           : sklearn.__version__,\n              'MatPlotLib'        : matplotlib.__version__,\n              'Tensorflow'        :  tf.__version__,\n              'Tensorflow Hub'    : tfhub.__version__,\n              'Tensorflow Addons' : tfa.__version__} )()","metadata":{"id":"PU7anjVXnnXs","outputId":"844a8af7-3745-4a8d-8ec1-edd93e93fb2a","execution":{"iopub.status.busy":"2022-05-28T04:59:55.089452Z","iopub.execute_input":"2022-05-28T04:59:55.089983Z","iopub.status.idle":"2022-05-28T04:59:55.098901Z","shell.execute_reply.started":"2022-05-28T04:59:55.089944Z","shell.execute_reply":"2022-05-28T04:59:55.097925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## List visible devices in Tensorflow","metadata":{}},{"cell_type":"code","source":"tf.config.list_physical_devices()","metadata":{"execution":{"iopub.status.busy":"2022-05-28T04:59:55.100471Z","iopub.execute_input":"2022-05-28T04:59:55.1009Z","iopub.status.idle":"2022-05-28T04:59:55.180803Z","shell.execute_reply.started":"2022-05-28T04:59:55.100844Z","shell.execute_reply":"2022-05-28T04:59:55.179923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setting seed value for reproducibility","metadata":{"id":"UIhWw0u7nnXx"}},{"cell_type":"code","source":"def set_seed(seed:int):\n  ''' Setting seeds for reproducibility '''\n  print(f'\\n... Setting seeds using: {seed} ...')\n  os.environ['PYTHONHASHSEED'] = str(seed)\n  random.seed(seed)\n  np.random.seed(seed)\n  tf.random.set_seed(seed)\n\nset_seed(CONFIG.SEED)","metadata":{"id":"QdWyD0axnnX0","outputId":"f93d6010-c367-46af-eb49-27863c71c8c1","execution":{"iopub.status.busy":"2022-05-28T04:59:55.182176Z","iopub.execute_input":"2022-05-28T04:59:55.183183Z","iopub.status.idle":"2022-05-28T04:59:55.191472Z","shell.execute_reply.started":"2022-05-28T04:59:55.183099Z","shell.execute_reply":"2022-05-28T04:59:55.19059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Heterogeneous compute","metadata":{"id":"rs0ENk46nnX3"}},{"cell_type":"code","source":"def gcp_tpu_setup():\n  return tf.distribute.cluster_resolver.TPUClusterResolver(tpu=CONFIG.GCP_TPU_WORKER, \n                                                           zone=CONFIG.GCP_ZONE, \n                                                           project=CONFIG.GCP_PROJECT)","metadata":{"id":"bW5s5_HhnnX5","execution":{"iopub.status.busy":"2022-05-28T04:59:55.194977Z","iopub.execute_input":"2022-05-28T04:59:55.195531Z","iopub.status.idle":"2022-05-28T04:59:55.201287Z","shell.execute_reply.started":"2022-05-28T04:59:55.195504Z","shell.execute_reply":"2022-05-28T04:59:55.200361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def heterogeneous_compute(TPU):\n  tpu, gpu, cpu = False, False, True\n\n  if TPU is not None and TPU:\n    print(f'\\n... Heterogeneous compute using TPU - {TPU.master()}...')\n    try:\n      tf.config.experimental_connect_to_cluster(TPU)\n      tf.tpu.experimental.initialize_tpu_system(TPU)\n      strategy = tf.distribute.TPUStrategy(TPU)\n      tpu = True\n    except:\n      tpu = False\n      strategy = tf.distribute.get_strategy()\n  else:\n    try:\n      physical_devices = tf.config.list_physical_devices('GPU')\n    except:\n      physical_devices = []\n    if len(physical_devices) >= 1:\n      print(f'\\n... Heterogeneous compute using GPU ...')\n      gpu = True\n    else:\n      print(f'\\n... Running on CPU ...')\n      cpu = True\n    try:\n      tf.config.experimental.set_memory_growth(physical_devices[0], True)\n    except:\n      warnings.warn('\\nFailed to set device memory growth ...')  \n    strategy = tf.distribute.get_strategy()\n\n  num_replicas = strategy.num_replicas_in_sync  \n  print(f'... Number of replicas: {num_replicas} ...\\n')\n  print(f'\\n... Heterogeneous computation setup finished ...\\n')\n\n  return tpu, gpu, cpu, strategy","metadata":{"id":"ixfvx8XannX9","execution":{"iopub.status.busy":"2022-05-28T04:59:55.202462Z","iopub.execute_input":"2022-05-28T04:59:55.202961Z","iopub.status.idle":"2022-05-28T04:59:55.213578Z","shell.execute_reply.started":"2022-05-28T04:59:55.202924Z","shell.execute_reply":"2022-05-28T04:59:55.212824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if (CONFIG.KAGGLE_KERNEL and CONFIG.TPU is None) or CONFIG.COLAB_KERNEL:\n  try:\n    CONFIG.TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  \n  except:\n    CONFIG.TPU = None\nelif CONFIG.USE_GCP_TPU:\n  CONFIG.TPU = gcp_tpu_setup()\n\ntpu, gpu, cpu, strategy = heterogeneous_compute(CONFIG.TPU)","metadata":{"id":"EEvnIlO-nnYB","outputId":"19f4d6c1-9ae7-4e8c-a166-978dc22f4e69","execution":{"iopub.status.busy":"2022-05-28T04:59:55.215929Z","iopub.execute_input":"2022-05-28T04:59:55.216181Z","iopub.status.idle":"2022-05-28T04:59:55.234281Z","shell.execute_reply.started":"2022-05-28T04:59:55.216158Z","shell.execute_reply":"2022-05-28T04:59:55.233131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setting-up storage bucket","metadata":{"id":"EEZg4G36PDcK"}},{"cell_type":"code","source":"try:\n  GCS_BUCKET = KaggleDatasets().get_gcs_path(CONFIG.NOTEBOOK_ID)\n  print(f'... GCS bucket address: {GCS_BUCKET} ...')\nexcept:\n  GCS_BUCKET = CONFIG.GCS_BUCKET  \nif tpu:\n  CONFIG.DATA_DIR = GCS_BUCKET  \n  save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n  load_locally = tf.saved_model.LoadOptions(experimental_io_device='/job:localhost')\nelse:\n  save_locally, load_locally = None, None\n\nprint(f'\\n... Data directory:\\n\\t--> {CONFIG.DATA_DIR}')\nprint(f'\\n... Directory listing :')\nfor file in tf.io.gfile.glob(os.path.join(CONFIG.DATA_DIR, '*')): print(f'\\t--> {file}')","metadata":{"id":"RNtL7t3onnYD","outputId":"9871e058-0871-4af7-acc6-91ae56ee9c70","execution":{"iopub.status.busy":"2022-05-28T04:59:55.2355Z","iopub.execute_input":"2022-05-28T04:59:55.235857Z","iopub.status.idle":"2022-05-28T05:00:15.284295Z","shell.execute_reply.started":"2022-05-28T04:59:55.235821Z","shell.execute_reply":"2022-05-28T05:00:15.283413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## JIT settings","metadata":{"id":"fJnYaTqCPDcQ"}},{"cell_type":"code","source":"try:\n  tf.config.optimizer.set_jit(CONFIG.USE_JIT)\nexcept:\n  print('Failed to set TF JIT values ...')","metadata":{"id":"1RNeKAvtnnYI","execution":{"iopub.status.busy":"2022-05-28T05:00:15.285436Z","iopub.execute_input":"2022-05-28T05:00:15.286348Z","iopub.status.idle":"2022-05-28T05:00:15.291643Z","shell.execute_reply.started":"2022-05-28T05:00:15.286307Z","shell.execute_reply":"2022-05-28T05:00:15.290764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read training data","metadata":{"id":"2pEsP6YinnYK"}},{"cell_type":"code","source":"train_dir = os.path.join(CONFIG.DATA_DIR, CONFIG.TRAIN_DIR)\ntrain_csv = os.path.join(CONFIG.DATA_DIR, CONFIG.TRAIN_CSV)\ntest_dir  = os.path.join(CONFIG.DATA_DIR, CONFIG.TEST_DIR)\nsub_csv   = os.path.join(CONFIG.DATA_DIR, CONFIG.SUBMISSION_CSV)","metadata":{"id":"Au1o2qZynnYR","execution":{"iopub.status.busy":"2022-05-28T05:00:15.293866Z","iopub.execute_input":"2022-05-28T05:00:15.29426Z","iopub.status.idle":"2022-05-28T05:00:15.308195Z","shell.execute_reply.started":"2022-05-28T05:00:15.294221Z","shell.execute_reply":"2022-05-28T05:00:15.307391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Get train and test image file-paths","metadata":{"id":"d8YDFeP5nnYT"}},{"cell_type":"code","source":"if tpu and CONFIG.ENABLE_TRAINING:\n  all_train_images = tf.io.gfile.glob(f'{train_dir}/*/*/*/*.png')\n  all_test_images = tf.io.gfile.glob(f'{test_dir}/*/*/*/*.png')\nelse:\n  all_train_images = glob(os.path.join(train_dir, '**', '*.png'), recursive=True)\n  all_test_images = glob(os.path.join(test_dir, '**', '*.png'), recursive=True)\nprint(len(all_test_images))","metadata":{"id":"q15-cMFonnYV","outputId":"a3192cb9-0f9a-4ee7-d733-108c0d94c729","execution":{"iopub.status.busy":"2022-05-28T05:00:15.311009Z","iopub.execute_input":"2022-05-28T05:00:15.311286Z","iopub.status.idle":"2022-05-28T05:00:19.608781Z","shell.execute_reply.started":"2022-05-28T05:00:15.311259Z","shell.execute_reply":"2022-05-28T05:00:19.608031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Determine whether the environment contains test data","metadata":{"id":"4py438cBnnYf"}},{"cell_type":"code","source":"CONFIG.DEBUG = CONFIG.DEBUG or len(all_test_images)==0","metadata":{"id":"t0L0SKKEPDck","execution":{"iopub.status.busy":"2022-05-28T05:00:19.610062Z","iopub.execute_input":"2022-05-28T05:00:19.610416Z","iopub.status.idle":"2022-05-28T05:00:19.614476Z","shell.execute_reply.started":"2022-05-28T05:00:19.610379Z","shell.execute_reply":"2022-05-28T05:00:19.613555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Read train and submission files","metadata":{"id":"p2MiLd4ynnYY"}},{"cell_type":"code","source":"if not CONFIG.KAGGLE_KERNEL and SETUP:\n  linux_shell(['python3 -m pip install fsspec gcsfs'])","metadata":{"id":"qGwoLwOgShCQ","execution":{"iopub.status.busy":"2022-05-28T05:00:19.615738Z","iopub.execute_input":"2022-05-28T05:00:19.616225Z","iopub.status.idle":"2022-05-28T05:00:19.627527Z","shell.execute_reply.started":"2022-05-28T05:00:19.616191Z","shell.execute_reply":"2022-05-28T05:00:19.626751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG.KAGGLE_KERNEL:\n  if CONFIG.ENABLE_TRAINING or CONFIG.DEBUG:\n    train_df = pd.read_csv(train_csv)\n  sub_df   = pd.read_csv(sub_csv)\nelse:\n  train_df = pd.read_csv(os.path.join(ROOT_DIR, CONFIG.NOTEBOOK_ID, CONFIG.TRAIN_CSV))\n  sub_df = pd.read_csv(os.path.join(ROOT_DIR, CONFIG.NOTEBOOK_ID, CONFIG.SUBMISSION_CSV))","metadata":{"id":"OUFjSsyennYa","execution":{"iopub.status.busy":"2022-05-28T05:00:19.628828Z","iopub.execute_input":"2022-05-28T05:00:19.629945Z","iopub.status.idle":"2022-05-28T05:00:20.187853Z","shell.execute_reply.started":"2022-05-28T05:00:19.629903Z","shell.execute_reply":"2022-05-28T05:00:20.187027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG.VERBOSE:\n  if CONFIG.ENABLE_TRAINING or CONFIG.DEBUG:\n    print('\\n .. Train file ...')\n    display(train_df.head())\n  print('\\n .. Submission file ...')\n  display(sub_df.head())","metadata":{"id":"4AF4EJeYnnYb","outputId":"fa6ca8e7-57c4-4813-b61c-23b8801dcb38","execution":{"iopub.status.busy":"2022-05-28T05:00:20.189208Z","iopub.execute_input":"2022-05-28T05:00:20.189631Z","iopub.status.idle":"2022-05-28T05:00:20.217806Z","shell.execute_reply.started":"2022-05-28T05:00:20.189588Z","shell.execute_reply":"2022-05-28T05:00:20.216938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Simulate submission using training files","metadata":{"id":"z6QIRCLpnnYj"}},{"cell_type":"code","source":"if CONFIG.DEBUG:\n  test_dir = train_dir\n  all_test_images = all_train_images\n  first_50_cases = train_df.id.apply(lambda x: x.split('_', 1)[0]).unique()[:50]\n  sub_df = train_df[train_df.id.apply(lambda x: x.split('_', 1)[0]).isin(first_50_cases)]\n  sub_df = sub_df[['id', 'class']]\n  sub_df['predicted'] = ''\n\n  print('\\n\\n\\n... Submission data-frame ... \\n')\n  display(sub_df)","metadata":{"id":"KAZD4OuonnYk","outputId":"bd6a72c3-95d7-4aef-b1bf-4226d3e4e636","execution":{"iopub.status.busy":"2022-05-28T05:00:20.219181Z","iopub.execute_input":"2022-05-28T05:00:20.219657Z","iopub.status.idle":"2022-05-28T05:00:20.367544Z","shell.execute_reply.started":"2022-05-28T05:00:20.219615Z","shell.execute_reply":"2022-05-28T05:00:20.366713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = CONFIG.CLASSES\nsf_classes = CONFIG.SHORTFORM_CLASSES\nSF2LF = {_sf:_lf for _sf,_lf in zip(sf_classes, classes)}\nLF2SF = {_lf:_sf for _sf,_lf in zip(sf_classes, classes)}","metadata":{"id":"DNeMilq1nnYn","execution":{"iopub.status.busy":"2022-05-28T05:00:20.368816Z","iopub.execute_input":"2022-05-28T05:00:20.369402Z","iopub.status.idle":"2022-05-28T05:00:20.374595Z","shell.execute_reply.started":"2022-05-28T05:00:20.369356Z","shell.execute_reply":"2022-05-28T05:00:20.373794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pre-processing","metadata":{"id":"bsA7Cl_HnnYs"}},{"cell_type":"code","source":"def get_filepath_from_partial_identifier(_ident, file_list):\n  return [x for x in file_list if _ident in x][0]\n\ndef df_preprocessing(df, globbed_file_list, is_test:bool=False):\n  ''' The preprocessing steps applied to get column information '''\n  # 1. Get Case-ID as a column (str and int)\n  df['case_id_str'] = df['id'].apply(lambda x: x.split('_', 2)[0])\n  df['case_id'] = df['id'].apply(lambda x: int(x.split('_', 2)[0].replace('case', '')))\n\n  # 2. Get Day as a column\n  df['day_num_str'] = df['id'].apply(lambda x: x.split('_', 2)[1])\n  df['day_num'] = df['id'].apply(lambda x: int(x.split('_', 2)[1].replace('day', '')))\n\n  # 3. Get Slice Identifier as a column\n  df['slice_id'] = df['id'].apply(lambda x: x.split('_', 2)[2])\n\n  # 4. Get full file paths for the representative scans\n  df['_partial_ident'] = (globbed_file_list[0].rsplit('/', 4)[0]+'/' +                            \n                          df['case_id_str']+'/'+ # .../case###/\n                          df['case_id_str'] +\n                          '_'+df['day_num_str'] + \n                          '/scans/' +\n                          df['slice_id'])\n  _tmp_merge_df = pd.DataFrame(\n      {'_partial_ident':[x.rsplit('_',4)[0] for x in globbed_file_list], \n         'f_path':globbed_file_list})\n  df = df.merge(_tmp_merge_df, on='_partial_ident').drop(columns=['_partial_ident'])\n\n  # 5. Get slice dimensions from filepath (int in pixels)\n  df['slice_h'] = df['f_path'].apply(lambda x: int(x[:-4].rsplit('_',4)[1]))\n  df['slice_w'] = df['f_path'].apply(lambda x: int(x[:-4].rsplit('_',4)[2]))\n\n  # 6. Pixel spacing from filepath (float in mm)\n  df['px_spacing_h'] = df['f_path'].apply(lambda x: float(x[:-4].rsplit('_',4)[3]))\n  df['px_spacing_w'] = df['f_path'].apply(lambda x: float(x[:-4].rsplit('_',4)[4]))\n\n  if not is_test:\n    # 7. Merge 3 rows into a single row \n    # Segmentation-RLE is the only unique information across those rows\n    l_bowel_df = df[df['class']=='large_bowel'][['id', 'segmentation']].rename(\n        columns={'segmentation':'lb_seg_rle'})\n    s_bowel_df = df[df['class']=='small_bowel'][['id', 'segmentation']].rename(\n        columns={'segmentation':'sb_seg_rle'})\n    stomach_df = df[df['class']=='stomach'][['id', 'segmentation']].rename(\n        columns={'segmentation':'st_seg_rle'})\n    df = df.merge(l_bowel_df, on='id', how='left')\n    df = df.merge(s_bowel_df, on='id', how='left')\n    df = df.merge(stomach_df, on='id', how='left')\n    df = df.drop_duplicates(subset=['id',]).reset_index(drop=True)\n    df['lb_seg_flag'] = df['lb_seg_rle'].apply(lambda x: not pd.isna(x))\n    df['sb_seg_flag'] = df['sb_seg_rle'].apply(lambda x: not pd.isna(x))\n    df['st_seg_flag'] = df['st_seg_rle'].apply(lambda x: not pd.isna(x))\n    df['n_segs'] = (df['lb_seg_flag'].astype(int)+\n                    df['sb_seg_flag'].astype(int)+\n                    df['st_seg_flag'].astype(int))\n\n  # 8. Reorder columns to the a new ordering \n  # (drops class and segmentation as no longer necessary)\n  new_col_order = ['id', 'f_path', 'n_segs',\n                   'lb_seg_rle', 'lb_seg_flag',\n                   'sb_seg_rle', 'sb_seg_flag', \n                   'st_seg_rle', 'st_seg_flag',\n                   'slice_h', 'slice_w', 'px_spacing_h', \n                   'px_spacing_w', 'case_id_str', 'case_id', \n                   'day_num_str', 'day_num', 'slice_id', 'predicted']\n  if is_test: new_col_order.insert(1, 'class')\n  new_col_order = [_c for _c in new_col_order if _c in df.columns]\n  df = df[new_col_order]\n\n  return df","metadata":{"id":"rWRf6YDYnnYw","execution":{"iopub.status.busy":"2022-05-28T05:00:20.376047Z","iopub.execute_input":"2022-05-28T05:00:20.376575Z","iopub.status.idle":"2022-05-28T05:00:20.39974Z","shell.execute_reply.started":"2022-05-28T05:00:20.376537Z","shell.execute_reply":"2022-05-28T05:00:20.398812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG.DEBUG or CONFIG.ENABLE_TRAINING: \n  train_df = df_preprocessing(train_df, all_train_images)\nsub_df = df_preprocessing(sub_df, all_test_images, is_test=True)","metadata":{"id":"Q9Rjr6s9nnY1","execution":{"iopub.status.busy":"2022-05-28T05:00:20.402757Z","iopub.execute_input":"2022-05-28T05:00:20.403237Z","iopub.status.idle":"2022-05-28T05:00:22.878822Z","shell.execute_reply.started":"2022-05-28T05:00:20.403206Z","shell.execute_reply":"2022-05-28T05:00:22.878009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG.VERBOSE:\n  if CONFIG.DEBUG or CONFIG.ENABLE_TRAINING:\n    print('\\n ... Pre-processed train file ...\\n')\n    display(train_df.head())\n  print('\\n ... Pre-processed submission file ...\\n')   \n  display(sub_df.head())","metadata":{"id":"HxmhOnlRnnY3","outputId":"e936b0a5-b2b3-4a33-b875-5b559d68c775","execution":{"iopub.status.busy":"2022-05-28T05:00:22.879983Z","iopub.execute_input":"2022-05-28T05:00:22.880473Z","iopub.status.idle":"2022-05-28T05:00:22.918197Z","shell.execute_reply.started":"2022-05-28T05:00:22.880434Z","shell.execute_reply":"2022-05-28T05:00:22.917401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper functions","metadata":{"id":"AeYnMHvznnY5"}},{"cell_type":"markdown","source":"## Handle run-length-encoding using NumPy","metadata":{"id":"Z92XCnCOnnY7"}},{"cell_type":"code","source":"# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n# modified from: https://www.kaggle.com/inversion/run-length-decoding-quick-start\ndef rle_decode(mask_rle, shape, color:int=1):\n  ''' \n  Args:\n      mask_rle (str): run-length as string formated (start length)\n      shape (tuple of ints): (height,width) of array to return \n    \n  Returns: \n      Mask (np.array)\n          - 1 indicating mask\n          - 0 indicating background\n\n  '''\n  # Split the string by space, then convert it into a integer array\n  s = np.array(mask_rle.split(), dtype=int)\n\n  # Every even value is the start, every odd value is the 'run' length\n  starts = s[0::2] - 1\n  lengths = s[1::2]\n  ends = starts + lengths\n\n  # The image image is actually flattened since RLE is a 1D 'run'\n  if len(shape)==3:\n    h, w, d = shape\n    img = np.zeros((h * w, d), dtype=np.float32)\n  else:\n    h, w = shape\n    img = np.zeros((h * w,), dtype=np.float32)\n\n  # The color here is actually just any integer you want!\n  for lo, hi in zip(starts, ends):\n    img[lo : hi] = color\n\n  # Don't forget to change the image back to the original shape\n  return img.reshape(shape)\n\n# https://www.kaggle.com/namgalielei/which-reshape-is-used-in-rle\ndef rle_decode_top_to_bot_first(mask_rle, shape):\n  '''\n  Args:\n      mask_rle (str): run-length as string formated (start length)\n      shape (tuple of ints): (height,width) of array to return \n    \n  Returns:\n      Mask (np.array)\n          - 1 indicating mask\n          - 0 indicating background\n  '''\n  s = mask_rle.split()\n  starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n  starts -= 1\n  ends = starts + lengths\n  img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n  for lo, hi in zip(starts, ends):\n    img[lo:hi] = 1\n  return img.reshape((shape[1], shape[0]), order='F').T  # Reshape from top -> bottom first\n\n# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\ndef rle_encode(img):\n  '''\n  Args:\n      img (np.array): \n          - 1 indicating mask\n          - 0 indicating background\n    \n  Returns: \n      run length as string formated\n  '''\n  pixels = img.flatten()\n  pixels = np.concatenate([[0], pixels, [0]])\n  runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n  runs[1::2] -= runs[::2]\n  return ' '.join(str(x) for x in runs)","metadata":{"id":"SouJdyFbnnY8","execution":{"iopub.status.busy":"2022-05-28T05:00:22.919647Z","iopub.execute_input":"2022-05-28T05:00:22.92029Z","iopub.status.idle":"2022-05-28T05:00:22.933978Z","shell.execute_reply.started":"2022-05-28T05:00:22.920249Z","shell.execute_reply":"2022-05-28T05:00:22.933209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def flatten_l_o_l(nested_list):\n  '''Flatten a list of lists'''\n  return [item for sublist in nested_list for item in sublist]\n\ndef load_json_to_dict(json_path):\n  with open(json_path) as json_file:\n    data = json.load(json_file)\n  return data\n\ndef open_gray16(_path, normalize:bool=True, to_rgb:bool=False):\n  '''Helper to open files'''\n  if normalize:\n    if to_rgb:\n      return np.tile(np.expand_dims(\n               cv2.imread(_path, cv2.IMREAD_ANYDEPTH)/65535., axis=-1), 3)\n    else:\n      return cv2.imread(_path, cv2.IMREAD_ANYDEPTH)/65535.\n  else:\n    if to_rgb:\n      return np.tile(np.expand_dims(\n               cv2.imread(_path, cv2.IMREAD_ANYDEPTH), axis=-1), 3)\n    else:\n      return cv2.imread(_path, cv2.IMREAD_ANYDEPTH)","metadata":{"id":"jvAE2VJVnnZC","execution":{"iopub.status.busy":"2022-05-28T05:00:22.935472Z","iopub.execute_input":"2022-05-28T05:00:22.936176Z","iopub.status.idle":"2022-05-28T05:00:22.94802Z","shell.execute_reply.started":"2022-05-28T05:00:22.936134Z","shell.execute_reply":"2022-05-28T05:00:22.947123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataframe functions","metadata":{"id":"rVAQWZLVfyUj"}},{"cell_type":"code","source":"def df_process(input_df):\n  input_df['which_segs'] = input_df.lb_seg_flag.astype(int).astype(str) + \\\n                           input_df.sb_seg_flag.astype(int).astype(str) + \\\n                           input_df.st_seg_flag.astype(int).astype(str)\n  return input_df\n \ndef df_generator(df):\n  return df['id'], df['which_segs'], df['case_id']\n\ndef df_indexer(df, idxs):\n  proc_df=df.iloc[idxs]\n  num_samples = len(proc_df)\n  proc_df=proc_df.sample(num_samples).reset_index(drop=True)  \n  return proc_df\n\ndef df_dropna(df):\n  df.lb_seg_rle.fillna('', inplace=True)\n  df.sb_seg_rle.fillna('', inplace=True)\n  df.st_seg_rle.fillna('', inplace=True)  \n  return df\n\ndef df_make_masks(df, image_size:tuple=(256, 256), \n                  mode:str='multiclass', output_dir:str='./'):\n  _masks_dir = f'{output_dir}/{mode}/npy_files'\n  if not os.path.isdir(_masks_dir): os.makedirs(_masks_dir, exist_ok=True)\n  df[f'{mode}_mask_path'] = df.progress_apply(lambda _row: make_seg_mask(\n                              _row, _masks_dir, resize_to=image_size), axis=1)\n  del _masks_dir\n  return df\n\ndef df_mask_paths(df, proc_df, mode:str='multiclass'):\n  return proc_df.merge(df[['id', f'{mode}_mask_path']], on='id')","metadata":{"id":"tehl5z52ft0e","execution":{"iopub.status.busy":"2022-05-28T05:00:22.954613Z","iopub.execute_input":"2022-05-28T05:00:22.955234Z","iopub.status.idle":"2022-05-28T05:00:22.966429Z","shell.execute_reply.started":"2022-05-28T05:00:22.955195Z","shell.execute_reply":"2022-05-28T05:00:22.965508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tensorflow functions for handling images and masks","metadata":{"id":"uMJb3c_gPDde"}},{"cell_type":"code","source":"def tf_load_png(img_path, channels:int=3, dtype=tf.uint16):\n  with warnings.catch_warnings(record=True):  \n    img_bytes = tf.io.read_file(img_path)\n  return tf.image.decode_png(img_bytes, channels=channels, dtype=dtype)\n\ndef tf_normalize(img:tf.Tensor, dtype=tf.float32, epsilon:float=1e-16)->tf.Tensor:\n  with warnings.catch_warnings(record=True):   \n    img = tf.cast(img, dtype=dtype)\n  return ((img-tf.reduce_min(img))/(tf.reduce_max(img)-tf.reduce_min(img)+epsilon))\n\ndef tf_img_resize(img:tf.Tensor, image_size:tuple=(512,512))->tf.Tensor:\n  with warnings.catch_warnings(record=True):   \n    return tf.image.resize(img, (tf.constant(image_size[0]), tf.constant(image_size[1])))\n\ndef tf_flip_left_right(img:tf.Tensor, mask:tf.Tensor)->tf.Tensor:\n  return tf.image.flip_left_right(img), tf.image.flip_left_right(mask)\n\ndef tf_flip_up_down(img:tf.Tensor, mask:tf.Tensor)->tf.Tensor:\n  return tf.image.flip_up_down(img), tf.image.flip_up_down(mask)\n\ndef tf_rle_decode(mask_rle, shape):\n  shape = tf.convert_to_tensor(shape, tf.int64)\n  size = tf.math.reduce_prod(shape)\n\n  # Split string\n  s = tf.strings.split(mask_rle)\n  s = tf.strings.to_number(s, tf.int64)\n\n  # Get starts and lengths\n  starts = s[::2] - 1\n  lens = s[1::2]\n\n  # Make ones to be scattered\n  total_ones = tf.reduce_sum(lens)\n  ones = tf.ones([total_ones], tf.uint8)\n\n  # Make scattering indices\n  r = tf.range(total_ones)\n  lens_cum = tf.math.cumsum(lens)\n  s = tf.searchsorted(lens_cum, r, 'right')\n  idx = r + tf.gather(starts - tf.pad(lens_cum[:-1], [(1, 0)]), s)\n    \n  # Scatter ones into flattened mask\n  mask_flat = tf.scatter_nd(tf.expand_dims(idx, 1), ones, [size])\n\n  # Reshape into mask\n  return tf.reshape(mask_flat, shape)","metadata":{"id":"ulYgCOoPPDdg","execution":{"iopub.status.busy":"2022-05-28T05:00:22.968968Z","iopub.execute_input":"2022-05-28T05:00:22.969614Z","iopub.status.idle":"2022-05-28T05:00:22.985928Z","shell.execute_reply.started":"2022-05-28T05:00:22.969565Z","shell.execute_reply":"2022-05-28T05:00:22.984607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Track memory usage","metadata":{"id":"KjzHNKEEA-Jn"}},{"cell_type":"code","source":"class mem_profiler():\n  def __init__(self, suffix:str='B', divisor:float=1024,\n               units:list=['','Ki','Mi','Gi','Ti','Pi','Ei','Zi','Yi']):\n    self.suffix = suffix\n    self.units = units\n    self.divisor = divisor  \n  def _num_formatter(self, inp_num):\n    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n    for unit in self.units[:-1]:\n      if abs(inp_num) < self.divisor:\n        return '%3.1f %s%s' % (inp_num, unit, self.suffix)\n      inp_num /= self.divisor\n    return '%.1f %s%s' % (inp_num, self.units[-1], self.suffix)\n  def __call__(self):\n    memory_utilization()\n    _mem_usage = {}\n    print('\\n---- Global memory usage ---\\n')\n    for name, size in sorted(((name, \n      sys.getsizeof(value)) for name, value in globals().items()),\n        key= lambda x: -x[1])[:10]:\n      print('{:>30}: {:>8}'.format(name, self._num_formatter(size)))\n      _mem_usage.update({name: size})\n    print('\\n---- Local memory usage ---\\n')  \n    for name, size in sorted(((name, \n      sys.getsizeof(value)) for name, value in locals().items()),\n        key= lambda x: -x[1])[:10]:\n      print('{:>30}: {:>8}'.format(name, self._num_formatter(size)))\n      _mem_usage.update({name: size})\n    return _mem_usage\n\ndef mem_cleaner(var_list:list, num_tries:int=2, verbose:bool=False): \n  for var in var_list:\n    try:\n      del globals()[var]\n      clear_memory(4)\n    except Exception as e:\n      print(f'Failed to clear in-memory variables due to: {e} ...')\n      clear_memory(4)\n\ndef housekeeping(verbose:bool=False)->None:\n  mem_cleaner(['auto_environment', 'auto_setup', 'auto_data_download', 'mount_google_drive', \n   'DOWNLOAD_RAW_DATA', 'KaggleDatasets', 'set_cuda_malloc_env', 'set_tf_verbosity',\n   'set_python_warnings_verbosity', 'mlLibs_info', 'set_seed', 'gcp_tpu_setup', 'df_idx',\n   'heterogeneous_compute', 'GCS_BUCKET', 'save_locally', 'load_locally', 'train_dir',\n   'train_csv', 'first_50_cases', 'classes', 'sf_classes', 'SF2LF', 'LF2SF', 'plot_preds',\n   'get_filepath_from_partial_identifier', 'df_preprocessing', 'rle_decode', 'open_gray16',\n   'rle_decode_top_to_bot_first', 'flatten_l_o_l', 'load_json_to_dict', 'efns', 'k',\n   'df_process', 'df_generator', 'df_indexer', 'df_dropna', 'df_make_masks', 'df_mask_paths',\n   'tf_img_resize', 'tf_flip_left_right', 'tf_flip_up_down', 'tf_rle_decode', 'make_seg_mask',\n   'tf_load_mask', 'tf_pair_augment', 'tf_image_mask_pair', 'tf_image_mask_aug_pair',\n   'preprocess_train', 'make_train_dataset', 'train_ds', 'val_ds', 'pred_rles', 'img_batch', \n   'GarbageCollection', 'plot_history', 'is_extension_type', 'squeeze_or_expand_dimensions',\n   'is_tensor_or_extension_type', 'remove_squeezable_dimensions', 'IoU_Loss', \n   'LossFunctionWrapper','model_train', 'get_overlay', 'get_miss_overlay'])\n  clear_memory(4)\n  if verbose: print('\\n---Memory usage after housekeeping---\\n'); _ = mem_usage()\n\ntry:\n  mem_usage = mem_profiler()\nexcept:\n  mem_usage = None","metadata":{"id":"CF5j515nA-Jp","execution":{"iopub.status.busy":"2022-05-28T05:00:22.987533Z","iopub.execute_input":"2022-05-28T05:00:22.988169Z","iopub.status.idle":"2022-05-28T05:00:23.010635Z","shell.execute_reply.started":"2022-05-28T05:00:22.988134Z","shell.execute_reply":"2022-05-28T05:00:23.009806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG.ENABLE_TRAINING and CONFIG.TRAIN_VAL_SPLIT:\n  gkf =  GroupKFold(n_splits=CONFIG.NUM_FOLDS)  \n  train_df = df_process(train_df) \n  # train_df = train_df[train_df.n_segs>0].reset_index(drop=True)\n  df1, df2, df3 = df_generator(train_df)\n  for train_idxs, val_idxs in gkf.split(df1, df2, df3):\n    split_train_df = df_dropna(df_indexer(train_df, train_idxs))\n    split_val_df = df_dropna(df_indexer(train_df, val_idxs))\n    break\nelif CONFIG.ENABLE_TRAINING:\n  split_train_df, split_val_df = df_dropna(train_df), df_dropna(train_df)\nelif CONFIG.DEBUG:\n  split_val_df = df_dropna(train_df)\n\nif CONFIG.VERBOSE:\n  if CONFIG.ENABLE_TRAINING:\n    print('\\nFold 1: train data-frame \\n\\n')\n    display(split_train_df)\n\n  print('\\n\\n\\n\\nFold 1: validation data-frame \\n\\n')\n  display(split_val_df)","metadata":{"id":"c02HVXaknnZG","outputId":"431a4053-6f5c-4042-a0c0-9792e792fc94","execution":{"iopub.status.busy":"2022-05-28T05:00:23.012108Z","iopub.execute_input":"2022-05-28T05:00:23.012955Z","iopub.status.idle":"2022-05-28T05:00:23.061208Z","shell.execute_reply.started":"2022-05-28T05:00:23.012917Z","shell.execute_reply":"2022-05-28T05:00:23.06036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save segmentation masks from run-length-encoded labels","metadata":{"id":"3eSY42U3NrwI"}},{"cell_type":"code","source":"def make_seg_mask(row, output_dir, resize_to):\n  _output_style = 'multiclass' if 'multiclass' in output_dir else 'multilabel'\n  _slice_shape = (row.slice_w, row.slice_h)\n\n  if not pd.isna(row.lb_seg_rle):\n    lb_mask = rle_decode(row.lb_seg_rle, _slice_shape, )\n  else:\n    lb_mask = np.zeros(_slice_shape)\n\n  if not pd.isna(row.sb_seg_rle):\n    sb_mask = rle_decode(row.sb_seg_rle, _slice_shape)\n  else:\n    sb_mask = np.zeros(_slice_shape)\n\n  if not pd.isna(row.st_seg_rle):\n    st_mask = rle_decode(row.st_seg_rle, _slice_shape)\n  else:\n    st_mask = np.zeros(_slice_shape)\n\n  if _output_style=='multiclass':\n    mask_arr = st_mask*3                         # stomach     = 3\n    mask_arr = np.where(sb_mask==1, 2, mask_arr) # small bowel = 2\n    mask_arr = np.where(lb_mask==1, 1, mask_arr) # large bowel = 1\n  else:\n    mask_arr = np.stack([lb_mask, sb_mask, st_mask], axis=-1)\n\n  mask_arr = cv2.resize(\n        mask_arr, resize_to, interpolation=cv2.INTER_NEAREST).astype(np.uint8)\n  mask_path = os.path.join(output_dir, f'{row.id}_mask')\n  np.save(mask_path, mask_arr)\n  return mask_path+'.npy'","metadata":{"id":"UyHbugd1nnZJ","execution":{"iopub.status.busy":"2022-05-28T05:00:23.062675Z","iopub.execute_input":"2022-05-28T05:00:23.06329Z","iopub.status.idle":"2022-05-28T05:00:23.074751Z","shell.execute_reply.started":"2022-05-28T05:00:23.063251Z","shell.execute_reply":"2022-05-28T05:00:23.073916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG.SAVE_MASKS:\n  train_df = df_make_masks(train_df, image_size=CONFIG.IMAGE_SIZE, mode=CONFIG.STYLE, \n                      output_dir=CONFIG.OUTPUT_DIR)\n  split_train_df = df_mask_paths(train_df, split_train_df, mode=CONFIG.STYLE)\n  split_val_df = df_mask_paths(train_df, split_val_df, mode=CONFIG.STYLE)","metadata":{"id":"6SarTYDRnnZM","execution":{"iopub.status.busy":"2022-05-28T05:00:23.076489Z","iopub.execute_input":"2022-05-28T05:00:23.07722Z","iopub.status.idle":"2022-05-28T05:00:23.087722Z","shell.execute_reply.started":"2022-05-28T05:00:23.077178Z","shell.execute_reply":"2022-05-28T05:00:23.086946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Functions for creating datasets","metadata":{"id":"kxnAQ8rWPDf2"}},{"cell_type":"code","source":"def tf_load_image(path:str, \n                  dtype=tf.float32, \n                  epsilon:float=1e-16, \n                  normalize:bool=True)->tf.Tensor:\n  '''\n  Load an image with the correct shape using only TF\n    \n  Args:\n      path (tf.string): Path to the image to be loaded\n      resize_to (tuple, optional): Size to reshape image\n    \n  Returns:\n      3 channel tf.Constant image ready for training/inference\n  '''\n  with warnings.catch_warnings(record=True):\n    img = tf_load_png(path, channels=3, dtype=tf.uint16)\n    if normalize:\n      img = 255*tf_normalize(img, dtype=dtype, epsilon=epsilon)\n    img = tf_img_resize(img, image_size=CONFIG.IMAGE_SIZE)\n  return tf.cast(img, dtype=dtype)\n\ndef tf_load_mask(rle_strs, \n                 root_shape, \n                 dtype=tf.uint8, \n                 style:str='multiclass')->tf.Tensor:\n  tf_masks = [tf.cast(\n                tf.image.resize(\n                  tf.expand_dims(\n                    tf_rle_decode(rle_str, root_shape), axis=-1), \n                  size=(\n                    tf.constant(CONFIG.MASK_SIZE[0]), \n                    tf.constant(CONFIG.MASK_SIZE[1])\n                  ), \n                  method=tf.image.ResizeMethod.NEAREST_NEIGHBOR\n                ), \n                dtype\n                ) for rle_str in rle_strs]\n\n  if style=='multilabel':\n    return tf.concat(tf_masks, axis=-1)\n  else:        \n    _tf_masks = tf.zeros((*CONFIG.MASK_SIZE, 1), dtype=dtype)\n    _tf_masks = tf_masks[2]*tf.constant(3, dtype=dtype)          # small bowel = 3\n    _tf_masks = tf.where(tf_masks[1]==tf.constant(\n        1, dtype=dtype), tf.constant(2, dtype=dtype), _tf_masks) # small bowel = 2\n    _tf_masks = tf.where(tf_masks[0]==tf.constant(\n        1, dtype=dtype), tf.constant(1, dtype=dtype), _tf_masks) # large bowel = 1\n    return tf.cast(_tf_masks, dtype=dtype)\n\ndef tf_pair(img:tf.Tensor, mask:tf.Tensor)->tf.Tensor:\n  return img, mask\n\ndef tf_img(img:tf.Tensor)->tf.Tensor:\n  return img\n\ndef tf_pair_cond(img:tf.Tensor, mask:tf.Tensor, aug_fn)->tf.Tensor:\n  return tf.cond(\n           tf.random.uniform([])<=tf.constant(0.5), \n           lambda: aug_fn(img, mask), \n           lambda: tf_pair(img, mask)\n           )\n \ndef tf_pair_augment(img:tf.Tensor, mask:tf.Tensor)->tf.Tensor:\n  # Image-mask pairwise augmentation\n  if CONFIG.FLIP_HORIZONTAL:\n    img, mask  = tf_pair_cond(\n                   img, \n                   mask,\n                   tf_flip_left_right\n                   )\n  if CONFIG.FLIP_VERTICAL:\n    img, mask  = tf_pair_cond(\n                   img, \n                   mask,\n                   tf_flip_up_down\n                   )\n  \n  if CONFIG.RANDOM_BRIGHTNESS:\n    img = tf.cond(\n           tf.random.uniform([])<=tf.constant(0.5), \n           lambda: tf.image.random_brightness(img, 0.1), \n           lambda: tf_img(img)\n           )\n  if CONFIG.RANDOM_CONTRAST:\n    img = tf.cond(\n           tf.random.uniform([])<=tf.constant(0.5), \n           lambda: tf.image.random_contrast(img, 0.1, 0.5), \n           lambda: tf_img(img)\n           )\n  if CONFIG.RANDOM_GAMMA:\n    img = tf.cond(\n           tf.random.uniform([])<=tf.constant(0.5), \n           lambda: tf.image.adjust_gamma(img, 1e-6), \n           lambda: tf_img(img)\n           )\n  if CONFIG.RANDOM_HUE:\n    img = tf.cond(\n           tf.random.uniform([])<=tf.constant(0.5), \n           lambda: tf.image.random_hue(img, 0.1), \n           lambda: tf_img(img)\n           )\n  if CONFIG.RANDOM_SATURATION:\n    img = tf.cond(\n           tf.random.uniform([])<=tf.constant(0.5), \n           lambda: tf.image.random_saturation(img, 0.1, 0.5), \n           lambda: tf_img(img)\n           )\n  return img, mask\n\ndef tf_image_mask_pair(path, \n                       rle_strs, \n                       root_shape, \n                       dtype=tf.uint8, \n                       epsilon:float=1e-16, \n                       style:str='multiclass', \n                       normalize:bool=True)->tf.Tensor:\n  img  = tf_load_image(path, dtype=dtype, epsilon=epsilon,normalize=normalize)\n  mask = tf_load_mask(rle_strs, root_shape, dtype=dtype, style=style)\n  img, mask = tf.cast(img, dtype=dtype), tf.cast(mask, dtype=dtype)\n  return img, mask\n\ndef tf_image_mask_aug_pair(path, \n                           rle_strs, \n                           root_shape, \n                           dtype=tf.uint8, \n                           epsilon:float=1e-16, \n                           style:str='multiclass', \n                           normalize:bool=True)->tf.Tensor:\n  img, mask = tf_image_mask_pair(path, rle_strs, root_shape, dtype=dtype, \n                                 epsilon=epsilon, style=style, normalize=normalize)\n  img, mask = tf_pair_augment(img, mask)\n  img, mask = tf.cast(img, dtype=dtype), tf.cast(mask, dtype=dtype)  \n  return img, mask\n\ndef preprocess_train(img_batch:tf.Tensor, mask_batch:tf.Tensor)->tf.Tensor:\n  dtype      = getattr(tf, CONFIG.DTYPE)  \n  img_batch  = img_batch/tf.constant(127.5)-tf.constant(1.0)\n  img_batch  = tf.cast(img_batch, dtype=dtype)  \n  mask_batch = tf.cast(mask_batch, dtype=dtype)\n  return img_batch, mask_batch\n\ndef preprocess_test(img_batch:tf.Tensor)->tf.Tensor:\n  with warnings.catch_warnings(record=True):  \n    dtype     = getattr(tf, CONFIG.DTYPE)\n    img_batch = img_batch/tf.constant(127.5)-tf.constant(1.0)\n    img_batch = tf.cast(img_batch, dtype=dtype) \n  return img_batch","metadata":{"id":"dhsUt_21nnZO","execution":{"iopub.status.busy":"2022-05-28T05:00:23.089614Z","iopub.execute_input":"2022-05-28T05:00:23.090097Z","iopub.status.idle":"2022-05-28T05:00:23.120433Z","shell.execute_reply.started":"2022-05-28T05:00:23.090055Z","shell.execute_reply":"2022-05-28T05:00:23.119369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create training and validation dataset","metadata":{"id":"mZq_dqgSnnZS"}},{"cell_type":"code","source":"try:\n  AUTOTUNE = tf.data.AUTOTUNE\nexcept:\n  AUTOTUNE = None","metadata":{"id":"WDX6UZZTnnZU","execution":{"iopub.status.busy":"2022-05-28T05:00:23.122052Z","iopub.execute_input":"2022-05-28T05:00:23.122622Z","iopub.status.idle":"2022-05-28T05:00:23.132335Z","shell.execute_reply.started":"2022-05-28T05:00:23.122582Z","shell.execute_reply":"2022-05-28T05:00:23.131426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_train_dataset(input_df, batch_size:int=1, mode:str='train'):\n  ds = tf.data.Dataset.from_tensor_slices(\n      (input_df.f_path, \n       (input_df.lb_seg_rle,\n        input_df.sb_seg_rle,\n        input_df.st_seg_rle), \n       (input_df.slice_w, \n        input_df.slice_h)))\n  dtype = getattr(tf, CONFIG.DTYPE)\n  shuffle_buffer = len(input_df) if CONFIG.OPTIMUM_SHUFFLE else CONFIG.SHUFFLE_BUFFER  \n  if mode =='train':\n    ds = ds.map(lambda x,y,z:(tf_image_mask_aug_pair(x,y,z, style=CONFIG.STYLE, dtype=dtype)), \n                num_parallel_calls=AUTOTUNE)\n    ds = ds.shuffle(shuffle_buffer)                            \\\n           .batch(batch_size, drop_remainder=True)             \\\n           .map(preprocess_train, num_parallel_calls=AUTOTUNE) \\\n           .prefetch(AUTOTUNE)\n  elif mode =='val' or mode=='valid' or mode=='validation':\n    ds = ds.map(lambda x,y,z:(tf_image_mask_pair(x,y,z, style=CONFIG.STYLE, dtype=dtype)), \n                num_parallel_calls=AUTOTUNE)\n    ds = ds.shuffle(shuffle_buffer)                            \\\n           .batch(batch_size, drop_remainder=True)      \\\n           .map(preprocess_train, num_parallel_calls=AUTOTUNE) \\\n           .prefetch(AUTOTUNE)\n  else:\n    raise ValueError('Unknown dataset creation mode. Options: \"train\", \"val\" ...')\n  return ds\n\ndef make_test_dataset(input_df, batch_size:int=1):\n  with warnings.catch_warnings(record=True):   \n    dtype = getattr(tf, CONFIG.DTYPE)\n    ds = tf.data.Dataset.from_tensor_slices(input_df.iloc[::3].f_path.tolist())\n    ds = ds.map(lambda x:tf_load_image(x, dtype=dtype), num_parallel_calls=AUTOTUNE)\n    ds = ds.batch(batch_size)                \\\n           .map(preprocess_test, \n                num_parallel_calls=AUTOTUNE) \\\n           .prefetch(AUTOTUNE)\n    return ds","metadata":{"id":"FtPlJmvCnnZW","execution":{"iopub.status.busy":"2022-05-28T05:00:23.133945Z","iopub.execute_input":"2022-05-28T05:00:23.134316Z","iopub.status.idle":"2022-05-28T05:00:23.149951Z","shell.execute_reply.started":"2022-05-28T05:00:23.134277Z","shell.execute_reply":"2022-05-28T05:00:23.149064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\ntrain_ds, val_ds = None, None\nif CONFIG.ENABLE_TRAINING and CONFIG.DEBUG and CONFIG.VERBOSE:\n  train_ds = make_train_dataset(split_train_df, batch_size=CONFIG.BATCH_SIZE)\nif not CONFIG.ENABLE_TRAINING and CONFIG.VERBOSE:\n  val_ds = make_train_dataset(split_val_df, batch_size=CONFIG.BATCH_SIZE, mode='val')\nif not CONFIG.TRAIN_VAL_SPLIT:\n  val_ds = make_train_dataset(split_train_df, batch_size=CONFIG.BATCH_SIZE, mode='val')","metadata":{"id":"GK6f7ZtEnnZY","execution":{"iopub.status.busy":"2022-05-28T05:00:23.152942Z","iopub.execute_input":"2022-05-28T05:00:23.153548Z","iopub.status.idle":"2022-05-28T05:00:26.520702Z","shell.execute_reply.started":"2022-05-28T05:00:23.153509Z","shell.execute_reply":"2022-05-28T05:00:26.519914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualize training data","metadata":{"id":"PN61tiSJnnZa"}},{"cell_type":"code","source":"if (CONFIG.ENABLE_TRAINING or CONFIG.DEBUG) and CONFIG.VERBOSE: \n  ds = train_ds if CONFIG.ENABLE_TRAINING else val_ds  \n  for _img_batch, _mask_batch in ds.take(1):\n    print(_img_batch.shape, _mask_batch.shape)\n    _img, _mask = _img_batch[0], _mask_batch[0]\n    if len(_mask.shape)==3 and _mask.shape[-1]==1:\n      _mask = np.squeeze(_mask, axis=-1)\n    del _img_batch, _mask_batch; _ = gc.collect()\n    plt.figure(figsize=(15,5))\n    plt.subplot(1,2,1)\n    plt.imshow(tf.cast(_mask, tf.float32))\n\n    plt.subplot(1,2,2)\n    plt.imshow(tf.cast((_img+1)*127.5, tf.uint8))\n\n    plt.tight_layout()\n    plt.show()","metadata":{"id":"HBbEZfFknnZc","outputId":"c5054d90-109f-45bc-930c-3a3d695a3a08","execution":{"iopub.status.busy":"2022-05-28T05:00:26.521991Z","iopub.execute_input":"2022-05-28T05:00:26.522331Z","iopub.status.idle":"2022-05-28T05:00:33.081651Z","shell.execute_reply.started":"2022-05-28T05:00:26.522293Z","shell.execute_reply":"2022-05-28T05:00:33.080912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create test dataset","metadata":{"id":"6xGrwgDLnnZd"}},{"cell_type":"code","source":" with warnings.catch_warnings(record=True):\n  test_ds = make_test_dataset(sub_df, batch_size=CONFIG.TEST_BATCH_SIZE)","metadata":{"id":"97Ee1-8UnnZf","execution":{"iopub.status.busy":"2022-05-28T05:00:33.083016Z","iopub.execute_input":"2022-05-28T05:00:33.083467Z","iopub.status.idle":"2022-05-28T05:00:33.255305Z","shell.execute_reply.started":"2022-05-28T05:00:33.083428Z","shell.execute_reply":"2022-05-28T05:00:33.254557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create EfficientNet FCNet segmentation model\nA fully connected segmentation model using [EfficientNet](https://keras.io/api/applications/efficientnet/) backbone","metadata":{"id":"qwV3d4mwnnZh"}},{"cell_type":"code","source":"scale_factor = CONFIG.IMAGE_SIZE[0]//128\nif scale_factor < 1:\n  raise ValueError('Image size has to be greater than or equal to 128 pixels ...')\nelif scale_factor > 16:\n  raise ValueError('Image size has to smaller than or equal to 2048 pixels ...')","metadata":{"id":"g1HTSnIannZk","execution":{"iopub.status.busy":"2022-05-28T05:00:33.256539Z","iopub.execute_input":"2022-05-28T05:00:33.256925Z","iopub.status.idle":"2022-05-28T05:00:33.262368Z","shell.execute_reply.started":"2022-05-28T05:00:33.256886Z","shell.execute_reply":"2022-05-28T05:00:33.26134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Efn_FCNet(fc_dim:tuple, \n              input_size:tuple, \n              num_classes:int, \n              dropout:float=0.2, \n              backbone:str='EfficientNetB0', \n              train_backbone:bool=True, \n              weights:str=None):\n  encoder = getattr(tf.keras.applications, backbone)  \n  base_model = encoder(include_top=False, weights=weights)\n  base_model.trainable = train_backbone\n  inputs = tf.keras.layers.Input(shape=(*input_size, 3), name='input_layer')\n  x = base_model(inputs)\n  x = tf.keras.layers.GlobalAveragePooling2D(name='global_average_pooling_layer')(x)\n  x = tf.keras.layers.Dropout(dropout/2, name='gap_dropout')(x)  \n  x = tf.keras.layers.Dense(fc_dim[0]*fc_dim[1]*fc_dim[2], name='fc_dense')(x)\n  x = tf.keras.layers.Reshape(fc_dim, name='fc_resize')(x)  \n  x = tf.keras.layers.UpSampling2D(size=(input_size[0]//x.shape[1], \n                                         input_size[1]//x.shape[2]), \n                                   interpolation='bilinear', \n                                   name='fc_upsample_2D')(x)\n  x = tf.keras.layers.Dropout(dropout/2, name='fc_dropout')(x)\n  x = tf.keras.layers.UpSampling2D(size=(input_size[0]//x.shape[1], \n                                         input_size[1]//x.shape[2]), \n                                   interpolation='bilinear', \n                                   name='out_upsample_2D')(x)\n  outputs = tf.keras.layers.Conv2D(num_classes, kernel_size=(1, 1), \n                                   padding='same', name='conv_preds')(x)\n  return tf.keras.Model(inputs=inputs, outputs=outputs)","metadata":{"id":"A3YG1DsPnnZm","execution":{"iopub.status.busy":"2022-05-28T05:00:33.263898Z","iopub.execute_input":"2022-05-28T05:00:33.264508Z","iopub.status.idle":"2022-05-28T05:00:33.279033Z","shell.execute_reply.started":"2022-05-28T05:00:33.264471Z","shell.execute_reply":"2022-05-28T05:00:33.277818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG.STYLE=='multiclass':\n  NUM_CLASSES = len(classes) + 1 # n_classses+background\nelse:\n  NUM_CLASSES = len(classes)     # n_classses (binary so background is 0 in each channel)\n\nPRETRAINED_WEIGHTS = os.path.join(CONFIG.PRETRAINED_WEIGHTS_DIR, CONFIG.PRETRAINED_WEIGHTS)\nPRETRAINED_WEIGHTS = PRETRAINED_WEIGHTS if os.path.exists(PRETRAINED_WEIGHTS) else \\\n                     CONFIG.DEFAULT_PRETRAINED_WEIGHTS ","metadata":{"id":"AGr6AjJpnnZo","execution":{"iopub.status.busy":"2022-05-28T05:00:33.28077Z","iopub.execute_input":"2022-05-28T05:00:33.281298Z","iopub.status.idle":"2022-05-28T05:00:33.295086Z","shell.execute_reply.started":"2022-05-28T05:00:33.28123Z","shell.execute_reply":"2022-05-28T05:00:33.294182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build model","metadata":{"id":"PQkSEMCvnnZq"}},{"cell_type":"code","source":"def get_model():\n  return Efn_FCNet(CONFIG.FC_DIM, CONFIG.IMAGE_SIZE, \n                   num_classes=NUM_CLASSES,\n                   backbone=CONFIG.BACKBONE,\n                   train_backbone=CONFIG.TRAIN_BACKBONE, \n                   weights=PRETRAINED_WEIGHTS)","metadata":{"id":"4bgZuntAnnZr","execution":{"iopub.status.busy":"2022-05-28T05:00:33.296725Z","iopub.execute_input":"2022-05-28T05:00:33.297195Z","iopub.status.idle":"2022-05-28T05:00:33.303004Z","shell.execute_reply.started":"2022-05-28T05:00:33.297129Z","shell.execute_reply":"2022-05-28T05:00:33.301576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG.MODEL_SUMMARY=='plot':\n  efns = get_model()  \n  display(tf.keras.utils.plot_model(efns))\nelif CONFIG.MODEL_SUMMARY=='summary' and CONFIG.VERBOSE:\n  efns = get_model()  \n  print(efns.summary())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Custom callbacks","metadata":{"id":"G4mJDYpInnZv"}},{"cell_type":"code","source":"class GarbageCollection(tf.keras.callbacks.Callback):\n  def __init__(self, clear_session:bool=False)->None:\n    self.clear_session = clear_session\n  def on_epoch_end(self, epoch, logs=None)->None:\n    _ =  gc.collect()\n    if self.clear_session: tf.keras.backend.clear_session()","metadata":{"id":"RKvSNRm8nnZw","execution":{"iopub.status.busy":"2022-05-28T05:02:15.187164Z","iopub.execute_input":"2022-05-28T05:02:15.187525Z","iopub.status.idle":"2022-05-28T05:02:15.193335Z","shell.execute_reply.started":"2022-05-28T05:02:15.187495Z","shell.execute_reply":"2022-05-28T05:02:15.192273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_history(history, fold_num:str='1', metrics:list=['acc',]):\n  fig = px.line(history.history, \n                x=range(len(history.history['loss'])), y=['loss', 'val_loss'],\n                labels={'value':'Loss (log-axis)', 'x':'Epoch #'},\n                title=f'<b>FOLD {fold_num} MODEL - LOSS</b>', log_y=True)\n  fig.show()\n\n  for _m in metrics:\n    fig = px.line(history.history, \n                  x=range(len(history.history[_m])), y=[_m, f'val_{_m}'],\n                  labels={'value':f'{_m} (log-axis)', 'x':'Epoch #'},\n                  title=f'<b>FOLD {fold_num} MODEL - {_m}</b>', log_y=True)\n  fig.show()","metadata":{"id":"ZhYrNAjWnnZz","execution":{"iopub.status.busy":"2022-05-28T05:02:15.46294Z","iopub.execute_input":"2022-05-28T05:02:15.463503Z","iopub.status.idle":"2022-05-28T05:02:15.470372Z","shell.execute_reply.started":"2022-05-28T05:02:15.463452Z","shell.execute_reply":"2022-05-28T05:02:15.469606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# IoU metrics","metadata":{"id":"0deT687cnnZ2"}},{"cell_type":"code","source":"class iou_coef():\n  def __init__(self, \n               dtype=tf.float32, \n               smooth:float=1, \n               epsilon:float=1e-16, \n               name:str='iouCoef')->None:\n    self.dtype, self.smooth, self.epsilon = dtype, smooth, epsilon\n    self.name, self.__name__ = name, name\n  @tf.function \n  def _iou_coef(self, _y_true:tf.Tensor, _y_pred:tf.Tensor)->tf.Tensor:\n    _y_true = tf.cast(_y_true, dtype=self.dtype)\n    _y_pred = tf.cast(_y_pred, dtype=self.dtype)\n    _intersection = K.sum(K.abs(_y_true * _y_pred), axis=[1,2,3])\n    _union = K.sum(_y_true, [1,2,3]) + K.sum(_y_pred, [1,2,3]) - _intersection\n    _iou = K.mean(\n            (_intersection + self.smooth) /\n            (_union + self.smooth + self.epsilon), \n            axis=0\n            )\n    return _iou\n  @tf.function\n  def __call__(self, y_true:tf.Tensor, y_pred:tf.Tensor)->tf.Tensor:\n    return self._iou_coef(y_true, y_pred)\n\nclass iou_loss():\n  def __init__(self, \n               dtype=tf.float32, \n               smooth:float=1, \n               epsilon:float=1e-16, \n               name:str='iouLoss',\n               **kwargs)->None:      \n    self.dtype, self.smooth, self.epsilon = dtype, smooth, epsilon\n    self.name, self.__name__ = name, name\n  @tf.function\n  def _iou_loss(self, _y_true:tf.Tensor, _y_pred:tf.Tensor)->tf.Tensor:\n    _iou_coef = iou_coef(\n                  dtype=self.dtype, smooth=self.smooth, epsilon=self.epsilon\n                  )\n    _iou = _iou_coef(_y_true, _y_pred)\n    return tf.math.exp(K.abs(1 - _iou) + self.epsilon)\n  @tf.function\n  def __call__(self, y_true:tf.Tensor, y_pred:tf.Tensor)->tf.Tensor:\n    return self._iou_loss(y_true, y_pred)","metadata":{"id":"tkP0rJv_nnZ3","execution":{"iopub.status.busy":"2022-05-28T05:02:15.624676Z","iopub.execute_input":"2022-05-28T05:02:15.625341Z","iopub.status.idle":"2022-05-28T05:02:15.640978Z","shell.execute_reply.started":"2022-05-28T05:02:15.625302Z","shell.execute_reply":"2022-05-28T05:02:15.639934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loss function -- Tensorflow wrapper\n\nTensorflow wrapper for integrating custom loss functions","metadata":{"id":"u6_IK1VOuhz6"}},{"cell_type":"code","source":"def is_extension_type(tensor):\n  '''Adapted from https://github.com/keras-team/keras/blob/master/keras/utils/tf_utils.py'''\n  return isinstance(tensor, tf.__internal__.CompositeTensor)\n\ndef is_tensor_or_extension_type(x):\n  '''Adapted from https://github.com/keras-team/keras/blob/master/keras/utils/tf_utils.py'''\n  return tf.is_tensor(x) or is_extension_type(x)\n\ndef remove_squeezable_dimensions(labels, predictions, expected_rank_diff=0, name=None):\n  with tf.keras.backend.name_scope(name or 'remove_squeezable_dimensions'):\n    if not is_tensor_or_extension_type(predictions):\n      predictions = tf.convert_to_tensor(predictions)\n    if not is_tensor_or_extension_type(labels):\n      labels = tf.convert_to_tensor(labels)\n    predictions_shape = predictions.shape\n    predictions_rank = predictions_shape.ndims\n    labels_shape = labels.shape\n    labels_rank = labels_shape.ndims\n    if (labels_rank is not None) and (predictions_rank is not None):\n      # Use static rank.\n      rank_diff = predictions_rank - labels_rank\n      if (rank_diff == expected_rank_diff + 1 and\n          predictions_shape.dims[-1].is_compatible_with(1)):\n        predictions = tf.squeeze(predictions, [-1])\n      elif (rank_diff == expected_rank_diff - 1 and\n            labels_shape.dims[-1].is_compatible_with(1)):\n        labels = tf.squeeze(labels, [-1])\n      return labels, predictions\n\ndef squeeze_or_expand_dimensions(y_pred, y_true=None, sample_weight=None):\n  y_pred_shape = y_pred.shape\n  y_pred_rank = y_pred_shape.ndims\n  if y_true is not None:\n    # If sparse matrix is provided as `y_true`, the last dimension in `y_pred`\n    # may be > 1. Eg: y_true = [0, 1, 2] (shape=(3,)),\n    # y_pred = [[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]] (shape=(3, 3))\n    # In this case, we should not try to remove squeezable dimension.\n    y_true_shape = y_true.shape\n    y_true_rank = y_true_shape.ndims\n    if (y_true_rank is not None) and (y_pred_rank is not None):\n      # Use static rank for `y_true` and `y_pred`.\n      if (y_pred_rank - y_true_rank != 1) or y_pred_shape[-1] == 1:\n        y_true, y_pred = remove_squeezable_dimensions(\n            y_true, y_pred)\n    else:\n      # Use dynamic rank.\n      rank_diff = tf.rank(y_pred) - tf.rank(y_true)\n      squeeze_dims = lambda: remove_squeezable_dimensions(  # pylint: disable=g-long-lambda\n          y_true, y_pred)\n      is_last_dim_1 = tf.equal(1, tf.shape(y_pred)[-1])\n      maybe_squeeze_dims = lambda: tf.cond(  # pylint: disable=g-long-lambda\n          is_last_dim_1, squeeze_dims, lambda: (y_true, y_pred))\n      y_true, y_pred = tf.cond(\n          tf.equal(1, rank_diff), maybe_squeeze_dims, squeeze_dims)\n\n  if sample_weight is None:\n    return y_pred, y_true\n\n  weights_shape = sample_weight.shape\n  weights_rank = weights_shape.ndims\n  if weights_rank == 0:  # If weights is scalar, do nothing.\n    return y_pred, y_true, sample_weight\n\n  if (y_pred_rank is not None) and (weights_rank is not None):\n    # Use static rank.\n    if weights_rank - y_pred_rank == 1:\n      sample_weight = tf.squeeze(sample_weight, [-1])\n    elif y_pred_rank - weights_rank == 1:\n      sample_weight = tf.expand_dims(sample_weight, [-1])\n    return y_pred, y_true, sample_weight\n\n  # Use dynamic rank.\n  weights_rank_tensor = tf.rank(sample_weight)\n  rank_diff = weights_rank_tensor - tf.rank(y_pred)\n  maybe_squeeze_weights = lambda: tf.squeeze(sample_weight, [-1])\n\n  def _maybe_expand_weights():\n    expand_weights = lambda: tf.expand_dims(sample_weight, [-1])\n    return tf.cond(tf.equal(rank_diff, -1), expand_weights, lambda: sample_weight)\n\n  def _maybe_adjust_weights():\n    return tf.cond(tf.equal(rank_diff, 1), maybe_squeeze_weights,\n             _maybe_expand_weights)\n\n  # squeeze or expand last dim of `sample_weight` if its rank differs by 1\n  # from the new rank of `y_pred`.\n  sample_weight = tf.cond(tf.equal(weights_rank_tensor, 0), lambda: sample_weight,\n                    _maybe_adjust_weights)\n  return y_pred, y_true, sample_weight\n\ndef get(identifier):\n  if identifier is None:\n    return None\n  if isinstance(identifier, str):\n    return deserialize(str(identifier))\n  if isinstance(identifier, dict):\n    return deserialize(identifier)\n  if callable(identifier):\n    return identifier\n  raise ValueError(\n      f'Could not interpret loss function identifier: {identifier}')\n\nclass LossFunctionWrapper(tf.keras.losses.Loss):\n  ''' Adapted from https://github.com/keras-team/keras/blob/master/keras/losses.py '''\n  def __init__(self, fn, name:str=None, reduction=tf.keras.losses.Reduction, **kwargs)->None:\n    super().__init__(reduction=reduction, name=name)\n    self.fn = fn\n    self._fn_kwargs = kwargs\n\n  def call(self, y_true, y_pred):\n    if tf.is_tensor(y_pred) and tf.is_tensor(y_true):\n      y_pred, y_true = squeeze_or_expand_dimensions(y_pred, y_true)\n    try:\n      ag_fn = tf.__internal__.autograph.tf_convert(\n        self.fn, tf.__internal__.autograph.control_status_ctx())\n    except AttributeError:\n      ag_fn = tf_convert(self.fn, control_status_ctx())\n    return ag_fn(y_true, y_pred, **self._fn_kwargs)\n\n  def get_config(self):\n    config = {}\n    for k, v in self._fn_kwargs.items():\n      config[k] = tf.keras.backend.eval(v) if tf.keras.utils.is_tensor_or_variable(v) else v\n\n    if tf.keras.saving.experimental.saving_lib._ENABLED:  # pylint: disable=protected-access\n      config['fn'] = tf.keras.utils.generic_utils.get_registered_name(self.fn)\n\n    base_config = super().get_config()\n    return dict(list(base_config.items()) + list(config.items()))\n\n  @classmethod\n  def from_config(cls, config):\n    if tf.keras.saving.experimental.saving_lib._ENABLED:  # pylint: disable=protected-access\n      fn_name = config.pop('fn', None)\n      if fn_name and cls is LossFunctionWrapper:\n        config['fn'] = get(fn_name)\n    return cls(**config)","metadata":{"id":"S2-xiBttdbuy","execution":{"iopub.status.busy":"2022-05-28T05:02:15.902682Z","iopub.execute_input":"2022-05-28T05:02:15.903136Z","iopub.status.idle":"2022-05-28T05:02:15.933945Z","shell.execute_reply.started":"2022-05-28T05:02:15.903101Z","shell.execute_reply":"2022-05-28T05:02:15.933038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Implement IoU metric as a loss function","metadata":{"id":"HKgjrcK9MjyV"}},{"cell_type":"code","source":"class IoU_Loss(LossFunctionWrapper):\n  def __init__(self, name:str='IoU_Loss', dtype=tf.float32, \n               smooth:float=1, epsilon:float=1e-16,\n               reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE)->None:\n    super().__init__(iou_loss(dtype=dtype, smooth=smooth, epsilon=epsilon), \n                     name=name, reduction=reduction)","metadata":{"id":"ywCio9DaMfhV","execution":{"iopub.status.busy":"2022-05-28T05:02:16.034454Z","iopub.execute_input":"2022-05-28T05:02:16.035269Z","iopub.status.idle":"2022-05-28T05:02:16.041215Z","shell.execute_reply.started":"2022-05-28T05:02:16.035235Z","shell.execute_reply":"2022-05-28T05:02:16.040161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train model","metadata":{"id":"kCY1gTObnnZ5"}},{"cell_type":"markdown","source":"## Load pre-trained model weights","metadata":{"id":"aJlJR_PonnZ6"}},{"cell_type":"code","source":"def model_loader(wt, model=None, tpu:bool=False, custom_objects=None):\n  try:\n    if tpu:\n      localhost_load_option = tf.saved_model.LoadOptions(\n          experimental_io_device='/job:localhost')\n      model = tf.keras.models.load_model(wt, options=localhost_load_option,\n                                         custom_objects=custom_objects)\n    else:  \n      model = tf.keras.models.load_model(wt, custom_objects=custom_objects)\n    print(f'Loaded model: {wt}')\n    return model\n  except Exception as e:\n    print(f'Model loading failed due to: {e} ...')\n    if model is not None:\n      print(f'Attempting to load weights from : {wt} instead ....')\n      if tpu:\n        localhost_load_option = tf.saved_model.LoadOptions(\n          experimental_io_device='/job:localhost')\n        model.load_weights(wt, options=localhost_load_option)\n      else:\n        model.load_weights(wt)  \n      print(f'Loaded model weights: {wt}')\n      return model\n    raise ValueError('... Unable to load any model ...')","metadata":{"id":"CugB2dFAnnZ8","execution":{"iopub.status.busy":"2022-05-28T05:02:16.166311Z","iopub.execute_input":"2022-05-28T05:02:16.16722Z","iopub.status.idle":"2022-05-28T05:02:16.17581Z","shell.execute_reply.started":"2022-05-28T05:02:16.167174Z","shell.execute_reply":"2022-05-28T05:02:16.174919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_weights(wt_file:str, model=None, custom_objects=None, tpu:bool=False):\n  if model is None:\n    model = get_segmentation_model()\n    \n  if os.path.exists(f'{wt_file}.h5'):  \n    model.load_weights(f'{wt_file}.h5')\n    print(f'Loaded weights from: {wt_file}.h5 ...')\n  elif os.path.exists(f'{wt_file}.index') or os.path.exists(wt_file):\n    try:\n      if tpu:\n        localhost_load_option = tf.saved_model.LoadOptions(\n            experimental_io_device='/job:localhost')\n        model.load_weights(wt_file, options=localhost_load_option)\n      else:\n        model.load_weights(wt_file)  \n      if CONFIG.VERBOSE:\n        print(f'Loaded weights: {wt_file} ...')\n    except Exception as e:\n      if CONFIG.VERBOSE:\n        print(f'Retry loading models due to: \\n\\t\\t{e} ...')\n      model = model_loader(\n                Path(wt_file), \n                model, \n                tpu=tpu, \n                custom_objects=custom_objects\n                )\n  return model","metadata":{"id":"AKZl1V_0A-K9","execution":{"iopub.status.busy":"2022-05-28T05:02:16.248723Z","iopub.execute_input":"2022-05-28T05:02:16.249409Z","iopub.status.idle":"2022-05-28T05:02:16.258213Z","shell.execute_reply.started":"2022-05-28T05:02:16.249374Z","shell.execute_reply":"2022-05-28T05:02:16.256936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define training callbacks","metadata":{"id":"K9cDbIREKHZB"}},{"cell_type":"code","source":"def get_callbacks(ckpt:str, ckpt_dir:str='./', tpu:bool=False):\n  lr_cb = tf.keras.callbacks.ReduceLROnPlateau(monitor=CONFIG.EVAL_FUNCTION, \n                                               factor=0.75, patience=2, verbose=1, \n                                               mode=CONFIG.EVAL_FUNCTION_MODE)\n  \n  es_cb = tf.keras.callbacks.EarlyStopping(monitor=CONFIG.EVAL_FUNCTION, patience=4, \n                                           mode=CONFIG.EVAL_FUNCTION_MODE,\n                                           verbose=1, restore_best_weights=True)\n  \n  if CONFIG.COLAB_KERNEL: ckpt_dir = CONFIG.GOOGLE_DRIVE\n  ckpt_cb = tf.keras.callbacks.ModelCheckpoint(f'{ckpt_dir}/{ckpt}', \n              monitor=CONFIG.EVAL_FUNCTION, mode=CONFIG.EVAL_FUNCTION_MODE, \n                save_weights_only=CONFIG.IOU_LOSS, save_best_only=True, \n                options=None if CONFIG.IOU_LOSS else save_locally)\n  \n  if CONFIG.IOU_METRICS:\n    iou_ckpt_cb = tf.keras.callbacks.ModelCheckpoint(\n      f'{ckpt_dir}/{ckpt}_'+'{val_iouCoef:.2f}', \n        monitor='val_iouCoef', mode='max', save_weights_only=CONFIG.IOU_LOSS,\n          save_best_only=True, options=None if CONFIG.IOU_LOSS else save_locally)\n    \n  if tpu is not None:\n    gc_cb = GarbageCollection(clear_session=True)\n  else:\n    gc_cb = GarbageCollection()\n\n  cb = [lr_cb, es_cb, ckpt_cb, gc_cb]\n  if CONFIG.IOU_METRICS: cb.append(iou_ckpt_cb)\n  return cb","metadata":{"id":"xc8u5ZERaIuc","execution":{"iopub.status.busy":"2022-05-28T05:02:16.438822Z","iopub.execute_input":"2022-05-28T05:02:16.43966Z","iopub.status.idle":"2022-05-28T05:02:16.449703Z","shell.execute_reply.started":"2022-05-28T05:02:16.439624Z","shell.execute_reply":"2022-05-28T05:02:16.448705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define training metrics","metadata":{"id":"zNEjCb2-KCqW"}},{"cell_type":"code","source":"def get_metrics(metrics, enable_iou_metrics:bool=False):\n  dtype = getattr(tf, CONFIG.DTYPE)\n  if enable_iou_metrics: metrics.extend([iou_coef(dtype=dtype),\n                                         iou_loss(dtype=dtype)])\n  return metrics","metadata":{"id":"AdMqvf7j7Gae","execution":{"iopub.status.busy":"2022-05-28T05:02:16.530377Z","iopub.execute_input":"2022-05-28T05:02:16.530702Z","iopub.status.idle":"2022-05-28T05:02:16.535604Z","shell.execute_reply.started":"2022-05-28T05:02:16.530675Z","shell.execute_reply":"2022-05-28T05:02:16.534725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_custom_objects():\n  _custom_objects = None\n  if CONFIG.IOU_METRICS: \n    _custom_objects = {'iou_coef':iou_coef, 'iou_loss':iou_loss}\n  return _custom_objects","metadata":{"id":"bIhbjrv58AEu","execution":{"iopub.status.busy":"2022-05-28T05:02:16.593153Z","iopub.execute_input":"2022-05-28T05:02:16.593522Z","iopub.status.idle":"2022-05-28T05:02:16.599957Z","shell.execute_reply.started":"2022-05-28T05:02:16.593492Z","shell.execute_reply":"2022-05-28T05:02:16.599236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training function","metadata":{"id":"58vf7KhNJ_Z0"}},{"cell_type":"code","source":"def model_train(train_ds, val_ds, wt_file:str, metrics:list, callbacks:list, \n                model=None, custom_objects=None, tpu:bool=tpu, verbose:bool=False):\n  opt = getattr(tf.keras.optimizers, CONFIG.OPTIMIZER)(CONFIG.LEARNING_RATE)\n\n  if CONFIG.IOU_LOSS:\n    loss = IoU_Loss(dtype=CONFIG.DTYPE, epsilon=1e-24)\n  elif CONFIG.STYLE=='multiclass':\n    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n  else:\n    loss = tfa.losses.SigmoidFocalCrossEntropy(from_logits=True)\n   \n  model = load_weights(wt_file, model, custom_objects=custom_objects, tpu=tpu)\n\n  model.compile(optimizer=opt, loss=loss, metrics=metrics)\n    \n  if verbose:\n    print('Memory usage at training start ...')\n    if mem_usage is not None: _ = mem_usage(); del _\n  if tpu:\n    model.fit(train_ds, validation_data=val_ds, \n              epochs=CONFIG.EPOCHS, callbacks=callbacks)\n    print('\\n... Finished training on TPU ...')\n  else:\n    history = model.fit(train_ds, validation_data=val_ds, \n                        epochs=CONFIG.EPOCHS, callbacks=cb)\n    plot_history(history, metrics=metrics)\n  if verbose:\n    print('Memory usage at training end ...')\n    if mem_usage is not None: _ = mem_usage(); del _","metadata":{"id":"PIoi2eJUXxXi","execution":{"iopub.status.busy":"2022-05-28T05:02:16.65823Z","iopub.execute_input":"2022-05-28T05:02:16.658835Z","iopub.status.idle":"2022-05-28T05:02:16.667769Z","shell.execute_reply.started":"2022-05-28T05:02:16.658804Z","shell.execute_reply":"2022-05-28T05:02:16.666798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_weights_file(fold:int=0, wt_filename:str='model.h5', wt_dir:str='./'):\n  if CONFIG.COLAB_KERNEL and ((not UPDATE_WEIGHTS) or CONFIG.TRAIN_VAL_SPLIT): \n    wt_dir = CONFIG.GOOGLE_DRIVE \n  wt_file = os.path.join(wt_dir, wt_filename)\n  if fold is not None:\n    fold_wt_file = os.path.join(wt_dir, f'{wt_filename}-fold_{fold:02d}')\n  if os.path.exists(f'{fold_wt_file}.h5'):\n    return f'{fold_wt_file}.h5'   \n  elif os.path.exists(fold_wt_file):\n    return fold_wt_file\n  return wt_file","metadata":{"id":"lJ2XF3ANlOAg","execution":{"iopub.status.busy":"2022-05-28T05:02:16.764081Z","iopub.execute_input":"2022-05-28T05:02:16.764901Z","iopub.status.idle":"2022-05-28T05:02:16.771623Z","shell.execute_reply.started":"2022-05-28T05:02:16.764837Z","shell.execute_reply":"2022-05-28T05:02:16.770828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model training","metadata":{"id":"43VuErhZ-H6F"}},{"cell_type":"code","source":"if CONFIG.ENABLE_TRAINING and CONFIG.TRAIN_VAL_SPLIT:\n  train_ds, val_ds = None, None\n  gkf = GroupKFold(n_splits=CONFIG.NUM_FOLDS)\n  train_df = df_process(train_df) \n  df1, df2, df3 = df_generator(train_df)\n  fold = 0\n  for train_idxs, val_idxs in gkf.split(df1, df2, df3):\n    print(f'\\n... Training fold: {fold} ...')  \n    split_train_df = df_dropna(df_indexer(train_df, train_idxs))\n    split_val_df = df_dropna(df_indexer(train_df, val_idxs))\n    if CONFIG.FOLD_SELECTION is None or (CONFIG.FOLD_SELECTION == fold):\n      try:\n        with strategy.scope():\n          wt_file = get_weights_file(fold=fold, wt_filename=CONFIG.SAVED_WEIGHTS, \n                                     wt_dir=CONFIG.SAVED_WEIGHTS_DIR)\n          efns = get_model()\n\n          cb = get_callbacks(ckpt=f'{CONFIG.SAVED_WEIGHTS}-fold_{fold:02d}', \n                             ckpt_dir='./', tpu=tpu)\n        \n          metrics = get_metrics(metrics=CONFIG.METRICS, \n                                enable_iou_metrics=CONFIG.IOU_METRICS)\n\n          custom_objects = get_custom_objects()\n\n          train_ds = make_train_dataset(split_train_df, batch_size=CONFIG.BATCH_SIZE)\n          val_ds = make_train_dataset(split_train_df, mode='val',\n                                      batch_size=CONFIG.BATCH_SIZE)\n\n          model_train(train_ds, val_ds, wt_file=wt_file, metrics=metrics, \n                      callbacks=cb, model=efns, custom_objects=custom_objects,\n                      tpu=tpu, verbose=CONFIG.VERBOSE); fold+=1\n\n          mem_cleaner([train_ds, val_ds, efns, \n                       split_train_df, split_val_df, \n                       metrics, cb, custom_objects])\n          clear_memory(clear_session=True if tpu else False)\n      except Exception as e:\n        print(f'Training encountered the following error: \\n\\n{e}')\n    else:\n      fold+=1    \nelif CONFIG.ENABLE_TRAINING:\n  with strategy.scope():\n    wt_file = os.path.join(CONFIG.SAVED_WEIGHTS_DIR, CONFIG.SAVED_WEIGHTS)\n    if CONFIG.COLAB_KERNEL and not UPDATE_WEIGHTS: \n      wt_file=os.path.join(CONFIG.GOOGLE_DRIVE, CONFIG.SAVED_WEIGHTS)\n\n    efns = get_model()\n    \n    metrics = get_metrics(metrics=CONFIG.METRICS, enable_iou_metrics=CONFIG.IOU_METRICS)\n\n    cb = get_callbacks(ckpt=CONFIG.SAVED_WEIGHTS, ckpt_dir='./', tpu=tpu)\n\n    model_train(train_ds, val_ds, wt_file=wt_file, \n                metrics=metrics, callbacks=cb, model=efns, tpu=tpu, \n                custom_objects=get_custom_objects(), verbose=CONFIG.VERBOSE)","metadata":{"id":"O_Qc45nannZ-","execution":{"iopub.status.busy":"2022-05-28T05:02:16.904954Z","iopub.execute_input":"2022-05-28T05:02:16.905638Z","iopub.status.idle":"2022-05-28T05:02:16.920148Z","shell.execute_reply.started":"2022-05-28T05:02:16.905599Z","shell.execute_reply":"2022-05-28T05:02:16.919267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create inference model","metadata":{"id":"AJ-W_sLjaXvU"}},{"cell_type":"code","source":"def get_inference_model():  \n  wt_file = get_weights_file(fold=CONFIG.FOLD_SELECTION,\n                             wt_filename=CONFIG.SAVED_WEIGHTS,\n                             wt_dir=CONFIG.SAVED_WEIGHTS_DIR)\n  custom_objects = get_custom_objects()\n  model = get_model()\n  try:\n    model.load_weights(wt_file)\n    print(f'Loaded weights from: {wt_file} ...')\n  except:\n    model = load_weights(wt_file, model, custom_objects=custom_objects, tpu=tpu)\n  return model","metadata":{"id":"kziCJA9AXMUX","execution":{"iopub.status.busy":"2022-05-28T05:02:16.978676Z","iopub.execute_input":"2022-05-28T05:02:16.979496Z","iopub.status.idle":"2022-05-28T05:02:16.985543Z","shell.execute_reply.started":"2022-05-28T05:02:16.979455Z","shell.execute_reply":"2022-05-28T05:02:16.984451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG.VERBOSE:\n  efns = get_inference_model()","metadata":{"id":"f5DdlizFnhtM","outputId":"9b5f2e84-8221-41c7-8b48-a9cfbeb8c2d4","execution":{"iopub.status.busy":"2022-05-28T05:02:18.821682Z","iopub.execute_input":"2022-05-28T05:02:18.822044Z","iopub.status.idle":"2022-05-28T05:02:26.059973Z","shell.execute_reply.started":"2022-05-28T05:02:18.822013Z","shell.execute_reply":"2022-05-28T05:02:26.058171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create predictions","metadata":{}},{"cell_type":"code","source":"def get_predictions(img, model, mode:str='multilabel'):\n  preds_ =  model(img)\n  if mode=='multilabel':\n    return np.where(tf.nn.sigmoid(preds_)>=0.1, 1.0, 0.0)\n  else:\n    return np.argmax(preds_, axis=-1) ","metadata":{"execution":{"iopub.status.busy":"2022-05-28T05:02:26.061938Z","iopub.execute_input":"2022-05-28T05:02:26.062301Z","iopub.status.idle":"2022-05-28T05:02:26.067417Z","shell.execute_reply.started":"2022-05-28T05:02:26.062262Z","shell.execute_reply":"2022-05-28T05:02:26.066587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot predictions","metadata":{"id":"vE7w1q1DnnaE"}},{"cell_type":"code","source":"def get_overlay(img, mask, alpha:float=0.999, beta:float=0.45, gamma:float=0):\n  img = (img/img.max()).astype(np.float32)\n  if len(mask.shape)!=3:\n    mask_rgb = np.zeros_like(img, dtype=np.float32)\n    mask_rgb[..., 2] = np.where(mask==3, 1.0, 0.0)\n    mask_rgb[..., 1] = np.where(mask==2, 1.0, 0.0)\n    mask_rgb[..., 0] = np.where(mask==1, 1.0, 0.0)\n  else:\n    mask_rgb=mask.astype(np.float32)\n  seg_overlay = cv2.addWeighted(src1=img, alpha=alpha, \n                                src2=mask_rgb, beta=beta, gamma=gamma)\n  return seg_overlay\n\ndef get_miss_overlay(gt_mask, pred_mask, _alpha:float=0.9, \n                     _beta:float=0.25, _gamma:float=0):\n  miss_rgb = np.zeros((*pred_mask.shape[:2],3), dtype=np.float32)\n  if len(pred_mask.shape)==2:\n    miss_rgb[..., 1] = np.where((gt_mask==pred_mask)&(gt_mask!=0), 0.8, 0.0)\n    miss_rgb[..., 0] = np.where((gt_mask!=pred_mask), 0.8, 0.0)\n  else:\n    miss_rgb = np.where((gt_mask==pred_mask) & (gt_mask!=0.0), \n                        (0.0,0.8,0.0), (0.0,0.0,0.0))\n    miss_rgb = np.where((gt_mask!=pred_mask), (0.8,0.0,0.0), miss_rgb)\n  return miss_rgb\n\ndef plot_preds(img, pred_mask, gt_mask):\n  gt_overlay = get_overlay(img, gt_mask)\n  pred_overlay = get_overlay(img, pred_mask)\n  miss_overlay = get_miss_overlay(gt_mask, pred_mask)\n    \n  plt.figure(figsize=(20,12))\n    \n  for i, (_desc, _img) in enumerate(zip(['Original', \n                                         'Prediction Mask', \n                                         'Ground-Truth Mask', \n                                         'Miss Mask'], \n                                        \n                                        [img, \n                                         pred_overlay, \n                                         gt_overlay, \n                                         miss_overlay])):        \n    plt.subplot(1,4,i+1)\n    plt.imshow(_img)\n    plt.title(f'{_desc} Image', fontweight='bold')        \n    plt.axis(False)\n        \n    if i in [1,2]:\n      handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), \n                                                           (0.0,0.667,0.0), \n                                                           (0.0,0.0,0.667)]]\n      labels = ['Large bowel segmentation map', \n                'Small bowel segmentation map', \n                'Stomach segmentation map']\n      plt.legend(handles,labels)\n    elif i==3:\n      handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.0,0.8,0.0), \n                                                           (0.8,0.0,0.0), \n                                                           (0.0, 0.0, 0.0)]]\n      labels = ['Agreement', 'Disagreement', 'Background']\n      plt.legend(handles,labels)\n  plt.tight_layout()\n  plt.show()","metadata":{"id":"ogmYL-DonnaG","execution":{"iopub.status.busy":"2022-05-28T05:02:26.068912Z","iopub.execute_input":"2022-05-28T05:02:26.069459Z","iopub.status.idle":"2022-05-28T05:02:26.088604Z","shell.execute_reply.started":"2022-05-28T05:02:26.069423Z","shell.execute_reply":"2022-05-28T05:02:26.087673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sample predictions using training data","metadata":{"id":"nUNc5ePennaJ"}},{"cell_type":"code","source":"if (CONFIG.DEBUG or CONFIG.ENABLE_TRAINING) and CONFIG.VERBOSE:\n  if val_ds is None:\n    val_ds = make_train_dataset(split_train_df, batch_size=10, mode='val')  \n  for _img_batch, _mask_batch in val_ds.take(1):\n    _pred_batch = get_predictions(_img_batch, efns, mode=CONFIG.STYLE)\n    _img_batch = ((_img_batch+1)*127.5).numpy().astype(np.int32)\n    _mask_batch = _mask_batch.numpy().squeeze().astype(np.float32)\n    break\n\n  for _img, _pred, _mask in zip(_img_batch, _pred_batch, _mask_batch):\n    plot_preds(_img, _pred, _mask)\n    mem_cleaner(['_img', '_pred', '_mask'])\n  mem_cleaner(['_img_batch', '_pred_batch', '_mask_batch'])","metadata":{"id":"DPHjAB6wnnaL","outputId":"b458826f-88f1-4a6e-8e86-3d0a6ea61d75","execution":{"iopub.status.busy":"2022-05-28T05:08:28.811416Z","iopub.execute_input":"2022-05-28T05:08:28.811908Z","iopub.status.idle":"2022-05-28T05:08:41.326145Z","shell.execute_reply.started":"2022-05-28T05:08:28.811831Z","shell.execute_reply":"2022-05-28T05:08:41.325227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Housekeeping","metadata":{"id":"Tdg663SubYds"}},{"cell_type":"code","source":"if CONFIG.KAGGLE_KERNEL:\n  !rm -rf ./multi*\nelse:\n  !rm -rf {ROOT_DIR}/multi*\n\nhousekeeping()\n\nclear_memory(4, clear_session=False)","metadata":{"id":"QyinkVjennaN","execution":{"iopub.status.busy":"2022-05-28T05:02:46.647271Z","iopub.status.idle":"2022-05-28T05:02:46.648188Z","shell.execute_reply.started":"2022-05-28T05:02:46.647953Z","shell.execute_reply":"2022-05-28T05:02:46.647979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{"id":"UltBtuBUnnaP"}},{"cell_type":"code","source":"def pred_2_rle(pred_arr, root_shape):\n  # Get correct size pred array based on initial slice size\n  pred_arr = cv2.resize(pred_arr, root_shape, interpolation=cv2.INTER_NEAREST)\n    \n  # Get individual segmentation masks\n  lb_mask = np.where(pred_arr==1,1,0)\n  sb_mask = np.where(pred_arr==2,1,0)\n  st_mask = np.where(pred_arr==3,1,0)\n    \n  return rle_encode(lb_mask), rle_encode(sb_mask), rle_encode(st_mask)","metadata":{"id":"jnFeoSaknnaQ","execution":{"iopub.status.busy":"2022-05-28T05:02:46.649376Z","iopub.status.idle":"2022-05-28T05:02:46.649937Z","shell.execute_reply.started":"2022-05-28T05:02:46.649673Z","shell.execute_reply":"2022-05-28T05:02:46.649698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_TEST = int(np.ceil((len(sub_df)//3) / CONFIG.TEST_BATCH_SIZE))\nprint(f'Number of test samples: {NUM_TEST} ...')","metadata":{"id":"q0Y-J5LJnnaU","outputId":"711fe75e-4cb3-443f-f6d3-77cf3d244fbf","execution":{"iopub.status.busy":"2022-05-28T05:02:46.651494Z","iopub.status.idle":"2022-05-28T05:02:46.652144Z","shell.execute_reply.started":"2022-05-28T05:02:46.651918Z","shell.execute_reply":"2022-05-28T05:02:46.651942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if gpu:\n  gpu_name = tf.config.list_physical_devices(device_type='GPU')[0][0]\n  print(gpu_name)","metadata":{"execution":{"iopub.status.busy":"2022-05-28T05:02:46.653297Z","iopub.status.idle":"2022-05-28T05:02:46.653959Z","shell.execute_reply.started":"2022-05-28T05:02:46.653716Z","shell.execute_reply":"2022-05-28T05:02:46.653739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, img_batch in tqdm(enumerate(test_ds), total=NUM_TEST):\n  if CONFIG.VERBOSE:\n    print(f'Memory usage at inference batch: {i} start ...')\n    if mem_usage is not None: _ = mem_usage(); del _; _ = gc.collect()\n  if i%CONFIG.CLEANUP_FREQUENCY==0:\n    clear_memory(clear_session=False)\n    if i==0:\n      mem_cleaner(['efns']); clear_memory(clear_session=False); efns = None\n      with warnings.catch_warnings(record=True):\n        with strategy.scope():\n          efns = get_inference_model()\n      if efns is None:\n        raise ValueError('... No inference model found. Nothing to do here!!! ...')  \n    print(f\"Processed test samples' batch: {i}/{NUM_TEST} ...\")\n    \n  if CONFIG.DEBUG and CONFIG.SPEED_SUB and i>=CONFIG.SPEED_SUB_SAMPLES: break\n  \n  with warnings.catch_warnings(record=True):\n    with strategy.scope():    \n      pred_batch = get_predictions(img_batch, efns, mode=CONFIG.STYLE)\n  del img_batch\n    \n  # Loop over prediction and determine submission dataframe index \n  # (3*individual-count because of reduced inference size)\n  with warnings.catch_warnings(record=True):\n    for j, _pred in enumerate(pred_batch):\n      df_idx = 3*(i*CONFIG.TEST_BATCH_SIZE+j)\n      pred_rles = pred_2_rle(_pred, (sub_df.iloc[df_idx]['slice_h'], \n                                     sub_df.iloc[df_idx]['slice_w']))\n      del j, _pred    \n      # Loop over rles and assign the correct row of the submission dataframe\n      for k, pred_rle in enumerate(pred_rles):\n        sub_df.loc[df_idx+k, 'predicted'] = pred_rle\n        del k, pred_rle\n  del pred_batch\n  if CONFIG.VERBOSE:\n    print(f'Memory usage at inference batch: {i} end ...')\n    if mem_usage is not None: _ = mem_usage(); del _; _ = gc.collect()\nmem_cleaner(['test_ds', 'efns']); clear_memory(4, clear_session=True)","metadata":{"id":"WXnWGPTFnnaW","outputId":"fd895a03-977d-489b-8cc1-3b4a134ec437","execution":{"iopub.status.busy":"2022-05-28T05:02:46.655166Z","iopub.status.idle":"2022-05-28T05:02:46.655817Z","shell.execute_reply.started":"2022-05-28T05:02:46.655589Z","shell.execute_reply":"2022-05-28T05:02:46.655612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{"id":"oNWZQ8yDnnaY"}},{"cell_type":"code","source":"sub_df = sub_df[['id', 'class', 'predicted']]\nsub_df.to_csv('submission.csv', index=False)\nif CONFIG.VERBOSE: display(sub_df)","metadata":{"id":"4XH8tqJXnnaZ","outputId":"7e16eb00-9f40-4b09-810d-61b2ff401810","execution":{"iopub.status.busy":"2022-05-28T05:02:46.656993Z","iopub.status.idle":"2022-05-28T05:02:46.657639Z","shell.execute_reply.started":"2022-05-28T05:02:46.65741Z","shell.execute_reply":"2022-05-28T05:02:46.657434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Folder sync","metadata":{"id":"wAbx7ku3PDhQ"}},{"cell_type":"code","source":"if CONFIG.KAGGLE_KERNEL:\n  if not CONFIG.ENABLE_TRAINING:\n    wt_file = os.path.join(CONFIG.SAVED_WEIGHTS_DIR, CONFIG.SAVED_WEIGHTS)\n    linux_shell([f'cp -r {wt_file}* ./', 'rm -rf ./multi*'])\nelse:\n  if CONFIG.ENABLE_TRAINING:\n    saved_wts = os.path.join(CONFIG.GOOGLE_DRIVE, CONFIG.SAVED_WEIGHTS)\n    if os.path.exists(f'{ROOT_DIR}/{CONFIG.SYNC_DIR}'):\n      linux_shell([f'cp -r {saved_wts}* {ROOT_DIR}/{CONFIG.SYNC_DIR}/'])\n    else:\n      linux_shell([f'mkdir {ROOT_DIR}/{CONFIG.SYNC_DIR}',\n                   f'cp -r {saved_wts}* {ROOT_DIR}/{CONFIG.SYNC_DIR}/'])\n  for dir in os.listdir(f'{ROOT_DIR}/{CONFIG.SYNC_DIR}'):\n    if os.path.isdir(f'{ROOT_DIR}/{CONFIG.SYNC_DIR}/{dir}'):\n      linux_shell([\n        f'cd {ROOT_DIR}/{CONFIG.SYNC_DIR}/; zip -r ./{dir}.zip ./{dir}; cd ../',\n        f'rm -r {ROOT_DIR}/{CONFIG.SYNC_DIR}/{dir}/'])\n  update_msg = 'Synced external directory ...'   \n  linux_shell([\n    f'kaggle datasets version -p {ROOT_DIR}/{CONFIG.SYNC_DIR} -m \"{update_msg}\"'])","metadata":{"id":"q0BEpBdrIZsC","execution":{"iopub.status.busy":"2022-05-28T05:02:46.658823Z","iopub.status.idle":"2022-05-28T05:02:46.659495Z","shell.execute_reply.started":"2022-05-28T05:02:46.659252Z","shell.execute_reply":"2022-05-28T05:02:46.659275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# References:\n**1. This notebook is forked and modified from the [original code notebook by @dschettler8845](https://www.kaggle.com/code/dschettler8845/uwmgit-deeplabv3-w-se-aspp-tf-e2e-pipeline)**\n\n**2. [University of Wisconsin-Madison gastro intestinal cancer segmentation dataset on Kaggle](https://www.kaggle.com/competitions/uw-madison-gi-tract-image-segmentation)**","metadata":{"id":"6XMIxaXMnnab"}},{"cell_type":"code","source":"","metadata":{"id":"hZGzbqC-dsgF"},"execution_count":null,"outputs":[]}]}