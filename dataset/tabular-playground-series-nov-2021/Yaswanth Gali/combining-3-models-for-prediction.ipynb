{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## We are combining 3 diffrent models for our final predictions(xgboost,lightgbm,catboost).This is called model blending","metadata":{}},{"cell_type":"markdown","source":"## Import libarires","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nimport optuna","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"../input/tabular-playground-series-nov-2021/train.csv\")\ndf_test=pd.read_csv(\"../input/tabular-playground-series-nov-2021/test.csv\")\nsample_submission=pd.read_csv(\"../input/tabular-playground-series-nov-2021/sample_submission.csv\")\ntest_df=df_test.copy()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#taking only useful columns for predictions\nuseful_cols=[c for c in df.columns if c not in (\"id\",\"target\",\"kfold\")]\ndf_test=df_test[useful_cols]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## xgboost","metadata":{}},{"cell_type":"code","source":"#First we dividing the data into 5 folds so our model won't overfit\nkf=KFold(n_splits=5,random_state=42,shuffle=True)\nfor fold,(train_index,valid_index) in enumerate(kf.split(X=df)):\n    df.loc[valid_index,\"kfold\"]=fold\n    \n    \nfinal_test_pred=[]\nfinal_valid_pred={}\nscores=[]\n\n\n\nfor fold in range(5):\n    xtrain=df[df.kfold != fold].reset_index(drop=True)#training set=4 folds\n    xvalid=df[df.kfold == fold].reset_index(drop=True)#validation set=1 fold\n    xtest=df_test.copy()\n    \n    valid_id=xvalid.id.values.tolist()#since we are shuffiling the data we need to kepp track of the id\n    #test_id=xtest.id.values.tolist()\n    \n    \n    ytrain=xtrain.target\n    yvalid=xvalid.target\n    \n    xtrain=xtrain[useful_cols]#taking only useful columns\n    xvalid=xvalid[useful_cols]\n    \n    #our model\n    model=XGBClassifier(random_state=fold,\n                        predictor=\"gpu_predictor\",\n                        tree_method='gpu_hist')\n    \n    model.fit(xtrain,ytrain)\n    pred_valid=model.predict(xvalid)#predicting on validation set\n    pred_test=model.predict(xtest)#predicting on test set\n    final_test_pred.append(pred_test)#appending the test predictions\n    final_valid_pred.update(dict(zip(valid_id,pred_valid)))#updating the vaid predicions\n    score=roc_auc_score(yvalid,pred_valid)\n    print(score,fold)\n    scores.append(score)#calculating and appendint the scores\n    \n    \n    \nprint(np.mean(scores)) \n#converting our valid predictions to a dataframe\nfinal_valid_pred=pd.DataFrame.from_dict(final_valid_pred,orient='index').reset_index()\nfinal_valid_pred.columns=['id',\"preds_1\"]\nfinal_valid_pred.to_csv('train_pred_1.csv',index=False)\n\n#converting our test predictions to a dataframe\nsample_submission.target=np.mean(np.column_stack(final_test_pred),axis=1)\nsample_submission.columns=['id','preds_1']\nsample_submission.to_csv(\"test_pred_1.csv\",index=False)\n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## lightgbm","metadata":{}},{"cell_type":"code","source":"kf=KFold(n_splits=5,random_state=42,shuffle=True)\nfor fold,(train_index,valid_index) in enumerate(kf.split(X=df)):\n    df.loc[valid_index,\"kfold\"]=fold\n    \n    \nfinal_test_pred=[]\nfinal_valid_pred={}\nscores=[]\n\n\n\nfor fold in range(5):\n    xtrain=df[df.kfold != fold].reset_index(drop=True)\n    xvalid=df[df.kfold == fold].reset_index(drop=True)\n    xtest=df_test.copy()\n    \n    valid_id=xvalid.id.values.tolist()\n    #test_id=xtest.id.values.tolist()\n    \n    \n    ytrain=xtrain.target\n    yvalid=xvalid.target\n    \n    xtrain=xtrain[useful_cols]\n    xvalid=xvalid[useful_cols]\n    \n    model=LGBMClassifier(device = \"gpu\",\n                    gpu_platform_id=0,\n                     gpu_device_id = 0)\n    \n    model.fit(xtrain,ytrain)\n    pred_valid=model.predict(xvalid)\n    pred_test=model.predict(xtest)\n    final_test_pred.append(pred_test)\n    final_valid_pred.update(dict(zip(valid_id,pred_valid)))\n    score=roc_auc_score(yvalid,pred_valid)\n    print(score,fold)\n    scores.append(score)\n    \n    \n    \nprint(np.mean(scores))    \n    \nfinal_valid_pred=pd.DataFrame.from_dict(final_valid_pred,orient='index').reset_index()\nfinal_valid_pred.columns=['id',\"preds_2\"]\nfinal_valid_pred.to_csv('train_pred_2.csv',index=False)\n\nsample_submission.target=np.mean(np.column_stack(final_test_pred),axis=1)\nsample_submission.columns=['id','preds_2']\nsample_submission.to_csv(\"test_pred_2.csv\",index=False)    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## catboost","metadata":{}},{"cell_type":"code","source":"kf=KFold(n_splits=5,random_state=42,shuffle=True)\nfor fold,(train_index,valid_index) in enumerate(kf.split(X=df)):\n    df.loc[valid_index,\"kfold\"]=fold\n    \n    \nfinal_test_pred=[]\nfinal_valid_pred={}\nscores=[]\n\n\n\nfor fold in range(5):\n    xtrain=df[df.kfold != fold].reset_index(drop=True)\n    xvalid=df[df.kfold == fold].reset_index(drop=True)\n    xtest=df_test.copy()\n    \n    valid_id=xvalid.id.values.tolist()\n    #test_id=xtest.id.values.tolist()\n    \n    \n    ytrain=xtrain.target\n    yvalid=xvalid.target\n    \n    xtrain=xtrain[useful_cols]\n    xvalid=xvalid[useful_cols]\n    \n    model=CatBoostClassifier(task_type = \"GPU\")\n    \n    model.fit(xtrain,ytrain)\n    pred_valid=model.predict(xvalid)\n    pred_test=model.predict(xtest)\n    final_test_pred.append(pred_test)\n    final_valid_pred.update(dict(zip(valid_id,pred_valid)))\n    score=roc_auc_score(yvalid,pred_valid)\n    print(score,fold)\n    scores.append(score)\n    \n    \n    \nprint(np.mean(scores))    \n\nfinal_valid_pred=pd.DataFrame.from_dict(final_valid_pred,orient='index').reset_index(\n)\nfinal_valid_pred.columns=['id',\"preds_3\"]\nfinal_valid_pred.to_csv('train_pred_3.csv',index=False)\n\nsample_submission.target=np.mean(np.column_stack(final_test_pred),axis=1)\nsample_submission.columns=['id','preds_3']\nsample_submission.to_csv(\"test_pred_3.csv\",index=False)\n    \n    \n    ","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reading the prediction on vaidation set of the 3 model\ndf1=pd.read_csv(\"./train_pred_1.csv\")\ndf2=pd.read_csv(\"./train_pred_2.csv\")\ndf3=pd.read_csv(\"./train_pred_3.csv\")\n\n#reading the prediction of test set of the 3 model\ndf_test1=pd.read_csv(\"./test_pred_1.csv\")\ndf_test2=pd.read_csv(\"./test_pred_2.csv\")\ndf_test3=pd.read_csv(\"./test_pred_3.csv\")\n\n#we are merging the predictions with the original dataframe\n\ndf=df.merge(df1,on=\"id\",how=\"left\")\ndf=df.merge(df2,on=\"id\",how=\"left\")\ndf=df.merge(df3,on=\"id\",how=\"left\")\n\ntest_df=test_df.merge(df1,on=\"id\",how=\"left\")\ntest_df=test_df.merge(df2,on=\"id\",how=\"left\")\ntest_df=test_df.merge(df3,on=\"id\",how=\"left\")\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial):\n    \n    #These are the feature we are goint to use for predictions\n    final_useful_features=['preds_1','preds_2','preds_3']\n\n    kf=KFold(n_splits=5,random_state=42,shuffle=True)\n    for fold,(train_index,valid_index) in enumerate(kf.split(X=df)):\n        df.loc[valid_index,\"kfold\"]=fold\n\n\n    final_pred=[]\n    final_valid_pred={}\n    scores=[]\n\n\n\n    for fold in range(5):\n        xtrain=df[df.kfold != fold].reset_index(drop=True)\n        xvalid=df[df.kfold == fold].reset_index(drop=True)\n        xtest=test_df.copy()\n\n        valid_id=xvalid.id.values.tolist()\n        #test_id=xtest.id.values.tolist()\n\n\n        ytrain=xtrain.target\n        yvalid=xvalid.target\n\n        xtrain=xtrain[final_useful_features]\n        xvalid=xvalid[final_useful_features]\n        xtest=xtest[final_useful_features]\n\n\n        params = {\n            'learning_rate': 0.07853392035787837,\n            'reg_lambda': 1.7549293092194938e-05,\n            'reg_alpha': 14.68267919457715, \n            'subsample': 0.8031450486786944, \n            'colsample_bytree': 0.170759104940733, \n            'max_depth': 3\n        }\n\n        model = XGBClassifier(\n            random_state=fold,\n            n_jobs=4,\n            n_estimators=5000,\n            **params\n        )\n\n        model.fit(xtrain,ytrain)\n        pred_valid=model.predict(xvalid)\n        pred_test=model.predict(xtest)\n        final_pred.append(pred_test)\n        final_valid_pred.update(dict(zip(valid_id,pred_valid)))\n        score=roc_auc_score(yvalid,pred_valid)\n        print(score,fold)\n        scores.append(score)\n    \n    \n    \nprint(np.mean(scores)) \n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"study = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"sample_submission.target=np.mean(np.column_stack(final_test_pred),axis=1)\nsample_submission.columns=['id','target']\nsample_submission.to_csv(\"my_output1.csv\",index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}