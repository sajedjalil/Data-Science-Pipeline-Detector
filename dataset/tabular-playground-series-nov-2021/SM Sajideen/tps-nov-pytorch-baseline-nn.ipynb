{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Update\n* Added uniform weight initialization.\n* Loss graphs.\n* Early Stopping.","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import gc\nimport numpy as np\nimport pandas as pd\nimport math\nimport torch\nimport copy\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.metrics import roc_auc_score\nfrom datetime import datetime\nimport torch.nn.functional as F","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-28T10:11:30.324672Z","iopub.execute_input":"2021-11-28T10:11:30.325269Z","iopub.status.idle":"2021-11-28T10:11:32.446901Z","shell.execute_reply.started":"2021-11-28T10:11:30.325182Z","shell.execute_reply":"2021-11-28T10:11:32.446166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tabular-playground-series-nov-2021/train.csv')\ntest = pd.read_csv('/kaggle/input/tabular-playground-series-nov-2021/test.csv')\nsub = pd.read_csv('/kaggle/input/tabular-playground-series-nov-2021/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-28T10:11:32.448425Z","iopub.execute_input":"2021-11-28T10:11:32.448662Z","iopub.status.idle":"2021-11-28T10:11:58.82002Z","shell.execute_reply.started":"2021-11-28T10:11:32.448629Z","shell.execute_reply":"2021-11-28T10:11:58.819013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else 'cpu'\nBATCH_SIZE = 512\nEPOCHS = 50","metadata":{"execution":{"iopub.status.busy":"2021-11-28T10:11:58.821439Z","iopub.execute_input":"2021-11-28T10:11:58.821715Z","iopub.status.idle":"2021-11-28T10:11:58.8677Z","shell.execute_reply.started":"2021-11-28T10:11:58.821679Z","shell.execute_reply":"2021-11-28T10:11:58.866842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FEATURES = [col for col in train.columns if col not in ['id','target']]\ny = train.target\ntrain_df = train.drop(columns=['id', 'target'])\ntest_df = test.drop(columns=['id'])","metadata":{"execution":{"iopub.status.busy":"2021-11-28T10:11:58.869879Z","iopub.execute_input":"2021-11-28T10:11:58.870492Z","iopub.status.idle":"2021-11-28T10:11:59.145322Z","shell.execute_reply.started":"2021-11-28T10:11:58.870452Z","shell.execute_reply":"2021-11-28T10:11:59.144495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Target Distribution","metadata":{}},{"cell_type":"code","source":"def target_dist():\n    palette = 'Set2'\n    plt=sns.countplot(x=y,palette=palette)\n    plt.set_title('Target distribution')\n    sns.despine()\n\ntarget_dist()","metadata":{"execution":{"iopub.status.busy":"2021-11-28T10:11:59.146893Z","iopub.execute_input":"2021-11-28T10:11:59.147196Z","iopub.status.idle":"2021-11-28T10:11:59.377476Z","shell.execute_reply.started":"2021-11-28T10:11:59.147158Z","shell.execute_reply":"2021-11-28T10:11:59.376805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training data\nprint(f'Numerical attributes: {len(train_df._get_numeric_data().columns)}' )\nprint(f'Categorical attributes: {abs(len(train_df.columns) - len(train_df._get_numeric_data().columns))}')\n# testing data\nprint(f'Numerical attributes: {len(test_df._get_numeric_data().columns)}' )\nprint(f'Categorical attributes: {abs(len(test_df.columns) - len(test_df._get_numeric_data().columns))}')","metadata":{"execution":{"iopub.status.busy":"2021-11-28T10:11:59.378738Z","iopub.execute_input":"2021-11-28T10:11:59.379148Z","iopub.status.idle":"2021-11-28T10:11:59.386668Z","shell.execute_reply.started":"2021-11-28T10:11:59.37911Z","shell.execute_reply":"2021-11-28T10:11:59.385991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"scaler_standard = StandardScaler()\ntrain_df[FEATURES] = scaler_standard.fit_transform(train_df[FEATURES])\ntest_df[FEATURES] = scaler_standard.transform(test_df[FEATURES])","metadata":{"execution":{"iopub.status.busy":"2021-11-28T10:11:59.388156Z","iopub.execute_input":"2021-11-28T10:11:59.388399Z","iopub.status.idle":"2021-11-28T10:12:01.520092Z","shell.execute_reply.started":"2021-11-28T10:11:59.388364Z","shell.execute_reply":"2021-11-28T10:12:01.519369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset:\n    def __init__(self, X, y=None):\n        self.X = X\n        self.y = y\n    def __len__(self):\n        return len(self.X)\n    def __getitem__(self, idx):\n        if self.y is None:\n            return torch.tensor(self.X.values[idx], dtype=torch.float)\n        else:\n            return torch.tensor(self.X.values[idx], dtype=torch.float), torch.tensor(self.y.values[idx], dtype=torch.float)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T10:12:01.521743Z","iopub.execute_input":"2021-11-28T10:12:01.522155Z","iopub.status.idle":"2021-11-28T10:12:01.529307Z","shell.execute_reply.started":"2021-11-28T10:12:01.522118Z","shell.execute_reply":"2021-11-28T10:12:01.528674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Weights Init","metadata":{}},{"cell_type":"markdown","source":"* A uniform distribution has the equal probability of picking any number from a set of numbers.\n* The general rule for setting the weights in a neural network is to set them to be close to zero without being too small.","metadata":{}},{"cell_type":"code","source":"# takes in a module and applies the specified weight initialization\ndef weights_init_uniform_rule(m):\n    classname = m.__class__.__name__\n    if classname.find('Linear') != -1:\n        n = m.in_features\n        y = 1.0/np.sqrt(n)\n        m.weight.data.uniform_(-y, y)\n        m.bias.data.fill_(0)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T10:12:01.53259Z","iopub.execute_input":"2021-11-28T10:12:01.533074Z","iopub.status.idle":"2021-11-28T10:12:01.543813Z","shell.execute_reply.started":"2021-11-28T10:12:01.533044Z","shell.execute_reply":"2021-11-28T10:12:01.543153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"def fc_block(in_f, out_f):\n        return nn.Sequential(\n            nn.Linear(in_f, out_f),\n            nn.SiLU(),\n            nn.Dropout(0.3),\n        )    \nclass Net(nn.Module):\n    def __init__(self, n):\n        super(Net, self).__init__()\n        self.flatten = nn.Flatten()\n        self.fc1 = fc_block(n, 192)\n        self.fc2 = fc_block(192, 96)\n        self.fc3 = fc_block(96, 48)\n        self.out = nn.Sequential(\n            nn.Linear(48, 1),\n            nn.Sigmoid()\n        )    \n    def forward(self, x):\n        x = self.flatten(x)\n        x = self.fc1(x)\n        x = self.fc2(x)\n        x = self.fc3(x)\n        x = self.out(x)\n        return x\n\nnet_model = Net(len(FEATURES)).to(device)\nnet_model.apply(weights_init_uniform_rule)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T10:12:01.546748Z","iopub.execute_input":"2021-11-28T10:12:01.547196Z","iopub.status.idle":"2021-11-28T10:12:03.92419Z","shell.execute_reply.started":"2021-11-28T10:12:01.547105Z","shell.execute_reply":"2021-11-28T10:12:03.923463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def batch_gd(model, train_loader, test_loader, epochs, val_score_best):\n    train_losses = np.zeros(epochs)\n    test_losses = np.zeros(epochs)\n    epochs_no_improve = 0\n    for it in range(epochs):\n        t0 = datetime.now()\n        model.train()\n        train_loss = []\n        train_roc = []\n        for batch_idx, (inputs, targets) in enumerate(train_loader):\n            # move data to GPU\n            inputs, targets = inputs.to(device), targets.to(device)\n            # zero the parameter gradients\n            optimizer.zero_grad()\n            # Forward pass\n            outputs = model(inputs)\n            targets = targets.unsqueeze(1)\n            loss = criterion(outputs, targets)\n            # Backward and optimize\n            loss.backward()\n            optimizer.step()\n            train_loss.append(loss.item())\n            train_roc.append(roc_auc_score(targets.cpu().data.numpy(), outputs.cpu().data.numpy()))\n            \n        else:\n            model.eval()\n            test_loss = []\n            test_roc = []\n            for inputs, targets in test_loader:\n                inputs, targets = inputs.to(device), targets.to(device)\n                outputs = model(inputs)\n                targets = targets.unsqueeze(1)\n                loss = criterion(outputs, targets)\n                test_loss.append(loss.item())\n                test_roc.append(roc_auc_score(targets.cpu().data.numpy(), outputs.cpu().data.numpy()))\n            #get train and test loss\n            test_loss = np.mean(test_loss)\n            train_loss = np.mean(train_loss)\n            lr_scheduler.step(test_loss)\n            ###    \n            print('learning_rate: {}'.format(optimizer.state_dict()['param_groups'][0]['lr']))\n            # Save losses\n            train_losses[it] = train_loss\n            test_losses[it] = test_loss\n            test_roc_auc = np.mean(test_roc)\n            # saving best weights\n            if test_loss < val_score_best:\n                epochs_no_improve = 0\n                val_score_best = test_loss\n                print(f'--- saving best weights ---')\n                torch.save(model.state_dict(), 'best_weights.pth')\n            else:\n                epochs_no_improve += 1\n            # getting the duration\n            dt = datetime.now() - t0\n            print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, Train ROC: {(np.mean(train_roc)):.4f}, \\\n                    Test Loss: {test_loss:.4f}, Test ROC: {test_roc_auc:.4f}, Improvement: {epochs_no_improve}, Duration: {dt}')\n            if epochs_no_improve == 10:\n                print(f'Early Stopping..\\n')\n                break\n    return train_losses, test_losses","metadata":{"execution":{"iopub.status.busy":"2021-11-28T10:12:03.925486Z","iopub.execute_input":"2021-11-28T10:12:03.925892Z","iopub.status.idle":"2021-11-28T10:12:03.940305Z","shell.execute_reply.started":"2021-11-28T10:12:03.925855Z","shell.execute_reply":"2021-11-28T10:12:03.939641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# garbage collection\ngc.collect()\n# creating and loading test data\ntest_dataset = CustomDataset(test_df)\ntest_loader = DataLoader(test_dataset, batch_size = 512)\n# defining folds dictionary\nfolds_train_losses = {}\nfolds_test_losses = {}\n# test data predictions\ntest_predictions = []\n# defining skfolds\nskf = StratifiedKFold(n_splits=5, random_state=47, shuffle=True)\nfor fold, (train_idx, val_idx) in enumerate(skf.split(train_df, y)):\n    X_train, y_train = train_df.iloc[train_idx], y.iloc[train_idx]\n    X_val, y_val = train_df.iloc[val_idx], y.iloc[val_idx]\n    \n    train_dataset = CustomDataset(X=X_train, y=y_train)\n    val_dataset = CustomDataset(X=X_val, y=y_val)\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n        \n    criterion = nn.BCELoss()    \n    optimizer = torch.optim.Adam(net_model.parameters(), lr=0.001)\n    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=2, \n                                                          verbose=True, min_lr=1e-7, mode='min')    \n    # training and validation\n    val_score_best = math.inf\n    train_losses, test_losses = batch_gd(net_model, train_loader, val_loader, EPOCHS, val_score_best)\n    folds_train_losses[fold] = train_losses\n    folds_test_losses[fold] = test_losses\n    \n    # loading best weights\n    # print(f'--- loading best weights ---')\n    # net_model.load_state_dict(torch.load('best_weights.pth'))\n    \n    # prediction on test data\n    test_preds = []\n    net_model.eval()\n    with torch.no_grad():\n        for idx, batch_tensor in enumerate(test_loader):\n            batch_tensor = batch_tensor.to(device)\n            preds = net_model(batch_tensor)\n            test_preds.extend(preds.cpu().detach().numpy())\n    test_predictions.append(test_preds)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T10:15:59.467482Z","iopub.execute_input":"2021-11-28T10:15:59.467744Z","iopub.status.idle":"2021-11-28T11:25:45.859059Z","shell.execute_reply.started":"2021-11-28T10:15:59.467715Z","shell.execute_reply":"2021-11-28T11:25:45.858315Z"},"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Losses and Plots","metadata":{}},{"cell_type":"code","source":"def average_loss_per_fold():\n    for (f_train, l_train), (f_test, l_test) in zip(folds_train_losses.items(), folds_test_losses.items()):\n        print(f'Fold: {f_train} \\t Average Train Loss: {np.mean(l_train)} \\t Average Test Loss: {np.mean(l_test)}')\n    \naverage_loss_per_fold()","metadata":{"execution":{"iopub.status.busy":"2021-11-28T12:24:28.463865Z","iopub.execute_input":"2021-11-28T12:24:28.464564Z","iopub.status.idle":"2021-11-28T12:24:28.470416Z","shell.execute_reply.started":"2021-11-28T12:24:28.464526Z","shell.execute_reply":"2021-11-28T12:24:28.469534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold in range(0,5):\n    sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n    fig, ax = plt.subplots(1, 1, tight_layout=True, figsize=(8,4))\n    plt.title(f'Fold: {fold+1}')\n    plt.subplot(1,1,1)\n    fold_df = pd.DataFrame(data=list(np.stack((folds_train_losses[fold], folds_test_losses[fold])).T),\n                     columns=['train_loss','val_loss'])\n    plt.plot(fold_df.loc[:, ['train_loss', 'val_loss']], label=fold_df.columns)\n    plt.xticks(np.arange(0,51,5))\n    plt.legend(fontsize=13)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T12:47:12.05231Z","iopub.execute_input":"2021-11-28T12:47:12.052569Z","iopub.status.idle":"2021-11-28T12:47:14.140374Z","shell.execute_reply.started":"2021-11-28T12:47:12.052538Z","shell.execute_reply":"2021-11-28T12:47:14.139734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"tp_df=pd.DataFrame(data=[list(i) for i in zip(*test_predictions)], columns=['fold_1','fold_2','fold_3','fold_4','fold_5'])\ntp_df.head(4)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T13:23:33.104313Z","iopub.execute_input":"2021-11-28T13:23:33.104625Z","iopub.status.idle":"2021-11-28T13:23:34.568255Z","shell.execute_reply.started":"2021-11-28T13:23:33.104588Z","shell.execute_reply":"2021-11-28T13:23:34.567541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictions_v2 = copy.deepcopy(test_predictions)\nsub['target'] = np.mean(np.column_stack(test_predictions_v2), axis=1)\nsub.to_csv(\"submission.csv\",index=None)\nsub.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T13:23:50.574594Z","iopub.execute_input":"2021-11-28T13:23:50.574844Z","iopub.status.idle":"2021-11-28T13:24:00.704618Z","shell.execute_reply.started":"2021-11-28T13:23:50.574816Z","shell.execute_reply":"2021-11-28T13:24:00.703888Z"},"trusted":true},"execution_count":null,"outputs":[]}]}