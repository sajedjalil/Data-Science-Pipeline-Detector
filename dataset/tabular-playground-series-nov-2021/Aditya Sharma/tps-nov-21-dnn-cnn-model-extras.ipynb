{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Intro\n\n**This notebook is highly based on amazing work done by DLASTSTARK, JAVIER VALLEJOS and PRIYANSHU CHAUDHARY, you may find link below:**\n\n* https://www.kaggle.com/dlaststark/tps-1121-dnn-v4\n* \nhttps://www.kaggle.com/javiervallejos/simple-nn-with-good-results-tps-nov-21\n* https://www.kaggle.com/chaudharypriyanshu/understanding-neural-net\n\n\n    \n**Please give them fully deserved interest!** ðŸ‘\n\n![](https://media.giphy.com/media/I4wGMXoi2kMDe/giphy-downsized-large.gif)","metadata":{}},{"cell_type":"markdown","source":"# Import libraries","metadata":{"papermill":{"duration":0.027505,"end_time":"2021-11-02T17:30:59.265588","exception":false,"start_time":"2021-11-02T17:30:59.238083","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import gc\nimport itertools\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import StratifiedKFold\n\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.layers import Concatenate\nfrom tensorflow.keras.layers import Input, BatchNormalization\nfrom tensorflow.keras.layers import Dense, Dropout, Multiply\n\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nnp.random.seed(42)\ntf.random.set_seed(42)","metadata":{"papermill":{"duration":5.597777,"end_time":"2021-11-02T17:31:04.881182","exception":false,"start_time":"2021-11-02T17:30:59.283405","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-12T12:54:02.066411Z","iopub.execute_input":"2021-11-12T12:54:02.066692Z","iopub.status.idle":"2021-11-12T12:54:02.075198Z","shell.execute_reply.started":"2021-11-12T12:54:02.066664Z","shell.execute_reply":"2021-11-12T12:54:02.074302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load source datasets","metadata":{"papermill":{"duration":0.01508,"end_time":"2021-11-02T17:31:04.912113","exception":false,"start_time":"2021-11-02T17:31:04.897033","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/tabular-playground-series-nov-2021/train.csv\")\ntrain_df.set_index('id', inplace=True)\nprint(f\"train_df: {train_df.shape}\")\ntrain_df.head()","metadata":{"papermill":{"duration":16.039469,"end_time":"2021-11-02T17:31:20.965377","exception":false,"start_time":"2021-11-02T17:31:04.925908","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-12T12:54:02.094159Z","iopub.execute_input":"2021-11-12T12:54:02.094426Z","iopub.status.idle":"2021-11-12T12:54:11.290845Z","shell.execute_reply.started":"2021-11-12T12:54:02.094391Z","shell.execute_reply":"2021-11-12T12:54:11.29009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(\"../input/tabular-playground-series-nov-2021/test.csv\")\ntest_df.set_index('id', inplace=True)\nind = test_df.index.tolist()\nprint(f\"test_df: {test_df.shape}\")\ntest_df.head()","metadata":{"papermill":{"duration":13.399826,"end_time":"2021-11-02T17:31:34.381089","exception":false,"start_time":"2021-11-02T17:31:20.981263","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-12T12:54:11.292147Z","iopub.execute_input":"2021-11-12T12:54:11.292494Z","iopub.status.idle":"2021-11-12T12:54:19.59277Z","shell.execute_reply.started":"2021-11-12T12:54:11.292453Z","shell.execute_reply":"2021-11-12T12:54:19.59208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering\nI was basing on DLASTSTARK feature engineering proposal but also added some statistics as : *'mean', 'std', 'min', 'max', 'median'*. During many tests found it worth to consider.","metadata":{"papermill":{"duration":0.025402,"end_time":"2021-11-02T17:31:34.43279","exception":false,"start_time":"2021-11-02T17:31:34.407388","status":"completed"},"tags":[]}},{"cell_type":"code","source":"mode = 'add'\n\nif mode == 'add':\n    \n    features = test_df.columns.tolist() \n\n    for col in tqdm(features):\n        train_df[col+'_bin'] = train_df[col].apply(lambda x: 1 if np.cbrt(x)>0 else 0) #1\n        test_df[col+'_bin'] = test_df[col].apply(lambda x: 1 if np.cbrt(x)>0 else 0) #1\n    \n    print('Calc train features...')\n\n    train_df[\"mean\"] = train_df[features].mean(axis=1)\n    train_df[\"std\"] = train_df[features].std(axis=1)\n    train_df[\"min\"] = train_df[features].min(axis=1)\n    train_df[\"max\"] = train_df[features].max(axis=1)\n    train_df[\"median\"] = train_df[features].median(axis=1)\n\n\n    \n    print('Calc test features...')\n    test_df[\"mean\"] = test_df[features].mean(axis=1)\n    test_df[\"std\"] = test_df[features].std(axis=1)\n    test_df[\"min\"] = test_df[features].min(axis=1)\n    test_df[\"max\"] = test_df[features].max(axis=1)\n    test_df[\"median\"] = test_df[features].median(axis=1)\n\n\n    features = test_df.columns.tolist()\n\n    features.extend(['mean', 'std', 'min', 'max', 'median'])\n\n    print(f\"train_df: {train_df.shape} \\ntest_df: {test_df.shape}\")\n\nelse:\n    pass","metadata":{"execution":{"iopub.status.busy":"2021-11-12T12:54:19.594947Z","iopub.execute_input":"2021-11-12T12:54:19.595268Z","iopub.status.idle":"2021-11-12T12:58:58.863979Z","shell.execute_reply.started":"2021-11-12T12:54:19.595217Z","shell.execute_reply":"2021-11-12T12:58:58.862351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Scaling / Dim Reduction / Whitening\nBelow you may switch between dim reduction / scaling / whitening methods prepared above. By default I did not use them.\nIf you are novice you may find some interesting information below:\n\n1. PCA: https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n2. Quantile Transformation: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.QuantileTransformer.html\n3. MinMaxScaler: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n4. Whitening: https://en.wikipedia.org/wiki/Whitening_transformation","metadata":{}},{"cell_type":"code","source":"from sklearn.decomposition import PCA\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import QuantileTransformer\n\ndef PCA_transform(train, test):\n    pca = PCA(n_components=16, whiten = False)\n    train = train.drop(columns=['target']).values\n    test = test.values\n    train = pca.fit_transform(train)\n    test = pca.transform(test)\n    return train, test\n\ndef Q_transform(train, test):\n    qtf = QuantileTransformer(random_state=21, n_quantiles=2000, output_distribution='normal')\n    train = train.drop(columns=['target']).values\n    test = test.values\n    train = qtf.fit_transform(train)\n    test = qtf.transform(test)\n    return train, test\n\ndef svd_whiten(train, test):\n    train = train.drop(columns=['target']).values\n    test = test.values\n    \n    U, s, Vt = np.linalg.svd(train, full_matrices=False)\n    train_arr = np.dot(U, Vt)\n    \n    U, s, Vt = np.linalg.svd(test, full_matrices=False)\n    test_arr = np.dot(U, Vt)\n    # U and Vt are the singular matrices, and s contains the singular values.\n    # Since the rows of both U and Vt are orthonormal vectors, then U * Vt\n    # will be white\n    return train_arr, test_arr\n\ndef scale_data(train, test):\n    feats_to_scale = ['f{}' for e in range(100)]\n    feats_to_add = ['f{}_bin' for e in range(100)] + ['mean', 'std', 'min', 'max', 'median']\n    \n    \n    train = train.drop(columns=['target']).values\n    test = test.values\n    \n    scaler = MinMaxScaler(feature_range=(0, 1))\n    train_arr = scaler.fit_transform(train)\n    test_arr = scaler.transform(test)\n\n    return train_arr, test_arr","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mode = None\n\nif mode == 'PCA':\n    targets = train_df.target.values\n    train_arr, test_arr = PCA_transform(train_df, test_df)\nelif mode == 'Quantile':\n    targets = train_df.target.values\n    train_arr, test_arr = Q_transform(train_df, test_df)\nelif mode == 'SVD':\n    targets = train_df.target.values\n    train_arr, test_arr = svd_whiten(train_df, test_df)\nelif mode == 'SCALE':\n    targets = train_df.target.values\n    train_arr, test_arr = scale_data(train_df, test_df)\nelse:\n    targets = train_df.target.values\n    train_arr = train_df.drop(columns=['target']).values\n    test_arr = test_df.values","metadata":{"execution":{"iopub.status.busy":"2021-11-12T12:58:58.865281Z","iopub.execute_input":"2021-11-12T12:58:58.865614Z","iopub.status.idle":"2021-11-12T12:59:00.302741Z","shell.execute_reply.started":"2021-11-12T12:58:58.865574Z","shell.execute_reply":"2021-11-12T12:59:00.301974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_arr.shape, test_arr.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-12T12:59:00.303871Z","iopub.execute_input":"2021-11-12T12:59:00.30414Z","iopub.status.idle":"2021-11-12T12:59:00.308885Z","shell.execute_reply.started":"2021-11-12T12:59:00.304103Z","shell.execute_reply":"2021-11-12T12:59:00.307752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_arr.max(), train_arr.min(), test_arr.max(), test_arr.min())","metadata":{"execution":{"iopub.status.busy":"2021-11-12T12:59:00.30997Z","iopub.execute_input":"2021-11-12T12:59:00.310384Z","iopub.status.idle":"2021-11-12T12:59:00.630826Z","shell.execute_reply.started":"2021-11-12T12:59:00.310347Z","shell.execute_reply":"2021-11-12T12:59:00.630063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.DataFrame(train_arr)\ntest_df = pd.DataFrame(test_arr)\nfeatures = train_df.shape[1]\nprint(f\"Num features: {train_df.shape[1]}\")","metadata":{"papermill":{"duration":0.051103,"end_time":"2021-11-02T17:36:09.049494","exception":false,"start_time":"2021-11-02T17:36:08.998391","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-12T12:59:00.632347Z","iopub.execute_input":"2021-11-12T12:59:00.632797Z","iopub.status.idle":"2021-11-12T12:59:00.643795Z","shell.execute_reply.started":"2021-11-12T12:59:00.632758Z","shell.execute_reply":"2021-11-12T12:59:00.643064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper Function","metadata":{"papermill":{"duration":0.070583,"end_time":"2021-11-02T17:36:37.322203","exception":false,"start_time":"2021-11-02T17:36:37.25162","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def plot_confusion_matrix(cm, classes):\n\n    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n    plt.title('Confusion matrix', fontweight='bold', pad=15)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=0)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], 'd'),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label', fontweight='bold')\n    plt.xlabel('Predicted label', fontweight='bold')\n    plt.tight_layout()","metadata":{"papermill":{"duration":0.08571,"end_time":"2021-11-02T17:36:37.47462","exception":false,"start_time":"2021-11-02T17:36:37.38891","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-12T12:59:00.645206Z","iopub.execute_input":"2021-11-12T12:59:00.64549Z","iopub.status.idle":"2021-11-12T12:59:00.655174Z","shell.execute_reply.started":"2021-11-12T12:59:00.645452Z","shell.execute_reply":"2021-11-12T12:59:00.654405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Keras Model\n\nModel structure was enhanced by an additional branch of CONV2D which was to extract additional features concatenated then with Enc/Dec outputs.","metadata":{"papermill":{"duration":0.150894,"end_time":"2021-11-02T17:36:37.707248","exception":false,"start_time":"2021-11-02T17:36:37.556354","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from tensorflow.keras.layers import Reshape, Conv2D, GlobalMaxPooling2D, UpSampling2D, MaxPooling2D, Flatten, AveragePooling2D\n\ndef dnn_model():\n    x_input = Input(shape=(features,))\n    \n    x1 = Dense(units=386, activation='swish')(x_input)\n    x1 = BatchNormalization()(x1)\n    x2 = Dropout(rate=0.45)(x1)\n    \n    x2 = Dense(units=192, activation='swish')(x2)\n    x2 = BatchNormalization()(x2)\n    x3 = Dropout(rate=0.35)(x2)\n    \n    x3 = Dense(units=98, activation='swish')(x3)\n    x3 = BatchNormalization()(x3)\n    x3 = Dropout(rate=0.25)(x3)\n    \n    x4 = Dense(units=192, activation='swish')(x3)\n    x4 = BatchNormalization()(x4)\n    x4 = Multiply()([x2, x4])\n    x4 = Dropout(rate=0.35)(x4)\n    \n    x5 = Dense(units=386, activation='swish')(x4)\n    x5 = BatchNormalization()(x5)\n    x5 = Multiply()([x1, x5])\n    x5 = Dropout(rate=0.45)(x5)\n    \n    x_e1 = Concatenate()([x3, x5])\n    x = Reshape((22, 22, 1))(x_e1)\n    \n    x = Conv2D(16, kernel_size=(3, 3), padding='same', activation='swish')(x)#16\n    x = AveragePooling2D((2, 2), padding='same')(x)\n    x = Conv2D(8, kernel_size=(3, 3), padding='same', activation='swish')(x)#8\n    x = AveragePooling2D((2, 2), padding='same')(x)\n    x = Conv2D(8, kernel_size=(3, 3), padding='same', activation='swish')(x)#8\n    \n    enc = AveragePooling2D((2, 2), padding='same')(x)\n    \n    flat = Flatten()(enc)\n    \n    x = Concatenate()([x_e1, flat])\n    \n    x = Dense(units=128, activation='swish')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(rate=0.25)(x)\n    \n    x_output = Dense(units=1, activation='sigmoid')(x)\n\n    model = Model(inputs=x_input, outputs=x_output, \n                  name='DNN_Model')\n    return model","metadata":{"papermill":{"duration":0.090804,"end_time":"2021-11-02T17:36:37.873038","exception":false,"start_time":"2021-11-02T17:36:37.782234","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-12T12:59:00.658102Z","iopub.execute_input":"2021-11-12T12:59:00.658444Z","iopub.status.idle":"2021-11-12T12:59:00.67468Z","shell.execute_reply.started":"2021-11-12T12:59:00.658407Z","shell.execute_reply":"2021-11-12T12:59:00.673938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = dnn_model()","metadata":{"papermill":{"duration":2.449959,"end_time":"2021-11-02T17:36:40.393963","exception":false,"start_time":"2021-11-02T17:36:37.944004","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-12T12:59:00.676095Z","iopub.execute_input":"2021-11-12T12:59:00.676597Z","iopub.status.idle":"2021-11-12T12:59:03.286854Z","shell.execute_reply.started":"2021-11-12T12:59:00.676555Z","shell.execute_reply":"2021-11-12T12:59:03.285996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\nplot_model(\n    model, \n    to_file='DNN_CNN_Model.png', \n    show_shapes=True,\n    show_layer_names=True\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-12T12:59:03.288147Z","iopub.execute_input":"2021-11-12T12:59:03.288422Z","iopub.status.idle":"2021-11-12T12:59:04.357563Z","shell.execute_reply.started":"2021-11-12T12:59:03.288387Z","shell.execute_reply":"2021-11-12T12:59:04.356802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# UMAP VIS\nSome sample visualisation by umap reduction in 3D space, found it useful to compare scaling methods.\nIf you are not familiar with umap check it out here: https://umap-learn.readthedocs.io/en/latest/basic_usage.html","metadata":{}},{"cell_type":"code","source":"import plotly\nimport plotly.graph_objs as go\nimport numpy as np\nimport random\nimport umap\n\nSAVE_FLAG = False\nfile_out = './default.html'\n\nto_vis = pd.DataFrame(train_arr)\nto_vis['label'] = targets\nto_vis = to_vis.sample(n=5000)\nlabels = to_vis.label.tolist()\n\nprint(to_vis.label.value_counts())\n\nX_emb = to_vis.drop(columns=['label'])\n\nmetric_umap = 'correlation'\nadapted_embedded = umap.UMAP(n_neighbors=25,\n                      n_components=3,\n                      min_dist=0.5,\n                      metric=metric_umap).fit_transform(X_emb)\n\nadapted_embedded = pd.DataFrame(adapted_embedded, columns=['V1', 'V2', 'V3'])\nadapted_embedded['to_view'] = ''\nadapted_embedded['labels'] = labels\nlabels_list = adapted_embedded.labels.value_counts().index.tolist()\n\n\n\ndef plot_tsne(df:pd.DataFrame, label_list, to_save = False, add_custom_legend = False, file_out = 'default.html'):\n    list_of_plots = []\n    for i, lab in enumerate(label_list):\n        adapted_embedded_f = df[df.labels == lab]\n        color = random.randint(0, 0xFFFFFF)\n        \n        x1 = adapted_embedded_f['V1'].values\n        y1 = adapted_embedded_f['V2'].values\n        z1 = adapted_embedded_f['V3'].values\n        \n\n        plot_f = go.Scatter3d(\n                x=x1,\n                y=y1,\n                z=z1,\n                hovertext = adapted_embedded_f.to_view.tolist(),\n                mode='markers',\n                marker=dict(\n                    size=4,\n                    color=color,            \n                    symbol='circle',\n                    line=dict(\n                            color=color,\n                            width=1\n                        )\n                ),\n                name=lab,\n            )\n        list_of_plots.append(plot_f)\n    \n    fig = go.Figure(data=list_of_plots)\n    \n    if add_custom_legend:\n        fig.update_layout(\n        legend=dict(\n                x=0,\n                y=1,\n                traceorder=\"reversed\",\n                title_font_family=\"Calibri\",\n                font=dict(\n                    family=\"Courier\",\n                    size=12,\n                    color=\"black\"\n                ),\n                bgcolor=\"White\",\n                bordercolor=\"Black\",\n                borderwidth=1\n                )\n            )\n        \n    plotly.offline.iplot(fig)\n    if to_save:\n        plotly.offline.plot(fig, filename=file_out)\n        \nplot_tsne(adapted_embedded, labels_list, to_save=SAVE_FLAG, file_out = file_out)","metadata":{"execution":{"iopub.status.busy":"2021-11-12T12:59:04.360095Z","iopub.execute_input":"2021-11-12T12:59:04.360419Z","iopub.status.idle":"2021-11-12T12:59:53.488985Z","shell.execute_reply.started":"2021-11-12T12:59:04.360374Z","shell.execute_reply":"2021-11-12T12:59:53.488271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training and testing\n\nClass weighting implemented mechanism is controled by CLASS_WEIGHT_FLAG, by default it's off (data is almost balanced).","metadata":{}},{"cell_type":"code","source":"FOLD = 5\nVERBOSE = 0\nSEEDS = [2021, 2025]\nBATCH_SIZE = 2048\nCLASS_WEIGHT_FLAG = False\n\ncounter = 0\noof_score = 0\ny_pred_final_dnn = np.zeros((test_df.shape[0], 1))\ny_pred_meta_dnn = np.zeros((train_df.shape[0], 1))\n\n\nfor sidx, seed in enumerate(SEEDS):\n    seed_score = 0\n    \n    kfold = StratifiedKFold(n_splits=FOLD, shuffle=True, random_state=seed)\n\n    for idx, (train, val) in enumerate(kfold.split(train_arr, targets)):\n        counter += 1\n        \n        #define train and validation data by indices\n        train_x, train_y = train_arr[train], targets[train]\n        val_x, val_y = train_arr[val], targets[val]\n        \n        #count zero and one label ratios\n        zero = np.unique(train_y, return_counts=True)[1][0]\n        one = np.unique(train_y, return_counts=True)[1][1]\n        total = len(train_y)\n\n        weight_for_0 = (1 / zero)*(total)/2.0 \n        weight_for_1 = (1 / one)*(total)/2.0\n\n        class_weight = {0: weight_for_0, 1: weight_for_1}\n\n        print('Weight for class 0: {:.2f}'.format(weight_for_0))\n        print('Weight for class 1: {:.2f}'.format(weight_for_1))\n        \n        #init and compile model\n        model = dnn_model()\n        model.compile(optimizer=Adam(learning_rate=1e-2), \n                      loss=\"binary_crossentropy\", \n                      metrics=['AUC'])\n\n        lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, \n                               patience=7, verbose=VERBOSE)\n        \n        chk_point = ModelCheckpoint(f'./Keras_DNN_Model_{counter}C.h5', \n                                    monitor='val_loss', verbose=VERBOSE, \n                                    save_best_only=True, mode='min')\n\n        es = EarlyStopping(monitor=\"val_loss\", patience=30, \n                           verbose=VERBOSE, mode=\"min\", \n                           restore_best_weights=True)\n        \n        if CLASS_WEIGHT_FLAG == False:\n            class_weight = None\n        else:\n            pass\n        \n        #train model\n        model.fit(train_x, train_y, \n                  validation_data=(val_x, val_y), \n                  epochs=900,\n                  verbose=VERBOSE,\n                  class_weight=class_weight,\n                  batch_size=BATCH_SIZE, \n                  callbacks=[lr, chk_point, es])\n        \n        #load model and perform tests\n        model = load_model(f'./Keras_DNN_Model_{counter}C.h5')\n        \n        y_pred = model.predict(val_x, batch_size=BATCH_SIZE)\n        y_pred_meta_dnn[val] += y_pred\n        y_pred_final_dnn += model.predict(test_arr, batch_size=BATCH_SIZE)\n        \n        score = roc_auc_score(val_y, y_pred)\n        oof_score += score\n        seed_score += score\n        print(\"\\nSeed-{} | Fold-{} | OOF Score: {}\\n\".format(seed, idx, score))\n        \n        del model, y_pred\n        del train_x, train_y\n        del val_x, val_y\n        gc.collect()\n    \n    print(\"\\nSeed: {} | Aggregate OOF Score: {}\\n\\n\".format(seed, (seed_score / FOLD)))\n\n\ny_pred_meta_dnn = y_pred_meta_dnn / float(len(SEEDS))\ny_pred_final_dnn = y_pred_final_dnn / float(counter)\noof_score /= float(counter)","metadata":{"papermill":{"duration":5565.435531,"end_time":"2021-11-02T19:09:25.87511","exception":false,"start_time":"2021-11-02T17:36:40.439579","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-12T12:59:53.490424Z","iopub.execute_input":"2021-11-12T12:59:53.490837Z","iopub.status.idle":"2021-11-12T14:14:32.414718Z","shell.execute_reply.started":"2021-11-12T12:59:53.490799Z","shell.execute_reply":"2021-11-12T14:14:32.41311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Aggregate OOF Score: {}\".format(oof_score))","metadata":{"execution":{"iopub.status.busy":"2021-11-12T14:14:32.417086Z","iopub.execute_input":"2021-11-12T14:14:32.417611Z","iopub.status.idle":"2021-11-12T14:14:32.422763Z","shell.execute_reply.started":"2021-11-12T14:14:32.417579Z","shell.execute_reply":"2021-11-12T14:14:32.421936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_meta = np.mean(y_pred_meta_dnn, axis=1)\ny_pred = (y_pred_meta>0.5).astype(int)\nprint(classification_report(targets, y_pred))","metadata":{"papermill":{"duration":0.924393,"end_time":"2021-11-02T19:09:26.849091","exception":false,"start_time":"2021-11-02T19:09:25.924698","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-12T14:14:32.424325Z","iopub.execute_input":"2021-11-12T14:14:32.424662Z","iopub.status.idle":"2021-11-12T14:14:33.412989Z","shell.execute_reply.started":"2021-11-12T14:14:32.424623Z","shell.execute_reply":"2021-11-12T14:14:33.411018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnf_matrix = confusion_matrix(targets, y_pred, labels=[0, 1])\nnp.set_printoptions(precision=2)\nplt.figure(figsize=(12, 5))\nplot_confusion_matrix(cnf_matrix, classes=[0, 1])","metadata":{"papermill":{"duration":1.037883,"end_time":"2021-11-02T19:09:27.937405","exception":false,"start_time":"2021-11-02T19:09:26.899522","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-12T14:14:33.414682Z","iopub.execute_input":"2021-11-12T14:14:33.414949Z","iopub.status.idle":"2021-11-12T14:14:34.615706Z","shell.execute_reply.started":"2021-11-12T14:14:33.414911Z","shell.execute_reply":"2021-11-12T14:14:34.615046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Some weighted average ensemble\n","metadata":{"papermill":{"duration":0.050559,"end_time":"2021-11-02T19:09:29.302859","exception":false,"start_time":"2021-11-02T19:09:29.2523","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def avg_results(l1, l2):\n    en_l = []\n    for i, e in enumerate(l1):\n        r = (0.3 * e) + (0.7 * l2[i])\n        en_l.append(r)\n        \n    return en_l\n\nl1 = y_pred_final_dnn.ravel()\nl2 = pd.read_csv('../input/simple-nn-with-good-results-tps-nov-21/submission.csv').target.tolist()\n\nens = avg_results(l1, l2)\n\ndf_vis = pd.DataFrame()\ndf_vis['model1'] = l1\ndf_vis['model2'] = l2\ndf_vis['model_ens'] = ens","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#DNN/CNN model prob dist\ndf_vis.model1.hist(bins=1000)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Simple NN model prob dist\ndf_vis.model2.hist(bins=1000)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Ens model prob dist\ndf_vis.model_ens.hist(bins=1000)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Submission","metadata":{}},{"cell_type":"code","source":"submit_df = pd.read_csv(\"../input/tabular-playground-series-nov-2021/sample_submission.csv\")\nsubmit_df['target'] = ens\nsubmit_df.to_csv(\"submission.csv\", index=False)\nsubmit_df.head()","metadata":{"papermill":{"duration":1.874193,"end_time":"2021-11-02T19:09:31.22794","exception":false,"start_time":"2021-11-02T19:09:29.353747","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-12T14:14:34.616963Z","iopub.execute_input":"2021-11-12T14:14:34.617712Z","iopub.status.idle":"2021-11-12T14:14:36.496031Z","shell.execute_reply.started":"2021-11-12T14:14:34.617672Z","shell.execute_reply":"2021-11-12T14:14:36.49514Z"},"trusted":true},"execution_count":null,"outputs":[]}]}