{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-17T02:13:30.353592Z","iopub.execute_input":"2021-11-17T02:13:30.353889Z","iopub.status.idle":"2021-11-17T02:13:30.36597Z","shell.execute_reply.started":"2021-11-17T02:13:30.353857Z","shell.execute_reply":"2021-11-17T02:13:30.364992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime\nimport numpy as np\nimport pandas as pd\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.utils import shuffle\n\nimport optuna\nimport seaborn as sns\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import StratifiedKFold\n\nimport gc","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:13:30.367719Z","iopub.execute_input":"2021-11-17T02:13:30.368253Z","iopub.status.idle":"2021-11-17T02:13:30.375474Z","shell.execute_reply.started":"2021-11-17T02:13:30.368211Z","shell.execute_reply":"2021-11-17T02:13:30.374586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datenow = datetime.now().strftime('%d%m%Y_%H%M%S')  # will be appended to oof and submission files\nmodelname = 'catboost'                               # will be appended to oof and submission files\n\nseed = 42 \nn_folds = 5 # or 10\n\nearly_stopping_rounds = 50 # early stopping rounds for Xgboost\n\nrun_optuna_hyperparam_search = False  # Switch for optuna hyper param tuning","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:13:30.377633Z","iopub.execute_input":"2021-11-17T02:13:30.378393Z","iopub.status.idle":"2021-11-17T02:13:30.390362Z","shell.execute_reply.started":"2021-11-17T02:13:30.378354Z","shell.execute_reply":"2021-11-17T02:13:30.389636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not run_optuna_hyperparam_search:  \n    \n    #if not running optuna (i.e run_optuna_hyperparam_search is False) use these parameters for xgboost else best param \n    # from Optuna will be picked up\n    params = {'iterations': 17298,\n               'learning_rate': 0.03429054860458741,\n               'reg_lambda': 0.3242286463210283,\n               'subsample': 0.9433911589913944,\n               'random_strength': 22.4849972385133,\n               'depth': 8,\n               'min_data_in_leaf': 4,\n               'leaf_estimation_iterations': 8,\n               'task_type':\"GPU\",\n               'bootstrap_type':'Poisson',\n               'verbose' : 500,\n               'early_stopping_rounds' : 200,\n               'eval_metric' : 'AUC'}\n    \nelse:  #will run optuna first and pick best parameter and run xgboost\n    \n    n_folds_for_optuna = 1  # how many folds to be considered for optuna hyper parameter tuning.\n    n_trials = 3            # how many optuna trials (change it to 50-100-200 depending on number of estimators you choose in objective(trial) function below)\n        \n    \n    def objective(trial):\n    # Even if some parameter is constant e.g n_estimators, mention it as trial.suggest_categorical like done below.This notebook picks best_params\n    # from trial and runs Xgboost. Hence if 'n_estimators' is mentioned as 'n_estimators': 4000 instead of 'n_estimators':trial.suggest_categorical('n_estimators',[4000])\n    # then it will have to be defined explicitly in the xgboost initialization in the last cell of this notebook\n    \n        params  = {\n            'iterations': trial.suggest_int('iterations',250,300),\n          'n_estimators': trial.suggest_categorical('n_estimators',[4000]), \n          'learning_rate': trial.suggest_float('learning_rate',1e-3,5e-1,log=True),\n          'max_depth': trial.suggest_int('max_depth',3,12),\n          #'colsample_bytree': trial.suggest_float('colsample_bytree',0.2,0.99,log=True),\n          'subsample': trial.suggest_float('subsample',0.2,0.99,log=True),\n          'eval_metric': trial.suggest_categorical('eval_metric',['auc']),\n          #'use_label_encoder':trial.suggest_categorical('use_label_encoder',[False]),\n          #'gamma': trial.suggest_categorical('gamma',[0, 0.25, 0.5, 1.0]),\n          'reg_lambda': trial.suggest_categorical('reg_lambda',[0.1, 1.0, 5.0, 10.0, 50.0, 100.0]),\n          #'tree_method': trial.suggest_categorical('tree_method',['gpu_hist']),\n          #'gpu_id': trial.suggest_categorical('gpu_id',[0]),\n          #'predictor' : trial.suggest_categorical('predictor',['gpu_predictor']),\n          'random_state': trial.suggest_categorical('random_state',[seed])\n         }  \n        model = CatBoostClassifier(**params)\n\n        auc = fit_n_folds(model,n=n_folds_for_optuna,optimize=True)\n\n        return auc","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:13:30.395585Z","iopub.execute_input":"2021-11-17T02:13:30.396662Z","iopub.status.idle":"2021-11-17T02:13:30.423337Z","shell.execute_reply.started":"2021-11-17T02:13:30.39662Z","shell.execute_reply":"2021-11-17T02:13:30.422118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# load data","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/tabular-playground-series-nov-2021/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:13:30.426118Z","iopub.execute_input":"2021-11-17T02:13:30.428503Z","iopub.status.idle":"2021-11-17T02:13:39.974233Z","shell.execute_reply.started":"2021-11-17T02:13:30.426447Z","shell.execute_reply":"2021-11-17T02:13:39.97334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = [col for col in train_df.columns if col.startswith('f')]\ntarget = ['target']","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:13:39.977675Z","iopub.execute_input":"2021-11-17T02:13:39.977893Z","iopub.status.idle":"2021-11-17T02:13:39.983792Z","shell.execute_reply.started":"2021-11-17T02:13:39.977866Z","shell.execute_reply":"2021-11-17T02:13:39.983083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_n_splits(n=10):\n    \n    # Get Folds\n    skf = StratifiedKFold(n_splits=n,random_state=42,shuffle=True)\n    skf.get_n_splits(train_df[features],train_df[target])\n    for idx,(train_index,val_index) in enumerate(skf.split(train_df[features],train_df[target])):\n        train_df.loc[val_index ,'Fold'] = idx\n    \n    # Check Folds\n    for i in range(n):\n        print(f'*****Fold {i}*****')\n        print(train_df[train_df['Fold'] == i][target].value_counts(normalize=True))\n        print(f'******************')\n        \n    # Save Folds\n    train_df.to_csv(f'Stratified{n}Fold_NOV2021_TPS.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:13:39.985997Z","iopub.execute_input":"2021-11-17T02:13:39.986341Z","iopub.status.idle":"2021-11-17T02:13:39.995363Z","shell.execute_reply.started":"2021-11-17T02:13:39.986304Z","shell.execute_reply":"2021-11-17T02:13:39.994678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generate_n_splits(n=5)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:13:39.996572Z","iopub.execute_input":"2021-11-17T02:13:39.997336Z","iopub.status.idle":"2021-11-17T02:14:49.450231Z","shell.execute_reply.started":"2021-11-17T02:13:39.997297Z","shell.execute_reply":"2021-11-17T02:14:49.449311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_l = pd.read_csv(f'./Stratified5Fold_NOV2021_TPS.csv',index_col='id')\ntest_df_l = pd.read_csv('../input/tabular-playground-series-nov-2021/test.csv',index_col='id')\nsubmission_df = pd.read_csv('../input/tabular-playground-series-nov-2021/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:14:49.451513Z","iopub.execute_input":"2021-11-17T02:14:49.451937Z","iopub.status.idle":"2021-11-17T02:15:07.228863Z","shell.execute_reply.started":"2021-11-17T02:14:49.451898Z","shell.execute_reply":"2021-11-17T02:15:07.22811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_l.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:15:07.230093Z","iopub.execute_input":"2021-11-17T02:15:07.230351Z","iopub.status.idle":"2021-11-17T02:15:07.248304Z","shell.execute_reply.started":"2021-11-17T02:15:07.230317Z","shell.execute_reply":"2021-11-17T02:15:07.247433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = [col for col in train_df_l.columns if col.startswith('f')]\ntarget = ['target']","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:15:07.249553Z","iopub.execute_input":"2021-11-17T02:15:07.249845Z","iopub.status.idle":"2021-11-17T02:15:07.257864Z","shell.execute_reply.started":"2021-11-17T02:15:07.249808Z","shell.execute_reply":"2021-11-17T02:15:07.257106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sources: \n# https://www.kaggle.com/dmitryuarov/tps-soft-voting-xgb-cb-lgbm#Basic-information\n# https://www.kaggle.com/rinnqd/reduce-memory-usage\n# https://www.kaggle.com/heiswicked/smtm-s-tps-sep-catboost\n\ndef reduce_size(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n\n    print(f\"After Reduction : {round(end_mem, 2)}MB\")\n    print(f\"Reduced: {round(100*(start_mem - end_mem)/(start_mem), 2)}%\")\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:15:07.259274Z","iopub.execute_input":"2021-11-17T02:15:07.259867Z","iopub.status.idle":"2021-11-17T02:15:07.276888Z","shell.execute_reply.started":"2021-11-17T02:15:07.259826Z","shell.execute_reply":"2021-11-17T02:15:07.27602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = reduce_size(train_df_l)\ntest_df = reduce_size(test_df_l)\n\ndel train_df_l\ndel test_df_l\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:15:07.278247Z","iopub.execute_input":"2021-11-17T02:15:07.279189Z","iopub.status.idle":"2021-11-17T02:15:21.70022Z","shell.execute_reply.started":"2021-11-17T02:15:07.279151Z","shell.execute_reply":"2021-11-17T02:15:21.699432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper Methods","metadata":{}},{"cell_type":"code","source":"def get_nth_fold(n=0):\n    train_idx = (train_df['Fold'] != n)\n    val_idx = (train_df['Fold'] == n)\n    \n    return train_df.loc[train_idx][features],train_df.loc[train_idx][target],train_df.loc[val_idx][features],train_df.loc[val_idx][target]","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:15:21.702684Z","iopub.execute_input":"2021-11-17T02:15:21.704221Z","iopub.status.idle":"2021-11-17T02:15:21.709436Z","shell.execute_reply.started":"2021-11-17T02:15:21.70418Z","shell.execute_reply":"2021-11-17T02:15:21.708451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit_n_folds(model,n=10,optimize=False):\n    \n    val_auc_scores = []\n    test_preds = []\n    final_valid_predictions = {}\n    for i in range(n): \n        \n        if not optimize:\n            print(f'** Processing Fold {i} ***')\n        \n        train_auc_score = 0\n        val_auc_score = 0\n        \n        X_train,y_train,X_val,y_val = get_nth_fold(n=i)\n        \n        \n        \n        model.fit(X_train,y_train.values.ravel(), eval_set=[(X_val, y_val.values.ravel())],early_stopping_rounds=early_stopping_rounds,verbose=False)\n        y_pred = model.predict_proba(X_train)[:,1]\n        train_auc_score = roc_auc_score(y_train.values.ravel(),y_pred)\n        \n        y_val_pred = model.predict_proba(X_val)[:,1]\n        \n        valid_index = y_val.index.values\n        final_valid_predictions.update(dict(zip(valid_index,y_val_pred)))\n\n        val_auc_score = roc_auc_score(y_val.values.ravel(),y_val_pred)\n        val_auc_scores.append(val_auc_score)\n        \n        \n        if not optimize:\n            test_pred = model.predict_proba(test_df[features])[:,1]\n            test_preds.append(test_pred)\n            print(f'Fold {i} Train AUC - {train_auc_score},Val AUC - {val_auc_score}')\n        \n        del X_train\n        del y_train\n        del X_val\n        del y_val\n        gc.collect()\n        \n    \n    if optimize:\n        return np.mean(val_auc_scores)\n    else: \n        final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions,orient='index').reset_index()\n        final_valid_predictions.to_csv(f'oof_{modelname}_{datenow}.csv',index=0)  # Save OOF File.\n        del final_valid_predictions\n        _ = gc.collect()\n        print(f'Average Val AUC across folds - {np.mean(val_auc_scores)} std - {np.std(val_auc_scores)}')\n        return test_preds","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:16:23.907265Z","iopub.execute_input":"2021-11-17T02:16:23.907788Z","iopub.status.idle":"2021-11-17T02:16:23.91901Z","shell.execute_reply.started":"2021-11-17T02:16:23.907753Z","shell.execute_reply":"2021-11-17T02:16:23.918125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if run_optuna_hyperparam_search: \n    \n    study = optuna.create_study(direction='maximize')\n    study.optimize(objective,n_trials=n_trials)\n    print('**BEST TRIAL**')\n    print(study.best_trial)\n    \n    params = study.best_trial.params # pick the best param from optuna and assign to params. \n                                     # This will be used in next cell for xgb.","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:15:21.728008Z","iopub.execute_input":"2021-11-17T02:15:21.728335Z","iopub.status.idle":"2021-11-17T02:15:21.740156Z","shell.execute_reply.started":"2021-11-17T02:15:21.728286Z","shell.execute_reply":"2021-11-17T02:15:21.739269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = CatBoostClassifier(**params)\n\npreds = fit_n_folds(model,n=n_folds,optimize=False)\nsubmission_df.iloc[:,1:] = np.mean(np.stack(preds,axis=0),axis=0)\nsubmission_df.to_csv(f'submission_{modelname}_{datenow}.csv',index=0)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T02:16:37.271275Z","iopub.execute_input":"2021-11-17T02:16:37.27205Z","iopub.status.idle":"2021-11-17T02:27:56.632145Z","shell.execute_reply.started":"2021-11-17T02:16:37.272012Z","shell.execute_reply":"2021-11-17T02:27:56.631398Z"},"trusted":true},"execution_count":null,"outputs":[]}]}