{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Version\n\n- V7:\n    - load the last checkpoint with the best model\n    - Learning Rate Scheduler (CosineAnnealingLR)\n- V6:\n    - es_patience=20\n    - lr_patience=7\n    - epochs=125\n- V5:\n    - kaiming_uniform_ weights initializer\n    - One extra Dense layer\n- V4: \n    - Add Early Stopping: patience=5, \n    - Learning Rate Scheduler (ReduceLROnPlateau): patience=3\n    - Adam optimizer: learning_rate=0.01\n- V3: Swish activation\n- V2: \n    - Epochs=30\n    - n_folds=10\n- V1: \n    - SGD optimizer\n    - ReLU activation\n    - Epochs=5\n    - n_folds=5\n    - Model: 3 Linear layers (128-64-1)\n\n# References\n\n- https://www.kaggle.com/mmellinger66/tps-nov-21-keras-tuner\n- https://www.kaggle.com/lucamassaron/feature-selection-by-boruta-shap\n- https://www.kaggle.com/hiro5299834/tps-nov-2021-pytorch-lightning\n- https://www.kaggle.com/yasufuminakama/ventilator-pressure-lstm-starter","metadata":{}},{"cell_type":"code","source":"# ! pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2021-11-12T04:16:56.078568Z","iopub.execute_input":"2021-11-12T04:16:56.07912Z","iopub.status.idle":"2021-11-12T04:16:56.084292Z","shell.execute_reply.started":"2021-11-12T04:16:56.079029Z","shell.execute_reply":"2021-11-12T04:16:56.083215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport time\nimport math\n\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\n\nimport random\nimport feather\n\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold,StratifiedKFold, GroupKFold\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport torch\nfrom torch import nn\nimport torch.optim as optim\nfrom torch.utils import data\nimport torch.nn.functional as F\n# from torchsummary import summary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-12T04:16:56.085837Z","iopub.execute_input":"2021-11-12T04:16:56.086566Z","iopub.status.idle":"2021-11-12T04:16:56.890307Z","shell.execute_reply.started":"2021-11-12T04:16:56.086526Z","shell.execute_reply":"2021-11-12T04:16:56.889569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    competition = \"TPS_202111\"\n    seed = 42\n    n_folds = 10\n    batch_size = 1024\n    epochs = 125\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    es_patience = 20\n    lr_patience = 7\n    lr = 0.01","metadata":{"execution":{"iopub.status.busy":"2021-11-12T04:16:56.892541Z","iopub.execute_input":"2021-11-12T04:16:56.892814Z","iopub.status.idle":"2021-11-12T04:16:56.916479Z","shell.execute_reply.started":"2021-11-12T04:16:56.892772Z","shell.execute_reply":"2021-11-12T04:16:56.915795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this func follows pytorch lightning's seed_everythin --> https://pytorch-lightning.readthedocs.io/en/latest/_modules/pytorch_lightning/utilities/seed.html#seed_everything\ndef seed_everything(seed=Config.seed):\n    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)","metadata":{"execution":{"iopub.status.busy":"2021-11-12T04:16:56.91787Z","iopub.execute_input":"2021-11-12T04:16:56.918351Z","iopub.status.idle":"2021-11-12T04:16:56.933963Z","shell.execute_reply.started":"2021-11-12T04:16:56.918314Z","shell.execute_reply":"2021-11-12T04:16:56.933091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = Path('../input/tabular-playground-series-nov-2021')","metadata":{"execution":{"iopub.status.busy":"2021-11-12T04:16:56.93725Z","iopub.execute_input":"2021-11-12T04:16:56.93746Z","iopub.status.idle":"2021-11-12T04:16:56.945334Z","shell.execute_reply.started":"2021-11-12T04:16:56.937435Z","shell.execute_reply":"2021-11-12T04:16:56.944568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# train_df = pd.read_csv(data_dir / \"train.csv\", \n# #                        nrows=10000\n#                       )\n# test_df = pd.read_csv(data_dir / \"test.csv\",\n# #                      nrows=1000\n#                      )\n\n# Loading files in feather format\ntrain_df = feather.read_dataframe('../input/tpsnov21/train.feather')\ntest_df = feather.read_dataframe('../input/tpsnov21/test.feather')\nsample_submission = pd.read_csv(data_dir / \"sample_submission.csv\")\n\nprint(f\"train data: Rows={train_df.shape[0]}, Columns={train_df.shape[1]}\")\nprint(f\"test data : Rows={test_df.shape[0]}, Columns={test_df.shape[1]}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-12T04:16:56.947042Z","iopub.execute_input":"2021-11-12T04:16:56.947634Z","iopub.status.idle":"2021-11-12T04:16:57.876956Z","shell.execute_reply.started":"2021-11-12T04:16:56.947597Z","shell.execute_reply":"2021-11-12T04:16:57.876142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# features = [col for col in train_df.columns if col not in ('id', 'target')]\nfeatures = ['f1', 'f10', 'f11', 'f14', 'f15', 'f16', 'f17', 'f2', 'f20', 'f21', 'f22', 'f24', 'f25', 'f26', 'f27', 'f28', 'f3', 'f30', 'f31', 'f32', 'f33', 'f34', 'f36', 'f37', 'f4', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f5', 'f50', 'f51', 'f53', 'f54', 'f55', 'f57', 'f58', 'f59', 'f60', 'f61', 'f62', 'f64', 'f66', 'f67', 'f70', 'f71', 'f76', 'f77', 'f8', 'f80', 'f81', 'f82', 'f83', 'f87', 'f89', 'f9', 'f90', 'f91', 'f93', 'f94', 'f95', 'f96', 'f97', 'f98']","metadata":{"execution":{"iopub.status.busy":"2021-11-12T04:16:57.878232Z","iopub.execute_input":"2021-11-12T04:16:57.878709Z","iopub.status.idle":"2021-11-12T04:16:57.886587Z","shell.execute_reply.started":"2021-11-12T04:16:57.878666Z","shell.execute_reply":"2021-11-12T04:16:57.885859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TPSDataset(data.Dataset):\n    def __init__(self, X, y=None):\n        super(TPSDataset).__init__()\n        self.X = X\n        self.y = y\n        \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, idx):\n        if self.y is not None:\n            return {\n                'X' : torch.tensor(self.X.values[idx], dtype=torch.float),\n                'y' : torch.tensor(self.y.values[idx], dtype=torch.float)\n            }\n        else:\n            return {\n                'X' : torch.tensor(self.X.values[idx], dtype=torch.float),\n            }\n","metadata":{"execution":{"iopub.status.busy":"2021-11-12T04:16:57.887984Z","iopub.execute_input":"2021-11-12T04:16:57.88859Z","iopub.status.idle":"2021-11-12T04:16:57.89694Z","shell.execute_reply.started":"2021-11-12T04:16:57.888551Z","shell.execute_reply":"2021-11-12T04:16:57.896231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()\n\ntrain_df[features] = scaler.fit_transform(train_df[features])\ntest_df[features] = scaler.transform(test_df[features])","metadata":{"execution":{"iopub.status.busy":"2021-11-12T04:16:57.900184Z","iopub.execute_input":"2021-11-12T04:16:57.900547Z","iopub.status.idle":"2021-11-12T04:16:59.338389Z","shell.execute_reply.started":"2021-11-12T04:16:57.900512Z","shell.execute_reply":"2021-11-12T04:16:59.337574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = train_df.target\n\nX_test = test_df.drop(columns=[\"id\"], axis=1)\nX_train = train_df.drop(columns=[\"id\", \"target\"], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-12T04:16:59.339664Z","iopub.execute_input":"2021-11-12T04:16:59.340172Z","iopub.status.idle":"2021-11-12T04:16:59.614068Z","shell.execute_reply.started":"2021-11-12T04:16:59.340133Z","shell.execute_reply":"2021-11-12T04:16:59.613157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove the unimportant features\nX_train = X_train[features]\nX_test = X_test[features]","metadata":{"execution":{"iopub.status.busy":"2021-11-12T04:16:59.615395Z","iopub.execute_input":"2021-11-12T04:16:59.615732Z","iopub.status.idle":"2021-11-12T04:16:59.811034Z","shell.execute_reply.started":"2021-11-12T04:16:59.615692Z","shell.execute_reply":"2021-11-12T04:16:59.810125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = TPSDataset(X_train, y_train)\ntest_dataset = TPSDataset(X_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-12T04:16:59.812498Z","iopub.execute_input":"2021-11-12T04:16:59.812812Z","iopub.status.idle":"2021-11-12T04:16:59.820516Z","shell.execute_reply.started":"2021-11-12T04:16:59.81277Z","shell.execute_reply":"2021-11-12T04:16:59.819715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loader = data.DataLoader(test_dataset, batch_size = 1024)","metadata":{"execution":{"iopub.status.busy":"2021-11-12T04:16:59.822039Z","iopub.execute_input":"2021-11-12T04:16:59.822406Z","iopub.status.idle":"2021-11-12T04:16:59.830219Z","shell.execute_reply.started":"2021-11-12T04:16:59.822369Z","shell.execute_reply":"2021-11-12T04:16:59.829307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## PyTorch Model","metadata":{}},{"cell_type":"code","source":"def initialize_weights(model):\n    if isinstance(model, nn.Linear):\n#         nn.init.normal_(model.weight.data)\n#         nn.init.xavier_uniform_(model.weight.data)\n        nn.init.kaiming_uniform_(model.weight.data, nonlinearity=\"relu\")\n        nn.init.constant_(model.bias.data, 0)\n    elif isinstance(model, nn.Conv2d):\n        nn.init.kaiming_uniform_(model.weight.data, nonlinearity=\"relu\")\n        if model.bias is not None:\n            nn.init.constant_(model.bias.data, 0)","metadata":{"execution":{"iopub.status.busy":"2021-11-12T04:16:59.831812Z","iopub.execute_input":"2021-11-12T04:16:59.832133Z","iopub.status.idle":"2021-11-12T04:16:59.840711Z","shell.execute_reply.started":"2021-11-12T04:16:59.832096Z","shell.execute_reply":"2021-11-12T04:16:59.839933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, in_features, activation=F.relu):\n        super(Model, self).__init__()\n        self.fc1 = nn.Linear(in_features, 128)\n        self.bn1 = nn.BatchNorm1d(128)\n        self.fc2 = nn.Linear(128, 64)\n        self.bn2 = nn.BatchNorm1d(64)\n        self.fc3 = nn.Linear(64, 32)\n        self.bn3 = nn.BatchNorm1d(32)\n        self.fc4 = nn.Linear(32, 1)\n        self.flatten = nn.Flatten()\n        self.activation = activation\n\n    def forward(self, x):\n        x = self.flatten(x)\n        x = self.bn1(self.activation(self.fc1(x)))\n        x = self.bn2(self.activation(self.fc2(x)))\n        x = self.bn3(self.activation(self.fc3(x)))\n        x = torch.sigmoid(self.fc4(x))\n        \n        return torch.squeeze(x, dim=1)        ","metadata":{"execution":{"iopub.status.busy":"2021-11-12T04:16:59.842644Z","iopub.execute_input":"2021-11-12T04:16:59.843293Z","iopub.status.idle":"2021-11-12T04:16:59.855517Z","shell.execute_reply.started":"2021-11-12T04:16:59.843267Z","shell.execute_reply":"2021-11-12T04:16:59.854737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EarlyStopping:\n    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n\n    def __init__(\n        self, patience=7, verbose=False, delta=0, path=\"checkpoint.pt\", trace_func=print\n    ):\n        \"\"\"\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement.\n                            Default: False\n            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n                            Default: 0\n            trace_func (function): trace print function.\n                            Default: print\n        \"\"\"\n        self.patience = patience\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.val_loss_min = np.Inf\n        self.delta = delta\n        self.path = path\n        self.trace_func = trace_func\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_loss, model)\n        elif score < self.best_score + self.delta:\n            self.counter += 1\n            self.trace_func(\n                f\"EarlyStopping counter: {self.counter}/{self.patience}\"\n            )\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.counter = 0\n            self.save_checkpoint(val_loss, model)\n\n    def save_checkpoint(self, val_loss, model):\n        \"\"\"Saves model when validation loss decrease.\"\"\"\n        checkpoint = {\"config\": Config, \"model_state_dict\": model.state_dict()}\n\n        if self.verbose:\n            self.trace_func(\n                f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n            )\n        torch.save(model.state_dict(), self.path)\n        self.val_loss_min = val_loss","metadata":{"execution":{"iopub.status.busy":"2021-11-12T04:16:59.857017Z","iopub.execute_input":"2021-11-12T04:16:59.857334Z","iopub.status.idle":"2021-11-12T04:16:59.870241Z","shell.execute_reply.started":"2021-11-12T04:16:59.8573Z","shell.execute_reply":"2021-11-12T04:16:59.869548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model(in_features=len(features), activation=F.hardswish).to(Config.device)\nmodel.apply(initialize_weights)\n\nnum_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"Number of parameters: {num_params}\")\n\n# summary(model, (len(features)), batch_size=-1, device=\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2021-11-12T04:16:59.871357Z","iopub.execute_input":"2021-11-12T04:16:59.871772Z","iopub.status.idle":"2021-11-12T04:17:01.603372Z","shell.execute_reply.started":"2021-11-12T04:16:59.871732Z","shell.execute_reply":"2021-11-12T04:17:01.601314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training with Cross Validation","metadata":{}},{"cell_type":"code","source":"%%time\nseed_everything()\n\nfinal_test_predictions = []\nfinal_valid_predictions = {}\nscores = []\nhistories = []\n\nkf = StratifiedKFold(n_splits=Config.n_folds, random_state=Config.seed, shuffle=True)\n\nfor fold, (train_idx, valid_idx) in enumerate(kf.split(X = X_train, y = y_train)):\n    print(10*\"=\", f\"Fold={fold+1}/{Config.n_folds}\", 10*\"=\")\n    start_time = time.time()\n\n    train_subset = data.Subset(train_dataset, train_idx)\n    valid_subset = data.Subset(train_dataset, valid_idx)\n    train_loader = data.DataLoader(train_subset, batch_size = Config.batch_size, shuffle=True)\n    valid_loader = data.DataLoader(valid_subset, batch_size = Config.batch_size)\n        \n    model = Model(in_features=len(features), activation=F.hardswish).to(Config.device)\n    model.apply(initialize_weights)\n    criterion = nn.BCELoss()\n#     optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n    optimizer = optim.Adam(model.parameters(), Config.lr)\n    \n    # initialize the early_stopping object\n    early_stopping = EarlyStopping(\n        patience=Config.es_patience, verbose=True, path=f\"./model_checkpoint_{fold}.pt\"\n    )   \n    \n    # initialize the learning rate scheduler\n#     lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n#         optimizer, patience=Config.lr_patience, verbose=True\n#     )\n    Q = math.floor(len(train_idx)/Config.batch_size)\n    lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n        optimizer, T_max=Q, verbose=True\n    )\n    \n    val_loss = []\n    for epoch in range(Config.epochs):\n        epoch_loss = 0.0\n        for idx, batch in enumerate(train_loader):\n            X, y = batch[\"X\"].to(Config.device), batch[\"y\"].to(Config.device)\n\n            # zero the parameter gradients\n            optimizer.zero_grad()\n\n            pred = model(X)            \n            loss = criterion(pred, y)\n#             score = roc_auc_score(y, pred.detach()\n\n            loss.backward()\n            optimizer.step()\n            \n            epoch_loss += loss.item()\n\n        # print statistics\n        print('Epoch %d/%d -> loss: %.4f' % (epoch + 1, Config.epochs, epoch_loss))\n                \n        model.eval()\n        running_val_loss = 0.0\n        for idx, batch in enumerate(valid_loader):\n            with torch.no_grad():\n                X, y = batch[\"X\"].to(Config.device), batch[\"y\"].to(Config.device)\n                val_pred = model(X)\n                loss = criterion(val_pred, y)\n                running_val_loss += loss.item()\n                \n                \n        # early_stopping needs the validation loss to check if it has decreased,\n        # and if it has, it will make a checkpoint of the current model\n        early_stopping(running_val_loss, model)\n\n        if early_stopping.early_stop:\n            print(\"Early stopping...\")\n            break\n            \n#         print(f\"running val loss: {running_val_loss}\")\n#         lr_scheduler.step(running_val_loss) # use with ReduceLROnPlateau scheduler\n        lr_scheduler.step() # use with CosineAnnealingLR scheduler\n\n    # load the last checkpoint with the best model\n    model.load_state_dict(torch.load(f\"./model_checkpoint_{fold}.pt\"))\n    \n    # Predictions for OOF\n    print(\"--- Predicting OOF ---\")\n    valid_preds = []\n    scores = []\n    model.eval()\n    for idx, batch in enumerate(valid_loader):\n        with torch.no_grad():\n            X, y = batch[\"X\"].to(Config.device), batch[\"y\"].to(Config.device)\n            pred = model(X)\n            auc = roc_auc_score(y.cpu().numpy(), pred.detach().cpu().numpy())\n            valid_preds.extend(pred.detach().cpu().numpy()) \n            scores.append(auc)\n\n\n    final_valid_predictions.update(dict(zip(valid_idx, valid_preds)))\n    \n#     auc = roc_auc_score(y_valid,  valid_preds)\n#     scores.append(auc)\n    \n    # Predictions for Test Data\n    print(\"--- Predicting Test Data ---\")\n    test_preds = []\n    model.eval()\n    for idx, batch in enumerate(test_loader):\n        with torch.no_grad():\n            X = batch[\"X\"].to(Config.device)\n            pred = model(X)\n            test_preds.extend(pred.detach().cpu().numpy()) \n\n    final_test_predictions.append(test_preds)\n    \n    run_time = time.time() - start_time\n    print(f\"Fold={fold+1}, auc: {auc:.8f}, Run Time: {run_time:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-12T04:17:01.605003Z","iopub.execute_input":"2021-11-12T04:17:01.605505Z","iopub.status.idle":"2021-11-12T04:18:36.921164Z","shell.execute_reply.started":"2021-11-12T04:17:01.605456Z","shell.execute_reply":"2021-11-12T04:18:36.919569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Scores -> corrected: {np.mean(scores)-np.std(scores):.8f}, mean: {np.mean(scores):.8f}, std: {np.std(scores):.8f}\")","metadata":{"execution":{"iopub.status.busy":"2021-11-12T04:18:36.922636Z","iopub.execute_input":"2021-11-12T04:18:36.922891Z","iopub.status.idle":"2021-11-12T04:18:36.928333Z","shell.execute_reply.started":"2021-11-12T04:18:36.922857Z","shell.execute_reply":"2021-11-12T04:18:36.927343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission['target'] = np.mean(np.column_stack(final_test_predictions), axis=1)\nsample_submission.to_csv(\"test_pred_2.csv\",index=None)\nsample_submission.to_csv(\"submission.csv\",index=None)\nsample_submission","metadata":{"execution":{"iopub.status.busy":"2021-11-12T04:18:36.929736Z","iopub.execute_input":"2021-11-12T04:18:36.930506Z","iopub.status.idle":"2021-11-12T04:18:39.893684Z","shell.execute_reply.started":"2021-11-12T04:18:36.930467Z","shell.execute_reply":"2021-11-12T04:18:39.892928Z"},"trusted":true},"execution_count":null,"outputs":[]}]}