{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"I thought in this competition train and test data would be disributed identically, but I decided to test it anyway.\nTo my surprize, simple adversarial validation (see below) produced AUC of 0.853, and more advanced neural network model achieved AUC of 0.919!\nNext question is - how to reflect this information in modeling.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nimport lightgbm as lgb\n\n\n# read data\ntrain = pd.read_csv('/kaggle/input/tabular-playground-series-nov-2021/train.csv')\ntest  = pd.read_csv('/kaggle/input/tabular-playground-series-nov-2021/test.csv')\ntrain['target'] = 1\ntest['target'] = 0\ntrain = train.append(test).reset_index(drop=True)\n\n\n# prep data\ny  = np.array(train['target']).astype(np.float32)\ncols = train.drop(['id','target'], axis=1).columns\nx = np.array(train[cols]).astype(np.float32)\n\n\n# folds\nNF = 2\nfi = np.zeros(x.shape[1])\nparams = {'seed': 13, 'objective': 'binary', 'verbose': -1, 'num_leaves': 127}\nkf = StratifiedKFold(n_splits=NF, shuffle=True, random_state=13)\noof_pred  = np.zeros(x.shape[0], dtype=np.float32)\nfor fold, (train_idx, valid_idx) in enumerate(kf.split(x, y)):\n    x_train, x_valid = x[train_idx], x[valid_idx]\n    y_train, y_valid = y[train_idx], y[valid_idx]\n    lgb_train = lgb.Dataset(x_train, y_train)\n    lgb_valid = lgb.Dataset(x_valid, y_valid)\n    model = lgb.train(params, lgb_train, 200, valid_sets=[lgb_train, lgb_valid], early_stopping_rounds=100, verbose_eval=100)\n    fi += model.feature_importance(importance_type='gain', iteration=model.best_iteration)\n    oof_pred[valid_idx] = model.predict(x_valid).ravel()\n    CV = roc_auc_score(y_valid, oof_pred[valid_idx])\n    print('fold', fold, 'AUC', np.round(CV,3))\nCV = roc_auc_score(y, oof_pred)\nprint('AUC', np.round(CV,3))\nfi = fi / fi.sum()\nfeature_imp = pd.DataFrame(zip(fi, list(cols)), columns=['Value','Feature'])\nfeature_imp = feature_imp.sort_values(by='Value').reset_index(drop=True)\nfeature_imp['Value'] = np.round(feature_imp['Value'], 4)\nprint(feature_imp)","metadata":{"execution":{"iopub.status.busy":"2021-11-06T12:49:45.690754Z","iopub.execute_input":"2021-11-06T12:49:45.691127Z","iopub.status.idle":"2021-11-06T12:53:25.8355Z","shell.execute_reply.started":"2021-11-06T12:49:45.691049Z","shell.execute_reply":"2021-11-06T12:53:25.834267Z"},"trusted":true},"execution_count":null,"outputs":[]}]}