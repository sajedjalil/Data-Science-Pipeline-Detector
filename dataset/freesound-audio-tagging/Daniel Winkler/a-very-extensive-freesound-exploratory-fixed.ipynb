{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"cell_type":"markdown","source":"# Fork of Lathwal's notebook \"A Very Extensive Freesound Exploratory Analysis\"\nhttps://www.kaggle.com/codename007/a-very-extensive-freesound-exploratory-analysis/notebook\n\nThis fork fixes the pandas indexing, which is wrong in the referenced notebook.\n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline \n\nimport IPython.display as ipd  # To play sound in the notebook\nfrom tqdm import tqdm_notebook\nimport wave\nfrom scipy.io import wavfile\nSAMPLE_RATE = 44100\n\nimport seaborn as sns # for making plots with seaborn\ncolor = sns.color_palette()\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.offline as offline\noffline.init_notebook_mode()\nimport plotly.tools as tls\n# Math\nimport numpy as np\nfrom scipy.fftpack import fft\nfrom scipy import signal\nfrom scipy.io import wavfile\nimport librosa","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d076fa89-24f4-4759-bacf-a4307dcbe335","_uuid":"88bd76ba9e930d1ad9930258df649dbf99fd78fa","trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"facd7844-7323-4928-bcb8-813cbc1ba359","_uuid":"a28aaab7d3a0df35d309b54698c8dc1572db8f48","trusted":true,"collapsed":true},"cell_type":"code","source":"INPUT_LIB = '../input/'\naudio_train_files = os.listdir('../input/audio_train')\naudio_test_files = os.listdir('../input/audio_test')\ntrain = pd.read_csv('../input/train.csv')\nsubmission = pd.read_csv(\"../input/sample_submission.csv\", index_col='fname')\ntrain_audio_path = '../input/audio_train/audio_train/'\nfilename = '001ca53d.wav' # Hi-hat\nsample_rate, samples = wavfile.read(str(train_audio_path) + filename)\n#sample_rate = 16000","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"64f8b20e-a00e-4a63-8e36-4ffc1672bf5d","_uuid":"cc67aae1064845f6e4fb9dc6d280fcc030c29896","trusted":true},"cell_type":"code","source":"print(samples)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ddf7e577-44e7-4f14-9b33-1b02290df07c","_uuid":"3675492f1b0003194863afd644345d83b903ae6e","trusted":true},"cell_type":"code","source":"print(\"Size of training data\",train.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f0b4e979-d1ee-4cb3-b0a0-3a135f07560b","_uuid":"e8b1353be31acaa7ba459b38de2cc13eea6bf5c1","trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"68f69c7a-4e4b-4ded-beb2-f79289d949f3","_uuid":"1650e26b48ec4bd5211a9e86d6d4df3fe2bb35b6","trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"eee31195-7184-42e2-a5b7-be186a9b3463","_uuid":"7c4d83989143944324fa8a74dc1763336c93e443","collapsed":true,"trusted":true},"cell_type":"code","source":"def clean_filename(fname, string):   \n    file_name = fname.split('/')[1]\n    if file_name[:2] == '__':        \n        file_name = string + file_name\n    return file_name\n\ndef load_wav_file(name, path):\n    _, b = wavfile.read(path + name)\n    assert _ == SAMPLE_RATE\n    return b","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"48dac2d9-f6ee-4742-8a6f-73aede99cb5a","_uuid":"b95dc3806ce0bba677b545d559aae14c14ca403c","trusted":true,"collapsed":true},"cell_type":"code","source":"train_data = pd.DataFrame({'file_name' : train['fname'],\n                         'target' : train['label']})   \ntrain_data['time_series'] = train_data['file_name'].apply(load_wav_file, \n                                                      path=train_audio_path)    \ntrain_data['nframes'] = train_data['time_series'].apply(len)  ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b19dc0a1-ff5f-4a7e-82da-763cfb2d5e03","_uuid":"0c3d95b061d382e5a591140e1df03f6949289c07","trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"dfaf585f-83a8-459a-84d5-d671036e10a8","_uuid":"6741e54479b6c13d002b519a99580428dbf49ee4","trusted":true},"cell_type":"code","source":"print(\"Size of training data after some preprocessing : \",train_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5afb2f4f-1204-431b-be96-61e6efdd89ac","_uuid":"5b528668917c289337d3a7a91d3733b7b86b2db1","trusted":true},"cell_type":"code","source":"# missing data in training data set\ntotal = train_data.isnull().sum().sort_values(ascending = False)\npercent = (train_data.isnull().sum()/train_data.isnull().count()).sort_values(ascending = False)\nmissing_train_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2758351a-96d0-47f9-9a4c-a8d6cc789714","_uuid":"f9a63e51ff9713b18da868b489cb005cbda2aab8"},"cell_type":"markdown","source":"There is no missing data in training dataset"},{"metadata":{"_cell_guid":"5bfdf7e2-f5f1-4071-969f-d18490fa00ac","_uuid":"d073a9a680be0490484a730755bb41fe66155e63"},"cell_type":"markdown","source":"# Manually verified Audio"},{"metadata":{"_cell_guid":"486ee274-8363-4062-8aba-7398b7168511","_uuid":"f3dce38ad267d50d4149791d1d95a209f3f8b235","trusted":true},"cell_type":"code","source":"temp = train['manually_verified'].value_counts()\nlabels = temp.index\nsizes = (temp / temp.sum())*100\ntrace = go.Pie(labels=labels, values=sizes, hoverinfo='label+percent')\nlayout = go.Layout(title='Manually varification of labels(0 - No, 1 - Yes)')\ndata = [trace]\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"fd1b2bb1-bd10-4a98-b996-fa384ac9a67b","_uuid":"50badabfc75717ebe4bae3201f8342f1ed456620"},"cell_type":"markdown","source":"* Approximately 40 % labels are manually varified."},{"metadata":{"_cell_guid":"b6089cdb-1551-49e0-9f9c-40f6273a7d35","_uuid":"a6d2b3a1bec8c7246f22e857841b5f8edc034c2d","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.distplot(train_data.nframes.values, bins=50, kde=False)\nplt.xlabel('nframes', fontsize=12)\nplt.title(\"Histogram of #frames\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2cabc2ce-e532-4d2c-89cb-7b0ec940ac96","_uuid":"8f47d6f330c636dce18c545b953435f8caa6bc72","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(17,8))\nboxplot = sns.boxplot(x=\"target\", y=\"nframes\", data=train_data)\nboxplot.set(xlabel='', ylabel='')\nplt.title('Distribution of audio frames, per label', fontsize=17)\nplt.xticks(rotation=80, fontsize=17)\nplt.yticks(fontsize=17)\nplt.xlabel('Label name')\nplt.ylabel('nframes')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1d0958c2-ddc8-40b7-951a-fe42d0e942c9","_uuid":"a90f8969b4efa3f22f8cfc2dfb8a5ff016146934","trusted":true},"cell_type":"code","source":"print(\"Total number of labels in training data : \",len(train_data['target'].value_counts()))\nprint(\"Labels are : \", train_data['target'].unique())\nplt.figure(figsize=(15,8))\naudio_type = train_data['target'].value_counts().head(30)\nsns.barplot(audio_type.values, audio_type.index)\nfor i, v in enumerate(audio_type.values):\n    plt.text(0.8,i,v,color='k',fontsize=12)\nplt.xticks(rotation='vertical')\nplt.xlabel('Frequency')\nplt.ylabel('Label Name')\nplt.title(\"Top 30 labels with their frequencies in training data\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"26b351d7-3d22-4fe6-be72-27256b2f0bef","_uuid":"f01835ce7bd18bdd78f0c1ad098b90ee205bdfc5"},"cell_type":"markdown","source":"### Total number of labels are 41"},{"metadata":{"_cell_guid":"f905104a-3756-4ad8-bcb5-538ae9581cde","_uuid":"c221e583802c1a22820f2712bf95b2054cbd928a","trusted":true},"cell_type":"code","source":"temp = train_data.sort_values(by='target')\ntemp.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1240a3c5-8de3-4d16-bf5e-a9fe86b8648c","_uuid":"bf0f38c4747a77d54ee7e80d8e1f0f9ed603d953"},"cell_type":"markdown","source":"## Now look at  some labels waveform :\n  1. Acoustic_guitar\n  2. Applause\n  3. Bark"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"d2d0a325d0a4bd9fe8ac049a4cc6f81b18db10db"},"cell_type":"code","source":"def print_samples(description, offset):\n    print(description)\n    fig, ax = plt.subplots(10, 4, figsize = (12, 16))\n    for i in range(40):\n        el = temp.iloc[offset+i]\n        ax[i//4, i%4].plot(el['time_series'])\n        ax[i//4, i%4].set_title(el['file_name'][:-4])\n        ax[i//4, i%4].get_xaxis().set_ticks([])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5720e77c-7934-4f46-8ad1-c3e57185a776","_uuid":"f626d7a620064fbc1dccb5c4dae5dc841e987d64"},"cell_type":"markdown","source":"## 1. Acoustic_guitar"},{"metadata":{"_cell_guid":"a8c785a1-527e-4bd0-93bc-d093846672dc","_uuid":"c1507df985eca825fcd7ad70a71a5c0154907e95","trusted":true},"cell_type":"code","source":"print_samples(\"Acoustic_guitar\", 0)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6e41fd2d-d0d8-456e-b029-e1df5e7088d7","_uuid":"c2c66d8575d54116db171350958d28bf733048a5"},"cell_type":"markdown","source":"## 2. Applause"},{"metadata":{"_cell_guid":"df1a02cb-fd5c-4b2a-be6f-cce5ef6495d6","_uuid":"258e0c112bb554d0b003fa613b2d5c9919176a56","trusted":true},"cell_type":"code","source":"print_samples(\"Applause\", 300)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7bd366f9-68c9-44e8-b8ef-1bb77ba8de4a","_uuid":"b5d800ea2116bb7273f0b1e854dd61d11da5ff99"},"cell_type":"markdown","source":"## 3. Bark"},{"metadata":{"_cell_guid":"2850468b-84bc-4440-88e8-dde6f5ffd649","_uuid":"d2d02f8cf49eb86ae91791c5aac78b69a37913b9","trusted":true},"cell_type":"code","source":"print_samples(\"Bark\", 600)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"42b656d6-65f2-486a-9e24-13cb8868a93b","_uuid":"42494f1e0dccd9c4f5a0304b006a8904ce4231ad","trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud\nwordcloud = WordCloud(max_font_size=50, width=600, height=300).generate(' '.join(train_data.target))\nplt.figure(figsize=(15,8))\nplt.imshow(wordcloud)\nplt.title(\"Wordcloud for Labels\", fontsize=35)\nplt.axis(\"off\")\nplt.show() \n#fig.savefig(\"LabelsWordCloud\", dpi=900)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6466b131-c6a0-44d5-8d1e-98b55af08acc","_uuid":"8d7efdc223566e72bc9d345b5e7090b9b5d09a2a"},"cell_type":"markdown","source":"# Spectrogram"},{"metadata":{"_cell_guid":"85bba67f-297d-4879-ad92-9479e609eb9d","_uuid":"b375d512e1bff6c57432b22ea6332106eba739dd","collapsed":true,"trusted":true},"cell_type":"code","source":"def log_specgram(audio, sample_rate, window_size=20,\n                 step_size=10, eps=1e-10):\n    nperseg = int(round(window_size * sample_rate / 1e3))\n    noverlap = int(round(step_size * sample_rate / 1e3))\n    freqs, times, spec = signal.spectrogram(audio,\n                                    fs=sample_rate,\n                                    window='hann',\n                                    nperseg=nperseg,\n                                    noverlap=noverlap,\n                                    detrend=False)\n    return freqs, times, np.log(spec.T.astype(np.float32) + eps)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"32779efc-4d40-47a9-ac77-92746ded35eb","_uuid":"4436a296b711333a93f207e517aa2e89f21cbd22","trusted":true},"cell_type":"code","source":"freqs, times, spectrogram = log_specgram(samples, sample_rate)\n\nfig = plt.figure(figsize=(18, 8))\nax2 = fig.add_subplot(211)\nax2.imshow(spectrogram.T, aspect='auto', origin='lower', \n           extent=[times.min(), times.max(), freqs.min(), freqs.max()])\nax2.set_yticks(freqs[::40])\nax2.set_xticks(times[::40])\nax2.set_title('Spectrogram of Hi-hat ' + filename)\nax2.set_ylabel('Freqs in Hz')\nax2.set_xlabel('Seconds')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"68d18fde-7dec-454b-8242-7c03a0c1e68c","_uuid":"dc6e1989c13b7bde66563d6973615dcbe17678a7"},"cell_type":"markdown","source":"# Specgtrogram of \"Hi-Hat\" in 3d"},{"metadata":{"_cell_guid":"4337f736-0a55-4a25-850d-34831657c029","_uuid":"80bbd320562b1aad3938ae49ea5ce418c9eba234"},"cell_type":"markdown","source":"If we use spectrogram as an input features for NN, we have to remember to normalize features."},{"metadata":{"_cell_guid":"a9612a73-1416-4154-b973-2503a40a3dbb","_uuid":"c924a77c44e2ed82459c66d1f3387ea7a8a4212f","collapsed":true,"trusted":true},"cell_type":"code","source":"mean = np.mean(spectrogram, axis=0)\nstd = np.std(spectrogram, axis=0)\nspectrogram = (spectrogram - mean) / std","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f0159688-cd2a-4a1e-8fd9-3d3c37672b68","_uuid":"aa53ec594ded78fff8c84ee18404fad685b26f96","trusted":true},"cell_type":"code","source":"data = [go.Surface(z=spectrogram.T)]\nlayout = go.Layout(\n    title='Specgtrogram of \"Hi-Hat\" in 3d',\n    scene = dict(\n    yaxis = dict(title='Frequencies'),\n    xaxis = dict(title='Time'),\n    zaxis = dict(title='Log amplitude'),\n    ),\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2a2a29f1-5063-44be-8c49-67b64e2464c3","_uuid":"c225bb6c18b308060b80766dccd19cf9b31a4f5f","collapsed":true},"cell_type":"markdown","source":"# More To Come. Stayed Tuned !!"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}