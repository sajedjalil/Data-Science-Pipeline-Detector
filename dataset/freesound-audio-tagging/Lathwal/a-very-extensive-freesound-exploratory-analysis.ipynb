{"cells":[{"metadata":{},"cell_type":"markdown","source":"# More To Come. Stay Tuned. !!\nIf there are any suggestions/changes you would like to see in the Kernel please let me know :). Appreciate every ounce of help!\n\n**This notebook will always be a work in progress**. Please leave any comments about further improvements to the notebook! Any feedback or constructive criticism is greatly appreciated!. **If you like it or it helps you , you can upvote and/or leave a comment :).**|\n"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false,"collapsed":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline \n\nimport IPython.display as ipd  # To play sound in the notebook\nfrom tqdm import tqdm_notebook\nimport wave\nfrom scipy.io import wavfile\nSAMPLE_RATE = 44100\n\nimport seaborn as sns # for making plots with seaborn\ncolor = sns.color_palette()\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.offline as offline\noffline.init_notebook_mode()\nimport plotly.tools as tls\n# Math\nimport numpy as np\nfrom scipy.fftpack import fft\nfrom scipy import signal\nfrom scipy.io import wavfile\nimport librosa","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"88bd76ba9e930d1ad9930258df649dbf99fd78fa","_cell_guid":"d076fa89-24f4-4759-bacf-a4307dcbe335","trusted":false,"collapsed":true},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"a28aaab7d3a0df35d309b54698c8dc1572db8f48","_cell_guid":"facd7844-7323-4928-bcb8-813cbc1ba359","trusted":false},"cell_type":"code","source":"INPUT_LIB = '../input/'\naudio_train_files = os.listdir('../input/audio_train')\naudio_test_files = os.listdir('../input/audio_test')\ntrain = pd.read_csv('../input/train.csv')\nsubmission = pd.read_csv(\"../input/sample_submission.csv\", index_col='fname')\ntrain_audio_path = '../input/audio_train/'\nfilename = '/001ca53d.wav' # Hi-hat\nsample_rate, samples = wavfile.read(str(train_audio_path) + filename)\nsample_rate = 16000","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"collapsed":true},"cell_type":"code","source":"S = librosa.feature.melspectrogram(samples, sr=sample_rate, n_mels=128)\n\n# Convert to log scale (dB). We'll use the peak power (max) as reference.\nlog_S = librosa.power_to_db(S, ref=np.max)\n\nplt.figure(figsize=(12, 4))\nlibrosa.display.specshow(log_S, sr=sample_rate, x_axis='time', y_axis='mel')\nplt.title('Mel power spectrogram ')\nplt.colorbar(format='%+02.0f dB')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"cc67aae1064845f6e4fb9dc6d280fcc030c29896","_cell_guid":"64f8b20e-a00e-4a63-8e36-4ffc1672bf5d","trusted":false},"cell_type":"code","source":"print(samples)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"3675492f1b0003194863afd644345d83b903ae6e","_cell_guid":"ddf7e577-44e7-4f14-9b33-1b02290df07c","trusted":false},"cell_type":"code","source":"print(\"Size of training data\",train.shape)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"e8b1353be31acaa7ba459b38de2cc13eea6bf5c1","_cell_guid":"f0b4e979-d1ee-4cb3-b0a0-3a135f07560b","trusted":false},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"1650e26b48ec4bd5211a9e86d6d4df3fe2bb35b6","_cell_guid":"68f69c7a-4e4b-4ded-beb2-f79289d949f3","trusted":false},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"7c4d83989143944324fa8a74dc1763336c93e443","_cell_guid":"eee31195-7184-42e2-a5b7-be186a9b3463","trusted":false},"cell_type":"code","source":"def clean_filename(fname, string):   \n    file_name = fname.split('/')[1]\n    if file_name[:2] == '__':        \n        file_name = string + file_name\n    return file_name\n\ndef load_wav_file(name, path):\n    _, b = wavfile.read(path + name)\n    assert _ == SAMPLE_RATE\n    return b","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"b95dc3806ce0bba677b545d559aae14c14ca403c","_cell_guid":"48dac2d9-f6ee-4742-8a6f-73aede99cb5a","trusted":false},"cell_type":"code","source":"train_data = pd.DataFrame({'file_name' : train['fname'],\n                         'target' : train['label']})   \ntrain_data['time_series'] = train_data['file_name'].apply(load_wav_file, \n                                                      path=INPUT_LIB + 'audio_train/')    \ntrain_data['nframes'] = train_data['time_series'].apply(len)  ","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"0c3d95b061d382e5a591140e1df03f6949289c07","_cell_guid":"b19dc0a1-ff5f-4a7e-82da-763cfb2d5e03","trusted":false},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"6741e54479b6c13d002b519a99580428dbf49ee4","_cell_guid":"dfaf585f-83a8-459a-84d5-d671036e10a8","trusted":false},"cell_type":"code","source":"print(\"Size of training data after some preprocessing : \",train_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"5b528668917c289337d3a7a91d3733b7b86b2db1","_cell_guid":"5afb2f4f-1204-431b-be96-61e6efdd89ac","trusted":false},"cell_type":"code","source":"# missing data in training data set\ntotal = train_data.isnull().sum().sort_values(ascending = False)\npercent = (train_data.isnull().sum()/train_data.isnull().count()).sort_values(ascending = False)\nmissing_train_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f9a63e51ff9713b18da868b489cb005cbda2aab8","_cell_guid":"2758351a-96d0-47f9-9a4c-a8d6cc789714"},"cell_type":"markdown","source":"There is no missing data in training dataset"},{"metadata":{"_uuid":"d073a9a680be0490484a730755bb41fe66155e63","_cell_guid":"5bfdf7e2-f5f1-4071-969f-d18490fa00ac"},"cell_type":"markdown","source":"# Manually verified Audio"},{"metadata":{"collapsed":true,"_uuid":"f3dce38ad267d50d4149791d1d95a209f3f8b235","_cell_guid":"486ee274-8363-4062-8aba-7398b7168511","trusted":false},"cell_type":"code","source":"temp = train['manually_verified'].value_counts()\nlabels = temp.index\nsizes = (temp / temp.sum())*100\ntrace = go.Pie(labels=labels, values=sizes, hoverinfo='label+percent')\nlayout = go.Layout(title='Manually varification of labels(0 - No, 1 - Yes)')\ndata = [trace]\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"50badabfc75717ebe4bae3201f8342f1ed456620","_cell_guid":"fd1b2bb1-bd10-4a98-b996-fa384ac9a67b"},"cell_type":"markdown","source":"* Approximately 40 % labels are manually varified."},{"metadata":{"collapsed":true,"_uuid":"a6d2b3a1bec8c7246f22e857841b5f8edc034c2d","_cell_guid":"b6089cdb-1551-49e0-9f9c-40f6273a7d35","trusted":false},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.distplot(train_data.nframes.values, bins=50, kde=False)\nplt.xlabel('nframes', fontsize=12)\nplt.title(\"Histogram of #frames\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"8f47d6f330c636dce18c545b953435f8caa6bc72","_cell_guid":"2cabc2ce-e532-4d2c-89cb-7b0ec940ac96","trusted":false},"cell_type":"code","source":"plt.figure(figsize=(17,8))\nboxplot = sns.boxplot(x=\"target\", y=\"nframes\", data=train_data)\nboxplot.set(xlabel='', ylabel='')\nplt.title('Distribution of audio frames, per label', fontsize=17)\nplt.xticks(rotation=80, fontsize=17)\nplt.yticks(fontsize=17)\nplt.xlabel('Label name')\nplt.ylabel('nframes')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"a90f8969b4efa3f22f8cfc2dfb8a5ff016146934","_cell_guid":"1d0958c2-ddc8-40b7-951a-fe42d0e942c9","trusted":false},"cell_type":"code","source":"print(\"Total number of labels in training data : \",len(train_data['target'].value_counts()))\nprint(\"Labels are : \", train_data['target'].unique())\nplt.figure(figsize=(15,8))\naudio_type = train_data['target'].value_counts().head(30)\nsns.barplot(audio_type.values, audio_type.index)\nfor i, v in enumerate(audio_type.values):\n    plt.text(0.8,i,v,color='k',fontsize=12)\nplt.xticks(rotation='vertical')\nplt.xlabel('Frequency')\nplt.ylabel('Label Name')\nplt.title(\"Top 30 labels with their frequencies in training data\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f01835ce7bd18bdd78f0c1ad098b90ee205bdfc5","_cell_guid":"26b351d7-3d22-4fe6-be72-27256b2f0bef"},"cell_type":"markdown","source":"### Total number of labels are 41"},{"metadata":{"collapsed":true,"_uuid":"c221e583802c1a22820f2712bf95b2054cbd928a","_cell_guid":"f905104a-3756-4ad8-bcb5-538ae9581cde","trusted":false},"cell_type":"code","source":"temp = train_data.sort_values(by='target')\ntemp.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bf0f38c4747a77d54ee7e80d8e1f0f9ed603d953","_cell_guid":"1240a3c5-8de3-4d16-bf5e-a9fe86b8648c"},"cell_type":"markdown","source":"## Now look at  some labels waveform :\n  1. Acoustic_guitar\n  2. Applause\n  3. Bark"},{"metadata":{"_uuid":"f626d7a620064fbc1dccb5c4dae5dc841e987d64","_cell_guid":"5720e77c-7934-4f46-8ad1-c3e57185a776"},"cell_type":"markdown","source":"## 1. Acoustic_guitar"},{"metadata":{"collapsed":true,"_uuid":"c1507df985eca825fcd7ad70a71a5c0154907e95","_cell_guid":"a8c785a1-527e-4bd0-93bc-d093846672dc","trusted":false},"cell_type":"code","source":"print(\"Acoustic_guitar : \")\nfig, ax = plt.subplots(10, 4, figsize = (12, 16))\nfor i in range(40):\n    ax[i//4, i%4].plot(temp['time_series'][i])\n    ax[i//4, i%4].set_title(temp['file_name'][i][:-4])\n    ax[i//4, i%4].get_xaxis().set_ticks([])\nfig.savefig(\"AudioWaveform\", dpi=900)     ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2c66d8575d54116db171350958d28bf733048a5","_cell_guid":"6e41fd2d-d0d8-456e-b029-e1df5e7088d7"},"cell_type":"markdown","source":"## 2. Applause"},{"metadata":{"collapsed":true,"_uuid":"258e0c112bb554d0b003fa613b2d5c9919176a56","_cell_guid":"df1a02cb-fd5c-4b2a-be6f-cce5ef6495d6","trusted":false},"cell_type":"code","source":"print(\"Applause : \")\nfig, ax = plt.subplots(10, 4, figsize = (12, 16))\nfor i in range(40):\n    ax[i//4, i%4].plot(temp['time_series'][i+300])\n    ax[i//4, i%4].set_title(temp['file_name'][i+300][:-4])\n    ax[i//4, i%4].get_xaxis().set_ticks([])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b5d800ea2116bb7273f0b1e854dd61d11da5ff99","_cell_guid":"7bd366f9-68c9-44e8-b8ef-1bb77ba8de4a"},"cell_type":"markdown","source":"## 3. Bark"},{"metadata":{"collapsed":true,"_uuid":"d2d02f8cf49eb86ae91791c5aac78b69a37913b9","_cell_guid":"2850468b-84bc-4440-88e8-dde6f5ffd649","trusted":false},"cell_type":"code","source":"print(\"Bark : \")\nfig, ax = plt.subplots(10, 4, figsize = (12, 16))\nfor i in range(40):\n    ax[i//4, i%4].plot(temp['time_series'][i+600])\n    ax[i//4, i%4].set_title(temp['file_name'][i+600][:-4])\n    ax[i//4, i%4].get_xaxis().set_ticks([])","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"42494f1e0dccd9c4f5a0304b006a8904ce4231ad","_cell_guid":"42b656d6-65f2-486a-9e24-13cb8868a93b","trusted":false},"cell_type":"code","source":"from wordcloud import WordCloud\nwordcloud = WordCloud(max_font_size=50, width=600, height=300).generate(' '.join(train_data.target))\nplt.figure(figsize=(15,8))\nplt.imshow(wordcloud)\nplt.title(\"Wordcloud for Labels\", fontsize=35)\nplt.axis(\"off\")\nplt.show() \n#fig.savefig(\"LabelsWordCloud\", dpi=900)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8d7efdc223566e72bc9d345b5e7090b9b5d09a2a","_cell_guid":"6466b131-c6a0-44d5-8d1e-98b55af08acc"},"cell_type":"markdown","source":"# Spectrogram"},{"metadata":{"collapsed":true,"_uuid":"b375d512e1bff6c57432b22ea6332106eba739dd","_cell_guid":"85bba67f-297d-4879-ad92-9479e609eb9d","trusted":false},"cell_type":"code","source":"def log_specgram(audio, sample_rate, window_size=20,\n                 step_size=10, eps=1e-10):\n    nperseg = int(round(window_size * sample_rate / 1e3))\n    noverlap = int(round(step_size * sample_rate / 1e3))\n    freqs, times, spec = signal.spectrogram(audio,\n                                    fs=sample_rate,\n                                    window='hann',\n                                    nperseg=nperseg,\n                                    noverlap=noverlap,\n                                    detrend=False)\n    return freqs, times, np.log(spec.T.astype(np.float32) + eps)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"4436a296b711333a93f207e517aa2e89f21cbd22","_cell_guid":"32779efc-4d40-47a9-ac77-92746ded35eb","trusted":false},"cell_type":"code","source":"freqs, times, spectrogram = log_specgram(samples, sample_rate)\n\nfig = plt.figure(figsize=(18, 8))\nax2 = fig.add_subplot(211)\nax2.imshow(spectrogram.T, aspect='auto', origin='lower', \n           extent=[times.min(), times.max(), freqs.min(), freqs.max()])\nax2.set_yticks(freqs[::40])\nax2.set_xticks(times[::40])\nax2.set_title('Spectrogram of Hi-hat ' + filename)\nax2.set_ylabel('Freqs in Hz')\nax2.set_xlabel('Seconds')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dc6e1989c13b7bde66563d6973615dcbe17678a7","_cell_guid":"68d18fde-7dec-454b-8242-7c03a0c1e68c"},"cell_type":"markdown","source":"# Specgtrogram of \"Hi-Hat\" in 3d"},{"metadata":{"_uuid":"80bbd320562b1aad3938ae49ea5ce418c9eba234","_cell_guid":"4337f736-0a55-4a25-850d-34831657c029"},"cell_type":"markdown","source":"If we use spectrogram as an input features for NN, we have to remember to normalize features."},{"metadata":{"collapsed":true,"_uuid":"c924a77c44e2ed82459c66d1f3387ea7a8a4212f","_cell_guid":"a9612a73-1416-4154-b973-2503a40a3dbb","trusted":false},"cell_type":"code","source":"mean = np.mean(spectrogram, axis=0)\nstd = np.std(spectrogram, axis=0)\nspectrogram = (spectrogram - mean) / std","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"aa53ec594ded78fff8c84ee18404fad685b26f96","_cell_guid":"f0159688-cd2a-4a1e-8fd9-3d3c37672b68","trusted":false},"cell_type":"code","source":"data = [go.Surface(z=spectrogram.T)]\nlayout = go.Layout(\n    title='Specgtrogram of \"Hi-Hat\" in 3d',\n    scene = dict(\n    yaxis = dict(title='Frequencies', range=freqs),\n    xaxis = dict(title='Time', range=times),\n    zaxis = dict(title='Log amplitude'),\n    ),\n)\nfig = go.Figure(data=data, layout=layout)\npy.iplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"c225bb6c18b308060b80766dccd19cf9b31a4f5f","_cell_guid":"2a2a29f1-5063-44be-8c49-67b64e2464c3"},"cell_type":"markdown","source":"# More To Come. Stayed Tuned !!"}],"metadata":{"language_info":{"mimetype":"text/x-python","version":"3.6.5","codemirror_mode":{"name":"ipython","version":3},"name":"python","pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":1}