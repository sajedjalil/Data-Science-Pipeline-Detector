{"cells":[{"cell_type":"markdown","id":"6bbbe6fe","metadata":{},"source":"**This notebook is an exercise in the [Time Series](https://www.kaggle.com/learn/time-series) course.  You can reference the tutorial at [this link](https://www.kaggle.com/ryanholbrook/hybrid-models).**\n\n---\n"},{"cell_type":"markdown","id":"prompt-collaboration","metadata":{},"source":"# Introduction #\n\nRun this cell to set everything up!"},{"cell_type":"code","execution_count":null,"id":"flying-indonesia","metadata":{},"outputs":[],"source":"# Setup feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.time_series.ex5 import *\n\n# Setup notebook\nfrom pathlib import Path\nfrom learntools.time_series.style import *  # plot style settings\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import LabelEncoder\nfrom statsmodels.tsa.deterministic import DeterministicProcess\nfrom xgboost import XGBRegressor\n\n\ncomp_dir = Path('../input/store-sales-time-series-forecasting')\ndata_dir = Path(\"../input/ts-course-data\")\n\nstore_sales = pd.read_csv(\n    comp_dir / 'train.csv',\n    usecols=['store_nbr', 'family', 'date', 'sales', 'onpromotion'],\n    dtype={\n        'store_nbr': 'category',\n        'family': 'category',\n        'sales': 'float32',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\nstore_sales['date'] = store_sales.date.dt.to_period('D')\nstore_sales = store_sales.set_index(['store_nbr', 'family', 'date']).sort_index()\n\nfamily_sales = (\n    store_sales\n    .groupby(['family', 'date'])\n    .mean()\n    .unstack('family')\n    .loc['2017']\n)"},{"cell_type":"markdown","id":"sweet-camcorder","metadata":{},"source":"-------------------------------------------------------------------------------\n\nIn the next two questions, you'll create a boosted hybrid for the *Store Sales* dataset by implementing a new Python class. Run this cell to create the initial class definition. You'll add `fit` and `predict` methods to give it a scikit-learn like interface.\n"},{"cell_type":"code","execution_count":null,"id":"devoted-firmware","metadata":{},"outputs":[],"source":"# You'll add fit and predict methods to this minimal class\nclass BoostedHybrid:\n    def __init__(self, model_1, model_2):\n        self.model_1 = model_1\n        self.model_2 = model_2\n        self.y_columns = None  # store column names from fit method\n"},{"cell_type":"markdown","id":"legendary-description","metadata":{},"source":"# 1) Define fit method for boosted hybrid\n\nComplete the `fit` definition for the `BoostedHybrid` class. Refer back to steps 1 and 2 from the **Hybrid Forecasting with Residuals** section in the tutorial if you need."},{"cell_type":"code","execution_count":null,"id":"variable-victory","metadata":{},"outputs":[],"source":"def fit(self, X_1, X_2, y):\n    # YOUR CODE HERE: fit self.model_1\n    ____\n\n    y_fit = pd.DataFrame(\n        # YOUR CODE HERE: make predictions with self.model_1\n        ____,\n        index=X_1.index, columns=y.columns,\n    )\n\n    # YOUR CODE HERE: compute residuals\n    y_resid = ____\n    y_resid = y_resid.stack().squeeze() # wide to long\n\n    # YOUR CODE HERE: fit self.model_2 on residuals\n    self.model_2.fit(____, ____)\n\n    # Save column names for predict method\n    self.y_columns = y.columns\n    # Save data for question checking\n    self.y_fit = y_fit\n    self.y_resid = y_resid\n\n\n# Add method to class\nBoostedHybrid.fit = fit\n\n\n# Check your answer\nq_1.check()"},{"cell_type":"code","execution_count":null,"id":"sized-canberra","metadata":{},"outputs":[],"source":"# Lines below will give you a hint or solution code\n#q_1.hint()\n#q_1.solution()"},{"cell_type":"markdown","id":"racial-bikini","metadata":{},"source":"-------------------------------------------------------------------------------\n\n# 2) Define predict method for boosted hybrid\n\nNow define the `predict` method for the `BoostedHybrid` class. Refer back to step 3 from the **Hybrid Forecasting with Residuals** section in the tutorial if you need."},{"cell_type":"code","execution_count":null,"id":"artistic-reminder","metadata":{},"outputs":[],"source":"def predict(self, X_1, X_2):\n    y_pred = pd.DataFrame(\n        # YOUR CODE HERE: predict with self.model_1\n        ____,\n        index=X_1.index, columns=self.y_columns,\n    )\n    y_pred = y_pred.stack().squeeze()  # wide to long\n\n    # YOUR CODE HERE: add self.model_2 predictions to y_pred\n    y_pred += ____\n    \n    return y_pred.unstack()  # long to wide\n\n\n# Add method to class\nBoostedHybrid.predict = predict\n\n\n# Check your answer\nq_2.check()"},{"cell_type":"code","execution_count":null,"id":"authentic-biodiversity","metadata":{},"outputs":[],"source":"# Lines below will give you a hint or solution code\n#q_2.hint()\n#q_2.solution()"},{"cell_type":"markdown","id":"chief-barbados","metadata":{},"source":"-------------------------------------------------------------------------------\n\nNow you're ready to use your new `BoostedHybrid` class to create a model for the *Store Sales* data. Run the next cell to set up the data for training."},{"cell_type":"code","execution_count":null,"id":"talented-hands","metadata":{},"outputs":[],"source":"# Target series\ny = family_sales.loc[:, 'sales']\n\n\n# X_1: Features for Linear Regression\ndp = DeterministicProcess(index=y.index, order=1)\nX_1 = dp.in_sample()\n\n\n# X_2: Features for XGBoost\nX_2 = family_sales.drop('sales', axis=1).stack()  # onpromotion feature\n\n# Label encoding for 'family'\nle = LabelEncoder()  # from sklearn.preprocessing\nX_2 = X_2.reset_index('family')\nX_2['family'] = le.fit_transform(X_2['family'])\n\n# Label encoding for seasonality\nX_2[\"day\"] = X_2.index.day  # values are day of the month"},{"cell_type":"markdown","id":"boxed-concentrate","metadata":{},"source":"# 3) Train boosted hybrid\n\nCreate the hybrid model by initializing a `BoostedHybrid` class with `LinearRegression()` and `XGBRegressor()` instances."},{"cell_type":"code","execution_count":null,"id":"meaningful-japan","metadata":{},"outputs":[],"source":"# YOUR CODE HERE: Create LinearRegression + XGBRegressor hybrid with BoostedHybrid\nmodel = ____\n\n# YOUR CODE HERE: Fit and predict\nmodel.fit(____, ____, ____)\ny_pred = ____\n\ny_pred = y_pred.clip(0.0)\n\n\n# Check your answer\nq_3.check()"},{"cell_type":"code","execution_count":null,"id":"acting-courage","metadata":{},"outputs":[],"source":"# Lines below will give you a hint or solution code\n#q_3.hint()\n#q_3.solution()"},{"cell_type":"markdown","id":"minus-likelihood","metadata":{},"source":"-------------------------------------------------------------------------------\n\nDepending on your problem, you might want to use other hybrid combinations than the linear regression + XGBoost hybrid you've created in the previous questions. Run the next cell to try other algorithms from scikit-learn."},{"cell_type":"code","execution_count":null,"id":"illegal-ridge","metadata":{},"outputs":[],"source":"# Model 1 (trend)\nfrom pyearth import Earth\nfrom sklearn.linear_model import ElasticNet, Lasso, Ridge\n\n# Model 2\nfrom sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neural_network import MLPRegressor\n\n# Boosted Hybrid\n\n# YOUR CODE HERE: Try different combinations of the algorithms above\nmodel = BoostedHybrid(\n    model_1=Ridge(),\n    model_2=KNeighborsRegressor(),\n)"},{"cell_type":"markdown","id":"opened-history","metadata":{},"source":"These are just some suggestions. You might discover other algorithms you like in the scikit-learn [User Guide](https://scikit-learn.org/stable/supervised_learning.html).\n\nUse the code in this cell to see the predictions your hybrid makes."},{"cell_type":"code","execution_count":null,"id":"intensive-accent","metadata":{},"outputs":[],"source":"y_train, y_valid = y[:\"2017-07-01\"], y[\"2017-07-02\":]\nX1_train, X1_valid = X_1[: \"2017-07-01\"], X_1[\"2017-07-02\" :]\nX2_train, X2_valid = X_2.loc[:\"2017-07-01\"], X_2.loc[\"2017-07-02\":]\n\n# Some of the algorithms above do best with certain kinds of\n# preprocessing on the features (like standardization), but this is\n# just a demo.\nmodel.fit(X1_train, X2_train, y_train)\ny_fit = model.predict(X1_train, X2_train).clip(0.0)\ny_pred = model.predict(X1_valid, X2_valid).clip(0.0)\n\nfamilies = y.columns[0:6]\naxs = y.loc(axis=1)[families].plot(\n    subplots=True, sharex=True, figsize=(11, 9), **plot_params, alpha=0.5,\n)\n_ = y_fit.loc(axis=1)[families].plot(subplots=True, sharex=True, color='C0', ax=axs)\n_ = y_pred.loc(axis=1)[families].plot(subplots=True, sharex=True, color='C3', ax=axs)\nfor ax, family in zip(axs, families):\n    ax.legend([])\n    ax.set_ylabel(family)"},{"cell_type":"markdown","id":"efficient-hybrid","metadata":{},"source":"# 4) Fit with different learning algorithms\n\nOnce you're ready to move on, run the next cell for credit on this question."},{"cell_type":"code","execution_count":null,"id":"southern-trigger","metadata":{"lines_to_next_cell":2},"outputs":[],"source":"# View the solution (Run this cell to receive credit!)\nq_4.check()"},{"cell_type":"markdown","id":"classical-artist","metadata":{},"source":"# Keep Going #\n\n[**Convert any forecasting task**](https://www.kaggle.com/ryanholbrook/forecasting-with-machine-learning) to a machine learning problem with four ML forecasting strategies."},{"cell_type":"markdown","id":"19e0e6e7","metadata":{},"source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/time-series/discussion) to chat with other learners.*"}],"metadata":{"jupytext":{"cell_metadata_filter":"-all","formats":"ipynb,md"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":5}