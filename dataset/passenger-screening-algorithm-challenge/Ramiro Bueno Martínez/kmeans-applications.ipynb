{"cells":[{"outputs":[],"metadata":{"_uuid":"49dcf09247abfef871c28bb767936b60baa3036f","collapsed":true,"_cell_guid":"5dcc3732-bef3-44a9-a9f7-c0031bdf493c"},"execution_count":null,"cell_type":"code","source":"import sys\nimport os\nimport numpy as np\nfrom numpy import array, asarray, ma, zeros, sum\nfrom matplotlib import pyplot as plt\nimport cv2\nimport pandas as pd\nimport seaborn as sns\nimport scipy.stats as stats\nfrom scipy.cluster.vq import vq, kmeans, whiten, kmeans2\nfrom sklearn.cluster import DBSCAN\nfrom sklearn import metrics\nfrom sklearn.datasets.samples_generator import make_blobs\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import LinearSVC\nfrom sklearn.datasets import make_classification"},{"outputs":[],"metadata":{"_uuid":"4979653104b147671f429590b937b1c5309abd9a","_cell_guid":"1ddb84fa-49c6-4b2e-ab83-5b9fa9be0ac8"},"execution_count":null,"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\nos.system('mkdir ./output')\nos.system('mkdir ./output/Threats')\nos.system('mkdir ./output/NoThreats')\nos.system('mkdir ./training')\nos.system('mkdir ./results')\nos.system('mkdir ./models')\nos.system('mkdir ./input')\nprint(\"#################################\")\nprint(\"Directory application structure\")\nprint(\"#################################\")\nprint(check_output([\"ls\", \"../input/datainput\"]).decode(\"utf8\"))\nprint(check_output([\"ls\", \"../input/modelstraining\"]).decode(\"utf8\"))\n\n\n# Any results you write to the current directory are saved as output."},{"outputs":[],"metadata":{"_uuid":"9b4ace7f17f9d1471b08539b68bc5a940cdefba1","collapsed":true,"_cell_guid":"cc483fe8-8fe8-46ab-a997-133808119ba2"},"execution_count":null,"cell_type":"code","source":"############################################################################################################\n# Name: cluster_analisys\n# Autor: Ramiro Bueno Martínez\n# Date: 27/11/2017\n##########################################################################################################\ndef cluster_analisys(subset):\n\ttry:\n\t\twhitened = whiten(subset)\n\t\tcodebook,distortion = kmeans(whitened,5)\n\t\treturn distortion,whitened,codebook\n\texcept Exception as exception:\n\t\tprint (\"cluster_analisys: Excepcion {0}\".format(exception))"},{"outputs":[],"metadata":{"_uuid":"f3c1d4092c804a3b9df630e893a88933662779ec","collapsed":true,"_cell_guid":"54930a93-06c9-466c-831e-b6d2e0951261"},"execution_count":null,"cell_type":"code","source":"PATH_PHOTO_FILES = '.'\nNAME_FILE_MODEL_KMEANS = '../input/modelstraining/model_kmeans.csv'\nDATA_FOR_PREDICTION_FILE = '../input/datainput/0a83698bce92a6824dcc37c1d7fc31f5.csv'"},{"outputs":[],"metadata":{"_uuid":"cc11b623c77913c54873338c39b5608d678ac7d2","collapsed":true,"_cell_guid":"ff3d8bf0-34f0-4900-a7ad-4e2f262735da"},"execution_count":null,"cell_type":"code","source":"############################################################################################################\n# Name: creation_dataset_threats\n# Autor: Ramiro Bueno Martínez\n# Date: 27/11/2017\n# Description: The goal of this function is the finding of possible anomalies in the different kind of\n# images generated with the body scannes, using clustering techniques based in the analysis of different\n# part of the body and different possition imagees\n############################################################################################################\ndef creation_dataset_threats(dataset, FILENAME, highcontrast=False):\n\n\t\t# We have an image with a matrix structure of 660 rows by 512 colums\n\t\t# This function send this matrix to a algorithm to obtain different centroids and the distorsion\n\t\t# values that we will use to find possible anomalies \n\t\t#Initialization variables\n\t\tm_distortion = 0\n\t\tcol = 0\n\t\trow = 0\n\t\tnth = 0\n\t\t\n\t\t\n\t\toutput_dir = PATH_PHOTO_FILES + '/' + 'output'\n\t\tinput_dir = PATH_PHOTO_FILES + '/' + 'input'\n\t\t\n\t\t\n\t\tname_of_photo_file = input_dir + '/' + FILENAME\n\t\t\n\t\t\n\t\tprint (\"Starting clustering Analisys: {0}\".format(FILENAME))\n\t\t\n\t\t#Only they are going to analyse 4 Image Front-Behind-Left-Right\n\t\trange_images = [0,4,8,12]\n\t\ttry:\n\t\t\t\n\t\t\t#for nth in range(16):\n\t\t\tfor nth in range_images:\n\t\t\t\n\t\t\t\tan_img = get_single_image(name_of_photo_file, nth)  \t\t\t\t#returns the nth=3 image from the image stack\n\t\t\t\t\n\t\t\t\t#Prueba mejorando la resolución de la imagen \n\t\t\t\tif highcontrast == True:\n\t\t\t\t\timg_rescaled = convert_to_grayscale(an_img)\n\t\t\t\t\tan_img = spread_spectrum(img_rescaled)\n\t\t\n\t\t\t\tdata_array = np.array(an_img)\n\t\t\t\tdistortion_array[nth,1],whitened,codebook= cluster_analisys(data_array)\n\t\t\t\tm_distortion = m_distortion + distortion_array[nth,1]\n\t\t\t\trecord = pd.DataFrame([[FILENAME, nth, distortion_array[nth,1],'nothreat']],columns=['Name','Nth','Distortion','Threat'])\n\t\t\t\tdataset = dataset.append(record,ignore_index=True)\n\t\t\t\tcol = col + 1\n\t\t\t\tif col % 4 == 0:\n\t\t\t\t\trow = row + 1\n\t\t\t\t\tcol = 0\n\t\t\t\tprint(\".\")\n\t\t\n\t\t\n\t\t\n\t\t\t#plt.show()\n\t\t\t#print(distortion_array)\n\t\t\t####################################################\n\t\t\t#Esta parte se puede optimizar con las funciones DataFrame.mean()\n\t\t\tmedia = 0\n\t\t\tmedia = m_distortion / 4\n\t\t\t#print (\"Mean Value of Distortion: {0} \\n\".format(media))\n\t\t\t############################################################################################\n\t\t\t# At this point we are finding possible anomalies of different distortion measurement with\n\t\t\t# respect to a threshold fixed before\n\t\t\t############################################################################################\n\t\t\tpercent = 17  # 17% of the mean value we suppose that its a wrong value \n\t\t\t############################################################################################\n\t\t\tthreshold_thread = media * percent / 100\n\t\t\tfor i in range(len(dataset)):\n\t\t\t\tif abs(media - dataset.loc[i,('Distortion')]) > threshold_thread: \n\t\t\t\t\tdataset.loc[i,('Threat')] = 'threat'\n\t\t\t\tif abs(media - dataset.loc[i,('Distortion')]) <= threshold_thread:\n\t\t\t\t\tdataset.loc[i,('Threat')] = 'nothreat'\n\t\t\t\t\t\n\t\texcept Exception as exception:\n\t\t\tprint (\"Function [creation_dataset_threats]: Excepcion {0}\".format(exception))\n\t\t\tsys.exit(1)\n\t\tfinally:\n\t\t\treturn dataset"},{"outputs":[],"metadata":{"_uuid":"591e1a1258f7a1700a99059875ffd1f5f721fa3f","_cell_guid":"4d228864-dabb-43dd-9c1e-2297e5d15614"},"execution_count":null,"cell_type":"code","source":"if __name__ == \"__main__\":\n\n\tprint (\"DATA_ANALISIS_TOOL: Initialization of the system...\")\n\ttry:\n\t\tfile_models = os.listdir(\"../input/modelstraining\")\n        if 'model_kmeans.csv' in file_models:\n\t\t\tprint('The training data has been created before .........')\n\t\telse:\n\t\t\tfiles = os.listdir('./training')\n############################################################################################\n#TRAINING MODEL SECTION\n############################################################################################\n\t\t\n\t\t\n\t\t\n\t\t\tdataset_kmeans = pd.DataFrame(columns=['Id','Name','Nth','Distortion','Difference','Mean','Threat'])\n\t\t\t\n\t\t\tfor name_file in files:\n\t\t\t\tdataset_kmeans = creation_dataset_threats(dataset_kmeans, name_file, highcontrast=True)\n\t\t\n\t\t\n\t\t\tdistorsion_media = dataset_kmeans.mean(axis=None)['Distortion']\n\t\t\tfor index in range(len(dataset_kmeans)):\n\t\t\t\tdistortion = dataset_kmeans.iloc[index]['Distortion']\n\t\t\t\tdataset_kmeans.loc[index,('Difference')] = abs(distorsion_media - distortion)\n\t\t\t\tdataset_kmeans.loc[index,('Mean')] = distorsion_media\n\t\t\t\n\t\t\tsave_model(dataset_kmeans,NAME_FILE_MODEL_KMEANS) \n\t\t\tprint(\"Created csv training data ....................\")\n\t\t\n\t\t##############################################################################################\n\t\t#APPLICATION OF DIFFERENT KIND OF MODELS TO DETECT POSSIBLE THREATS\n\t\t##############################################################################################\n\t\tprint(\"Starting model creation based in Support Vector Machine Algorithm ......\")\n\t\tdataset = pd.read_csv(NAME_FILE_MODEL_KMEANS, sep=',')\n\t\tn_samp = len(dataset)\n\t\tX, y = make_classification(n_samples=n_samp, n_features=4, random_state=0)\n        row = 0\n\t\tfor index in range(len(dataset)):\n\t\t\tX[row][0]=dataset.loc[index,'Nth']\n\t\t\tX[row][1]=dataset.loc[index,'Distortion']\n\t\t\tX[row][2]=dataset.loc[index,'Difference']\n\t\t\tX[row][3]=dataset.loc[index,'Mean']\n\t\t\tif dataset.loc[index,'Threat'] == 'threat':\n\t\t\t\ty[index]=np.int32(1)\n\t\t\telse:\n\t\t\t\ty[index]=np.int32(0)\n\t\t\t\n\t\t\trow = row + 1\n\t\tclf = LinearSVC(random_state=0)\n\t\tclf.fit(X, y)\n\t\tprint(\"Created model ..........\")\n\t\tprint(\"Starting the process of detection threats .....\")\n\t\t\n        DATA_FOR_PREDICTION_FILE\n\t\tdataset = pd.read_csv(DATA_FOR_PREDICTION_FILE, sep=',')\n\t\tdata_array = np.array(dataset)\n        distortion,whitened,codebook = cluster_analisys(data_array)\n\t\t#Generation of the record data\n\t\tmean_value = dataset['Distortion'].mean()\n\t\tdifference = abs(mean_value - distortion)\n\t\t\n        result_of_prediction = clf.predict([[nth,distortion,difference,mean_value]]) \t\n\t\tname_file = DATA_FOR_PREDICTION_FILE\n        if result_of_prediction == True:\n\t\t\tprint(\"Passenger {0} it could suppose a thread at Body Scanner {1}\".format(name_file,3))\n\t\t\tthreat_result = True\n\t\t\t\t\t\n\t\telse:\n\t\t\tprint(\"Passenger {0} it could suppose a thread at Body Scanner {1}\".format(name_file,3))\n\t\t\t\t\t\t\t\n        \n        sys.exit(0)  #At the demo only the programme do a unique prediction\n  \t\n\texcept Exception as exception:\n\t\tprint (\"DATA_ANALISIS_TOOL: Excepcion {0}\".format(exception))\n\t\tsys.exit(1)\n\tfinally:\n\t\tprint(\"DATA_ANALISIS_TOOL: That's all\")"}],"nbformat_minor":1,"nbformat":4,"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python","version":"3.6.3","file_extension":".py","mimetype":"text/x-python"}}}