{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import gc\nimport re\nimport string\nimport operator\nfrom collections import defaultdict\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport re #for working with regular expression\nimport nltk #for natural language processing (nlp)\nimport spacy #also for nlp\nimport string #This is a module, Python also has built-in class str, these are different\n\n\nfrom sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-13T10:22:20.315739Z","iopub.execute_input":"2022-02-13T10:22:20.315997Z","iopub.status.idle":"2022-02-13T10:22:20.324607Z","shell.execute_reply.started":"2022-02-13T10:22:20.315968Z","shell.execute_reply":"2022-02-13T10:22:20.323868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading Training & Test Data","metadata":{}},{"cell_type":"code","source":"dataset = pd.read_csv('../input/nlp-getting-started/train.csv')\nprint(dataset.head())\ndataset.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T09:29:19.786521Z","iopub.execute_input":"2022-02-13T09:29:19.786791Z","iopub.status.idle":"2022-02-13T09:29:19.868181Z","shell.execute_reply.started":"2022-02-13T09:29:19.786753Z","shell.execute_reply":"2022-02-13T09:29:19.867348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_test = pd.read_csv('../input/nlp-getting-started/test.csv')\nprint(dataset_test.head())\ndataset_test.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T09:29:19.86949Z","iopub.execute_input":"2022-02-13T09:29:19.869815Z","iopub.status.idle":"2022-02-13T09:29:19.900361Z","shell.execute_reply.started":"2022-02-13T09:29:19.869777Z","shell.execute_reply":"2022-02-13T09:29:19.899661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analyzing Dataset","metadata":{}},{"cell_type":"markdown","source":"Converting text data to lowercase","metadata":{}},{"cell_type":"code","source":"dataset['lowered_text'] = dataset['text'].str.lower()\nprint(dataset['lowered_text'].head(3))\n\ndataset_test['text'] = dataset_test['text'].str.lower()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T09:29:19.902193Z","iopub.execute_input":"2022-02-13T09:29:19.902843Z","iopub.status.idle":"2022-02-13T09:29:19.918669Z","shell.execute_reply.started":"2022-02-13T09:29:19.902806Z","shell.execute_reply":"2022-02-13T09:29:19.917746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Removing the punctuation from text data","metadata":{}},{"cell_type":"code","source":"punctuation = string.punctuation\nprint(type(punctuation),punctuation)\n\nmapping = str.maketrans(\"\",\"\",punctuation)\n\nprint(type(mapping),mapping)\n\nprint(dataset['lowered_text'].head(10))    \ndataset['lowered_text'] = dataset[\"lowered_text\"].str.translate(mapping)\nprint(dataset['lowered_text'].head(10))  \n\ndataset_test['text'] = dataset[\"text\"].str.translate(mapping)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-13T09:29:19.92039Z","iopub.execute_input":"2022-02-13T09:29:19.92064Z","iopub.status.idle":"2022-02-13T09:29:19.990778Z","shell.execute_reply.started":"2022-02-13T09:29:19.920606Z","shell.execute_reply":"2022-02-13T09:29:19.990073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dealing with the stop_words in the text data","metadata":{}},{"cell_type":"code","source":"from nltk.corpus import stopwords\n\nstopwords_eng=stopwords.words('english')","metadata":{"execution":{"iopub.status.busy":"2022-02-13T09:29:19.991952Z","iopub.execute_input":"2022-02-13T09:29:19.992359Z","iopub.status.idle":"2022-02-13T09:29:20.000367Z","shell.execute_reply.started":"2022-02-13T09:29:19.992324Z","shell.execute_reply":"2022-02-13T09:29:19.999518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_stopwords(in_str):\n    new_str=''\n    words=in_str.split() #string is splitted through white space in a list of words\n    for tx in words:\n        if tx not in stopwords_eng:\n            new_str=new_str + tx + \" \"\n    return new_str\n\ndataset['lowered_text_stopword_removed'] = dataset['lowered_text'].apply(lambda x: remove_stopwords(x))\n\ndataset_test['text'] = dataset_test['text'].apply(lambda x: remove_stopwords(x))\n\n\nprint(dataset['lowered_text_stopword_removed'].head(5))","metadata":{"execution":{"iopub.status.busy":"2022-02-13T09:29:20.00172Z","iopub.execute_input":"2022-02-13T09:29:20.002072Z","iopub.status.idle":"2022-02-13T09:29:20.294644Z","shell.execute_reply.started":"2022-02-13T09:29:20.002026Z","shell.execute_reply":"2022-02-13T09:29:20.293266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Counting the frequency of all the words and display the most common words","metadata":{}},{"cell_type":"code","source":"from collections import Counter\n\ncounter = Counter()\nprint(type(counter))\n\nfor sent in dataset['lowered_text_stopword_removed']:\n    for word in sent.split():\n        counter[word]+=1\n        \nmost_cmn_words = counter.most_common(10)\n\nprint(type(most_cmn_words),most_cmn_words)\n\nmost_cmn_word_list = []\n\nfor word,frq in most_cmn_words:\n    most_cmn_word_list.append(word)\n    \nprint(most_cmn_word_list)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T09:29:20.295786Z","iopub.execute_input":"2022-02-13T09:29:20.296066Z","iopub.status.idle":"2022-02-13T09:29:20.346137Z","shell.execute_reply.started":"2022-02-13T09:29:20.296027Z","shell.execute_reply":"2022-02-13T09:29:20.345447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Display the rare words","metadata":{}},{"cell_type":"code","source":"most_rare_list=counter.most_common()[-10:] #list of tuples\n\n#separate words from tuple\nmost_rare_words=[]\nfor word, freq in most_rare_list:\n    most_rare_words.append(word)\n\nprint(most_rare_words)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T09:29:20.347446Z","iopub.execute_input":"2022-02-13T09:29:20.347689Z","iopub.status.idle":"2022-02-13T09:29:20.560945Z","shell.execute_reply.started":"2022-02-13T09:29:20.347656Z","shell.execute_reply":"2022-02-13T09:29:20.560072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generic function for removing specific sequence type of text","metadata":{}},{"cell_type":"code","source":"def remove_words(in_str,word_list):\n    new_str = ''\n    for word in in_str.split():\n        if word not in word_list:\n            new_str = new_str + word + \" \"\n    return new_str\n\ndataset['lowered_text_stopword_freq_removed'] = dataset['lowered_text_stopword_removed'].apply(lambda x: remove_words(x,most_cmn_word_list))\ndataset['lowered_text_stop_freq_rare_removed'] = dataset['lowered_text_stopword_freq_removed'].apply(lambda x: remove_words(x,most_rare_words))\n\ndataset['lowered_text_stop_freq_rare_removed'].head()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T09:29:20.564324Z","iopub.execute_input":"2022-02-13T09:29:20.564581Z","iopub.status.idle":"2022-02-13T09:29:20.640562Z","shell.execute_reply.started":"2022-02-13T09:29:20.564545Z","shell.execute_reply":"2022-02-13T09:29:20.639868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stemming (PorterStemmer)","metadata":{}},{"cell_type":"code","source":"from nltk.stem.porter import PorterStemmer\n\nstemmer = PorterStemmer()\n\ndef do_stemming(in_str):\n    new_str = ''\n    for word in in_str.split():\n        new_str = new_str + stemmer.stem(word) + \" \"\n    return new_str\n\ndataset['stemmed'] = dataset['lowered_text_stop_freq_rare_removed'].apply(lambda x: do_stemming(x))\n\ndataset['stemmed'].head()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T09:29:20.642756Z","iopub.execute_input":"2022-02-13T09:29:20.643218Z","iopub.status.idle":"2022-02-13T09:29:23.001777Z","shell.execute_reply.started":"2022-02-13T09:29:20.643182Z","shell.execute_reply":"2022-02-13T09:29:23.001087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lemmatization","metadata":{}},{"cell_type":"code","source":"from nltk.stem import WordNetLemmatizer\n\nlem = WordNetLemmatizer()\n\ndef do_lemmatizing(in_str):\n    new_str=\"\"\n    for word in in_str.split():\n        new_str=new_str + lem.lemmatize(word) + \" \"\n    return new_str\n\ndataset[\"lemmatized\"] = dataset[\"lowered_text_stop_freq_rare_removed\"].apply(lambda x: do_lemmatizing(x))\n\nprint(dataset[\"lemmatized\"].head(5))","metadata":{"execution":{"iopub.status.busy":"2022-02-13T09:29:23.003082Z","iopub.execute_input":"2022-02-13T09:29:23.00335Z","iopub.status.idle":"2022-02-13T09:29:25.018518Z","shell.execute_reply.started":"2022-02-13T09:29:23.003315Z","shell.execute_reply":"2022-02-13T09:29:25.017069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T09:29:25.01973Z","iopub.execute_input":"2022-02-13T09:29:25.020052Z","iopub.status.idle":"2022-02-13T09:29:25.036553Z","shell.execute_reply.started":"2022-02-13T09:29:25.020004Z","shell.execute_reply":"2022-02-13T09:29:25.035873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T09:55:06.627347Z","iopub.execute_input":"2022-02-13T09:55:06.628076Z","iopub.status.idle":"2022-02-13T09:55:06.638089Z","shell.execute_reply.started":"2022-02-13T09:55:06.628029Z","shell.execute_reply":"2022-02-13T09:55:06.637435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Keyword and Location","metadata":{}},{"cell_type":"code","source":"missing_cols = ['keyword','location']\n\ndataset[missing_cols].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T09:29:25.038196Z","iopub.execute_input":"2022-02-13T09:29:25.038682Z","iopub.status.idle":"2022-02-13T09:29:25.051706Z","shell.execute_reply.started":"2022-02-13T09:29:25.038646Z","shell.execute_reply":"2022-02-13T09:29:25.051069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(ncols=2, figsize=(17, 4), dpi=100)\n\nsns.barplot(\n        x=dataset[missing_cols].isnull().sum().index,\n        y=dataset[missing_cols].isnull().sum().values,\n        ax=axes[0]\n)\n\nsns.barplot(\n        x=dataset_test[missing_cols].isnull().sum().index,\n        y=dataset_test[missing_cols].isnull().sum().values,\n        ax=axes[1]\n)\n\naxes[0].set_ylabel('Missing Value Count', size=15, labelpad=20)\naxes[0].tick_params(axis='x', labelsize=15)\naxes[0].tick_params(axis='y', labelsize=15)\naxes[1].tick_params(axis='x', labelsize=15)\naxes[1].tick_params(axis='y', labelsize=15)\n\naxes[0].set_title('Training Set', fontsize=13)\naxes[1].set_title('Test Set', fontsize=13)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T09:29:25.052901Z","iopub.execute_input":"2022-02-13T09:29:25.053141Z","iopub.status.idle":"2022-02-13T09:29:25.570146Z","shell.execute_reply.started":"2022-02-13T09:29:25.053108Z","shell.execute_reply":"2022-02-13T09:29:25.569484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Number of unique values in keyword = {dataset[\"keyword\"].nunique()} (Training) - {dataset_test[\"keyword\"].nunique()} (Test)')\nprint(f'Number of unique values in location = {dataset[\"location\"].nunique()} (Training) - {dataset_test[\"location\"].nunique()} (Test)')","metadata":{"execution":{"iopub.status.busy":"2022-02-13T09:29:25.571417Z","iopub.execute_input":"2022-02-13T09:29:25.571844Z","iopub.status.idle":"2022-02-13T09:29:25.582009Z","shell.execute_reply.started":"2022-02-13T09:29:25.571804Z","shell.execute_reply":"2022-02-13T09:29:25.581126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Target and N-grams","metadata":{}},{"cell_type":"code","source":"dataset.groupby('target').count()['id']","metadata":{"execution":{"iopub.status.busy":"2022-02-13T09:29:25.583623Z","iopub.execute_input":"2022-02-13T09:29:25.583885Z","iopub.status.idle":"2022-02-13T09:29:25.602731Z","shell.execute_reply.started":"2022-02-13T09:29:25.583842Z","shell.execute_reply":"2022-02-13T09:29:25.60206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(ncols=2, figsize=(17, 4), dpi=100)\nplt.tight_layout()\n\ndataset.groupby('target').count()['id'].plot(kind='pie', ax=axes[0], labels=['Not Disaster', 'Disaster'])\n\nsns.countplot(x=dataset['target'], hue=dataset['target'], ax=axes[1])\n\naxes[0].set_ylabel('')\naxes[1].set_ylabel('')\naxes[1].set_xticklabels(['Not Disaster (4342)', 'Disaster (3271)'])\naxes[0].tick_params(axis='x', labelsize=15)\naxes[0].tick_params(axis='y', labelsize=15)\naxes[1].tick_params(axis='x', labelsize=15)\naxes[1].tick_params(axis='y', labelsize=15)\n\naxes[0].set_title('Target Distribution in Training Set', fontsize=13)\naxes[1].set_title('Target Count in Training Set', fontsize=13)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T09:29:25.603697Z","iopub.execute_input":"2022-02-13T09:29:25.603992Z","iopub.status.idle":"2022-02-13T09:29:25.964393Z","shell.execute_reply.started":"2022-02-13T09:29:25.603956Z","shell.execute_reply":"2022-02-13T09:29:25.963515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Embeddings and Text Cleaning","metadata":{}},{"cell_type":"markdown","source":"## Glove and FastText Embedding","metadata":{}},{"cell_type":"markdown","source":"#### Text cleaning is based on the embeddings below:\n\n* GloVe-300d-840B\n* FastText-Crawl-300d-2M","metadata":{}},{"cell_type":"code","source":"%%time\n\nglove_embeddings = np.load('../input/pickled-glove840b300d-for-10sec-loading/glove.840B.300d.pkl', allow_pickle=True)\nfasttext_embeddings = np.load('../input/pickled-crawl300d2m-for-kernel-competitions/crawl-300d-2M.pkl', allow_pickle=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T09:31:05.626097Z","iopub.execute_input":"2022-02-13T09:31:05.626664Z","iopub.status.idle":"2022-02-13T09:32:14.194777Z","shell.execute_reply.started":"2022-02-13T09:31:05.626621Z","shell.execute_reply":"2022-02-13T09:32:14.193184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_vocab(in_str):\n    tweets = in_str.apply(lambda x: x.split()).values\n    vocab = {}\n    for sent in tweets:\n        for word in sent:\n            try:\n                vocab[word]+=1\n            except KeyError:\n                vocab[word]=1\n    return vocab\n\ndef check_embeddings_coverage(in_str,word_embedding):\n    vocab = build_vocab(in_str)\n    covered = {}\n    not_covered = {}\n    n_covered = 0\n    n_not_covered = 0\n    \n    for word in vocab:\n        try:\n            covered[word] = word_embedding[word]\n            n_covered += vocab[word]\n        except:\n            not_covered[word] = vocab[word]\n            n_not_covered += vocab[word]\n            \n    vocab_coverage = len(covered)/len(vocab)\n    text_coverage = (n_covered / (n_covered + n_not_covered))\n    \n    sorted_not_covered = sorted(not_covered.items(), key=operator.itemgetter(1))[::-1]\n    \n    return sorted_not_covered, vocab_coverage, text_coverage\n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-13T09:59:20.148878Z","iopub.execute_input":"2022-02-13T09:59:20.149135Z","iopub.status.idle":"2022-02-13T09:59:20.157391Z","shell.execute_reply.started":"2022-02-13T09:59:20.149106Z","shell.execute_reply":"2022-02-13T09:59:20.156524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Embedding Coverage **Before** Text Cleaning","metadata":{}},{"cell_type":"code","source":"train_glove_oov, train_glove_vocab_coverage, train_glove_text_coverage = check_embeddings_coverage(dataset['lemmatized'], glove_embeddings)\ntest_glove_oov, test_glove_vocab_coverage, test_glove_text_coverage = check_embeddings_coverage(dataset_test['text'], glove_embeddings)\nprint('GloVe Embeddings cover {:.2%} of vocabulary and {:.2%} of text in Training Set'.format(train_glove_vocab_coverage, train_glove_text_coverage))\nprint('GloVe Embeddings cover {:.2%} of vocabulary and {:.2%} of text in Test Set'.format(test_glove_vocab_coverage, test_glove_text_coverage))\n\ntrain_fasttext_oov, train_fasttext_vocab_coverage, train_fasttext_text_coverage = check_embeddings_coverage(dataset['lemmatized'], fasttext_embeddings)\ntest_fasttext_oov, test_fasttext_vocab_coverage, test_fasttext_text_coverage = check_embeddings_coverage(dataset_test['text'], fasttext_embeddings)\nprint('FastText Embeddings cover {:.2%} of vocabulary and {:.2%} of text in Training Set'.format(train_fasttext_vocab_coverage, train_fasttext_text_coverage))\nprint('FastText Embeddings cover {:.2%} of vocabulary and {:.2%} of text in Test Set'.format(test_fasttext_vocab_coverage, test_fasttext_text_coverage))","metadata":{"execution":{"iopub.status.busy":"2022-02-13T09:59:21.143789Z","iopub.execute_input":"2022-02-13T09:59:21.144359Z","iopub.status.idle":"2022-02-13T09:59:21.312804Z","shell.execute_reply.started":"2022-02-13T09:59:21.14432Z","shell.execute_reply":"2022-02-13T09:59:21.312076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Text Cleaning","metadata":{}},{"cell_type":"code","source":"def clean(tweet): \n            \n    # Special characters\n    tweet = re.sub(r\"\\x89Û_\", \"\", tweet)\n    tweet = re.sub(r\"\\x89ÛÒ\", \"\", tweet)\n    tweet = re.sub(r\"\\x89ÛÓ\", \"\", tweet)\n    tweet = re.sub(r\"\\x89ÛÏWhen\", \"When\", tweet)\n    tweet = re.sub(r\"\\x89ÛÏ\", \"\", tweet)\n    tweet = re.sub(r\"China\\x89Ûªs\", \"China's\", tweet)\n    tweet = re.sub(r\"let\\x89Ûªs\", \"let's\", tweet)\n    tweet = re.sub(r\"\\x89Û÷\", \"\", tweet)\n    tweet = re.sub(r\"\\x89Ûª\", \"\", tweet)\n    tweet = re.sub(r\"\\x89Û\\x9d\", \"\", tweet)\n    tweet = re.sub(r\"å_\", \"\", tweet)\n    tweet = re.sub(r\"\\x89Û¢\", \"\", tweet)\n    tweet = re.sub(r\"\\x89Û¢åÊ\", \"\", tweet)\n    tweet = re.sub(r\"fromåÊwounds\", \"from wounds\", tweet)\n    tweet = re.sub(r\"åÊ\", \"\", tweet)\n    tweet = re.sub(r\"åÈ\", \"\", tweet)\n    tweet = re.sub(r\"JapÌ_n\", \"Japan\", tweet)    \n    tweet = re.sub(r\"Ì©\", \"e\", tweet)\n    tweet = re.sub(r\"å¨\", \"\", tweet)\n    tweet = re.sub(r\"SuruÌ¤\", \"Suruc\", tweet)\n    tweet = re.sub(r\"åÇ\", \"\", tweet)\n    tweet = re.sub(r\"å£3million\", \"3 million\", tweet)\n    tweet = re.sub(r\"åÀ\", \"\", tweet)\n    \n    # Contractions\n    tweet = re.sub(r\"he's\", \"he is\", tweet)\n    tweet = re.sub(r\"there's\", \"there is\", tweet)\n    tweet = re.sub(r\"We're\", \"We are\", tweet)\n    tweet = re.sub(r\"That's\", \"That is\", tweet)\n    tweet = re.sub(r\"won't\", \"will not\", tweet)\n    tweet = re.sub(r\"they're\", \"they are\", tweet)\n    tweet = re.sub(r\"Can't\", \"Cannot\", tweet)\n    tweet = re.sub(r\"wasn't\", \"was not\", tweet)\n    tweet = re.sub(r\"don\\x89Ûªt\", \"do not\", tweet)\n    tweet = re.sub(r\"aren't\", \"are not\", tweet)\n    tweet = re.sub(r\"isn't\", \"is not\", tweet)\n    tweet = re.sub(r\"What's\", \"What is\", tweet)\n    tweet = re.sub(r\"haven't\", \"have not\", tweet)\n    tweet = re.sub(r\"hasn't\", \"has not\", tweet)\n    tweet = re.sub(r\"There's\", \"There is\", tweet)\n    tweet = re.sub(r\"He's\", \"He is\", tweet)\n    tweet = re.sub(r\"It's\", \"It is\", tweet)\n    tweet = re.sub(r\"You're\", \"You are\", tweet)\n    tweet = re.sub(r\"I'M\", \"I am\", tweet)\n    tweet = re.sub(r\"shouldn't\", \"should not\", tweet)\n    tweet = re.sub(r\"wouldn't\", \"would not\", tweet)\n    tweet = re.sub(r\"i'm\", \"I am\", tweet)\n    tweet = re.sub(r\"I\\x89Ûªm\", \"I am\", tweet)\n    tweet = re.sub(r\"I'm\", \"I am\", tweet)\n    tweet = re.sub(r\"Isn't\", \"is not\", tweet)\n    tweet = re.sub(r\"Here's\", \"Here is\", tweet)\n    tweet = re.sub(r\"you've\", \"you have\", tweet)\n    tweet = re.sub(r\"you\\x89Ûªve\", \"you have\", tweet)\n    tweet = re.sub(r\"we're\", \"we are\", tweet)\n    tweet = re.sub(r\"what's\", \"what is\", tweet)\n    tweet = re.sub(r\"couldn't\", \"could not\", tweet)\n    tweet = re.sub(r\"we've\", \"we have\", tweet)\n    tweet = re.sub(r\"it\\x89Ûªs\", \"it is\", tweet)\n    tweet = re.sub(r\"doesn\\x89Ûªt\", \"does not\", tweet)\n    tweet = re.sub(r\"It\\x89Ûªs\", \"It is\", tweet)\n    tweet = re.sub(r\"Here\\x89Ûªs\", \"Here is\", tweet)\n    tweet = re.sub(r\"who's\", \"who is\", tweet)\n    tweet = re.sub(r\"I\\x89Ûªve\", \"I have\", tweet)\n    tweet = re.sub(r\"y'all\", \"you all\", tweet)\n    tweet = re.sub(r\"can\\x89Ûªt\", \"cannot\", tweet)\n    tweet = re.sub(r\"would've\", \"would have\", tweet)\n    tweet = re.sub(r\"it'll\", \"it will\", tweet)\n    tweet = re.sub(r\"we'll\", \"we will\", tweet)\n    tweet = re.sub(r\"wouldn\\x89Ûªt\", \"would not\", tweet)\n    tweet = re.sub(r\"We've\", \"We have\", tweet)\n    tweet = re.sub(r\"he'll\", \"he will\", tweet)\n    tweet = re.sub(r\"Y'all\", \"You all\", tweet)\n    tweet = re.sub(r\"Weren't\", \"Were not\", tweet)\n    tweet = re.sub(r\"Didn't\", \"Did not\", tweet)\n    tweet = re.sub(r\"they'll\", \"they will\", tweet)\n    tweet = re.sub(r\"they'd\", \"they would\", tweet)\n    tweet = re.sub(r\"DON'T\", \"DO NOT\", tweet)\n    tweet = re.sub(r\"That\\x89Ûªs\", \"That is\", tweet)\n    tweet = re.sub(r\"they've\", \"they have\", tweet)\n    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n    tweet = re.sub(r\"should've\", \"should have\", tweet)\n    tweet = re.sub(r\"You\\x89Ûªre\", \"You are\", tweet)\n    tweet = re.sub(r\"where's\", \"where is\", tweet)\n    tweet = re.sub(r\"Don\\x89Ûªt\", \"Do not\", tweet)\n    tweet = re.sub(r\"we'd\", \"we would\", tweet)\n    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n    tweet = re.sub(r\"weren't\", \"were not\", tweet)\n    tweet = re.sub(r\"They're\", \"They are\", tweet)\n    tweet = re.sub(r\"Can\\x89Ûªt\", \"Cannot\", tweet)\n    tweet = re.sub(r\"you\\x89Ûªll\", \"you will\", tweet)\n    tweet = re.sub(r\"I\\x89Ûªd\", \"I would\", tweet)\n    tweet = re.sub(r\"let's\", \"let us\", tweet)\n    tweet = re.sub(r\"it's\", \"it is\", tweet)\n    tweet = re.sub(r\"can't\", \"cannot\", tweet)\n    tweet = re.sub(r\"don't\", \"do not\", tweet)\n    tweet = re.sub(r\"you're\", \"you are\", tweet)\n    tweet = re.sub(r\"i've\", \"I have\", tweet)\n    tweet = re.sub(r\"that's\", \"that is\", tweet)\n    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n    tweet = re.sub(r\"doesn't\", \"does not\", tweet)\n    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n    tweet = re.sub(r\"didn't\", \"did not\", tweet)\n    tweet = re.sub(r\"ain't\", \"am not\", tweet)\n    tweet = re.sub(r\"you'll\", \"you will\", tweet)\n    tweet = re.sub(r\"I've\", \"I have\", tweet)\n    tweet = re.sub(r\"Don't\", \"do not\", tweet)\n    tweet = re.sub(r\"I'll\", \"I will\", tweet)\n    tweet = re.sub(r\"I'd\", \"I would\", tweet)\n    tweet = re.sub(r\"Let's\", \"Let us\", tweet)\n    tweet = re.sub(r\"you'd\", \"You would\", tweet)\n    tweet = re.sub(r\"It's\", \"It is\", tweet)\n    tweet = re.sub(r\"Ain't\", \"am not\", tweet)\n    tweet = re.sub(r\"Haven't\", \"Have not\", tweet)\n    tweet = re.sub(r\"Could've\", \"Could have\", tweet)\n    tweet = re.sub(r\"youve\", \"you have\", tweet)  \n    tweet = re.sub(r\"donå«t\", \"do not\", tweet)   \n            \n    # Character entity references\n    tweet = re.sub(r\"&gt;\", \">\", tweet)\n    tweet = re.sub(r\"&lt;\", \"<\", tweet)\n    tweet = re.sub(r\"&amp;\", \"&\", tweet)\n    \n    # Typos, slang and informal abbreviations\n    tweet = re.sub(r\"w/e\", \"whatever\", tweet)\n    tweet = re.sub(r\"w/\", \"with\", tweet)\n    tweet = re.sub(r\"USAgov\", \"USA government\", tweet)\n    tweet = re.sub(r\"recentlu\", \"recently\", tweet)\n    tweet = re.sub(r\"Ph0tos\", \"Photos\", tweet)\n    tweet = re.sub(r\"amirite\", \"am I right\", tweet)\n    tweet = re.sub(r\"exp0sed\", \"exposed\", tweet)\n    tweet = re.sub(r\"<3\", \"love\", tweet)\n    tweet = re.sub(r\"amageddon\", \"armageddon\", tweet)\n    tweet = re.sub(r\"Trfc\", \"Traffic\", tweet)\n    tweet = re.sub(r\"8/5/2015\", \"2015-08-05\", tweet)\n    tweet = re.sub(r\"WindStorm\", \"Wind Storm\", tweet)\n    tweet = re.sub(r\"8/6/2015\", \"2015-08-06\", tweet)\n    tweet = re.sub(r\"10:38PM\", \"10:38 PM\", tweet)\n    tweet = re.sub(r\"10:30pm\", \"10:30 PM\", tweet)\n    tweet = re.sub(r\"16yr\", \"16 year\", tweet)\n    tweet = re.sub(r\"lmao\", \"laughing my ass off\", tweet)   \n    tweet = re.sub(r\"TRAUMATISED\", \"traumatized\", tweet)\n    \n    # Hashtags and usernames\n    tweet = re.sub(r\"IranDeal\", \"Iran Deal\", tweet)\n    tweet = re.sub(r\"ArianaGrande\", \"Ariana Grande\", tweet)\n    tweet = re.sub(r\"camilacabello97\", \"camila cabello\", tweet) \n    tweet = re.sub(r\"RondaRousey\", \"Ronda Rousey\", tweet)     \n    tweet = re.sub(r\"MTVHottest\", \"MTV Hottest\", tweet)\n    tweet = re.sub(r\"TrapMusic\", \"Trap Music\", tweet)\n    tweet = re.sub(r\"ProphetMuhammad\", \"Prophet Muhammad\", tweet)\n    tweet = re.sub(r\"PantherAttack\", \"Panther Attack\", tweet)\n    tweet = re.sub(r\"StrategicPatience\", \"Strategic Patience\", tweet)\n    tweet = re.sub(r\"socialnews\", \"social news\", tweet)\n    tweet = re.sub(r\"NASAHurricane\", \"NASA Hurricane\", tweet)\n    tweet = re.sub(r\"onlinecommunities\", \"online communities\", tweet)\n    tweet = re.sub(r\"humanconsumption\", \"human consumption\", tweet)\n    tweet = re.sub(r\"Typhoon-Devastated\", \"Typhoon Devastated\", tweet)\n    tweet = re.sub(r\"Meat-Loving\", \"Meat Loving\", tweet)\n    tweet = re.sub(r\"facialabuse\", \"facial abuse\", tweet)\n    tweet = re.sub(r\"LakeCounty\", \"Lake County\", tweet)\n    tweet = re.sub(r\"BeingAuthor\", \"Being Author\", tweet)\n    tweet = re.sub(r\"withheavenly\", \"with heavenly\", tweet)\n    tweet = re.sub(r\"thankU\", \"thank you\", tweet)\n    tweet = re.sub(r\"iTunesMusic\", \"iTunes Music\", tweet)\n    tweet = re.sub(r\"OffensiveContent\", \"Offensive Content\", tweet)\n    tweet = re.sub(r\"WorstSummerJob\", \"Worst Summer Job\", tweet)\n    tweet = re.sub(r\"HarryBeCareful\", \"Harry Be Careful\", tweet)\n    tweet = re.sub(r\"NASASolarSystem\", \"NASA Solar System\", tweet)\n    tweet = re.sub(r\"animalrescue\", \"animal rescue\", tweet)\n    tweet = re.sub(r\"KurtSchlichter\", \"Kurt Schlichter\", tweet)\n    tweet = re.sub(r\"aRmageddon\", \"armageddon\", tweet)\n    tweet = re.sub(r\"Throwingknifes\", \"Throwing knives\", tweet)\n    tweet = re.sub(r\"GodsLove\", \"God's Love\", tweet)\n    tweet = re.sub(r\"bookboost\", \"book boost\", tweet)\n    tweet = re.sub(r\"ibooklove\", \"I book love\", tweet)\n    tweet = re.sub(r\"NestleIndia\", \"Nestle India\", tweet)\n    tweet = re.sub(r\"realDonaldTrump\", \"Donald Trump\", tweet)\n    tweet = re.sub(r\"DavidVonderhaar\", \"David Vonderhaar\", tweet)\n    tweet = re.sub(r\"CecilTheLion\", \"Cecil The Lion\", tweet)\n    tweet = re.sub(r\"weathernetwork\", \"weather network\", tweet)\n    tweet = re.sub(r\"withBioterrorism&use\", \"with Bioterrorism & use\", tweet)\n    tweet = re.sub(r\"Hostage&2\", \"Hostage & 2\", tweet)\n    tweet = re.sub(r\"GOPDebate\", \"GOP Debate\", tweet)\n    tweet = re.sub(r\"RickPerry\", \"Rick Perry\", tweet)\n    tweet = re.sub(r\"frontpage\", \"front page\", tweet)\n    tweet = re.sub(r\"NewsInTweets\", \"News In Tweets\", tweet)\n    tweet = re.sub(r\"ViralSpell\", \"Viral Spell\", tweet)\n    tweet = re.sub(r\"til_now\", \"until now\", tweet)\n    tweet = re.sub(r\"volcanoinRussia\", \"volcano in Russia\", tweet)\n    tweet = re.sub(r\"ZippedNews\", \"Zipped News\", tweet)\n    tweet = re.sub(r\"MicheleBachman\", \"Michele Bachman\", tweet)\n    tweet = re.sub(r\"53inch\", \"53 inch\", tweet)\n    tweet = re.sub(r\"KerrickTrial\", \"Kerrick Trial\", tweet)\n    tweet = re.sub(r\"abstorm\", \"Alberta Storm\", tweet)\n    tweet = re.sub(r\"Beyhive\", \"Beyonce hive\", tweet)\n    tweet = re.sub(r\"IDFire\", \"Idaho Fire\", tweet)\n    tweet = re.sub(r\"DETECTADO\", \"Detected\", tweet)\n    tweet = re.sub(r\"RockyFire\", \"Rocky Fire\", tweet)\n    tweet = re.sub(r\"Listen/Buy\", \"Listen / Buy\", tweet)\n    tweet = re.sub(r\"NickCannon\", \"Nick Cannon\", tweet)\n    tweet = re.sub(r\"FaroeIslands\", \"Faroe Islands\", tweet)\n    tweet = re.sub(r\"yycstorm\", \"Calgary Storm\", tweet)\n    tweet = re.sub(r\"IDPs:\", \"Internally Displaced People :\", tweet)\n    tweet = re.sub(r\"ArtistsUnited\", \"Artists United\", tweet)\n    tweet = re.sub(r\"ClaytonBryant\", \"Clayton Bryant\", tweet)\n    tweet = re.sub(r\"jimmyfallon\", \"jimmy fallon\", tweet)\n    tweet = re.sub(r\"justinbieber\", \"justin bieber\", tweet)  \n    tweet = re.sub(r\"UTC2015\", \"UTC 2015\", tweet)\n    tweet = re.sub(r\"Time2015\", \"Time 2015\", tweet)\n    tweet = re.sub(r\"djicemoon\", \"dj icemoon\", tweet)\n    tweet = re.sub(r\"LivingSafely\", \"Living Safely\", tweet)\n    tweet = re.sub(r\"FIFA16\", \"Fifa 2016\", tweet)\n    tweet = re.sub(r\"thisiswhywecanthavenicethings\", \"this is why we cannot have nice things\", tweet)\n    tweet = re.sub(r\"bbcnews\", \"bbc news\", tweet)\n    tweet = re.sub(r\"UndergroundRailraod\", \"Underground Railraod\", tweet)\n    tweet = re.sub(r\"c4news\", \"c4 news\", tweet)\n    tweet = re.sub(r\"OBLITERATION\", \"obliteration\", tweet)\n    tweet = re.sub(r\"MUDSLIDE\", \"mudslide\", tweet)\n    tweet = re.sub(r\"NoSurrender\", \"No Surrender\", tweet)\n    tweet = re.sub(r\"NotExplained\", \"Not Explained\", tweet)\n    tweet = re.sub(r\"greatbritishbakeoff\", \"great british bake off\", tweet)\n    tweet = re.sub(r\"LondonFire\", \"London Fire\", tweet)\n    tweet = re.sub(r\"KOTAWeather\", \"KOTA Weather\", tweet)\n    tweet = re.sub(r\"LuchaUnderground\", \"Lucha Underground\", tweet)\n    tweet = re.sub(r\"KOIN6News\", \"KOIN 6 News\", tweet)\n    tweet = re.sub(r\"LiveOnK2\", \"Live On K2\", tweet)\n    tweet = re.sub(r\"9NewsGoldCoast\", \"9 News Gold Coast\", tweet)\n    tweet = re.sub(r\"nikeplus\", \"nike plus\", tweet)\n    tweet = re.sub(r\"david_cameron\", \"David Cameron\", tweet)\n    tweet = re.sub(r\"peterjukes\", \"Peter Jukes\", tweet)\n    tweet = re.sub(r\"JamesMelville\", \"James Melville\", tweet)\n    tweet = re.sub(r\"megynkelly\", \"Megyn Kelly\", tweet)\n    tweet = re.sub(r\"cnewslive\", \"C News Live\", tweet)\n    tweet = re.sub(r\"JamaicaObserver\", \"Jamaica Observer\", tweet)\n    tweet = re.sub(r\"TweetLikeItsSeptember11th2001\", \"Tweet like it is september 11th 2001\", tweet)\n    tweet = re.sub(r\"cbplawyers\", \"cbp lawyers\", tweet)\n    tweet = re.sub(r\"fewmoretweets\", \"few more tweets\", tweet)\n    tweet = re.sub(r\"BlackLivesMatter\", \"Black Lives Matter\", tweet)\n    tweet = re.sub(r\"cjoyner\", \"Chris Joyner\", tweet)\n    tweet = re.sub(r\"ENGvAUS\", \"England vs Australia\", tweet)\n    tweet = re.sub(r\"ScottWalker\", \"Scott Walker\", tweet)\n    tweet = re.sub(r\"MikeParrActor\", \"Michael Parr\", tweet)\n    tweet = re.sub(r\"4PlayThursdays\", \"Foreplay Thursdays\", tweet)\n    tweet = re.sub(r\"TGF2015\", \"Tontitown Grape Festival\", tweet)\n    tweet = re.sub(r\"realmandyrain\", \"Mandy Rain\", tweet)\n    tweet = re.sub(r\"GraysonDolan\", \"Grayson Dolan\", tweet)\n    tweet = re.sub(r\"ApolloBrown\", \"Apollo Brown\", tweet)\n    tweet = re.sub(r\"saddlebrooke\", \"Saddlebrooke\", tweet)\n    tweet = re.sub(r\"TontitownGrape\", \"Tontitown Grape\", tweet)\n    tweet = re.sub(r\"AbbsWinston\", \"Abbs Winston\", tweet)\n    tweet = re.sub(r\"ShaunKing\", \"Shaun King\", tweet)\n    tweet = re.sub(r\"MeekMill\", \"Meek Mill\", tweet)\n    tweet = re.sub(r\"TornadoGiveaway\", \"Tornado Giveaway\", tweet)\n    tweet = re.sub(r\"GRupdates\", \"GR updates\", tweet)\n    tweet = re.sub(r\"SouthDowns\", \"South Downs\", tweet)\n    tweet = re.sub(r\"braininjury\", \"brain injury\", tweet)\n    tweet = re.sub(r\"auspol\", \"Australian politics\", tweet)\n    tweet = re.sub(r\"PlannedParenthood\", \"Planned Parenthood\", tweet)\n    tweet = re.sub(r\"calgaryweather\", \"Calgary Weather\", tweet)\n    tweet = re.sub(r\"weallheartonedirection\", \"we all heart one direction\", tweet)\n    tweet = re.sub(r\"edsheeran\", \"Ed Sheeran\", tweet)\n    tweet = re.sub(r\"TrueHeroes\", \"True Heroes\", tweet)\n    tweet = re.sub(r\"S3XLEAK\", \"sex leak\", tweet)\n    tweet = re.sub(r\"ComplexMag\", \"Complex Magazine\", tweet)\n    tweet = re.sub(r\"TheAdvocateMag\", \"The Advocate Magazine\", tweet)\n    tweet = re.sub(r\"CityofCalgary\", \"City of Calgary\", tweet)\n    tweet = re.sub(r\"EbolaOutbreak\", \"Ebola Outbreak\", tweet)\n    tweet = re.sub(r\"SummerFate\", \"Summer Fate\", tweet)\n    tweet = re.sub(r\"RAmag\", \"Royal Academy Magazine\", tweet)\n    tweet = re.sub(r\"offers2go\", \"offers to go\", tweet)\n    tweet = re.sub(r\"foodscare\", \"food scare\", tweet)\n    tweet = re.sub(r\"MNPDNashville\", \"Metropolitan Nashville Police Department\", tweet)\n    tweet = re.sub(r\"TfLBusAlerts\", \"TfL Bus Alerts\", tweet)\n    tweet = re.sub(r\"GamerGate\", \"Gamer Gate\", tweet)\n    tweet = re.sub(r\"IHHen\", \"Humanitarian Relief\", tweet)\n    tweet = re.sub(r\"spinningbot\", \"spinning bot\", tweet)\n    tweet = re.sub(r\"ModiMinistry\", \"Modi Ministry\", tweet)\n    tweet = re.sub(r\"TAXIWAYS\", \"taxi ways\", tweet)\n    tweet = re.sub(r\"Calum5SOS\", \"Calum Hood\", tweet)\n    tweet = re.sub(r\"po_st\", \"po.st\", tweet)\n    tweet = re.sub(r\"scoopit\", \"scoop.it\", tweet)\n    tweet = re.sub(r\"UltimaLucha\", \"Ultima Lucha\", tweet)\n    tweet = re.sub(r\"JonathanFerrell\", \"Jonathan Ferrell\", tweet)\n    tweet = re.sub(r\"aria_ahrary\", \"Aria Ahrary\", tweet)\n    tweet = re.sub(r\"rapidcity\", \"Rapid City\", tweet)\n    tweet = re.sub(r\"OutBid\", \"outbid\", tweet)\n    tweet = re.sub(r\"lavenderpoetrycafe\", \"lavender poetry cafe\", tweet)\n    tweet = re.sub(r\"EudryLantiqua\", \"Eudry Lantiqua\", tweet)\n    tweet = re.sub(r\"15PM\", \"15 PM\", tweet)\n    tweet = re.sub(r\"OriginalFunko\", \"Funko\", tweet)\n    tweet = re.sub(r\"rightwaystan\", \"Richard Tan\", tweet)\n    tweet = re.sub(r\"CindyNoonan\", \"Cindy Noonan\", tweet)\n    tweet = re.sub(r\"RT_America\", \"RT America\", tweet)\n    tweet = re.sub(r\"narendramodi\", \"Narendra Modi\", tweet)\n    tweet = re.sub(r\"BakeOffFriends\", \"Bake Off Friends\", tweet)\n    tweet = re.sub(r\"TeamHendrick\", \"Hendrick Motorsports\", tweet)\n    tweet = re.sub(r\"alexbelloli\", \"Alex Belloli\", tweet)\n    tweet = re.sub(r\"itsjustinstuart\", \"Justin Stuart\", tweet)\n    tweet = re.sub(r\"gunsense\", \"gun sense\", tweet)\n    tweet = re.sub(r\"DebateQuestionsWeWantToHear\", \"debate questions we want to hear\", tweet)\n    tweet = re.sub(r\"RoyalCarribean\", \"Royal Carribean\", tweet)\n    tweet = re.sub(r\"samanthaturne19\", \"Samantha Turner\", tweet)\n    tweet = re.sub(r\"JonVoyage\", \"Jon Stewart\", tweet)\n    tweet = re.sub(r\"renew911health\", \"renew 911 health\", tweet)\n    tweet = re.sub(r\"SuryaRay\", \"Surya Ray\", tweet)\n    tweet = re.sub(r\"pattonoswalt\", \"Patton Oswalt\", tweet)\n    tweet = re.sub(r\"minhazmerchant\", \"Minhaz Merchant\", tweet)\n    tweet = re.sub(r\"TLVFaces\", \"Israel Diaspora Coalition\", tweet)\n    tweet = re.sub(r\"pmarca\", \"Marc Andreessen\", tweet)\n    tweet = re.sub(r\"pdx911\", \"Portland Police\", tweet)\n    tweet = re.sub(r\"jamaicaplain\", \"Jamaica Plain\", tweet)\n    tweet = re.sub(r\"Japton\", \"Arkansas\", tweet)\n    tweet = re.sub(r\"RouteComplex\", \"Route Complex\", tweet)\n    tweet = re.sub(r\"INSubcontinent\", \"Indian Subcontinent\", tweet)\n    tweet = re.sub(r\"NJTurnpike\", \"New Jersey Turnpike\", tweet)\n    tweet = re.sub(r\"Politifiact\", \"PolitiFact\", tweet)\n    tweet = re.sub(r\"Hiroshima70\", \"Hiroshima\", tweet)\n    tweet = re.sub(r\"GMMBC\", \"Greater Mt Moriah Baptist Church\", tweet)\n    tweet = re.sub(r\"versethe\", \"verse the\", tweet)\n    tweet = re.sub(r\"TubeStrike\", \"Tube Strike\", tweet)\n    tweet = re.sub(r\"MissionHills\", \"Mission Hills\", tweet)\n    tweet = re.sub(r\"ProtectDenaliWolves\", \"Protect Denali Wolves\", tweet)\n    tweet = re.sub(r\"NANKANA\", \"Nankana\", tweet)\n    tweet = re.sub(r\"SAHIB\", \"Sahib\", tweet)\n    tweet = re.sub(r\"PAKPATTAN\", \"Pakpattan\", tweet)\n    tweet = re.sub(r\"Newz_Sacramento\", \"News Sacramento\", tweet)\n    tweet = re.sub(r\"gofundme\", \"go fund me\", tweet)\n    tweet = re.sub(r\"pmharper\", \"Stephen Harper\", tweet)\n    tweet = re.sub(r\"IvanBerroa\", \"Ivan Berroa\", tweet)\n    tweet = re.sub(r\"LosDelSonido\", \"Los Del Sonido\", tweet)\n    tweet = re.sub(r\"bancodeseries\", \"banco de series\", tweet)\n    tweet = re.sub(r\"timkaine\", \"Tim Kaine\", tweet)\n    tweet = re.sub(r\"IdentityTheft\", \"Identity Theft\", tweet)\n    tweet = re.sub(r\"AllLivesMatter\", \"All Lives Matter\", tweet)\n    tweet = re.sub(r\"mishacollins\", \"Misha Collins\", tweet)\n    tweet = re.sub(r\"BillNeelyNBC\", \"Bill Neely\", tweet)\n    tweet = re.sub(r\"BeClearOnCancer\", \"be clear on cancer\", tweet)\n    tweet = re.sub(r\"Kowing\", \"Knowing\", tweet)\n    tweet = re.sub(r\"ScreamQueens\", \"Scream Queens\", tweet)\n    tweet = re.sub(r\"AskCharley\", \"Ask Charley\", tweet)\n    tweet = re.sub(r\"BlizzHeroes\", \"Heroes of the Storm\", tweet)\n    tweet = re.sub(r\"BradleyBrad47\", \"Bradley Brad\", tweet)\n    tweet = re.sub(r\"HannaPH\", \"Typhoon Hanna\", tweet)\n    tweet = re.sub(r\"meinlcymbals\", \"MEINL Cymbals\", tweet)\n    tweet = re.sub(r\"Ptbo\", \"Peterborough\", tweet)\n    tweet = re.sub(r\"cnnbrk\", \"CNN Breaking News\", tweet)\n    tweet = re.sub(r\"IndianNews\", \"Indian News\", tweet)\n    tweet = re.sub(r\"savebees\", \"save bees\", tweet)\n    tweet = re.sub(r\"GreenHarvard\", \"Green Harvard\", tweet)\n    tweet = re.sub(r\"StandwithPP\", \"Stand with planned parenthood\", tweet)\n    tweet = re.sub(r\"hermancranston\", \"Herman Cranston\", tweet)\n    tweet = re.sub(r\"WMUR9\", \"WMUR-TV\", tweet)\n    tweet = re.sub(r\"RockBottomRadFM\", \"Rock Bottom Radio\", tweet)\n    tweet = re.sub(r\"ameenshaikh3\", \"Ameen Shaikh\", tweet)\n    tweet = re.sub(r\"ProSyn\", \"Project Syndicate\", tweet)\n    tweet = re.sub(r\"Daesh\", \"ISIS\", tweet)\n    tweet = re.sub(r\"s2g\", \"swear to god\", tweet)\n    tweet = re.sub(r\"listenlive\", \"listen live\", tweet)\n    tweet = re.sub(r\"CDCgov\", \"Centers for Disease Control and Prevention\", tweet)\n    tweet = re.sub(r\"FoxNew\", \"Fox News\", tweet)\n    tweet = re.sub(r\"CBSBigBrother\", \"Big Brother\", tweet)\n    tweet = re.sub(r\"JulieDiCaro\", \"Julie DiCaro\", tweet)\n    tweet = re.sub(r\"theadvocatemag\", \"The Advocate Magazine\", tweet)\n    tweet = re.sub(r\"RohnertParkDPS\", \"Rohnert Park Police Department\", tweet)\n    tweet = re.sub(r\"THISIZBWRIGHT\", \"Bonnie Wright\", tweet)\n    tweet = re.sub(r\"Popularmmos\", \"Popular MMOs\", tweet)\n    tweet = re.sub(r\"WildHorses\", \"Wild Horses\", tweet)\n    tweet = re.sub(r\"FantasticFour\", \"Fantastic Four\", tweet)\n    tweet = re.sub(r\"HORNDALE\", \"Horndale\", tweet)\n    tweet = re.sub(r\"PINER\", \"Piner\", tweet)\n    tweet = re.sub(r\"BathAndNorthEastSomerset\", \"Bath and North East Somerset\", tweet)\n    tweet = re.sub(r\"thatswhatfriendsarefor\", \"that is what friends are for\", tweet)\n    tweet = re.sub(r\"residualincome\", \"residual income\", tweet)\n    tweet = re.sub(r\"YahooNewsDigest\", \"Yahoo News Digest\", tweet)\n    tweet = re.sub(r\"MalaysiaAirlines\", \"Malaysia Airlines\", tweet)\n    tweet = re.sub(r\"AmazonDeals\", \"Amazon Deals\", tweet)\n    tweet = re.sub(r\"MissCharleyWebb\", \"Charley Webb\", tweet)\n    tweet = re.sub(r\"shoalstraffic\", \"shoals traffic\", tweet)\n    tweet = re.sub(r\"GeorgeFoster72\", \"George Foster\", tweet)\n    tweet = re.sub(r\"pop2015\", \"pop 2015\", tweet)\n    tweet = re.sub(r\"_PokemonCards_\", \"Pokemon Cards\", tweet)\n    tweet = re.sub(r\"DianneG\", \"Dianne Gallagher\", tweet)\n    tweet = re.sub(r\"KashmirConflict\", \"Kashmir Conflict\", tweet)\n    tweet = re.sub(r\"BritishBakeOff\", \"British Bake Off\", tweet)\n    tweet = re.sub(r\"FreeKashmir\", \"Free Kashmir\", tweet)\n    tweet = re.sub(r\"mattmosley\", \"Matt Mosley\", tweet)\n    tweet = re.sub(r\"BishopFred\", \"Bishop Fred\", tweet)\n    tweet = re.sub(r\"EndConflict\", \"End Conflict\", tweet)\n    tweet = re.sub(r\"EndOccupation\", \"End Occupation\", tweet)\n    tweet = re.sub(r\"UNHEALED\", \"unhealed\", tweet)\n    tweet = re.sub(r\"CharlesDagnall\", \"Charles Dagnall\", tweet)\n    tweet = re.sub(r\"Latestnews\", \"Latest news\", tweet)\n    tweet = re.sub(r\"KindleCountdown\", \"Kindle Countdown\", tweet)\n    tweet = re.sub(r\"NoMoreHandouts\", \"No More Handouts\", tweet)\n    tweet = re.sub(r\"datingtips\", \"dating tips\", tweet)\n    tweet = re.sub(r\"charlesadler\", \"Charles Adler\", tweet)\n    tweet = re.sub(r\"twia\", \"Texas Windstorm Insurance Association\", tweet)\n    tweet = re.sub(r\"txlege\", \"Texas Legislature\", tweet)\n    tweet = re.sub(r\"WindstormInsurer\", \"Windstorm Insurer\", tweet)\n    tweet = re.sub(r\"Newss\", \"News\", tweet)\n    tweet = re.sub(r\"hempoil\", \"hemp oil\", tweet)\n    tweet = re.sub(r\"CommoditiesAre\", \"Commodities are\", tweet)\n    tweet = re.sub(r\"tubestrike\", \"tube strike\", tweet)\n    tweet = re.sub(r\"JoeNBC\", \"Joe Scarborough\", tweet)\n    tweet = re.sub(r\"LiteraryCakes\", \"Literary Cakes\", tweet)\n    tweet = re.sub(r\"TI5\", \"The International 5\", tweet)\n    tweet = re.sub(r\"thehill\", \"the hill\", tweet)\n    tweet = re.sub(r\"3others\", \"3 others\", tweet)\n    tweet = re.sub(r\"stighefootball\", \"Sam Tighe\", tweet)\n    tweet = re.sub(r\"whatstheimportantvideo\", \"what is the important video\", tweet)\n    tweet = re.sub(r\"ClaudioMeloni\", \"Claudio Meloni\", tweet)\n    tweet = re.sub(r\"DukeSkywalker\", \"Duke Skywalker\", tweet)\n    tweet = re.sub(r\"carsonmwr\", \"Fort Carson\", tweet)\n    tweet = re.sub(r\"offdishduty\", \"off dish duty\", tweet)\n    tweet = re.sub(r\"andword\", \"and word\", tweet)\n    tweet = re.sub(r\"rhodeisland\", \"Rhode Island\", tweet)\n    tweet = re.sub(r\"easternoregon\", \"Eastern Oregon\", tweet)\n    tweet = re.sub(r\"WAwildfire\", \"Washington Wildfire\", tweet)\n    tweet = re.sub(r\"fingerrockfire\", \"Finger Rock Fire\", tweet)\n    tweet = re.sub(r\"57am\", \"57 am\", tweet)\n    tweet = re.sub(r\"fingerrockfire\", \"Finger Rock Fire\", tweet)\n    tweet = re.sub(r\"JacobHoggard\", \"Jacob Hoggard\", tweet)\n    tweet = re.sub(r\"newnewnew\", \"new new new\", tweet)\n    tweet = re.sub(r\"under50\", \"under 50\", tweet)\n    tweet = re.sub(r\"getitbeforeitsgone\", \"get it before it is gone\", tweet)\n    tweet = re.sub(r\"freshoutofthebox\", \"fresh out of the box\", tweet)\n    tweet = re.sub(r\"amwriting\", \"am writing\", tweet)\n    tweet = re.sub(r\"Bokoharm\", \"Boko Haram\", tweet)\n    tweet = re.sub(r\"Nowlike\", \"Now like\", tweet)\n    tweet = re.sub(r\"seasonfrom\", \"season from\", tweet)\n    tweet = re.sub(r\"epicente\", \"epicenter\", tweet)\n    tweet = re.sub(r\"epicenterr\", \"epicenter\", tweet)\n    tweet = re.sub(r\"sicklife\", \"sick life\", tweet)\n    tweet = re.sub(r\"yycweather\", \"Calgary Weather\", tweet)\n    tweet = re.sub(r\"calgarysun\", \"Calgary Sun\", tweet)\n    tweet = re.sub(r\"approachng\", \"approaching\", tweet)\n    tweet = re.sub(r\"evng\", \"evening\", tweet)\n    tweet = re.sub(r\"Sumthng\", \"something\", tweet)\n    tweet = re.sub(r\"EllenPompeo\", \"Ellen Pompeo\", tweet)\n    tweet = re.sub(r\"shondarhimes\", \"Shonda Rhimes\", tweet)\n    tweet = re.sub(r\"ABCNetwork\", \"ABC Network\", tweet)\n    tweet = re.sub(r\"SushmaSwaraj\", \"Sushma Swaraj\", tweet)\n    tweet = re.sub(r\"pray4japan\", \"Pray for Japan\", tweet)\n    tweet = re.sub(r\"hope4japan\", \"Hope for Japan\", tweet)\n    tweet = re.sub(r\"Illusionimagess\", \"Illusion images\", tweet)\n    tweet = re.sub(r\"SummerUnderTheStars\", \"Summer Under The Stars\", tweet)\n    tweet = re.sub(r\"ShallWeDance\", \"Shall We Dance\", tweet)\n    tweet = re.sub(r\"TCMParty\", \"TCM Party\", tweet)\n    tweet = re.sub(r\"marijuananews\", \"marijuana news\", tweet)\n    tweet = re.sub(r\"onbeingwithKristaTippett\", \"on being with Krista Tippett\", tweet)\n    tweet = re.sub(r\"Beingtweets\", \"Being tweets\", tweet)\n    tweet = re.sub(r\"newauthors\", \"new authors\", tweet)\n    tweet = re.sub(r\"remedyyyy\", \"remedy\", tweet)\n    tweet = re.sub(r\"44PM\", \"44 PM\", tweet)\n    tweet = re.sub(r\"HeadlinesApp\", \"Headlines App\", tweet)\n    tweet = re.sub(r\"40PM\", \"40 PM\", tweet)\n    tweet = re.sub(r\"myswc\", \"Severe Weather Center\", tweet)\n    tweet = re.sub(r\"ithats\", \"that is\", tweet)\n    tweet = re.sub(r\"icouldsitinthismomentforever\", \"I could sit in this moment forever\", tweet)\n    tweet = re.sub(r\"FatLoss\", \"Fat Loss\", tweet)\n    tweet = re.sub(r\"02PM\", \"02 PM\", tweet)\n    tweet = re.sub(r\"MetroFmTalk\", \"Metro Fm Talk\", tweet)\n    tweet = re.sub(r\"Bstrd\", \"bastard\", tweet)\n    tweet = re.sub(r\"bldy\", \"bloody\", tweet)\n    tweet = re.sub(r\"MetrofmTalk\", \"Metro Fm Talk\", tweet)\n    tweet = re.sub(r\"terrorismturn\", \"terrorism turn\", tweet)\n    tweet = re.sub(r\"BBCNewsAsia\", \"BBC News Asia\", tweet)\n    tweet = re.sub(r\"BehindTheScenes\", \"Behind The Scenes\", tweet)\n    tweet = re.sub(r\"GeorgeTakei\", \"George Takei\", tweet)\n    tweet = re.sub(r\"WomensWeeklyMag\", \"Womens Weekly Magazine\", tweet)\n    tweet = re.sub(r\"SurvivorsGuidetoEarth\", \"Survivors Guide to Earth\", tweet)\n    tweet = re.sub(r\"incubusband\", \"incubus band\", tweet)\n    tweet = re.sub(r\"Babypicturethis\", \"Baby picture this\", tweet)\n    tweet = re.sub(r\"BombEffects\", \"Bomb Effects\", tweet)\n    tweet = re.sub(r\"win10\", \"Windows 10\", tweet)\n    tweet = re.sub(r\"idkidk\", \"I do not know I do not know\", tweet)\n    tweet = re.sub(r\"TheWalkingDead\", \"The Walking Dead\", tweet)\n    tweet = re.sub(r\"amyschumer\", \"Amy Schumer\", tweet)\n    tweet = re.sub(r\"crewlist\", \"crew list\", tweet)\n    tweet = re.sub(r\"Erdogans\", \"Erdogan\", tweet)\n    tweet = re.sub(r\"BBCLive\", \"BBC Live\", tweet)\n    tweet = re.sub(r\"TonyAbbottMHR\", \"Tony Abbott\", tweet)\n    tweet = re.sub(r\"paulmyerscough\", \"Paul Myerscough\", tweet)\n    tweet = re.sub(r\"georgegallagher\", \"George Gallagher\", tweet)\n    tweet = re.sub(r\"JimmieJohnson\", \"Jimmie Johnson\", tweet)\n    tweet = re.sub(r\"pctool\", \"pc tool\", tweet)\n    tweet = re.sub(r\"DoingHashtagsRight\", \"Doing Hashtags Right\", tweet)\n    tweet = re.sub(r\"ThrowbackThursday\", \"Throwback Thursday\", tweet)\n    tweet = re.sub(r\"SnowBackSunday\", \"Snowback Sunday\", tweet)\n    tweet = re.sub(r\"LakeEffect\", \"Lake Effect\", tweet)\n    tweet = re.sub(r\"RTphotographyUK\", \"Richard Thomas Photography UK\", tweet)\n    tweet = re.sub(r\"BigBang_CBS\", \"Big Bang CBS\", tweet)\n    tweet = re.sub(r\"writerslife\", \"writers life\", tweet)\n    tweet = re.sub(r\"NaturalBirth\", \"Natural Birth\", tweet)\n    tweet = re.sub(r\"UnusualWords\", \"Unusual Words\", tweet)\n    tweet = re.sub(r\"wizkhalifa\", \"Wiz Khalifa\", tweet)\n    tweet = re.sub(r\"acreativedc\", \"a creative DC\", tweet)\n    tweet = re.sub(r\"vscodc\", \"vsco DC\", tweet)\n    tweet = re.sub(r\"VSCOcam\", \"vsco camera\", tweet)\n    tweet = re.sub(r\"TheBEACHDC\", \"The beach DC\", tweet)\n    tweet = re.sub(r\"buildingmuseum\", \"building museum\", tweet)\n    tweet = re.sub(r\"WorldOil\", \"World Oil\", tweet)\n    tweet = re.sub(r\"redwedding\", \"red wedding\", tweet)\n    tweet = re.sub(r\"AmazingRaceCanada\", \"Amazing Race Canada\", tweet)\n    tweet = re.sub(r\"WakeUpAmerica\", \"Wake Up America\", tweet)\n    tweet = re.sub(r\"\\\\Allahuakbar\\\\\", \"Allahu Akbar\", tweet)\n    tweet = re.sub(r\"bleased\", \"blessed\", tweet)\n    tweet = re.sub(r\"nigeriantribune\", \"Nigerian Tribune\", tweet)\n    tweet = re.sub(r\"HIDEO_KOJIMA_EN\", \"Hideo Kojima\", tweet)\n    tweet = re.sub(r\"FusionFestival\", \"Fusion Festival\", tweet)\n    tweet = re.sub(r\"50Mixed\", \"50 Mixed\", tweet)\n    tweet = re.sub(r\"NoAgenda\", \"No Agenda\", tweet)\n    tweet = re.sub(r\"WhiteGenocide\", \"White Genocide\", tweet)\n    tweet = re.sub(r\"dirtylying\", \"dirty lying\", tweet)\n    tweet = re.sub(r\"SyrianRefugees\", \"Syrian Refugees\", tweet)\n    tweet = re.sub(r\"changetheworld\", \"change the world\", tweet)\n    tweet = re.sub(r\"Ebolacase\", \"Ebola case\", tweet)\n    tweet = re.sub(r\"mcgtech\", \"mcg technologies\", tweet)\n    tweet = re.sub(r\"withweapons\", \"with weapons\", tweet)\n    tweet = re.sub(r\"advancedwarfare\", \"advanced warfare\", tweet)\n    tweet = re.sub(r\"letsFootball\", \"let us Football\", tweet)\n    tweet = re.sub(r\"LateNiteMix\", \"late night mix\", tweet)\n    tweet = re.sub(r\"PhilCollinsFeed\", \"Phil Collins\", tweet)\n    tweet = re.sub(r\"RudyHavenstein\", \"Rudy Havenstein\", tweet)\n    tweet = re.sub(r\"22PM\", \"22 PM\", tweet)\n    tweet = re.sub(r\"54am\", \"54 AM\", tweet)\n    tweet = re.sub(r\"38am\", \"38 AM\", tweet)\n    tweet = re.sub(r\"OldFolkExplainStuff\", \"Old Folk Explain Stuff\", tweet)\n    tweet = re.sub(r\"BlacklivesMatter\", \"Black Lives Matter\", tweet)\n    tweet = re.sub(r\"InsaneLimits\", \"Insane Limits\", tweet)\n    tweet = re.sub(r\"youcantsitwithus\", \"you cannot sit with us\", tweet)\n    tweet = re.sub(r\"2k15\", \"2015\", tweet)\n    tweet = re.sub(r\"TheIran\", \"Iran\", tweet)\n    tweet = re.sub(r\"JimmyFallon\", \"Jimmy Fallon\", tweet)\n    tweet = re.sub(r\"AlbertBrooks\", \"Albert Brooks\", tweet)\n    tweet = re.sub(r\"defense_news\", \"defense news\", tweet)\n    tweet = re.sub(r\"nuclearrcSA\", \"Nuclear Risk Control Self Assessment\", tweet)\n    tweet = re.sub(r\"Auspol\", \"Australia Politics\", tweet)\n    tweet = re.sub(r\"NuclearPower\", \"Nuclear Power\", tweet)\n    tweet = re.sub(r\"WhiteTerrorism\", \"White Terrorism\", tweet)\n    tweet = re.sub(r\"truthfrequencyradio\", \"Truth Frequency Radio\", tweet)\n    tweet = re.sub(r\"ErasureIsNotEquality\", \"Erasure is not equality\", tweet)\n    tweet = re.sub(r\"ProBonoNews\", \"Pro Bono News\", tweet)\n    tweet = re.sub(r\"JakartaPost\", \"Jakarta Post\", tweet)\n    tweet = re.sub(r\"toopainful\", \"too painful\", tweet)\n    tweet = re.sub(r\"melindahaunton\", \"Melinda Haunton\", tweet)\n    tweet = re.sub(r\"NoNukes\", \"No Nukes\", tweet)\n    tweet = re.sub(r\"curryspcworld\", \"Currys PC World\", tweet)\n    tweet = re.sub(r\"ineedcake\", \"I need cake\", tweet)\n    tweet = re.sub(r\"blackforestgateau\", \"black forest gateau\", tweet)\n    tweet = re.sub(r\"BBCOne\", \"BBC One\", tweet)\n    tweet = re.sub(r\"AlexxPage\", \"Alex Page\", tweet)\n    tweet = re.sub(r\"jonathanserrie\", \"Jonathan Serrie\", tweet)\n    tweet = re.sub(r\"SocialJerkBlog\", \"Social Jerk Blog\", tweet)\n    tweet = re.sub(r\"ChelseaVPeretti\", \"Chelsea Peretti\", tweet)\n    tweet = re.sub(r\"irongiant\", \"iron giant\", tweet)\n    tweet = re.sub(r\"RonFunches\", \"Ron Funches\", tweet)\n    tweet = re.sub(r\"TimCook\", \"Tim Cook\", tweet)\n    tweet = re.sub(r\"sebastianstanisaliveandwell\", \"Sebastian Stan is alive and well\", tweet)\n    tweet = re.sub(r\"Madsummer\", \"Mad summer\", tweet)\n    tweet = re.sub(r\"NowYouKnow\", \"Now you know\", tweet)\n    tweet = re.sub(r\"concertphotography\", \"concert photography\", tweet)\n    tweet = re.sub(r\"TomLandry\", \"Tom Landry\", tweet)\n    tweet = re.sub(r\"showgirldayoff\", \"show girl day off\", tweet)\n    tweet = re.sub(r\"Yougslavia\", \"Yugoslavia\", tweet)\n    tweet = re.sub(r\"QuantumDataInformatics\", \"Quantum Data Informatics\", tweet)\n    tweet = re.sub(r\"FromTheDesk\", \"From The Desk\", tweet)\n    tweet = re.sub(r\"TheaterTrial\", \"Theater Trial\", tweet)\n    tweet = re.sub(r\"CatoInstitute\", \"Cato Institute\", tweet)\n    tweet = re.sub(r\"EmekaGift\", \"Emeka Gift\", tweet)\n    tweet = re.sub(r\"LetsBe_Rational\", \"Let us be rational\", tweet)\n    tweet = re.sub(r\"Cynicalreality\", \"Cynical reality\", tweet)\n    tweet = re.sub(r\"FredOlsenCruise\", \"Fred Olsen Cruise\", tweet)\n    tweet = re.sub(r\"NotSorry\", \"not sorry\", tweet)\n    tweet = re.sub(r\"UseYourWords\", \"use your words\", tweet)\n    tweet = re.sub(r\"WordoftheDay\", \"word of the day\", tweet)\n    tweet = re.sub(r\"Dictionarycom\", \"Dictionary.com\", tweet)\n    tweet = re.sub(r\"TheBrooklynLife\", \"The Brooklyn Life\", tweet)\n    tweet = re.sub(r\"jokethey\", \"joke they\", tweet)\n    tweet = re.sub(r\"nflweek1picks\", \"NFL week 1 picks\", tweet)\n    tweet = re.sub(r\"uiseful\", \"useful\", tweet)\n    tweet = re.sub(r\"JusticeDotOrg\", \"The American Association for Justice\", tweet)\n    tweet = re.sub(r\"autoaccidents\", \"auto accidents\", tweet)\n    tweet = re.sub(r\"SteveGursten\", \"Steve Gursten\", tweet)\n    tweet = re.sub(r\"MichiganAutoLaw\", \"Michigan Auto Law\", tweet)\n    tweet = re.sub(r\"birdgang\", \"bird gang\", tweet)\n    tweet = re.sub(r\"nflnetwork\", \"NFL Network\", tweet)\n    tweet = re.sub(r\"NYDNSports\", \"NY Daily News Sports\", tweet)\n    tweet = re.sub(r\"RVacchianoNYDN\", \"Ralph Vacchiano NY Daily News\", tweet)\n    tweet = re.sub(r\"EdmontonEsks\", \"Edmonton Eskimos\", tweet)\n    tweet = re.sub(r\"david_brelsford\", \"David Brelsford\", tweet)\n    tweet = re.sub(r\"TOI_India\", \"The Times of India\", tweet)\n    tweet = re.sub(r\"hegot\", \"he got\", tweet)\n    tweet = re.sub(r\"SkinsOn9\", \"Skins on 9\", tweet)\n    tweet = re.sub(r\"sothathappened\", \"so that happened\", tweet)\n    tweet = re.sub(r\"LCOutOfDoors\", \"LC Out Of Doors\", tweet)\n    tweet = re.sub(r\"NationFirst\", \"Nation First\", tweet)\n    tweet = re.sub(r\"IndiaToday\", \"India Today\", tweet)\n    tweet = re.sub(r\"HLPS\", \"helps\", tweet)\n    tweet = re.sub(r\"HOSTAGESTHROSW\", \"hostages throw\", tweet)\n    tweet = re.sub(r\"SNCTIONS\", \"sanctions\", tweet)\n    tweet = re.sub(r\"BidTime\", \"Bid Time\", tweet)\n    tweet = re.sub(r\"crunchysensible\", \"crunchy sensible\", tweet)\n    tweet = re.sub(r\"RandomActsOfRomance\", \"Random acts of romance\", tweet)\n    tweet = re.sub(r\"MomentsAtHill\", \"Moments at hill\", tweet)\n    tweet = re.sub(r\"eatshit\", \"eat shit\", tweet)\n    tweet = re.sub(r\"liveleakfun\", \"live leak fun\", tweet)\n    tweet = re.sub(r\"SahelNews\", \"Sahel News\", tweet)\n    tweet = re.sub(r\"abc7newsbayarea\", \"ABC 7 News Bay Area\", tweet)\n    tweet = re.sub(r\"facilitiesmanagement\", \"facilities management\", tweet)\n    tweet = re.sub(r\"facilitydude\", \"facility dude\", tweet)\n    tweet = re.sub(r\"CampLogistics\", \"Camp logistics\", tweet)\n    tweet = re.sub(r\"alaskapublic\", \"Alaska public\", tweet)\n    tweet = re.sub(r\"MarketResearch\", \"Market Research\", tweet)\n    tweet = re.sub(r\"AccuracyEsports\", \"Accuracy Esports\", tweet)\n    tweet = re.sub(r\"TheBodyShopAust\", \"The Body Shop Australia\", tweet)\n    tweet = re.sub(r\"yychail\", \"Calgary hail\", tweet)\n    tweet = re.sub(r\"yyctraffic\", \"Calgary traffic\", tweet)\n    tweet = re.sub(r\"eliotschool\", \"eliot school\", tweet)\n    tweet = re.sub(r\"TheBrokenCity\", \"The Broken City\", tweet)\n    tweet = re.sub(r\"OldsFireDept\", \"Olds Fire Department\", tweet)\n    tweet = re.sub(r\"RiverComplex\", \"River Complex\", tweet)\n    tweet = re.sub(r\"fieldworksmells\", \"field work smells\", tweet)\n    tweet = re.sub(r\"IranElection\", \"Iran Election\", tweet)\n    tweet = re.sub(r\"glowng\", \"glowing\", tweet)\n    tweet = re.sub(r\"kindlng\", \"kindling\", tweet)\n    tweet = re.sub(r\"riggd\", \"rigged\", tweet)\n    tweet = re.sub(r\"slownewsday\", \"slow news day\", tweet)\n    tweet = re.sub(r\"MyanmarFlood\", \"Myanmar Flood\", tweet)\n    tweet = re.sub(r\"abc7chicago\", \"ABC 7 Chicago\", tweet)\n    tweet = re.sub(r\"copolitics\", \"Colorado Politics\", tweet)\n    tweet = re.sub(r\"AdilGhumro\", \"Adil Ghumro\", tweet)\n    tweet = re.sub(r\"netbots\", \"net bots\", tweet)\n    tweet = re.sub(r\"byebyeroad\", \"bye bye road\", tweet)\n    tweet = re.sub(r\"massiveflooding\", \"massive flooding\", tweet)\n    tweet = re.sub(r\"EndofUS\", \"End of United States\", tweet)\n    tweet = re.sub(r\"35PM\", \"35 PM\", tweet)\n    tweet = re.sub(r\"greektheatrela\", \"Greek Theatre Los Angeles\", tweet)\n    tweet = re.sub(r\"76mins\", \"76 minutes\", tweet)\n    tweet = re.sub(r\"publicsafetyfirst\", \"public safety first\", tweet)\n    tweet = re.sub(r\"livesmatter\", \"lives matter\", tweet)\n    tweet = re.sub(r\"myhometown\", \"my hometown\", tweet)\n    tweet = re.sub(r\"tankerfire\", \"tanker fire\", tweet)\n    tweet = re.sub(r\"MEMORIALDAY\", \"memorial day\", tweet)\n    tweet = re.sub(r\"MEMORIAL_DAY\", \"memorial day\", tweet)\n    tweet = re.sub(r\"instaxbooty\", \"instagram booty\", tweet)\n    tweet = re.sub(r\"Jerusalem_Post\", \"Jerusalem Post\", tweet)\n    tweet = re.sub(r\"WayneRooney_INA\", \"Wayne Rooney\", tweet)\n    tweet = re.sub(r\"VirtualReality\", \"Virtual Reality\", tweet)\n    tweet = re.sub(r\"OculusRift\", \"Oculus Rift\", tweet)\n    tweet = re.sub(r\"OwenJones84\", \"Owen Jones\", tweet)\n    tweet = re.sub(r\"jeremycorbyn\", \"Jeremy Corbyn\", tweet)\n    tweet = re.sub(r\"paulrogers002\", \"Paul Rogers\", tweet)\n    tweet = re.sub(r\"mortalkombatx\", \"Mortal Kombat X\", tweet)\n    tweet = re.sub(r\"mortalkombat\", \"Mortal Kombat\", tweet)\n    tweet = re.sub(r\"FilipeCoelho92\", \"Filipe Coelho\", tweet)\n    tweet = re.sub(r\"OnlyQuakeNews\", \"Only Quake News\", tweet)\n    tweet = re.sub(r\"kostumes\", \"costumes\", tweet)\n    tweet = re.sub(r\"YEEESSSS\", \"yes\", tweet)\n    tweet = re.sub(r\"ToshikazuKatayama\", \"Toshikazu Katayama\", tweet)\n    tweet = re.sub(r\"IntlDevelopment\", \"Intl Development\", tweet)\n    tweet = re.sub(r\"ExtremeWeather\", \"Extreme Weather\", tweet)\n    tweet = re.sub(r\"WereNotGruberVoters\", \"We are not gruber voters\", tweet)\n    tweet = re.sub(r\"NewsThousands\", \"News Thousands\", tweet)\n    tweet = re.sub(r\"EdmundAdamus\", \"Edmund Adamus\", tweet)\n    tweet = re.sub(r\"EyewitnessWV\", \"Eye witness WV\", tweet)\n    tweet = re.sub(r\"PhiladelphiaMuseu\", \"Philadelphia Museum\", tweet)\n    tweet = re.sub(r\"DublinComicCon\", \"Dublin Comic Con\", tweet)\n    tweet = re.sub(r\"NicholasBrendon\", \"Nicholas Brendon\", tweet)\n    tweet = re.sub(r\"Alltheway80s\", \"All the way 80s\", tweet)\n    tweet = re.sub(r\"FromTheField\", \"From the field\", tweet)\n    tweet = re.sub(r\"NorthIowa\", \"North Iowa\", tweet)\n    tweet = re.sub(r\"WillowFire\", \"Willow Fire\", tweet)\n    tweet = re.sub(r\"MadRiverComplex\", \"Mad River Complex\", tweet)\n    tweet = re.sub(r\"feelingmanly\", \"feeling manly\", tweet)\n    tweet = re.sub(r\"stillnotoverit\", \"still not over it\", tweet)\n    tweet = re.sub(r\"FortitudeValley\", \"Fortitude Valley\", tweet)\n    tweet = re.sub(r\"CoastpowerlineTramTr\", \"Coast powerline\", tweet)\n    tweet = re.sub(r\"ServicesGold\", \"Services Gold\", tweet)\n    tweet = re.sub(r\"NewsbrokenEmergency\", \"News broken emergency\", tweet)\n    tweet = re.sub(r\"Evaucation\", \"evacuation\", tweet)\n    tweet = re.sub(r\"leaveevacuateexitbe\", \"leave evacuate exit be\", tweet)\n    tweet = re.sub(r\"P_EOPLE\", \"PEOPLE\", tweet)\n    tweet = re.sub(r\"Tubestrike\", \"tube strike\", tweet)\n    tweet = re.sub(r\"CLASS_SICK\", \"CLASS SICK\", tweet)\n    tweet = re.sub(r\"localplumber\", \"local plumber\", tweet)\n    tweet = re.sub(r\"awesomejobsiri\", \"awesome job siri\", tweet)\n    tweet = re.sub(r\"PayForItHow\", \"Pay for it how\", tweet)\n    tweet = re.sub(r\"ThisIsAfrica\", \"This is Africa\", tweet)\n    tweet = re.sub(r\"crimeairnetwork\", \"crime air network\", tweet)\n    tweet = re.sub(r\"KimAcheson\", \"Kim Acheson\", tweet)\n    tweet = re.sub(r\"cityofcalgary\", \"City of Calgary\", tweet)\n    tweet = re.sub(r\"prosyndicate\", \"pro syndicate\", tweet)\n    tweet = re.sub(r\"660NEWS\", \"660 NEWS\", tweet)\n    tweet = re.sub(r\"BusInsMagazine\", \"Business Insurance Magazine\", tweet)\n    tweet = re.sub(r\"wfocus\", \"focus\", tweet)\n    tweet = re.sub(r\"ShastaDam\", \"Shasta Dam\", tweet)\n    tweet = re.sub(r\"go2MarkFranco\", \"Mark Franco\", tweet)\n    tweet = re.sub(r\"StephGHinojosa\", \"Steph Hinojosa\", tweet)\n    tweet = re.sub(r\"Nashgrier\", \"Nash Grier\", tweet)\n    tweet = re.sub(r\"NashNewVideo\", \"Nash new video\", tweet)\n    tweet = re.sub(r\"IWouldntGetElectedBecause\", \"I would not get elected because\", tweet)\n    tweet = re.sub(r\"SHGames\", \"Sledgehammer Games\", tweet)\n    tweet = re.sub(r\"bedhair\", \"bed hair\", tweet)\n    tweet = re.sub(r\"JoelHeyman\", \"Joel Heyman\", tweet)\n    tweet = re.sub(r\"viaYouTube\", \"via YouTube\", tweet)\n           \n    # Urls\n    tweet = re.sub(r\"https?:\\/\\/t.co\\/[A-Za-z0-9]+\", \"\", tweet)\n        \n    # Words with punctuations and special characters\n    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\"\n    for p in punctuations:\n        tweet = tweet.replace(p, f' {p} ')\n        \n    # ... and ..\n    tweet = tweet.replace('...', ' ... ')\n    if '...' not in tweet:\n        tweet = tweet.replace('..', ' ... ')      \n        \n    # Acronyms\n    tweet = re.sub(r\"MH370\", \"Malaysia Airlines Flight 370\", tweet)\n    tweet = re.sub(r\"mÌ¼sica\", \"music\", tweet)\n    tweet = re.sub(r\"okwx\", \"Oklahoma City Weather\", tweet)\n    tweet = re.sub(r\"arwx\", \"Arkansas Weather\", tweet)    \n    tweet = re.sub(r\"gawx\", \"Georgia Weather\", tweet)  \n    tweet = re.sub(r\"scwx\", \"South Carolina Weather\", tweet)  \n    tweet = re.sub(r\"cawx\", \"California Weather\", tweet)\n    tweet = re.sub(r\"tnwx\", \"Tennessee Weather\", tweet)\n    tweet = re.sub(r\"azwx\", \"Arizona Weather\", tweet)  \n    tweet = re.sub(r\"alwx\", \"Alabama Weather\", tweet)\n    tweet = re.sub(r\"wordpressdotcom\", \"wordpress\", tweet)    \n    tweet = re.sub(r\"usNWSgov\", \"United States National Weather Service\", tweet)\n    tweet = re.sub(r\"Suruc\", \"Sanliurfa\", tweet)   \n    \n    # Grouping same words without embeddings\n    tweet = re.sub(r\"Bestnaijamade\", \"bestnaijamade\", tweet)\n    tweet = re.sub(r\"SOUDELOR\", \"Soudelor\", tweet)\n    \n    return tweet","metadata":{"execution":{"iopub.status.busy":"2022-02-13T10:01:26.521068Z","iopub.execute_input":"2022-02-13T10:01:26.521345Z","iopub.status.idle":"2022-02-13T10:01:26.706444Z","shell.execute_reply.started":"2022-02-13T10:01:26.521314Z","shell.execute_reply":"2022-02-13T10:01:26.705568Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset['text_cleaned'] = dataset['lemmatized'].apply(lambda s : clean(s))\ndataset_test['text_cleaned'] = dataset_test['text'].apply(lambda s : clean(s))","metadata":{"execution":{"iopub.status.busy":"2022-02-13T10:02:51.872799Z","iopub.execute_input":"2022-02-13T10:02:51.87349Z","iopub.status.idle":"2022-02-13T10:09:15.477349Z","shell.execute_reply.started":"2022-02-13T10:02:51.873447Z","shell.execute_reply":"2022-02-13T10:09:15.476487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Embedding Coverage **After** Text Cleaning","metadata":{}},{"cell_type":"code","source":"train_glove_oov, train_glove_vocab_coverage, train_glove_text_coverage = check_embeddings_coverage(dataset['text_cleaned'], glove_embeddings)\ntest_glove_oov, test_glove_vocab_coverage, test_glove_text_coverage = check_embeddings_coverage(dataset_test['text_cleaned'], glove_embeddings)\nprint('GloVe Embeddings cover {:.2%} of vocabulary and {:.2%} of text in Training Set'.format(train_glove_vocab_coverage, train_glove_text_coverage))\nprint('GloVe Embeddings cover {:.2%} of vocabulary and {:.2%} of text in Test Set'.format(test_glove_vocab_coverage, test_glove_text_coverage))\n\ntrain_fasttext_oov, train_fasttext_vocab_coverage, train_fasttext_text_coverage = check_embeddings_coverage(dataset['text_cleaned'], fasttext_embeddings)\ntest_fasttext_oov, test_fasttext_vocab_coverage, test_fasttext_text_coverage = check_embeddings_coverage(dataset_test['text_cleaned'], fasttext_embeddings)\nprint('FastText Embeddings cover {:.2%} of vocabulary and {:.2%} of text in Training Set'.format(train_fasttext_vocab_coverage, train_fasttext_text_coverage))\nprint('FastText Embeddings cover {:.2%} of vocabulary and {:.2%} of text in Test Set'.format(test_fasttext_vocab_coverage, test_fasttext_text_coverage))","metadata":{"execution":{"iopub.status.busy":"2022-02-13T10:09:15.478766Z","iopub.execute_input":"2022-02-13T10:09:15.479012Z","iopub.status.idle":"2022-02-13T10:09:15.642998Z","shell.execute_reply.started":"2022-02-13T10:09:15.478977Z","shell.execute_reply":"2022-02-13T10:09:15.64229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After cleaning the tweets, glove_embeddings and fasttext_embeddings are deleted and garbage collected because they consume too much memory (10+ gigabytes).","metadata":{}},{"cell_type":"code","source":"del glove_embeddings, fasttext_embeddings, train_glove_oov, test_glove_oov, train_fasttext_oov, test_fasttext_oov\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T10:15:09.288223Z","iopub.execute_input":"2022-02-13T10:15:09.288605Z","iopub.status.idle":"2022-02-13T10:15:10.377986Z","shell.execute_reply.started":"2022-02-13T10:15:09.288569Z","shell.execute_reply":"2022-02-13T10:15:10.377314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross-validation (StratifiedKFold)","metadata":{}},{"cell_type":"code","source":"K = 3\n\nskf = StratifiedKFold(n_splits=K,random_state=1337,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T10:28:16.568101Z","iopub.execute_input":"2022-02-13T10:28:16.568668Z","iopub.status.idle":"2022-02-13T10:28:16.572598Z","shell.execute_reply.started":"2022-02-13T10:28:16.568633Z","shell.execute_reply":"2022-02-13T10:28:16.571743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DISASTER = dataset['target'] == 1\n\nprint('Whole Training Set Shape = {}'.format(dataset.shape))\nprint('Whole Training Set Unique keyword Count = {}'.format(dataset['keyword'].nunique()))","metadata":{"execution":{"iopub.status.busy":"2022-02-13T10:28:18.20464Z","iopub.execute_input":"2022-02-13T10:28:18.204892Z","iopub.status.idle":"2022-02-13T10:28:18.211522Z","shell.execute_reply.started":"2022-02-13T10:28:18.204863Z","shell.execute_reply":"2022-02-13T10:28:18.21064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for fold, (trn_idx, val_idx) in enumerate(skf.split(dataset['text_cleaned'], dataset['target']), 1):\n    print('\\nFold {} Training Set Shape = {} - Validation Set Shape = {}'.format(fold, dataset.loc[trn_idx, 'text_cleaned'].shape, dataset.loc[val_idx, 'text_cleaned'].shape))\n    print('Fold {} Training Set Unique keyword Count = {} - Validation Set Unique keyword Count = {}'.format(fold, dataset.loc[trn_idx, 'keyword'].nunique(), dataset.loc[val_idx, 'keyword'].nunique()))  ","metadata":{"execution":{"iopub.status.busy":"2022-02-13T10:28:18.468927Z","iopub.execute_input":"2022-02-13T10:28:18.469471Z","iopub.status.idle":"2022-02-13T10:28:18.491536Z","shell.execute_reply.started":"2022-02-13T10:28:18.469431Z","shell.execute_reply":"2022-02-13T10:28:18.490836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model **Training** & **Report**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}