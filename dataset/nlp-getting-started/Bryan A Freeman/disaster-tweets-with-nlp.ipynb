{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Disaster Tweets with NLP\n\n#### What should I expect the data format to be?\nEach sample in the train and test set has the following information:\n* The text of a tweet\n* A keyword from that tweet (although this may be blank!)\n* The location the tweet was sent from (may also be blank)\n\n#### What am I predicting?\n* Whether a given tweet is about a real disaster or not. \n* If so, predict a 1. If not, predict a 0.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import re\nimport string\nimport urllib\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()\nimport warnings\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.model_selection import train_test_split, KFold\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import SVC\nfrom nltk.tokenize import TweetTokenizer, sent_tokenize, word_tokenize, regexp_tokenize\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud, STOPWORDS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")\n\npd.options.display.max_rows = 10\npd.options.display.max_columns = 20\n\nprint(\"numpy version: {}\".format(np.__version__))\nprint(\"pandas version: {}\".format(pd.__version__))\nprint(\"seaborn version: {}\\n\".format(sns.__version__))\n\nsns.set_style(\"whitegrid\")\nflatui = [\"#9b59b6\", \"#3498db\", \"#95a5a6\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"]\nsns.set_palette(flatui)\n\nsns.palplot(sns.color_palette())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load the Data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv', encoding='utf8')\nprint('Train data loaded.')\n\n# Save a clean copy for later\nclean_copy = df_train.copy()\n\ndf_test = pd.read_csv('/kaggle/input/nlp-getting-started/test.csv', encoding='utf8')\nprint('Test data loaded.')\n\nsample_sub = pd.read_csv('/kaggle/input/nlp-getting-started/sample_submission.csv', encoding='utf8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('There are {} of records in the train data set.'.format(len(df_train.index)))\nprint('There are {} of records in the test data set.'.format(len(df_test.index)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Basic Data Exploration\n\n### Column Information","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have several null locations and some null keywords in the test data.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Target Distribution\n\nLet's take a quick look at the targets. The value counts should be only 0 or 1.**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"target_value_counts=df_train.target.value_counts()\nprint(target_value_counts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style('ticks')\nfig, ax = plt.subplots()\nfig.set_size_inches(11, 8)\nclrs = ['#2ecc71','#e74c3c']\nsns.barplot(x=target_value_counts.index,\n            y=target_value_counts, \n            capsize=.3, \n            palette=clrs)\nplt.xlabel(\"0=Fake News    or    1=Real Disaster\")\nplt.ylabel(\"Number of Tweets\")\nplt.title(\"Distribution of Test Data\")\nplt.show(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The dataset is a bit unbalanced. There are 4342 fake disasters, and 3271 real ones.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Missing Values\n\nI saw earlier that some location and keyword values are missing. Let´s take a closer look.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_with_missing = ['keyword', 'location']\ntrain_empties = df_train[cols_with_missing].isnull().sum()/len(df_train)*100\nfig, ax = plt.subplots()\nfig.set_size_inches(11, 8)\nclrs = ['#3498db', '#e74c3c']\nsns.barplot(x=train_empties.index,\n            y=train_empties.values,\n            ax=ax,\n            capsize=.3, \n            palette=clrs)\nax.set_ylabel('Percent Missing Values',labelpad=20)\nax.set_yticks(np.arange(0,40,5))\nax.set_ylim((0,35))\nax.set_title('Missing Keywords and Locations', fontsize=13)\nplt.show(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Keywords Exploration","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"keyword_value_counts=df_train['keyword'].value_counts()\nprint('There are {} unique keywords.\\n'.format(len(keyword_value_counts)))\nprint(keyword_value_counts)\ntop_25_kw = keyword_value_counts[:25]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Top 25 Keywords","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tick_range = [0,5,10,15,20,25,30,35,40,45]\nfig, ax = plt.subplots()\nfig.set_size_inches(16, 8)\nsns.barplot(y=top_25_kw.values,\n            x=top_25_kw.index,\n            palette=flatui)\nplt.xlabel('Keyword')\nplt.ylabel('Frequency')\nplt.xticks(rotation=45)\nplt.yticks(ticks=tick_range, rotation=0)\nplt.title(\"Frequency of Keyword Use - Top 25\")\nplt.show(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Top 25 Keywords for Fake Disasters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"true_ratios = df_train.groupby('keyword')['target'].mean().sort_values(ascending=False)\nfig, ax = plt.subplots()\nfig.set_size_inches(16, 8)\nsns.barplot(x=true_ratios.index[:25],\n            y=true_ratios.values[:25],\n            ax=ax,\n           palette=flatui)\nplt.xticks(rotation=45)\nplt.yticks(rotation=0)\nplt.xlabel('Keyword')\nplt.ylabel(\"True-False Ratio\")\nplt.title(\"Top 25 Keywords for Fake Disasters\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Location Exploration","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"loc_value_counts=df_train['location'].value_counts()\nprint('There are {} unique keywords.\\n'.format(len(loc_value_counts)))\nprint(loc_value_counts)\ntop_25_loc = loc_value_counts[:25]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Top 25 Locations","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tick_range = [0,20,40,60,80,100,120]\nfig, ax = plt.subplots()\nfig.set_size_inches(16, 8)\nsns.barplot(y=top_25_loc.values,\n            x=top_25_loc.index,\n            palette=flatui)\nplt.xlabel('Location')\nplt.ylabel('Frequency')\nplt.xticks(rotation=45)\nplt.yticks(ticks=tick_range, rotation=0)\nplt.title(\"Frequency of Locations - Top 25\")\nplt.show(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tweet Body Exploration","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# WordCloud helper function\n\ndef wc(x, stop_words, max_words, bgcolor, plot_title):\n    plt.figure(figsize = (16,8))\n    wc = WordCloud(background_color=bgcolor, stopwords=stop_words, max_words=max_words,  max_font_size=50).generate(str(x))\n    wc.generate(' '.join(x))\n    plt.title(plot_title)\n    plt.imshow(wc)\n    plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Most Frequent Words Real Disasters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"max_words = 500\nstop_words = [\"https\", \"co\", \"RT\", 'http', 'hi', 'amp', 'ha'] + list(STOPWORDS)\nwc(df_train[df_train['target']==1]['text'], stop_words, max_words,'black', 'Most Frequent Words - Real')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Most Frequent Words - Fake","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"wc(df_train[df_train['target']==0]['text'], stop_words, max_words,'black', 'Most Frequent Words - Fake')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Length of Tweet in Characters","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(16,8))\n\ntweet_len_real=df_train[df_train['target']==1]['text'].str.len()\nsns.distplot(tweet_len_real,\n             ax=ax1,\n             color='#e74c3c')\nax1.set_title('Real Disaster')\n\ntweet_len_fake=df_train[df_train['target']==0]['text'].str.len()\nsns.distplot(tweet_len_fake,\n             ax=ax2,\n             color='#2ecc71')\nax2.set_title('Fake Disaster')\n\nfig.suptitle('Length in Characters')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like a left skewed distribution for both. Fake tweets seem to be a bit longer on average.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Tweet Length in Words","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(16,8))\nwords_real=df_train[df_train['target']==1]['text'].str.split().apply(lambda x : [len(i) for i in x])\nwords_fake=df_train[df_train['target']==0]['text'].str.split().apply(lambda x : [len(i) for i in x])\n\n\nsns.distplot(words_real.map(lambda x: np.mean(x)),\n             ax=ax1,\n             color='#e74c3c')\nax1.set_title('Real Disaster')\n\nsns.distplot(words_fake.map(lambda x: np.mean(x)),\n             ax=ax2,\n             color='#2ecc71')\nax2.set_title('Fake Disaster')\n\nfig.suptitle('Average Length of Tweets in Words')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering\n\nI´m going to encapsulate all of my new feature creation into fuctions so I can more easily build a pipeline when I get to that point","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def avg_word_len(text):\n    words = word_tokenize(text)\n    word_lens = [len(w) for w in words]\n    return round(np.mean(word_lens),1)\n\ndef clean_text(text):\n    text = re.sub('[^a-zA-Z]', ' ', text)  \n    text = text.lower()  \n    # split to array(default delimiter is \" \") \n    text = text.split()  \n    text = [w for w in text if not w in set(stopwords.words('english'))] \n    text = ' '.join(text)            \n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def text_feature_eng(x):\n    \n    # Clean text\n    x['clean_text'] = x['text'].apply(lambda x : clean_text(x))\n\n    # Word Count\n    tweek_tzr = TweetTokenizer()\n    x['word_cnt'] = x['clean_text'].apply(lambda t: len(tweek_tzr.tokenize(t.lower())))\n\n    # Character Count\n    x['char_cnt'] = x['clean_text'].apply(lambda c: len(c))\n\n    # Hashtags\n    hashtag_re = r\"#\\w+\"\n    x['hashtag_ct'] = x['text'].apply(lambda h: len(regexp_tokenize(h, hashtag_re)))\n\n    # Average Word Length\n    x['avg_word_len'] = x['clean_text'].apply(avg_word_len)\n\n    # Numbers\n    num_re = r\"(\\d+\\.?,?\\s?\\d+)\"\n    x['num_cnt'] = x['text'].apply(lambda n: len(regexp_tokenize(n, num_re)))\n\n    # Punctuation Count\n    punct_re = r\"[^\\w\\s]\"\n    x['punct_cnt'] = x['text'].apply(lambda p: len(regexp_tokenize(p, punct_re)))\n\n    # Mentions\n    mention_re = r\"@\\w+\"\n    x['mention_cnt'] = x['text'].apply(lambda m: len(regexp_tokenize(m, mention_re)))\n\n    # Bag of Words\n    x['bow'] = x['clean_text'].apply(lambda t: [w for w in tweek_tzr.tokenize(t.lower())])\n\n    # Words without hashtags or mentions\n    x['words_only'] = x['bow'].apply(lambda w: [t for t in w if t.isalpha()])\n\n    # Stopwords\n    x['stopwords'] = x['bow'].apply(lambda x: [t for t in x if t in stopwords.words('english')])\n    \n    # Number of text emojis\n    x['emojis'] = x['text'].apply(lambda comment: sum(comment.count(e) for e in (':-)', ':)', ';-)', ';)', ':(', ':-(')))\n    \n    # Flag for missing keywords\n    x['no_keywords'] = x['keyword'].isna().astype(int)\n    \n    # Flag for missing location\n    x['no_location'] = x['location'].isna().astype(int)\n    \n    # Drop text column\n    x.drop('text', axis=1, inplace=True)\n    \n    x.avg_word_len.fillna(0) \n    \n    return x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build the Pipeline","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"   ### Prepare the Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Revert to a clean copy\ndf_train = clean_copy.copy()\n\n# Get the features and the lables\nX = df_train.copy()\n\n# Apply feature engineering process\nX_proc = text_feature_eng(X)\nprint('X_proc shape: {}'.format(X_proc.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_proc.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"all_features = [col for col in X_proc.columns.values \n                if col  not in ['id', 'target']]\nnum_features = [col for col in X_proc.columns.values \n                if col  not in ['id','target','bow','words_only',\n                                'stopwords', 'clean_text', \n                                'keyword', 'location','no_keywords',\n                                'no_location']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Make Test-Train Split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 37\nSPLIT = .8\n\nX_train, X_val, y_train, y_val = train_test_split(X_proc[all_features], \n                                                  X_proc['target'],\n                                                  train_size=SPLIT,\n                                                  shuffle=True,\n                                                  random_state=SEED)\nprint('{} training records'.format(len(X_train)))\nprint('{} training labels'.format(len(y_train)))\nprint('{} validation records'.format(len(X_val)))\nprint('{} validation labels'.format(len(y_val)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pipeline Feature Selectors\n\nI don't have homegenous features, so I want to be able to process one feature at a time. I had some trouble getting a single feature selector to work, so I created one for text features and one for numeric features.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Text feature selector\nclass TextSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, key):\n        self.key = key\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        return X[self.key]\n\n# Numeric feature selector    \nclass NumericSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, key):\n        self.key = key\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        return X[[self.key]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Per-feature pipline\ntfidf_pipeline = Pipeline([\n                ('selector', TextSelector(key='clean_text')),\n                ('tfidf', TfidfVectorizer())])\nlength_pipeline =  Pipeline([\n                ('selector', NumericSelector(key='avg_word_len')),\n                ('standard', StandardScaler())\n            ])\nwords_pipeline =  Pipeline([\n                ('selector', NumericSelector(key='word_cnt')),\n                ('standard', StandardScaler())\n            ])\nchar_pipeline =  Pipeline([\n                ('selector', NumericSelector(key='char_cnt')),\n                ('standard', StandardScaler())\n            ])\nnum_pipeline =  Pipeline([\n                ('selector', NumericSelector(key='num_cnt')),\n                ('standard', StandardScaler())\n            ])\npunct_pipeline =  Pipeline([\n                ('selector', NumericSelector(key='punct_cnt')),\n                ('standard', StandardScaler())\n            ])\n\n# Union the features together\nfeature_pipeline = FeatureUnion([('tfidf', tfidf_pipeline), \n                                 ('length', length_pipeline),\n                                 ('words', words_pipeline),\n                                 ('chars', char_pipeline),\n                                 ('nums', num_pipeline),\n                                 ('punct', punct_pipeline)])\n\nfeature_processing = Pipeline([('features', feature_pipeline)])\nfeature_processing.fit_transform(X_train)\nprint('X_train shape: {}'.format(X_train.shape))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build the Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tuned_parameters = {'kernel': ['linear'], \n                    'C': [1, 5, 10],\n                    'cache_size': [100,200,400],\n                    'degree': [2, 5, 10]}\n\nscores = ['precision', 'recall']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for score in scores:\n    print('Tuning hyper-parameters for %s \\n' % score)\n    print ('Creating pipeline instance.')\n    sentiment_pipeline = Pipeline([\n                ('features',feature_pipeline),\n                ('classifier', GridSearchCV(SVC(),\n                tuned_parameters, \n                scoring='%s_macro' % score,\n                verbose=10,\n                n_jobs=-1,\n                cv=3))])\n \n    print('Fitting the model.')\n    sentiment_pipeline.fit(X_train, y_train)\n\n    print('Tuning hyper-parameters for %s \\n' % score)\n    print('Best parameters set found on development set: \\n')\n    print(sentiment_pipeline.named_steps['classifier'].best_params_, '\\n')\n    print(\"Grid scores on development set:\\n\")\n    means = sentiment_pipeline.named_steps['classifier'].cv_results_['mean_test_score']\n    stds = sentiment_pipeline.named_steps['classifier'].cv_results_['std_test_score']\n    for mean, std, params in zip(means, stds, sentiment_pipeline.named_steps['classifier'].cv_results_['params']):\n          print(\"%0.3f (+/-%0.03f) for %r\"\n            % (mean, std * 2, params))\n    print()\n    print('Detailed classification report:\\n')\n    print('The model is trained on the full development set.')\n    print('The scores are computed on the full evaluation set.\\n')\n    y_true, y_pred = y_val, sentiment_pipeline.predict(X_val)\n    print(classification_report(y_val, y_pred), '\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Confusion Matrix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(y_val, y_pred)\nfig = plt.figure(figsize = (10,7))\nax = fig.add_subplot(111)\ncax = ax.matshow(cm)\nplt.title('Confusion matrix for SVC')\nfig.colorbar(cax)\nlabels = ['Fake', 'Real']\nax.set_xticklabels([''] + labels)\nax.set_yticklabels([''] + labels)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Final Model on Entire Test Set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_full = clean_copy\nX_train_proc = text_feature_eng(X_train_full)\n\ninference_pipeline = Pipeline([\n                ('features',feature_pipeline),\n                ('classifier', SVC(C=1,\n                                   kernel='linear',\n                                   random_state=SEED,\n                                   cache_size=200,\n                                   degree=1))])\n\ninference_pipeline.fit(X_train_proc[all_features], X_train_proc['target'])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = df_test.copy()\nX_test_proc = text_feature_eng(X_test)\nX_test_proc['avg_word_len'].fillna(0, inplace=True)\ny_pred = inference_pipeline.predict(X_test_proc[all_features])\nlen(y_pred)\nlen(X_test_proc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create Submission","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['id'], submission['target'] = X_test_proc['id'], y_pred\nsubmission.to_csv('/kaggle/working/submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}