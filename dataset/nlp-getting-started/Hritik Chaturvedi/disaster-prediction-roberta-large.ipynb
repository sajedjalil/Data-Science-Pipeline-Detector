{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-07T05:50:22.269635Z","iopub.execute_input":"2022-02-07T05:50:22.270047Z","iopub.status.idle":"2022-02-07T05:50:22.299973Z","shell.execute_reply.started":"2022-02-07T05:50:22.269927Z","shell.execute_reply":"2022-02-07T05:50:22.299281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.301915Z","iopub.execute_input":"2022-02-07T05:50:22.302432Z","iopub.status.idle":"2022-02-07T05:50:22.357008Z","shell.execute_reply.started":"2022-02-07T05:50:22.302395Z","shell.execute_reply":"2022-02-07T05:50:22.35628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test=pd.read_csv('../input/nlp-getting-started/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.358402Z","iopub.execute_input":"2022-02-07T05:50:22.358873Z","iopub.status.idle":"2022-02-07T05:50:22.386427Z","shell.execute_reply.started":"2022-02-07T05:50:22.358837Z","shell.execute_reply":"2022-02-07T05:50:22.385752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.387549Z","iopub.execute_input":"2022-02-07T05:50:22.387797Z","iopub.status.idle":"2022-02-07T05:50:22.408464Z","shell.execute_reply.started":"2022-02-07T05:50:22.387763Z","shell.execute_reply":"2022-02-07T05:50:22.407758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.410671Z","iopub.execute_input":"2022-02-07T05:50:22.410931Z","iopub.status.idle":"2022-02-07T05:50:22.421149Z","shell.execute_reply.started":"2022-02-07T05:50:22.410899Z","shell.execute_reply":"2022-02-07T05:50:22.420266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# checking target value when location not null","metadata":{}},{"cell_type":"code","source":"train_df[train_df.location.notnull()].target.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.422661Z","iopub.execute_input":"2022-02-07T05:50:22.423168Z","iopub.status.idle":"2022-02-07T05:50:22.437508Z","shell.execute_reply.started":"2022-02-07T05:50:22.423132Z","shell.execute_reply":"2022-02-07T05:50:22.436857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Knowing more about Location column","metadata":{}},{"cell_type":"code","source":"train_df[train_df.location.notnull()].location.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.438609Z","iopub.execute_input":"2022-02-07T05:50:22.439231Z","iopub.status.idle":"2022-02-07T05:50:22.451625Z","shell.execute_reply.started":"2022-02-07T05:50:22.439199Z","shell.execute_reply":"2022-02-07T05:50:22.450762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Too much data for only one location and data might get biased","metadata":{}},{"cell_type":"markdown","source":"# Dropping location column","metadata":{}},{"cell_type":"code","source":"train_df = train_df[['id','keyword','text','target']]","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.452558Z","iopub.execute_input":"2022-02-07T05:50:22.454212Z","iopub.status.idle":"2022-02-07T05:50:22.460354Z","shell.execute_reply.started":"2022-02-07T05:50:22.454169Z","shell.execute_reply":"2022-02-07T05:50:22.459419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = df_test[['id', 'keyword', 'text']]","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.461592Z","iopub.execute_input":"2022-02-07T05:50:22.462308Z","iopub.status.idle":"2022-02-07T05:50:22.470911Z","shell.execute_reply.started":"2022-02-07T05:50:22.462217Z","shell.execute_reply":"2022-02-07T05:50:22.470189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.472426Z","iopub.execute_input":"2022-02-07T05:50:22.4729Z","iopub.status.idle":"2022-02-07T05:50:22.484958Z","shell.execute_reply.started":"2022-02-07T05:50:22.472864Z","shell.execute_reply":"2022-02-07T05:50:22.484043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.486286Z","iopub.execute_input":"2022-02-07T05:50:22.486767Z","iopub.status.idle":"2022-02-07T05:50:22.496478Z","shell.execute_reply.started":"2022-02-07T05:50:22.486729Z","shell.execute_reply":"2022-02-07T05:50:22.49577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Handling other null values column","metadata":{}},{"cell_type":"code","source":"train_df['keyword'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.49817Z","iopub.execute_input":"2022-02-07T05:50:22.498447Z","iopub.status.idle":"2022-02-07T05:50:22.509462Z","shell.execute_reply.started":"2022-02-07T05:50:22.498414Z","shell.execute_reply":"2022-02-07T05:50:22.50867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dropping rest null values from the","metadata":{}},{"cell_type":"code","source":"# train_df.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.510918Z","iopub.execute_input":"2022-02-07T05:50:22.51141Z","iopub.status.idle":"2022-02-07T05:50:22.517362Z","shell.execute_reply.started":"2022-02-07T05:50:22.511376Z","shell.execute_reply":"2022-02-07T05:50:22.516575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.522579Z","iopub.execute_input":"2022-02-07T05:50:22.523143Z","iopub.status.idle":"2022-02-07T05:50:22.532688Z","shell.execute_reply.started":"2022-02-07T05:50:22.523079Z","shell.execute_reply":"2022-02-07T05:50:22.531839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Know more about target and text column","metadata":{}},{"cell_type":"code","source":"train_df['text'].iloc[5]","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.533976Z","iopub.execute_input":"2022-02-07T05:50:22.534405Z","iopub.status.idle":"2022-02-07T05:50:22.539742Z","shell.execute_reply.started":"2022-02-07T05:50:22.534372Z","shell.execute_reply":"2022-02-07T05:50:22.539017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['text'].iloc[1]","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.541115Z","iopub.execute_input":"2022-02-07T05:50:22.541534Z","iopub.status.idle":"2022-02-07T05:50:22.549101Z","shell.execute_reply.started":"2022-02-07T05:50:22.5415Z","shell.execute_reply":"2022-02-07T05:50:22.548379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.550486Z","iopub.execute_input":"2022-02-07T05:50:22.550878Z","iopub.status.idle":"2022-02-07T05:50:22.559617Z","shell.execute_reply.started":"2022-02-07T05:50:22.550841Z","shell.execute_reply":"2022-02-07T05:50:22.558792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pre-processing text","metadata":{}},{"cell_type":"markdown","source":"### Removing url","metadata":{}},{"cell_type":"code","source":"import re","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.561177Z","iopub.execute_input":"2022-02-07T05:50:22.561728Z","iopub.status.idle":"2022-02-07T05:50:22.566426Z","shell.execute_reply.started":"2022-02-07T05:50:22.561647Z","shell.execute_reply":"2022-02-07T05:50:22.565166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_URL(text):\n    url = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url.sub(r'',text)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.567393Z","iopub.execute_input":"2022-02-07T05:50:22.568237Z","iopub.status.idle":"2022-02-07T05:50:22.573941Z","shell.execute_reply.started":"2022-02-07T05:50:22.568193Z","shell.execute_reply":"2022-02-07T05:50:22.573198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['text'] = train_df['text'].apply(lambda x : remove_URL(x))","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.575545Z","iopub.execute_input":"2022-02-07T05:50:22.575928Z","iopub.status.idle":"2022-02-07T05:50:22.613138Z","shell.execute_reply.started":"2022-02-07T05:50:22.575889Z","shell.execute_reply":"2022-02-07T05:50:22.612511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['text'] = df_test['text'].apply(lambda x : remove_URL(x))","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.615578Z","iopub.execute_input":"2022-02-07T05:50:22.615757Z","iopub.status.idle":"2022-02-07T05:50:22.63463Z","shell.execute_reply.started":"2022-02-07T05:50:22.615735Z","shell.execute_reply":"2022-02-07T05:50:22.634044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Removing HTML tags","metadata":{}},{"cell_type":"code","source":"example = \"\"\"<div>\n<h1>Real or Fake</h1>\n<p>Kaggle </p>\n<a href=\"https://www.kaggle.com/c/nlp-getting-started\">getting started</a>\n</div>\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.635676Z","iopub.execute_input":"2022-02-07T05:50:22.637248Z","iopub.status.idle":"2022-02-07T05:50:22.641636Z","shell.execute_reply.started":"2022-02-07T05:50:22.637212Z","shell.execute_reply":"2022-02-07T05:50:22.640897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_html(text):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',text)\n    \nprint(remove_html(example))","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.643058Z","iopub.execute_input":"2022-02-07T05:50:22.643633Z","iopub.status.idle":"2022-02-07T05:50:22.651329Z","shell.execute_reply.started":"2022-02-07T05:50:22.643597Z","shell.execute_reply":"2022-02-07T05:50:22.650423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['text'] = train_df['text'].apply(lambda x : remove_html(x))","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.652763Z","iopub.execute_input":"2022-02-07T05:50:22.653413Z","iopub.status.idle":"2022-02-07T05:50:22.671681Z","shell.execute_reply.started":"2022-02-07T05:50:22.653305Z","shell.execute_reply":"2022-02-07T05:50:22.670911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['text'] = df_test['text'].apply(lambda x : remove_html(x))","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.67311Z","iopub.execute_input":"2022-02-07T05:50:22.67365Z","iopub.status.idle":"2022-02-07T05:50:22.685323Z","shell.execute_reply.started":"2022-02-07T05:50:22.673615Z","shell.execute_reply":"2022-02-07T05:50:22.684658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Removing emoji's","metadata":{}},{"cell_type":"code","source":"# Reference : https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b\ndef remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)\n\nremove_emoji(\"Omg another Earthquake üòîüòî\")","metadata":{"execution":{"iopub.status.busy":"2022-02-07T06:32:35.213037Z","iopub.execute_input":"2022-02-07T06:32:35.21375Z","iopub.status.idle":"2022-02-07T06:32:35.220621Z","shell.execute_reply.started":"2022-02-07T06:32:35.213707Z","shell.execute_reply":"2022-02-07T06:32:35.219955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['text'] = train_df['text'].apply(lambda x: remove_emoji(x))","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.702486Z","iopub.execute_input":"2022-02-07T05:50:22.703027Z","iopub.status.idle":"2022-02-07T05:50:22.76116Z","shell.execute_reply.started":"2022-02-07T05:50:22.702989Z","shell.execute_reply":"2022-02-07T05:50:22.760537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['text'] = df_test['text'].apply(lambda x: remove_emoji(x))","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.762289Z","iopub.execute_input":"2022-02-07T05:50:22.762656Z","iopub.status.idle":"2022-02-07T05:50:22.790409Z","shell.execute_reply.started":"2022-02-07T05:50:22.762623Z","shell.execute_reply":"2022-02-07T05:50:22.789778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Contractions and acronyms","metadata":{}},{"cell_type":"code","source":"def cleaner(tweet):\n  # Acronyms and miswritten words\n  tweet = re.sub(r\"Typhoon-Devastated\", \"typhoon devastated\", tweet)\n  tweet = re.sub(r\"TyphoonDevastated\", \"typhoon devastated\", tweet)\n  tweet = re.sub(r\"typhoondevastated\", \"typhoon devastated\", tweet)\n  tweet = re.sub(r\"MH370\", \"Malaysia Airlines Flight\", tweet)\n  tweet = re.sub(r\"MH\", \"Malaysia Airlines Flight\", tweet)\n  tweet = re.sub(r\"mh370\", \"Malaysia Airlines Flight\", tweet)\n  tweet = re.sub(r\"year-old\", \"years old\", tweet)\n  tweet = re.sub(r\"yearold\", \"years old\", tweet)\n  tweet = re.sub(r\"yr old\", \"years old\", tweet)\n  tweet = re.sub(r\"PKK\", \"Kurdistan Workers Party\", tweet)\n  tweet = re.sub(r\"MP\", \"madhya pradesh\", tweet)\n  tweet = re.sub(r\"rly\", \"railway\", tweet)\n  tweet = re.sub(r\"CDT\", \"Central Daylight Time\", tweet)\n  tweet = re.sub(r\"sensorsenso\", \"sensor senso\", tweet)\n  tweet = re.sub(r\"pm\", \"\", tweet)\n  tweet = re.sub(r\"PM\", \"\", tweet)\n  tweet = re.sub(r\"nan\", \" \", tweet)\n  tweet = re.sub(r\"terrorismturn\", \"terrorism turn\", tweet)\n  tweet = re.sub(r\"epicente\", \"epicenter\", tweet)\n  tweet = re.sub(r\"epicenterr\", \"epicenter\", tweet)\n  tweet = re.sub(r\"WAwildfire\", \"Washington Wildfire\", tweet)\n  tweet = re.sub(r\"prebreak\", \"pre break\", tweet)\n  tweet = re.sub(r\"nowplaying\", \"now playing\", tweet)\n  tweet = re.sub(r\"RT\", \"retweet\", tweet)\n  tweet = re.sub(r\"EbolaOutbreak\", \"Ebola Outbreak\", tweet)\n  tweet = re.sub(r\"LondonFire\", \"London Fire\", tweet)\n  tweet = re.sub(r\"IDFire\", \"Idaho Fire\", tweet)\n  tweet = re.sub(r\"withBioterrorism&use\", \"with Bioterrorism & use\", tweet)\n  tweet = re.sub(r\"NASAHurricane\", \"NASA Hurricane\", tweet)\n  tweet = re.sub(r\"withweapons\", \"with weapons\", tweet)\n  tweet = re.sub(r\"NuclearPower\", \"Nuclear Power\", tweet)\n  tweet = re.sub(r\"WhiteTerrorism\", \"White Terrorism\", tweet)\n  tweet = re.sub(r\"MyanmarFlood\", \"Myanmar Flood\", tweet)\n  tweet = re.sub(r\"ExtremeWeather\", \"Extreme Weather\", tweet)\n\n  # Special characters\n  tweet = re.sub(r\"%20\", \" \", tweet)\n  tweet = re.sub(r\"%\", \" \", tweet)\n  tweet = re.sub(r\"@\", \" \", tweet)\n  tweet = re.sub(r\"#\", \" \", tweet)\n  tweet = re.sub(r\"'\", \" \", tweet)\n  tweet = re.sub(r\"\\x89√ª_\", \" \", tweet)\n  tweet = re.sub(r\"\\x89√ª√≤\", \" \", tweet)\n  tweet = re.sub(r\"16yr\", \"16 year\", tweet)\n  tweet = re.sub(r\"re\\x89√ª_\", \" \", tweet)\n  tweet = re.sub(r\"\\x89√ª\", \" \", tweet)\n  tweet = re.sub(r\"\\x89√õ\", \" \", tweet)\n  tweet = re.sub(r\"re\\x89√õ\", \"re \", tweet)\n  tweet = re.sub(r\"re\\x89√ª\", \"re \", tweet)\n  tweet = re.sub(r\"\\x89√ª¬™\", \"'\", tweet)\n  tweet = re.sub(r\"\\x89√ª\", \" \", tweet)\n  tweet = re.sub(r\"\\x89√ª√≤\", \" \", tweet)\n  tweet = re.sub(r\"\\x89√õ_\", \"\", tweet)\n  tweet = re.sub(r\"\\x89√õ√í\", \"\", tweet)\n  tweet = re.sub(r\"\\x89√õ√ì\", \"\", tweet)\n  tweet = re.sub(r\"\\x89√õ√èWhen\", \"When\", tweet)\n  tweet = re.sub(r\"\\x89√õ√è\", \"\", tweet)\n  tweet = re.sub(r\"China\\x89√õ¬™s\", \"China's\", tweet)\n  tweet = re.sub(r\"let\\x89√õ¬™s\", \"let's\", tweet)\n  tweet = re.sub(r\"\\x89√õ√∑\", \"\", tweet)\n  tweet = re.sub(r\"\\x89√õ¬™\", \"\", tweet)\n  tweet = re.sub(r\"\\x89√õ\\x9d\", \"\", tweet)\n  tweet = re.sub(r\"√•_\", \"\", tweet)\n  tweet = re.sub(r\"\\x89√õ¬¢\", \"\", tweet)\n  tweet = re.sub(r\"\\x89√õ¬¢√•√ä\", \"\", tweet)\n  tweet = re.sub(r\"from√•√äwounds\", \"from wounds\", tweet)\n  tweet = re.sub(r\"√•√ä\", \"\", tweet)\n  tweet = re.sub(r\"√•√à\", \"\", tweet)\n  tweet = re.sub(r\"Jap√å_n\", \"Japan\", tweet)    \n  tweet = re.sub(r\"√å¬©\", \"e\", tweet)\n  tweet = re.sub(r\"√•¬®\", \"\", tweet)\n  tweet = re.sub(r\"Suru√å¬§\", \"Suruc\", tweet)\n  tweet = re.sub(r\"√•√á\", \"\", tweet)\n  tweet = re.sub(r\"√•¬£3million\", \"3 million\", tweet)\n  tweet = re.sub(r\"√•√Ä\", \"\", tweet)\n\n  # Contractions\n  tweet = re.sub(r\"he's\", \"he is\", tweet)\n  tweet = re.sub(r\"there's\", \"there is\", tweet)\n  tweet = re.sub(r\"We're\", \"We are\", tweet)\n  tweet = re.sub(r\"That's\", \"That is\", tweet)\n  tweet = re.sub(r\"won't\", \"will not\", tweet)\n  tweet = re.sub(r\"they're\", \"they are\", tweet)\n  tweet = re.sub(r\"Can't\", \"Cannot\", tweet)\n  tweet = re.sub(r\"wasn't\", \"was not\", tweet)\n  tweet = re.sub(r\"don\\x89√õ¬™t\", \"do not\", tweet)\n  tweet = re.sub(r\"aren't\", \"are not\", tweet)\n  tweet = re.sub(r\"isn't\", \"is not\", tweet)\n  tweet = re.sub(r\"What's\", \"What is\", tweet)\n  tweet = re.sub(r\"haven't\", \"have not\", tweet)\n  tweet = re.sub(r\"hasn't\", \"has not\", tweet)\n  tweet = re.sub(r\"There's\", \"There is\", tweet)\n  tweet = re.sub(r\"He's\", \"He is\", tweet)\n  tweet = re.sub(r\"It's\", \"It is\", tweet)\n  tweet = re.sub(r\"You're\", \"You are\", tweet)\n  tweet = re.sub(r\"I'M\", \"I am\", tweet)\n  tweet = re.sub(r\"Im\", \"I am\", tweet)\n  tweet = re.sub(r\"shouldn't\", \"should not\", tweet)\n  tweet = re.sub(r\"wouldn't\", \"would not\", tweet)\n  tweet = re.sub(r\"i'm\", \"I am\", tweet)\n  tweet = re.sub(r\"I\\x89√õ¬™m\", \"I am\", tweet)\n  tweet = re.sub(r\"I'm\", \"I am\", tweet)\n  tweet = re.sub(r\"Isn't\", \"is not\", tweet)\n  tweet = re.sub(r\"Here's\", \"Here is\", tweet)\n  tweet = re.sub(r\"you've\", \"you have\", tweet)\n  tweet = re.sub(r\"you\\x89√õ¬™ve\", \"you have\", tweet)\n  tweet = re.sub(r\"we're\", \"we are\", tweet)\n  tweet = re.sub(r\"what's\", \"what is\", tweet)\n  tweet = re.sub(r\"couldn't\", \"could not\", tweet)\n  tweet = re.sub(r\"we've\", \"we have\", tweet)\n  tweet = re.sub(r\"it\\x89√õ¬™s\", \"it is\", tweet)\n  tweet = re.sub(r\"doesn\\x89√õ¬™t\", \"does not\", tweet)\n  tweet = re.sub(r\"It\\x89√õ¬™s\", \"It is\", tweet)\n  tweet = re.sub(r\"Here\\x89√õ¬™s\", \"Here is\", tweet)\n  tweet = re.sub(r\"who's\", \"who is\", tweet)\n  tweet = re.sub(r\"I\\x89√õ¬™ve\", \"I have\", tweet)\n  tweet = re.sub(r\"y'all\", \"you all\", tweet)\n  tweet = re.sub(r\"can\\x89√õ¬™t\", \"cannot\", tweet)\n  tweet = re.sub(r\"would've\", \"would have\", tweet)\n  tweet = re.sub(r\"it'll\", \"it will\", tweet)\n  tweet = re.sub(r\"we'll\", \"we will\", tweet)\n  tweet = re.sub(r\"wouldn\\x89√õ¬™t\", \"would not\", tweet)\n  tweet = re.sub(r\"We've\", \"We have\", tweet)\n  tweet = re.sub(r\"he'll\", \"he will\", tweet)\n  tweet = re.sub(r\"Y'all\", \"You all\", tweet)\n  tweet = re.sub(r\"Weren't\", \"Were not\", tweet)\n  tweet = re.sub(r\"Didn't\", \"Did not\", tweet)\n  tweet = re.sub(r\"they'll\", \"they will\", tweet)\n  tweet = re.sub(r\"they'd\", \"they would\", tweet)\n  tweet = re.sub(r\"DON'T\", \"DO NOT\", tweet)\n  tweet = re.sub(r\"That\\x89√õ¬™s\", \"That is\", tweet)\n  tweet = re.sub(r\"they've\", \"they have\", tweet)\n  tweet = re.sub(r\"i'd\", \"I would\", tweet)\n  tweet = re.sub(r\"should've\", \"should have\", tweet)\n  tweet = re.sub(r\"You\\x89√õ¬™re\", \"You are\", tweet)\n  tweet = re.sub(r\"where's\", \"where is\", tweet)\n  tweet = re.sub(r\"Don\\x89√õ¬™t\", \"Do not\", tweet)\n  tweet = re.sub(r\"we'd\", \"we would\", tweet)\n  tweet = re.sub(r\"i'll\", \"I will\", tweet)\n  tweet = re.sub(r\"weren't\", \"were not\", tweet)\n  tweet = re.sub(r\"They're\", \"They are\", tweet)\n  tweet = re.sub(r\"Can\\x89√õ¬™t\", \"Cannot\", tweet)\n  tweet = re.sub(r\"you\\x89√õ¬™ll\", \"you will\", tweet)\n  tweet = re.sub(r\"I\\x89√õ¬™d\", \"I would\", tweet)\n  tweet = re.sub(r\"let's\", \"let us\", tweet)\n  tweet = re.sub(r\"it's\", \"it is\", tweet)\n  tweet = re.sub(r\"can't\", \"can not\", tweet)\n  tweet = re.sub(r\"cant\", \"can not\", tweet)\n  tweet = re.sub(r\"don't\", \"do not\", tweet)\n  tweet = re.sub(r\"dont\", \"do not\", tweet)\n  tweet = re.sub(r\"you're\", \"you are\", tweet)\n  tweet = re.sub(r\"i've\", \"I have\", tweet)\n  tweet = re.sub(r\"that's\", \"that is\", tweet)\n  tweet = re.sub(r\"i'll\", \"I will\", tweet)\n  tweet = re.sub(r\"doesn't\", \"does not\", tweet)\n  tweet = re.sub(r\"i'd\", \"I would\", tweet)\n  tweet = re.sub(r\"didn't\", \"did not\", tweet)\n  tweet = re.sub(r\"ain't\", \"am not\", tweet)\n  tweet = re.sub(r\"you'll\", \"you will\", tweet)\n  tweet = re.sub(r\"I've\", \"I have\", tweet)\n  tweet = re.sub(r\"Don't\", \"do not\", tweet)\n  tweet = re.sub(r\"I'll\", \"I will\", tweet)\n  tweet = re.sub(r\"I'd\", \"I would\", tweet)\n  tweet = re.sub(r\"Let's\", \"Let us\", tweet)\n  tweet = re.sub(r\"you'd\", \"You would\", tweet)\n  tweet = re.sub(r\"It's\", \"It is\", tweet)\n  tweet = re.sub(r\"Ain't\", \"am not\", tweet)\n  tweet = re.sub(r\"Haven't\", \"Have not\", tweet)\n  tweet = re.sub(r\"Could've\", \"Could have\", tweet)\n  tweet = re.sub(r\"youve\", \"you have\", tweet)  \n  tweet = re.sub(r\"don√•¬´t\", \"do not\", tweet)\n\n  return tweet","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.792234Z","iopub.execute_input":"2022-02-07T05:50:22.792591Z","iopub.status.idle":"2022-02-07T05:50:22.840605Z","shell.execute_reply.started":"2022-02-07T05:50:22.792558Z","shell.execute_reply":"2022-02-07T05:50:22.839551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['text'] = train_df['text'].apply(lambda s : cleaner(s))","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:22.841984Z","iopub.execute_input":"2022-02-07T05:50:22.842481Z","iopub.status.idle":"2022-02-07T05:50:24.263512Z","shell.execute_reply.started":"2022-02-07T05:50:22.842444Z","shell.execute_reply":"2022-02-07T05:50:24.262771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['text'] = df_test['text'].apply(lambda s : cleaner(s))","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:24.264937Z","iopub.execute_input":"2022-02-07T05:50:24.265344Z","iopub.status.idle":"2022-02-07T05:50:24.895853Z","shell.execute_reply.started":"2022-02-07T05:50:24.265308Z","shell.execute_reply":"2022-02-07T05:50:24.895129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Removing punctuations","metadata":{}},{"cell_type":"code","source":"import string","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:24.897897Z","iopub.execute_input":"2022-02-07T05:50:24.898298Z","iopub.status.idle":"2022-02-07T05:50:24.903006Z","shell.execute_reply.started":"2022-02-07T05:50:24.898261Z","shell.execute_reply":"2022-02-07T05:50:24.902189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_punct(text):\n    table=str.maketrans('','',string.punctuation)\n    return text.translate(table)\n\nexample=\"I am a #king\"\nprint(remove_punct(example))","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:24.904581Z","iopub.execute_input":"2022-02-07T05:50:24.904959Z","iopub.status.idle":"2022-02-07T05:50:24.913525Z","shell.execute_reply.started":"2022-02-07T05:50:24.904885Z","shell.execute_reply":"2022-02-07T05:50:24.912835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['text']= train_df['text'].apply(lambda x : remove_punct(x))","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:24.914494Z","iopub.execute_input":"2022-02-07T05:50:24.915162Z","iopub.status.idle":"2022-02-07T05:50:24.960385Z","shell.execute_reply.started":"2022-02-07T05:50:24.915126Z","shell.execute_reply":"2022-02-07T05:50:24.959777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['text']= df_test['text'].apply(lambda x : remove_punct(x))","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:24.96136Z","iopub.execute_input":"2022-02-07T05:50:24.961717Z","iopub.status.idle":"2022-02-07T05:50:24.983374Z","shell.execute_reply.started":"2022-02-07T05:50:24.961684Z","shell.execute_reply":"2022-02-07T05:50:24.982738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Removing multiple spaces","metadata":{}},{"cell_type":"code","source":"train_df['text'] = train_df['text'].str.replace('   ', ' ')\ntrain_df['text'] = train_df['text'].str.replace('     ', ' ')\ntrain_df['text'] = train_df['text'].str.replace('\\xa0 \\xa0 \\xa0', ' ')\ntrain_df['text'] = train_df['text'].str.replace('  ', ' ')\ntrain_df['text'] = train_df['text'].str.replace('‚Äî', ' ')\ntrain_df['text'] = train_df['text'].str.replace('‚Äì', ' ')","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:24.984715Z","iopub.execute_input":"2022-02-07T05:50:24.98502Z","iopub.status.idle":"2022-02-07T05:50:25.03464Z","shell.execute_reply.started":"2022-02-07T05:50:24.984966Z","shell.execute_reply":"2022-02-07T05:50:25.033955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['text'] = df_test['text'].str.replace('   ', ' ')\ndf_test['text'] = df_test['text'].str.replace('     ', ' ')\ndf_test['text'] = df_test['text'].str.replace('\\xa0 \\xa0 \\xa0', ' ')\ndf_test['text'] = df_test['text'].str.replace('  ', ' ')\ndf_test['text'] = df_test['text'].str.replace('‚Äî', ' ')\ndf_test['text'] = df_test['text'].str.replace('‚Äì', ' ')","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:25.035921Z","iopub.execute_input":"2022-02-07T05:50:25.036174Z","iopub.status.idle":"2022-02-07T05:50:25.147186Z","shell.execute_reply.started":"2022-02-07T05:50:25.036142Z","shell.execute_reply":"2022-02-07T05:50:25.146467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Select required columns\ndata = train_df[['text', 'target']]\n\n# Set your model output as categorical and save in new label col\ndata['target_label'] = pd.Categorical(train_df['target'])\n\n# Transform your output to numeric\ndata['target'] = data['target_label'].cat.codes","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:25.148847Z","iopub.execute_input":"2022-02-07T05:50:25.149393Z","iopub.status.idle":"2022-02-07T05:50:25.159762Z","shell.execute_reply.started":"2022-02-07T05:50:25.149356Z","shell.execute_reply":"2022-02-07T05:50:25.158998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading transformer","metadata":{}},{"cell_type":"code","source":"from transformers import RobertaTokenizer, TFRobertaModel, RobertaConfig \nfrom tensorflow.keras.layers import Input, Dropout, Dense\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.initializers import TruncatedNormal\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.metrics import CategoricalAccuracy\nfrom tensorflow.keras.utils import to_categorical\nimport tensorflow as tf\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:50:25.161216Z","iopub.execute_input":"2022-02-07T05:50:25.161674Z","iopub.status.idle":"2022-02-07T05:50:32.580028Z","shell.execute_reply.started":"2022-02-07T05:50:25.161619Z","shell.execute_reply":"2022-02-07T05:50:32.579199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### --------- Setup Roberta ---------- ###\n\nmodel_name = 'roberta-base'\n\n# Max length of tokens\nmax_length = 45\n\n# Load transformers config and set output_hidden_states to False\nconfig = RobertaConfig.from_pretrained(model_name)\nconfig.output_hidden_states = False\n\n# Load Roberta tokenizer\ntokenizer = RobertaTokenizer.from_pretrained(pretrained_model_name_or_path = model_name, config = config)\n\n# Load the Roberta model\ntransformer_roberta_model = TFRobertaModel.from_pretrained(model_name, config = config)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T06:26:35.035669Z","iopub.execute_input":"2022-02-07T06:26:35.035948Z","iopub.status.idle":"2022-02-07T06:26:39.902856Z","shell.execute_reply.started":"2022-02-07T06:26:35.035917Z","shell.execute_reply":"2022-02-07T06:26:39.902193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Adding more layers","metadata":{}},{"cell_type":"code","source":"### ------- Build the model ------- ###\n\n# Load the MainLayer\nroberta = transformer_roberta_model.layers[0]\n\n# Build your model input\ninput_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\ninputs = {'input_ids': input_ids}\n\n# Load the Transformers RoBERTa model as a layer in a Keras model\nroberta_model = roberta(inputs)[1]\ndropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\npooled_output = dropout(roberta_model, training=False)\n\ndropout_1 = Dropout(config.hidden_dropout_prob, name='pooled_output_1')\npooled_output_1 = dropout(pooled_output, training=False)\n\n# Then build your model output\ntargets = Dense(units=len(data.target_label.value_counts()), kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='target')(pooled_output_1)\noutputs = {'target': targets}\n\n# And combine it all in a model object\nmodel2 = Model(inputs=inputs, outputs=outputs, name='RoBERTa_Binary_Classifier')\n\n# Take a look at the model\nmodel2.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T06:36:03.927802Z","iopub.execute_input":"2022-02-07T06:36:03.928062Z","iopub.status.idle":"2022-02-07T06:36:05.493503Z","shell.execute_reply.started":"2022-02-07T06:36:03.928033Z","shell.execute_reply":"2022-02-07T06:36:05.492799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fine tunning RoBERTa-Base","metadata":{}},{"cell_type":"code","source":"### ------- Train the model ------- ###\n\noptimizer = Adam(learning_rate=6e-05,epsilon=1e-08,decay=0.01,clipnorm=1.0)\n\n# Set loss and metrics\nloss = {'target': CategoricalCrossentropy(from_logits = True)}\n\n# Compile the model\nmodel2.compile(optimizer = optimizer, loss = loss, metrics = ['accuracy'])\n\n# Ready output data for the model\ny_target = to_categorical(data['target'])\n\n# Tokenize the input (takes some time)\nx_train = tokenizer(\n            text=data['text'].to_list(),\n            add_special_tokens=True,\n            max_length=max_length,\n            truncation=True,\n            padding=True, \n            return_tensors='tf',\n            return_token_type_ids = False,\n            return_attention_mask = True,\n            verbose = True)\n\n# Fit the model\nhistory = model2.fit(\n    x={'input_ids': x_train['input_ids']},\n    y={'target': y_target},\n    validation_split=0.25,\n    batch_size=64,\n    epochs=10,\n    verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T06:36:39.065322Z","iopub.execute_input":"2022-02-07T06:36:39.065802Z","iopub.status.idle":"2022-02-07T06:43:20.264135Z","shell.execute_reply.started":"2022-02-07T06:36:39.065767Z","shell.execute_reply":"2022-02-07T06:43:20.263355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"x_test = tokenizer(\n          text=df_test['text'].to_list(),\n          add_special_tokens=True,\n          max_length=max_length,\n          truncation=True,\n          padding=True, \n          return_tensors='tf',\n          return_token_type_ids = False,\n          return_attention_mask = True,\n          verbose = True)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:51:34.367944Z","iopub.status.idle":"2022-02-07T05:51:34.368419Z","shell.execute_reply.started":"2022-02-07T05:51:34.368163Z","shell.execute_reply":"2022-02-07T05:51:34.368189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_predicted = model2.predict(\n    x={'input_ids': x_test['input_ids']},\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:51:34.369984Z","iopub.status.idle":"2022-02-07T05:51:34.370421Z","shell.execute_reply.started":"2022-02-07T05:51:34.370189Z","shell.execute_reply":"2022-02-07T05:51:34.370213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_predicted['target']","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:51:34.371781Z","iopub.status.idle":"2022-02-07T05:51:34.372206Z","shell.execute_reply.started":"2022-02-07T05:51:34.371968Z","shell.execute_reply":"2022-02-07T05:51:34.37199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_pred_max=[np.argmax(i) for i in label_predicted['target']]","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:51:34.373636Z","iopub.status.idle":"2022-02-07T05:51:34.374063Z","shell.execute_reply.started":"2022-02-07T05:51:34.373836Z","shell.execute_reply":"2022-02-07T05:51:34.373858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_pred_max[:10]","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:51:34.375346Z","iopub.status.idle":"2022-02-07T05:51:34.376012Z","shell.execute_reply.started":"2022-02-07T05:51:34.375772Z","shell.execute_reply":"2022-02-07T05:51:34.375799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:51:34.377309Z","iopub.status.idle":"2022-02-07T05:51:34.377707Z","shell.execute_reply.started":"2022-02-07T05:51:34.377489Z","shell.execute_reply":"2022-02-07T05:51:34.377511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(label_pred_max)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:51:34.378863Z","iopub.status.idle":"2022-02-07T05:51:34.379652Z","shell.execute_reply.started":"2022-02-07T05:51:34.379413Z","shell.execute_reply":"2022-02-07T05:51:34.379438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.id","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:51:34.380886Z","iopub.status.idle":"2022-02-07T05:51:34.38165Z","shell.execute_reply.started":"2022-02-07T05:51:34.381405Z","shell.execute_reply":"2022-02-07T05:51:34.38143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = pd.DataFrame({'id': df_test.id,\n                       'target': label_pred_max})\noutput.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T05:51:34.382732Z","iopub.status.idle":"2022-02-07T05:51:34.38333Z","shell.execute_reply.started":"2022-02-07T05:51:34.383099Z","shell.execute_reply":"2022-02-07T05:51:34.383122Z"},"trusted":true},"execution_count":null,"outputs":[]}]}