{"cells":[{"metadata":{},"cell_type":"markdown","source":"**The Objective of this kernel is to get you on your feet. I would be using Logisitic Regression to create a basic baseline prediction model. Once we have that in place we would be doing some basic data cleaning and applying SVM,Naive Bayes to the data.**\n\nWould be adding - data visualization , feature engineering steps in the future."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport warnings; warnings.simplefilter('ignore')\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\npd.set_option('display.width',1000000)\npd.set_option('display.max_columns', 500)\n\nscore_df = pd.DataFrame(columns={'Model Description','Score'})\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1. Loading data set **"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train= pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')\ndf_test=pd.read_csv('/kaggle/input/nlp-getting-started/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**2. Let's take initial look at the data **"},{"metadata":{"trusted":true},"cell_type":"code","source":" print(df_train.head(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check for Null/NAN Values"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train.isnull().any())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_test.isnull().any())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Exploring the data distribution of tweets"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfrom matplotlib import pyplot as plt\n\nfig, axes = plt.subplots(ncols=2, figsize=(17, 4), dpi=100)\nplt.tight_layout()\n\nlabels=['Disaster Tweet','No Disaster']\nsize=  [df_train['target'].mean()*100,abs(1-df_train['target'].mean())*100]\nexplode = (0, 0.1)\n#ig1,ax1 = plt.subplots()\naxes[0].pie(size,labels=labels,explode=explode,shadow=True,\n            startangle=90,autopct='%1.1f%%')\nsns.countplot(x=df_train['target'], hue=df_train['target'], ax=axes[1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before analyzing the data further would be nice to have a baseline model driven off just the tweet Text and TFIDF transformer. once we have some baseling we would look at some more visualization and feature engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nX_train,X_test,y_train,y_test = train_test_split(df_train['text'],df_train['target'])\nvector = TfidfVectorizer().fit(X_train)\n\n#print(vector.get_feature_names())\nX_train_vector = vector.transform(X_train)\nX_test_vector = vector.transform(X_test)\n\nmodel = LogisticRegression().fit(X_train_vector,y_train)\nprint('Logistic Regression ROC Auc Score with TFIDF - %3f'%(roc_auc_score(y_test,model.predict(X_test_vector))))\nprint('F1Score - %3f'%(f1_score(y_test,model.predict(X_test_vector))))\nscore_df = score_df.append({'Model Description':'Basic LR Model - Basline - TFIDF',\n                           'Score':roc_auc_score(y_test,model.predict(X_test_vector))}\n                           ,ignore_index=True)\n\n####### Now let's try with count vectorizer\n\ncv_vector = CountVectorizer().fit(X_train)\nX_train_vector = cv_vector.transform(X_train)\nX_test_vector = cv_vector.transform(X_test)\n\nmodel = LogisticRegression().fit(X_train_vector,y_train)\npredict = model.predict(X_test_vector)\nscore = roc_auc_score(y_test,predict)\nprint('Logistic Regression Roc AUC Score with countvectorizer - %3f'%score)\n\nscore_df = score_df.append({'Model Description':'Basic LR Model - Basline - CV',\n                          'Score':score}\n                          ,ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**3. Clean Data**  - So we have a baseline score of 79% to work with , let's get to clean data and see if we can improve the score\n\nAs first step in cleaning - let us replace some commonly occuring shorthands "},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef clean_text(text):\n    import re\n    text = text.lower()\n    text = re.sub(r\"i'm\", \"i am\", text)\n    text = re.sub(r\"you'll\", \"you will\", text)\n    text = re.sub(r\"i'll\", \"i will\", text)\n    text = re.sub(r\"she'll\", \"she will\", text)\n    text = re.sub(r\"he'll\", \"he will\", text)\n    text = re.sub(r\"he's\", \"he is\", text)\n    text = re.sub(r\"she's\", \"she is\", text)\n    text = re.sub(r\"that's\", \"that is\", text)\n    text = re.sub(r\"what's\", \"what is\", text)\n    text = re.sub(r\"where's\", \"where is\", text)\n    text = re.sub(r\"there's\", \"there is\", text)\n    text = re.sub(r\"here's\", \"here is\", text)\n    text = re.sub(r\"who's\", \"who is\", text)\n    text = re.sub(r\"how's\", \"how is\", text)\n    text = re.sub(r\"\\'ll\", \" will\", text)\n    text = re.sub(r\"\\'ve\", \" have\", text)\n    text = re.sub(r\"\\'re\", \" are\", text)\n    text = re.sub(r\"\\'d\", \" would\", text)\n    text = re.sub(r\"can't\", \"cannot\", text)\n    text = re.sub(r\"won't\", \"will not\", text)\n    text = re.sub(r\"don't\", \"do not\", text)\n    text = re.sub(r\"shouldn't\", \"should not\", text)\n    text = re.sub(r\"n't\", \" not\", text)\n    text = re.sub(r\"   \", \" \", text) # Remove any extra spaces\n    return text\n\n\ndf_train['clean_text'] = df_train['text'].apply(clean_text)\ndf_test['clean_text'] = df_test['text'].apply(clean_text)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the next step we are going to do some further massaging which would make Job of Prediction Algorithm easy\n\n* Let us remove any characters other then alphabets\n* Convert all dictionary to lower case - for consistency \n* Lemmatize - More details on Stemming and Lemmatization [here](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html)\n"},{"metadata":{},"cell_type":"markdown","source":"Also we are going to store this text in a seperate column as we want to keep the orignal text in case we want to do some feature engineering down the line."},{"metadata":{"trusted":true},"cell_type":"code","source":"def massage_text(text):\n    import re\n    from nltk.corpus import stopwords\n    ## remove anything other then characters and put everything in lowercase\n    tweet = re.sub(\"[^a-zA-Z]\", ' ', text)\n    tweet = tweet.lower()\n    tweet = tweet.split()\n\n    from nltk.stem import WordNetLemmatizer\n    lem = WordNetLemmatizer()\n    tweet = [lem.lemmatize(word) for word in tweet\n             if word not in set(stopwords.words('english'))]\n    tweet = ' '.join(tweet)\n    return tweet\n    print('--here goes nothing')\n    print(text)\n    print(tweet)\n\ndf_train['clean_text'] = df_train['text'].apply(massage_text)\ndf_test['clean_text'] = df_test['text'].apply(massage_text)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's take a look at the data now "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.iloc[0:10][['text','clean_text']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**4. Creation of more Models**"},{"metadata":{},"cell_type":"markdown","source":"4.1 Start by creating a Logistic Regression model again , this time we will use Grid Seach for hyper-parameter optimization"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\n\nvector = TfidfVectorizer().fit(df_train['clean_text'])\ndf_train_vector = vector.transform(df_train['clean_text'])\ndf_test_vector = vector.transform(df_test['clean_text'])\nlr_model = LogisticRegression()\ngrid_values =  {'penalty':['l1', 'l2'],'C':[0.01, 0.1, 1, 10, 100]}\ngrid_search_model = GridSearchCV(lr_model,param_grid=grid_values,cv=3)\ngrid_search_model.fit(df_train_vector,df_train['target'])\n\nprint(grid_search_model.best_estimator_)\nprint(grid_search_model.best_score_)\nprint(grid_search_model.best_params_)\n\n## dumping the output to a file \npredict_df = pd.DataFrame()\npredict = grid_search_model.predict(df_test_vector)\npredict_df['id'] = df_test['id']\npredict_df['target'] = predict\npredict_df.to_csv('sample_submission_2.csv', index=False)\nscore_df = score_df.append({'Model Description':'LR Model - with data cleaning and Grid Search',\n                           'Score':grid_search_model.best_score_}\n                           ,ignore_index=True)\n\n\n### let's have another model with some ngram's though \nX_train,X_test,y_train,y_test = train_test_split(df_train['clean_text'],df_train['target'])\nvector = TfidfVectorizer(ngram_range=(1,3)).fit(X_train)\nX_train_vector = vector.transform(X_train)\nX_test_vector = vector.transform(X_test)\n\nlr_model = LogisticRegression(C=1,penalty='l2').fit(X_train_vector,y_train)\npredict = lr_model.predict(X_test_vector)\nscore = roc_auc_score(y_test,predict)\nprint('Roc AUC curve for LR and TFIDF with ngrams  - %3f'%score)\n\nscore_df = score_df.append({'Model Description':'LR Model - with ngram range',\n                           'Score':score}\n                           ,ignore_index=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\n\n### let's have another model with some ngram's though \nX_train,X_test,y_train,y_test = train_test_split(df_train['clean_text'],df_train['target'])\nvector = TfidfVectorizer(ngram_range=(1,3)).fit(X_train)\nX_train_vector = vector.transform(X_train)\nX_test_vector = vector.transform(X_test)\n\nlr_model = LogisticRegression(C=1,penalty='l2').fit(X_train_vector,y_train)\npredict = lr_model.predict(X_test_vector)\nscore = roc_auc_score(y_test,predict)\nprint('Roc AUC curve for LR and TFIDF with ngrams  - %3f'%score)\n\nscore_df = score_df.append({'Model Description':'LR Model - with ngram range',\n                           'Score':grid_search_model.score}\n                           ,ignore_index=True)\n\nvector = TfidfVectorizer(ngram_range=(1,3)).fit(df_train['clean_text'])\nX_train_vector = vector.transform(df_train['clean_text'])\nX_test_vector = vector.transform(df_test['clean_text'])\nlr_model = LogisticRegression(C=1,penalty='l2').fit(X_train_vector,df_train['target'])\npredict = lr_model.predict(X_test_vector)\n\n\n## dumping the output to a file \npredict_df = pd.DataFrame()\npredict_df['id'] = df_test['id']\npredict_df['target'] = predict\npredict_df.to_csv('sample_submission_001.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.concat([df_test,predict_df['target']],axis=1)\n\n### you could dump this in a csv and do further analysis to check what\n### misclassifications are there manually ,observations could then be used \n### to further tweak stuff\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4.2 Let's apply Gaussian NB to the data "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import GridSearchCV\n\nX_train, X_test, y_train, y_test = \\\n        train_test_split(df_train['clean_text'], df_train['target'], random_state=20)\n## Apply Tfidf tranformation\nvector = TfidfVectorizer().fit(X_train)\nX_train_vector = vector.transform(X_train)\nX_test_vector  = vector.transform(X_test)\ndf_test_vector = vector.transform(df_test['clean_text'])\n\ngb_model= GaussianNB().fit(X_train_vector.todense(),y_train)\npredict = gb_model.predict(X_test_vector.todense())\n\nprint('Roc AUC score - %3f'%(roc_auc_score(y_test,predict)))\nscore_df = score_df.append({'Model Description':'Naive Bayes',\n                           'Score':roc_auc_score(y_test,predict)}\n                           ,ignore_index=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"4.3 Support Vector Classifier - with Grid search to Optimize parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\n\nvector = TfidfVectorizer().fit(df_train['clean_text'])\ndf_train_vector = vector.transform(df_train['clean_text'])\ndf_test_vector = vector.transform(df_test['clean_text'])\n\nsvc_model = SVC()\ngrid_values={'kernel':['linear', 'poly', 'rbf'],'C':[0.001,0.01,1,10]}\ngrid_search_model= GridSearchCV(svc_model,param_grid=grid_values,cv=3)\ngrid_search_model.fit(df_train_vector,df_train['target'])\n\nprint(grid_search_model.best_estimator_)\nprint(grid_search_model.best_score_)\nprint(grid_search_model.best_params_)\n\nscore_df = score_df.append({'Model Description':'SVC - with Grid Search',\n                           'Score':grid_search_model.best_score_}\n                           ,ignore_index=True)\n\npredict = grid_search_model.predict(df_test_vector)\npredict_df = pd.DataFrame()\npredict_df['id'] = df_test['id']\npredict_df['target'] = predict\n\n# # print(predict_df.head(5))\npredict_df.to_csv('sample_submission_4.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at score_df which has scores of all models till now and let's sort the output in ascending based on the Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"score_df[['Model Description','Score']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Please Upvote if you found the notebook usefull.Also please leave a comment if you think something could be improved/done in a better way. **\n\nI have written another notebook to implement Word Embeddings using Word2Vec and then doing prediction implemention LR/ RF , it would save you a lot of time if you are new to Embeddings here is the [link](https://www.kaggle.com/slatawa/simple-implementation-of-word2vec)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}