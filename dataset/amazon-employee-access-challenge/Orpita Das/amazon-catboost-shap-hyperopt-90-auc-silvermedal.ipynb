{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Catboost & Hyperopt : Amazon employees dataset\n\n* **Information from [Kaggle](https://www.kaggle.com/c/amazon-employee-access-challenge/overview)**\n    - When an employee at any company starts work, they first need to obtain the computer access necessary to fulfill their role.\n    - **Given data about current employees and their provisioned access, models can be built that automatically determine access privileges as employees enter and leave roles within a company.** These auto-access models seek to minimize the human involvement required to grant or revoke employee access.\n    \n    \n* **Catboost**: \n    - **Yandex, the developers of Catboost, claim that default Catboost provides ~20% logloss improvement over LightGMB & XGBoost. Tuning further improves performance of the model.**\n    - **I will be testing these claims.**\n    - Catboost uses gradient boosted trees. Great for working on catgorical data and mixed data (with both categorical and numerical features)\n    - Data is quantized into bins. The algorithm decides bin 'borders'(We can set our own values too). This quantization supports faster integration into parallel processing workflows. \n    - Symmetric gradient boosted trees are built, each subsequent tree improves the performance of the previous set of trees. \n    - Categorical preprocessing steps like One-Hot-Encoding, text preprocessing steps like tokenization, Bag of Words models can be performed within the Catboost algorithm (No need for additional preprocessing.)  \n    \n    \n* **RESULT**:\n    - **One of the columns had duplicated information. After removing this column - the default algorithm gave the best loss publicised by Yandex (~0.137). A kaggle submission showed 90% AUC score.**\n    - Hyperopt tuning did not improve scores. \n    - Yandex's claims were proven. It had the best loss among the boosting models as shown in table below. \n    \n    \n<table>\n  <tr>\n    <th>Model</th>\n    <th>Logloss from default</th>\n  </tr>\n  <tr>\n    <td>Catboost</td>\n    <td>0.13516505504697254</td>\n  </tr>\n  <tr>\n    <td>Xgboost</td>\n    <td>0.1554555542790197</td>\n  </tr>\n  <tr>\n    <td>LightGBM</td>\n    <td>0.16383632381872779</td>\n  </tr>\n</table>\n    \n    \n    \n## Table of Contents\n* [Imports & Read in file](#first)\n* [Explore data](#second)\n* [Preprocessing](#third)\n* [Baseline Model](#fifth)\n* [Test set performance](#eighth)\n* [Hyperparameter tuning](#sixth)\n* [Model validation](#seventh)\n* [Other Boosting Algorithms](#ninth)\n\n<img src=\"https://images.freeimages.com/images/large-previews/753/go-to-work-1189863.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/>\n\n\n* **Description of Features:**\n    \n<table>\n  <tr>\n    <th>Label</th>\n    <th>Description</th>\n  </tr>\n  <tr>\n    <td>ACTION</td>\n    <td>ACTION is 1 if the resource was approved, 0 if the resource was not</td>\n  </tr>\n  <tr>\n    <td>RESOURCE</td>\n    <td>An ID for each resource</td>\n  </tr>\n  <tr>\n    <td>EMPLOYEE ID</td>\n    <td>The EMPLOYEE ID of the manager of the current EMPLOYEE ID record; an employee may have only one manager at a time</td>\n  </tr>\n  <tr>\n    <td>ROLE_ROLLUP_1</td>\n    <td>Company role grouping category id 1 (e.g. US Engineering)<td>\n  </tr>\n  <tr>\n    <td>ROLE_ROLLUP_2</td>\n    <td>Company role grouping category id 2 (e.g. US Retail)</td>\n  </tr>\n  <tr>\n    <td>ROLE_DEPTNAME</td>\n    <td>Company role department description (e.g. Retail)</td>\n  </tr>\n  <tr>\n    <td>ROLE_TITLE</td>\n    <td>Company role business title description (e.g. Senior Engineering Retail Manager)</td>\n  </tr>\n  <tr>\n    <td>ROLE_FAMILY_DESC</td>\n    <td>Company role family extended description (e.g. Retail Manager, Software Engineering)</td>\n  </tr>\n  <tr>\n    <td>ROLE_FAMILY</td>\n    <td>Company role family description (e.g. Retail Manager)</td>\n  </tr>\n  <tr>\n    <td>ROLE_CODE</td>\n    <td>Company role code; this code is unique to each role (e.g. Manager)</td>\n</table>"},{"metadata":{},"cell_type":"markdown","source":"## Imports & Read in file <a class=\"anchor\" id=\"first\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"import shap\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report,confusion_matrix, precision_recall_curve, roc_curve, roc_auc_score, log_loss\nfrom sklearn.model_selection import train_test_split\nfrom catboost import CatBoostClassifier, cv, Pool\nfrom hyperopt import hp, fmin, tpe, Trials, STATUS_OK\nfrom itertools import combinations\n\n%matplotlib inline\nsns.set(style='ticks')\npd.options.display.max_columns = 500\npd.options.display.max_rows = 500","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read in data\ntest = pd.read_csv(\"../input/amazon-employee-access-challenge/test.csv\")\ntrain = pd.read_csv(\"../input/amazon-employee-access-challenge/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def performance(model, X_test, y_test):\n    \n    \"\"\"\n    Accepts a fitted model and an evaluation dataset at input.\n    Prints the confusion matrix, classification_report & auc score. \n    Also, displays Precision-Recall curve & ROC curve.\n    \"\"\"\n    \n    # Make predictions on test set\n    y_pred=model.predict(X_test)\n    y_pred=np.round(y_pred)\n    \n    # Confusion matrix\n    print(confusion_matrix(y_test, y_pred))\n    \n    # AUC score\n    y_pred_prob = model.predict_proba(X_test)\n    print(\"AUC score: \", roc_auc_score(y_test, y_pred_prob[:,1]))\n    \n    # Logloss\n    print(\"Logloss : \", log_loss(y_test, y_pred_prob))\n\n    # Accuracy, Precision, Recall, F1 score\n    print(classification_report(y_test, y_pred))\n    \n    # Precision-Recall curve\n    precisions, recalls, thresholds = precision_recall_curve(y_test, y_pred)\n    plt.plot(recalls, precisions, \"b-\", linewidth=2)\n    plt.xlabel(\"Recall\", fontsize=16)\n    plt.ylabel(\"Precision\", fontsize=16)\n    plt.axis([0, 1, 0, 1])\n    plt.grid(True)\n    plt.show()\n\n    # ROC curve\n    fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob[:,1])\n    plt.plot([0, 1], [0, 1],'k--')\n    plt.plot(fpr, tpr, label='Neural Network')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve')\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Explore data <a class=\"anchor\" id=\"second\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train shape: {}, Test shape: {}\".format(train.shape, test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n* Target: ACTION\n* 9 categorical features (represented as numbers for privacy reasons)\n\n"},{"metadata":{},"cell_type":"markdown","source":"### Null values"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.isnull().any()) \nprint(test.isnull().any())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compare number of Unique Categorical labels for train and test\n\nunique_train= pd.DataFrame([(col,train[col].nunique()) for col in train.columns], \n                           columns=['Columns', 'Unique categories'])\nunique_test=pd.DataFrame([(col,test[col].nunique()) for col in test.columns],\n                columns=['Columns', 'Unique categories'])\nunique_train=unique_train[1:]\nunique_test=unique_test[1:]\n\nfig, ax = plt.subplots(2, 1, sharex=True, sharey=True)\nax[0].bar(unique_train.Columns, unique_train['Unique categories'])\nax[1].bar(unique_test.Columns, unique_test['Unique categories'])\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The Training and Test data have different subsets of categorical variables."},{"metadata":{},"cell_type":"markdown","source":"### Balance of target labels"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train.ACTION)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The dataset represents a case of Imbalanced classes. The 0 label has fewer values."},{"metadata":{},"cell_type":"markdown","source":"### Correlations"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for duplicated rows\n\nif (sum(train.duplicated()), sum(test.duplicated())) == (0,0):\n    print('No duplicated rows')\nelse: \n    print('train: ',sum(train.duplicated()))\n    print('test: ',sum(train.duplicated()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for duplicated columns                          \n\nfor col1,col2 in combinations(train.columns, 2):\n    condition1=len(train.groupby([col1,col2]).size())==len(train.groupby([col1]).size())\n    condition2=len(train.groupby([col1,col2]).size())==len(train.groupby([col2]).size())\n    condition3=(train[col1].nunique()==train[col2].nunique())\n    if (condition1 | condition2) & condition3:\n        print(col1,col2)\n        print('Potential Categorical column duplication')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby(['ROLE_TITLE', 'ROLE_CODE']).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* ROLE_TITLE and ROLE_CODE represent the same data. One of the two features can be dropped. "},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing <a class=\"anchor\" id=\"third\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### Set random seed"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(123)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop duplicated column\ntrain.drop('ROLE_CODE', axis=1, inplace=True)\ntest.drop('ROLE_CODE', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split into features and target\ny = train['ACTION']\nX = train.drop('ACTION', axis=1)\n\n# Split into train & validation set\nX_train, X_val, y_train, y_val = train_test_split(X, y, train_size=0.8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Baseline Model <a class=\"anchor\" id=\"fifth\"></a>"},{"metadata":{},"cell_type":"markdown","source":"* It is important to tell CatBoost which columns are categorical and which ones are text. If no information is provided - CatBoost assumes all features are numerical. \n\n\n* Default values of CatBoostClassifier() parameters depend of the type of input data - CatBoost automatically applies the best settings. Catboost can distinguish between binary & multiclass problems - it will appropriately assign 'Logloss' as the 'loss_function' for Binary problems, 'MultiClass' for multiclass problems and 'RMSE' for regression problems. \n\n\n* Default number of 'iterations' is 1000. I set early stopping rounds to 100 (for boosting algos high patience values give best models) for the first run and I also selected 'use_best_model'= True . (When we fit using the model, we want to use the best model, rather than the potentially substandard model saved in memory at the end of training). 'custom_metric' provides an additional plot to moniter while CatBoost fits (It does not change training performance). 'eval_metric' is the metric used for 'best model' selection. \n\n\n* When fitting 'eval_set' is optional. If we provide 'eval_metric' and 'use_best_model' (metric used for overfit detection), we will need to provide 'eval_set'. \n\n\n* AUC selected as parameter of choice - as Kaggle competition requires this. Logloss also studied to prove Yandex's claims about Catboost's superior performance. \n\n\n* Input data can be in many different tabular forms. \n    - If only a dataframe is provided, first column is assumed to be the target. Rest of the columns are assumed to be features. \n    - We can provide a dataframe of features and a dataframe/array of target values, as we do in Sklearn. \n    - The Pool() class is specific to CatBoost. "},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features = [*range(8)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CatBoostClassifier(custom_metric=['TotalF1'], early_stopping_rounds=100, eval_metric='AUC')\n\nmodel.fit(X_train, y_train, cat_features=cat_features,\n          eval_set=(X_val, y_val), plot=True, verbose=False, use_best_model=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"performance(model, X_val, y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_imp=model.get_feature_importance(prettified=True)\nplt.bar(feat_imp['Feature Id'], feat_imp['Importances'])\nplt.xlabel('Features')\nplt.ylabel('Feature Importance')\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The best model has a **loss of 0.137** and an **AUC score of 89.7%**. \n\n\n* RESOURCE & ROLE_DEPTNAME are the most important features. \n\n\n* Let us look at model performance of the test set now by making a submission to Kaggle. \n"},{"metadata":{},"cell_type":"markdown","source":"## Test set performance <a class=\"anchor\" id=\"eighth\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub=pd.read_csv(\"../input/amazon-employee-access-challenge/sampleSubmission.csv\")\nsum(test.id==sub.Id), test.shape\n\n#sub.to_csv('amazon1.csv', index=False, header=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=model.predict_proba(test.drop('id', axis=1))\nsub.Action=y_pred[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('amazon1.csv', index=False, header=True)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* The default model gives an **AUC score of 0.90373**. Not bad for the first model!! \n* The winning submission has a score of 92%. Lets see if we can tune the model to squeeze out the last 2%. \n\n\n* We will study the paramaters of the default model and try to provide a sensible range for hyperopt to tune on. "},{"metadata":{"trusted":true},"cell_type":"code","source":"model.get_all_params()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## Hyperparameter tuning <a class=\"anchor\" id=\"sixth\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nCOmmented out as it takes too long to run. \nUnder construction, some things can be improved.\nspace = {\n    'depth': hp.quniform(\"depth\", 1, 16, 1),\n    'border_count': hp.quniform('border_count', 32, 255, 1),\n    'l2_leaf_reg': hp.uniform('l2_leaf_reg', 3, 8),\n    #'rsm': hp.uniform('rsm', 0.1, 1), # use only when task_type is default CPU\n    'scale_pos_weight': hp.uniform('scale_pos_weight', 0.06, 1), # Can be set only when loss_function is default Logloss\n    #'loss_function' : hp.choice('loss_function', ['Logloss', 'CrossEntropy'])\n}\n\n\ndef hyperparameter_tuning(space):\n    model = CatBoostClassifier(depth=int(space['depth']),\n                               border_count=space['border_count'],\n                               l2_leaf_reg=space['l2_leaf_reg'],\n                               #rsm=space['rsm'],\n                               scale_pos_weight=space['scale_pos_weight']\n                               #loss_function=space['loss_function'],\n                               task_type='GPU', # change to CPU when working on personal system\n                               eval_metric='AUC'\n                               early_stopping_rounds=100,\n                              thread_count=-1)\n\n    model.fit(X_train, y_train, cat_features=cat_features,use_best_model=True,\n              verbose=False, eval_set=(X_val, y_val))\n\n    preds_class = model.predict_proba(X_val)\n    #score = classification_report(y_val, preds_class, output_dict=True)['0']['f1-score']\n    score = roc_auc_score(y_val, preds_class[:,1])\n    return{'loss': 1-score, 'status': STATUS_OK}\n\n\nbest = fmin(fn=hyperparameter_tuning,\n            space=space,\n            algo=tpe.suggest,\n            max_evals=50)\n\nprint(best)\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Validation <a class=\"anchor\" id=\"seventh\"></a>"},{"metadata":{},"cell_type":"markdown","source":"* Some differnt sets of parameters returned as 'best' by hyperopt. \n* {'border_count': 209.0, 'depth': 8.0, 'l2_leaf_reg': 7.476976878626717, 'loss_function': 0, 'rsm': 0.7556557996868841}\n* {'border_count': 248.0, 'depth': 4.0, 'l2_leaf_reg': 4.830204209625978, 'scale_pos_weight': 0.4107081177319144}\n* {'border_count': 129.0, 'depth': 10.0, 'l2_leaf_reg': 4.450385969436819, 'scale_pos_weight': 0.1034646048953394}"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Best of the tuned models\nmodel = CatBoostClassifier(border_count=248, depth=4, l2_leaf_reg=4.830204209625978,\n                           scale_pos_weight=0.4107081177319144, \n                           eval_metric='AUC',\n                           use_best_model=True,\n                          early_stopping_rounds=100)\nbest=model.fit(X_train, y_train, cat_features=cat_features, eval_set=(X_val, y_val), use_best_model=True,\n          verbose=False, plot=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"performance(model, X_val, y_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Shap\n\n* Refer to https://www.kaggle.com/dansbecker/shap-values for explanation of SHAP. \n* \"SHAP values interpret the impact of having a certain value for a given feature in comparison to the prediction we'd make if that feature took some baseline value.\""},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CatBoostClassifier(border_count=248, depth=4, l2_leaf_reg=4.830204209625978,\n                           scale_pos_weight=0.4107081177319144, iterations = 400)\nmodel.fit(X_train, y_train, cat_features=cat_features,\n          verbose=False, plot=False)\nshap.initjs()\nexplainer = shap.TreeExplainer(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* We will look at SHAP values for a single row of the dataset (we arbitrarily chose row 2). For context, we'll look at the raw predictions before looking at the SHAP values. "},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Probability of class 1 = {:.4f}'.format(model.predict_proba(X_train.iloc[2:3])[0][1]))\n#print('Formula raw prediction = {:.4f}'.format(model.predict(X_train.iloc[0:1], prediction_type='RawFormulaVal')[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap_values = explainer.shap_values(Pool(X_train, y_train, cat_features=cat_features))\nshap.force_plot(explainer.expected_value, shap_values[2,:], X_train.iloc[2,:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* There is 97% likelihood for positive label - for this instance.\n\n\n* From the plot we see that the base value is 2.638. \n* The SHAP values of all features sum up to explain why our prediction is different from the baseline (value of +3.46 - a positive value).\n* The contribution of each of the features towards change from base values is shown in the plot. \n* 'RESOURCES' contributes towards a more positive values. All the other features contribute to more negative value for the prediction in row 2. "},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.summary_plot(shap_values, X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Contribution of all the features and all the instances of the features towards predictions are shown using the red/blue dots. "},{"metadata":{},"cell_type":"markdown","source":"### Cross validation to check for overfitting\n\n* Explanation of what cv() function in Catboost does: \"The dataset is split into N folds. Nâ€“1 folds are used for training, and one fold is used for model performance estimation. N models are updated on each iteration K. Each model is evaluated on its' own validation dataset on each iteration. This produces N metric values on each iteration K. \""},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CatBoostClassifier(border_count=248, depth=4, l2_leaf_reg=4.830204209625978,\n                           scale_pos_weight=0.4107081177319144,\n                           loss_function='Logloss',\n                           eval_metric='AUC',\n                           use_best_model=True,\n                          early_stopping_rounds=100)\ncv_data = cv(Pool(X_train, y_train, cat_features=cat_features), params=model.get_params(),\n             verbose=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = np.max(cv_data['test-AUC-mean'])\nprint('AUC score from cross-validation: ', score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_data['test-AUC-mean'].plot()\nplt.xlabel('Iterations')\nplt.ylabel('test-AUC-Mean')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Other Boosting Algorithms <a class=\"anchor\" id=\"ninth\"></a>"},{"metadata":{},"cell_type":"markdown","source":"### Xgboost"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = xgb.XGBClassifier()\nclf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"performance(clf, X_val, y_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### LightGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = lgb.Dataset(X_train, label=y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param = {'objective': 'binary'}\nparam['metric'] = 'auc'\nbst = lgb.train(train_set=train_data, params=param)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_prob=bst.predict(X_val)\ny_pred=np.round(y_pred_prob)\n\n# Confusion matrix\nprint(confusion_matrix(y_val, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# AUC score\nprint(\"AUC score: \", roc_auc_score(y_val, y_pred_prob))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Logloss\nprint(\"Logloss : \", log_loss(y_val, y_pred_prob))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Accuracy, Precision, Recall, F1 score\nprint(classification_report(y_val, y_pred))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"284.444px"},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":4}