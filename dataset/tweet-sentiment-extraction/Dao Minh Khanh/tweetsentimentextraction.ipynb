{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-24T08:18:24.477597Z","iopub.execute_input":"2021-07-24T08:18:24.477956Z","iopub.status.idle":"2021-07-24T08:18:24.49767Z","shell.execute_reply.started":"2021-07-24T08:18:24.477882Z","shell.execute_reply":"2021-07-24T08:18:24.496825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport seaborn as sns \nfrom matplotlib import pyplot as plt \nfrom transformers import RobertaModel,RobertaTokenizer,RobertaConfig,AdamW,get_linear_schedule_with_warmup\nfrom tokenizers import ByteLevelBPETokenizer\nimport torch \nfrom torch.utils.data import Dataset,DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch import nn,optim \nimport os \nimport time \nimport random \nfrom collections import defaultdict\nfrom tqdm import tqdm\nimport re\nimport math\nimport pickle\nfrom sklearn.model_selection import StratifiedKFold\nimport gc \ngc.enable()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T08:18:36.389979Z","iopub.execute_input":"2021-07-24T08:18:36.390295Z","iopub.status.idle":"2021-07-24T08:18:43.308983Z","shell.execute_reply.started":"2021-07-24T08:18:36.390268Z","shell.execute_reply":"2021-07-24T08:18:43.308169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"train=pd.read_csv('../input/tweet-sentiment-extraction/train.csv')\ntest=pd.read_csv('../input/tweet-sentiment-extraction/test.csv')\nsubmission=pd.read_csv('../input/tweet-sentiment-extraction/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-24T08:19:15.137618Z","iopub.execute_input":"2021-07-24T08:19:15.137947Z","iopub.status.idle":"2021-07-24T08:19:15.229019Z","shell.execute_reply.started":"2021-07-24T08:19:15.137919Z","shell.execute_reply":"2021-07-24T08:19:15.228201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['length']=train.text.astype(str).apply(lambda x:len(x))\ntrain['num_words']=train.text.astype(str).apply(lambda x:len(x.split()))","metadata":{"execution":{"iopub.status.busy":"2021-07-24T08:20:01.6517Z","iopub.execute_input":"2021-07-24T08:20:01.652141Z","iopub.status.idle":"2021-07-24T08:20:01.755426Z","shell.execute_reply.started":"2021-07-24T08:20:01.652107Z","shell.execute_reply":"2021-07-24T08:20:01.754574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T08:20:08.975791Z","iopub.execute_input":"2021-07-24T08:20:08.976149Z","iopub.status.idle":"2021-07-24T08:20:09.009781Z","shell.execute_reply.started":"2021-07-24T08:20:08.976118Z","shell.execute_reply":"2021-07-24T08:20:09.008789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2021-07-24T08:20:17.638395Z","iopub.execute_input":"2021-07-24T08:20:17.638749Z","iopub.status.idle":"2021-07-24T08:20:17.653765Z","shell.execute_reply.started":"2021-07-24T08:20:17.63872Z","shell.execute_reply":"2021-07-24T08:20:17.652931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocess Data","metadata":{}},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-24T08:20:59.429515Z","iopub.execute_input":"2021-07-24T08:20:59.429886Z","iopub.status.idle":"2021-07-24T08:20:59.447714Z","shell.execute_reply.started":"2021-07-24T08:20:59.429855Z","shell.execute_reply":"2021-07-24T08:20:59.446716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have 1 row which has nan value","metadata":{}},{"cell_type":"code","source":"train=train.dropna()\ntrain=train.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T08:20:59.754327Z","iopub.execute_input":"2021-07-24T08:20:59.754798Z","iopub.status.idle":"2021-07-24T08:20:59.80987Z","shell.execute_reply.started":"2021-07-24T08:20:59.754753Z","shell.execute_reply":"2021-07-24T08:20:59.808756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2021-07-24T08:20:59.965891Z","iopub.execute_input":"2021-07-24T08:20:59.968381Z","iopub.status.idle":"2021-07-24T08:20:59.993964Z","shell.execute_reply.started":"2021-07-24T08:20:59.968322Z","shell.execute_reply":"2021-07-24T08:20:59.993211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Loader","metadata":{}},{"cell_type":"code","source":"class Config:\n    MAX_LENGTH=256\n    BATCH_SIZE=32\n    EPOCHS=5\n    TOKENIZER=ByteLevelBPETokenizer(\n      vocab='../input/roberta-base/vocab.json',\n      merges='../input/roberta-base/merges.txt',\n      add_prefix_space=True,\n      lowercase=True\n    )\n    TOKENIZER.enable_truncation(max_length=MAX_LENGTH)\n    VOCAB=TOKENIZER.get_vocab()\n    INT_TO_WORD={value:key for key,value in VOCAB.items()}\n    CLS_ID=VOCAB['<s>']\n    SEP_ID=VOCAB['</s>']\n    PAD_ID=VOCAB['<pad>']","metadata":{"execution":{"iopub.status.busy":"2021-07-24T08:22:49.397965Z","iopub.execute_input":"2021-07-24T08:22:49.398515Z","iopub.status.idle":"2021-07-24T08:22:49.588799Z","shell.execute_reply.started":"2021-07-24T08:22:49.398275Z","shell.execute_reply":"2021-07-24T08:22:49.587958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp=Config.TOKENIZER.encode(' hello, my name is khanh')","metadata":{"execution":{"iopub.status.busy":"2021-07-24T08:23:04.519819Z","iopub.execute_input":"2021-07-24T08:23:04.520142Z","iopub.status.idle":"2021-07-24T08:23:04.527682Z","shell.execute_reply.started":"2021-07-24T08:23:04.520112Z","shell.execute_reply":"2021-07-24T08:23:04.526776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp.offsets","metadata":{"execution":{"iopub.status.busy":"2021-07-24T08:23:14.019767Z","iopub.execute_input":"2021-07-24T08:23:14.020103Z","iopub.status.idle":"2021-07-24T08:23:14.025359Z","shell.execute_reply.started":"2021-07-24T08:23:14.020075Z","shell.execute_reply":"2021-07-24T08:23:14.024456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_data(tweet,sentiment,config):\n    tweet=\" \"+\" \".join(tweet.lower().split())\n    token=config.TOKENIZER.encode(tweet)\n    sentiment_values={\n      value:config.VOCAB[value] for value in ['positive','negative','neutral']\n    }\n    input_ids=[config.CLS_ID]+[sentiment_values[sentiment]]+[config.SEP_ID]+token.ids+[config.SEP_ID]\n    attention_mask=[1]*len(input_ids)\n    offsets=[(0,0)]*3+token.offsets+[(0,0)]\n    #padding_len=Config.MAX_LENGTH-len(input_ids)\n    # if padding_len>0:\n    #     input_ids=input_ids+[Config.PAD_ID]*padding_len\n    #     attention_mask=attention_mask+[0]*padding_len\n    #     offsets=offsets+[(0,0)]*padding_len\n    return tweet,input_ids,attention_mask,offsets\n","metadata":{"execution":{"iopub.status.busy":"2021-07-24T09:15:06.941967Z","iopub.execute_input":"2021-07-24T09:15:06.942422Z","iopub.status.idle":"2021-07-24T09:15:06.951433Z","shell.execute_reply.started":"2021-07-24T09:15:06.942371Z","shell.execute_reply":"2021-07-24T09:15:06.950606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_index(tweet,selected_text,offsets,config):\n    selected_text=\" \"+\" \".join(selected_text.lower().split())\n    index1,index2=None,None\n    length=len(selected_text)-1\n    for value in [position for position,value in enumerate(tweet) if value==selected_text[1]]:\n        if \" \"+tweet[value:value+length]==selected_text:\n            index1=value\n            index2=value+length-1\n    temp=[0]*len(tweet)\n    start_index,end_index=None,None\n    #print(len(temp),'--->',index1,'---->',index2)\n    if index1!=None and index2!=None:\n        #print(index1,'-->',index2)\n        for i in range(index1,index2+1):\n            temp[i]=1\n        list_index=[]\n        for i,(offset1,offset2) in enumerate(offsets):\n            if sum(temp[offset1:offset2])>0:\n                list_index.append(i)\n        start_index=list_index[0]\n        end_index=list_index[-1]\n    return start_index,end_index\n","metadata":{"execution":{"iopub.status.busy":"2021-07-24T09:15:08.289762Z","iopub.execute_input":"2021-07-24T09:15:08.290067Z","iopub.status.idle":"2021-07-24T09:15:08.297978Z","shell.execute_reply.started":"2021-07-24T09:15:08.290039Z","shell.execute_reply":"2021-07-24T09:15:08.296966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_indexs,end_indexs=[],[]\nfor i in range(len(train)):\n    tweet_temp=train['text'][i]\n    sentiment=train['sentiment'][i]\n    selected_temp=train['selected_text'][i]\n    tweet_temp,_,_,offsets=get_data(tweet_temp,sentiment,Config)\n    start_index,end_index=find_index(tweet_temp,selected_temp,offsets,Config)\n    if start_index is None:\n        print(tweet_temp,'------>',selected_temp)\n    start_indexs.append(start_index)\n    end_indexs.append(end_index)\n\ntrain['start_index']=start_indexs\ntrain['end_index']=end_indexs","metadata":{"execution":{"iopub.status.busy":"2021-07-24T09:15:09.813707Z","iopub.execute_input":"2021-07-24T09:15:09.814031Z","iopub.status.idle":"2021-07-24T09:15:13.194505Z","shell.execute_reply.started":"2021-07-24T09:15:09.814002Z","shell.execute_reply":"2021-07-24T09:15:13.193355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2021-07-24T08:24:07.009509Z","iopub.execute_input":"2021-07-24T08:24:07.009968Z","iopub.status.idle":"2021-07-24T08:24:07.033948Z","shell.execute_reply.started":"2021-07-24T08:24:07.009915Z","shell.execute_reply":"2021-07-24T08:24:07.033232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TweetSentimentExtraction(Dataset):\n    def __init__(self,data,config):\n        self.data=data\n        self.tokenizer=config.TOKENIZER\n        self.max_length=config.MAX_LENGTH\n        self.is_test=\"selected_text\" in self.data\n        self.config=config\n        self.cls_id=self.config.VOCAB['<s>']\n        self.sep_id=self.config.VOCAB['</s>']\n        self.pad_id=self.config.VOCAB['<pad>']\n\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self,idx):\n        row=self.data.iloc[idx]\n        tweet=row.text\n        sentiment=row.sentiment\n        tweet,input_ids,attention_mask,offsets=get_data(tweet,sentiment,self.config)\n        data={}\n        data['input_ids']=torch.tensor(input_ids,dtype=torch.long)\n        data['attention_mask']=torch.tensor(attention_mask,dtype=torch.long)\n        data['tweet']=tweet\n        data['offsets']=offsets\n        if self.is_test:\n            start_index=row.start_index\n            end_index=row.end_index\n            data['start_index']=start_index\n            data['end_index']=end_index\n        return data\n    \n\n\nclass MyCollate:\n    def __init__(self,pad_id,is_test=False):\n        self.pad_id=pad_id\n        self.is_test=is_test\n        \n    def __call__(self,batch):\n        input_ids=[item['input_ids'] for item in batch]\n        attention_mask=[item['attention_mask'] for item in batch]\n        tweet=[item['tweet'] for item in batch]\n        offsets=[item['offsets'] for item in batch]\n        input_ids=pad_sequence(input_ids,batch_first=True,padding_value=self.pad_id)\n        attention_mask=pad_sequence(attention_mask,batch_first=True,padding_value=0)\n        if len(offsets)<input_ids.size(1):\n            padding_len=input_ids.size(1)-len(offsets)\n            offsets=offsets+[(0,0)]*padding_len\n\n        if not self.is_test:\n            #print(start_index)\n            start_index=[item['start_index'] for item in batch]\n            end_index=[item['end_index'] for item in batch]\n            start_index=torch.tensor(start_index,dtype=torch.long)\n            end_index=torch.tensor(end_index,dtype=torch.long)\n            return {\n                \"input_ids\":input_ids,\n                \"attention_mask\":attention_mask,\n                \"offsets\":offsets,\n                'tweet':tweet,\n                \"start_index\":start_index,\n                \"end_index\":end_index\n            }\n        else:\n            return {\n                \"input_ids\":input_ids,\n                \"attention_mask\":attention_mask,\n                \"offsets\":offsets,\n                'tweet':tweet\n            }\n        ","metadata":{"execution":{"iopub.status.busy":"2021-07-24T09:15:34.622919Z","iopub.execute_input":"2021-07-24T09:15:34.623223Z","iopub.status.idle":"2021-07-24T09:15:34.638018Z","shell.execute_reply.started":"2021-07-24T09:15:34.623198Z","shell.execute_reply":"2021-07-24T09:15:34.637018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_val_loader(df,train_index,val_index):\n    train=df.iloc[train_index]\n    val=df.iloc[val_index]\n    train_dataset=TweetSentimentExtraction(train,Config)\n    val_dataset=TweetSentimentExtraction(val,Config)\n    train_loader=DataLoader(train_dataset,batch_size=Config.BATCH_SIZE,shuffle=False,num_workers=2,collate_fn=MyCollate(Config.PAD_ID))\n    val_loader=DataLoader(val_dataset,batch_size=Config.BATCH_SIZE,shuffle=False,num_workers=2,collate_fn=MyCollate(Config.PAD_ID))\n    return train_loader,val_loader","metadata":{"execution":{"iopub.status.busy":"2021-07-24T09:15:35.561746Z","iopub.execute_input":"2021-07-24T09:15:35.562061Z","iopub.status.idle":"2021-07-24T09:15:35.567937Z","shell.execute_reply.started":"2021-07-24T09:15:35.562034Z","shell.execute_reply":"2021-07-24T09:15:35.566846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2021-07-24T09:15:36.225338Z","iopub.execute_input":"2021-07-24T09:15:36.225669Z","iopub.status.idle":"2021-07-24T09:15:36.230486Z","shell.execute_reply.started":"2021-07-24T09:15:36.225641Z","shell.execute_reply":"2021-07-24T09:15:36.229412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super(Model,self).__init__()\n        self.config=RobertaConfig.from_pretrained('../input/roberta-base/config.json',output_hidden_states=True)\n        self.bert=RobertaModel.from_pretrained('../input/roberta-base',config=self.config)\n        self.hidden_size=self.bert.config.hidden_size\n        self.norm=nn.LayerNorm(self.hidden_size)\n        self.linear=nn.Sequential(\n            nn.Linear(self.hidden_size,self.hidden_size),\n            nn.LayerNorm(self.hidden_size),\n            nn.ReLU(),\n            nn.Linear(self.hidden_size,2)\n        )\n    \n    def __init__weight(self,module):\n        if isinstance(module,nn.Linear):\n            module.weight.data.normal_(mean=0,std=seld.bert.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module,nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n    \n    def forward(self,input_ids,attention_mask,token_type_ids=None):\n        outputs=self.bert(input_ids,attention_mask)\n        hidden_states=outputs.hidden_states#batch_size*seq_length*hidden_size\n        out=torch.stack([hidden_states[-1],hidden_states[-2],hidden_states[-3],hidden_states[-4]])\n        out=torch.mean(out,0)\n        out=self.linear(out)\n        start_logit,end_logit=torch.split(out,1,-1)\n        start_logit=start_logit.squeeze(dim=-1)\n        end_logit=end_logit.squeeze(dim=-1)\n        return start_logit,end_logit\n        ","metadata":{"execution":{"iopub.status.busy":"2021-07-24T09:17:28.994063Z","iopub.execute_input":"2021-07-24T09:17:28.994405Z","iopub.status.idle":"2021-07-24T09:17:29.0054Z","shell.execute_reply.started":"2021-07-24T09:17:28.994377Z","shell.execute_reply":"2021-07-24T09:17:29.004518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_selected_text(text,start_index,end_index,offsets):\n    selected_text=\"\"\n    for i in range(start_index,end_index+1):\n        selected_text+=text[offsets[i][0]:offsets[i][1]]\n#         if (i+1)<len(offsets) and offsets[i][0]<offsets[i+1][0]:\n#             selected_text+=\" \"\n    return selected_text","metadata":{"execution":{"iopub.status.busy":"2021-07-24T09:17:29.757355Z","iopub.execute_input":"2021-07-24T09:17:29.757698Z","iopub.status.idle":"2021-07-24T09:17:29.763089Z","shell.execute_reply.started":"2021-07-24T09:17:29.757667Z","shell.execute_reply":"2021-07-24T09:17:29.762138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_loss(start_targets,end_targets,start_logit,end_logit):\n    loss_fn=nn.CrossEntropyLoss(reduction=\"mean\")\n    loss1=loss_fn(start_logit,start_targets)\n    loss2=loss_fn(end_logit,end_targets)\n    loss=loss1+loss2\n    return loss\n\ndef jaccard_score(str1,str2):\n    a=set(str1.lower().split())\n    b=set(str2.lower().split())\n    c=a.intersection(b)\n    return float(len(c))/(len(a)+len(b)-len(c))\n\ndef computer_jaccard_score(text,start_index,end_index,start_logit,end_logit,offsets):\n    start_pred=np.argmax(start_logit)\n    end_pred=np.argmax(end_logit)\n    if start_pred>end_pred:\n        pred=text\n    else:\n        pred=get_selected_text(text,start_pred,end_pred,offsets)\n    true=get_selected_text(text,start_index,end_index,offsets)\n    return jaccard_score(true,pred)\n\ndef save_checkpoint(model_state_dict,fold):\n    #path=\"/content/drive/MyDrive/Model/TweetSentimentExtraction\"\n#     if os.path.exists(path) is False:\n#         os.makedirs(path,exist_ok=True)\n        \n    # with open(path+f'/history_{epoch}_fold{fold}.pickle','wb') as file:\n    #     pickle.dump(history,file,protocol=pickle.HIGHEST_PROTOCOL)\n    # print(\"Save history done\")\n    torch.save(model_state_dict,f\"/model_fold{fold}.pth\")\n    print(\"Save model done\")","metadata":{"execution":{"iopub.status.busy":"2021-07-24T09:17:29.93289Z","iopub.execute_input":"2021-07-24T09:17:29.933164Z","iopub.status.idle":"2021-07-24T09:17:29.942155Z","shell.execute_reply.started":"2021-07-24T09:17:29.93314Z","shell.execute_reply":"2021-07-24T09:17:29.940322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model,loader,len_val):\n    print('---------------------------TIME FOR EVALUATE---------------------------')\n    model.eval()\n    val_loss=0\n    score=0\n    with torch.no_grad():\n        for idx,data in enumerate(loader):\n            input_ids=data['input_ids'].to(device)\n            attention_mask=data['attention_mask'].to(device)\n            offsets=data['offsets']\n            tweets=data['tweet']\n            start_logit,end_logit=model(input_ids,attention_mask)\n            loss=get_loss(\n                data['start_index'].to(device),\n                data['end_index'].to(device),\n                start_logit,\n                end_logit\n            )\n            val_loss+=loss.item()\n            start_indexs=data['start_index'].cpu().detach().numpy()\n            end_indexs=data['end_index'].cpu().detach().numpy()\n            start_logit=start_logit.cpu().detach().numpy()\n            end_logit=end_logit.cpu().detach().numpy()\n            for i in range(len(input_ids)):\n                score+=computer_jaccard_score(\n                    tweets[i],\n                    start_indexs[i],\n                    end_indexs[i],\n                    start_logit[i],\n                    end_logit[i],\n                    offsets[i]\n                )\n    return val_loss/len(loader),score/len_val","metadata":{"execution":{"iopub.status.busy":"2021-07-24T09:17:30.16095Z","iopub.execute_input":"2021-07-24T09:17:30.161225Z","iopub.status.idle":"2021-07-24T09:17:30.170766Z","shell.execute_reply.started":"2021-07-24T09:17:30.1612Z","shell.execute_reply":"2021-07-24T09:17:30.169706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model,train_loader,val_loader,optimizer,scheduler,fold,len_val):\n    model.train()\n    train_loss=0\n    history=defaultdict(list)\n    jaccard_score_final=None\n    print(f\"----------------------------------FOLD {fold}----------------------------------\\n\\n\")\n    for epoch in range(Config.EPOCHS+1):\n        train_loss=0\n        start_time=time.time()\n        print('---------------------------TIME FOR TRANING---------------------------')\n        for idx,data in enumerate(train_loader):\n            input_ids=data['input_ids'].to(device)\n            attention_mask=data['attention_mask'].to(device)\n            start_logit,end_logit=model(input_ids,attention_mask)\n            optimizer.zero_grad()\n            loss=get_loss(\n                data['start_index'].to(device),\n                data['end_index'].to(device),\n                start_logit,\n                end_logit\n            )\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n            train_loss+=loss.item()\n            if idx%100==0:\n                print(idx,end=\" \")\n        print()\n        train_loss/=len(train_loader)\n        val_loss,score=evaluate(model,val_loader,len_val)\n        history['train_loss'].append(train_loss)\n        history['val_loss'].append(val_loss)\n        history['jaccard_score'].append(score)\n        print(f\"Epochs:{epoch}---Train loss:{train_loss}---Val loss:{val_loss}---Jaccard score val:{score}---Time:{time.time()-start_time}\")\n        if jaccard_score_final is None or score>jaccard_score_final:\n            model_state=model.state_dict()\n            jaccard_score_final=score\n    \n    save_checkpoint(model_state,fold)             \n    print('\\n\\n')\n","metadata":{"execution":{"iopub.status.busy":"2021-07-24T09:17:30.368997Z","iopub.execute_input":"2021-07-24T09:17:30.369272Z","iopub.status.idle":"2021-07-24T09:17:30.380079Z","shell.execute_reply.started":"2021-07-24T09:17:30.369246Z","shell.execute_reply":"2021-07-24T09:17:30.379013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# kfold=StratifiedKFold(n_splits=5,shuffle=True,random_state=43)\n\n# for fold,(train_indexs,val_indexs) in enumerate(kfold.split(train,train.sentiment),start=1):\n#     model=Model().to(device)\n#     optimizer=AdamW(model.parameters(),lr=1e-5)\n#     scheduler=get_linear_schedule_with_warmup(\n#         optimizer,\n#         num_warmup_steps=50,\n#         num_training_steps=len(train)//Config.BATCH_SIZE*Config.EPOCHS    \n#     )\n\n#     train_loader,val_loader=get_train_val_loader(train,train_indexs,val_indexs)\n#     train_model(model,train_loader,val_loader,optimizer,scheduler,fold,len(val_indexs))\n#     del model,optimizer,scheduler\n#     torch.cuda.empty_cache()\n#     gc.collect()\n  ","metadata":{"execution":{"iopub.status.busy":"2021-07-24T09:17:30.825081Z","iopub.execute_input":"2021-07-24T09:17:30.825355Z","iopub.status.idle":"2021-07-24T09:17:30.828899Z","shell.execute_reply.started":"2021-07-24T09:17:30.82533Z","shell.execute_reply":"2021-07-24T09:17:30.827935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset=TweetSentimentExtraction(test,Config)\ntest_loader=DataLoader(\n                        test_dataset,batch_size=Config.BATCH_SIZE,\n                        shuffle=False,num_workers=2,\n                        collate_fn=MyCollate(Config.PAD_ID,is_test=True)\n                    )","metadata":{"execution":{"iopub.status.busy":"2021-07-24T09:17:31.14899Z","iopub.execute_input":"2021-07-24T09:17:31.14927Z","iopub.status.idle":"2021-07-24T09:17:31.153931Z","shell.execute_reply.started":"2021-07-24T09:17:31.149244Z","shell.execute_reply":"2021-07-24T09:17:31.152999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models=[]\nfor file_model in os.listdir('../input/tweetsentimentextractionroberta'):\n    model_temp=Model().to(device)\n    model_temp.load_state_dict(torch.load('../input/tweetsentimentextractionroberta/'+file_model))\n    model_temp.eval()\n    models.append(model_temp)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T09:21:07.725387Z","iopub.execute_input":"2021-07-24T09:21:07.725795Z","iopub.status.idle":"2021-07-24T09:21:36.533947Z","shell.execute_reply.started":"2021-07-24T09:21:07.725752Z","shell.execute_reply":"2021-07-24T09:21:36.533004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_predict(input_ids,attention_mask,size_batch):\n    start_preds=torch.tensor([0]*size_batch,dtype=torch.long).to(device)\n    end_preds=torch.tensor([0]*size_batch,dtype=torch.long).to(device)\n    for i in range(len(models)):\n        model=models[i]\n        start_logit,end_logit=model(input_ids,attention_mask)\n        start_index=torch.argmax(start_logit,dim=1)\n        end_index=torch.argmax(end_logit,dim=1)\n        start_preds+=start_index\n        end_preds+=end_index\n    start_preds=start_preds.cpu().detach().numpy()\n    end_preds=end_preds.cpu().detach().numpy()\n    return (start_preds/len(models)).astype(int),(end_preds/len(models)).astype(int)\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2021-07-24T09:37:59.237227Z","iopub.execute_input":"2021-07-24T09:37:59.237646Z","iopub.status.idle":"2021-07-24T09:37:59.246057Z","shell.execute_reply.started":"2021-07-24T09:37:59.23761Z","shell.execute_reply":"2021-07-24T09:37:59.244999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds=[]\nfor data in test_loader:\n    input_ids=data['input_ids'].to(device)\n    attention_mask=data['attention_mask'].to(device)\n    offsets=data['offsets']\n    tweets=data['tweet']\n    start_indexs,end_indexs=get_predict(input_ids,attention_mask,len(tweets))\n    for i in range(len(tweets)):\n        if start_indexs[i]>end_indexs[i]:\n            result=tweets[i]\n        else:\n            result=get_selected_text(tweets[i],start_indexs[i],end_indexs[i],offsets[i])\n        preds.append(result)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T09:38:23.327272Z","iopub.execute_input":"2021-07-24T09:38:23.327648Z","iopub.status.idle":"2021-07-24T09:38:48.09743Z","shell.execute_reply.started":"2021-07-24T09:38:23.327614Z","shell.execute_reply":"2021-07-24T09:38:48.096552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preds=[]\n# for data in test_loader:\n#     input_ids=data['input_ids'].to(device)\n#     attention_mask=data['attention_mask'].to(device)\n#     tweet=data['tweet']\n#     offsets=data['offsets']\n#     start_logits=[]\n#     end_logits=[]\n#     for model in models:\n#         with torch.no_grad():\n#             outputs=model(input_ids,attention_mask)\n#             start_logits.append(torch.softmax(outputs[0],dim=1).cpu().detach().numpy())\n#             end_logits.append(torch.softmax(outputs[1],dim=1).cpu().detach().numpy())\n#     start_logits=np.mean(start_logits,axis=0)\n#     end_logits=np.mean(end_logits,axis=0)\n#     start_indexs=np.argmax(start_logits,axis=1)\n#     end_indexs=np.argmax(end_logits,axis=1)\n#     for i in range(len(tweet)):\n#         start_pred=start_indexs[i]\n#         end_pred=end_indexs[i]\n#         if start_pred>end_pred:\n#             result=tweet[i]\n#         else:\n#             result=get_selected_text(tweet[i],start_pred,end_pred,offsets[i])\n#         preds.append(result)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T09:22:14.658478Z","iopub.execute_input":"2021-07-24T09:22:14.65884Z","iopub.status.idle":"2021-07-24T09:22:39.096105Z","shell.execute_reply.started":"2021-07-24T09:22:14.658807Z","shell.execute_reply":"2021-07-24T09:22:39.095105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def replace_string(x):\n    x=re.sub('!+','!',x)\n    x=re.sub('.+','.',x)\n    return x","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.selected_text=preds\n# submission['selected_text'] = submission['selected_text'].apply(lambda x: replace_string(x))\nsubmission.to_csv('submission.csv',index=False)\nsubmission.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T09:38:51.639962Z","iopub.execute_input":"2021-07-24T09:38:51.640293Z","iopub.status.idle":"2021-07-24T09:38:51.680859Z","shell.execute_reply.started":"2021-07-24T09:38:51.640263Z","shell.execute_reply":"2021-07-24T09:38:51.679908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}