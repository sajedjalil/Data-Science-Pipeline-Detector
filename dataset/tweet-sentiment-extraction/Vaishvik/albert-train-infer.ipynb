{"cells":[{"metadata":{},"cell_type":"markdown","source":"<center><font size='3'>Extraction :ALBERTðŸ˜› [Train + Infer]</font></center>\n![](https://miro.medium.com/max/450/1*p3Ste5R_iJzi5IcSmFkmtg.png)\n* This competition wants us to Extract the words which are responsible for the sentiment of the tweet.\n* IMP POINT: Almost 97 % Jaccard Similarity in train data \"text\" and \"selected_text\".In conclusion maybe  we can use neutral \"text\" as it is for \"selected_text\" for test data submission. <br>\n\n\n<font size='3' color='GREEN'>Contents</font>\n* [Install and imports](#1)\n* [Convert to JSON](#2)\n* [MODEL TRAIN](#3)\n* [MODEL INFER](#4)\n\nThis kernel is build from refing :https://www.kaggle.com/vaishvik25/question-answering-starter-pack"},{"metadata":{},"cell_type":"markdown","source":"<center><font size='6' color='blue'> ALBERT (WHAT? AND WHY?) </font></center><br>\n\n\n<font size='3'>\nWHAT ?<br>The ALBERT model was proposed in ALBERT: A Lite BERT for Self-supervised Learning of Language Representations by Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut. It presents two parameter-reduction techniques to lower memory consumption and increase the trainig speed of BERT:<br>\n] Splitting the embedding matrix into two smaller matrices<br>\n] Using repeating layers split among groups<br>\n] https://arxiv.org/abs/1909.11942 <br>\n</font>\n<br><br>\n<font size='3'>\nWHY ?<br> Its Currently Trending on SQuAD2.0 Leaderboard for Question Answering Model F1 Accuracy. So, may be for Q&A apporch it can give nice result.\n</font>\n![](https://i.ibb.co/tsJm3fj/albert.png) "},{"metadata":{},"cell_type":"markdown","source":"# <a name=\"imports\" id=\"1\"></a>1. Install and Import"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install '/kaggle/input/simple-transformers-pypi/seqeval-0.0.12-py3-none-any.whl' -q\n!pip install '/kaggle/input/simple-transformers-pypi/simpletransformers-0.22.1-py3-none-any.whl' -q","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from simpletransformers.question_answering import QuestionAnsweringModel\nimport pandas as pd\nimport numpy as np\nimport json","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\ntest_df = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\nsub_df = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/sample_submission.csv')\n\ntrain = np.array(train_df)\ntest = np.array(test_df)\nuse_cuda = True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a name=\"reading\" id=\"2\"></a> 2. Converting test data to JSON\n\n* Train data is already converted here. https://www.kaggle.com/vaishvik25/tweet-sentiment-extraction-json<br>\n* But during submission kaggle use full test set there it is needed to convert in kernel. <br>\n* The Code of JSON convertion from https://www.kaggle.com/jonathanbesomi/question-answering-starter-pack"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"%%time\n\n\"\"\"\nPrepare testing data in QA-compatible format\n\"\"\"\n\noutput = {}\noutput['version'] = 'v1.0'\noutput['data'] = []\n\ndef do_qa_test(test):\n    paragraphs = []\n    for line in test:\n        context = line[1]\n        qas = []\n        question = line[-1]\n        qid = line[0]\n        if type(context) != str or type(question) != str:\n            print(context, type(context))\n            print(answer, type(answer))\n            print(question, type(question))\n            continue\n        answers = []\n        answers.append({'answer_start': 1000000, 'text': '__None__'})\n        qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n\n        paragraphs.append({'context': context.lower(), 'qas': qas})\n        output['data'].append({'title': 'None', 'paragraphs': paragraphs})\n    return paragraphs\n\nqa_test = do_qa_test(test)\n\nwith open('test.json', 'w') as outfile:\n    json.dump(qa_test, outfile)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a name=\"Training\" id=\"3\"></a> 3. Model Training ....\n\nUsing my training kernel out to save GPU time.<br>\nTo train uncomment train command."},{"metadata":{"trusted":true},"cell_type":"code","source":"MODEL_PATH = '/kaggle/input/albert-train/outputs/checkpoint-10308-epoch-3/' # MODEL PATH OF PRETRAINED MODEL\n\n\nmodel = QuestionAnsweringModel('albert', \n                               MODEL_PATH, \n                                   args={'reprocess_input_data': True,\n                                     'overwrite_output_dir': True,\n                                     'learning_rate': 5e-5,\n                                     'num_train_epochs': 3,\n                                     'max_seq_length': 192,\n                                     'doc_stride': 64,\n                                     'fp16': False,\n                                    },\n                              use_cuda=use_cuda)\n\n\n# model.train_model('/kaggle/input/tweet-sentiment-extraction-json/train.json') #UNCOMMENT to TRAIN","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a name=\"Infer\" id=\"4\"></a> 4. Model INFER"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Infering on trained model\npredictions = model.predict(qa_test)\npredictions_df = pd.DataFrame.from_dict(predictions)\n\nsub_df['selected_text'] = predictions_df['answer']\nsub_df.to_csv('submission.csv', index=False)\n\nsub_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n<font size='3' color='Blue'>If you find this kernel useful, consider doing an upvote [^]</font>\n![](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcSMkBhNBPXLA05LbULNGM--2DOdI4z_mQOcrBHkKoLaPA4BwgpI&usqp=CAU)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}