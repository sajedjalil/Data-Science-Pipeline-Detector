{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Import necessary libaries."},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings, re, string\n\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize \n\nfrom wordcloud import WordCloud\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.pipeline import Pipeline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Config\n* Settings to remove `matplotlib` and `sklearn` warnings, width of columns pandas and make constant lists. "},{"metadata":{"trusted":false},"cell_type":"code","source":"warnings.filterwarnings('ignore')\npd.set_option('max_colwidth', -1)\n\nSents = ['negative','neutral','positive']\nColors = {'Reds':'#e60000'\n          , 'Greys':'#a6a6a6'\n          , 'Greens':'#4ecc4e'}\n\nPATH_DATA = '../input/tweet-sentiment-extraction/'","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"df = (pd.read_csv(f'{PATH_DATA}train.csv'              \n                  , sep = ','\n                  , header = 0)\n      .fillna(''))\n\ntest = (pd.read_csv(f'{PATH_DATA}test.csv')\n        .fillna(''))\n\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":false},"cell_type":"code","source":"Grafico = (df.groupby(['sentiment'], as_index = True)\n           .count()['textID']).plot(kind = 'bar'\n                                    , width = 0.5\n                                    , color = Colors.values()\n                                    , stacked = True\n                                    , legend = False\n                                    , fontsize = 10\n                                    , figsize = (5, 3))\n\n[spine.set_visible(False) for spine in Grafico.spines.values()]\n\nGrafico.spines['bottom'].set_visible(True)\nGrafico.grid(axis = 'y', alpha = 0.25)\nGrafico.set_ylabel('')\nGrafico.set_xlabel('')\n\nplt.tick_params(left = False, bottom = False)\nplt.xticks(rotation = 0)\nplt.title('sentiment')\nplt.show()\nplt.close()    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def plotHist(ax, df, Sent, Color):\n    Grafico(df[df.sentiment == Sent].text.str.len(),ax, Color)\n    \ndef plotWords(ax, df, Sent, Color):\n    Grafico(df[df.sentiment == Sent].text.apply(lambda x: len(str(x).split())),ax, Color)\n    \ndef Grafico(serie, ax, Color):\n    ax.hist(serie, color = Color)\n    [spine.set_visible(False) for spine in ax.spines.values()]\n    ax.tick_params(left = False, bottom = False)\n    ax.spines['bottom'].set_visible(True)\n    ax.grid(axis = 'y', alpha = 0.25)\n    \nfig, axs = plt.subplots(1, 3, figsize = (12,3))\nfor ax, Sent, Color in zip(axs, Sents, Colors.values()):\n    plotHist(ax, df, Sent, Color)\n\nfig.suptitle('Caracteres x tweet', x = 0.07, y=0.72, rotation = 90)\nplt.show()\nplt.close()\n\nfig, axs = plt.subplots(1, 3, figsize = (12,3))\nfor ax, Sent, Color in zip(axs, Sents, Colors.values()):\n    plotWords(ax, df, Sent, Color)\n\nfig.suptitle('Words x tweet'\n             , x = 0.07\n             , y = 0.72\n             , rotation = 90)\nplt.show()\nplt.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tokenize & WordCloud"},{"metadata":{"trusted":false},"cell_type":"code","source":"Punct_List = dict((ord(punct), None) for punct in string.punctuation)\n\ndef TxNormalize(text):\n    text = text.lower()\n    tokens = word_tokenize(str(text).replace('/',' ').translate(Punct_List))\n    return [x for x in tokens if x not in stopwords.words('english') + ['u', 'im']]\n\ndef tokenize(df, filtro):\n    tokens = []\n    for i in df[(df.sentiment == filtro) & (df.Val == 0)].text:\n        tokens += TxNormalize(i)\n    return tokens\n\ndef Crear_WordCloud(ax, tokens, Color, Titulo, Theme):\n    if len(tokens) > 0:\n        wc = WordCloud(width = 6000\n                       , height = 3500\n                       , min_font_size = 60\n                       , max_words = 100\n                       , background_color = 'white'\n                       , colormap = Theme\n                       , random_state = 0\n                      ).generate(tokens) \n        \n        ax.imshow(wc)\n        ax.set_title(Titulo, fontsize = 60, color = Color)\n        ax.axis('off')\n\ndef Plot(ax, df, Color, Sent):\n    datos = df.word.value_counts(sort = True).nlargest(25)\n    ax.barh(datos.index, datos.values, color = Color)\n    \n    ax.tick_params(left = False, bottom = False)\n    ax.invert_yaxis()\n    [spine.set_visible(False) for spine in ax.spines.values()]\n    ax.spines['left'].set_visible(True)\n    ax.set_title(Sent.capitalize(), fontsize = 14)\n    ax.grid(axis = 'x', alpha = 0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"Words = [\n    (df[(df.sentiment == Sent)].text\n     .apply(TxNormalize)\n     .explode()\n     .str.cat(sep = ' '))\n    for Sent in Sents]\n\nfig, axs = plt.subplots(nrows = 3, ncols = 1, figsize = (20, 32))\n\nfor ax, Sent, Color, Token, Theme in zip(axs, Sents, Colors.values(), Words, Colors.keys()):\n    Crear_WordCloud(ax, Token, Color, Sent.capitalize(), Theme)\n    \nplt.show()\nplt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig, axs = plt.subplots(nrows = 1, ncols = 3, figsize = (18, 12))\n\nfor ax, Sent, Color, tokens in zip(axs, Sents, Colors.values(), Words):\n    Plot(ax, pd.DataFrame(tokens.split(' '), columns = ['word']), Color, Sent)\n    \nfig.suptitle('Most frecuent words', fontsize = 20)\nplt.show()\nplt.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":false},"cell_type":"code","source":"def createModel():\n    Pipe = Pipeline(steps = [('Vec', CountVectorizer(tokenizer = lambda x: x.split()))\n                             , ('Clf', SGDClassifier(max_iter = 1000, random_state = 0))])\n    \n    return Pipe\n\nX = pd.concat([df.text, test.text], axis=0)\ny = pd.concat([df.sentiment, test.sentiment], axis=0)\n\nModel = createModel().fit(X, y)\npred = Model.predict(X)\n\nprint(classification_report(y_true = y, y_pred = pred))\nprint('\\nShape:', X.shape, y.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Word Selector Model\n\nImplementing the word selection process as a custom estimator class allows using `GridSearchCV` to find best parameters."},{"metadata":{"trusted":false},"cell_type":"code","source":"class WordSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, pos_class_std = 2.2, neg_class_std = 2.2):\n        self.scores = {}\n        self.pos_class_std = pos_class_std\n        self.neg_class_std = neg_class_std\n\n        self.vocabulary_ = Model.named_steps['Vec'].vocabulary_\n        self.coef_ = Model.named_steps['Clf'].coef_ \n        \n        self.weights_by_classes = {\n            'negative': list(enumerate(self.coef_[0]))\n            , 'neutral':  list(enumerate(self.coef_[1]))\n            , 'positive': list(enumerate(self.coef_[2]))\n        }\n  \n    def get_weights(self, text_list, class_weights):\n        text_idx = [self.vocabulary_[tok.lower()] for tok in text_list if tok.lower() in self.vocabulary_]\n        \n        return [class_weights[idx][1] for idx in text_idx]\n\n    def get_top_words(self, words_list, weights_list, num_std):\n        mean, std, top_words = [np.mean(weights_list), np.std(weights_list), []]\n        \n        for word, weight in zip(words_list, weights_list):\n            if weight > (mean +  num_std * std):\n                top_words.append(word)\n                \n        return ' '.join(top_words)\n\n\n    def select_words(self, df):  \n        text, sentiment = df\n\n        if sentiment == 'neutral':\n            return text\n        elif sentiment == 'positive':\n            num_std = self.pos_class_std\n        else:\n            num_std = self.neg_class_std   \n            \n        text = ' '.join(re.sub('(\\w+:\\/\\/\\S+)', ' ', text).split()).split()\n        weights = self.get_weights(text, self.weights_by_classes[sentiment])\n        res = self.get_top_words(text, weights, num_std = num_std)\n\n        return ' '.join(text) if res == '' else res\n    \n    def fit(self, X, y = None):\n        return self\n    \n    def predict(self, X):\n\n        df = X\n        df['selected_text'] = X[['text', 'sentiment']].apply(self.select_words, axis=1)\n\n        return df.selected_text\n    \n    def jaccard(self, df):\n        \n        a = set(df.predictions.lower().split()) \n        b = set(df.selected_text.lower().split())\n        \n        if len(a) + len(b) == 0:\n            return 0.5\n        c = a.intersection(b)\n        return float(len(c)) / (len(a) + len(b) - len(c))\n\n    def score(self, X, y):\n        df = X\n        df['selected_text'] = y\n        df['predictions'] = self.predict(df[['text', 'sentiment']])\n        \n        df['score'] = df[['predictions', 'selected_text']].apply(self.jaccard, axis=1)\n\n        return round(df.score.mean(), 4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Grid Search for Word Selector Model"},{"metadata":{"trusted":false},"cell_type":"code","source":"parameters = {\n    'pos_class_std': [1.90, 1.93, 1.95, 1.98]\n    , 'neg_class_std': [2.28, 2.3, 2.32, 2.34]\n}\n\ngs = GridSearchCV(WordSelector()\n                  , parameters\n                  , cv = 5\n                  , verbose = 1\n                  , n_jobs = -1\n                 )\n\ngs = gs.fit(df[['text', 'sentiment']], df['selected_text'])\n\ngs.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"word_selector = WordSelector(pos_class_std = gs.best_params_['pos_class_std']\n                             , neg_class_std = gs.best_params_['neg_class_std'])\n\ndf['predictions'] = word_selector.predict(df[['text', 'sentiment']])\ndf['score'] = df[['predictions', 'selected_text']].apply(word_selector.jaccard, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def Matriz(df, Score):\n    df = (df.groupby('sentiment')['score'].agg([np.sum, np.size])\n          .reset_index())\n    \n    df['1'] = df['size'] - df['sum']\n    \n    Grafico = (df[['sentiment','sum', '1']]\n               .set_index('sentiment')\n               .reindex(columns=['sum', '1'])).plot(kind = 'bar'\n                                                    , width = 0.5\n                                                    , color = [['#00acee','#00acee','#00acee'], Colors.values()]\n                                                    , stacked = True\n                                                    , legend = False\n                                                    , fontsize = 10\n                                                    , figsize = (5, 3))\n\n    [spine.set_visible(False) for spine in Grafico.spines.values()]\n\n    Grafico.spines['bottom'].set_visible(True)    \n    Grafico.grid(axis = 'y', alpha = 0.25)\n    Grafico.set_ylabel('')\n    Grafico.set_xlabel('')\n\n    Grafico.legend({'Jaccard: ' + str(round(Score * 100,2)) + ' %'}\n                   , loc = 'center'\n                   , bbox_to_anchor = (0.5, 1.13)\n                   , ncol = 1\n                   , frameon = False\n                   , fontsize = 12)\n\n    plt.tick_params(left = False, bottom = False)\n    plt.xticks(rotation = 0)\n    plt.show()\n    plt.close()\n\nMatriz(df, word_selector.score(df[['text', 'sentiment']], df.selected_text))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Submission"},{"metadata":{"trusted":false},"cell_type":"code","source":"test['selected_text'] = word_selector.predict(test[['text', 'sentiment']])\n\ntest[['textID','selected_text']].to_csv('submission.csv', index=False, header=True)\n\ntest[['textID','selected_text']].head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.2"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":4}