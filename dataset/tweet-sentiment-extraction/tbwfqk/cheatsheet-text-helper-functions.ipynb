{"cells":[{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"brown\"><i><b><center>\"With hard work, you can get fire out of a stone.\"</center></b></i></font>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+3\" color=purple ><b> <center><u>Text Helper Functions</u></center></b></font>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Version 4**  :  First Run <br>\n**Version 6**  :  Added 9 new regex function required for text processing.<br>\n**Version 7**  :  Added few functions and modified scripts.<br>\n**Version 8**  :  Updated kernel with few more functions and modified scripts.<br>\n**Version 9**  :  Modified script <br>\n**Version 10** :  Added description and modified script in 4.13 <br>\n**Version 11** :  Added few more helpers<br>\n**Version 12** :  Few modifications and added few more helpers<br>\n**Version 13** :  Added two more functions.<br>\n**Version 14** :  Small modification<br>\n**Version 15** :  Added more function<br>\n**Version 16** :  Added tag function<br>\n**Version 17** :  Fixed bug from V16<br>\n**Version 18** :  Added two more functions- ip and mac address<br>\n**Version 19** :  Added subword and latitude & longitude<br>\n**Version 20** :  Added PAN validation <br>\n**Version 21** :  Added Phone Number Country code<br>\n**Version 22** :  Added Positive and Negative look ahead<br>\n**Version 23** :  Added Positive and Negative look behind<br>\n**Version 24** :  (Current) Bug fix from V23<br>\n**Version 25** :  *Loading...*","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id='top'></a>\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\"  role=\"tab\" aria-controls=\"home\">Table of content</h3>\n\n* [1. Objective](#1)   \n* [2. Data](#2)\n* [3. Basic Data Explorers](#3)\n    - [3.1 Missing values](#3.1)\n    - [3.2 Count values](#3.2)\n    - [3.3 Unique values](#3.3)\n    - [3.4 Duplicate values](#3.4)\n    - [3.5 Stat](#3.5)\n* [4. Regex Helpers](#4)\n    - [4.1 URL](#4.1)\n    - [4.2 Emoticons](#4.2)\n    - [4.3 Email](#4.3)\n    - [4.4 Hash](#4.4)\n    - [4.5 Mention](#4.5)\n    - [4.6 Number](#4.6)\n    - [4.7 Phone Number](#4.7)\n    - [4.8 Year](#4.8)\n    - [4.9 Non Alphanumeric](#4.9)\n    - [4.10 Punctuations](#4.10)\n    - [4.11 Stopwords](#4.11)\n    - [4.12 N-grams](#4.12)\n    - [4.13 Repetitive Character](#4.13)\n    - [4.14 Dollar](#4.14)\n    - [4.15 Number-Greater](#4.15)\n    - [4.16 Number- Lesser](#4.16)\n    - [4.17 OR](#4.17)\n    - [4.18 AND](#4.18)\n    - [4.19 Dates](#4.19)\n    - [4.20 Only Words](#4.20)\n    - [4.21 Only Numbers](#4.21)\n    - [4.22 Boundaries](#4.22)\n    - [4.23 Search](#4.23)\n    - [4.24 Pick Sentence](#4.24)\n    - [4.25 Duplicate Sentence](#4.25)\n    - [4.26 Caps Words](#4.26)\n    - [4.27 Length of Words](#4.27)\n    - [4.28 Length of Characters](#4.28)\n    - [4.29 Get ID](#4.29)\n    - [4.30 Specific String Rows](#4.30)\n    - [4.31 Hex code to Color](#4.31)\n    - [4.32 Tags](#4.32)\n    - [4.33 IP Address](#4.33)\n    - [4.34 Mac Address](#4.34)\n    - [4.35 Subword](#4.35)\n    - [4.36 Latitude & Longitude](#4.36)\n    - [4.37 PAN](#4.37)\n    - [4.38 Phone Number Country Code](#4.38)\n    - [4.39 Positive Look Ahead](#4.39)\n    - [4.40 Negative Look Ahead](#4.40)\n    - [4.41 Positive Look Behind](#4.41)\n    - [4.42 Negative Look Behind](#4.42)\n    \n* [5. End Notes](#5)\n    ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+3\" color=\"blue\"><b>1. Objective</b></font><br><a id=\"1\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"The aim of this kernel is to provide helper function for basic text processing.This functions can aid you to understand the data much better and perform EDA.\nMy major focus will be on apply regex on text but still i have mentioned few basic starter codes on the 3rd part of kernel.Rest all sections will deal with text preprocessing.The whole kernel can be useful for everyone especially **beginners**.\n\n<font size=\"+1\"><i>Readers,I am making you lazy to code but at same time I am helping you out.Do utilize this kernel for any of your text oriented competitions.</i></font><br><br>\n    \n<font size=\"+1\" color=chocolate ><b>Please appreciate me through your Upvote.</b></font>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+3\" color=\"blue\"><b>2. Data</b></font><br><a id=\"2\"></a>\n\nI will be using data from [Twitter Sentiment Analysis](https://www.kaggle.com/c/tweet-sentiment-extraction/data) competiton","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport re\nimport emoji\n\n#Count vectorizer for N grams\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n\n# Nltk for tekenize and stopwords\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize \n\n#Loading data\ndf=pd.read_csv('../input/tweet-sentiment-extraction/train.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+3\" color=\"blue\"><b>3. Basic Data Explorers</b></font><br> <a id=\"3\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"indigo\"><b>3.1 Missing values</b></font><br><a id=\"3.1\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def missing_value_of_data(data):\n    total=data.isnull().sum().sort_values(ascending=False)\n    percentage=round(total/data.shape[0]*100,2)\n    return pd.concat([total,percentage],axis=1,keys=['Total','Percentage'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missing_value_of_data(df)\n#  Reason for 0 percentage value = Round of 1 divided by 27481 will be 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will drop NA values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df=df.dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"indigo\"><b>3.2 Count Values</b></font><br><a id=\"3.2\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_values_in_column(data,feature):\n    total=data.loc[:,feature].value_counts(dropna=False)\n    percentage=round(data.loc[:,feature].value_counts(dropna=False,normalize=True)*100,2)\n    return pd.concat([total,percentage],axis=1,keys=['Total','Percentage'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_values_in_column(df,'sentiment')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"indigo\"><b>3.3 Unique Values</b></font><br><a id=\"3.3\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def unique_values_in_column(data,feature):\n    unique_val=pd.Series(data.loc[:,feature].unique())\n    return pd.concat([unique_val],axis=1,keys=['Unique Values'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_values_in_column(df,'sentiment')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"indigo\"><b>3.4 Duplicate Values</b></font><br><a id=\"3.4\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"    \ndef duplicated_values_data(data):\n    dup=[]\n    columns=data.columns\n    for i in data.columns:\n        dup.append(sum(data[i].duplicated()))\n    return pd.concat([pd.Series(columns),pd.Series(dup)],axis=1,keys=['Columns','Duplicate count'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"duplicated_values_data(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"indigo\"><b>3.5 Stat</b></font><br><a id=\"3.5\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since these kind of basic python functions are pretty much well known to all python users.We dont need much focus here.Still I will elaborate this section in upcoming versions.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+3\" color=\"blue\"><b>4. Regex Helpers</b></font><br> \n<a id=\"4\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Major RE functions\n\n* **re.findall**   - Module is used to search for ‚Äúall‚Äù occurrences that match a given pattern.\n* **re.sub**       - Substitute the matched RE patter with given text\n* **re.match**     - The match function is used to match the RE pattern to string with optional flags\n* **re.search**    - This method takes a regular expression pattern and a string and searches for that pattern with the string.\n\n\nWe will be mostly using re.findall to detect patterns.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"indigo\"><b>4.1 URL</b></font><br><a id=\"4.1\"></a>","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def find_url(string): \n    text = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',string)\n    return \"\".join(text) # converting return value from list to string","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=\"I love spending time at https://www.kaggle.com/\"\nfind_url(sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['url']=df['text'].apply(lambda x:find_url(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"indigo\"><b>4.2 Emoticons</b></font><br><a id=\"4.2\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Find and convert emoji to text","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_emoji(text):\n    emo_text=emoji.demojize(text)\n    line=re.findall(r'\\:(.*?)\\:',emo_text)\n    return line","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=\"I love ‚öΩ very much üòÅ\"\nfind_emoji(sentence)\n\n# Emoji cheat sheet - https://www.webfx.com/tools/emoji-cheat-sheet/\n# Uniceode for all emoji : https://unicode.org/emoji/charts/full-emoji-list.html","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['emoji']=df['text'].apply(lambda x: find_emoji(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Remove Emoji from text","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=\"Its all about \\U0001F600 face\"\nprint(sentence)\nremove_emoji(sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['text']=df['text'].apply(lambda x: remove_emoji(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"indigo\"><b>4.3 Email</b></font><br><a id=\"4.3\"></a>\n\nExtract email from text","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_email(text):\n    line = re.findall(r'[\\w\\.-]+@[\\w\\.-]+',str(text))\n    return \",\".join(line)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=\"My gmail is abc99@gmail.com\"\nfind_email(sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['email']=df['text'].apply(lambda x: find_email(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"indigo\"><b>4.4 Hash</b></font><br><a id=\"4.4\"></a>\n\nThis value is especially to denote trends in twitter.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_hash(text):\n    line=re.findall(r'(?<=#)\\w+',text)\n    return \" \".join(line)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=\"#Corona is trending now in the world\" \nfind_hash(sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['hash']=df['text'].apply(lambda x: find_hash(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"indigo\"><b>4.5 Mention</b></font><br><a id=\"4.5\"></a>\n\n@ - Used to mention someone in tweets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_at(text):\n    line=re.findall(r'(?<=@)\\w+',text)\n    return \" \".join(line)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=\"@David,can you help me out\"\nfind_at(sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['at_mention']=df['text'].apply(lambda x: find_at(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"indigo\"><b>4.6 Number</b></font><br><a id=\"4.6\"></a>\n\nPick only number from sentence","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_number(text):\n    line=re.findall(r'[0-9]+',text)\n    return \" \".join(line)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=\"2833047 people are affected by corona now\"\nfind_number(sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['number']=df['text'].apply(lambda x: find_number(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"indigo\"><b>4.7 Phone Number</b></font><br><a id=\"4.7\"></a>\n\nIndian Mobile numbers have ten digit.I will write that pattern below","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_phone_number(text):\n    line=re.findall(r\"\\b\\d{10}\\b\",text)\n    return \"\".join(line)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"find_phone_number(\"9998887776 is a phone number of Mark from 210,North Avenue\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['phone_number']=df['text'].apply(lambda x: find_phone_number(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"indigo\"><b>4.8 Year</b></font><br><a id=\"4.8\"></a>\n\nExtract year from 1940 till 2020","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_year(text):\n    line=re.findall(r\"\\b(19[40][0-9]|20[0-1][0-9]|2020)\\b\",text)\n    return line","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=\"India got independence on 1947.\"\nfind_year(sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['year']=df['text'].apply(lambda x: find_year(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"indigo\"><b>4.9 Non Alphanumeric</b></font><br><a id=\"4.9\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_nonalp(text):\n    line = re.findall(\"[^A-Za-z0-9 ]\",text)\n    return line","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=\"Twitter has lots of @ and # in posts.(general tweet)\"\nfind_nonalp(sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['non_alp']=df['text'].apply(lambda x: find_nonalp(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"indigo\"><b>4.10 Punctuations</b></font><br><a id=\"4.10\"></a>\n\nRetrieve punctuations from sentence.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_punct(text):\n    line = re.findall(r'[!\"\\$%&\\'()*+,\\-.\\/:;=#@?\\[\\\\\\]^_`{|}~]*', text)\n    string=\"\".join(line)\n    return list(string)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"example=\"Corona virus have kiled #24506 confirmed cases now.#Corona is un(tolerable)\"\nprint(find_punct(example))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['punctuation']=df['text'].apply(lambda x : find_punct(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"indigo\"><b>4.11 Stopwords</b></font><br><a id=\"4.11\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def stop_word_fn(text):\n    stop_words = set(stopwords.words('english')) \n    word_tokens = word_tokenize(text) \n    non_stop_words = [w for w in word_tokens if not w in stop_words] \n    stop_words= [w for w in word_tokens if w in stop_words] \n    return stop_words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"example_sent = \"This is a sample sentence, showing off the stop words filtration.\"\nstop_word_fn(example_sent)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['stop_words']=df['text'].apply(lambda x : stop_word_fn(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"indigo\"><b>4.12 N-grams</b></font><br><a id=\"4.12\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def ngrams_top(corpus,ngram_range,n=None):\n    \"\"\"\n    List the top n words in a vocabulary according to occurrence in a text corpus.\n    \"\"\"\n    vec = CountVectorizer(stop_words = 'english',ngram_range=ngram_range).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    total_list=words_freq[:n]\n    df=pd.DataFrame(total_list,columns=['text','count'])\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ngrams_top(df['text'],(1,1),n=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ngrams_top(df['text'],(2,2),n=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ngrams_top(df['text'],(3,3),n=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"indigo\"><b>4.13 Repetitive Character</b></font><br><a id=\"4.13\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"If you want to change match repetitive characters to n numbers,**chage the return line in the *rep function* to grp[0:n]**.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def rep(text):\n    grp = text.group(0)\n    if len(grp) > 1:\n        return grp[0:1] # can change the value here on repetition\ndef unique_char(rep,sentence):\n    convert = re.sub(r'(\\w)\\1+', rep, sentence) \n    return convert","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=\"heyyy this is loong textttt sooon\"\nunique_char(rep,sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['unique_char']=df['text'].apply(lambda x : unique_char(rep,x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"indigo\"><b>4.14 Dollar</b></font><br><a id=\"4.14\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_dollar(text):\n    line=re.findall(r'\\$\\d+(?:\\.\\d+)?',text)\n    return \" \".join(line)\n\n# \\$ - dollar sign followed by\n# \\d+ one or more digits\n# (?:\\.\\d+)? - decimal which is optional","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=\"this shirt costs $20.56\"\nfind_dollar(sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['dollar']=df['text'].apply(lambda x : find_dollar(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"indigo\"><b>4.15 Number-Greater</b></font><br><a id=\"4.15\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Number greater than 930\ndef num_great(text): \n    line=re.findall(r'9[3-9][0-9]|[1-9]\\d{3,}',text)\n    return \" \".join(line)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=\"It is expected to be more than 935 corona death and 29974 observation cases across 29 states in india\"\nnum_great(sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Number greater than 930 (Just part of example)\ndf['num_great']=df['text'].apply(lambda x : num_great(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"indigo\"><b>4.16 Number Lesser</b></font><br><a id=\"4.16\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number less than 930\ndef num_less(text):\n    only_num=[]\n    for i in text.split():\n        line=re.findall(r'^(9[0-2][0-0]|[1-8][0-9][0-9]|[1-9][0-9]|[0-9])$',i) # 5 500\n        only_num.append(line)\n        all_num=[\",\".join(x) for x in only_num if x != []]\n    return \" \".join(all_num)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=\"There are some countries where less than 920 cases exist with 1100 observations\"\nnum_less(sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Number greater than 930 (Just part of example)\ndf['num_less']=df['text'].apply(lambda x : num_less(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"indigo\"><b>4.17 OR</b></font><br><a id=\"4.17\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def or_cond(text,key1,key2):\n    line=re.findall(r\"{}|{}\".format(key1,key2), text) \n    return \" \".join(line)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=\"sad and sorrow displays emotions\"\nor_cond(sentence,'sad','sorrow')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looks for sorrow or sad word\ndf['sad_or_sorrow']=df['text'].apply(lambda x : or_cond(x,'sad','sorrow'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"indigo\"><b>4.18 AND</b></font><br><a id=\"4.18\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def and_cond(text):\n    line=re.findall(r'(?=.*do)(?=.*die).*', text) \n    return \" \".join(line)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Both string present:\",and_cond(\"do or die is a motivating phrase\"))\nprint(\"Only one string present :\",and_cond('die word is other side of emotion'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Looks for do and die both else empty\ndf['do_and_die']=df['text'].apply(lambda x : and_cond(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"indigo\"><b>4.19 Dates</b></font><br><a id=\"4.19\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# mm-dd-yyyy format \ndef find_dates(text):\n    line=re.findall(r'\\b(1[0-2]|0[1-9])/(3[01]|[12][0-9]|0[1-9])/([0-9]{4})\\b',text)\n    return line\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=\"Todays date is 04/28/2020 for format mm/dd/yyyy, not 28/04/2020\"\nfind_dates(sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['dates']=df['text'].apply(lambda x : find_dates(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"indigo\"><b>4.20 Only Words</b></font><br><a id=\"4.20\"></a>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def only_words(text):\n    line=re.findall(r'\\b[^\\d\\W]+\\b', text)\n    return \" \".join(line)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=\"the world population has grown from 1650 million to 6000 million\"\nonly_words(sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['only_words']=df['text'].apply(lambda x : only_words(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.21\"></a>\n<font size=\"+2\" color=\"indigo\"><b>4.21 Only Numbers</b></font>","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def only_numbers(text):\n    line=re.findall(r'\\b\\d+\\b', text)\n    return \" \".join(line)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=\"the world population has grown from 1650 million to 6000 million\"\nonly_numbers(sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['only_num']=df['text'].apply(lambda x : only_numbers(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.22\"></a>\n<font size=\"+2\" color=\"indigo\"><b>4.22 Boundaries</b></font><br><br>\nPicking up the words with boundaries","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extracting word with boundary\ndef boundary(text):\n    line=re.findall(r'\\bneutral\\b', text)\n    return \" \".join(line)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=\"Most tweets are neutral in twitter\"\nboundary(sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['bound']=df['text'].apply(lambda x : boundary(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.23\"></a>\n<font size=\"+2\" color=\"indigo\"><b>4.23 Search</b></font><br><br>\nIs the key word present in the sentence?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def search_string(text,key):\n    return bool(re.search(r''+key+'', text))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=\"Happy Mothers day to all Moms\"\nsearch_string(sentence,'day')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['search_day']=df['text'].apply(lambda x : search_string(x,'day'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.24\"></a>\n<font size=\"+2\" color=\"indigo\"><b>4.24 Pick Sentence</b></font><br><br>\nIf we want to get all sentence with particular keyword.We can use below function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def pick_only_key_sentence(text,keyword):\n    line=re.findall(r'([^.]*'+keyword+'[^.]*)', text)\n    return line","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=\"People are fighting with covid these days.Economy has fallen down.How will we survice covid\"\npick_only_key_sentence(sentence,'covid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['pick_senence']=df['text'].apply(lambda x : pick_only_key_sentence(x,'covid'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.25\"></a>\n<font size=\"+2\" color=\"indigo\"><b>4.25 Duplicate Sentence</b></font><br><br>\nMost webscrapped data contains duplicated sentence.This function could retrieve unique ones.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def pick_unique_sentence(text):\n    line=re.findall(r'(?sm)(^[^\\r\\n]+$)(?!.*^\\1$)', text)\n    return line","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=\"I thank doctors\\nDoctors are working very hard in this pandemic situation\\nI thank doctors\"\npick_unique_sentence(sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['pick_unique']=df['text'].apply(lambda x : pick_unique_sentence(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.26\"></a>\n<font size=\"+2\" color=\"indigo\"><b>4.26 Caps Words</b></font><br><br>\nExtract words starting with capital letter.Some words like names,place or universal object are usually mentioned in a text starting with CAPS.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_capital(text):\n    line=re.findall(r'\\b[A-Z]\\w+', text)\n    return line","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=\"World is affected by corona crisis.No one other than God can save us from it\"\nfind_capital(sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['caps_word']=df['text'].apply(lambda x : find_capital(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.27\"></a>\n<font size=\"+2\" color=\"indigo\"><b>4.27 Length of words</b></font><br><br>\nNo regex but added one liner to identify length of words in a sentence","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['text_length']=df['text'].str.split().map(lambda x: len(x))\ndf[['text','text_length']].sample(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.28\"></a>\n<font size=\"+2\" color=\"indigo\"><b>4.28 Length of characters</b></font><br><br>\nNo regex but added one liner to identify length of characters in a sentence including space","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['char_length']=df['text'].str.len()\ndf[['text','char_length']].sample(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.29\"></a>\n<font size=\"+2\" color=\"indigo\"><b>4.29 Get ID</b></font><br><br>\nMost data has IDs in it with some prefix.So if we want to pick only numbers in ID leaving the prefix out,we can apply below function.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_id(text):\n    line=re.findall(r'\\bIND(\\d+)', text)\n    return line","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=\"My company id is IND50120.And I work under Asia region\"\nfind_id(sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['get_id']=df['text'].apply(lambda x : find_id(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.30\"></a>\n<font size=\"+2\" color=\"indigo\"><b>4.30 Specific String Rows</b></font><br><br>\nQuering for specific string can also be done by directly applying *\"str.contains(\"XXXX\")\"* to a series/column of a dataframe","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"my_string_rows = df[df['text'].str.contains(\"good\")]\nmy_string_rows[['text']].sample(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.31\"></a>\n<font size=\"+2\" color=\"indigo\"><b>4.31 Hex code to Color</b></font><br><br>\nConverting hex color codes to color names.We will install and import webcolors. (only for CSS3 colors)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install webcolors\nimport webcolors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_color(string): \n    text = re.findall('\\#(?:[0-9a-fA-F]{3}){1,2}',string)\n    conv_name=[]\n    for i in text:\n        conv_name.append(webcolors.hex_to_name(i))\n    return conv_name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=\"Find the color of #00FF00 and #FF4500\"\nfind_color(sentence)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Try more hex codes:https://www.rapidtables.com/web/css/css-color.html","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.32\"></a>\n<font size=\"+2\" color=\"indigo\"><b>4.32 Tags</b></font><br><br>\nMost of web scrapped data contains html tags.It can be removed from below re script","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_tag(string):\n    text=re.sub('<.*?>','',string)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=\"Markdown sentences can use <br> for breaks and <i></i> for italics\"\nremove_tag(sentence)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.33\"></a>\n<font size=\"+2\" color=\"indigo\"><b>4.33 IP Address</b></font><br><br>\nExtract IP address from text.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def ip_add(string):\n    text=re.findall('\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}',string)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=\"An example of ip address is 125.16.100.1\"\nip_add(sentence)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.34\"></a>\n<font size=\"+2\" color=\"indigo\"><b>4.34 Mac Address</b></font><br><br>\nExtract Mac address from text.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def mac_add(string):\n    text=re.findall('(?:[0-9a-fA-F]:?){12}',string)\n    return text\n#https://stackoverflow.com/questions/26891833/python-regex-extract-mac-addresses-from-string/26892371","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence=\"MAC ADDRESSES of this laptop - 00:24:17:b1:cc:cc .Other details will be mentioned\"\nmac_add(sentence)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.35\"></a>\n<font size=\"+2\" color=\"indigo\"><b>4.35 Subword</b></font><br><br>\nExtract number of subwords from sentences and words.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def subword(string,sub): \n    text=re.findall(sub,string)\n    return len(text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence = 'Fundamentalism and constructivism are important skills'\nsubword(sentence,'ism') # change subword and try for others","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.36\"></a>\n<font size=\"+2\" color=\"indigo\"><b>4.36 Latitude & Longitude</b></font><br><br>\nExtract number of subwords from sentences and words.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def lat_lon(string):\n    text=re.findall(r'^[-+]?([1-8]?\\d(\\.\\d+)?|90(\\.0+)?),\\s*[-+]?(180(\\.0+)?|((1[0-7]\\d)|([1-9]?\\d))(\\.\\d+)?)$',string)\n    if text!=[]:\n        print(\"[{}] is valid latitude & longitude\".format(string))\n    else:\n        print(\"[{}] is not a valid latitude & longitude\".format(string))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lat_lon('28.6466772,76.8130649')\nlat_lon('2324.3244,3423.432423')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.37\"></a>\n<font size=\"+2\" color=\"indigo\"><b>4.37 PAN</b></font><br><br>\n\nPAN Validation:\n\n[First 5 letters in CAPS+4 didgits+Last letter in CAPS]","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def valid_pan(string):\n    text=re.findall(r'^([A-Z]){5}([0-9]){4}([A-Z]){1}$',string)\n    if text!=[]:\n        print(\"{} is valid PAN number\".format(string))\n    else:\n        print(\"{} is not a valid PAN number\".format(string))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_pan(\"ABCSD0123K\")\nvalid_pan(\"LEcGD012eg\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.38\"></a>\n<font size=\"+2\" color=\"indigo\"><b>4.38 Phone number Code</b></font><br><br>\n**Format**: [Country code]-[Local Area Code]-[Number]  ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def valid_phone_code(string):\n    text=re.findall(r'^([0-9]){2}(-)([0-9]){2}(-)(\\d+)$',string)\n    if text!=[]:\n        print(\"{} is valid Indian Phone number wth country code\".format(string))\n    else:\n        print(\"{} is not a valid Indian Phone number wth country code\".format(string))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_phone_code('91-44-23413627')\nvalid_phone_code('291-4456-23413627')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.39\"></a>\n<font size=\"+2\" color=\"indigo\"><b>4.39 Positive Look Ahead</b></font><br><br>\nPositive look ahead will succeed if passed non-consuming expression **does match** against the forthcoming input.<br>\nThe syntax is <code>A(?=B)</code> where <code>A</code> is actual expression and <code>B</code> is non-consuming expression.\n\nScripts utlized from [here](https://github.com/nikhilkumarsingh/RegEx-In-Python/blob/master/16.%20Look%20ahead.ipynb)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def pos_look_ahead(string,A,B):\n    pattern = re.compile(''+A+'(?=\\s'+B+')')\n    match = pattern.search(string)\n    print(\"position:{} Matched word:{}\".format(match.span(),match.group()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos_look_ahead(\"I love kaggle. I love DL\",\"love\",\"DL\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.40\"></a>\n<font size=\"+2\" color=\"indigo\"><b>4.40 Negative Look Ahead</b></font><br><br>\nNegative look ahead will succeed if passed non-consuming expression **does not match** against the forthcoming input.<br>\nThe syntax is <code>A(?!B)</code> where <code>A</code> is actual expression and <code>B</code> is non-consuming expression.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def neg_look_ahead(string,A,B):\n    pattern = re.compile(''+A+'(?!\\s'+B+')')\n    match = pattern.search(string)\n    print(\"position:{} Matched word:{}\".format(match.span(),match.group()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neg_look_ahead(\"I love kaggle. I love DL\",\"love\",\"DL\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.41\"></a>\n<font size=\"+2\" color=\"indigo\"><b>4.41 Positive Look Behind</b></font><br><br>\nPositive look behind will succeed if passed non-consuming expression **does match** against the forthcoming input.<br>\nThe syntax is <code>A(?<=B)</code> where <code>A</code> is actual expression and <code>B</code> is non-consuming expression.\n    \nScripts utilized from [here](https://github.com/nikhilkumarsingh/RegEx-In-Python/blob/master/17.%20Look%20behind.ipynb)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def pos_look_behind(string,A,B):\n    pattern = re.compile(\"(?<=\"+A+\"\\s)\"+B+\"\")\n    match = pattern.search(string)\n    print(\"position:{} Matched word: {}\".format(match.span(),match.group()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos_look_behind(\"i love nlp.everyone likes nlp\",\"love\",\"nlp\")\n# the word \"nlp\" that do come after \"love\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4.42\"></a>\n<font size=\"+2\" color=\"indigo\"><b>4.42 Negative Look Behind</b></font><br><br>\nPositive look behind will succeed if passed non-consuming expression **does not match** against the forthcoming input.<br>\nThe syntax is \"A(?<!=B)\" where \"A\"is actual expression and \"B\" is non-consuming expression.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def neg_look_behind(string,A,B):\n    pattern = re.compile(\"(?<!\"+A+\"\\s)\"+B+\"\")\n    match = pattern.search(string)\n    print(\"position:{} Matched word: {}\".format(match.span(),match.group()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neg_look_behind(\"i love nlp.everyone likes nlp\",\"love\",\"nlp\")\n# the word \"nlp\" that doesnt come after \"love\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## *Data with new Features*","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sample(5)\n# We will see empty values too as most of text may not have related feature.You can filter and check.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+3\" color=\"blue\"><b>5. End Notes</b></font><br> <a id=\"5\"></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"No worries.This is not the end of kernel.**I have updated this kernel with few more functions (Now version 24 is live)**.Going forward i will add more helper functions in upcoming versions.I would like to get appreciation from you with an üëç .Please <font size=\"+1\" color=\"red\"><b>Upvote</b></font> and keep it in your favourite list.\n\nThanks for your patience.\n\n\n*Happy Kaggling!!!*.\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"chocolate\"><b>My Other Kernels</b></font><br>\n\nClick on the button to view kernels...\n\n<a href=\"https://www.kaggle.com/raenish/cheatsheet-100-plotly-part-1-basic\" class=\"btn btn-primary\" style=\"color:white;\">100+ Plotly Basic</a>\n\n<a href=\"https://www.kaggle.com/raenish/cheatsheet-100-plotly-part-2-advanced\" class=\"btn btn-primary\" style=\"color:white;\">100+ Plotly Advanced</a>\n\n<a href=\"https://www.kaggle.com/raenish/don-t-shoot/\" class=\"btn btn-primary\" style=\"color:white;\">Don't Shoot</a>\n\n<a href=\"https://www.kaggle.com/raenish/become-grandmaster/\" class=\"btn btn-primary\" style=\"color:white;\">Become GrandMaster</a>\n\n<a href=\"https://www.kaggle.com/raenish/cheatsheet-date-helpers/\" class=\"btn btn-primary\" style=\"color:white;\">Cheatsheet Date Helpers</a>\n\n<a href=\"https://www.kaggle.com/raenish/tweet-sentiment-insight-eda/\" class=\"btn btn-primary\" style=\"color:white;\">Tweet Sentiment Extraction</a>\n<br>\n<br>\n### If these kernels impress you,give them an <font size=\"+2\" color=\"red\"><b>Upvote</b></font>.<br>\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<font size=\"+2\" color=\"chocolate\"><b>Reference</b></font><br>\n* https://www.guru99.com/python-regular-expressions-complete-tutorial.html\n* https://docs.python.org/3.4/library/re.html\n* https://www3.ntu.edu.sg/home/ehchua/programming/howto/Regexe.html#zz-1.9\n* https://www.debuggex.com/cheatsheet/regex/python\n* https://blog.finxter.com/python-regex-and-operator-tutorial-video/\n* https://www.oreilly.com/library/view/regular-expressions-cookbook/9781449327453/ch04s04.html\n* https://www.webfx.com/tools/emoji-cheat-sheet/\n* https://github.com/nikhilkumarsingh/RegEx-In-Python/blob/master/17.%20Look%20behind.ipynb\n* https://github.com/nikhilkumarsingh/RegEx-In-Python/blob/master/16.%20Look%20ahead.ipynb","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Version 25** : <font size=\"+3\" color=\"red\"><b><i>Loading...</i></b></font><br><br>\n<a href=\"#top\" class=\"btn btn-success btn-lg active\" role=\"button\" aria-pressed=\"true\" style=\"color:white\" data-toggle=\"popover\" title=\"go to Colors\">Go to TOP</a>","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}