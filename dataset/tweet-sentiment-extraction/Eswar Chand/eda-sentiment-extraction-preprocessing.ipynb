{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"!pip install chart_studio\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom wordcloud import WordCloud, STOPWORDS\nimport spacy\nfrom spacy.lang.en.stop_words import STOP_WORDS\nfrom spacy.lang.en import English\nimport re\nimport string\n\nimport matplotlib.pyplot as plt\nfrom plotly import tools\nimport chart_studio.plotly as py\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nimport seaborn as sns\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading the data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\ntest = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\nsub = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['text'] = train['text'].str.replace('[{}]'.format(string.punctuation), '')\ntest['text'] = test['text'].str.replace('[{}]'.format(string.punctuation), '')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.size)\nprint(train.shape)\nprint(test.shape)\nprint(test.size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train['sentiment'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Word clouds of Text:"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"# Thanks : https://www.kaggle.com/aashita/word-clouds-of-various-shapes ##\ndef plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(10.0,10.0), color = 'white',\n                   title = None, title_size=40, image_color=False):\n    stopwords = set(STOPWORDS)\n    more_stopwords = {'one', 'br', 'Po', 'th', 'sayi', 'fo', 'Unknown'}\n    stopwords = stopwords.union(more_stopwords)\n\n    wordcloud = WordCloud(background_color=color,\n                    stopwords = stopwords,\n                    max_words = max_words,\n                    max_font_size = max_font_size, \n                    random_state = 42,\n                    width=600, \n                    height=300,\n                    mask = mask)\n    wordcloud.generate(str(text))\n    \n    plt.figure(figsize=figure_size)\n    if image_color:\n        image_colors = ImageColorGenerator(mask);\n        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n        plt.title(title, fontdict={'size': title_size,  \n                                  'verticalalignment': 'bottom'})\n    else:\n        plt.imshow(wordcloud);\n        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n                                  'verticalalignment': 'bottom'})\n    plt.axis('off');\n    plt.tight_layout()  \n    \nplot_wordcloud(train.loc[train['sentiment'] == 'neutral', 'text'].append(test.loc[test['sentiment'] == 'neutral', 'text']), title=\"Word Cloud of Neutral tweets\",color = 'white')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_wordcloud(train.loc[train['sentiment'] == 'positive', 'text'].append(test.loc[test['sentiment'] == 'positive', 'text']), title=\"Word Cloud of Positive tweets\",color = 'green')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_wordcloud(train.loc[train['sentiment'] == 'negative', 'text'].append(test.loc[test['sentiment'] == 'negative', 'text']), title=\"Word Cloud of negative tweets\",color = 'red')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Text Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"## 1.Ngram Analysis:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import defaultdict\ntrain0_df = train[train[\"sentiment\"]=='positive'].dropna().append(test[test[\"sentiment\"]=='positive'].dropna())\ntrain1_df = train[train[\"sentiment\"]=='neutral'].dropna().append(test[test[\"sentiment\"]=='neutral'].dropna())\ntrain2_df = train[train[\"sentiment\"]=='negative'].dropna().append(test[test[\"sentiment\"]=='neutral'].dropna())\n\n## custom function for ngram generation ##\ndef generate_ngrams(text, n_gram=1):\n    token = [token for token in text.lower().split(\" \") if token != \"\" if token not in STOPWORDS]\n    ngrams = zip(*[token[i:] for i in range(n_gram)])\n    return [\" \".join(ngram) for ngram in ngrams]\n\n## custom function for horizontal bar chart ##\ndef horizontal_bar_chart(df, color):\n    trace = go.Bar(\n        y=df[\"word\"].values[::-1],\n        x=df[\"wordcount\"].values[::-1],\n        showlegend=False,\n        orientation = 'h',\n        marker=dict(\n            color=color,\n        ),\n    )\n    return trace\n\n## Get the bar chart from sincere questions ##\nfreq_dict = defaultdict(int)\nfor sent in train0_df[\"text\"]:\n    for word in generate_ngrams(sent):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace0 = horizontal_bar_chart(fd_sorted.head(25), 'red')\n\n## Get the bar chart from insincere questions ##\nfreq_dict = defaultdict(int)\nfor sent in train1_df[\"text\"]:\n    for word in generate_ngrams(sent):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace1 = horizontal_bar_chart(fd_sorted.head(25), 'green')\n\n## Get the bar chart from sincere questions ##\nfreq_dict = defaultdict(int)\nfor sent in train2_df[\"text\"]:\n    for word in generate_ngrams(sent):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace2 = horizontal_bar_chart(fd_sorted.head(25), 'orange')\n\n# Creating two subplots\nfig = tools.make_subplots(rows=3, cols=1, vertical_spacing=0.04,\n                          subplot_titles=[\"Frequent words of positive tweets\", \"Frequent words of neutral tweets\",\n                                          \"Frequent words of negative tweets\"])\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 2, 1)\nfig.append_trace(trace2, 3, 1)\nfig['layout'].update(height=1200, width=900, paper_bgcolor='rgb(233,233,233)', title=\"Word Count Plots\")\niplot(fig, filename='word-plots')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.Bi-gram Plots:"},{"metadata":{"trusted":true},"cell_type":"code","source":"freq_dict = defaultdict(int)\nfor sent in train0_df[\"text\"]:\n    for word in generate_ngrams(sent,2):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace0 = horizontal_bar_chart(fd_sorted.head(25), 'gray')\n\n\nfreq_dict = defaultdict(int)\nfor sent in train1_df[\"text\"]:\n    for word in generate_ngrams(sent,2):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace1 = horizontal_bar_chart(fd_sorted.head(25), 'orange')\n\nfreq_dict = defaultdict(int)\nfor sent in train2_df[\"text\"]:\n    for word in generate_ngrams(sent,2):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace2 = horizontal_bar_chart(fd_sorted.head(25), 'brown')\n\n\n\n# Creating two subplots\nfig = tools.make_subplots(rows=3, cols=1, vertical_spacing=0.04,horizontal_spacing=0.25,\n                          subplot_titles=[\"Bigram plots of Positive tweets\", \n                                          \"Bigram plots of Neutral tweets\",\n                                          \"Bigram plots of Negative tweets\"\n                                          ])\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 2, 1)\nfig.append_trace(trace2, 3, 1)\n\n\nfig['layout'].update(height=1000, width=800, paper_bgcolor='rgb(233,233,233)', title=\"Bigram Plots\")\niplot(fig, filename='word-plots')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.Tri-gram Plots:"},{"metadata":{"trusted":true},"cell_type":"code","source":"for sent in train0_df[\"text\"]:\n    for word in generate_ngrams(sent,3):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace0 = horizontal_bar_chart(fd_sorted.head(25), 'blue')\n\n\nfreq_dict = defaultdict(int)\nfor sent in train1_df[\"text\"]:\n    for word in generate_ngrams(sent,3):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace1 = horizontal_bar_chart(fd_sorted.head(25), 'green')\n\nfreq_dict = defaultdict(int)\nfor sent in train2_df[\"text\"]:\n    for word in generate_ngrams(sent,3):\n        freq_dict[word] += 1\nfd_sorted = pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])\nfd_sorted.columns = [\"word\", \"wordcount\"]\ntrace2 = horizontal_bar_chart(fd_sorted.head(25), 'violet')\n\n\n\n\n# Creating two subplots\nfig = tools.make_subplots(rows=3, cols=1, vertical_spacing=0.04, horizontal_spacing=0.05,\n                          subplot_titles=[\"Tri-gram plots of Positive tweets\", \n                                          \"Tri-gram plots of Neutral tweets\",\n                                          \"Tri-gram plots of Negative tweets\"])\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 2, 1)\nfig.append_trace(trace2, 3, 1)\nfig['layout'].update(height=1200, width=1200, paper_bgcolor='rgb(233,233,233)', title=\"Trigram Count Plots\")\niplot(fig, filename='word-plots')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above Ngaram analysis we can observe that neutral tweets and negative tweets had more amount of repeteted words than positive tweets."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train[\"num_words\"] = train[\"text\"].apply(lambda x: len(str(x).split()))\ntest[\"num_words\"] = test[\"text\"].apply(lambda x: len(str(x).split()))\ntrain['select_num_words'] = train[\"selected_text\"].apply(lambda x: len(str(x).split()))\n\n## Number of unique words in the text ##\ntrain[\"num_unique_words\"] = train[\"text\"].apply(lambda x: len(set(str(x).split())))\ntest[\"num_unique_words\"] = test[\"text\"].apply(lambda x: len(set(str(x).split())))\ntrain['select_num_unique_words'] = train[\"selected_text\"].apply(lambda x: len(set(str(x).split())))\n\n## Number of characters in the text ##\ntrain[\"num_chars\"] = train[\"text\"].apply(lambda x: len(str(x)))\ntest[\"num_chars\"] = test[\"text\"].apply(lambda x: len(str(x)))\ntrain['select_num_chars'] = train[\"selected_text\"].apply(lambda x: len(str(x)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.Histogram plot of Number of words"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Histogram(x=train['num_words'],name = 'Number of words in text of train data'))\nfig.add_trace(go.Histogram(x=test['num_words'],name = 'Number of words in text of test data'))\nfig.add_trace(go.Histogram(x=train['select_num_words'],name = 'Number of words in selected text'))\n\n# Overlay both histograms\nfig.update_layout(barmode='stack')\n# Reduce opacity to see both histograms\nfig.update_traces(opacity=0.75)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can observe from above histogram plot that the number of words in train text and test text ranges from 1 to 30.Selected text words mostly fall in range of 1-10. "},{"metadata":{},"cell_type":"markdown","source":"# Histogram plots of Number of characters"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig_ = go.Figure()\nfig_.add_trace(go.Histogram(x=train['num_chars'],name = 'Number of characters in text of train data',marker = dict(color = 'rgba(222, 111, 33, 0.8)')))\nfig_.add_trace(go.Histogram(x=test['num_chars'],name = 'Number of characters in text of test data',marker = dict(color = 'rgba(33, 1, 222, 0.8)')))\nfig_.add_trace(go.Histogram(x=train['select_num_chars'],name = 'Number of characters in selected text',marker = dict(color = 'rgba(108, 25, 7, 0.8)')))\n\n# Overlay both histograms\nfig_.update_layout(barmode='stack')\n# Reduce opacity to see both histograms\nfig_.update_traces(opacity=0.75)\nfig_.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From above plot we can see that number of characters in test and train set was in same range.In selected text the range flows from 3 to 138 Characters."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig_ = go.Figure()\nfig_.add_trace(go.Histogram(x=train['num_unique_words'],name = 'Number of unique words in text of train data',marker = dict(color = 'rgba(222, 1, 3, 0.8)')))\nfig_.add_trace(go.Histogram(x=test['num_unique_words'],name = 'Number of unique words in text of test data',marker = dict(color = 'rgba(3, 221, 2, 0.8)')))\nfig_.add_trace(go.Histogram(x=train['select_num_unique_words'],name = 'Number of unique words in selected text',marker = dict(color = 'rgba(1, 2, 237, 0.8)')))\n\n# Overlay both histograms\nfig_.update_layout(barmode='stack')\n# Reduce opacity to see both histograms\nfig_.update_traces(opacity=0.75)\nfig_.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that number of unique words in train and test sets range from 1 to 26. In selected text most number  "},{"metadata":{},"cell_type":"markdown","source":"**NOW BASIC EDA, TEXT PREPROCESSING IS COMPLETED **"},{"metadata":{},"cell_type":"markdown","source":"# NOW START BUILDING THE MODEL"},{"metadata":{},"cell_type":"markdown","source":"**stay tuned** I will update the model of having high accuracy soon. "},{"metadata":{},"cell_type":"markdown","source":"**Please upvote if you like it and keep me motivated**"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}