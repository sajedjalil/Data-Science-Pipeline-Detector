{"cells":[{"metadata":{},"cell_type":"markdown","source":"## <font size='5' color='red'>Contents</font>\n\n* [introduction](#1)\n\n* [Loading required packages](#2)\n\n* [Getting basic Ideas](#3) \n\n    * [Basic Cleaning]()\n    \n* [Exploratory Data analysis](#4)\n\n    * [Class distribution]()\n    * [Distribution of length of tweets]()\n    * [Distribution of number of words in tweets]()\n    * [Distribution of target]()\n    * [Common Stopwords]()\n    * [Common words in tweets w/o stopwords]()\n    * [Common bigrams in tweeets]()\n    * [WordClouds of tweets]()\n    * [Readability index](#5)\n    \n* [Hints for post-processing](#9)\n\n    * [analyzing jaccard similarity]()\n\n\n\n* [Bert-Lstm Model](#7)\n    * [Data preparation]()\n    * [Model]()\n    * [Post processing]()\n    * [Making our submission]()\n\n## <font size='4' color='red'>If you find this kernel useful,consider doing an upvote..this will motivate me create more content</font>"},{"metadata":{},"cell_type":"markdown","source":"## <font size='5' color='green'>Introduction</font><a id='1'></a>"},{"metadata":{},"cell_type":"markdown","source":"With all of the tweets circulating every second it is hard to tell whether the sentiment behind a specific tweet will impact a company, or a person's, brand for being viral (positive), or devastate profit because it strikes a negative tone. Capturing sentiment in language is important in these times where decisions and reactions are created and updated in seconds. But, which words actually lead to the sentiment description? In this competition you will need to pick out the part of the tweet (word or phrase) that reflects the sentiment.\n\nHelp build your skills in this important area with this broad dataset of tweets. Work on your technique to grab a top spot in this competition. What words in tweets support a positive, negative, or neutral sentiment?\n![](https://media.giphy.com/media/xUPGcEOEllmvFAvako/giphy.gif)"},{"metadata":{},"cell_type":"markdown","source":"## <font size='4' color='green'>Loading Required packages</font><a id='2'></a>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install textstat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom nltk.stem import WordNetLemmatizer,PorterStemmer\nfrom collections import defaultdict,Counter\nfrom wordcloud import WordCloud, STOPWORDS\nfrom plotly.subplots import make_subplots\nfrom nltk.tokenize import word_tokenize\nimport plotly.figure_factory as ff\nfrom nltk.corpus import stopwords\nfrom nltk.corpus import stopwords\nimport plotly.graph_objects as go\nfrom textblob import TextBlob\nimport plotly.graph_objs as go\nimport matplotlib.pyplot as plt\nfrom nltk.util import ngrams\nimport plotly.offline as py\nimport plotly.express as px\nfrom statistics import *\nfrom plotly import tools\nimport seaborn as sns\nfrom tqdm import tqdm\nimport pandas as pd\nimport numpy as np\nimport textstat\nimport string\nimport json\nimport nltk\nimport gc\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"py.init_notebook_mode(connected=True)\nnltk.download('stopwords')\nstop=set(stopwords.words('english'))\nplt.style.use('seaborn')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font size='4' color='green'>Getting Basic Ideas</font><a id='3'></a>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train=pd.read_csv(\"../input/tweet-sentiment-extraction/train.csv\")\ntest=pd.read_csv(\"../input/tweet-sentiment-extraction/test.csv\")\ntarget=train['sentiment']","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('There are {} rows and {} cols in train set'.format(train.shape[0],train.shape[1]))\nprint('There are {} rows and {} cols in test set'.format(test.shape[0],test.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import re\ndef basic_cleaning(text):\n    text=re.sub(r'https?://www\\.\\S+\\.com','',text)\n    text=re.sub(r'[^A-Za-z|\\s]','',text)\n    return text\n\ndef clean(df):\n    for col in ['text','selected_text']:\n        df[col]=df[col].astype(str).apply(lambda x:basic_cleaning(x))\n    return df\n\ncolors=['blue','green','red']\nsent=train.sentiment.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font size='4' color='green'>Exploratory Data Analysis</font><a id='4'></a>"},{"metadata":{},"cell_type":"markdown","source":"- Let's first take a look at the class distribution of sentiment label"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig=make_subplots(1,2,subplot_titles=('Train set','Test set'))\nx=train.sentiment.value_counts()\nfig.add_trace(go.Bar(x=x.index,y=x.values,marker_color=['blue','green','red'],name='train'),row=1,col=1)\nx=test.sentiment.value_counts()\nfig.add_trace(go.Bar(x=x.index,y=x.values,marker_color=['blue','green','red'],name='test'),row=1,col=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- There is a class imbalance between labels,neutral class dominates over the other class tweets.\n- The distributions of labels follows the same trend in train and test.\n\n**But our task is not to predict these labels,but to predict the selected text which can help us figure out the sentiment**"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df=pd.concat([train,test])\ndf['text']=df['text'].astype(str)\ndf['seleceted_text']=df['selected_text'].astype(str)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font size='3' color='blue'>What's the distribution of length of tweet?</font>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"vals=[]\nfor i in range(0,3):\n    x=df[df['sentiment']==sent[i]]['text'].str.len()\n    vals.append(x)\n\nfig = ff.create_distplot(vals, sent,show_hist=False)\nfig.update_layout(title=\"Distribution of number of characters in tweets\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The number of character in tweets ranges from 1 to 160 (max).\n- More tweets contains less than 60 characters.\n"},{"metadata":{},"cell_type":"markdown","source":"### <font size='3' color='blue'>What is the distribution of selected text?</font>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"vals=[]\nfor i in range(0,3):\n    x=df[df['sentiment']==sent[i]]['selected_text'].dropna().str.len()\n    vals.append(x)\n\nfig = ff.create_distplot(vals, sent)\nfig.update_layout(title=\"Distribution of number of characters in selected text\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The selected test is of much larger length in neutral sentiment tweets.Why is this ? We wil find out later..\n- The distribution of selected texts in positive and negative are almost the same."},{"metadata":{},"cell_type":"markdown","source":"### <font size='3' color='blue'>What is the distribution of Number of words in a tweet?</font>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\nsent=df.sentiment.unique()\nfig,ax= plt.subplots(1,3,figsize=(12,6))\nfor i in range(0,3):\n    df[df['sentiment']==sent[i]]['text'].str.split().str.len().hist(ax=ax[i],color=colors[i])\n    ax[i].set_title(sent[i])\nfig.suptitle(\"Distribution of number of No: Words in Tweets\", fontsize=14)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The number of words in tweets ranges from 1 to 30,5-10 being the most common choice."},{"metadata":{},"cell_type":"markdown","source":"### <font size='3' color='blue'>What is distribution of number of words in selected text?</font>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\nsent=train.sentiment.unique()\nfig,ax= plt.subplots(1,3,figsize=(12,6))\nfor i in range(0,3):\n    train[train['sentiment']==sent[i]]['selected_text'].str.split().str.len().hist(ax=ax[i],color=colors[i])\n    ax[i].set_title(sent[i])\nfig.suptitle(\"Distribution of number of No: Words in Selected text\", fontsize=14)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Yes,this  follows the same trend as of number of characters."},{"metadata":{},"cell_type":"markdown","source":"### <font size='3' color='blue'>Which are the most common stopwords?</font>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def preprocess_news(df,stop=stop,n=1,col='text'):\n    '''Function to preprocess and create corpus'''\n    new_corpus=[]\n    stem=PorterStemmer()\n    lem=WordNetLemmatizer()\n    for text in df[col]:\n        words=[w for w in word_tokenize(text) if (w not in stop)]\n       \n        words=[lem.lemmatize(w) for w in words if(len(w)>n)]\n     \n        new_corpus.append(words)\n        \n    new_corpus=[word for l in new_corpus for word in l]\n    return new_corpus\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"\nfig,ax=plt.subplots(1,3,figsize=(15,7))\nfor i in range(3):\n    new=df[df['sentiment']==sent[i]]\n    corpus_train=preprocess_news(new,{})\n    \n    dic=defaultdict(int)\n    for word in corpus_train:\n        if word  in stop:\n            dic[word]+=1\n            \n    top=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10] \n    x,y=zip(*top)\n    ax[i].bar(x,y,color=colors[i])\n    ax[i].set_title(sent[i],color=colors[i])\n\nfig.suptitle(\"Common stopwords in different sentiments\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. `the` dominated in the list of common stopwords,followed by `and` and '`you`"},{"metadata":{},"cell_type":"markdown","source":"### <font size='3' color='blue'>Distribution of no: punctuations in tweets</font>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df['punc']=df['text'].apply(lambda x : [c for c in x if c in string.punctuation])\nfig,ax=plt.subplots(1,3,figsize=(10,6))\nfor i in range(3):\n    new=df[df['sentiment']==sent[i]]['punc'].map(lambda x: len(x))\n    sns.distplot(new,color=colors[i],ax=ax[i])\n    ax[i].set_title(sent[i],color=colors[i])\n    \nfig.suptitle(\"Number of Punctuations in tweets\") ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- All the distributions are left skewed.\n- There happens to be more punctuations in positive tweets."},{"metadata":{},"cell_type":"markdown","source":"### <font size='3' color='blue'>Number of unique words in tweets</font>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig,ax=plt.subplots(1,3,figsize=(12,7))\nfor i in range(3):\n    new=df[df['sentiment']==sent[i]]['text'].map(lambda x: len(set(x.split())))\n    sns.distplot(new.values,ax=ax[i],color=colors[i])\n    ax[i].set_title(sent[i])\nfig.suptitle(\"Distribution of number of unique words\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"hmm..the distribution seems to be quite similar,let us check for selected text"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig,ax=plt.subplots(1,3,figsize=(12,7))\nfor i in range(3):\n    new=df[df['sentiment']==sent[i]]['selected_text'].astype(str).map(lambda x: len(set(x.split())))\n    sns.distplot(new.values,ax=ax[i],color=colors[i])\n    ax[i].set_title(sent[i])\nfig.suptitle(\"Distribution of number of unique words\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- For negative and positive tweets this distributions is similar,this should be because of selected keywords from tweets.\n- In case of neutral tweets it is spread and there aren't a specefic keyword to select.\n- This may cause neutral class to be difficult to predict."},{"metadata":{},"cell_type":"markdown","source":"### <font size='3' color='blue'>Common punctuations in tweets</font>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig,ax=plt.subplots(1,3,figsize=(15,10))\nfor i in range(3):\n    new=df[df['sentiment']==sent[i]]['punc']\n    punc=[p for pun in new.values for p in pun]\n    counter=Counter(punc).most_common(10)\n    x,y=zip(*counter)\n    ax[i].bar(x,y,color=colors[i])\n    ax[i].set_title(sent[i],color=colors[i])\n    \nfig.suptitle(\"Punctuations in tweets\")   \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font size='4' color='blue'>Which are the most common words?</font> "},{"metadata":{"trusted":true},"cell_type":"code","source":"df=clean(df)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"\nfig,ax=plt.subplots(1,3,figsize=(20,12))\nfor i in range(3):\n    new=df[df['sentiment']==sent[i]]\n    corpus_train=preprocess_news(new,n=3)\n    counter=Counter(corpus_train)\n    most=counter.most_common()\n    x=[]\n    y=[]\n    for word,count in most[:20]:\n        if (word not in stop) :\n            x.append(word)\n            y.append(count)\n    sns.barplot(x=y,y=x,ax=ax[i],color=colors[i])\n    ax[i].set_title(sent[i],color=colors[i])\nfig.suptitle(\"Common words in tweet text\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- It is evident that there are more positive words like `good`,`thanks` etc on positive tweets.\n- It can be observed that there are a lot of negative words in negative tweets."},{"metadata":{},"cell_type":"markdown","source":"## <font color='blue' size='4'>Which are the most common words in selected text?</font>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig,ax=plt.subplots(1,3,figsize=(20,12))\nfor i in range(3):\n    new=df[df['sentiment']==sent[i]]   \n    corpus=preprocess_news(new,n=3,col='selected_text')\n    counter=Counter(corpus)\n    most=counter.most_common()\n    x=[]\n    y=[]\n    for word,count in most[:20]:\n        if (word not in stop) :\n            x.append(word)\n            y.append(count)\n    sns.barplot(x=y,y=x,ax=ax[i],color=colors[i])\n    ax[i].set_title(sent[i],color=colors[i])\nfig.suptitle(\"Common words in selected text\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The above trend repreats here ,here it is more evident and clear.\n- Let's dig bit further for positive ane negetive words...\n"},{"metadata":{},"cell_type":"markdown","source":"### <font size='3' color='blue'>Check for bigrams in selected text</font>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def get_top_ngram(corpus, n=None):\n    vec = CountVectorizer(ngram_range=(n, n),stop_words=stop).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig,ax=plt.subplots(1,2,figsize=(15,10))\nfor i in range(2):\n    new=df[df['sentiment']==sent[i+1]]['selected_text']\n    top_n_bigrams=get_top_ngram(new,2)[:20]\n    x,y=map(list,zip(*top_n_bigrams))\n    sns.barplot(x=y,y=x,ax=ax[i],color=colors[i+1])\n    ax[i].set_title(sent[i+1])\n    \nfig.suptitle(\"Common bigrams in selected text\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Well,you can see the difference.\n- `'positve` tweets are filled with positive words like `great day`,'`happy day` etc.\n- `negative` tweets have bigrams like `im sorry`, and many words starting with `dont`."},{"metadata":{},"cell_type":"markdown","source":"### <font size='3' color='blue'>WordCloud for tweets</font>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"stopwords = set(STOPWORDS)\n\ndef show_wordcloud(data, title = None,ax=None):\n    wordcloud = WordCloud(\n        background_color='white',\n        stopwords=stopwords,\n        max_words=100,\n        max_font_size=30, \n        scale=3,\n        random_state=1 \n        )\n    \n    wordcloud=wordcloud.generate(str(data))\n    ax.imshow(wordcloud,interpolation='nearest')\n    ax.axis('off')\n    #plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig,ax=plt.subplots(1,3,figsize=(20,12))\nfor i in range(3):\n    new=df[df['sentiment']==sent[i]]['text']\n    show_wordcloud(new,ax=ax[i])\n    ax[i].set_title(sent[i],color=colors[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font size='3' color='blue'>Wordcloud for selected text</font>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig,ax=plt.subplots(1,3,figsize=(20,12))\nfor i in range(3):\n    new=df[df['sentiment']==sent[i]]['selected_text'].dropna()\n    show_wordcloud(new,ax=ax[i])\n    ax[i].set_title(sent[i],color=colors[i])\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's do the same for selected_text and see the distribution"},{"metadata":{},"cell_type":"markdown","source":"## <font color='green' size='4'>Readability features</font><a id='5'></a>\n\nReadability is the ease with which a reader can understand a written text. In natural language processing, the readability of text depends on its content. It focuses on the words we choose, and how we put them into sentences and paragraphs for the readers to comprehend.\n9.1 The Flesch Reading Ease formula\n\n   - In the Flesch reading-ease test, higher scores indicate material that is easier to read; lower numbers mark passages that are more difficult to read. The formula for the Flesch reading-ease score (FRES) test is \n![](data:image/png;base64,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)   \n   \n   \n   \n  -  90-100 - Very Easy\n  -  80-89 - Easy\n  -  70-79 - Fairly Easy\n  -  60-69 - Standard\n  -  50-59 - Fairly Difficult\n  -  30-49 - Difficult\n  -  0-29 - Very Confusing\n"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#utility functions:\ndef plot_readability(a,b,c,title,bins=0.4,colors=colors):\n    trace1 = ff.create_distplot([a,b,c],sent, bin_size=bins, colors=colors, show_rug=False)\n    trace1['layout'].update(title=title)\n    py.iplot(trace1, filename='Distplot')\n    table_data= [[\"Statistical Measures\",\"neu\",'pos','neg'],\n                [\"Mean\",mean(a),mean(b),mean(c)],\n                [\"Standard Deviation\",pstdev(a),pstdev(b),pstdev(c)],\n                [\"Variance\",pvariance(a),pvariance(b),pvariance(c)],\n                [\"Median\",median(a),median(b),median(c)],\n                [\"Maximum value\",max(a),max(b),max(c)],\n                [\"Minimum value\",min(a),min(b),min(c)]]\n    trace2 = ff.create_table(table_data)\n    py.iplot(trace2, filename='Table')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"tqdm.pandas()\nfre_neu = np.array(df[\"text\"][df[\"sentiment\"] == sent[0]].progress_apply(textstat.flesch_reading_ease))\nfre_pos = np.array(df[\"text\"][df[\"sentiment\"] == sent[1]].progress_apply(textstat.flesch_reading_ease))\nfre_neg = np.array(df[\"text\"][df[\"sentiment\"] == sent[2]].progress_apply(textstat.flesch_reading_ease))\n\nplot_readability(fre_neu,fre_pos,fre_neg,\"Flesch Reading Ease\",20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Mean score of tweets is ~70,so it is considered as fairly easy to read."},{"metadata":{},"cell_type":"markdown","source":"## <font size='4' color='red'>Hints for post processing</font><a id='9'></a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def jaccard(str1, str2): \n    a = set(str(str1).lower().split()) \n    b = set(str(str2).lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def plot_jaccard(sentiment,ax):\n    jacc=[]\n    text=train[train['sentiment']==sentiment].dropna()['text'].values.tolist()\n    selected=train[train['sentiment']==sentiment].dropna()['selected_text'].values.tolist()\n    for i,k in zip(text,selected):\n        jacc.append(jaccard(i,k))\n    ax.hist(jacc,bins=10,color='blue',alpha=0.4)\n    ax.set_title(sentiment)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2,ax3)=plt.subplots(1,3,figsize=(15,5))\nplot_jaccard('positive',ax=ax1)\nplot_jaccard('negative',ax2)\nplot_jaccard('neutral',ax3)\nfig.suptitle('jaccard similarity of text and selected text')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- here we can easily observe that the jaccard similarity of most of samples with negative sentiment is close to 1,which means that most of the text is in selected text.\n- Also there are some examples in positive and negative tweets with similarity of 1 (entire text).We will investigate them too."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['jaccard']=train.apply(lambda x : jaccard(x.text,x.selected_text),axis=1)\npositive=train[(train['sentiment']=='positive') & (train['jaccard']>0.9)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"positive.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Are these examples due to some manual errors? There seems to be positive keywords in them like \"love\",\"cute\",\"welcome\" etc..\n- let's examine if this has anything to do with text length"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,7))\nx=train[train['sentiment']=='positive']['text'].str.len()\ny=train[(train['sentiment']=='positive')]['jaccard'].values.tolist()\nax1.scatter(x,y,color='green',alpha=.4)\nax1.set_xlabel('text length')\nax1.set_ylabel('jaccard similarity with selected text')\nax1.set_title(\"text length vs jaccard similarity\")\nx=train[train['sentiment']=='positive']['text'].apply(lambda x : len(x.split()))\nax2.scatter(x,y,color='green',alpha=.4)\nax2.set_xlabel('text length')\nax2.set_ylabel('jaccard similarity with selected text')\nax2.set_title(\"no: of words vs jaccard similarity\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Couldn't find any evidence or relation between them in positive tweets.Let's check for negative tweets"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,7))\nx=train[train['sentiment']=='negative']['text'].str.len()\ny=train[(train['sentiment']=='negative')]['jaccard'].values.tolist()\nax1.scatter(x,y,color='red',alpha=.4)\nax1.set_xlabel('text length')\nax1.set_ylabel('jaccard similarity with selected text')\nax1.set_title(\"text length vs jaccard similarity\")\nx=train[train['sentiment']=='negative']['text'].apply(lambda x : len(x.split()))\nax2.scatter(x,y,color='red',alpha=.4)\nax2.set_xlabel('text length')\nax2.set_ylabel('jaccard similarity with selected text')\nax2.set_title(\"no: of words vs jaccard similarity\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Same here !\nI think in this situation we should check the distribution of sentiment polarity of selected text.See if it actually matches with the label or if there are any outliers."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_sent(text):\n    testimonial = TextBlob(str(text))\n    return testimonial.sentiment.polarity\n\nplt.figure(figsize=(10,7))\ntrain['polarity']=train['selected_text'].apply(lambda x : get_sent(x))\nsns.boxplot(x='sentiment', y='polarity', data=train)\nplt.gca().set_title('Sentiment vs Polarity of selected text')\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wow,the results look pretty satisfactory,but there are outliers especially in the negative tweets.\n\nlet's check the correlation between the number of words in tweet and selected text\n"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import scipy\ncorr=[]\nfor i in sent:\n    text_pos=train[train['sentiment']==i]['text'].astype(str).map(lambda x : len(x.split()))\n    sel_pos=train[train['sentiment']==i]['selected_text'].astype(str).map(lambda x : len(x.split()))\n    corr.append(scipy.stats.pearsonr(text_pos,sel_pos)[0])\nplt.bar(sent,corr,color='blue',alpha=.7)\nplt.gca().set_title(\"pearson corr between no: words in text and selected text\")\nplt.gca().set_ylabel(\"correlation\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font size='4' color='red'>Tensorflow roberta model</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import *\nimport tensorflow as tf\nimport tokenizers","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Many many thanks to one of the most wonderful kaggler @chrisdeotte for his [kernel](https://www.kaggle.com/cdeotte/tensorflow-roberta-0-705/data).Take a second to upvote his work.\n- I have done an inference with this by training 6 epochs and 5 folds.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"MAXLEN=128\nPATH = '../input/tf-roberta/'\ntokenizer=tokenizers.ByteLevelBPETokenizer(vocab_file=PATH+'vocab-roberta-base.json', \n    merges_file=PATH+'merges-roberta-base.txt', \n    lowercase=True,\n    add_prefix_space=True)\n\nsentiment_id = {'positive': 1313, 'negative': 2430, 'neutral': 7974}\ntrain = pd.read_csv('../input/tweet-sentiment-extraction/train.csv').fillna('')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ct=train.shape[0]\ninput_ids=np.ones((ct,MAXLEN),dtype='int32')\nattention_mask=np.zeros((ct,MAXLEN),dtype='int32')\ntoken_type_ids=np.zeros((ct,MAXLEN),dtype='int32')\nstart_tokens=np.zeros((ct,MAXLEN),dtype='int32')\nend_tokens=np.zeros((ct,MAXLEN),dtype='int32')\n\n\nfor k in tqdm(range(ct)):\n    \n    text1=\" \"+\" \".join(train.loc[k,\"text\"].split())\n    text2=\" \".join(train.loc[k,\"selected_text\"].split())\n    idx=text1.find(text2)\n    chars=np.zeros(len(text1))\n    chars[idx:idx+len(text2)]=1\n    if (text1[idx-1]==\" \"):\n        chars[idx-1]=1\n    enc=tokenizer.encode(text1)\n    \n    offsets=enc.offsets\n    \n    toks=[]\n    for i,(a,b) in enumerate(offsets):\n        sm=np.sum(chars[a:b])\n        if sm > 0:\n            toks.append(i)\n            \n    s_tok = sentiment_id[train.loc[k,'sentiment']]\n    input_ids[k,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n    attention_mask[k,:len(enc.ids)+5] = 1\n    if len(toks)>0:\n        start_tokens[k,toks[0]+1] = 1\n        end_tokens[k,toks[-1]+1] = 1\n    \n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/tweet-sentiment-extraction/test.csv').fillna('')\n\nct = test.shape[0]\ninput_ids_t = np.ones((ct,MAXLEN),dtype='int32')\nattention_mask_t = np.zeros((ct,MAXLEN),dtype='int32')\ntoken_type_ids_t = np.zeros((ct,MAXLEN),dtype='int32')\n\nfor k in tqdm(range(test.shape[0])):\n        \n    # INPUT_IDS\n    text1 = \" \"+\" \".join(test.loc[k,'text'].split())\n    enc = tokenizer.encode(text1)                \n    s_tok = sentiment_id[test.loc[k,'sentiment']]\n    input_ids_t[k,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n    attention_mask_t[k,:len(enc.ids)+5] = 1\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    ids = tf.keras.layers.Input((MAXLEN,), dtype=tf.int32)\n    att = tf.keras.layers.Input((MAXLEN,), dtype=tf.int32)\n    tok = tf.keras.layers.Input((MAXLEN,), dtype=tf.int32)\n\n    config = RobertaConfig.from_pretrained(PATH+'config-roberta-base.json')\n    bert_model = TFRobertaModel.from_pretrained(PATH+'pretrained-roberta-base.h5',config=config)\n    x = bert_model(ids,attention_mask=att,token_type_ids=tok)\n    \n    x1 = tf.keras.layers.Dropout(0.1)(x[0]) \n    x1 = tf.keras.layers.Conv1D(1,1)(x1)\n    x1 = tf.keras.layers.Flatten()(x1)\n    x1 = tf.keras.layers.Activation('softmax')(x1)\n    \n    x2 = tf.keras.layers.Dropout(0.1)(x[0]) \n    x2 = tf.keras.layers.Conv1D(1,1)(x2)\n    x2 = tf.keras.layers.Flatten()(x2)\n    x2 = tf.keras.layers.Activation('softmax')(x2)\n\n    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1,x2])\n    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=build_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nmodels=os.listdir(\"../input/tfroberta5fold6epochs\")\nmodel_file_path=\"../input/tfroberta5fold6epochs/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_token=np.zeros((ct,MAXLEN),dtype='float64')\nend_token=np.zeros((ct,MAXLEN),dtype='float64')\n\nfor model_path in models:\n    model.load_weights(model_file_path+model_path)\n    pred=model.predict([input_ids_t,attention_mask_t,token_type_ids_t])\n    \n    start_token+=pred[0]/len(models)\n    end_token+=pred[1]/len(models)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_token=np.argmax(start_token,axis=1)\nend_token=np.argmax(end_token,axis=1)\nselected_text=[]\nfor k in range(ct):\n    \n    a=start_token[k]\n    b=end_token[k]\n    if a<b:\n        text1 = \" \"+\" \".join(test.loc[k,'text'].split())\n        enc = tokenizer.encode(text1)\n        selected_text.append(tokenizer.decode(enc.ids[a-1:b]))\n    else:\n        if test.loc[k,'sentiment']==\"neutral\":\n            selected_text.append(test.loc[k,'text'])\n        else:\n            text1 = \" \"+\" \".join(test.loc[k,'text'].split())\n            enc = tokenizer.encode(text1)\n            selected_text.append(tokenizer.decode(enc.ids[b-1:a]))\n            \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['selected_text']=selected_text\ntest[['textID','selected_text']].to_csv('submission.csv',index=False)\npd.set_option('max_colwidth', 60)\ntest.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del model\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font size='4' color='blue'>BERT Embeddings with LSTM Model</font><a id='5'></a>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"cols=['textID','text','sentiment','selected_text']\ntrain_df=train[cols].copy()\ndel train\ntest_df=test.copy()\ndel test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this section I am trying to build a multi-input model using BERT embedding for predicting the target keyphrases.\nI will explain my approach step by step,this is a naive approach and will be improved later."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom kaggle_datasets import KaggleDatasets\nimport transformers\nfrom tqdm.notebook import tqdm\nfrom tokenizers import BertWordPieceTokenizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\nfrom tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D,Bidirectional\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import TimeDistributed\nfrom tensorflow.keras.layers import concatenate\nfrom tensorflow.compat.v1.keras.layers import CuDNNLSTM\nimport gc\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train_df=pd.read_csv(\"../input/tweet-sentiment-extraction/train.csv\")\ntest_df=pd.read_csv(\"../input/tweet-sentiment-extraction/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data preparation"},{"metadata":{},"cell_type":"markdown","source":"- Below function is from this [kernel](https://www.kaggle.com/xhlulu/jigsaw-tpu-distilbert-with-huggingface-and-keras) by @xhlulu,this is used to encode the sentences easily and quickly using distilbert tokenizer."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def fast_encode(texts, tokenizer, chunk_size=256, maxlen=128):\n    tokenizer.enable_truncation(max_length=maxlen)\n    tokenizer.enable_padding(max_length=maxlen)\n    all_ids = []\n    \n    for i in tqdm(range(0, len(texts), chunk_size)):\n        text_chunk = texts[i:i+chunk_size].tolist()\n        encs = tokenizer.encode_batch(text_chunk)\n        all_ids.extend([enc.ids for enc in encs])\n    \n    return np.array(all_ids)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We load the Distilbert pretained tokenizer (uncased) and save it to directory.\n- Reload and use BertWordPieceTokenizer.\n- An implementation of a tokenizer consists of the following pipeline of processes, each applying different transformations to the textual information:\n![](https://miro.medium.com/max/1400/1*7uy9X3eE1rVmqV08yKrDgg.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')  ## change it to commit\n\n# Save the loaded tokenizer locally\nsave_path = '/kaggle/working/distilbert_base_uncased/'\nif not os.path.exists(save_path):\n    os.makedirs(save_path)\ntokenizer.save_pretrained(save_path)\n\n# Reload it with the huggingface tokenizers library\nfast_tokenizer = BertWordPieceTokenizer('distilbert_base_uncased/vocab.txt', lowercase=True)\nfast_tokenizer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Now the comment text is prepared and encoded using this tokenizer easily.\n- We here set the maxlen=128,(limit)"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = fast_encode(train_df.text.astype(str), fast_tokenizer, maxlen=128)\nx_test = fast_encode(test_df.text.astype(str),fast_tokenizer,maxlen=128)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Now we load the pretrained bert ('uncased') transformer layer.\n- This is used for creating the representations and training our corpus."},{"metadata":{"trusted":true},"cell_type":"code","source":"transformer_layer = transformers.TFDistilBertModel.from_pretrained('distilbert-base-uncased')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This code is lifted from [kernel](https://www.kaggle.com/gskdhiman/bert-baseline-starter-kernel#Training).\n- In this section we create the representaion for the selected text from tweet text.\n- The representation is created such that the positions of tokens which is selcted from text is represented with 1 and others with 0.\n- for example,consider the tweet `\" I have a cute dog\"` and selected text `\"cute dog\"`\n- This produces the ouput as ` [0,0,0,1,1]`"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_targets(df):\n    df['t_text'] = df['text'].apply(lambda x: tokenizer.tokenize(str(x)))\n    df['t_selected_text'] = df['selected_text'].apply(lambda x: tokenizer.tokenize(str(x)))\n    def func(row):\n        x,y = row['t_text'],row['t_selected_text'][:]\n        for offset in range(len(x)):\n            d = dict(zip(x[offset:],y))\n            #when k = v that means we found the offset\n            check = [k==v for k,v in d.items()]\n            if all(check)== True:\n                break \n        return [0]*offset + [1]*len(y) + [0]* (len(x)-offset-len(y))\n    df['targets'] = df.apply(func,axis=1)\n    return df\n\ntrain_df = create_targets(train_df)\n\nprint('MAX_SEQ_LENGTH_TEXT', max(train_df['t_text'].apply(len)))\nprint('MAX_TARGET_LENGTH',max(train_df['targets'].apply(len)))\nMAX_TARGET_LEN=108","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Now we need to make each output of the same length to feed it to the neural network.\n- For that we find the maxlength of the target and pad all other target to this length."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['targets'] = train_df['targets'].apply(lambda x :x + [0] * (MAX_TARGET_LEN-len(x)))\ntargets=np.asarray(train_df['targets'].values.tolist())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We need to use the sentiment as a feature,for this encode it using LabelEncode."},{"metadata":{"trusted":true},"cell_type":"code","source":"lb=LabelEncoder()\nsent_train=lb.fit_transform(train_df['sentiment'])\nsent_test=lb.fit_transform(test_df['sentiment'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{},"cell_type":"markdown","source":"- This is a multi-input model (comment+sentiment label).\n- I have made a simple LSTM model\n- concatenated both the inputs "},{"metadata":{"trusted":true},"cell_type":"code","source":"def new_model(transformer_layer):\n    \n    inp = Input(shape=(128, ))\n    inp2= Input(shape=(1,))\n    \n    embedding_matrix=transformer_layer.weights[0].numpy()\n\n    x = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],weights=[embedding_matrix],trainable=False)(inp)\n\n    x = CuDNNLSTM(150, return_sequences=True,name='lstm_layer',)(x)\n    x = CuDNNLSTM(100, return_sequences=False,name='lstm_layer-2',)(x)\n    \n    y =Dense(10,activation='relu')(inp2)\n    x= concatenate([x,y])\n    \n    x = Dense(MAX_TARGET_LEN,activation='sigmoid')(x)\n\n    model = Model(inputs=[inp,inp2], outputs=x)\n\n    model.compile(loss='binary_crossentropy',\n                      optimizer='adam')\n\n\n    #prinnt(model.summary())\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Fitting the model "},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel=new_model(transformer_layer)\nhistory=model.fit([x_train,sent_train],targets,epochs=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Make predictions on test"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions=model.predict([x_test,sent_test])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The function below is used to convert the output to text format.\n"},{"metadata":{},"cell_type":"markdown","source":"## Post processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndef convert_output(sub,predictions):\n    preds=[]\n    for i,row in enumerate(sub['text']):\n\n        text,target=row.lower(),predictions[i].tolist()\n        target=np.round(target).tolist()\n        try:\n            start,end=target.index(1),target[::-1].index(1)\n            text_list=tokenizer.tokenize(text)\n            text_list=text_list+((108-len(text_list))*['pad'])\n            start_w,end_w=text_list[start],text_list[-end]\n            start=text.find(start_w.replace(\"#\",'',1))    ## remove # to match substring\n            end=text.find(end_w.replace(\"#\",''),start)\n            #pred=' '.join([x for x in text_list[start:-end]])\n            pred=text[start:end]\n        except:\n            pred=text\n        \n        preds.append(pred)\n        \n    return preds\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_text=convert_output(test_df,predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(prediction_text)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Making our submission"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"sub=pd.read_csv(\"../input/tweet-sentiment-extraction/sample_submission.csv\")\nsub['selected_text']=prediction_text\nsub.to_csv('submission.csv',index=False)\nsub.head()"},{"metadata":{},"cell_type":"markdown","source":"## <font size='4' color='blue'>Work in progress !!!</font> \n## <font size='4' color='red'>Do an upvote if you think this was helpful</font> "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}