{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n# Tweet Sentiment Extraction\n\n![tweets_resize.png](attachment:113a7a6d-1cba-4e25-b3ad-3b77fb2d5136.png)\n\n\n## Overview\n\nThis Notebook will be completed in two main ways.<br/>\nFirst, find and visualize useful data or meaningful relationships within the data.<br/>\nSecond, select a model based on the visualization of the previous process. Transform or refine the data into the appropriate form for the model to be used.<br/><br/>\n\nThis competition does not categorize the positive or negative of a sentence, unlike a general emotional analysis competition.<br/>\nIn the sentence, it was interesting in that it was a contest to extract the sentence that influenced the emotion of the sentence the most. \n##### \"We should keep in mind that we should extract sentences, not categorize sentiment.\"<br/>\n\n\n#### My opinion :\n1) Since all data have different lengths of labels, we have to infer the values from start index and end index.<br/>\n2) The result we have to submit is the original sentence, so it should not be cleaning text. But this notebook will preprocess for visualization.","metadata":{},"attachments":{"113a7a6d-1cba-4e25-b3ad-3b77fb2d5136.png":{"image/png":"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"}}},{"cell_type":"markdown","source":"***\n\n## My workflow\n#### 1. Import & Install libray\n* Import basic libray\n* Import Enginnering libray\n* Install stopwords list\n\n#### 2. Check out my data\n* Check Shape / Info\n\n#### 3. Exploratory Data Analysis(EDA) with Visualization [Before Preprocessing]\n* Plot the null values\n* Plot the \"sentiment\" columns count\n* Number of alphabets by sentence / Number of words by sentence\n* Bi-gram by sentiment per texts in Tweets\n\n#### 4. Prepocessing Data\n* Drop null rows & useless columns\n* Cleansing \"text\" / \"selected_text\" data\n\n#### 5. Visualization [After Preprocessing]\n* Wordcloude by sentiment per selected text in Tweets\n\n#### 6. Feature Enginnering \n* How to use Bert tokenization\n* Convert to data suitable for Bert model (Dataset / Dataloader)\n\n#### 7.Modeling\n* Bert Modeling\n* Loss Function (CrossEntropyLoss / Jaccard )\n* Training\n* Evaluating\n\n#### 8. Submission\n* Submit the predictions.","metadata":{}},{"cell_type":"markdown","source":"# 1. Import & Install libray\n* Import basic libray\n* Import Enginnering libray\n* Install stopwords list","metadata":{}},{"cell_type":"code","source":"import re\nimport os\nimport random\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nimport plotly.express as px\n\nimport warnings\nwarnings.filterwarnings('ignore')\nplt.style.use('seaborn')\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:33:44.38991Z","iopub.execute_input":"2021-06-13T04:33:44.390565Z","iopub.status.idle":"2021-06-13T04:33:47.714048Z","shell.execute_reply.started":"2021-06-13T04:33:44.390454Z","shell.execute_reply":"2021-06-13T04:33:47.713203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchtext\nfrom torchtext import data, datasets\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data\nfrom torch.utils.data import TensorDataset, DataLoader\nimport torch.optim as optim\n\nimport transformers\nfrom transformers import BertTokenizer, BertModel, BertConfig\n\nimport tokenizers\n\nimport nltk\nfrom nltk.stem import SnowballStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom wordcloud import WordCloud\nfrom PIL import Image\n\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:33:47.716093Z","iopub.execute_input":"2021-06-13T04:33:47.716573Z","iopub.status.idle":"2021-06-13T04:33:49.59128Z","shell.execute_reply.started":"2021-06-13T04:33:47.716536Z","shell.execute_reply":"2021-06-13T04:33:49.59043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nltk.download('stopwords')\nfrom nltk.corpus import stopwords\nstop_words = stopwords.words('english')","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:33:49.594295Z","iopub.execute_input":"2021-06-13T04:33:49.59455Z","iopub.status.idle":"2021-06-13T04:34:09.648696Z","shell.execute_reply.started":"2021-06-13T04:33:49.594523Z","shell.execute_reply":"2021-06-13T04:34:09.64706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\ntest_df = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:34:09.650566Z","iopub.execute_input":"2021-06-13T04:34:09.650917Z","iopub.status.idle":"2021-06-13T04:34:09.793806Z","shell.execute_reply.started":"2021-06-13T04:34:09.650879Z","shell.execute_reply":"2021-06-13T04:34:09.793044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Check out my data\n* Check Shape / Info\n* Set color palette","metadata":{}},{"cell_type":"code","source":"print(\"Train data size : {}\".format(train_df.shape))\nprint(\"Test data size : {}\".format(test_df.shape))","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:34:16.885525Z","iopub.execute_input":"2021-06-13T04:34:16.885838Z","iopub.status.idle":"2021-06-13T04:34:16.890948Z","shell.execute_reply.started":"2021-06-13T04:34:16.885809Z","shell.execute_reply":"2021-06-13T04:34:16.889909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:34:20.815784Z","iopub.execute_input":"2021-06-13T04:34:20.816129Z","iopub.status.idle":"2021-06-13T04:34:20.837398Z","shell.execute_reply.started":"2021-06-13T04:34:20.816097Z","shell.execute_reply":"2021-06-13T04:34:20.836463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PuBu_palette = sns.color_palette(\"PuBu\", 10)\nYlGnBu_palette = sns.color_palette(\"YlGnBu\", 10)\nsns.palplot(PuBu_palette)\nsns.palplot(YlGnBu_palette)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:34:37.241582Z","iopub.execute_input":"2021-06-13T04:34:37.241904Z","iopub.status.idle":"2021-06-13T04:34:37.392723Z","shell.execute_reply.started":"2021-06-13T04:34:37.241876Z","shell.execute_reply":"2021-06-13T04:34:37.391796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### âœ”ï¸ This notebook will use this palettes.","metadata":{}},{"cell_type":"markdown","source":"# 3. Exploratory Data Analysis(EDA) with Visualization [Before Preprocessing]\n* Plot the null values\n* Plot the \"sentiment\" columns count\n* Number of alphabets by sentence / Number of words by sentence\n* Bi-gram by sentiment per texts in Tweets","metadata":{}},{"cell_type":"markdown","source":"### 3-1)  Plot the Null Values","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(train_df.isnull().sum(), columns=[\"Train Null Count\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:35:44.481496Z","iopub.execute_input":"2021-06-13T04:35:44.481818Z","iopub.status.idle":"2021-06-13T04:35:44.50064Z","shell.execute_reply.started":"2021-06-13T04:35:44.481791Z","shell.execute_reply":"2021-06-13T04:35:44.499544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(test_df.isnull().sum(), columns=[\"Test Null Count\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:35:44.791416Z","iopub.execute_input":"2021-06-13T04:35:44.791711Z","iopub.status.idle":"2021-06-13T04:35:44.800748Z","shell.execute_reply.started":"2021-06-13T04:35:44.791681Z","shell.execute_reply":"2021-06-13T04:35:44.799907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msno.matrix(df=train_df.iloc[:,:],figsize=(5,5),color=YlGnBu_palette[8])","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:35:47.732749Z","iopub.execute_input":"2021-06-13T04:35:47.733087Z","iopub.status.idle":"2021-06-13T04:35:48.009907Z","shell.execute_reply.started":"2021-06-13T04:35:47.733056Z","shell.execute_reply":"2021-06-13T04:35:48.009023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3-2)  Plot the \"sentiment\" columns count","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1,1,figsize=(7, 5))\nax = sns.countplot(train_df[\"sentiment\"].sort_values(ascending=False),\n              order = train_df['sentiment'].value_counts().index,\n              palette=PuBu_palette[-5:])\nax.patch.set_alpha(0)\nfig.text(0.1,0.92,\"distribution by Sentiment in Tweets\", fontweight=\"bold\", fontfamily='serif', fontsize=17)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:35:57.572673Z","iopub.execute_input":"2021-06-13T04:35:57.573012Z","iopub.status.idle":"2021-06-13T04:35:57.731614Z","shell.execute_reply.started":"2021-06-13T04:35:57.572961Z","shell.execute_reply":"2021-06-13T04:35:57.730668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3-3) Number of alphabets by sentence / Number of words by sentence","metadata":{}},{"cell_type":"code","source":"def get_length_alphabets(text):\n    text = str(text)\n    return len(text)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:36:17.001941Z","iopub.execute_input":"2021-06-13T04:36:17.002308Z","iopub.status.idle":"2021-06-13T04:36:17.006217Z","shell.execute_reply.started":"2021-06-13T04:36:17.002277Z","shell.execute_reply":"2021-06-13T04:36:17.005365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_length_words(text):\n    text = str(text)\n    return len(text.split(' '))","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:36:17.642707Z","iopub.execute_input":"2021-06-13T04:36:17.643046Z","iopub.status.idle":"2021-06-13T04:36:17.647884Z","shell.execute_reply.started":"2021-06-13T04:36:17.643015Z","shell.execute_reply":"2021-06-13T04:36:17.646986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['length_alphabets'] = train_df['text'].apply(lambda x: get_length_alphabets(x))\ntrain_df['length_words'] = train_df['text'].apply(lambda x: get_length_words(x))\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:36:17.649433Z","iopub.execute_input":"2021-06-13T04:36:17.649977Z","iopub.status.idle":"2021-06-13T04:36:17.722658Z","shell.execute_reply.started":"2021-06-13T04:36:17.649936Z","shell.execute_reply":"2021-06-13T04:36:17.721918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### ðŸ’¡ We can check dataframes describe ([length_alphabets] / [length_words] )","metadata":{}},{"cell_type":"code","source":"train_df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:36:22.132551Z","iopub.execute_input":"2021-06-13T04:36:22.13287Z","iopub.status.idle":"2021-06-13T04:36:22.155225Z","shell.execute_reply.started":"2021-06-13T04:36:22.132841Z","shell.execute_reply":"2021-06-13T04:36:22.15442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PuBu_palette","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:36:24.433296Z","iopub.execute_input":"2021-06-13T04:36:24.433823Z","iopub.status.idle":"2021-06-13T04:36:24.447068Z","shell.execute_reply.started":"2021-06-13T04:36:24.433778Z","shell.execute_reply":"2021-06-13T04:36:24.446118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"three_PuBu_palette = list()\nthree_PuBu_palette.append(PuBu_palette[2])\nthree_PuBu_palette.append(PuBu_palette[6])\nthree_PuBu_palette.append(PuBu_palette[4])\nthree_PuBu_palette","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:36:25.072021Z","iopub.execute_input":"2021-06-13T04:36:25.072378Z","iopub.status.idle":"2021-06-13T04:36:25.082192Z","shell.execute_reply.started":"2021-06-13T04:36:25.072345Z","shell.execute_reply":"2021-06-13T04:36:25.081218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(12, 8))\ngs = fig.add_gridspec(2,1)\n\naxes = list()\n\nfor index, data in zip(range(2), train_df):\n    axes.append(fig.add_subplot(gs[index, 0]))\n    \n    \n    if index==0:\n        sns.kdeplot(x='length_alphabets', data=train_df, \n                        fill=True, ax=axes[index], cut=0, bw_method=0.20, \n                        lw=1.4 , hue='sentiment', palette=three_PuBu_palette,\n                         alpha=0.3)\n    else:\n        sns.kdeplot(x='length_words', data=train_df, \n                    fill=True, ax=axes[index], cut=0, bw_method=0.20, \n                    lw=1.4 , hue='sentiment',palette=three_PuBu_palette,\n                     alpha=0.3) \n\n    axes[index].set_yticks([])\n    if index != 1 : axes[index].set_xticks([])\n    axes[index].set_ylabel('')\n    axes[index].set_xlabel('')\n    axes[index].spines[[\"top\",\"right\",\"left\",\"bottom\"]].set_visible(False)\n    \n    \n    if index == 0:\n        axes[index].text(-0.2,0,\"length_alphabets\",fontweight=\"light\", fontfamily='serif', fontsize=13,ha=\"right\")\n    else:\n        axes[index].text(-0.2,0,\"length_words\",fontweight=\"light\", fontfamily='serif', fontsize=13,ha=\"right\")\n        \n        \n    axes[index].patch.set_alpha(0)\n    if index != 0 : axes[index].get_legend().remove()\n        \nfig.text(0.05,0.91,\"Count distribution by length in Tweets\", fontweight=\"bold\", fontfamily='serif', fontsize=20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:36:26.042576Z","iopub.execute_input":"2021-06-13T04:36:26.042883Z","iopub.status.idle":"2021-06-13T04:36:26.736786Z","shell.execute_reply.started":"2021-06-13T04:36:26.042852Z","shell.execute_reply":"2021-06-13T04:36:26.735888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3-4) Bi-gram by sentiment per texts in Tweets","metadata":{}},{"cell_type":"code","source":"def get_top_tweet_bigrams(corpus, n=None):\n    vec = CountVectorizer(ngram_range=(2, 2)).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:n]","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:37:09.073165Z","iopub.execute_input":"2021-06-13T04:37:09.073494Z","iopub.status.idle":"2021-06-13T04:37:09.082075Z","shell.execute_reply.started":"2021-06-13T04:37:09.073464Z","shell.execute_reply":"2021-06-13T04:37:09.080925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1,3, figsize=(12, 10), constrained_layout=True)\n\nsentiment_list = list(np.unique(train_df['sentiment']))\n\nfor i, sentiment in zip(range(3), sentiment_list):\n    top_tweet_bigrams = get_top_tweet_bigrams(train_df[train_df['sentiment']==sentiment]['text'].fillna(\" \"))[:10]\n    x,y = map(list,zip(*top_tweet_bigrams))\n    sns.barplot(x=y, y=x, ax=axes[i], palette=PuBu_palette[::-1])\n    axes[i].text(0,-0.7, sentiment, fontweight=\"bold\", fontfamily='serif', fontsize=13,ha=\"right\")\n    axes[i].patch.set_alpha(0)\n\nfig.text(0,1.01,\"Bi-gram by {}texts in Tweets\".format(sentiment), fontweight=\"bold\", fontfamily='serif', fontsize=18)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:37:09.421421Z","iopub.execute_input":"2021-06-13T04:37:09.421693Z","iopub.status.idle":"2021-06-13T04:37:11.788789Z","shell.execute_reply.started":"2021-06-13T04:37:09.421664Z","shell.execute_reply":"2021-06-13T04:37:11.787908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Prepocessing Data\n* Drop null rows & useless columns\n* Cleansing \"text\" / \"selected_text\" data","metadata":{}},{"cell_type":"markdown","source":"### 4-1) Drop null rows & useless columns","metadata":{}},{"cell_type":"code","source":"train_df_before_drop_shape = train_df.shape\ntest_df_before_drop_shape = test_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:37:37.253037Z","iopub.execute_input":"2021-06-13T04:37:37.25336Z","iopub.status.idle":"2021-06-13T04:37:37.257192Z","shell.execute_reply.started":"2021-06-13T04:37:37.253333Z","shell.execute_reply":"2021-06-13T04:37:37.25607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.dropna(inplace=True)\ntest_df.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:37:37.57993Z","iopub.execute_input":"2021-06-13T04:37:37.580261Z","iopub.status.idle":"2021-06-13T04:37:37.600356Z","shell.execute_reply.started":"2021-06-13T04:37:37.580232Z","shell.execute_reply":"2021-06-13T04:37:37.599557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.drop(['length_alphabets','length_words'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:37:37.957237Z","iopub.execute_input":"2021-06-13T04:37:37.957525Z","iopub.status.idle":"2021-06-13T04:37:37.964132Z","shell.execute_reply.started":"2021-06-13T04:37:37.9575Z","shell.execute_reply":"2021-06-13T04:37:37.963264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_drop_shape = train_df.shape\ntest_df_drop_shape = test_df.shape\n\nprint(\"Train dataset Shape : {} => {}\".format(train_df_before_drop_shape, train_df_drop_shape))\nprint(\"Test dataset Shape : {} => {}\".format(test_df_before_drop_shape, test_df_drop_shape))","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:37:38.342685Z","iopub.execute_input":"2021-06-13T04:37:38.343012Z","iopub.status.idle":"2021-06-13T04:37:38.349367Z","shell.execute_reply.started":"2021-06-13T04:37:38.342966Z","shell.execute_reply":"2021-06-13T04:37:38.348353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4-2) Cleansing \"text\" / \"selected_text\" data","metadata":{}},{"cell_type":"code","source":"def preprocess_fn(text):\n    text = str(text)\n    text = text.lower()  # lowercase\n\n    text = re.sub(r'[!]+', '!', text)\n    text = re.sub(r'[?]+', '?', text)\n    text = re.sub(r'[.]+', '.', text)\n    text = re.sub(r\"'\", \"\", text)\n    text = re.sub('\\s+', ' ', text).strip()  # Remove and double spaces\n    text = re.sub(r'&amp;?', r'and', text)  # replace & -> and\n    # remove some puncts (except . ! # ? *)\n    text = re.sub(r'[:\"$%&\\+,-/:;<=>@\\\\^_{|}~`]+', '', text)\n    emoji_pattern = re.compile(\"[\"\n                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                               u\"\\U00002702-\\U000027B0\"\n                               u\"\\U000024C2-\\U0001F251\"\n                               \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'EMOJI', text)\n    \n    return text","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:37:39.242687Z","iopub.execute_input":"2021-06-13T04:37:39.243016Z","iopub.status.idle":"2021-06-13T04:37:39.249185Z","shell.execute_reply.started":"2021-06-13T04:37:39.242963Z","shell.execute_reply":"2021-06-13T04:37:39.248285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['text'] = train_df['text'].apply(lambda x: preprocess_fn(x))\ntrain_df['selected_text'] = train_df['selected_text'].apply(lambda x: preprocess_fn(x))\n\ntest_df['text'] = test_df['text'].apply(lambda x: preprocess_fn(x))","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:37:39.653092Z","iopub.execute_input":"2021-06-13T04:37:39.653343Z","iopub.status.idle":"2021-06-13T04:37:40.891762Z","shell.execute_reply.started":"2021-06-13T04:37:39.653319Z","shell.execute_reply":"2021-06-13T04:37:40.890949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:37:40.893201Z","iopub.execute_input":"2021-06-13T04:37:40.893555Z","iopub.status.idle":"2021-06-13T04:37:40.906258Z","shell.execute_reply.started":"2021-06-13T04:37:40.893519Z","shell.execute_reply":"2021-06-13T04:37:40.905335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Visualization [After Preprocessing]\n* Wordcloude by sentiment per selected text in Tweets","metadata":{}},{"cell_type":"markdown","source":"### 5-1) Wordcloud by sentiment per selected text in Tweets","metadata":{}},{"cell_type":"code","source":"mask_dir = np.array(Image.open('../input/masksforwordclouds/twitter_mask3.jpg'))","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:37:42.352321Z","iopub.execute_input":"2021-06-13T04:37:42.352651Z","iopub.status.idle":"2021-06-13T04:37:42.368731Z","shell.execute_reply.started":"2021-06-13T04:37:42.35262Z","shell.execute_reply":"2021-06-13T04:37:42.36796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1,3, figsize=(24,12))\nsentiment_list = np.unique(train_df['sentiment'])\n\nfor i, sentiment in zip(range(3), sentiment_list):\n    wc = WordCloud(background_color=\"white\", max_words = 2000, width = 1600, height = 800, mask=mask_dir, colormap=\"Blues\").generate(\" \".join(train_df[train_df['sentiment']==sentiment]['selected_text']))\n    \n    axes[i].text(0.5,1, \"{} text\".format(sentiment), fontweight=\"bold\", fontfamily='serif', fontsize=17)\n    axes[i].patch.set_alpha(0)\n    axes[i].axis('off')\n    axes[i].imshow(wc)\n\nfig.text(0.1,0.8,\"WordCloud by sentiment per selected text in Tweets\", fontweight=\"bold\", fontfamily='serif', fontsize=20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:37:43.743775Z","iopub.execute_input":"2021-06-13T04:37:43.744146Z","iopub.status.idle":"2021-06-13T04:37:48.427695Z","shell.execute_reply.started":"2021-06-13T04:37:43.744115Z","shell.execute_reply":"2021-06-13T04:37:48.426922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Feature Enginnering \n* How to use Bert tokenization\n* Convert to data suitable for Bert model (Dataset / Dataloader)","metadata":{}},{"cell_type":"markdown","source":"#### -> We do not preprocess because our goal is to print literally.","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\ntest_df = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\n\ntrain_df.dropna(inplace=True)\ntest_df.dropna(inplace=True)\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:38:03.712935Z","iopub.execute_input":"2021-06-13T04:38:03.713306Z","iopub.status.idle":"2021-06-13T04:38:03.799323Z","shell.execute_reply.started":"2021-06-13T04:38:03.713273Z","shell.execute_reply":"2021-06-13T04:38:03.798351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6-1) How to use Bert tokenization","metadata":{}},{"cell_type":"code","source":"bert_tokenizer = BertTokenizer.from_pretrained(\n    '../input/bert-base-uncased/vocab.txt',\n    do_lower_case=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:38:04.071718Z","iopub.execute_input":"2021-06-13T04:38:04.072032Z","iopub.status.idle":"2021-06-13T04:38:04.135126Z","shell.execute_reply.started":"2021-06-13T04:38:04.071984Z","shell.execute_reply":"2021-06-13T04:38:04.134367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Original Text\")\nprint(train_df['text'][0]) # original sentence\nprint(\"\\n\")\n\nprint(\"Original Text Data\")\nprint(bert_tokenizer.tokenize(train_df['text'][0]))\nprint(bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize(train_df['text'][0])))\nprint(bert_tokenizer.decode(bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize(train_df['text'][0]))))\nprint(\"\\n\")\n\nprint(\"Selcted Text Data\")\nprint(bert_tokenizer.tokenize(train_df['selected_text'][0]))\nprint(bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize(train_df['selected_text'][0])))\nprint(bert_tokenizer.decode(bert_tokenizer.convert_tokens_to_ids(bert_tokenizer.tokenize(train_df['selected_text'][0]))))","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:38:04.292554Z","iopub.execute_input":"2021-06-13T04:38:04.292809Z","iopub.status.idle":"2021-06-13T04:38:09.284805Z","shell.execute_reply.started":"2021-06-13T04:38:04.292784Z","shell.execute_reply":"2021-06-13T04:38:09.283503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_max_len(df):\n    max_len = 0\n    for text in df['text']:\n\n        # Tokenize the text and add special tokens i.e `[CLS]` and `[SEP]`\n        input_ids = bert_tokenizer.encode(text, add_special_tokens=True)\n        # Update the maximum sentence length.\n        max_len = max(max_len, len(input_ids))\n\n    return max_len","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:38:09.286622Z","iopub.execute_input":"2021-06-13T04:38:09.287205Z","iopub.status.idle":"2021-06-13T04:38:09.296874Z","shell.execute_reply.started":"2021-06-13T04:38:09.28714Z","shell.execute_reply":"2021-06-13T04:38:09.296033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_len = get_max_len(train_df)\nprint(\"max len : \", max_len)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:38:09.298821Z","iopub.execute_input":"2021-06-13T04:38:09.2994Z","iopub.status.idle":"2021-06-13T04:38:22.366745Z","shell.execute_reply.started":"2021-06-13T04:38:09.299363Z","shell.execute_reply":"2021-06-13T04:38:22.365806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6-2) Convert to data suitable for Bert model (Dataset / Dataloader)","metadata":{}},{"cell_type":"code","source":"class BertDataset(torch.utils.data.Dataset):\n    def __init__(self, df, max_len=max_len, is_label=False):\n        self.df = df\n        self.max_len = max_len + 3 # 3 means `[CLS]` and sentiment and `[SEP]`\n        self.is_label = is_label\n\n        \n    def __len__(self):\n        return len(self.df)\n    \n\n    def __getitem__(self, index):\n        global data\n        data = {}\n        row = self.df.iloc[index]\n\n        ids, masks, token_type  = self.get_bert_tokenize(row)\n        data['input_ids'] = ids\n        data['attention_masks'] = masks\n        data['token_type_ids'] = token_type\n        \n        # Text / Selected Text Decode\n        data['text'] = bert_tokenizer.decode(ids)\n        \n        if self.is_label:\n            start_idx, end_idx = self.get_label_idx(data, row)\n            data['start_index'] = start_idx\n            data['end_index'] = end_idx\n             \n        return data\n\n        \n    def get_label_idx(self, data, row):\n        # get lavel ids\n        global start_index\n        global end_index\n        \n        text_id = bert_tokenizer.encode(\n                row['selected_text'],\n                add_special_tokens=False,\n            )\n        label_len = len(text_id)\n            \n        # get start index / end index        \n        for i in range(self.max_len):\n            if data['input_ids'][i] == text_id[0]:\n                if data['input_ids'][i+label_len-1] == text_id[-1]:\n                    start_index = i\n                    end_index = i+label_len-1\n                    break\n\n        return torch.tensor(start_index), torch.tensor(end_index)\n    \n    \n    def get_bert_tokenize(self, row):\n        \n        text = row['text']\n        sentiment = row['sentiment']\n        \n        encoded = bert_tokenizer.encode_plus(\n          sentiment,\n          text,\n          add_special_tokens=True,\n          max_length=self.max_len,\n          pad_to_max_length=True,\n          return_token_type_ids=True,\n          return_attention_mask=True,\n          return_tensors='pt'\n        )\n\n        input_ids = encoded['input_ids'].squeeze()\n        attention_masks = encoded['attention_mask'].squeeze()\n        token_type_ids = encoded['token_type_ids'].squeeze()\n        \n        return input_ids, attention_masks, token_type_ids  ","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:38:22.368387Z","iopub.execute_input":"2021-06-13T04:38:22.368891Z","iopub.status.idle":"2021-06-13T04:38:22.382191Z","shell.execute_reply.started":"2021-06-13T04:38:22.36885Z","shell.execute_reply":"2021-06-13T04:38:22.381408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* 1) Split Train data / Validation data\n* 2) Get Dataset\n* 3) Get Dataloader","metadata":{}},{"cell_type":"code","source":"train_df, val_df = train_test_split(train_df, test_size=0.2)\nprint(\"Train dataframe size:\",train_df.shape)\nprint(\"Validation dataframe size:\",val_df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:38:22.383475Z","iopub.execute_input":"2021-06-13T04:38:22.383809Z","iopub.status.idle":"2021-06-13T04:38:22.402825Z","shell.execute_reply.started":"2021-06-13T04:38:22.383774Z","shell.execute_reply":"2021-06-13T04:38:22.401789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = BertDataset(train_df, is_label=True)\nval_dataset = BertDataset(val_df, is_label=True)\ntest_dataset = BertDataset(test_df, is_label=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:38:22.404084Z","iopub.execute_input":"2021-06-13T04:38:22.404412Z","iopub.status.idle":"2021-06-13T04:38:22.409166Z","shell.execute_reply.started":"2021-06-13T04:38:22.404379Z","shell.execute_reply":"2021-06-13T04:38:22.407964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Original text length: {} \\n\".format(len(train_dataset[0]['input_ids'])))\nprint(\"Original text: {} \\n\\n\".format(train_dataset[0]['text']))\n\nprint(\"[input_ids] \\n\", train_dataset[0]['input_ids'])\nprint(\"\\n[attention_masks] \\n\", train_dataset[0]['attention_masks'])\nprint(\"\\n[token_type_ids] \\n\", train_dataset[0]['token_type_ids'])","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:38:22.41045Z","iopub.execute_input":"2021-06-13T04:38:22.41096Z","iopub.status.idle":"2021-06-13T04:38:22.469677Z","shell.execute_reply.started":"2021-06-13T04:38:22.410916Z","shell.execute_reply":"2021-06-13T04:38:22.468672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- 1. input_ids: Token value to be passed to the model.\n- 2. attention_masks: Token value for the model to recognize the sequence.\n- 3. token_type_ids: Token value for the model to distinguish between two sequences. The first is 'sentiment', and the second is a token value for the 'text' value.","metadata":{}},{"cell_type":"code","source":"def get_train_val_loaders(train_dataset, val_dataset, batch_size=8):\n    \n    train_loader = torch.utils.data.DataLoader(\n        train_dataset,\n        batch_size=8, \n        shuffle=True, \n        num_workers=0,\n        drop_last=True)\n    \n    val_loader = torch.utils.data.DataLoader(\n        val_dataset,\n        batch_size=batch_size, \n        shuffle=False, \n        num_workers=0)\n    \n    dataloaders_dict = {\"train\": train_loader, \"val\": val_loader}\n    return dataloaders_dict\n\n\ndef get_test_loader(dataset, batch_size=32):\n    \n    loader = torch.utils.data.DataLoader(\n        dataset,\n        batch_size=batch_size, \n        shuffle=False, \n        num_workers=0)  \n    \n    return loader","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:38:22.472926Z","iopub.execute_input":"2021-06-13T04:38:22.473409Z","iopub.status.idle":"2021-06-13T04:38:22.479285Z","shell.execute_reply.started":"2021-06-13T04:38:22.473373Z","shell.execute_reply":"2021-06-13T04:38:22.478095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict_loader = get_train_val_loaders(train_dataset, val_dataset)\ntest_loader = get_test_loader(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:38:22.480951Z","iopub.execute_input":"2021-06-13T04:38:22.481331Z","iopub.status.idle":"2021-06-13T04:38:22.487665Z","shell.execute_reply.started":"2021-06-13T04:38:22.481293Z","shell.execute_reply":"2021-06-13T04:38:22.486666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dict_loader","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:38:22.48895Z","iopub.execute_input":"2021-06-13T04:38:22.489308Z","iopub.status.idle":"2021-06-13T04:38:22.500243Z","shell.execute_reply.started":"2021-06-13T04:38:22.489275Z","shell.execute_reply":"2021-06-13T04:38:22.499442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7.Modeling\n* Bert Modeling\n* Loss Function (CrossEntropyLoss / Jaccard )\n* Training\n* Evaluating","metadata":{}},{"cell_type":"code","source":"USE_CUDA = torch.cuda.is_available() \nprint(USE_CUDA)\n\ndevice = torch.device('cuda:0' if USE_CUDA else 'cpu') \nprint('A device that proceeds with : ',device)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:38:22.501334Z","iopub.execute_input":"2021-06-13T04:38:22.501685Z","iopub.status.idle":"2021-06-13T04:38:22.553241Z","shell.execute_reply.started":"2021-06-13T04:38:22.501652Z","shell.execute_reply":"2021-06-13T04:38:22.552489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7-1) Bert Modeling","metadata":{}},{"cell_type":"code","source":"## main ##\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        config = BertConfig.from_pretrained(\n            '../input/bert-base-uncased/config.json', output_hidden_states=True)    \n        self.bert = transformers.BertModel.from_pretrained(\n            '../input/bert-base-uncased/pytorch_model.bin', config=config)\n        self.hidden_size = self.bert.config.hidden_size\n        self.LSTM = nn.LSTM(self.hidden_size*2, 128)\n        self.layer = nn.Sequential(\n            nn.Linear(128,64),\n            nn.Dropout(0.2),\n        )\n    \n        # The output will have two dimensions (\"start_logits\", and \"end_logits\")\n        self.FC = nn.Linear(64,2)\n        torch.nn.init.normal_(self.FC.weight, std=0.02)\n        \n \n    def forward(self, ids, mask, token):\n        # Return the hidden states from the BERT backbone\n        out = self.bert(\n            ids,\n            attention_mask=mask,\n            token_type_ids=token\n        )\n        \n        out = torch.cat((out[2][-1],out[2][-2]), dim=-1)\n        \n        out, _ = self.LSTM(out)\n        out = self.layer(out)\n        logits = self.FC(out)\n        start_logits, end_logits = logits.split(1, dim=-1)\n        start_logits = start_logits.squeeze(-1)\n        end_logits = end_logits.squeeze(-1)\n\n        return start_logits, end_logits","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:38:22.554416Z","iopub.execute_input":"2021-06-13T04:38:22.554936Z","iopub.status.idle":"2021-06-13T04:38:22.565287Z","shell.execute_reply.started":"2021-06-13T04:38:22.554902Z","shell.execute_reply":"2021-06-13T04:38:22.56446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7-2) Loss Function \n* CrossEntropyLoss\n* Jaccard ","metadata":{}},{"cell_type":"code","source":"def loss_fn(start_logits, end_logits, start_positions, end_positions):\n    ce_loss = nn.CrossEntropyLoss()\n    start_loss = ce_loss(start_logits, start_positions)\n    end_loss = ce_loss(end_logits, end_positions)    \n    total_loss = start_loss + end_loss\n    return total_loss","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:38:22.566625Z","iopub.execute_input":"2021-06-13T04:38:22.567222Z","iopub.status.idle":"2021-06-13T04:38:22.573755Z","shell.execute_reply.started":"2021-06-13T04:38:22.567188Z","shell.execute_reply":"2021-06-13T04:38:22.572925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_selected_text(text_encode, start_idx, end_idx):\n    text_encode = text_encode[start_idx: end_idx + 1]\n    selected_text = bert_tokenizer.decode(text_encode)\n    return selected_text\n\n\ndef get_original_text(text_encode):\n    text_encode = text_encode[3:]\n    for i, encode in enumerate(text_encode):\n        if encode == 102:\n            last_index = i\n            break\n    return bert_tokenizer.decode(text_encode[:last_index])\n    \n       \ndef jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))\n\n\ndef compute_jaccard_score(text_encode, start_idx, end_idx, start_logits, end_logits):\n    start_pred = np.argmax(start_logits)\n    end_pred = np.argmax(end_logits)\n    # print(\"start predict index : {} / end predict index : {}\".format(start_pred, end_pred))\n    # print(\"start real index : {} / end real index : {}\".format(start_idx, end_idx))\n    # print(text_encode)\n    \n    if start_pred > end_pred:\n        pred = get_original_text(text_encode)\n        # print(\"get original text\", pred)\n    else:\n        pred = get_selected_text(text_encode, start_pred, end_pred)\n        # print(\"get selected text : \",pred)\n        \n    true = get_selected_text(text_encode, start_idx, end_idx)\n    # print(\"get label text : \",true)\n    return jaccard(true, pred)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:38:22.575052Z","iopub.execute_input":"2021-06-13T04:38:22.57575Z","iopub.status.idle":"2021-06-13T04:38:22.585192Z","shell.execute_reply.started":"2021-06-13T04:38:22.575713Z","shell.execute_reply":"2021-06-13T04:38:22.584328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7-3) Training","metadata":{}},{"cell_type":"code","source":"def train_model(model, dataloaders_dict, criterion, optimizer, num_epochs, filename):\n    model.to(device)\n\n    for epoch in range(num_epochs):\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n\n            epoch_loss = 0.0\n            epoch_jaccard = 0.0\n            \n            for j, data in enumerate((dataloaders_dict[phase])):\n                ids = data['input_ids'].to(device, dtype=torch.int64)\n                masks = data['attention_masks'].to(device, dtype=torch.int64)\n                token = data['token_type_ids'].to(device, dtype=torch.int64)\n                start_idx = data['start_index'].to(device, dtype=torch.int64)\n                end_idx = data['end_index'].to(device, dtype=torch.int64)\n\n                optimizer.zero_grad()\n\n                with torch.set_grad_enabled(phase == 'train'):\n                    \n                    start_logits, end_logits = model(ids, masks, token)\n                    \n                    loss = criterion(start_logits, end_logits, start_idx, end_idx)\n                    \n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                    epoch_loss += loss.item() * len(ids)\n                    \n                    start_idx = start_idx.cpu().detach().numpy()\n                    end_idx = end_idx.cpu().detach().numpy()\n                    start_logits = torch.softmax(start_logits, dim=1).cpu().detach().numpy()\n                    end_logits = torch.softmax(end_logits, dim=1).cpu().detach().numpy()\n                    \n                    \n                    for i in range(len(ids)):                        \n                        jaccard_score = compute_jaccard_score(\n                            ids[i],\n                            start_idx[i],#ì¸ì½”ë”© í›„\n                            end_idx[i],\n                            start_logits[i], #ì¸ì½”ë”© í›„\n                            end_logits[i])\n                        epoch_jaccard += jaccard_score\n                    \n            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n            epoch_jaccard = epoch_jaccard / len(dataloaders_dict[phase].dataset)\n            \n            print('Epoch {}/{} | {:^5} | Loss: {:.4f} | Jaccard: {:.4f}'.format(\n                epoch + 1, num_epochs, phase, epoch_loss, epoch_jaccard))\n    \n    torch.save(model.state_dict(), SAVE_MODEL_PATH)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:38:22.586645Z","iopub.execute_input":"2021-06-13T04:38:22.58709Z","iopub.status.idle":"2021-06-13T04:38:22.602067Z","shell.execute_reply.started":"2021-06-13T04:38:22.587058Z","shell.execute_reply":"2021-06-13T04:38:22.60128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Training Bert Model","metadata":{}},{"cell_type":"code","source":"import gc\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:38:22.603676Z","iopub.execute_input":"2021-06-13T04:38:22.603919Z","iopub.status.idle":"2021-06-13T04:38:22.808061Z","shell.execute_reply.started":"2021-06-13T04:38:22.603888Z","shell.execute_reply":"2021-06-13T04:38:22.80714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 3\nSAVE_MODEL_PATH = f'bert.pth'","metadata":{"execution":{"iopub.status.busy":"2021-06-13T04:38:22.810279Z","iopub.execute_input":"2021-06-13T04:38:22.810527Z","iopub.status.idle":"2021-06-13T04:38:22.817659Z","shell.execute_reply.started":"2021-06-13T04:38:22.810504Z","shell.execute_reply":"2021-06-13T04:38:22.816852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model() \noptimizer = optim.AdamW(model.parameters(), lr=3e-5, betas=(0.9, 0.999))\ncriterion = loss_fn\n\ntrain_model(\n    model, \n    dict_loader,\n    criterion, \n    optimizer, \n    EPOCHS,\n    SAVE_MODEL_PATH)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T11:16:32.41043Z","iopub.execute_input":"2021-06-02T11:16:32.410779Z","iopub.status.idle":"2021-06-02T11:25:12.131309Z","shell.execute_reply.started":"2021-06-02T11:16:32.410748Z","shell.execute_reply":"2021-06-02T11:25:12.128911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 7-4) Evaluating","metadata":{}},{"cell_type":"code","source":"predictions = []\n\nmodel = Model()\nmodel.cuda()\nmodel.load_state_dict(torch.load(f'bert.pth'))\nmodel.eval()\n\n\nfor data in test_loader:\n    ids = data['input_ids'].to(device, dtype=torch.int64)\n    masks = data['attention_masks'].to(device, dtype=torch.int64)\n    token = data['token_type_ids'].to(device, dtype=torch.int64)\n                                          \n    start_logits = []\n    end_logits = []\n    with torch.no_grad():\n        start_logit, end_logit = model(ids, masks, token)\n        start_logits = torch.softmax(start_logit, dim=1).cpu().detach().numpy()\n        end_logits = torch.softmax(end_logit, dim=1).cpu().detach().numpy()\n    \n    for i in range(len(ids)):    \n        start_pred = np.argmax(start_logits[i])\n        end_pred = np.argmax(end_logits[i])\n        if start_pred > end_pred:\n            pred = get_original_text(ids[i])\n        else:\n            pred = get_selected_text(ids[i], start_pred, end_pred)\n        predictions.append(pred)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:57.300391Z","iopub.status.idle":"2021-05-28T08:55:57.301142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:57.302295Z","iopub.status.idle":"2021-05-28T08:55:57.303011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"[Predicton head]\")\nfor i,pred in enumerate(predictions[:5]):\n    print(\"index\",i,\": \",pred)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:57.304075Z","iopub.status.idle":"2021-05-28T08:55:57.304761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. Submission\n* Submit the predictions","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv('../input/tweet-sentiment-extraction/sample_submission.csv')\nsubmission['selected_text'] = predictions\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:57.305829Z","iopub.status.idle":"2021-05-28T08:55:57.306542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:57.307589Z","iopub.status.idle":"2021-05-28T08:55:57.308317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### reference \n* https://www.kaggle.com/subinium/tps-apr-highlighting-the-data : EDA part (Visualiztion)\n* https://www.kaggle.com/shoheiazuma/tweet-sentiment-roberta-pytorch : Feature Enginnering & Modeling(Bert)\n* https://www.kaggle.com/abhishek/bert-base-uncased-using-pytorch : Modeling(Bert)\n* https://www.kaggle.com/parulpandey/eda-and-preprocessing-for-bert : Modeling(Bert)\n\n###  If this notebook is useful for your kaggling, \"UPVOTE\" for it ðŸ‘€\n#### THX to Reading My NotebookðŸŒˆ","metadata":{}}]}