{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Install dependencies","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install '/kaggle/input/simple-transformers-pypi/seqeval-0.0.12-py3-none-any.whl' -q\n!pip install '/kaggle/input/simple-transformers-pypi/simpletransformers-0.22.1-py3-none-any.whl' -q","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocess the data in Squad training format","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Training corpus","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\n\ntrain_data = list()\n\nimport pandas as pd\n\ntrain = pd.read_csv('../input/tweet-sentiment-extraction/train.csv')\n\nfor id, row in train.iterrows():\n    template = {\n        'context': \"\",\n        'qas': [\n            {\n                'id': \"\",\n                'is_impossible': False,\n                'question': \"\",\n                'answers': [\n                    {\n                        'text': \"\",\n                        'answer_start':''\n                    }\n                ]\n            }\n        ]\n    }\n    template['qas'][0]['id'] = row['textID']\n    \n    context = str(row['text'])\n    question = row['sentiment']\n    answer = str(row['selected_text'])\n    \n    template['context'] = context.lower()\n    template['qas'][0]['question'] = question.lower()\n    template['qas'][0]['answers'][0]['text'] = answer.lower()\n    try:\n        template['qas'][0]['answers'][0]['answer_start'] = context.index(answer)\n    except AttributeError:\n        print(id, row['text'], row['selected_text'])\n\n    train_data.append(template)\n\nwith open('train_processed.json', 'w') as f:\n    json.dump(train_data, f)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test corpus","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\n\ntest_data = list()\n\nimport pandas as pd\n\ntest = pd.read_csv('../input/tweet-sentiment-extraction/test.csv')\n\nfor id, row in test.iterrows():\n    template = {\n        'context': \"\",\n        'qas': [\n            {\n                'id': \"\",\n                'is_impossible': False,\n                'question': \"\",\n                'answers': [\n                    {\n                        'text': \"\",\n                        'answer_start': ''\n                    }\n                ]\n            }\n        ]\n    }\n\n    template['context'] = str(row['text']).lower()\n    template['qas'][0]['id'] = row['textID']\n    template['qas'][0]['question'] = str(row['sentiment']).lower()\n    test_data.append(template)\n\nwith open('test_processed.json', 'w') as f:\n    json.dump(test_data, f)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create model and run the training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from simpletransformers.question_answering import QuestionAnsweringModel\nimport json\nimport os\nimport logging\n\n\nlogging.basicConfig(level=logging.INFO)\ntransformers_logger = logging.getLogger(\"transformers\")\ntransformers_logger.setLevel(logging.WARNING)\n\nwith open('train_processed.json', 'r') as f:\n    train_data = json.load(f)\n\ntrain_args = {\n    'reprocess_input_data': True,\n    'use_multiprocessing': False,\n#     'use_early_stopping': True,\n#     'early_stopping_patience': 7,\n#     'weight_decay': 0.000001,\n    'do_lower_case': True,\n    \"wandb_project\": False,\n    'learning_rate': 5e-5,\n    'num_train_epochs': 3,\n    'max_seq_length': 192,\n    'doc_stride': 64,\n    'overwrite_output_dir': True,\n    'reprocess_input_data': False,\n#     'train_batch_size': 8,\n#     'gradient_accumulation_steps': 1,\n    'save_steps': 0,\n    'fp16': False,\n    'save_eval_checkpoints': False,\n    'save_model_every_epoch': False\n}\n\narch = 'albert'\nm = '/kaggle/input/pretrained-albert-pytorch/albert-large-v1'\n\n# arch = 'distilbert'\n# m = '/kaggle/input/transformers-pretrained-distilbert/distilbert-base-uncased-distilled-squad/'\n\n# m = 'outputs/best_model'\n# m = 'outputs/checkpoint-1644-epoch-2'\n\n# Create the QuestionAnsweringModel\nmodel = QuestionAnsweringModel(arch, m,\n                               args=train_args,\n                               use_cuda=True\n                               )\n\n# Train the model with JSON file\n# model.train_model()\n\nmodel.train_model(train_data)\n\n\nwith open('test_processed.json', 'r') as f:\n    test_data = json.load(f)\n\nimport pandas as pd\npred = model.predict(test_data)\n\nfinal_output = list()\n\nfor p in pred:\n    idText = p['id']\n    answer = p['answer']\n    out = {'textID': idText, 'selected_text': answer}\n    final_output.append(out)\n    \nout_df = pd.DataFrame(final_output)\nout_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}