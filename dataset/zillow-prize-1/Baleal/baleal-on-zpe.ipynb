{"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"pygments_lexer":"ipython3","file_extension":".py","mimetype":"text/x-python","nbconvert_exporter":"python","version":"3.6.1","name":"python"}},"nbformat_minor":0,"cells":[{"metadata":{"_uuid":"13d217817290becd8dd0f41a5108db8b96dd166d","_execution_state":"idle","collapsed":false,"_cell_guid":"65c07bb7-7f8d-46a6-abb5-2bd109c4c339"},"source":"This notebook will be my first attempt on the Zillow Prize competition\nThe objective: Build a model to improve the Zestimate residual error.","outputs":[],"execution_count":null,"cell_type":"markdown"},{"metadata":{"_uuid":"c996571ac7a13da5b959404a50dc5534207da622","_execution_state":"idle","collapsed":false,"_cell_guid":"fa56e7a6-b5ed-4e40-a0a8-e619ef9cbbf5"},"source":" ## 1. Data Exploration ##","outputs":[],"execution_count":null,"cell_type":"markdown"},{"metadata":{"trusted":false,"_execution_state":"idle","_uuid":"98f5000bd8d7362ecdf73b8a67ed4a848f46120a","_cell_guid":"33ca57a7-8e1f-4957-b838-165086883c7a"},"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncolor = sns.color_palette()\n\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","outputs":[],"execution_count":null,"cell_type":"code"},{"metadata":{"_uuid":"2b9a97dd7076e9980ff97b4fc97d55ebeb42595e","_execution_state":"idle","collapsed":false,"_cell_guid":"04290e0d-9c3f-41ac-9311-78df7a2d7924"},"source":"1.1 Train_2016_v2\n-----------------\n\nI used https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-zillow-prize as a nice introduction to the data exploration\n\n1. Parcel Id: 90554 Id's are unique/ 127 *2 /1 * 3 \n2. logerror: normally distributed with heavy outliners\n3. Transaciont date: the number of transactions is way smaler for the months nov - dec ( from the datapage: *The train data has all the transactions before October 15, 2016, plus some of the transactions after October 15, 2016*) . When checking for weekdays: the number of transactions rise during to week, maxing on friday. Almost no transactions occur during weekends.","outputs":[],"execution_count":null,"cell_type":"markdown"},{"metadata":{"_uuid":"da16b62dae417f846c30fa881b91308bedec2bde","_execution_state":"idle","collapsed":false,"_cell_guid":"91d862f5-7df6-42d1-9f87-09ea28a626c9","trusted":false},"source":"train_df = pd.read_csv(\"../input/train_2016_v2.csv\", parse_dates = [\"transactiondate\"])\ntrain_df.shape","outputs":[],"execution_count":null,"cell_type":"code"},{"metadata":{"_uuid":"f77a65b67890b6de9e3d613bd5fca0ac7f7c6d5a","_execution_state":"idle","collapsed":false,"_cell_guid":"25587b0a-facc-4063-8d2d-01285882c82c","trusted":false},"source":"train_df['transaction_day'] = train_df['transactiondate'].dt.weekday\n\ncnt_srs = train_df['transaction_day'].value_counts()\nplt.figure(figsize=(10,6))\nsns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8, color=color[3])\nplt.xticks(rotation='vertical')\nplt.xlabel('Day of transaction', fontsize=12)\nplt.ylabel('Number of Occurrences', fontsize=12)\nplt.show()","outputs":[],"execution_count":null,"cell_type":"code"},{"metadata":{"_uuid":"19a84ee1f38b517472c707304a004cb543a5e212","_execution_state":"idle","collapsed":false,"_cell_guid":"fb0064e9-c570-410f-bb6a-6e9802035cfe"},"source":"\n\n1.2 Properties_2016\n-----------------\n\n","outputs":[],"execution_count":null,"cell_type":"markdown"},{"metadata":{"_uuid":"c3b0743dfb51de1d648db583c119b93383ce8ea1","_execution_state":"idle","collapsed":false,"_cell_guid":"816a486d-b204-44f0-9235-fa0cadbdb0f3","trusted":false},"source":"prop_df = pd.read_csv(\"../input/properties_2016.csv\")\nprop_df.shape","outputs":[],"execution_count":null,"cell_type":"code"},{"metadata":{"_uuid":"eff40e4311a0b8b4d6b098209f185f36a60cd362","_execution_state":"idle","collapsed":false,"_cell_guid":"98d050c3-3331-4f97-92f8-1843f9c97f28"},"source":"Not all the data in the properties is linked to an errorlog (90275 vs 2985217)","outputs":[],"execution_count":null,"cell_type":"markdown"},{"metadata":{"_uuid":"4e8680bdb71acf2ab550c053eb849f76fc7d60b6","_execution_state":"idle","collapsed":false,"_cell_guid":"8612185d-ea5c-4fce-9d1e-f5c350f04df8","trusted":false},"source":"if train_df.shape[1] == 3: \n    train_df = pd.merge(train_df, prop_df, on='parcelid', how='left' )\ntrain_df.shape\n","outputs":[],"execution_count":null,"cell_type":"code"},{"metadata":{"_uuid":"5d536390178092f8925599a3386ab1a929d1a3ff","_execution_state":"idle","collapsed":false,"_cell_guid":"e9eb30e0-4c96-4fb5-9282-d07efef26b93"},"source":"Lets check for the Nans in th train_df dataset:\n10 variables have over 99% of Nans","outputs":[],"execution_count":null,"cell_type":"markdown"},{"metadata":{"_uuid":"654ad9ae74aed078f057c62318e9c72a2387c8d0","_execution_state":"idle","collapsed":false,"_cell_guid":"cdc6b9b4-55f0-4931-aba8-613276b086b3","trusted":false},"source":"def NanPercent(daf):\n    var, c_nan, p_nan = [], [], [];\n    for i in range (0,len(list(daf))):\n            count_nan = daf.shape[0] - daf[list(daf)[i]].count()\n            percent_nan = (count_nan / daf.shape[0]) * 100\n            var.append(list(daf)[i]),c_nan.append(count_nan), p_nan.append(percent_nan)\n    \n    Nanpercent_df = pd.DataFrame(\n        {'Variable': var,\n         'Nr of Nans': c_nan,\n         '% of Nans': p_nan\n        })\n    return Nanpercent_df.sort_values(['% of Nans'])\nNanPercent(train_df)","outputs":[],"execution_count":null,"cell_type":"code"},{"metadata":{"_uuid":"43a630392e6c674ea14038c8649b079c72bf1a6a","_execution_state":"idle","collapsed":false,"_cell_guid":"d2254c4a-c95c-41c0-a81c-8666b0f538d4","trusted":false},"source":"#Data PreProcessing\n#propertyzoningdesc => string\ntrain_df['propertyzoningdesc'] = train_df['propertyzoningdesc'].astype(str)\n#hashottuborspa => TRUE ==> 1\ntrain_df.hashottuborspa.replace('True',1, inplace=True)\ntrain_df['hashottuborspa'] = train_df['hashottuborspa'].astype('float64')\n#propertycountylandusecode ==> string\ntrain_df['propertycountylandusecode'] = train_df['propertycountylandusecode'].astype(str)\n#fireplaceflag ==> TRUE ==> 1\ntrain_df.fireplaceflag.replace('True',1, inplace=True)\ntrain_df['fireplaceflag'] = train_df['fireplaceflag'].astype('float64')\n#taxdelinquencyflag ==> y\ntrain_df.taxdelinquencyflag.replace('Y',1, inplace=True)\ntrain_df['taxdelinquencyflag'] = train_df['taxdelinquencyflag'].astype('float64')\n\ntrain_df.dtypes","outputs":[],"execution_count":null,"cell_type":"code"},{"metadata":{"collapsed":false,"_execution_state":"idle","_uuid":"9f1c12589e94958efdb11a12f0673a2f57e04ffa","_cell_guid":"c3329c89-ec15-40b1-909b-0b1cdd4fe66a","trusted":false},"source":"sns.set(context=\"paper\", font=\"monospace\")\ncorrmat = train_df.corr()\nf, ax = plt.subplots(figsize=(12,9))\nsns.heatmap(corrmat,vmax=1, square=True)\nf.tight_layout()","outputs":[],"execution_count":null,"cell_type":"code"}],"nbformat":4}