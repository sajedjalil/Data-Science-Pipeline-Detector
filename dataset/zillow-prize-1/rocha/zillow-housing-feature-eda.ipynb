{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"c29c6b2a-00a8-7f8b-3dcd-26d457bbcab8"},"source":"## Zillow Housing--Feature EDA\n\nThere's already some excellent kernel in python, you can have a reference.    \n\n[Missing Values & Multicollinearity--vivek][1]  \n  \n[Simple Exploration Notebook - SRK][2]\n\n**my object**  \n To have easy and quick roadmap to what i have done to playing the data.\n\n  [1]: https://www.kaggle.com/viveksrinivasan/zillow-eda-on-missing-values-multicollinearity\n  [2]: https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-zillow-prize"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8c8984a7-1e7f-3d39-31e1-3c2f288f04c0"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"25792a8f-8ba3-8231-3f5c-579bcde7d315"},"outputs":[],"source":"%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport missingno as msno\ncolor = sns.color_palette()\nfrom matplotlib import pyplot as plt\npd.set_option(\"display.max_columns\",100)\nplt.style.use(\"ggplot\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"64713f56-b229-89e5-438f-91f3e97026d9"},"source":"# Reading In Dataset"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bea62c44-967e-2170-7474-4ac834c7309e"},"outputs":[],"source":"## read in the property data and merge with trainId\ntrain = pd.read_csv('../input/train_2016.csv', parse_dates=[\"transactiondate\"])\nproperties = pd.read_csv('../input/properties_2016.csv')\nmerged = pd.merge(train,properties,on=\"parcelid\",how=\"left\")\ndel properties\nmerged.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"fb52c08c-405d-9b98-efaa-6422162efcf8"},"source":"# Shape and size"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cf388c39-3677-a039-1b58-e203e8435e97"},"outputs":[],"source":"## find no error predict\nmerged_no_err = merged[merged.logerror ==0]\nmerged_err = merged[merged.logerror !=0]\n\n## calculate rows\ntotal_row = merged.shape[0]\nno_err_row = merged_no_err.shape[0]\nerr_row = merged_err.shape[0]\nprint(\"total row is: {:d}\".format(total_row))\nprint(\"no error row is: {:d}\".format(no_err_row))\nprint(\"error row is: {:d}\".format(err_row))"},{"cell_type":"markdown","metadata":{"_cell_guid":"b856ccb7-0518-2cb7-d5fc-d61bc65b8dd6"},"source":"# missing data analysis  \n\n---  \nFrom the beginning of EDA , we should know what's happening in our missing data? Is there some logic problem? Or some doable cleaning and wrangling. We should not abandon the missing feature or samples immediately.  \nFor example, the missing correlation map, we can using a dict mapping to fill the na when the cor <1. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"52ecbf63-5658-cea8-d681-db08d5d52d47"},"outputs":[],"source":"## select the column with missing value\nmissingValueColumns = merged.columns[merged.isnull().any()].tolist()\n\n## plot missing value\n(merged[missingValueColumns].isnull().sum()/total_row).sort_values().plot.barh(figsize=(10,16))\nmsno.heatmap(merged[missingValueColumns],figsize=(20,20))"},{"cell_type":"markdown","metadata":{"_cell_guid":"6c01bce3-d947-25dc-c8b9-dbf0328bfdf2"},"source":"# Object anaylsis"},{"cell_type":"markdown","metadata":{"_cell_guid":"d0ee93fd-9b9f-08d5-0384-f8790a3ce84c"},"source":"Do some modification of some outlier, we can have a look at the beautiful distribution of our logerror."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"75bc3cb7-8ce9-39c6-8675-3489a42f75a6"},"outputs":[],"source":"ulimit = np.percentile(merged.logerror.values, 99)\nllimit = np.percentile(merged.logerror.values, 1)\nmerged['logerror'].ix[merged['logerror']>ulimit] = ulimit\nmerged['logerror'].ix[merged['logerror']<llimit] = llimit\n\nplt.figure(figsize=(12,8))\nsns.distplot(merged.logerror.values, bins=50, kde=False)\nplt.xlabel('logerror', fontsize=12)\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"bd98e30f-6520-fe30-a247-d9eee5da42ef"},"source":"From the fig, we see about 30k samples contribute 80% error, so may be we can focus on samples have bad prediction.\nAnd our threshold is [-inf, -0.05] U [0.05, inf].  \nMaybe in the future we can analysis the model from postive error and negative error."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a86055d8-e60f-f632-6b7c-07d95242fdcd"},"outputs":[],"source":"## calculate cdf \n(abs(merged_err.logerror).sort_values().cumsum()/abs(merged_err.logerror).sum())\\\n.sort_values(ascending=False).reset_index(drop=True).plot.line(title=\"cdf error of feature\")\n\n## choose the 80% error of samplews\nper8_merged = merged_err[\\\n                         ((abs(merged_err.logerror).sort_values().cumsum()\\\n                           /abs(merged_err.logerror).sum())\\\n                          >0.2).sort_index()]\n\n## split the data\npos_err = per8_merged[per8_merged.logerror > 0]\nneg_err = per8_merged[per8_merged.logerror < 0]\n\nprint(\"The threshold is [-inf,-0.05] | [0.05,inf]\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ba4d280c-b8ab-ebdb-6359-9c2165b85929"},"outputs":[],"source":"var"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"99f1496a-5e49-766e-18d6-98ed23eddaf4"},"outputs":[],"source":"col_name = merged.columns.tolist()\ncol_name = col_name[:5]\nfor var in col_name:\n    merged[var].value_counts().sort_index().plot.bar()"},{"cell_type":"markdown","metadata":{"_cell_guid":"a39add4d-0075-91c0-1265-779643df60f1"},"source":"### That's just the begining.  Stay tunes. "}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}