{"cells":[{"metadata":{"_uuid":"50993e218df81ac4c4fa29e99caa190ae9c65a6c","_cell_guid":"b0b9c7eb-f6c7-4fb6-8a0a-3508a0a4f092"},"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n%matplotlib inline\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","cell_type":"code","outputs":[],"execution_count":1},{"metadata":{"_kg_hide-output":true,"_kg_hide-input":false},"source":"df_train = pd.read_csv('../input/train_2016_v2.csv', parse_dates=['transactiondate'])\n\ndf_prop = pd.read_csv('../input/properties_2016.csv')\n\ndf_sample = pd.read_csv('../input/sample_submission.csv')\n\ndf_prop17 = pd.read_csv('../input/properties_2017.csv')\n\ndf_train17 = pd.read_csv('../input/train_2017.csv', parse_dates=['transactiondate'])\n","cell_type":"code","outputs":[],"execution_count":2},{"metadata":{},"source":"df_train.shape","cell_type":"code","outputs":[],"execution_count":3},{"metadata":{},"source":"df_train17.shape","cell_type":"code","outputs":[],"execution_count":4},{"metadata":{},"cell_type":"markdown","source":"There are less items in df_train17 than 16."},{"metadata":{},"cell_type":"markdown","source":"Let's find out how many items exist in both datasets."},{"metadata":{},"source":"pd.merge(df_train, df_train17, on='parcelid')","cell_type":"code","outputs":[],"execution_count":5},{"metadata":{"collapsed":true},"source":"missing_df17 = df_prop17.isnull().sum(axis=0).reset_index()\nmissing_df17.columns = ['column_name', 'missing_count']\nmissing_df17 = missing_df17.sort_values(by='missing_count')\n# missing_df17['missing_count'] /= df_prop17.shape[0]\n\nmissing_df = df_prop.isnull().sum(axis=0).reset_index()\nmissing_df.columns = ['column_name', 'missing_count']\nmissing_df = missing_df.sort_values(by='missing_count')\n# missing_df['missing_count'] /= df_prop.shape[0]\n# get missing value information","cell_type":"code","outputs":[],"execution_count":6},{"metadata":{"_kg_hide-output":false},"source":"fig = plt.figure(figsize=(10, 8))\nplt.plot(range(missing_df.shape[0]), missing_df['missing_count'])\nplt.plot(range(missing_df17.shape[0]), missing_df17['missing_count'])","cell_type":"code","outputs":[],"execution_count":7},{"metadata":{},"source":"pd.concat([missing_df['column_name'], missing_df17['column_name']], axis=1)","cell_type":"code","outputs":[],"execution_count":8},{"metadata":{},"cell_type":"markdown","source":"We can see that there're not much change between two properties dataset, and tax-related properties have a lot missing values."},{"metadata":{"collapsed":true},"source":"tax_columns = ['structuretaxvaluedollarcnt',\n       'taxvaluedollarcnt', 'landtaxvaluedollarcnt']\n       # 'taxamount', 'taxdelinquencyflag', 'taxdelinquencyyear']","cell_type":"code","outputs":[],"execution_count":9},{"metadata":{},"source":"pd.DataFrame(df_prop[tax_columns].values / df_prop17[tax_columns].values).dropna(0, 'any')","cell_type":"code","outputs":[],"execution_count":10},{"metadata":{},"source":"","cell_type":"code","outputs":[],"execution_count":null},{"metadata":{"collapsed":true},"source":"","cell_type":"code","outputs":[],"execution_count":null}],"metadata":{"language_info":{"version":"3.6.1","pygments_lexer":"ipython3","mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"},"file_extension":".py","nbconvert_exporter":"python","name":"python"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat_minor":1,"nbformat":4}