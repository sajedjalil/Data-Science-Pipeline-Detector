{"cells":[{"metadata":{"_cell_guid":"d5337f7f-275a-46eb-980e-b0c026021409","_uuid":"db21b0f41fc6d0e332c72bd94ef3898bbaf4272f","_execution_state":"idle"},"source":"# Zillow House EDA：The Fast &  Curious Journey\n\n`Majin Buu - UPDATED Year Build Error, 9 Sept 2017`\n### UPDATE: ` Multiplicative Model`\n---\n\n- **1 First Step**\n    - 1.1 Load libraries and helper functions\n    - 1.2 Load data\n    - 1.3 Check the Memory Usage\n    - 1.4 DataType Converting\n    - 1.5 DateTime Parsing\n- **2 Univariable Analysis**\n    - 2.1 Basic Statistic using Pandas and Numpy\n    - 2.2 The Distribution of our target variables (**logerror**)\n\n\n- **3 Multivariate Analysis**\n    - 3.1 Target Variable Distribution Join Fips by Bokeh\n    - 3.2 Geographic Location by Folium and Cluster by KMeans\n    - 3.3 Where are the Perfect Estimation area ?\n- **4 Time Series Approach**\n    - 4.1 Aggragation & Visualization\n        - Time Series Components\n        - Combining Time Series Components\n    - 4.2 Moving Average Smoothing / Random Walk and Stationarity\n    - 4.3 Prophet Forecasting\n\n\n\n- **Reference**\n        \nIn this Notebook, you will discover time series forecasting. After reading this Notebook, you will know:\n1. Basic Time Series analysis, and time series forecasting. \n2. The Time Series components to consider in time series data.\n3. Examples of Time Series to make your understanding concrete.\n4. Time Series Libararies\n\nLet’s get started.\n#### NOTE - Please UPVOTING if you like, **all your support is my motivation to update the notebook**.\n\n","cell_type":"markdown"},{"metadata":{"_cell_guid":"8b6bb590-fd94-4f5b-ab10-74955af824eb","_uuid":"f95c69a26ddca052dc7ab8aee0b97f7b9dd5a21c"},"source":"### 1.1 Load libraries and helper functions","cell_type":"markdown"},{"metadata":{"_cell_guid":"bb3e5c02-3fb4-4209-8e2d-43bb25c75c2c","_uuid":"8edd39e48fcade778eb69f78b69952dbf4f2be4b","collapsed":true},"source":"import pandas as pd\nimport numpy as np\nfrom scipy import stats\n\n# Forceasting with decompasable model\nfrom pylab import rcParams\nimport statsmodels.api as sm\nfrom statsmodels.tsa.stattools import adfuller\n\n# Datetime operations\nimport time\n\n# Visualisation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport folium\nfrom fbprophet import Prophet\nplt.style.use('fivethirtyeight')\nimport pickle\nimport gc\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"e0b7a12a-e6af-41ab-96c0-53ee0811b59f","_uuid":"37f955f186e680226d2776eb05ecad88c9932b11"},"source":"### 1.2 Load Data","cell_type":"markdown"},{"metadata":{"_cell_guid":"e8bcba61-e5b7-4e4f-abd8-29aff9c2ec11","_uuid":"d1a5e06d74e0fd720e2849065c0c3eb530b265c7","collapsed":true},"source":"start = time.time()\nprop = pd.read_csv('../input/properties_2016.csv')\ntrain = pd.read_csv(\"../input/train_2016_v2.csv\", parse_dates=[\"transactiondate\"])\ndf_train = train.merge(prop, how='left', on='parcelid')\nend = time.time()\nprint(\"time taken by thie script by now is {} sec.\".format(end-start))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"757bcb5d-f656-4700-bc34-9a31edae9f76","_uuid":"c10c3e21ee9bce417d126a43b39107bbfa753c83"},"source":"### 1.3 Check the Memory Usage \n- Very useful skill if we only have enough hardware resource","cell_type":"markdown"},{"metadata":{"scrolled":true,"_cell_guid":"bed1c5e3-a92f-4b57-9712-1ebbe70f44d0","_uuid":"592d3563eb833fc3dfbec6f8b7dbb01895bcbb7e","collapsed":true},"source":"# To avoid Notebook flood, by setting verbose False\ntrain.info(verbose=False)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"fea11cb6-6599-4969-a2a4-ff2cf5abd47d","_uuid":"bddbc2dad579e65c262898bc7555d8e13f6cea63","collapsed":true},"source":"prop.info(verbose=False)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"5c2f32ba-5eea-4796-bf98-1cb519d04bb2","_uuid":"ce39417dd41eaf0e9764b31c77a63329eb989bcf","collapsed":true},"source":"df_train.info(verbose=False)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"01b4d7b1-bcd9-4029-a49f-d060dce9de95","_uuid":"7dfaa4dcb595981114f8d01bfad3cf15eac6389c","collapsed":true},"source":"df_train.get_dtype_counts()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"d1d39c3d-867d-4b33-b070-663cf4761877","_uuid":"08e0fcca4efc38e7f98acb7e6df62197260fdc64","collapsed":true},"source":"del prop, train\ngc.collect()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"4f264c7e-aadd-4220-b504-a23353a4a60e","_uuid":"af565f010a3b975bda497cb5540407fea7355fc5"},"source":"### 1.4 DataType Converting\n- Reference: [Anokas](https://www.kaggle.com/anokas) script","cell_type":"markdown"},{"metadata":{"_cell_guid":"42a282de-a3d2-483d-a209-ac8592d07683","_uuid":"f8bc78ce1416d566dd32e19a76a21508afc2e7d1","collapsed":true},"source":"for c, dtype in zip(df_train.columns, df_train.dtypes):\n    if dtype == np.float64:\n        df_train[c] = df_train[c].astype(np.float32) \n    elif dtype == np.int64:\n        df_train[c] = df_train[c].astype(np.int32) \ngc.collect()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"247a24c7-2af8-4438-bfcc-52b4c5cb715b","_uuid":"7948a545280b160679efa00c90c4e3c33824c592"},"source":"### 1.5 DateTime Parsing","cell_type":"markdown"},{"metadata":{"_cell_guid":"0fe6dfe0-cc4b-4a52-9486-1dea469774f6","_uuid":"c516573c0c1f3444aadde66cd8ef9487d8f44fa7","collapsed":true},"source":"df_train['transaction_month'] = df_train['transactiondate'].dt.month\ndf_train['transaction_year'] = df_train['transactiondate'].dt.year","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"605a3191-e06c-47e4-ad14-24e9ad3d2924","_uuid":"462ef8df877472f756d522b0f12eedcc4f8e5ee0"},"source":"# 2 Univariable Analysis\n---\n### We'll just focus on the target variable (**Log Error**)\n- Fundamental Statistic\n- Visaulize the dstribution of logerror\n\n`logerror = log(Zestimate) - log(Saleprice)`","cell_type":"markdown"},{"metadata":{"_cell_guid":"5f22d90b-a6a7-4fe5-95a8-bbf9ff91a9ed","_uuid":"ffb26b848d7c37eac20a7bd722b465c3e95c5bce"},"source":"## 2.1 Basic Statistic using Pandas and Numpy\n-  **Pandas DataFrame/Numpy API**\n\n`df.mean(), np.mean(df)`","cell_type":"markdown"},{"metadata":{"_cell_guid":"3ba985a3-9916-4a7f-bd85-cfabf6bba70d","_uuid":"fc3d095fb93d815b19b34b3428516d119ebecf57","collapsed":true},"source":"me = np.mean(df_train['logerror']); med = np.median(df_train['logerror']); st = df_train['logerror'].std(); \nprint(df_train['logerror'].describe())","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"5d1d2a18-0f13-47a3-84fc-08de64dc6d44","_uuid":"3daf7f7a0c3f6be7ca5b34199f725523eb0bbfcd"},"source":"- The mean, median, and mode of a normal distribution are equal.","cell_type":"markdown"},{"metadata":{"_cell_guid":"36a43f64-e0ee-4289-9682-7c792fb7a01f","_uuid":"ffa181ece39c54429781c078f5f7390bb5386b02","collapsed":true},"source":"x = df_train['logerror']\nf, (ax_box, ax_hist) = plt.subplots(2, sharex=True ,\n                                    gridspec_kw={\"height_ratios\": (.15, .85)})\nsns.boxplot(x, ax=ax_box)\nsns.distplot(x, ax=ax_hist, bins=400, kde=False)\nax_box.set(yticks=[])\nsns.despine(ax=ax_hist)\nsns.despine(ax=ax_box, left=True)\nplt.xlim([me-2*st, me+2*st])\nplt.show()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"50ad9c53-2fc0-4af9-832e-80430df719a7","_uuid":"9193961eaaa6d2687df5c938afe8b2b8008765f8"},"source":"#### We get that the distribution spikes which very close to zero\n- Zillow has Good Data Scientists","cell_type":"markdown"},{"metadata":{"_cell_guid":"4fef2fde-db9f-45ad-bc1e-c66144269c60","_uuid":"23f284b0c6c228157f56799773d9e483e977909b"},"source":"# 3. Multivariate Analysis. \n---\n","cell_type":"markdown"},{"metadata":{"_cell_guid":"298f600e-08ab-4a2b-9d05-9d577146991a","_uuid":"34aca2083211f1c0bc0736e3a85521110044a782"},"source":"## 3.1 Target Variable Distribution Join Fips by Bokeh\n\n- Reference - \n[Philipp Spachtholz](https://www.kaggle.com/philippsp/exploratory-analysis-zillow) FanNotebook, we introduce **Absolute logerror** and **FIPS** codes map to city.\n","cell_type":"markdown"},{"metadata":{"_cell_guid":"3e6db15b-7304-456e-a844-c5be85f109cc","_uuid":"62fa2f352da450fccab27bc14d6ca46aa2ec16b5","collapsed":true},"source":"df_train.loc[:,'abs_logerror'] = df_train['logerror'].abs()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"b14b3d11-adc0-478f-abfc-38b8dd01ba35","_uuid":"317f253a75847275fc83a7cc19a3576aa87addfb"},"source":"- Transaction Date Vs ** Mean Error** in each County","cell_type":"markdown"},{"metadata":{"_cell_guid":"ed4c05ed-8ac6-4368-9866-d965a155ce6b","_uuid":"2612022375214f4229d0aa40f1c30e3c25904cbb","collapsed":true},"source":"from bokeh.palettes import Spectral4\nfrom bokeh.plotting import figure, output_notebook, show\n\nfips1 = pd.DataFrame(df_train.loc[df_train['fips']==6037].groupby('transactiondate')['abs_logerror'].mean())\nfips1.reset_index(inplace = True)\nfips2 = pd.DataFrame(df_train.loc[df_train['fips']==6059].groupby('transactiondate')['abs_logerror'].mean())\nfips2.reset_index(inplace = True)\nfips3 = pd.DataFrame(df_train.loc[df_train['fips']==6111].groupby('transactiondate')['abs_logerror'].mean())\nfips3.reset_index(inplace = True)\n\n\noutput_notebook()\nout = figure(plot_width=800, plot_height=250, x_axis_type=\"datetime\")\n\nfor data, name, color in zip([fips1, fips2, fips3], [\"Los Angeles\", \"Orange County\", \"Ventura County\"], Spectral4):\n\n    out.line(data['transactiondate'], data['abs_logerror'], line_width=2, color=color, alpha=0.8, legend=name)\n\nout.legend.location = \"top_left\"\nout.legend.click_policy=\"hide\"\nshow(out)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"d15a10d3-d178-4aa6-8745-9df5a369277f","_uuid":"677f53c399bb5261533d1b04d5b70cce9d6e1a95"},"source":"- Year Build Vs **Mean Error** in each County","cell_type":"markdown"},{"metadata":{"_cell_guid":"bcb1bd88-5ffe-48cc-9539-d1ae544a607b","_uuid":"0dccb6f36d85ddfbae844a2786e759d928938952","collapsed":true},"source":"#yearbuilt\nfips1 = pd.DataFrame(df_train.loc[df_train['fips']==6037].groupby('yearbuilt')['abs_logerror'].mean())\nfips1.reset_index(inplace = True)\nfips2 = pd.DataFrame(df_train.loc[df_train['fips']==6059].groupby('yearbuilt')['abs_logerror'].mean())\nfips2.reset_index(inplace = True)\nfips3 = pd.DataFrame(df_train.loc[df_train['fips']==6111].groupby('yearbuilt')['abs_logerror'].mean())\nfips3.reset_index(inplace = True)\n\noutput_notebook()\nout = figure(plot_width=800, plot_height=250)\n\nfor data, name, color in zip([fips1, fips2, fips3], [\"Los Angeles\", \"Orange County\", \"Ventura County\"], Spectral4):\n\n    out.line(data['yearbuilt'], data['abs_logerror'], line_width=2, color=color, alpha=0.8, legend=name)\n\nout.legend.location = \"top_right\"\nout.legend.click_policy=\"hide\"\nshow(out)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"2e2b9293-ff4d-4e5e-a280-49cc65cfa87c","_uuid":"38e986442a6fb0af05690146c79a8c267029e9d3"},"source":"### An important note:  \n- Ventura Country has **Spikes** means Zillow Estimation Inaccurate","cell_type":"markdown"},{"metadata":{"_cell_guid":"1d2b23e9-739f-4386-8b89-d1be7fcd4bf7","_uuid":"238c522a0625f1f7a35290fe87dc533f2cffdf9e","collapsed":true},"source":"import plotly # visualization\nfrom plotly.graph_objs import Scatter, Figure, Layout # visualization\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot,iplot # visualization\nimport plotly.figure_factory as ff # visualization\nimport plotly.graph_objs as go # visualization\ninit_notebook_mode(connected=True) # visualization\n\nworst_prediction = df_train['abs_logerror'].quantile(q=.95)\n\n\ntrace0 = go.Scatter(\n    y = df_train[(df_train['fips']==6037)&(df_train['abs_logerror']>worst_prediction)].\\\n                groupby('yearbuilt')['abs_logerror'].mean(),\n    x = df_train[(df_train['fips']==6037)&(df_train['abs_logerror']>worst_prediction)].\\\n                groupby('yearbuilt')['abs_logerror'].mean().index,\n    mode = 'lines+markers',\n    name = \"Los Angeles\", \n)\ntrace1 = go.Scatter(\n    y = df_train[(df_train['fips']==6059)&(df_train['abs_logerror']>worst_prediction)].\\\n                groupby('yearbuilt')['abs_logerror'].mean(),\n    x = df_train[(df_train['fips']==6059)&(df_train['abs_logerror']>worst_prediction)].\\\n                groupby('yearbuilt')['abs_logerror'].mean().index,\n    mode = 'lines+markers',\n    name = \"Orange County\"\n)\ntrace2 = go.Scatter(\n    y = df_train[(df_train['fips']==6111)&(df_train['abs_logerror']>worst_prediction)].\\\n                groupby('yearbuilt')['abs_logerror'].mean(),\n    x = df_train[(df_train['fips']==6111)&(df_train['abs_logerror']>worst_prediction)].\\\n                groupby('yearbuilt')['abs_logerror'].mean().index,\n    mode = 'lines+markers',\n    name = \"Ventura County\"\n)\ndata = [trace0, trace1, trace2]\n\nplotly.offline.iplot(data, filename='line-mode')","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"2794f921-b3d0-465b-bc21-326e0a63a64e","_uuid":"09d69ded3d4e99a36b6efe07677774f852db5bcc"},"source":"\n\n## 3.2 Geographic Location by Folium and Cluster by KMeans\n\n### Introduction:\n\nFolium builds on the data wrangling strengths of the Python ecosystem and the mapping strengths of the Leaflet.js library. \n\nManipulate your data in Python, then visualize it in on a Leaflet map via Folium.","cell_type":"markdown"},{"metadata":{"_cell_guid":"a51855e7-67de-4669-9861-570ed6ffc5e8","_uuid":"2af03c3f8b7499c2447fb52e33c0e30e384ae58b","collapsed":true},"source":"geo_df = df_train[['latitude', 'longitude','logerror']]","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"b67dbbd7-1345-4420-90e5-b29bf38d1bd2","_uuid":"3d0574bab1699d7070da6c0c178d516b8e295fa2","collapsed":true},"source":"geo_df['longitude']/=1e6\ngeo_df['latitude']/=1e6","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"7d9b83c5-2308-4072-94c9-8ff88ca1c399","_uuid":"595d7b13bf4854f7fc0b386c5999dd165c1f1d9b","collapsed":true},"source":"geo_df.dropna(subset=['latitude','longitude'], axis=0 ,inplace=True)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"918d195e-d339-4938-9f04-6a7e0ea83370","_uuid":"d3b6b79a2ea71e4377e0db566646156b2a1e9feb","collapsed":true},"source":"from sklearn.cluster import MiniBatchKMeans\nkmeans = MiniBatchKMeans(n_clusters=120, batch_size=1000).fit(geo_df[['latitude','longitude']])\ngeo_df.loc[:, 'label'] = kmeans.labels_","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"f0461ceb-a42e-4632-ba1e-52e78a0428c7","_uuid":"bcf4e9fd314f7bc585ab500dc25736bbbe567dc7","collapsed":true},"source":"map_2 = folium.Map(location=[34.088537, -118.249923],\n                   zoom_start=9)\nfor label in kmeans.cluster_centers_:\n    folium.Marker(location=[label][0]).add_to(map_2)\n\nmap_2","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"0200607c-85ac-45cd-910b-9805cdc9efe1","_uuid":"61a6fa5d285f25fc4e52c7338a9334e7f5befd36","collapsed":true},"source":"map_1 = folium.Map(location=[34.088537, -118.249923], zoom_start=9,\n                   tiles='Stamen Terrain')\nfor label in kmeans.cluster_centers_:\n    folium.Marker(location=[label][0]).add_to(map_1)\nmap_1\n","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"bc65e3ca-0434-4ea7-a338-2efdd399b165","_uuid":"2cf8b90f079b2d34dadfd643637652775dfe3790","collapsed":true},"source":"del map_2 ,map_1\ngc.collect()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"a1d0fa82-2809-4a8a-8cff-9b4ec09fa3a6","_uuid":"a46402045becddb0463aeb51b510852622a4ca8d"},"source":"### Finding:\n-  Most houses locat in **Flat Ground**\n-  Few locat in **Santa Catalina Island**","cell_type":"markdown"},{"metadata":{"_cell_guid":"ef46c905-1bd7-4f74-ba1d-4a91db33077c","_uuid":"30569742d65fb2599dc1d58728df151058365489"},"source":"## 3.3 Where are the Perfect Estimation area ?\n\n- We are going to have a look \n- Ignoring Time Series, i.e Without taking month into consideration ","cell_type":"markdown"},{"metadata":{"_cell_guid":"7b8dce41-681f-4400-b105-89f5bb2c7a7a","_uuid":"eaf7a9fa8354b714e70cbd057163bd3b7cd66b3c","collapsed":true},"source":"gc.collect()\nperfect_geo_df = geo_df[geo_df['logerror']==0]\nperfect_geo_df.shape","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"10935ad8-676e-4322-90e4-da8428463065","_uuid":"15fc295c5d4616851cd779bb11607ed682eb4d41","collapsed":true},"source":"map_perfect = folium.Map(location=[34.088537, -118.249923], zoom_start=9,\n                   tiles='Stamen Toner')\nfor lat, lon in zip(perfect_geo_df.latitude, perfect_geo_df.longitude):\n    folium.Marker(location=[lat,lon]).add_to(map_perfect)\nmap_perfect\n","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"e7342572-792b-4091-9d84-0ae19b9b1227","_uuid":"2791c3b58d152332d3b257eba0b9f5a5527899a4","collapsed":true},"source":"del perfect_geo_df, map_perfect, geo_df\ngc.collect()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"0dbb6aa0-ba0d-4cc7-ab94-cbb32d16c30b","_uuid":"50614405888ca49fa86288f7930be5f402dc37c0"},"source":"### An important note:\n- There is no pattern between Geo and perfect Estimation\n- Never Happen in the Santa Catalina Island (Millionair hard to predict :-) )","cell_type":"markdown"},{"metadata":{"_cell_guid":"e5abe7d4-34b6-4cfe-82d3-b1dca8dcca85","_uuid":"9febbe30e13971755ca2992fedd10bb929d08899"},"source":"# 4. Time Series Approach\n---\n","cell_type":"markdown"},{"metadata":{"_cell_guid":"fb3cddb2-6a66-465b-a6fa-528a95ddae08","_uuid":"90a7822cd0ff0fb58c9e78182709d14685387097"},"source":"## 4.1 Aggragation & Visualisation\n","cell_type":"markdown"},{"metadata":{"_cell_guid":"d2d641d7-f65a-45ce-a3b9-585124b2c93b","_uuid":"64d06c61b97ba1781d40132c7be539d893401537"},"source":"### OverAll Average Absolute Log Error","cell_type":"markdown"},{"metadata":{"scrolled":true,"_cell_guid":"e2e269bf-744f-4a88-9803-c935350d5819","_uuid":"4a77115d2a06f7e46440c681dfab6c7f5fcef4a2","collapsed":true},"source":"plt.figure(figsize=(20, 6))\nmean_group = df_train[['transactiondate','abs_logerror']].groupby(['transactiondate'])['abs_logerror'].mean()\nplt.plot(mean_group)\nplt.xlabel('Date', fontsize=15)\nplt.ylabel('Absolute Log error', fontsize=15)\nplt.title('Time Series - Average')\nplt.show()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"266a90d2-b637-4d0a-a735-a2f0abd87ff8","_uuid":"7168f36fce68b7c8c9d473411348b46f33e803c1"},"source":"### Los Angeles Average Absolute Log error","cell_type":"markdown"},{"metadata":{"_cell_guid":"34259f40-5777-4f23-9981-7f55a9fa5eda","_uuid":"bcd88500e963fc2f4bb8d8f540385785f6b8ed9e","collapsed":true},"source":"plt.figure(figsize=(20, 6)) \nfips1 = pd.DataFrame(df_train.loc[df_train['fips']==6037].groupby('transactiondate')['abs_logerror'].mean())\nplt.plot(fips1,c='k')\nplt.xlabel('Date', fontsize=15)\nplt.ylabel('Absolute Log error', fontsize=15)\nplt.title('Time Series Los Angeles - Average')\nplt.show()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"3fe34c79-d8c0-430e-9a3d-e9abc113400b","_uuid":"647e3d06219eac9949fbb0729d749bc3e311b493"},"source":"### Orange County Average Absolute Log error","cell_type":"markdown"},{"metadata":{"_cell_guid":"7df285a0-428f-495c-bfe5-97db0f14b2ed","_uuid":"db14b90d63a55b6127b1fa1a2b10b8223ce29e8a","collapsed":true},"source":"plt.figure(figsize=(20, 6)) \nfips1 = pd.DataFrame(df_train.loc[df_train['fips']==6059].groupby('transactiondate')['abs_logerror'].mean())\nplt.plot(fips1, c = 'm')\nplt.xlabel('Date', fontsize=15)\nplt.ylabel('Absolute Log error', fontsize=15)\nplt.title('Time Series Orange County - Average')\nplt.show()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"ae4f50c0-81cf-43e4-9736-89f07a1d960c","_uuid":"9d63c9585c454a432928b1012a6685b4b8830a13"},"source":"### Ventura County  Average Absolute Log error","cell_type":"markdown"},{"metadata":{"_cell_guid":"e1a1d020-839c-48f2-9f8f-cd6ba5d22974","_uuid":"9e7adca71992a7296ae55555effbceb643b957dd","collapsed":true},"source":"plt.figure(figsize=(20, 6))\nfips1 = pd.DataFrame(df_train.loc[df_train['fips']==6111].groupby('transactiondate')['abs_logerror'].mean())\nplt.plot(fips1, c = 'y')\nplt.xlabel('Date', fontsize=15)\nplt.ylabel('Absolute Log error', fontsize=15)\nplt.title('Time Series Ventura County - Average')\nplt.show()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"a638162d-4168-4bcc-8468-d33db16eafb1","_uuid":"627d4fe10e9188d25b2f5d9ab134fae28736c4bd"},"source":"- Median of Absolute Logerror","cell_type":"markdown"},{"metadata":{"_cell_guid":"6ae77b1d-847b-466e-b9f2-c199b8191a84","_uuid":"fb0d9c5d3e3aa4d2c43a7b231228c7398f751334","collapsed":true},"source":"plt.figure(figsize=(20, 6))\nmedian_group = df_train[['transactiondate','abs_logerror']].groupby(['transactiondate'])['abs_logerror'].median()\nplt.plot(median_group, c='b')\nplt.xlabel('Date', fontsize=15)\nplt.ylabel('Absolute Log error', fontsize=15)\nplt.title('Time Series - Median')\nplt.show()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"02f64e81-845a-4861-b480-c3a04feb9590","_uuid":"9d57680573e84d6b282bd484ef535fb1b47e368c"},"source":"- Standard Deviation of Absolute Logerror","cell_type":"markdown"},{"metadata":{"_cell_guid":"07dd8f59-66ed-44f5-8934-9d5677665c0f","_uuid":"3182a72b98b49b3783a23c11436e486f904ddfbe","collapsed":true},"source":"plt.figure(figsize=(20, 6))\nstd_group = df_train[['transactiondate','abs_logerror']].groupby(['transactiondate'])['abs_logerror'].median()\nplt.plot(std_group, c='g')\nplt.xlabel('Date', fontsize=15)\nplt.ylabel('Absolute Log error', fontsize=15)\nplt.title('Time Series - STD')\nplt.show()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"15ccf374-369e-45f6-83d9-41dbb1b83669","_uuid":"d022578924eaf1f8dd4a2f32acc2a37c7f3c6d92","collapsed":true},"source":"del mean_group, median_group, std_group\ngc.collect()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"c94dbd40-6452-4089-a945-cd2588b17343","_uuid":"2e0ae0f4bf2ed51503f25fcb246670a306f300f1"},"source":"\nHere, I only use inliner \n    - Definition:  Absolute Logerror < Mean + Std","cell_type":"markdown"},{"metadata":{"_cell_guid":"cefcf834-c693-4393-b854-33ce1f1bcc13","_uuid":"9a3447b527d0d373659211ec3b0d92b1778873f9","collapsed":true},"source":"df_train = df_train[df_train['abs_logerror']<  me + st ]\nmean_group = df_train[['transactiondate','abs_logerror']].groupby(['transactiondate'])['abs_logerror'].mean()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"87573303-ab24-4ef6-890a-e339447225f6","_uuid":"cd4cd79864d1b9330a4450f28b386b391dd15415"},"source":"### Time Series Components\n  \n- A given time series is thought to consist of three systematic components including level, trend, seasonality, and one non-systematic component called noise. These components are defined as follows:\n\n    1. **Level**: The average value in the series.\n    2. **Trend**: The increasing or decreasing value in the series. \n    3. **Seasonality**: The repeating short-term cycle in the series. \n    4. **Noise**: The random variation in the series.\n\n","cell_type":"markdown"},{"metadata":{"_cell_guid":"75061381-99a4-40e8-9e9d-ddaf8dff02b6","_uuid":"ea08875da9eae0a21660437b03467cbffbd0856e"},"source":"### Combining Time Series Components\n- A series is thought to be an aggregate or combination of these four components. All series have a level and noise. The trend and seasonality components are optional. It is helpful to think of the components as combining either **additively** or **multiplicatively**.\n\n    - Additive Model\n        y(t) = Level + Trend + Seasonality + Noise \n        \n    - Multiplicative Model\n        y(t) = Level x Trend x Seasonality x Noise \n","cell_type":"markdown"},{"metadata":{"_cell_guid":"727e6061-890c-483d-b2d6-f3096860e6f3","_uuid":"31f8fd85ece28f8b9f7473c31ee7bccf8fc8553b"},"source":"- Additive Model","cell_type":"markdown"},{"metadata":{"_cell_guid":"6faed842-4f94-4842-8df0-1939b904ff16","_uuid":"6abd04c00596b3a41e24c8a964e200d1ab97f9dd","collapsed":true},"source":"times_series_means =  pd.DataFrame(mean_group).reset_index(drop=False)\ndf_date_index = times_series_means[['transactiondate','abs_logerror']].set_index('transactiondate')\ndecomposition = sm.tsa.seasonal_decompose(df_date_index, model='additive',freq = 31)\ntrend = decomposition.trend\nseasonal = decomposition.seasonal\nresidual = decomposition.resid\nrcParams['figure.figsize'] = 15, 8\n\nplt.subplot(411)\nplt.title('Obesered = Level + Trend + Seasonality + Noise ')\nplt.plot(df_date_index, label='Observed')\nplt.legend(loc='best')\nplt.subplot(412)\nplt.plot(trend, label='Trend')\nplt.legend(loc='best')\nplt.subplot(413)\nplt.plot(seasonal,label='Seasonality')\nplt.legend(loc='best')\nplt.subplot(414)\nplt.plot(residual, label='Residuals')\nplt.legend(loc='best')\nplt.tight_layout()\nplt.show()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"9b6aa4b9-bb07-4276-98a9-d79aea5ee6a5","_uuid":"1ef2f5fe7eef4b46df1766c1fdcf9c49292d17c9"},"source":"- Multiplicative","cell_type":"markdown"},{"metadata":{"_cell_guid":"b723c772-aa47-435e-b7a5-cf8d2326ccbb","_uuid":"d773e1278ca7cb15be764d0dc681979a1befd0c4","collapsed":true},"source":"times_series_means =  pd.DataFrame(mean_group).reset_index(drop=False)\ndf_date_index = times_series_means[['transactiondate','abs_logerror']].set_index('transactiondate')\ndecomposition = sm.tsa.seasonal_decompose(df_date_index, model='multiplicative',freq = 14)\ntrend = decomposition.trend\nseasonal = decomposition.seasonal\nresidual = decomposition.resid\nrcParams['figure.figsize'] = 15, 8\n\nplt.subplot(411)\nplt.title('Obesered = Level x Trend x Seasonality x Noise ')\nplt.plot(df_date_index, label='Observed')\nplt.legend(loc='best')\nplt.subplot(412)\nplt.plot(trend, label='Trend')\nplt.legend(loc='best')\nplt.subplot(413)\nplt.plot(seasonal,label='Seasonality')\nplt.legend(loc='best')\nplt.subplot(414)\nplt.plot(residual, label='Residuals')\nplt.legend(loc='best')\nplt.tight_layout()\nplt.show()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"4b16dd6f-0fe3-47a9-9753-3df64d9495d8","_uuid":"e2a0ff6cd24ea4e10b42bb8cef48609a806c0673"},"source":"## 4.2 Moving Average Smoothing / Random Walk and Stationarity\n\nMoving average smoothing is a naive and effective technique in time series forecasting. It can be used for data preparation, feature engineering, and even directly for making predictions.\n\nA stationary time series is one where the values are not a function of time. We can confirm this using a statistical significance test, specifically the Augmented Dickey-Fuller test.\n\n- The script is copied from kaggler \n    1. [Julien Heiduk](https://www.kaggle.com/zoupet) and  \n    2. https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/ \n    3. [Dr. Jason Brownlee]()","cell_type":"markdown"},{"metadata":{"_cell_guid":"dd45a4b9-4567-460b-89c7-d25cb2114be0","_uuid":"592590914450ac60d45b02b619c71c744efc49c0","collapsed":true},"source":"def test_stationarity(timeseries):\n    plt.figure(figsize=(15, 8))\n    #Determing rolling statistics\n    rolmean = pd.rolling_mean(timeseries, window=31) # Slide window depend on past 1 month\n    rolstd = pd.rolling_std(timeseries, window=31)\n\n    #Plot rolling statistics:\n    orig = plt.plot(timeseries, color='blue',label='Original')\n    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n    plt.legend(loc='best', fontsize=15)\n    plt.title('Rolling Mean & Standard Deviation', fontsize=15)\n    plt.xlabel('Date', fontsize=15)\n    plt.ylabel('Absolute Log Error', fontsize=15)\n    plt.show(block=False)\n    \n    #Perform Dickey-Fuller test:\n    print('Results of Dickey-Fuller Test:')\n    dftest = sm.tsa.adfuller(timeseries['abs_logerror'], autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print(dfoutput)\n    \ntest_stationarity(df_date_index)   ","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"520c5fd3-34e2-4e3e-8719-233f305a39c6","_uuid":"0df1b75b6ef93a4814874d7df6a4c7929dbe35fe"},"source":"The **null hypothesis** of the test is that the time series is **non-stationary** and we can see that the test statistic value was **-1.736474e+01** with a significance level of less than **1%** (i.e. a low probability that the result is a statistical fluke). \n\nRejecting the null hypothesis means that the process has no unit root, and in turn that the time series is ** stationary** or does not have time-dependent structure.\n\n# Non Time Dependent Structure\n- Under Constraint\n    - Exclude Outlier\n    - Only depend on past 3 months ","cell_type":"markdown"},{"metadata":{"_cell_guid":"14e1fb86-0e31-46f9-9fb8-972fffab4eb4","_uuid":"1f35e9d8e6142fea1ce2bec2b33e0d2986eaa9a8"},"source":"## 4.3 Prophet Forecasting\n### This is inspired by kaggler [Julien Heiduk](https://www.kaggle.com/zoupet)\n\n- This tool was created by Facebook. \nMore information on the library here: https://research.fb.com/prophet-forecasting-at-scale/\n","cell_type":"markdown"},{"metadata":{"_cell_guid":"a5464aeb-4305-44a2-992d-c46eceab662a","_uuid":"f847108438a7d7af93680ee67732ed1f168d50ff","collapsed":true},"source":"sns.set(font_scale=1) \ndf_prophet =  pd.DataFrame(mean_group).reset_index(drop=False)\ndf_prophet = df_prophet.iloc[-92:,:] # Forecast due to past 3 months\ndf_prophet.columns = ['ds','y']\n\nm = Prophet()\nm.fit(df_prophet)\nfuture = m.make_future_dataframe(periods=59,freq='D') # Forecast Jan 2017\nforecast = m.predict(future)\nplt.figure(figsize=(30, 6))\nfig = m.plot(forecast)\nplt.show()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"45585d5d-1223-4d7a-b326-468d55a95670","_uuid":"7c465130af1055cd981fd6a0450f5609546a77bf"},"source":"## Reference\n- [1] [Philipp Spachtholz](https://www.kaggle.com/philippsp/exploratory-analysis-zillow)\n- [2] [Julien Heiduk](https://www.kaggle.com/zoupet) \n- [3] [Aarshay Jain](https://www.analyticsvidhya.com/blog/author/aarshay/) A comprehensive beginner’s guide to create a Time Series Forecast\n- [4] [Dr. Jason Brownlee]()\n\n","cell_type":"markdown"},{"metadata":{"_cell_guid":"1cce868d-105e-4336-8d25-a7311fbf8053","_uuid":"bb01583838220d34a15d0edcf9a9b8b868d2c177"},"source":"## Stay tuned, this notebook will be updated on a regular basis\n","cell_type":"markdown"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","pygments_lexer":"ipython3","name":"python","version":"3.6.3"},"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"}}}