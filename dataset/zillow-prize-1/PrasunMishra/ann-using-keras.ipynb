{"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"name":"python","version":"3.6.1","pygments_lexer":"ipython3","file_extension":".py"}},"nbformat":4,"cells":[{"outputs":[],"cell_type":"code","metadata":{"_uuid":"0944700485eefcdad0e7e9159fd4e57dcd3c93db","trusted":true,"_cell_guid":"8684bfd0-dec8-41c5-a2e6-4918d3fbec2d","collapsed":true},"source":"# Added by Prasun Mishra 8/6 - still WIP\n#import missingno as msno\nfrom datetime import datetime\nimport numpy as np\nimport numpy as numpy\nimport pandas as pd\nimport pylab\nimport calendar\nfrom scipy import stats\nimport seaborn as sns\nfrom sklearn import model_selection, preprocessing\nfrom scipy.stats import kendalltau\nimport warnings\nimport matplotlib.pyplot as plt\nimport pandas\n## Keras comes here\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import LabelEncoder\n\n# Load train, Prop and sample\nprint('Loading train, prop and sample data')\ntrain = pd.read_csv(\"../input/train_2016_v2.csv\", parse_dates=[\"transactiondate\"])\nprop = pd.read_csv('../input/properties_2016.csv')\nsample = pd.read_csv('../input/sample_submission.csv')\n \nprint('Fitting Label Encoder on properties')\nfor c in prop.columns:\n    prop[c]=prop[c].fillna(-1)\n    if prop[c].dtype == 'object':\n        lbl = LabelEncoder()\n        lbl.fit(list(prop[c].values))\n        prop[c] = lbl.transform(list(prop[c].values))\n        \n#Create df_train and x_train y_train from that\nprint('Creating training set:')\ndf_train = train.merge(prop, how='left', on='parcelid')\n\n###########################################################\ndf_train[\"transactiondate\"] = pd.to_datetime(df_train[\"transactiondate\"])\ndf_train[\"transactiondate_year\"] = df_train[\"transactiondate\"].dt.year\ndf_train[\"transactiondate_month\"] = df_train[\"transactiondate\"].dt.month\ndf_train['transactiondate_quarter'] = df_train['transactiondate'].dt.quarter\ndf_train[\"transactiondate\"] = df_train[\"transactiondate\"].dt.day\n\n\n###########################################\n\nprint('Fill  NA/NaN values using suitable method' )\n#df_train.fillna(df_train.mean(),inplace = True)\ndf_train.fillna(-1.0)\n\n#df_train =df_train[ df_train.logerror > -0.4005 ]\n#df_train=df_train[ df_train.logerror < 0.412 ]\n\nprint('Create x_train and y_train from df_train' )\nx_train = df_train.drop(['parcelid', 'logerror', 'transactiondate', 'propertyzoningdesc', 'propertycountylandusecode','fireplacecnt', 'fireplaceflag'], axis=1)\ny_train = df_train[\"logerror\"]\n\n#print(\"Bind x_train to float32:\")\n#x_train = x_train.values.astype(np.float32, copy=False)\n\n\ny_mean = np.mean(y_train)\nprint(x_train.shape, y_train.shape)\ntrain_columns = x_train.columns\n\nfor c in x_train.dtypes[x_train.dtypes == object].index.values:\n    x_train[c] = (x_train[c] == True)\n# Create df_test and test set\nprint('Creating df_test  :')\nsample['parcelid'] = sample['ParcelId']\n\nprint(\"Merge Sample with property data :\")\ndf_test = sample.merge(prop, on='parcelid', how='left')\n\n\n########################\ndf_test[\"transactiondate\"] = pd.to_datetime(df_train[\"transactiondate\"])\ndf_test[\"transactiondate_year\"] = df_test[\"transactiondate\"].dt.year\ndf_test[\"transactiondate_month\"] = df_test[\"transactiondate\"].dt.month\ndf_test['transactiondate_quarter'] = df_test['transactiondate'].dt.quarter\ndf_test[\"transactiondate\"] = df_test[\"transactiondate\"].dt.day     \n\n#################################\n\n\nx_test = df_test[train_columns]\n\nprint('Shape of x_test:', x_test.shape)\nprint(\"Preparing x_test:\")\nfor c in x_test.dtypes[x_test.dtypes == object].index.values:\n    x_test[c] = (x_test[c] == True)\n  \n#print(\"Bind x_test to float32:\")\n#x_test = x_test.values.astype(np.float32, copy=False)\n\n\n\n\n","execution_count":null},{"outputs":[],"cell_type":"code","metadata":{"collapsed":true,"trusted":true,"_uuid":"35af494554ad4f7fffc8ca3e1f1b98a234b212a8"},"source":"\n#############################Imputer##################\n\nfrom sklearn.preprocessing import Imputer\nimputer= Imputer()\nimputer.fit(x_train.iloc[:, :])\nx_train = imputer.transform(x_train.iloc[:, :])\nimputer.fit(x_test.iloc[:, :])\nx_test = imputer.transform(x_test.iloc[:, :])\n\n#########################Standard Scalar##############\n\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)\n\n################################################\n","execution_count":null},{"outputs":[],"cell_type":"code","metadata":{"collapsed":true,"trusted":true,"_uuid":"aea353813c614b284094297f46ae1104daafb98a"},"source":"len_x=int(x_train.shape[1])\nprint(\"len_x is:\",len_x)\n#########################################################################\n####################ANN Starts here#\n\nclassifier = Sequential()\nclassifier.add(Dense(units = 28 , kernel_initializer = 'normal', activation = 'relu', input_dim = len_x))\nclassifier.add(Dense(units = 14, kernel_initializer = 'normal', activation = 'relu'))\nclassifier.add(Dense(units = 7, kernel_initializer = 'normal', activation = 'relu'))\nclassifier.add(Dense(units = 3, kernel_initializer = 'normal', activation = 'relu'))\nclassifier.add(Dense(1, kernel_initializer='normal'))\nclassifier.compile(loss='mae', optimizer='rmsprop', metrics=['mae', 'accuracy'])\n#classifier.compile(loss='mean_absolute_error', optimizer='rmsprop', metrics=['mae', 'accuracy'])\n\nclassifier.fit(np.array(x_train), np.array(y_train), batch_size = 10, epochs = 10)\n\nprint(\"x_test.shape:\",x_test.shape)\ny_pred_ann = classifier.predict(x_test)\n\n#######################################################################################\n\nprint( \"\\nPreparing results for write :\" )\n","execution_count":null},{"outputs":[],"cell_type":"code","metadata":{"collapsed":true,"trusted":true,"_uuid":"0340a4a2d4cadf04ff283d82670f85bb14e5df4b"},"source":"y_pred = y_pred_ann.flatten()\n\n#output = pd.DataFrame({'ParcelId': properties['parcelid'].astype(np.int32),\noutput = pd.DataFrame({'ParcelId': prop['parcelid'].astype(np.int32),\n        '201610': y_pred, '201611': y_pred, '201612': y_pred,\n        '201710': y_pred, '201711': y_pred, '201712': y_pred})\n# set col 'ParceID' to first col\ncols = output.columns.tolist()\ncols = cols[-1:] + cols[:-1]\noutput = output[cols]\n\nprint( \"\\nWriting results to disk:\" )\noutput.to_csv('Only_ANN_{}.csv'.format(datetime.now().strftime('%Y%m%d_%H%M%S')), index=False)\n\nprint( \"\\nFinished!\" )\n","execution_count":null}],"nbformat_minor":1}