{"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"pygments_lexer":"ipython3","mimetype":"text/x-python","nbconvert_exporter":"python","version":"3.6.1","codemirror_mode":{"version":3,"name":"ipython"},"file_extension":".py","name":"python"}},"cells":[{"cell_type":"markdown","source":"The Python file Zillow Competition :","metadata":{"_execution_state":"idle","_uuid":"25c20881f7f0a34e47367f1353825d3c206b5bfc","_cell_guid":"6cd6921e-825c-4f51-b40e-4a7c1596242d"}},{"metadata":{"_execution_state":"idle","_uuid":"2304e5d3718b745e89b94a7126d08dfb571ed697","_cell_guid":"55ccc4ea-e17c-49c0-8850-ac8c11223b62"},"cell_type":"code","outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport xgboost as xgb\nfrom sklearn.preprocessing import LabelEncoder\n\nproperties = pd.read_csv('../input/properties_2016.csv')\ntrain = pd.read_csv(\"../input/train_2016_v2.csv\")\nfor c in properties.columns:\n    properties[c]=properties[c].fillna(1)\n    if properties[c].dtype == 'object':\n        lbl = LabelEncoder()\n        lbl.fit(list(properties[c].values))\n        properties[c] = lbl.transform(list(properties[c].values))\n\ntrain_df = train.merge(properties, how='left', on='parcelid')\nx_train = train_df.drop(['parcelid', 'logerror','transactiondate'], axis=1)\nx_test = properties.drop(['parcelid'], axis=1)\n# shape        \nprint('Shape train: {}\\nShape test: {}'.format(x_train.shape, x_test.shape))\n\n# drop out ouliers\ntrain_df=train_df[ train_df.logerror > -0.4 ]\ntrain_df=train_df[ train_df.logerror < 0.4 ]\nx_train=train_df.drop(['parcelid', 'logerror','transactiondate'], axis=1)\ny_train = train_df[\"logerror\"].values.astype(np.float32)\ny_mean = np.mean(y_train)\n\nprint('After removing outliers:')     \nprint('Shape train: {}\\nShape test: {}'.format(x_train.shape, x_test.shape))\n\n\n# xgboost params\nxgb_params = {\n    'eta': 0.028,\n    'max_depth': 5,\n    'subsample': 0.80,\n    'objective': 'reg:linear',\n    'eval_metric': 'mae',\n    'base_score': y_mean,\n    'silent': 1\n}\n\ndtrain = xgb.DMatrix(x_train, y_train)\ndtest = xgb.DMatrix(x_test)\n\n# cross-validation\ncv_result = xgb.cv(xgb_params, \n                   dtrain, \n                   nfold=5,\n                   num_boost_round=100,\n                   early_stopping_rounds=5,\n                   verbose_eval=10, \n                   show_stdv=False\n                  )\nnum_boost_rounds = len(cv_result)\nprint(num_boost_rounds)\n# train model\nmodel = xgb.train(dict(xgb_params, silent=1), dtrain, num_boost_round=num_boost_rounds)\npred = model.predict(dtest)\ny_pred=[]\n\nfor i,predict in enumerate(pred):\n    y_pred.append(str(round(predict,10)))\ny_pred=np.array(y_pred)\n\noutput = pd.DataFrame({'ParcelId': properties['parcelid'].astype(np.int32),\n        '201610': y_pred, '201611': y_pred, '201612': y_pred,\n        '201710': y_pred, '201711': y_pred, '201712': y_pred})\n# set col 'ParceID' to first col\ncols = output.columns.tolist()\ncols = cols[-1:] + cols[:-1]\noutput = output[cols]\nfrom datetime import datetime\noutput.to_csv('sub{}.csv'.format(datetime.now().strftime('%Y%m%d_%H%M%S')), index=False)\noutput ","execution_count":null}],"nbformat":4,"nbformat_minor":1}