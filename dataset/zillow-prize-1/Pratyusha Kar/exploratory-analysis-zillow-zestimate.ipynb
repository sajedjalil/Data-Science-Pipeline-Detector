{"cells":[{"metadata":{"trusted":false,"_uuid":"c099f9a5e91f125a7e1496b1baced100b64f64a8"},"cell_type":"code","source":"#-----------\"Exploratory Analysis Zillow\"---------------#\n#Link :https://www.kaggle.com/philippsp/exploratory-analysis-zillow\n#Module :14","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a6b1c66b10d3ba95b691d512065e7c57885200c5"},"cell_type":"code","source":"### Welcome and good luck to you all at Zillow's Home Value prediction!\n#### with a price pool of 1.2 Million Dollar\n\n#Here is a first exploratory analysis of the competition dataset.\n#We are provided with a list of real estate properties in three counties (Los Angeles, Orange and Ventura, California) \n#data in 2016.\n\n\n#Zillow provides a \"Zestimate\", which is an estimated property value.\n#Our task in this competition is to predict the the difference between the actual price and the estimate of the price (Zestimate). So, in fact we are predicting, where Zillow's Zestimate will be good, and where it will be bad.\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"989eb7711aaa8e4ac82c9b90b4975e4cfbc8984a"},"cell_type":"code","source":"import sys\n!{sys.executable} -m pip install xgboost\n!{sys.executable} -m pip install mlxtend\n!{sys.executable} -m pip install plotly\n!{sys.executable} -m pip install ggplot","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a7a0ba262c301824d607aa9944ffcf5fb5f387a1"},"cell_type":"code","source":"!conda install -c conda-forge --yes plotnine","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"4d403096ffb6904f8d247f705b80dc0269d28043"},"cell_type":"code","source":"from plotnine import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"3e8204ac79c65be17fbfd4cd6ffe1f259fb17900"},"cell_type":"code","source":"from ggplot import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"cd9b9ab09c462679e156d35f0f593ff5a6041f99"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n#import ggplot\nfrom scipy import stats\nfrom io import StringIO\nimport sklearn as sk\nimport itertools\nimport plotly.plotly as py\nimport plotly.tools as tls\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\nfrom io import StringIO\nfrom string import ascii_letters\nfrom statsmodels.graphics.mosaicplot import mosaic\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import Perceptron\nfrom sklearn import tree\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn import svm\nimport xgboost as xgb\nfrom mlxtend.classifier import StackingClassifier\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\n\nsns.set(style='white', context='notebook', palette='deep')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a2da44eb914c3f3d5f9a82b5ac686fdf306874c7"},"cell_type":"code","source":"# Properties\nproperties = pd.read_csv(\"../input/properties_2016.csv\")\nprint(properties)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"91d06db07f1347895c6c459759c1383df844aa9c"},"cell_type":"code","source":"# Transactions\ntransaction = pd.read_csv(\"../input/train_2016_v2.csv\")\nprint(transaction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"dbac49fca4923da05a61715aabdeda2e10e488c1"},"cell_type":"code","source":"# Sample Submission\nsample_submission = pd.read_csv(\"../input/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"8cb00d68562a95e84973ae56d7f086b3997c746d"},"cell_type":"code","source":"# Renaming the features\ndata_dictionary_string = \"\"\"key|old_key|description\naircon|airconditioningtypeid|Type of cooling system present in the home (if any)architectural_style\narchitecturalstyletypeid|architecturalstyletypeid|Architectural style of the home (i.e. ranch, colonial, split-level, etcâ€¦)\narea_base|finishedsquarefeet6|Base unfinished and finished area\narea_firstfloor_finished|finishedfloor1squarefeet|Size of the finished living area on the first (entry) floor of the home\narea_garage|garagetotalsqft|Total number of square feet of all garages on lot including an attached garage\narea_live_finished|finishedsquarefeet12|Finished living area\narea_liveperi_finished|finishedsquarefeet13|Perimeter living area\narea_lot|lotsizesquarefeet|Area of the lot in square feet\narea_patio|yardbuildingsqft17|Patio in yard\narea_pool|poolsizesum|Total square footage of all pools on property\narea_shed|yardbuildingsqft26|Storage shed/building in yard\narea_total_calc|calculatedfinishedsquarefeet|Calculated total finished living area of the home\narea_total_finished|finishedsquarefeet15|Total area\narea_unknown|finishedsquarefeet50|Size of the finished living area on the first (entry) floor of the home\nbasementsqft|basementsqft|Finished living area below or partially below ground level\nbuild_year|yearbuilt|The Year the principal residence was built\ndeck|decktypeid|Type of deck (if any) present on parcelfinishedfloor1squarefeet\nflag_fireplace|fireplaceflag|Is a fireplace present in this home\nflag_tub|hashottuborspa|Does the home have a hot tub or spa\nframing|buildingclasstypeid|The building framing type (steel frame, wood frame, concrete/brick)\nheating|heatingorsystemtypeid|Type of home heating system\nid_fips|fips|Federal Information Processing Standard code - see https://en.wikipedia.org/wiki/FIPS_county_code for more details\nid_parcel|parcelid|Unique identifier for parcels (lots)\nid_zoning_raw|rawcensustractandblock|Census tract and block ID combined - also contains blockgroup assignment by extension\nid_zoning|censustractandblock|Census tract and block ID combined - also contains blockgroup assignment by extension\nlatitude|latitude|Latitude of the middle of the parcel multiplied by 10e6\nlongitude|longitude|Longitude of the middle of the parcel multiplied by 10e6\nmaterial|typeconstructiontypeid|What type of construction material was used to construct the home\nnum_75_bath|threequarterbathnbr|Number of 3/4 bathrooms in house (shower + sink + toilet)\nnum_bathroom_calc|calculatedbathnbr|Number of bathrooms in home including fractional bathroom\nnum_bathroom|bathroomcnt|Number of bathrooms in home including fractional bathrooms\nnum_bath|fullbathcnt|Number of full bathrooms (sink, shower + bathtub, and toilet) present in home\nnum_bedroom|bedroomcnt|Number of bedrooms in home\nnum_fireplace|fireplacecnt|Number of fireplaces in a home (if any)\nnum_garage|garagecarcnt|Total number of garages on the lot including an attached garage\nnum_pool|poolcnt|Number of pools on the lot (if any)\nnum_room|roomcnt|Total number of rooms in the principal residence\nnum_story|numberofstories|Number of stories or levels the home has\nnum_unit|unitcnt|Number of units the structure is built into (i.e. 2 = duplex, 3 = triplex, etc...)\npooltypeid10|pooltypeid10|Spa or Hot Tub\npooltypeid2|pooltypeid2|Pool with Spa/Hot Tub\npooltypeid7|pooltypeid7|Pool without hot tub\nquality|buildingqualitytypeid|Overall assessment of condition of the building from best (lowest) to worst (highest)\nregion_city|regionidcity|City in which the property is located (if any)\nregion_county|regionidcounty|County in which the property is located\nregion_neighbor|regionidneighborhood|Neighborhood in which the property is located\nregion_zip|regionidzip|Zip code in which the property is located\nstory|storytypeid|Type of floors in a multi-story house (i.e. basement and main level, split-level, attic, etc.). See tab for details.\ntax_building|structuretaxvaluedollarcnt|The assessed value of the built structure on the parcel\ntax_delinquency_year|taxdelinquencyyear|Year for which the unpaid propert taxes were due\ntax_delinquency|taxdelinquencyflag|Property taxes for this parcel are past due as of 2015\ntax_land|landtaxvaluedollarcnt|The assessed value of the land area of the parcel\ntax_property|taxamount|The total property tax assessed for that assessment year\ntax_total|taxvaluedollarcnt|The total tax assessed value of the parcel\ntax_year|assessmentyear|The year of the property tax assessmentbasementsqft\nzoning_landuse_county|propertycountylandusecode|County land use code i.e. it's zoning at the county level\nzoning_landuse|propertylandusetypeid|Type of land use the property is zoned for\nzoning_property|propertyzoningdesc|Description of the allowed land uses (zoning) for that property\n\"\"\"\n\ndata_dictionary_df = pd.read_csv(StringIO(data_dictionary_string), sep=\"|\") \ndata_dictionary_df.sort_values(by=\"key\", inplace=True)\n#data_dictionary_df.index = data_dictionary_df[\"key\"]\ndata_dictionary_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"60fb9b9279a3b5676ddd10e95fb6de264b21ce93"},"cell_type":"code","source":"data_dictionary = data_dictionary_df[\"description\"]\ndata_dictionary.index = data_dictionary_df[\"key\"]\ndata_dictionary[\"id_parcel\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e792f75c6b697127ac3d35190b7935c9485250a5"},"cell_type":"code","source":"# Remap properties with new keys from data_dictionary\ndata_dictionary_rename = data_dictionary_df[\"key\"]\ndata_dictionary_rename.index  = data_dictionary_df[\"old_key\"]\ndata_dictionary_rename.to_dict()\n\n# Apply rename to properties\nproperties.rename(columns=data_dictionary_rename, inplace=True)\nproperties.index = properties['id_parcel']\nproperties.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"87aa5c8e635025e26969d4820bf27b5d7401a1f2"},"cell_type":"code","source":"#Transactions dates\ntransaction = transaction.rename(columns={\n    \"parcelid\": \"id_parcel\",  \n    \"transactiondate\": \"date\" \n})\ntransaction.sort_values(by=\"id_parcel\", inplace=True)\ntransaction.index = transaction['id_parcel']\ntransaction.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a16ad026038e2bbfba6928a95d44a80a782be7d4"},"cell_type":"code","source":"#Graph 1\n# Distribution of transaction dates \n#As shown in the figure in RMD file, there are only some of the transactions after 25.10 in the train set, \n#because the rest is in the test set (for the public LB).\n\ntransaction[\"Year\"] = pd.DatetimeIndex(transaction['date']).year\ntransaction[\"Month\"] = pd.DatetimeIndex(transaction['date']).month\ntransaction[\"Year_Month\"] = pd.DatetimeIndex(transaction['date']).year.astype(str) +\"-\"+ pd.DatetimeIndex(transaction['date']).month.astype(str)\n\ndf2 = pd.DataFrame({\n    'YearMonth': ['Jan-2016', 'Feb-2016', 'March-2016', 'April-2016', 'May-2016', 'June-2016', 'July-2016','August-2016','Sept-2016','Oct-2016','Nov-2016','Dec-2016'],\n    'Month': [1, 2, 3, 4, 5, 6,7,8,9,10,11,12],\n    'sort_num' : [10,11,12,13,14,15,16,17,18,19,20,21]\n}\n)\n\nTemp_Graph_1 = {'count': transaction.groupby(['Month']).size()}\ndata = pd.DataFrame(Temp_Graph_1) \nprint(Temp_Graph_1)\ndf = pd.merge(data, df2, on='Month')\ndf = pd.DataFrame(df)\ndf.plot.bar(x='YearMonth' , y='count' , color=\"red\") + plt.axvline(x=9, c=\"black\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b7d64ed5fb6263dd10ea15af0931e720a2f462a6"},"cell_type":"code","source":"#Graph_2\n#To get a feel for the data let's first have a look at the distribution of our outcome (logerror), i.e. the difference in log(Zestimate)-log(Saleprice)\n\nTemp_Graph_2 = {'logerror': transaction['logerror']}\ndata = pd.DataFrame(Temp_Graph_2)\ngg = ggplot(data, aes(x='logerror')) + geom_histogram(bins=400, fill=\"red\") + xlim(-0.5, 0.5)+ ylab(\"Count\")\nprint(gg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"c64a177bbd524fa92e1cc85934c1ac40228f0615"},"cell_type":"code","source":"#In fact there are two outcomes you can look at:  \n\n#  - logerror: log(Zestimate) - log(Saleprice). So a positive logerror means Zestimate is overestimating the Saleprice, a negative logerror means that Zestimate is underestimating Saleprice. \n#  - absolute logerror: a small value means that log(Zestimate) is close to log(Saleprice). So, Zestimate predictions are close to Saleprice.\n\n#Any association with logerror would indicate that a feature would be associated with over- or understimating the sale price.\n#Any association of a feature with absolute logerror would indicate that the feature is associated with a better or worse Zestimate.\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"cb0c6df9b10f3481d554da8aff0d03fb35d5d939"},"cell_type":"code","source":"#Graph_3\n# Absolute logerror\nTemp_Graph_3 = {'abs_logerror': abs(transaction['logerror'])}\ndata = pd.DataFrame(Temp_Graph_3)\n\ngg = ggplot(data, aes(x='abs_logerror')) + geom_histogram(bins=400, fill=\"red\") + xlim(0, 0.5)+ ylab(\"Count\")\nprint(gg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"0cc3e79880de338992d22849fdad49c72b0a69b0"},"cell_type":"code","source":"from datetime import datetime","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d823fee23e779e33b0b37a423cc3caebc655cfa2"},"cell_type":"code","source":"#Graph_4\n#How does absolute log error change with time\ntransaction[\"abs_logerror\"] = abs(transaction[\"logerror\"])\nTemp_Graph_4 = {'mean_abs_logerror': transaction.groupby(['Month'])['abs_logerror'].mean()}\ndata = pd.DataFrame(Temp_Graph_4)  #.sort_values(by =\"Month\" , ascending=True)\ndf4 = pd.merge(data, df2, on='Month')\n\ngg = ggplot(df4, aes(x='YearMonth', y='mean_abs_logerror')) + geom_line(size=1.5, color=\"red\") + geom_point(size=5, color=\"red\") + theme_bw()\nprint(gg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5fb98ddf3c1ea9759ea70b0326047b1c60fe03d5"},"cell_type":"code","source":"#Graph_5\n#How does log error change with time\nTemp_Graph_5 = {'mean_logerror': transaction.groupby(['Month'])['logerror'].mean()}\ndata = pd.DataFrame(Temp_Graph_5)  \ndf = pd.merge(data, df2, on='Month')\ngg = ggplot(df, aes(x='YearMonth', y='mean_logerror')) + geom_line(size=1.5, color=\"red\") + geom_point(size=5, color=\"red\") + theme_bw()\nprint(gg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"4c6b7bcd728fd48db966cf2d5022b104e7cfce9d"},"cell_type":"code","source":"#Graph_6\n### Missing values\n#We have seen many missing values in the data peeking. \n#How many missing values are there for each feature?\n#In fact, some features are missing nearly completely. So, we probably have to work more with the others.\nplt.figure(figsize=(20,20))\nGraph6 = {'feature' : [], 'missing_pct' : []}\nList_Columns = list((pd.DataFrame(properties).columns.values))\nfor i in List_Columns:\n    Graph6['feature'].append(i)\n    Graph6['missing_pct'].append(properties[i].isna().sum()/len(properties[i]))\n\nprint(List_Columns)    \nTemp_Graph_6 = pd.DataFrame(Graph6)\nTemp_Graph_6 = Temp_Graph_6.sort_values(by ='missing_pct', ascending= False).reset_index(drop=True)\n\nTemp_Graph_6.plot.barh(x='feature' , color=\"red\" , figsize = (30, 20))+theme_bw()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f54692daa40de30b5d7edb29b89fa4360680f475"},"cell_type":"code","source":"data_dictionary = data_dictionary_df[\"description\"]\ndata_dictionary.index = data_dictionary_df[\"key\"]\ndata_dictionary[\"build_year\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"4aef6934dacfcd335daf7bf0564cbc24f54332a9"},"cell_type":"code","source":"data_dictionary_rename = data_dictionary_df[\"key\"]\ndata_dictionary_rename.index  = data_dictionary_df[\"old_key\"]\ndata_dictionary_rename.to_dict()\n\n# Apply rename to properties\nproperties.rename(columns=data_dictionary_rename, inplace=True)\nproperties.index = properties['build_year']\nproperties.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"90b2de66941feb0b687bf00a3f70dbb95a9128fe"},"cell_type":"code","source":"properties = properties.rename(columns={\n    \"yearbuilt\": \"build_year\",  \n})\nproperties.index = properties['build_year']\nproperties.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"00af7fd33b4d501a01a5e95cba4d54ad804de106"},"cell_type":"code","source":"#Graph_7\n# Correlation with absolute logerror\n#num_ features:\nTemp_Graph_7 = Temp_Graph_6.loc[Temp_Graph_6['missing_pct'] <0.75]\nTemp_Graph_7 = Temp_Graph_7.loc[Temp_Graph_7['feature'].str.contains('num_', regex=True)]\ntransaction['abs_logerror'] = abs(transaction['logerror'])\nResults = pd.merge(transaction,\n                   properties,\n                   left_on = 'id_parcel',\n                   right_on = 'id_parcel',\n                   how = 'left'\n                  )\n\ncol = []\nfor i in Temp_Graph_7['feature']:\n    col.append(i)    \ncol.append('abs_logerror')\n\nResults = Results.loc[:,col]\ncorr = Results.corr()\n\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nf, ax = plt.subplots(figsize=(11, 9))\n\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"23cbdb2300a4656a8df175e1d62656a3716e8631"},"cell_type":"code","source":"#Graph_8\n# Correlation with absolute logerror\n#area_ features\nTemp_Graph_8 = Temp_Graph_6.loc[Temp_Graph_6['missing_pct'] <0.75]\nTemp_Graph_8 = Temp_Graph_8.loc[Temp_Graph_8['feature'].str.contains('area_', regex=True)]\ntransaction['abs_logerror'] = abs(transaction['logerror'])\n\nResults = pd.merge(transaction,\n                   properties,\n                   left_on = 'id_parcel',\n                   right_on = 'id_parcel',\n                   how = 'left'\n                  )\n\ncol = []\nfor i in Temp_Graph_8['feature']:\n    col.append(i)    \ncol.append('abs_logerror')\n\nResults = Results.loc[:,col]\ncorr = Results.corr()\n\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nf, ax = plt.subplots(figsize=(11, 9))\n\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ac1b0306a14cc3529b22c4bcf5d552649d248365"},"cell_type":"code","source":"#Graph_9\n# Correlation with absolute logerror\n#tax_ features\nTemp_Graph_9 = Temp_Graph_6.loc[Temp_Graph_6['missing_pct'] <0.75]\nTemp_Graph_9 = Temp_Graph_9.loc[Temp_Graph_9['feature'].str.contains('tax_', regex=True)]\ntransaction['abs_logerror'] = abs(transaction['logerror'])\n\nResults = pd.merge(transaction,\n                   properties,\n                   left_on = 'id_parcel',\n                   right_on = 'id_parcel',\n                   how = 'left'\n                  )\nTemp_Graph_9.drop(Temp_Graph_9.index[4] ,axis=0)\ncol = []\nfor i in Temp_Graph_9['feature']:\n    col.append(i)    \ncol.append('abs_logerror')\n\nResults = Results.loc[:,col]\ncorr = Results.corr()\n\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nf, ax = plt.subplots(figsize=(11, 9))\n\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"47216cfb2587bc2bc93054354cd09e881c274751"},"cell_type":"code","source":"#Graph_10\n#Correlation with logerror\n#num_ features:\nTemp_Graph_10 = Temp_Graph_6.loc[Temp_Graph_6['missing_pct'] <0.75]\nTemp_Graph_10 = Temp_Graph_10.loc[Temp_Graph_10['feature'].str.contains('num_', regex=True)]\nlogerror = transaction['logerror']\n\nResults = pd.merge(transaction,\n                   properties,\n                   left_on = 'id_parcel',\n                   right_on = 'id_parcel',\n                   how = 'left'\n                  )\n\ncol = []\nfor i in Temp_Graph_10['feature']:\n    col.append(i)    \ncol.append('logerror')\n\nResults = Results.loc[:,col]\ncorr = Results.corr()\n\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nf, ax = plt.subplots(figsize=(11, 9))\n\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"72b1c46e463cde7be18209afde65dbfde16b2b30"},"cell_type":"code","source":"#Graph_11\n# Correlation with logerror\n#area_ features\nTemp_Graph_11 = Temp_Graph_6.loc[Temp_Graph_6['missing_pct'] <0.75]\nTemp_Graph_11 = Temp_Graph_11.loc[Temp_Graph_11['feature'].str.contains('area_', regex=True)]\nlogerror = transaction['logerror']\n\nResults = pd.merge(transaction,\n                   properties,\n                   left_on = 'id_parcel',\n                   right_on = 'id_parcel',\n                   how = 'left'\n                  )\n\ncol = []\nfor i in Temp_Graph_11['feature']:\n    col.append(i)    \ncol.append('logerror')\n\nResults = Results.loc[:,col]\ncorr = Results.corr()\n\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nf, ax = plt.subplots(figsize=(11, 9))\n\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e2cb110e868276381d9885e030ddce63ab6bde93"},"cell_type":"code","source":"#Graph_12\n# Correlation with logerror\n#tax_ features\nTemp_Graph_12 = Temp_Graph_6.loc[Temp_Graph_6['missing_pct'] <0.75]\nTemp_Graph_12 = Temp_Graph_12.loc[Temp_Graph_12['feature'].str.contains('tax_', regex=True)]\nlogerror = transaction['logerror']\n\nResults = pd.merge(transaction,\n                   properties,\n                   left_on = 'id_parcel',\n                   right_on = 'id_parcel',\n                   how = 'left'\n                  )\n\ncol = []\nfor i in Temp_Graph_12['feature']:\n    col.append(i)    \ncol.append('logerror')\n\nResults = Results.loc[:,col]\ncorr = Results.corr()\n\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nf, ax = plt.subplots(figsize=(11, 9))\n\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"55f40817888ef2003111f73b06fff30144e358e5"},"cell_type":"code","source":"#Graph_13\n# When were the houses built?\nTemp_Graph_7 = Temp_Graph_6.loc[Temp_Graph_6['missing_pct'] <0.75]\nTemp_Graph_7 = Temp_Graph_7.loc[Temp_Graph_7['feature'].str.contains('num_', regex=True)]\ntransaction['abs_logerror'] = abs(transaction['logerror'])\nResults = pd.merge(transaction,\n                   properties,\n                   left_on = 'id_parcel',\n                   right_on = 'id_parcel',\n                   how = 'left'\n                  )\nGraph_13 = pd.DataFrame(Results)\ngg = ggplot(Graph_13, aes('build_year')) + geom_density(color=\"red\", size=1.2)+theme_bw()\nprint(gg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"cee7661b53dd62f98f4354c9b911ede32b5200d3"},"cell_type":"code","source":"#Graph_14\n# How does the absolute logerror change with build_year?\nf, ax = plt.subplots(figsize=(12, 6))\ndf = Results.groupby('build_year', as_index = False)['abs_logerror'].mean()\nsns.regplot(x=\"build_year\", y=\"abs_logerror\", data=df, scatter=True, order=3, truncate=True, color=\"r\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"2797920b96b47fb3e030b96d7de68d7f55d1f1f1"},"cell_type":"code","source":"#Graph_15\n# How does the logerror change with build_year?\nf, ax = plt.subplots(figsize=(12, 6))\ndf = Results.groupby('build_year', as_index = False)['logerror'].mean()\nsns.regplot(x=\"build_year\", y=\"logerror\", data=df, scatter=True, order=3, truncate=True, color = 'r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"679bfe941d82a18881743a6bc861392c71ee1248"},"cell_type":"code","source":"#Graph_16\n# Where does Zestimate predict well?\n#To get a quick feel where zestimate predicts well, we can group our absolute logerror into different percentiles, \n#e.g. the percentile with best predictions (top 10%), worst predictions (worst 10%) \n#and typical predictions (50% around the median).\n\ndef eq_mask(df, key, value):\n    return df[df[key] == value]\ntransaction['percentile'] = pd.cut(transaction['abs_logerror'], np.quantile(transaction['abs_logerror'],(0, 0.1, 0.2, 0.25 ,0.5 ,0.75, 0.9, 1)),include_lowest=True,labels=False)\nResults = pd.merge(transaction,\n                   properties,\n                   left_on = 'id_parcel',\n                   right_on = 'id_parcel',\n                   how = 'left'\n                  )\n\ntmp1  = eq_mask(Results,'percentile', 1)\ntmp1 = tmp1.sample(n=5000)\ntmp1['type'] = \"best_fit\"\ntmp2  = eq_mask(Results,'percentile', 5)\n#tmp2 = tmp2.sample(n=5000)\ntmp2['type'] = \"worst_fit\"\ntmp3  = eq_mask(Results,'percentile', 3)\ntmp3 = tmp3.sample(n=5000)\ntmp3['type'] = \"typical_fit\"\n\n#If the distributions of features are largely overlapping for these three groups of transactions \n#the feature most likely does not have a large effect on the goodness of estimation. \n#Let's see one example.\n\ntmp = pd.DataFrame(pd.concat([tmp1,tmp2,tmp3]))\ncol_pal = \"Blues\"\ngg = ggplot(tmp,aes(x='latitude',fill='type', color='type'))+geom_density(size=1.2,alpha=0.5) +theme_bw() #+ scale_fill_brewer(palette=col_pal)+scale_color_brewer(palette=col_pal)\nprint(gg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"35f1a9b1016d76d0c3cd900b6d63d48140ab9135"},"cell_type":"code","source":"#Graph_17\n#We can see that rows resulting in the worst predictions have a lower density for lower latitude values, \n#but a higher density for intermediate latitudes (around 34000000). \ntmptrans = pd.merge(transaction,\n                   properties,\n                   left_on = 'id_parcel',\n                   right_on = 'id_parcel',\n                   how = 'left'\n                  )\ndata_17 = tmptrans[['latitude' , 'abs_logerror']]\nlm=sns.lmplot(x='latitude',y='abs_logerror',data=data_17, scatter=False, order= 3,truncate= True, fit_reg=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"c044fe18cfdd43fecff320e9e2993c000ad89f3a"},"cell_type":"code","source":"#Graph_18\ncol_pal = \"Blues\"\ngg = ggplot(tmp,aes(x='longitude',fill='type', color='type')) + geom_density(size=1.2,alpha=0.5) + theme_bw() \nprint(gg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5efd36b633346994043a952407bb4ffbab17f59e"},"cell_type":"code","source":"#Graph 19\ntmptrans = pd.merge(transaction,\n                   properties,\n                   left_on = 'id_parcel',\n                   right_on = 'id_parcel',\n                   how = 'left'\n                  )\ndata_18 = tmptrans[['longitude' , 'abs_logerror']]\nlm=sns.lmplot(x='longitude',y='abs_logerror',data=data_18, scatter=False, order= 3,truncate= True, fit_reg=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a4f4f3143b2b551f8a4f0869c463829cd0b04e34"},"cell_type":"code","source":"#Graph 20\ncol_pal = \"Blues\"\ngg = ggplot(tmp,aes(x='area_total_finished',fill='type', color='type')) + geom_density(size=1.2,alpha=0.5) + theme_bw() \nprint(gg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"0b194004b9d51daa093e46e942e5d353eed0ca5e"},"cell_type":"code","source":"#graph 21\ndata_21 = tmptrans[['area_total_finished' , 'abs_logerror']]\nlm=sns.lmplot(x='area_total_finished',y='abs_logerror',data=data_21, scatter=False, order= 3,truncate= True, fit_reg=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"3b5ef67700d8ab7fd43cd514197845788c38ff7f"},"cell_type":"code","source":"#Graph_22\ncol_pal = \"Blues\"\ngg = ggplot(tmp,aes(x='area_live_finished',fill='type', color='type')) + geom_density(size=1.2,alpha=0.5) + theme_bw() \nprint(gg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"aa5f1fff674e7df432c18d50adbafc95e3943d6e"},"cell_type":"code","source":"#Graph 23\ncol_pal = \"Blues\"\ngg = ggplot(tmp,aes(x='num_room',fill='type', color='type')) + geom_density(size=1.2,alpha=0.5) + theme_bw() \nprint(gg)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"4e0c73ba3063ee1a096d259b8f6ccad6f5da6237"},"cell_type":"code","source":"#Graph 24\ncol_pal = \"Blues\"\ngg = ggplot(tmp,aes(x='num_unit',fill='type', color='type')) + geom_density(size=1.2,alpha=0.5) + theme_bw() \nprint(gg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"3cad85ccb34f456a5aebb9bbcf78f22a2b88e9dd"},"cell_type":"code","source":"#Graph 25\ncol_pal = \"Blues\"\ngg = ggplot(tmp,aes(x='build_year',fill='type', color='type')) + geom_density(size=1.2,alpha=0.5) + theme_bw()\nprint(gg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"bff174f913a9e2f7ed8cb55626a4efb07ce5001f"},"cell_type":"code","source":"#Graph 26\ncol_pal = \"Blues\"\ngg = ggplot(tmp,aes(x='tax_total',fill='type', color='type')) + geom_density(size=1.2,alpha=0.5) + theme_bw() \nprint(gg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d4a9644f3011e63549ca723525b4a629b6d47258"},"cell_type":"code","source":"#Graph 27\ndata_27 = tmptrans[['tax_total' , 'abs_logerror']]\nlm=sns.lmplot(x='tax_total',y='abs_logerror',data=data_27, scatter=False, order= 3,truncate= True, fit_reg=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"1f7fc3289dcd0a2dcfbce15bb2db62b5ab69dd77"},"cell_type":"code","source":"#Graph 28\ncol_pal = \"Blues\"\ngg = ggplot(tmp,aes(x='tax_building',fill='type', color='type')) + geom_density(size=1.2,alpha=0.5) + theme_bw() \nprint(gg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"512e7778f71998c98a3c1cbf357962f98f95e4fc"},"cell_type":"code","source":"#Graph 29\n# Where does Zestimate over or underpredict?\ntmptrans = pd.merge(transaction,\n                   properties,\n                   left_on = 'id_parcel',\n                   right_on = 'id_parcel',\n                   how = 'left'\n                  )\ntmptrans['overunder'] = 'under'\ntmptrans.ix[ (tmptrans.logerror > 0 ), ['overunder'] ] = 'over'\ntmptrans.ix[ (tmptrans.logerror < 0 ), ['overunder'] ] = 'under'\ncol_pal = \"red\"\ndata_29 = tmptrans[['latitude' , 'abs_logerror', 'overunder']]\nlm=sns.lmplot(x='latitude',y='abs_logerror', hue='overunder', data=data_29, scatter=False, order= 3,truncate= True, fit_reg=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a49e81463ac68f8215247ef7c5f873d36b7dc2a6"},"cell_type":"code","source":"!pip install ipyleaflet\n!jupyter nbextension enable --py --sys-prefix ipyleaflet","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"71abdd2cfcb2c253dc33226f54f820c68cf76183"},"cell_type":"code","source":"#Graph 30\ntmptrans = pd.merge(transaction,\n                   properties,\n                   left_on = 'id_parcel',\n                   right_on = 'id_parcel',\n                   how = 'left'\n                  )\ntmptrans['overunder'] = 'under'\ntmptrans.ix[ (tmptrans.logerror > 0 ), ['overunder'] ] = 'over'\ntmptrans.ix[ (tmptrans.logerror < 0 ), ['overunder'] ] = 'under'\ncol_pal = \"red\"\ndata_30 = tmptrans[['longitude' , 'abs_logerror', 'overunder']]\nlm=sns.lmplot(x='longitude',y='abs_logerror' ,hue='overunder',data=data_30, scatter=False, order= 3,truncate= True, fit_reg=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"cda1759b0022c39fbc3de7e5502a3b4b043540ee"},"cell_type":"code","source":"#Graph_31(map1)\n#Both for latitude and longitude there is a range where Zestimate both under- and overpredicts. \n#Where is that?\n\n!pip install folium\nimport folium\nm = folium.Map(\n    width='100%', \n    height='100%',\n    location=[33.8, -118.5],\n    min_lat=-118.5, max_lat=33.8, min_lon=-118.25, max_lon=34.15,\n    zoom_start=10,\n)\nfolium.PolyLine([[-118.5,33.8],[-118.25,34.15]]).add_to(m)\nfolium.Rectangle([-118.5,33.8]).add_to(m)\nm","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"4974a5e7fd60f2e39b71b910e67143366828059d"},"cell_type":"code","source":"#Graph 32 \n#For properties with small calculated total area, Zestimate seems to overpredict.\ndata_32 = tmptrans[['area_total_calc' , 'abs_logerror', 'overunder']]\nlm=sns.lmplot(x='area_total_calc',y='abs_logerror' ,hue='overunder',data=data_32, scatter=False, order= 3,truncate= True, fit_reg=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d0a18daa9d862c6cd5b4b9a4b840f31568912dbb"},"cell_type":"code","source":"#Whereas for actual finished area there is no such effect. ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a131aa6ef617f3542fd64cbf23d2fc12bc200a25"},"cell_type":"code","source":"#Graph 33\ndata_33 = tmptrans[['area_total_finished' , 'abs_logerror', 'overunder']]\nlm=sns.lmplot(x='area_total_finished',y='abs_logerror' ,hue='overunder',data=data_33, scatter=False, order= 3,truncate= True, fit_reg=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a746dd0f85399241a530cf86a7c800571f1f750c"},"cell_type":"code","source":"#Graph 34\ndata_34 = tmptrans[['area_lot' , 'abs_logerror', 'overunder']]\nlm=sns.lmplot(x='area_lot',y='abs_logerror' ,hue='overunder',data=data_34, scatter=False, order= 3,truncate= True, fit_reg=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"7c8686043ca9024ca9b72674929684c3a942921d"},"cell_type":"code","source":"#Graph 35\ndata_35 = tmptrans[['num_room' , 'abs_logerror', 'overunder']]\nlm=sns.lmplot(x='num_room',y='abs_logerror' ,hue='overunder',data=data_35, scatter=False, order= 3,truncate= True, fit_reg=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"61a4e41333bbbae1a1a1f403b93e222e07adae27"},"cell_type":"code","source":"#Graph 36\ndata_36 = tmptrans[['build_year' , 'abs_logerror', 'overunder']]\nlm=sns.lmplot(x='build_year',y='abs_logerror' ,hue='overunder',data=data_36, scatter=False, order= 3,truncate= True, fit_reg=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"803fd874a8d17cf3188defc0419fc65da1b0d7a0"},"cell_type":"code","source":"#Graph 37\ndata_37 = tmptrans[['tax_total' , 'abs_logerror', 'overunder']]\nlm=sns.lmplot(x='tax_total',y='abs_logerror' ,hue='overunder',data=data_37, scatter=False, order= 3,truncate= True, fit_reg=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"2a21ea5c2b3213d4657f0ec5aba14eede066e518"},"cell_type":"code","source":"#Graph 38\n#Where are all those properties?\nproperties_G38 = properties[['id_parcel','longitude','latitude']]\nproperties_G38 = properties_G38.sample(n=1000)\nlat_Min = pd.DataFrame(properties_G38['latitude'] / 1e6).min()\nlat_Max = pd.DataFrame(properties_G38['latitude'] / 1e6).max()\nlon_Min = pd.DataFrame(properties_G38['longitude'] / 1e6).min()\nlon_Max = pd.DataFrame(properties_G38['longitude'] / 1e6).max()\n\nData_38 = pd.merge(properties_G38,\n                   transaction,\n                   left_on = 'id_parcel',\n                   right_on = 'id_parcel',\n                   how = 'left'\n                  )\nData_38['lat'] = Data_38['latitude'] / 1e6\nData_38['lon'] = Data_38['longitude'] / 1e6\n\n\nm = folium.Map(\n    width='100%', \n    height='100%',\n    location=[34.29, -119.13],\n    min_lat=lat_Min, max_lat=lat_Max, min_lon=lon_Min, max_lon=lon_Max,\n    zoom_start=8,\n)\nfolium.PolyLine([[-119.447353,33.340239],[-117.561077,34.799328]]).add_to(m)\n\nData_38.dropna()\nData_38.apply(lambda row:folium.CircleMarker(location=[row[\"lat\"], row[\"lon\"]]).add_to(m),axis=1)\nm","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"e21281b888cc36d3f2e8a6d20fa3fcc34bff579f"},"cell_type":"code","source":"#Graph 39\n#Map absolute logerror\n#Show the absolute logerror on map. Red = higher.\nproperties_G39 = properties[['id_parcel','longitude','latitude']]\nproperties_G39 = properties_G39.sample(n=1000)\n\nDataTemp_39 = pd.merge(properties_G39,\n                   transaction,\n                   left_on = 'id_parcel',\n                   right_on = 'id_parcel',\n                   how = 'left'\n                  )\nDataTemp_39.dropna(how=\"any\")\nDataTemp_39['lat'] = DataTemp_39['latitude'] / 1e6\nDataTemp_39['lon'] = DataTemp_39['longitude'] / 1e6\n\nData_39 = DataTemp_39[['id_parcel','lat','lon','abs_logerror','percentile']]\n\nData_39['color'] = \"\"\n\nData_39.ix[ (Data_39.percentile ==1 ), ['color'] ] = '#ffffcc'\nData_39.ix[ (Data_39.percentile ==2 ), ['color'] ] = '#fed976'\nData_39.ix[ (Data_39.percentile ==3 ), ['color'] ] = '#feb24c'\nData_39.ix[ (Data_39.percentile ==4 ), ['color'] ] = '#fd8d3c'\nData_39.ix[ (Data_39.percentile ==5 ), ['color'] ] = '#fc4e2a'\n\nm = folium.Map(\n    width='100%', \n    height='100%',\n    location=[34.29, -119.13],\n    min_lat=lat_Min, max_lat=lat_Max, min_lon=lon_Min, max_lon=lon_Max,\n    zoom_start=8,\n)\nfolium.PolyLine([[-119.447353,33.340239],[-117.561077,34.799328]]).add_to(m)\n\nData_39.dropna(subset = ['lat'])\nData_39.dropna(subset = ['lon'])\n\nData_39.apply(lambda row:folium.CircleMarker(location=[row[\"lat\"], \n                                                  row[\"lon\"]], color= row[\"color\"]).add_to(m),\n         axis=1)\nm","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}