{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nCreates a EfficientNetV2 Model as defined in:\nMingxing Tan, Quoc V. Le. (2021). \nEfficientNetV2: Smaller Models and Faster Training\narXiv preprint arXiv:2104.00298.\nimport from https://github.com/d-li14/mobilenetv2.pytorch\n\"\"\"\n\nimport torch\nimport torch.nn as nn\nimport math\n\n__all__ = ['effnetv2_s', 'effnetv2_m', 'effnetv2_l', 'effnetv2_xl']\n\n\ndef _make_divisible(v, divisor, min_value=None):\n    \"\"\"\n    This function is taken from the original tf repo.\n    It ensures that all layers have a channel number that is divisible by 8\n    It can be seen here:\n    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n    :param v:\n    :param divisor:\n    :param min_value:\n    :return:\n    \"\"\"\n    if min_value is None:\n        min_value = divisor\n    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n    # Make sure that round down does not go down by more than 10%.\n    if new_v < 0.9 * v:\n        new_v += divisor\n    return new_v\n\n\n# SiLU (Swish) activation function\nif hasattr(nn, 'SiLU'):\n    SiLU = nn.SiLU\nelse:\n    # For compatibility with old PyTorch versions\n    class SiLU(nn.Module):\n        def forward(self, x):\n            return x * torch.sigmoid(x)\n\nclass SELayer(nn.Module):\n    def __init__(self, inp, oup, reduction=4):\n        super(SELayer, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Sequential(\n                nn.Linear(oup, _make_divisible(inp // reduction, 8)),\n                SiLU(),\n                nn.Linear(_make_divisible(inp // reduction, 8), oup),\n                nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        b, c, _, _ = x.size()\n        y = self.avg_pool(x).view(b, c)\n        y = self.fc(y).view(b, c, 1, 1)\n        return x * y\n\n\ndef conv_3x3_bn(inp, oup, stride):\n    return nn.Sequential(\n        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n        nn.BatchNorm2d(oup),\n        SiLU()\n    )\n\n\ndef conv_1x1_bn(inp, oup):\n    return nn.Sequential(\n        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n        nn.BatchNorm2d(oup),\n        SiLU()\n    )\n\n\nclass MBConv(nn.Module):\n    def __init__(self, inp, oup, stride, expand_ratio, use_se):\n        super(MBConv, self).__init__()\n        assert stride in [1, 2]\n\n        hidden_dim = round(inp * expand_ratio)\n        self.identity = stride == 1 and inp == oup\n        if use_se:\n            self.conv = nn.Sequential(\n                # pw\n                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                SiLU(),\n                # dw\n                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                SiLU(),\n                SELayer(inp, hidden_dim),\n                # pw-linear\n                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n            )\n        else:\n            self.conv = nn.Sequential(\n                # fused\n                nn.Conv2d(inp, hidden_dim, 3, stride, 1, bias=False),\n                nn.BatchNorm2d(hidden_dim),\n                SiLU(),\n                # pw-linear\n                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n                nn.BatchNorm2d(oup),\n            )\n\n\n    def forward(self, x):\n        if self.identity:\n            return x + self.conv(x)\n        else:\n            return self.conv(x)\n\n\nclass EffNetV2(nn.Module):\n    def __init__(self, cfgs, num_classes=1000, width_mult=1.):\n        super(EffNetV2, self).__init__()\n        self.cfgs = cfgs\n\n        # building first layer\n        input_channel = _make_divisible(24 * width_mult, 8)\n        layers = [conv_3x3_bn(3, input_channel, 2)]\n        # building inverted residual blocks\n        block = MBConv\n        for t, c, n, s, use_se in self.cfgs:\n            output_channel = _make_divisible(c * width_mult, 8)\n            for i in range(n):\n                layers.append(block(input_channel, output_channel, s if i == 0 else 1, t, use_se))\n                input_channel = output_channel\n        self.features = nn.Sequential(*layers)\n        # building last several layers\n        output_channel = _make_divisible(1792 * width_mult, 8) if width_mult > 1.0 else 1792\n        self.conv = conv_1x1_bn(input_channel, output_channel)\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.classifier = nn.Linear(output_channel, num_classes)\n\n        self._initialize_weights()\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.conv(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.classifier(x)\n        return x\n\n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n                m.weight.data.normal_(0, math.sqrt(2. / n))\n                if m.bias is not None:\n                    m.bias.data.zero_()\n            elif isinstance(m, nn.BatchNorm2d):\n                m.weight.data.fill_(1)\n                m.bias.data.zero_()\n            elif isinstance(m, nn.Linear):\n                m.weight.data.normal_(0, 0.001)\n                m.bias.data.zero_()\n\n\ndef effnetv2_s(**kwargs):\n    \"\"\"\n    Constructs a EfficientNetV2-S model\n    \"\"\"\n    cfgs = [\n        # t, c, n, s, SE\n        [1,  24,  2, 1, 0],\n        [4,  48,  4, 2, 0],\n        [4,  64,  4, 2, 0],\n        [4, 128,  6, 2, 1],\n        [6, 160,  9, 1, 1],\n        [6, 256, 15, 2, 1],\n    ]\n    return EffNetV2(cfgs, **kwargs)\n\n\ndef effnetv2_m(**kwargs):\n    \"\"\"\n    Constructs a EfficientNetV2-M model\n    \"\"\"\n    cfgs = [\n        # t, c, n, s, SE\n        [1,  24,  3, 1, 0],\n        [4,  48,  5, 2, 0],\n        [4,  80,  5, 2, 0],\n        [4, 160,  7, 2, 1],\n        [6, 176, 14, 1, 1],\n        [6, 304, 18, 2, 1],\n        [6, 512,  5, 1, 1],\n    ]\n    return EffNetV2(cfgs, **kwargs)\n\n\ndef effnetv2_l(**kwargs):\n    \"\"\"\n    Constructs a EfficientNetV2-L model\n    \"\"\"\n    cfgs = [\n        # t, c, n, s, SE\n        [1,  32,  4, 1, 0],\n        [4,  64,  7, 2, 0],\n        [4,  96,  7, 2, 0],\n        [4, 192, 10, 2, 1],\n        [6, 224, 19, 1, 1],\n        [6, 384, 25, 2, 1],\n        [6, 640,  7, 1, 1],\n    ]\n    return EffNetV2(cfgs, **kwargs)\n\n\ndef effnetv2_xl(**kwargs):\n    \"\"\"\n    Constructs a EfficientNetV2-XL model\n    \"\"\"\n    cfgs = [\n        # t, c, n, s, SE\n        [1,  32,  4, 1, 0],\n        [4,  64,  8, 2, 0],\n        [4,  96,  8, 2, 0],\n        [4, 192, 16, 2, 1],\n        [6, 256, 24, 1, 1],\n        [6, 512, 32, 2, 1],\n        [6, 640,  8, 1, 1],\n    ]\n    return EffNetV2(cfgs, **kwargs)","metadata":{"execution":{"iopub.status.busy":"2021-09-22T08:18:25.261442Z","iopub.execute_input":"2021-09-22T08:18:25.262017Z","iopub.status.idle":"2021-09-22T08:18:26.495269Z","shell.execute_reply.started":"2021-09-22T08:18:25.261929Z","shell.execute_reply":"2021-09-22T08:18:26.494436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport json\nimport glob\nimport random\nimport collections\n\nimport numpy as np\nimport pandas as pd\nimport pydicom as dicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-09-22T08:18:26.496522Z","iopub.execute_input":"2021-09-22T08:18:26.496948Z","iopub.status.idle":"2021-09-22T08:18:27.794784Z","shell.execute_reply.started":"2021-09-22T08:18:26.496919Z","shell.execute_reply":"2021-09-22T08:18:27.793978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys \n\nimport time\n\nimport torch\nfrom torch import nn\nfrom torch.utils import data as torch_data\nfrom sklearn import model_selection as sk_model_selection\nfrom torch.nn import functional as torch_functional\n\n#from sklearn.model_selection import StratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2021-09-22T08:18:27.79635Z","iopub.execute_input":"2021-09-22T08:18:27.796794Z","iopub.status.idle":"2021-09-22T08:18:27.973737Z","shell.execute_reply.started":"2021-09-22T08:18:27.796764Z","shell.execute_reply":"2021-09-22T08:18:27.972522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Support Function","metadata":{}},{"cell_type":"code","source":"def load_dicom(path):\n    image = dicom.read_file(path)\n    data = image.pixel_array\n    data = data - np.min(data)\n    if(np.max(data) != 0):\n        data = data/np.max(data)\n    data = (data *256).astype(np.uint8)\n    data = cv2.resize(data, (256, 256))\n    data = cv2.cvtColor(data,cv2.COLOR_GRAY2RGB)\n    return data","metadata":{"execution":{"iopub.status.busy":"2021-09-22T08:18:27.975394Z","iopub.execute_input":"2021-09-22T08:18:27.975706Z","iopub.status.idle":"2021-09-22T08:18:27.983289Z","shell.execute_reply.started":"2021-09-22T08:18:27.975669Z","shell.execute_reply":"2021-09-22T08:18:27.981865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def is_valid_image(path, threshold=32768):\n    data = load_dicom(path)\n    if (np.count_nonzero(data) > threshold):\n        return True\n    else:\n        return False","metadata":{"execution":{"iopub.status.busy":"2021-09-22T08:18:27.984856Z","iopub.execute_input":"2021-09-22T08:18:27.985221Z","iopub.status.idle":"2021-09-22T08:18:27.996707Z","shell.execute_reply.started":"2021-09-22T08:18:27.985186Z","shell.execute_reply":"2021-09-22T08:18:27.995488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n\nset_seed(42)","metadata":{"execution":{"iopub.status.busy":"2021-09-22T08:18:27.997905Z","iopub.execute_input":"2021-09-22T08:18:27.99826Z","iopub.status.idle":"2021-09-22T08:18:28.017717Z","shell.execute_reply.started":"2021-09-22T08:18:27.998227Z","shell.execute_reply":"2021-09-22T08:18:28.016317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualize on labels","metadata":{}},{"cell_type":"code","source":"class DataCustomer(torch_data.Dataset):\n    def __init__(self, paths, labels):\n        self.paths = paths\n        self.labels = labels\n    def __len__(self):\n        return len(self.labels)\n    def __getitem__(self, index):\n        data_path = self.paths[index]\n        data = load_dicom(data_path)\n        data = torch.tensor(data).float()\n        \n        data = torch.reshape(data, (3,256,256))\n        Y = torch.tensor(self.labels[index]).float()\n        return {\"X\":data, \"y\":Y}","metadata":{"execution":{"iopub.status.busy":"2021-09-22T08:18:28.019387Z","iopub.execute_input":"2021-09-22T08:18:28.019734Z","iopub.status.idle":"2021-09-22T08:18:28.030774Z","shell.execute_reply.started":"2021-09-22T08:18:28.019701Z","shell.execute_reply":"2021-09-22T08:18:28.029751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LossMeter:\n    def __init__(self):\n        self.avg = 0\n        self.n = 0\n\n    def update(self, val):\n        self.n += 1\n        # incremental update\n        self.avg = val / self.n + (self.n - 1) / self.n * self.avg\n\n        \nclass AccMeter:\n    def __init__(self):\n        self.avg = 0\n        self.n = 0\n        \n    def update(self, y_true, y_pred):\n        y_true = y_true.cpu().numpy().astype(int)\n        y_pred = y_pred.cpu().numpy() >= 0\n        last_n = self.n\n        self.n += len(y_true)\n        true_count = np.sum(y_true == y_pred)\n        # incremental update\n        self.avg = true_count / self.n + last_n / self.n * self.avg","metadata":{"execution":{"iopub.status.busy":"2021-09-22T08:18:28.032691Z","iopub.execute_input":"2021-09-22T08:18:28.033184Z","iopub.status.idle":"2021-09-22T08:18:28.052561Z","shell.execute_reply.started":"2021-09-22T08:18:28.033127Z","shell.execute_reply":"2021-09-22T08:18:28.051177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Trainer:\n    def __init__(\n        self, \n        model, \n        device, \n        optimizer, \n        criterion, \n        loss_meter, \n        score_meter\n    ):\n        self.model = model\n        self.device = device\n        self.optimizer = optimizer\n        self.criterion = criterion\n        self.loss_meter = loss_meter\n        self.score_meter = score_meter\n        \n        self.best_valid_score = -np.inf\n        self.n_patience = 0\n        \n        self.messages = {\n            \"epoch\": \"[Epoch {}: {}] loss: {:.5f}, score: {:.5f}, time: {} s\",\n            \"checkpoint\": \"The score improved from {:.5f} to {:.5f}. Save model to '{}'\",\n            \"patience\": \"\\nValid score didn't improve last {} epochs.\"\n        }\n    \n    def fit(self, epochs, train_loader, valid_loader, save_path, patience):        \n        for n_epoch in range(1, epochs + 1):\n            self.info_message(\"EPOCH: {}\", n_epoch)\n            \n            train_loss, train_score, train_time = self.train_epoch(train_loader)\n            valid_loss, valid_score, valid_time = self.valid_epoch(valid_loader)\n            \n            self.info_message(\n                self.messages[\"epoch\"], \"Train\", n_epoch, train_loss, train_score, train_time\n            )\n            \n            self.info_message(\n                self.messages[\"epoch\"], \"Valid\", n_epoch, valid_loss, valid_score, valid_time\n            )\n\n            if True:\n#             if self.best_valid_score < valid_score:\n                self.info_message(\n                    self.messages[\"checkpoint\"], self.best_valid_score, valid_score, save_path\n                )\n                self.best_valid_score = valid_score\n                self.save_model(n_epoch, save_path)\n                self.n_patience = 0\n            else:\n                self.n_patience += 1\n            \n            if self.n_patience >= patience:\n                self.info_message(self.messages[\"patience\"], patience)\n                break\n            \n    def train_epoch(self, train_loader):\n        self.model.train()\n        t = time.time()\n        train_loss = self.loss_meter()\n        train_score = self.score_meter()\n        \n        for step, batch in enumerate(train_loader, 1):\n            X = batch[\"X\"].to(self.device)\n            targets = batch[\"y\"].to(self.device)\n            self.optimizer.zero_grad()\n            outputs = torch.sigmoid(self.model(X)).squeeze(1)\n            \n            loss = self.criterion(outputs, targets)\n            loss.backward()\n\n            train_loss.update(loss.detach().item())\n            train_score.update(targets, outputs.detach())\n\n            self.optimizer.step()\n            \n            _loss, _score = train_loss.avg, train_score.avg\n            message = 'Train Step {}/{}, train_loss: {:.5f}, train_score: {:.5f}'\n            self.info_message(message, step, len(train_loader), _loss, _score, end=\"\\r\")\n        \n        return train_loss.avg, train_score.avg, int(time.time() - t)\n    \n    def valid_epoch(self, valid_loader):\n        self.model.eval()\n        t = time.time()\n        valid_loss = self.loss_meter()\n        valid_score = self.score_meter()\n\n        for step, batch in enumerate(valid_loader, 1):\n            with torch.no_grad():\n                X = batch[\"X\"].to(self.device)\n                targets = batch[\"y\"].to(self.device)\n                \n                #torch.sigmoid(model(batch[\"X\"].to(device)))\n                \n                outputs = torch.sigmoid(self.model(X)).squeeze(1)\n                loss = self.criterion(outputs, targets)\n\n                valid_loss.update(loss.detach().item())\n                valid_score.update(targets, outputs)\n                \n            _loss, _score = valid_loss.avg, valid_score.avg\n            message = 'Valid Step {}/{}, valid_loss: {:.5f}, valid_score: {:.5f}'\n            self.info_message(message, step, len(valid_loader), _loss, _score, end=\"\\r\")\n        \n        return valid_loss.avg, valid_score.avg, int(time.time() - t)\n    \n    def save_model(self, n_epoch, save_path):\n        torch.save(\n            {\n                \"model_state_dict\": self.model.state_dict(),\n                \"optimizer_state_dict\": self.optimizer.state_dict(),\n                \"best_valid_score\": self.best_valid_score,\n                \"n_epoch\": n_epoch,\n            },\n            save_path,\n        )\n    \n    @staticmethod\n    def info_message(message, *args, end=\"\\n\"):\n        print(message.format(*args), end=end)","metadata":{"execution":{"iopub.status.busy":"2021-09-22T08:18:28.05574Z","iopub.execute_input":"2021-09-22T08:18:28.056259Z","iopub.status.idle":"2021-09-22T08:18:28.085176Z","shell.execute_reply.started":"2021-09-22T08:18:28.056206Z","shell.execute_reply":"2021-09-22T08:18:28.084018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/dfdxinnhathemattroi/filetrainxin.csv\", index_col = False)\n\nindx = df['patient_id'].unique()\nindx_train, indx_val = sk_model_selection.train_test_split(\n    indx,\n    test_size = 0.2,\n    random_state = 42,\n)\ndf_train = df[df['patient_id'].isin(indx_train)]\ndf_valid = df[df['patient_id'].isin(indx_val)]\ndisplay(len(df_train['patient_id'].unique()))\ndisplay(len(df_valid['patient_id'].unique()))","metadata":{"execution":{"iopub.status.busy":"2021-09-22T08:18:28.087194Z","iopub.execute_input":"2021-09-22T08:18:28.087562Z","iopub.status.idle":"2021-09-22T08:18:30.114898Z","shell.execute_reply.started":"2021-09-22T08:18:28.087515Z","shell.execute_reply":"2021-09-22T08:18:30.113889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# #device = \"cpu\"\n\n\n# train_data_retriever = DataCustomer(\n#     df_train[\"file_paths\"].values, \n#     df_train[\"label\"].values, \n# )\n\n# valid_data_retriever = DataCustomer(\n#     df_valid[\"file_paths\"].values, \n#     df_valid[\"label\"].values,\n# )\n\n# train_loader = torch_data.DataLoader(\n#     train_data_retriever,\n#     batch_size=64,\n#     shuffle=True,\n#     num_workers=8,\n# )\n\n# valid_loader = torch_data.DataLoader(\n#     valid_data_retriever, \n#     batch_size=64,\n#     shuffle=False,\n#     num_workers=8,\n# )\n\n# model = effnetv2_s(num_classes = 1)\n# model.to(device)\n\n# checkpoint = torch.load(\"../input/v336epoch/best-modelv3.pth\")\n# model.load_state_dict(checkpoint[\"model_state_dict\"])\n\n# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n# criterion = torch_functional.binary_cross_entropy_with_logits\n\n# trainer = Trainer(\n#     model, \n#     device, \n#     optimizer, \n#     criterion, \n#     LossMeter, \n#     AccMeter\n# )\n\n# history = trainer.fit(\n#     7, \n#     train_loader, \n#     valid_loader, \n#     \"best-modelv4.pth\", \n#     100,\n# )","metadata":{"execution":{"iopub.status.busy":"2021-09-22T03:10:37.774609Z","iopub.execute_input":"2021-09-22T03:10:37.775029Z","iopub.status.idle":"2021-09-22T03:10:37.780946Z","shell.execute_reply.started":"2021-09-22T03:10:37.774967Z","shell.execute_reply":"2021-09-22T03:10:37.779857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# FILTER TESTDATA WITH THRESHOLD = 10 AND ONLY USE T2w SCAN TYPE","metadata":{}},{"cell_type":"code","source":"sample_df = pd.read_csv('../input/dfdxinnhathemattroi/filetestxin.csv', index_col = False)\nsample_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-09-22T08:18:37.908002Z","iopub.execute_input":"2021-09-22T08:18:37.908425Z","iopub.status.idle":"2021-09-22T08:18:38.048206Z","shell.execute_reply.started":"2021-09-22T08:18:37.908389Z","shell.execute_reply":"2021-09-22T08:18:38.047025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp = sample_df.paths.values\ntmp[0]","metadata":{"execution":{"iopub.status.busy":"2021-09-22T08:18:41.049636Z","iopub.execute_input":"2021-09-22T08:18:41.050076Z","iopub.status.idle":"2021-09-22T08:18:41.058098Z","shell.execute_reply.started":"2021-09-22T08:18:41.05004Z","shell.execute_reply":"2021-09-22T08:18:41.056452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_PATH_TEST = \"../input/rsna-miccai-brain-tumor-radiogenomic-classification/test\"\nf = []\nfor (dirpath, dirnames, filenames) in os.walk(IMG_PATH_TEST):\n    f.extend(os.path.join(dirpath, x) for x in filenames)\n    \ntest_file_paths_df = pd.DataFrame({'file_paths': f})\ntest_file_paths_df['directory'] = IMG_PATH_TEST\ntest_file_paths_df['dataset'] = test_file_paths_df['file_paths'].str.split(\"/\", n = 7, expand = True)[3]\ntest_file_paths_df['patient_id'] = test_file_paths_df['file_paths'].str.split(\"/\", n = 7, expand = True)[4]\ntest_file_paths_df['scan_type'] = test_file_paths_df['file_paths'].str.split(\"/\", n = 7, expand = True)[5]\ntest_file_paths_df['file'] = test_file_paths_df['file_paths'].str.split(\"/\", n = 7, expand = True)[6]\ndisplay(test_file_paths_df.head(2))\ntest_file_paths_df.shape[0]","metadata":{"execution":{"iopub.status.busy":"2021-09-22T08:19:00.890694Z","iopub.execute_input":"2021-09-22T08:19:00.89134Z","iopub.status.idle":"2021-09-22T08:19:13.407658Z","shell.execute_reply.started":"2021-09-22T08:19:00.891281Z","shell.execute_reply":"2021-09-22T08:19:13.406465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df=test_file_paths_df[test_file_paths_df['file_paths'].isin(tmp)]\ndisplay(test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-22T08:19:13.410151Z","iopub.execute_input":"2021-09-22T08:19:13.41061Z","iopub.status.idle":"2021-09-22T08:19:13.468294Z","shell.execute_reply.started":"2021-09-22T08:19:13.410563Z","shell.execute_reply":"2021-09-22T08:19:13.467093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodels = []\nfor i in range(1):\n    model = effnetv2_s(num_classes = 1)\n    model.to(device)\n    \n    checkpoint = torch.load(\"../input/v557epoch/v5-57epoch.pth\",map_location=torch.device('cpu'))\n    model.load_state_dict(checkpoint[\"model_state_dict\"])\n    model.eval()\n    \n    models.append(model)","metadata":{"execution":{"iopub.status.busy":"2021-09-22T08:19:22.238444Z","iopub.execute_input":"2021-09-22T08:19:22.238853Z","iopub.status.idle":"2021-09-22T08:19:27.124205Z","shell.execute_reply.started":"2021-09-22T08:19:22.238819Z","shell.execute_reply":"2021-09-22T08:19:27.123305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_id = test_df['patient_id'].map(int).tolist()","metadata":{"execution":{"iopub.status.busy":"2021-09-22T08:19:49.350923Z","iopub.execute_input":"2021-09-22T08:19:49.351508Z","iopub.status.idle":"2021-09-22T08:19:49.369813Z","shell.execute_reply.started":"2021-09-22T08:19:49.351469Z","shell.execute_reply":"2021-09-22T08:19:49.36858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestDataCustomer(torch_data.Dataset):\n    def __init__(self, paths):\n        self.paths = paths\n        \n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self, index):\n        data_path = self.paths[index]\n        data = load_dicom(data_path)\n        \n        data = torch.tensor(data).float()\n        data = torch.reshape(data, (3,256,256))\n        \n        return {\"X\": data, \"id\": _id[index]}","metadata":{"execution":{"iopub.status.busy":"2021-09-22T08:19:49.764005Z","iopub.execute_input":"2021-09-22T08:19:49.764427Z","iopub.status.idle":"2021-09-22T08:19:49.772152Z","shell.execute_reply.started":"2021-09-22T08:19:49.764366Z","shell.execute_reply":"2021-09-22T08:19:49.771328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv\")\n\ntest_data_retriever = TestDataCustomer( \n    test_df['file_paths'].values,\n)\n\ntest_loader = torch_data.DataLoader(\n    test_data_retriever,\n    batch_size=64,\n    shuffle=False,\n    num_workers=8,\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-22T08:20:08.963076Z","iopub.execute_input":"2021-09-22T08:20:08.963495Z","iopub.status.idle":"2021-09-22T08:20:08.979058Z","shell.execute_reply.started":"2021-09-22T08:20:08.963459Z","shell.execute_reply":"2021-09-22T08:20:08.977806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = []\nids = []\n\nfor e, batch in enumerate(test_loader):\n    print(f\"{e}/{len(test_loader)}\", end=\"\\r\")\n    with torch.no_grad():\n        tmp_pred = np.zeros((batch[\"X\"].shape[0], ))\n        for model in models:\n            tmp_res = torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n            tmp_pred += tmp_res\n        y_pred.extend(tmp_pred)\n        ids.extend(batch[\"id\"].numpy().tolist())","metadata":{"execution":{"iopub.status.busy":"2021-09-22T08:20:09.182215Z","iopub.execute_input":"2021-09-22T08:20:09.182592Z","iopub.status.idle":"2021-09-22T08:20:39.339912Z","shell.execute_reply.started":"2021-09-22T08:20:09.182561Z","shell.execute_reply":"2021-09-22T08:20:39.337604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\"BraTS21ID\": ids, \"MGMT_value\": y_pred})\nsubmission = submission.groupby(['BraTS21ID'], as_index = False).median()\nsubmission.to_csv(\"submission.csv\",float_format='{:.1f}'.format, encoding='utf-8', index=False)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2021-09-21T13:23:20.29215Z","iopub.status.idle":"2021-09-21T13:23:20.292654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(5, 5))\nplt.hist(submission[\"MGMT_value\"]);","metadata":{"execution":{"iopub.status.busy":"2021-09-21T13:23:20.293925Z","iopub.status.idle":"2021-09-21T13:23:20.294461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## WORK IN PROGRESS...","metadata":{}},{"cell_type":"code","source":"# # def is_valid_image(path, threshold=10):\n# #     data = load_dicom(path)\n# #     if np.mean(data)<threshold:\n# #         return False\n# #     else:\n# #         return True\n\n\n# def change_path(path):\n#     path = path.replace(\"rsna-miccai-png\",\"rsna-miccai-brain-tumor-radiogenomic-classification\")\n#     path = path.replace(\".png\", \".dcm\")\n#     return path","metadata":{"execution":{"iopub.status.busy":"2021-09-21T13:23:20.295628Z","iopub.status.idle":"2021-09-21T13:23:20.296075Z"},"trusted":true},"execution_count":null,"outputs":[]}]}