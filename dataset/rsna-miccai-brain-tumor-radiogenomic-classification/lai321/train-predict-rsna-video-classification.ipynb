{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Copy from [[PyTorch Train] RSNA Video Classification + W&B üöÄ](https://www.kaggle.com/heyytanay/pytorch-train-rsna-video-classification-w-b) and edit for running without Internet.","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-success\">\n    <h2 align='center'>üìî Imports and Installation</h2>\n</div>","metadata":{}},{"cell_type":"markdown","source":"[](https://www.kaggle.com/heyytanay/pytorch-train-rsna-video-classification-w-b)","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-09-13T10:26:51.483593Z","iopub.execute_input":"2021-09-13T10:26:51.484091Z","iopub.status.idle":"2021-09-13T10:26:51.491396Z","shell.execute_reply.started":"2021-09-13T10:26:51.484056Z","shell.execute_reply":"2021-09-13T10:26:51.489608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nimport re\nimport gc\nimport platform\nimport random\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\n#import einops\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nimport json\n\nimport glob\nimport cv2\n\n#from rich import print as _pprint\n#from rich.progress import track\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n#import wandb\n\nimport warnings\nwarnings.simplefilter('ignore')","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:26:51.493786Z","iopub.execute_input":"2021-09-13T10:26:51.494504Z","iopub.status.idle":"2021-09-13T10:26:51.508534Z","shell.execute_reply.started":"2021-09-13T10:26:51.494326Z","shell.execute_reply":"2021-09-13T10:26:51.507054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-success\">\n    <h2 align='center'>‚õΩ Utility Functions </h2>\n</div>","metadata":{}},{"cell_type":"code","source":"if os.path.exists(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification\"):\n    data_directory = '../input/rsna-miccai-brain-tumor-radiogenomic-classification'\n    pytorch3dpath = \"../input/efficientnetpyttorch3d/EfficientNet-PyTorch-3D\"\nelse:\n    data_directory = '/media/roland/data/kaggle/rsna-miccai-brain-tumor-radiogenomic-classification'\n    pytorch3dpath = \"EfficientNet-PyTorch-3D\"","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:26:51.51117Z","iopub.execute_input":"2021-09-13T10:26:51.51168Z","iopub.status.idle":"2021-09-13T10:26:51.520248Z","shell.execute_reply.started":"2021-09-13T10:26:51.511619Z","shell.execute_reply":"2021-09-13T10:26:51.519011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mri_types=['FLAIR']\n\ndef get_patient_id(patient_id):\n    res=str(int(patient_id)).zfill(5)\n    return res\n    \n\ndef get_path(row,is_test=False,mri_type=mri_types[0]):\n    patient_id = get_patient_id(row.BraTS21ID)\n    if is_test:\n        path=f'../input/rsna-miccai-png/test/{patient_id}/{mri_type}/'\n    else:\n        path=f'../input/rsna-miccai-png/train/{patient_id}/{mri_type}/'\n    return path\n\ndef wandb_log(**kwargs):\n    \"\"\"\n    Logs a key-value pair to W&B\n    \"\"\"\n    for k, v in kwargs.items():\n        wandb.log({k: v})\n        \ndef cprint(string):\n    \"\"\"\n    Utility function for beautiful colored printing.\n    \"\"\"\n    print(f\"[black]{string}[/black]\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-13T10:26:51.52304Z","iopub.execute_input":"2021-09-13T10:26:51.523381Z","iopub.status.idle":"2021-09-13T10:26:51.537385Z","shell.execute_reply.started":"2021-09-13T10:26:51.523336Z","shell.execute_reply":"2021-09-13T10:26:51.535756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-success\">\n    <h2 align='center'>üöÄ Config Dictionary and W&B Integration </h2>\n</div>","metadata":{}},{"cell_type":"code","source":"Config = dict(\n    MAX_FRAMES = 12,\n    EPOCHS = 15,\n    LR = 1.2e-5,\n    IMG_SIZE = (224, 224),\n    FEATURE_EXTRACTOR = 'resnet34',\n    DR_RATE = 0.35,\n    NUM_CLASSES = 1,\n    RNN_HIDDEN_SIZE = 100,\n    RNN_LAYERS = 1,\n    TRAIN_BS = 8,\n    VALID_BS = 4,\n    NUM_WORKERS = 2,\n    infra = \"Kaggle\",\n    competition = 'rsna_miccai',\n    _wandb_kernel = 'tanaym'\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:26:51.539386Z","iopub.execute_input":"2021-09-13T10:26:51.540224Z","iopub.status.idle":"2021-09-13T10:26:51.549378Z","shell.execute_reply.started":"2021-09-13T10:26:51.540177Z","shell.execute_reply":"2021-09-13T10:26:51.548158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Augments:\n    \"\"\"\n    Contains Train, Validation Augments\n    \"\"\"\n    train_augments = A.Compose([\n        ToTensorV2(p=1.0),\n    ],p=1.)\n    \n    valid_augments = A.Compose([\n        ToTensorV2(p=1.0),\n    ], p=1.)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:26:51.551394Z","iopub.execute_input":"2021-09-13T10:26:51.552112Z","iopub.status.idle":"2021-09-13T10:26:51.560902Z","shell.execute_reply.started":"2021-09-13T10:26:51.552068Z","shell.execute_reply":"2021-09-13T10:26:51.5597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-success\">\n    <h2 align='center'>üíª Custom Dataset Class</h2>\n</div>\n\n<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:verdana; line-height: 1.7em;\">\n    üìå In this custom Dataset, I am essentially reading \"MAX_FRAMES\" number of images from a patient's FLAIR folder and making list of those frames and converting it to torch tensor.\n</div>","metadata":{}},{"cell_type":"code","source":"class RSNADataset(Dataset):\n    def __init__(self, df, augments=None, is_test=False):\n        self.df = df\n        self.augments = augments\n        self.is_test = is_test\n        \n    def __getitem__(self, idx):\n        row = self.df.loc[idx]\n        paths = self.getPaths(row)\n        frames = []\n        for path in paths:\n            img = cv2.imread(path)\n            img = cv2.resize(img, Config['IMG_SIZE'])\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n            frames.append(img)\n\n        frames_tr = np.stack(frames, axis=2)\n        #frames_tr = np.asarray(frames_tr,dtype=int)\n        if self.augments:\n            for frame in frames:\n                frame = self.augments(image=frame)['image']\n                frames_tr.append(frame)\n            \n        if self.is_test:\n            return frames_tr,idx\n        else:\n            label = torch.tensor(row['MGMT_value']).float()\n            return frames_tr, label\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def getPaths(self, row):\n        paths = glob.glob(row['path'] + '*.png')\n        sortedPaths = self.sort(paths)\n        maxWindowStart = len(sortedPaths) - Config['MAX_FRAMES']\n        start = 0 # np.random.randint(1, maxWindowStart)\n        paths = sortedPaths[start:Config['MAX_FRAMES']]\n        \n        return paths\n        \n    def sort(self, entry):\n        # https://stackoverflow.com/a/2669120/7636462\n        convert = lambda text: int(text) if text.isdigit() else text \n        alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n    \n        return sorted(entry, key = alphanum_key)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:26:51.565161Z","iopub.execute_input":"2021-09-13T10:26:51.565545Z","iopub.status.idle":"2021-09-13T10:26:51.58058Z","shell.execute_reply.started":"2021-09-13T10:26:51.565514Z","shell.execute_reply":"2021-09-13T10:26:51.579041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-success\">\n    <h2 align='center'>üìà Model Class with ResNext Backbone</h2>\n</div>","metadata":{}},{"cell_type":"code","source":"with open('../input/timm-pretrained-resnet/index.json','r') as f:\n    index=json.load(f)\n    \nbackstone=Config['FEATURE_EXTRACTOR']\nwhere=index['resnet'][backstone]","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:26:51.734474Z","iopub.execute_input":"2021-09-13T10:26:51.734837Z","iopub.status.idle":"2021-09-13T10:26:51.741988Z","shell.execute_reply.started":"2021-09-13T10:26:51.734806Z","shell.execute_reply":"2021-09-13T10:26:51.740591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass ResNextModel(nn.Module):\n    def __init__(self):\n        super(ResNextModel, self).__init__()\n        self.backbone = timm.create_model(backstone, pretrained=False, in_chans=1)\n        pretrained=f'../input/timm-pretrained-resnet/resnet/{where}'\n        state_dict=torch.load(pretrained)\n        conv1_weight = state_dict['conv1.weight']\n        state_dict['conv1.weight'] = conv1_weight.sum(dim=1, keepdim=True)\n        self.backbone.load_state_dict(state_dict)\n    def forward(self, x):\n        return self.backbone(x)\n\nclass Identity(nn.Module):\n    def __init__(self):\n        super(Identity, self).__init__()\n    def forward(self, x):\n        return x\n\nclass RSNAModel(nn.Module):\n    def __init__(self, pretrained=True):\n        super(RSNAModel, self).__init__()\n        self.backbone = ResNextModel()\n        num_features = self.backbone.backbone.fc.in_features\n        \n        self.backbone.backbone.fc = Identity()\n        self.dropout= nn.Dropout(Config['DR_RATE'])\n        self.rnn = nn.LSTM(num_features, Config['RNN_HIDDEN_SIZE'], Config['RNN_LAYERS'])\n        self.fc1 = nn.Linear(Config['RNN_HIDDEN_SIZE'], Config['NUM_CLASSES'])\n        \n    def forward(self, x):\n        b_z, fr, h, w = x.shape\n        ii = 0\n        in_pass = x[:, ii].unsqueeze_(1)\n        y = self.backbone((in_pass))\n        output, (hn, cn) = self.rnn(y.unsqueeze(1))\n        for ii in range(1, fr):\n            y = self.backbone((x[:, ii].unsqueeze_(1)))\n            out, (hn, cn) = self.rnn(y.unsqueeze(1), (hn, cn))\n        out = self.dropout(out[:, -1])\n        out = self.fc1(out)\n        out = torch.sigmoid(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:26:51.744513Z","iopub.execute_input":"2021-09-13T10:26:51.745466Z","iopub.status.idle":"2021-09-13T10:26:51.769226Z","shell.execute_reply.started":"2021-09-13T10:26:51.745361Z","shell.execute_reply":"2021-09-13T10:26:51.767721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-success\">\n    <h2 align='center'>üè¥‚Äç‚ò†Ô∏è Training and Validation Functions</h2>\n</div>","metadata":{}},{"cell_type":"code","source":"def train_one_epoch(model, train_dataloader, optimizer, loss_fn, epoch, device, log_wandb=True, verbose=False):\n    \"\"\"\n    Trains model for one epoch\n    \"\"\"\n    model.train()\n    running_loss = 0\n    prog_bar = tqdm(enumerate(train_dataloader), total=len(train_dataloader))\n    for batch, (frames, targets) in prog_bar:\n        optimizer.zero_grad()\n        \n        frames = frames.to(device, torch.float)\n        targets = targets.to(device, torch.float)\n        #print(frames.shape)\n        # Re arrange the frames in the format our model wants to recieve\n        #frames = einops.rearrange(frames, 'b h w f -> b f h w')\n        frames = frames.permute(0,3,1,2)\n        preds = model(frames).view(-1)\n        del frames\n        gc.collect()\n        loss = loss_fn(preds, targets)\n        \n        loss.backward()\n        optimizer.step()\n        \n        loss_item = loss.item()\n        running_loss += loss_item\n        \n        prog_bar.set_description(f\"loss: {loss_item:.4f}\")\n        \n        if log_wandb == True:\n            wandb_log(\n                batch_train_loss=loss_item\n            )\n        \n        if verbose == True and batch % 20 == 0:\n            print(f\"Batch: {batch}, Loss: {loss_item}\")\n    \n    avg_loss = running_loss / len(train_dataloader)\n    \n    return avg_loss\n\n@torch.no_grad()\ndef valid_one_epoch(model, valid_dataloader, loss_fn, epoch, device, log_wandb=True, verbose=False):\n    \"\"\"\n    Validates the model for one epoch\n    \"\"\"\n    model.eval()\n    running_loss = 0\n    prog_bar = tqdm(enumerate(valid_dataloader), total=len(valid_dataloader))\n    \n    for batch, (frames, targets) in prog_bar:\n        frames = frames.to(device, torch.float)\n        targets = targets.to(device, torch.float)\n\n        # Re arrange the frames in the format our model wants to recieve\n        #frames = einops.rearrange(frames, 'b h w f -> b f h w')\n        frames = frames.permute(0,3,1,2)\n        preds = model(frames).view(-1)\n        del frames\n        gc.collect()\n        loss = loss_fn(preds, targets)\n        loss_item = loss.item()\n        running_loss += loss_item\n\n        prog_bar.set_description(f\"val_loss: {loss_item:.4f}\")\n\n        if log_wandb == True:\n            wandb_log(\n                batch_val_loss=loss_item\n            )\n\n        if verbose == True and batch % 10 == 0:\n            print(f\"Batch: {batch}, Loss: {loss_item}\")\n    \n    avg_val_loss = running_loss / len(valid_dataloader)\n    \n    return avg_val_loss","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:26:51.772067Z","iopub.execute_input":"2021-09-13T10:26:51.772544Z","iopub.status.idle":"2021-09-13T10:26:51.791644Z","shell.execute_reply.started":"2021-09-13T10:26:51.772498Z","shell.execute_reply":"2021-09-13T10:26:51.790144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-success\">\n    <h2 align='center'>üèó Training and Validating the Model</h2>\n</div>","metadata":{}},{"cell_type":"code","source":"log_wandb = False\nif torch.cuda.is_available():\n    print(\"Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n    device = torch.device('cuda')\nelse:\n    print(\"\\nGPU not found. Using CPU: {}\\n\".format(platform.processor()))\n    device = torch.device('cpu')\n\n\n# Load training csv file\ndf = pd.read_csv('../input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv')\ndf['path'] = df.apply(lambda row: get_path(row), axis=1)\n#df=df[:20]  #close it for submitting\n\n# Removing two patient ids from the dataframe since there are not FLAIR directories for these ids. \ndf = df.loc[df.BraTS21ID!=109]\ndf = df.loc[df.BraTS21ID!=709]\ndf = df.reset_index(drop=True)\n\ntrain_df, valid_df = train_test_split(df, test_size=0.1, stratify=df.MGMT_value.values)\ntrain_df = train_df.reset_index(drop=True)\nvalid_df = valid_df.reset_index(drop=True)\n\nprint(f'Size of Training Set: {len(train_df)}, Validation Set: {len(valid_df)}')","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:26:51.794019Z","iopub.execute_input":"2021-09-13T10:26:51.794593Z","iopub.status.idle":"2021-09-13T10:26:51.835611Z","shell.execute_reply.started":"2021-09-13T10:26:51.794538Z","shell.execute_reply":"2021-09-13T10:26:51.834632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepera_data():\n    train_data = RSNADataset(train_df)\n    valid_data = RSNADataset(valid_df)\n\n    train_loader = DataLoader(\n        train_data,\n        batch_size=Config['TRAIN_BS'], \n        shuffle=True,\n        num_workers=Config['NUM_WORKERS']\n    )\n\n    valid_loader = DataLoader(\n        valid_data, \n        batch_size=Config['VALID_BS'], \n        shuffle=False,\n        num_workers=Config['NUM_WORKERS']\n    )\n    return train_loader,valid_loader\n\ntrain_loader,valid_loader=prepera_data()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:26:51.837157Z","iopub.execute_input":"2021-09-13T10:26:51.837578Z","iopub.status.idle":"2021-09-13T10:26:51.846087Z","shell.execute_reply.started":"2021-09-13T10:26:51.837548Z","shell.execute_reply":"2021-09-13T10:26:51.843967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def hunt_model():\n    model = RSNAModel()\n    model = model.to(device)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=Config['LR'])\n\n    train_loss_fn = nn.BCEWithLogitsLoss()\n    valid_loss_fn = nn.BCEWithLogitsLoss()\n\n    print(f\"\\nUsing Backbone: {Config['FEATURE_EXTRACTOR']}\")\n\n    current_loss = 1000\n    for epoch in range(Config['EPOCHS']):\n        print(f\"\\n{'--'*8} EPOCH: {epoch+1} {'--'*8}\\n\")\n\n        train_loss = train_one_epoch(model, train_loader, optimizer, train_loss_fn, epoch=epoch, device=device, log_wandb=log_wandb)\n\n        valid_loss = valid_one_epoch(model, valid_loader, valid_loss_fn, epoch=epoch, device=device, log_wandb=log_wandb)\n\n        print(f\"val_loss: {valid_loss:.4f}\")\n\n        if log_wandb == True:\n            wandb_log(\n                train_loss=train_loss,\n                valid_loss=valid_loss\n            )\n\n        if valid_loss < current_loss:\n            current_loss = valid_loss\n            torch.save(model.state_dict(), f\"model_{Config['FEATURE_EXTRACTOR']}.pt\")\n    return model\n\nmodel=hunt_model()\nmodelfiles=[model]","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:26:51.848097Z","iopub.execute_input":"2021-09-13T10:26:51.848795Z","iopub.status.idle":"2021-09-13T10:45:14.091489Z","shell.execute_reply.started":"2021-09-13T10:26:51.848752Z","shell.execute_reply":"2021-09-13T10:45:14.087704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nfrom skimage.transform import resize\ndef load_dicom_image(path, img_size, voi_lut=True, rotate=0):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n       \n    #data=crop_center(data,100,100)\n    \n    if np.max(data)==0:\n        data=None\n    else:\n        data = cv2.resize(data, img_size)\n    return data\n\n\ndef load_dicom_images_3d(scan_id,img_size, mri_type=\"FLAIR\", rotate=0,split='test'):\n\n    files = sorted(glob.glob(f\"{data_directory}/{split}/{scan_id}/{mri_type}/*.dcm\"), \n               key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n    '''\n    middle = len(files)//2\n    num_imgs2 = num_imgs//2\n    p1 = max(0, middle - num_imgs2)\n    p2 = min(len(files), middle + num_imgs2)\n    '''\n    #img3d = np.stack([load_dicom_image(f, rotate=rotate) for f in files[p1:p2]]).T \n    img3d=[]\n    #n=min(len(files),Config['MAX_FRAMES'])\n    frame_count=0\n    for f in files:\n \n        temp= load_dicom_image(f,img_size=Config['IMG_SIZE'])\n        if  temp is None:\n            #print('remove empty array')\n            continue\n        else:\n            img3d.append(temp)\n            frame_count+=1\n            if frame_count>=Config['MAX_FRAMES']:\n                break\n    img3d=np.stack(img3d,axis=2)\n    img3d = img3d - np.min(img3d)\n    img3d = img3d / np.max(img3d)\n    #img3d=np.asarray(img3d,dtype=np.uint8)\n    #print(f'before:{img3d.shape}')\n    #img3d=min_cube(img3d)\n    #print(f'after:{img3d.shape}')\n    #img3d=np.stack([load_dicom_image(f) for f in files])\n    #if img3d.shape[-1] < num_imgs:\n    #    n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n    #    img3d = np.concatenate((img3d,  n_zero), axis = -1)\n        \n    #if np.min(img3d) < np.max(img3d):\n    \n    \n    if rotate > 0 :\n        #rot_choices = [0, cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_90_COUNTERCLOCKWISE, cv2.ROTATE_180]\n        #data = cv2.rotate(data, rot_choices[rotate])\n        if rotate==1:\n            img3d=img3d+np.random.random(img3d.shape)*0.012\n        elif rotate==2:\n            img3d=gaussian_filter(img3d,sigma=7)\n        elif rotate==3:\n            img3d=img3d*1.05;\n            img3d[img3d>1]=1.\n        elif rotate==4:\n            img3d=laplace(img3d)\n        elif rotate==5:\n            img3d=crop_center(img3d,(150,150,150))\n        else: \n            img3d=img3d*0.99\n    #img3d.shape\n    if frame_count<Config['MAX_FRAMES']:\n        img3d=resize(img3d,(SIZE,SIZE,Config['MAX_FRAMES']))\n        print(scan_id,frame_count)\n    #print(img3d.shape,scan_id,frame_count)\n    return img3d\n    #return np.expand_dims(img3d,0)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:45:14.093396Z","iopub.execute_input":"2021-09-13T10:45:14.093902Z","iopub.status.idle":"2021-09-13T10:45:14.356026Z","shell.execute_reply.started":"2021-09-13T10:45:14.09382Z","shell.execute_reply":"2021-09-13T10:45:14.354938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestSet(Dataset):\n    def __init__(self, df, mri_type):\n        #self.paths = paths\n        self.df=df\n        self.mri_type = mri_type\n        self.label_smoothing = 0\n        self.augment =False\n          \n    def __len__(self):\n        return len(self.df)\n    '''\n    def old(self):\n        row = self.df.loc[idx]\n        paths = self.getPaths(row)\n        frames = []\n        for path in paths:\n            img = cv2.imread(path)\n            img = cv2.resize(img, Config['IMG_SIZE'])\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n            frames.append(img)\n\n        frames_tr = np.stack(frames, axis=2)\n        #frames_tr = np.asarray(frames_tr,dtype=int)\n        if self.augments:\n            for frame in frames:\n                frame = self.augments(image=frame)['image']\n                frames_tr.append(frame)\n            \n        if self.is_test:\n            return frames_tr,idx\n        else:\n            label = torch.tensor(row['MGMT_value']).float()\n            return frames_tr, label\n    '''  \n    \n    def __getitem__(self, idx):\n        row = self.df.loc[idx]\n        scan_id=row['BraTS21ID']\n        frames = load_dicom_images_3d(str(scan_id).zfill(5), img_size=Config['IMG_SIZE'],mri_type=self.mri_type)\n        #print(scan_id,frames.shape)\n        return frames, idx","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:45:14.360595Z","iopub.execute_input":"2021-09-13T10:45:14.360985Z","iopub.status.idle":"2021-09-13T10:45:14.369427Z","shell.execute_reply.started":"2021-09-13T10:45:14.360952Z","shell.execute_reply":"2021-09-13T10:45:14.367946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def min_cube(array_3d):\n    brain=np.nonzero(array_3d)\n    up=np.max(brain,axis=1)+1\n    down=np.min(brain,axis=1) \n    solid=array_3d[down[0]:up[0],down[1]:up[1],down[2]:up[2]]    \n    return solid","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:45:14.372093Z","iopub.execute_input":"2021-09-13T10:45:14.372694Z","iopub.status.idle":"2021-09-13T10:45:14.3849Z","shell.execute_reply.started":"2021-09-13T10:45:14.372639Z","shell.execute_reply":"2021-09-13T10:45:14.383537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, df, mri_type, split):\n    print(\"Predict:\",mri_type, df.shape)\n    df.loc[:,\"MRI_Type\"] = mri_type\n    #display(df)\n    #test_data = RSNADataset(df,is_test=True)\n    test_data=TestSet(\n        df, mri_type\n    )\n    test_loader = DataLoader(\n        test_data, \n        batch_size=4,\n        shuffle=False,\n        num_workers=1\n    )\n    model.to(device)\n    #print(test_loader[0])\n    #checkpoint = torch.load(modelfile)\n    #model.load_state_dict(checkpoint[\"model_state_dict\"])\n    model.eval()\n    #model.train()\n    \n    y_pred = []\n    ids = []\n\n    for e, batch in enumerate(test_loader,1):\n        print(f\"{e}/{len(test_loader)}\", end=\"\\r\")\n        with torch.no_grad():\n            frames,ids_=batch\n            #print(frames.shape)\n            frames = frames.permute(0,3,1,2)\n            frames = frames.to(device, torch.float)\n            tmp_pred = model(frames).view(-1)\n            #print(tmp_pred)\n            if tmp_pred.size == 1:\n                y_pred.append(tmp_pred.item())\n            else:\n                y_pred.extend(tmp_pred.tolist())\n            ids.extend(ids_.numpy().tolist())\n            \n    preddf = pd.DataFrame({\"BraTS21ID\": ids, \"MGMT_value\": y_pred}) \n    preddf = preddf.set_index(\"BraTS21ID\")\n    return preddf","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:45:14.386852Z","iopub.execute_input":"2021-09-13T10:45:14.387425Z","iopub.status.idle":"2021-09-13T10:45:14.399853Z","shell.execute_reply.started":"2021-09-13T10:45:14.387379Z","shell.execute_reply":"2021-09-13T10:45:14.398536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv')\nsubmission=df.copy(deep=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:45:14.401678Z","iopub.execute_input":"2021-09-13T10:45:14.402439Z","iopub.status.idle":"2021-09-13T10:45:14.434396Z","shell.execute_reply.started":"2021-09-13T10:45:14.402392Z","shell.execute_reply":"2021-09-13T10:45:14.433132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['path'] = submission.apply(lambda row: get_path(row,is_test=True), axis=1)\n\nsubmission[\"MGMT_value\"] = 0\nfor m, mtype in zip(modelfiles, mri_types):\n    pred = predict(m, submission, mtype, split=\"test\")\n    submission[\"MGMT_value\"] += pred[\"MGMT_value\"]","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:45:14.436328Z","iopub.execute_input":"2021-09-13T10:45:14.436844Z","iopub.status.idle":"2021-09-13T10:45:29.652375Z","shell.execute_reply.started":"2021-09-13T10:45:14.436791Z","shell.execute_reply":"2021-09-13T10:45:29.651148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[\"MGMT_value\"] /= len(modelfiles)\n#submission.drop(columns=['path','MRI_Type'],inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:45:29.65439Z","iopub.execute_input":"2021-09-13T10:45:29.654841Z","iopub.status.idle":"2021-09-13T10:45:29.663773Z","shell.execute_reply.started":"2021-09-13T10:45:29.65479Z","shell.execute_reply":"2021-09-13T10:45:29.662513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['MGMT_value']=submission[\"MGMT_value\"]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#submission=submission.set_index('BraTS21ID')\ndf.to_csv(\"submission.csv\",index=False)\ndf","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:45:29.665428Z","iopub.execute_input":"2021-09-13T10:45:29.66593Z","iopub.status.idle":"2021-09-13T10:45:29.682584Z","shell.execute_reply.started":"2021-09-13T10:45:29.665886Z","shell.execute_reply":"2021-09-13T10:45:29.681401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[\"MGMT_value\"].hist()","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:45:29.684157Z","iopub.execute_input":"2021-09-13T10:45:29.684639Z","iopub.status.idle":"2021-09-13T10:45:29.945333Z","shell.execute_reply.started":"2021-09-13T10:45:29.684584Z","shell.execute_reply":"2021-09-13T10:45:29.944177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2021-09-13T10:45:29.946762Z","iopub.execute_input":"2021-09-13T10:45:29.947193Z","iopub.status.idle":"2021-09-13T10:45:29.965483Z","shell.execute_reply.started":"2021-09-13T10:45:29.947162Z","shell.execute_reply":"2021-09-13T10:45:29.964025Z"},"trusted":true},"execution_count":null,"outputs":[]}]}