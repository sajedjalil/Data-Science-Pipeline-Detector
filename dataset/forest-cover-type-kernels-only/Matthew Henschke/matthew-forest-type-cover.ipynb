{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fd06974d2173aa45c013765d9b0c5815841f2845","trusted":false},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"18d264f73649fa47a42d24fd137f682ca4b05c75","trusted":false},"cell_type":"code","source":"# from sklearn import preprocessing, pipeline, ensemble, impute\n# categorical_cleanup = pipeline.make_pipeline(    impute.\n#  )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b170d5a8a49dd5886dddd9d9cfba6622f4d5b225","trusted":false},"cell_type":"code","source":"# preprocess data\n# feature engineering\n\nX = train.drop([\"Id\", \"Cover_Type\"], axis=1)\ny = train[\"Cover_Type\"]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3694cb4f32cfc1012d4c24dab4f531ae6b08d84c","trusted":false},"cell_type":"code","source":"# create our models\nimport xgboost\nxgb = xgboost.XGBClassifier()\n\nfrom sklearn.linear_model import LogisticRegression as LR\nlreg = LR(multi_class = \"ovr\")\n\nfrom sklearn.ensemble import GradientBoostingClassifier as GBC \ngbc = GBC()\n\nfrom sklearn.multiclass import OneVsRestClassifier as OVR\novr1 = OVR(gbc)\n\n\nfrom sklearn.neighbors import KNeighborsClassifier as KNC\nknn = KNC()\n\novr2 = OVR(knn)\n\nfrom sklearn.ensemble import RandomForestClassifier as RFC\nrf = RFC()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"62972facf10b9cf73d8a6f16eefd252f75f7390d","trusted":false},"cell_type":"code","source":"from sklearn import model_selection\n# using train test split\nX_train, X_val, y_train, y_val = model_selection.train_test_split(X, y, test_size =0.25,random_state =7)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV as GS\n# parameters\nparams = {\n    \"n_estimators\" : [250, 350, 450, 550, 650]\n}\n\n# Grid Search\ngs = GS(xgb, params)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1a0e21463b4e9f458c2b414f9bf0f8d9fe94a0e2","trusted":false},"cell_type":"code","source":"# # set up the stack\n# classifiers = [xgb, lreg, gbc, ovr1, knn, ovr2, rf]\n# from mlxtend.classifier import StackingClassifier as SC\n# stack = SC(classifiers = classifiers, meta_classifier = rf)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f75c43311439c68a9ec45904027944e197d82f42","trusted":false},"cell_type":"code","source":"# # using grid search for parameter tuning\n# from sklearn.model_selection import GridSearchCV as GS\n\n# # parameters\n# params = {\n#     \"n_estimators\" : [25,50,75,100, 125,150,175,200]\n# }\n\n# # Grid Search\n# gs = GS(rf, params)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fc445263e7b2592fda9f31f95702c56e4e5f85cb","trusted":false},"cell_type":"code","source":"# fit the data into all of the models\n# stack.fit(X_train, y_train)\nrf.fit(X_train, y_train)\ngs.fit(X_train, y_train)\n# xgb.fit(X_train, y_train)\n# lreg.fit(X_train, y_train)\n# ovr1.fit(X_train, y_train)\n# knn.fit(X_train, y_train)\n# ovr2.fit(X_train, y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fd36bcd0ef337318b2b24aaef7e844139b63e4e3","trusted":false},"cell_type":"code","source":"# # y_pred_xgb = xgb.predict(X_val)\n# # y_pred_lreg = lreg.predict(X_val)\n# # y_pred_gbc = gbc.predict(X_val)\n# # y_pred_ovr1 = ovr.predict(X_val)\n# # y_pred_knn = knn.predict(X_val)\n# # y_pred_ovr2 = ovr2.predict(X_val)\ny_pred_gs = gs.predict(X_val)\n# y_pred_stack = stack.predict(X_val)\ny_pred_rf = rf.predict(X_val)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"190aebdf059932fc7a284fa29a60fdc044ac584d","trusted":false},"cell_type":"code","source":"# # calculate the root mean squared error for prediction for all models\nfrom sklearn.metrics import mean_squared_log_error\nfrom math import sqrt\n# print(\"RMSE Scores:\")\n# # print(\"The RMSE for XGBoost is {}\".format(sqrt(mean_squared_log_error(y_val, y_pred_xgb))))\n# # print(\"The RMSE for Logistic Regression is {}\".format(sqrt(mean_squared_log_error(y_val, y_pred_lreg))))\n# # print(\"The RMSE for Gradient Boosting Classification is {}\".format(sqrt(mean_squared_log_error(y_val, y_pred_gbc))))\n# # print(\"The RMSE for One vs Rest Classifier is {}\".format(sqrt(mean_squared_log_error(y_val, y_pred_ovr1))))\n# # print(\"The RMSE for KNearest Classifier is {}\".format(sqrt(mean_squared_log_error(y_val, y_pred_knn))))\n# # print(\"The RMSE for One vs Rest Classifier is {}\".format(sqrt(mean_squared_log_error(y_val, y_pred_ovr2))))\n# print(\"The RMSE for Stacking Classifier is {}\".format(sqrt(mean_squared_log_error(y_val, y_pred_stack))))\nprint(\"The RMSE for Grid Search is {}\".format(sqrt(mean_squared_log_error(y_val, y_pred_gs))))\n# print(\"The RMSE for Random Forest with Grid Search is {}\".format(sqrt(mean_squared_log_error(y_val, y_pred_gs))))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b47d3a983a087c56b7f825fbb0b8037d56ef853c","trusted":true},"cell_type":"code","source":"\n\ny_pred = gs.predict(test.drop(\"Id\", axis=1))\nsubmission = pd.DataFrame(\n{\n    \"Id\": test[\"Id\"],\n    \"Cover_Type\": y_pred\n})\nsubmission.to_csv(\"submission.csv\", index=False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}