{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# RSNA CHALLENGE"},{"metadata":{"trusted":true,"_uuid":"e3ed4a24c44a24f69968ecb99ef75ff7f85bebfb"},"cell_type":"code","source":"from skimage import io\nimport os\nimport pandas as pd\nimport numpy as np\nimport pydicom\nfrom pydicom.data import get_testdata_files\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nfrom PIL import Image\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.core import Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import backend as K\n\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3ee179954591f2ac0f1efce69c9124b0e425aaf"},"cell_type":"markdown","source":"## 1. Explore Data\nFor solve the challenge the first step is explore the data of dataset"},{"metadata":{"trusted":true,"_uuid":"6a2c62a61b1b17809777d4ca1a521fccd53153c4"},"cell_type":"code","source":"PATH = \"../input\"\nprint(os.listdir(PATH))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b5c0407fb70c0f211e38b86b4065781175a9695e"},"cell_type":"markdown","source":"### 1.1 File: stage_1_detailed_class_info.csv\nProvides detailed information about the type of positive or negative class for each image."},{"metadata":{"trusted":true,"_uuid":"cece5cf530d13bc081ff97e0c8862040b494fd07"},"cell_type":"code","source":"pd.read_csv(PATH+\"/stage_1_detailed_class_info.csv\").head()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"_uuid":"d0cd570f2f0ad0980ae8ef831232cb2780d2b04a"},"cell_type":"markdown","source":"### 1.2 File: stage_1_sample_submission.csv\nA sample submission file in the correct format. Contains patientIds for the test set. Note that the sample submission contains one box per image, but there is no limit to the number of bounding boxes that can be assigned to a given image."},{"metadata":{"trusted":true,"_uuid":"6515a6aa406d8c77b7a79c8552db72ab264701d9"},"cell_type":"code","source":"pd.read_csv(PATH+\"/stage_1_sample_submission.csv\").head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b22a5b8f14a9854d1ac0fdb77ca976140d8cb1f"},"cell_type":"markdown","source":"### 1.3 File: stage_1_train.csv \nThe training set. Contains patientIds and bounding box / target information.\n* **patientId:** A patientId. Each patientId corresponds to a unique image.\n* **x:** The upper-left x coordinate of the bounding box.\n* **y:** The upper-left y coordinate of the bounding box.\n* **width:** The width of the bounding box.\n* **height:** The height of the bounding box.\n* **Target:** The binary Target, indicating whether this sample has evidence of pneumonia.\n"},{"metadata":{"trusted":true,"_uuid":"22a46d781911f6f0bc41db22679e96af5a8f246f"},"cell_type":"code","source":"pd.read_csv(PATH+\"/stage_1_train_labels.csv\").head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f56984e06ab9b7b42f48ef42ebea88ef321d7a6d"},"cell_type":"markdown","source":"### 1.4 Medical Image"},{"metadata":{"trusted":true,"_uuid":"5b41057be827e464d2f5c44682104cde192b3fa3"},"cell_type":"code","source":"filename = pydicom.read_file(PATH+\"/stage_1_train_images/00436515-870c-4b36-a041-de91049b9ab4.dcm\")\nfilename.pixel_array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa28499b9b54a51eb060d45fe6b33652ee4c15b0"},"cell_type":"code","source":"io.imshow(filename.pixel_array)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea70daf34c48bea39ac4c0f93ae3fea517f1424e"},"cell_type":"markdown","source":"### 1.5 Class and Boxes\n* **Target = 0**  Not pneumonia\n* **Target = 1**  Pneumonia\n* **Pneumonia images** have boxes that show pneumonia location"},{"metadata":{"trusted":true,"_uuid":"1c6542aa2f525fbc18f50aaf9e4f6d93a89f194d"},"cell_type":"code","source":"train = pd.read_csv(PATH+\"/stage_1_train_labels.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e251092fc4185bd06cfa2f05db0ae2cff42dd24e"},"cell_type":"code","source":"\ntest = pd.read_csv(PATH+\"/stage_1_sample_submission.csv\")\ntrain[train[\"patientId\"] == \"00436515-870c-4b36-a041-de91049b9ab4\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d6a84aad7de148ed603282184f74d9d424b4aed"},"cell_type":"code","source":"im = np.array(filename.pixel_array, dtype=np.uint8)\n\n# Create figure and axes\nfig,ax = plt.subplots(1)\n\n# Display the image\nax.imshow(im)\n\n# Create a Rectangle patch\nrect_1 = patches.Rectangle((264,152),213,379,linewidth=1,edgecolor='r',facecolor='none')\nrect_2 = patches.Rectangle((562,152),256,453,linewidth=1,edgecolor='r',facecolor='none')\n# Add the patch to the Axes\nax.add_patch(rect_1)\nax.add_patch(rect_2)\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"718c741c552f3941fcff9ff3f3d4ffec55012e30"},"cell_type":"code","source":"# Function create by soply on GithubGist\ndef show_images(images, cols = 1, titles = None):\n    \"\"\"Display a list of images in a single figure with matplotlib.\n    \n    Parameters\n    ---------\n    images: List of np.arrays compatible with plt.imshow.\n    \n    cols (Default = 1): Number of columns in figure (number of rows is \n                        set to np.ceil(n_images/float(cols))).\n    \n    titles: List of titles corresponding to each image. Must have\n            the same length as titles.\n    \"\"\"\n    assert((titles is None)or (len(images) == len(titles)))\n    n_images = len(images)\n    if titles is None: titles = ['Image (%d)' % i for i in range(1,n_images + 1)]\n    fig = plt.figure()\n    for n, (image, title) in enumerate(zip(images, titles)):\n        a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)\n        if image.ndim == 2:\n            plt.gray()\n        plt.imshow(image)\n        a.set_title(title)\n    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa19ad3259918a87ea06e614295df67bb4789656"},"cell_type":"code","source":"filename_2 = pydicom.read_file(PATH+\"/stage_1_train_images/0004cfab-14fd-4e49-80ba-63a80b6bddd6.dcm\")\nshow_images([filename_2.pixel_array,filename.pixel_array], titles = [\"Not pneumonia\", \"pneumonia\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c95528bbb8bfa4ab10042098327f4fe84485c350"},"cell_type":"markdown","source":"## 2. Semantic Segmentation"},{"metadata":{"_uuid":"ed9ace294ba1951aa4242e0090565c9a65bd686d"},"cell_type":"markdown","source":"### 2.1 Get TRAIN data"},{"metadata":{"trusted":true,"_uuid":"9f86139d8a080c8f2e72a39aa48a9b968584be35"},"cell_type":"code","source":"X_train, y_train, train_names = [], [], []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61929fa3e06afc5818c131983a0892cc93bfe3e0"},"cell_type":"code","source":"IMG_SIZE = 1024\nNEW_SIZE = 128\nN = IMG_SIZE/NEW_SIZE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d237821ab5309b899b7e082c27109ed0621f0e0"},"cell_type":"code","source":"for i in np.unique(train[\"patientId\"]):\n    data = train[train[\"patientId\"]== i]\n    image = data[\"patientId\"].values[0]\n    new_image = Image.fromarray(pydicom.read_file(PATH+\"/stage_1_train_images/\"+image+\".dcm\").pixel_array).resize((NEW_SIZE,NEW_SIZE), Image.ANTIALIAS)\n    \n    X_train.append(np.array(new_image).reshape((NEW_SIZE,NEW_SIZE,1)))\n    train_names.append(data[\"patientId\"].values[0])\n    if 0 not in data[\"Target\"].values:\n        \n        new = np.zeros((NEW_SIZE,NEW_SIZE))\n        \n        for j in range(data.shape[0]):\n            x = int(data[\"x\"].values[j]/N)\n            y = int(data[\"y\"].values[j]/N)\n            width = int(data[\"width\"].values[j]/N)\n            height = int(data[\"height\"].values[j]/N)\n            new[y:y+height,x:x+width] = 1\n        \n        y_train.append(new.reshape((NEW_SIZE,NEW_SIZE,1)))\n    else:\n        new = np.zeros((NEW_SIZE,NEW_SIZE))\n        y_train.append(new.reshape((NEW_SIZE,NEW_SIZE,1)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"1d968f645f7314ab55986fa1baa703658f5f988e"},"cell_type":"code","source":"X_train[9]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2667bddcf0c881156e378c05aa942f5a8a17e357"},"cell_type":"code","source":"X_train[9].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0b19f1278d127c29e79148f431f9bcf6c9046cae"},"cell_type":"code","source":"show_images([X_train[71].reshape((256,256)),y_train[71].reshape((256,256))], titles=[\"Image\",\"Ground Truht\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c68e0350259510b726e980c4c9698c5a96fb8654"},"cell_type":"markdown","source":"the convertionis rigth?"},{"metadata":{"trusted":true,"_uuid":"57f548cea428c73ee5a5cb005255118bf9a589b8"},"cell_type":"code","source":"filename = pydicom.read_file(PATH+\"/stage_1_train_images/\"+train_names[71]+\".dcm\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12d5d1d0cda2cf4caba53e0939ad0f1ee392c05c"},"cell_type":"code","source":"train[train[\"patientId\"] == train_names[71]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c737e364324ee076ab98ef1c357cecde8fb5d5f4"},"cell_type":"code","source":"im = np.array(filename.pixel_array, dtype=np.uint8)\n\n# Create figure and axes\nfig,ax = plt.subplots(1)\n\n# Display the image\nax.imshow(im)\n\n# Create a Rectangle patch\nrect_1 = patches.Rectangle((698,288),226,311,linewidth=1,edgecolor='r',facecolor='none')\nrect_2 = patches.Rectangle((326,212),181,275,linewidth=1,edgecolor='r',facecolor='none')\n# Add the patch to the Axes\nax.add_patch(rect_1)\nax.add_patch(rect_2)\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b935423e10597ea7a5438cd6e8b8559bcca2423"},"cell_type":"code","source":"show_images([X_train[71].reshape((256,256)),y_train[71].reshape((256,256))], titles=[\"Image\",\"Ground Truht\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e7481a08ded72637a1a13567649fdbb67ef2a5b3"},"cell_type":"markdown","source":"### 2.2 Get TEST data"},{"metadata":{"_uuid":"6ccb3eb2ac7e96da7e82e240c62f905d6af93838"},"cell_type":"markdown","source":"X_test, test_names = [], []"},{"metadata":{"_uuid":"b9f1e568ac5f98b6627ec107393031156e6cf3b0"},"cell_type":"markdown","source":"for i in np.unique(test[\"patientId\"]):\n    data = test[test[\"patientId\"]== i]\n    image = data[\"patientId\"].values[0]\n    new_image = Image.fromarray(pydicom.read_file(PATH+\"/stage_1_test_images/\"+image+\".dcm\").pixel_array).resize((NEW_SIZE,NEW_SIZE), Image.ANTIALIAS)\n    \n    X_test.append(np.array(new_image).reshape((256,256,1)))\n    test_names.append(data[\"patientId\"].values[0])"},{"metadata":{"trusted":true,"_uuid":"bd928d1968b1be5b68fbf4ca58bbcb8f0549b6bb"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"83726c03301b240f36d0d73e368d906075dcfa63"},"cell_type":"markdown","source":"### 2.3 Unet Model\nTHis model is take thanks `Kjetil Åmdal-Sævik` [kaggle user](https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277)"},{"metadata":{"trusted":true,"_uuid":"7f18b278620a382b46943007918501ac97bcf51d"},"cell_type":"code","source":"def mean_iou(y_true, y_pred):\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        y_pred_ = tf.to_int32(y_pred > t)\n        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n        K.get_session().run(tf.local_variables_initializer())\n        with tf.control_dependencies([up_opt]):\n            score = tf.identity(score)\n        prec.append(score)\n    return K.mean(K.stack(prec), axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b49fd7dbc1a1aabac4ebd1b42d6b365daf9cccb9"},"cell_type":"code","source":"inputs = Input((NEW_SIZE, NEW_SIZE, 1))\ns = Lambda(lambda x: x / 255) (inputs)\n\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (s)\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\nc5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\nc5 = Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n\nu6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\nc6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n\nu7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\nc7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n\nu8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\nc8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n\nu9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\nc9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\nmodel = Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"424844ad78dcbb0f90238c3508d7e2764b100548"},"cell_type":"code","source":"earlystopper = EarlyStopping(patience=5, verbose=1)\ncheckpointer = ModelCheckpoint('model-dsbowl2018-1.h5', verbose=1, save_best_only=True)\nresults = model.fit(np.array(X_train), np.array(y_train), validation_split=0.1, batch_size=2, epochs=10, callbacks=[earlystopper, checkpointer])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0e0726e661afd2cc0acf8e2c5f5d568fc57cbe6"},"cell_type":"code","source":"### 2.4 Load Model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c3f8a9d2489280159ad4f680f3d7fd73a4763b74"},"cell_type":"code","source":"model = load_model('model-dsbowl2018-1.h5', custom_objects={'mean_iou': mean_iou})","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}