{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nfrom joblib import Parallel, delayed\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBRegressor\nimport os\nfrom sklearn.linear_model import LinearRegression\nimport warnings\nfrom sklearn.model_selection import train_test_split, KFold\nimport lightgbm as lgb\nimport time\nimport joblib\nimport datatable as dt\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import OneHotEncoder, RobustScaler, StandardScaler\nwarnings.filterwarnings(action='ignore', category=UserWarning)\nfrom tqdm import tqdm\nimport gc","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-30T03:53:46.826901Z","iopub.execute_input":"2021-06-30T03:53:46.827259Z","iopub.status.idle":"2021-06-30T03:53:49.925026Z","shell.execute_reply.started":"2021-06-30T03:53:46.827181Z","shell.execute_reply":"2021-06-30T03:53:49.924203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Infer: https://www.kaggle.com/yus002/realized-volatility-prediction-lgbm-infer","metadata":{}},{"cell_type":"markdown","source":"# Training Data Set comes from \n* # https://www.kaggle.com/mayunnan/realized-volatility-prediction-code-template\n* # https://www.kaggle.com/thanish/randomforest-starter-submission","metadata":{}},{"cell_type":"markdown","source":"# Helper methods","metadata":{}},{"cell_type":"code","source":"def my_metrics(y_true, y_pred):\n    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\ndef rmspe(y_true, y_pred):  # f(y_true: array, y_pred: array) -> name: string, eval_result: float, is_higher_better: bool\n    output = my_metrics(y_true, y_pred)\n    return 'rmspe', output, False\ndef log_return(list_stock_prices):\n    return np.log(list_stock_prices).diff() \ndef realized_volatility(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))\n\ndef get_stock_stat(stock_id : int, dataType = 'train'):   \n    book_train_subset = pd.read_parquet(f'../input/optiver-realized-volatility-prediction/book_{dataType}.parquet/stock_id={stock_id}/')\n    book_train_subset.sort_values(by=['time_id', 'seconds_in_bucket'])\n\n    book_train_subset['bas'] = (book_train_subset[['ask_price1', 'ask_price2']].min(axis = 1)\n                                / book_train_subset[['bid_price1', 'bid_price2']].max(axis = 1)\n                                - 1)                               \n    book_train_subset['wap'] = (book_train_subset['bid_price1'] * book_train_subset['ask_size1'] +\n                            book_train_subset['ask_price1'] * book_train_subset['bid_size1']) / (\n                            book_train_subset['bid_size1']+ book_train_subset['ask_size1'])\n    book_train_subset['log_return'] = (book_train_subset.groupby(by = ['time_id'])['wap'].\n                                       apply(log_return).\n                                       reset_index(drop = True).\n                                       fillna(0)\n                                      )\n    stock_stat = pd.merge(\n        book_train_subset.groupby(by = ['time_id'])['log_return'].agg(realized_volatility).reset_index(),\n        book_train_subset.groupby(by = ['time_id'], as_index = False)['bas'].mean(),\n        on = ['time_id'],\n        how = 'left'\n    )\n    stock_stat['stock_id'] = stock_id\n    return stock_stat\ndef get_dataSet(stock_ids : list, dataType = 'train'):\n    stock_stat = Parallel(n_jobs=-1)(\n        delayed(get_stock_stat)(stock_id, dataType) \n        for stock_id in stock_ids\n    )\n    stock_stat_df = pd.concat(stock_stat, ignore_index = True)\n    return stock_stat_df","metadata":{"execution":{"iopub.status.busy":"2021-06-30T03:54:08.295565Z","iopub.execute_input":"2021-06-30T03:54:08.296002Z","iopub.status.idle":"2021-06-30T03:54:08.317207Z","shell.execute_reply.started":"2021-06-30T03:54:08.295961Z","shell.execute_reply":"2021-06-30T03:54:08.315947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"keep_stock_id = 1\n#keep_stock_id = 1\n\nfolds = 7\nseed_list = [i for i in range(12, 13)]\nearly_stopping = 200","metadata":{"execution":{"iopub.status.busy":"2021-06-30T03:54:10.772817Z","iopub.execute_input":"2021-06-30T03:54:10.773139Z","iopub.status.idle":"2021-06-30T03:54:10.778701Z","shell.execute_reply.started":"2021-06-30T03:54:10.773109Z","shell.execute_reply":"2021-06-30T03:54:10.777506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"# train -------------------------\nif keep_stock_id:\n    td = dt.fread('../input/mytrain/X_131_features.csv')\n    X = td.to_pandas()\n    del td\nelse: \n    X = pd.read_csv(\"../input/mytrain/X.csv\")\ny = pd.read_csv(\"../input/mytrain/y.csv\")\n# to_test ----------------------------------------------------\ntest = pd.read_csv('../input/optiver-realized-volatility-prediction/test.csv')\ntest_stock_stat_df = get_dataSet(stock_ids = test['stock_id'].unique(), dataType = 'test')\ntest_dataSet = pd.merge(test, test_stock_stat_df, on = ['stock_id', 'time_id'], how = 'left')\ntest_dataSet = test_dataSet\nfinal_pred1 = test_dataSet[['row_id']]\nto_test = test_dataSet.drop(['row_id'], axis = 1).fillna(0)\nif keep_stock_id:\n    train = pd.read_csv(\"../input/optiver-realized-volatility-prediction/train.csv\")\n    cols = [f'stock_id_{c}' for c in list(set(train.stock_id))]\n    to_test[cols] = pd.DataFrame(np.stack([(to_test.stock_id == c).astype('int') for c in list(set(train.stock_id))]).T, columns = cols)\nelse:\n    to_test = to_test.drop(\"stock_id\", axis = 1)\n    X = X.drop(\"stock_id\", axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T03:54:13.69663Z","iopub.execute_input":"2021-06-30T03:54:13.696938Z","iopub.status.idle":"2021-06-30T03:54:17.891968Z","shell.execute_reply.started":"2021-06-30T03:54:13.696911Z","shell.execute_reply":"2021-06-30T03:54:17.891053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = {'input_path': \"../input/optiver-realized-volatility-prediction/trade_\",\n          'train_path': '../input/optiver-realized-volatility-prediction/train.csv',\n          'test_path' : '../input/optiver-realized-volatility-prediction/test.csv'}\ntest_df = pd.read_csv(config['test_path'])\ndef read_data(stock_id, data_type):\n    file = glob.glob(config['input_path']+f'{data_type}.parquet/stock_id={stock_id}/*')[0]\n    df = pd.read_parquet(file)\n    return df\ndef get_final_df(df, data_type):\n    final_df = pd.DataFrame()\n    unique_id = df['stock_id'].unique().tolist()\n    for stock_id in tqdm(unique_id):\n        temp_stock_df = read_data(stock_id=stock_id, data_type=data_type)\n        temp_stock_df['stock_id'] = stock_id\n        final_df = pd.concat([final_df, temp_stock_df])\n    final_df.reset_index(drop=True)\n    return final_df\ndef get_agg_info(df):\n    agg_df = df.groupby(['stock_id', 'time_id']).agg(mean_sec_in_bucket = ('seconds_in_bucket', 'mean'), \n                                                     mean_price = ('price', 'mean'),\n                                                     mean_size = ('size', 'mean'),\n                                                     mean_order = ('order_count', 'mean'),\n                                                     max_sec_in_bucket = ('seconds_in_bucket', 'max'), \n                                                     max_price = ('price', 'max'),\n                                                     max_size = ('size', 'max'),\n                                                     max_order = ('order_count', 'max'),\n                                                     min_sec_in_bucket = ('seconds_in_bucket', 'min'), \n                                                     min_price = ('price', 'min'),\n                                                     min_size = ('size', 'min'),\n                                                     min_order = ('order_count', 'min'),\n                                                     median_sec_in_bucket = ('seconds_in_bucket', 'median'), \n                                                     median_price = ('price', 'median'),\n                                                     median_size = ('size', 'median'),\n                                                     median_order = ('order_count', 'median')\n                                                    ).reset_index()\n    \n    return agg_df\ntest_final_df = get_final_df(df=test_df, data_type='test')\ntest_agg = get_agg_info(df=test_final_df)\ntest_final_df = pd.merge(test_df, test_agg, on=['stock_id', 'time_id'], how='left')\ntest_final_df.fillna(-999, inplace=True)\ntest_final_df = test_final_df.drop(\"row_id\", axis = 1)\nto_test = to_test.merge(test_final_df, on=['stock_id', 'time_id'], how='left')\nto_test.fillna(-999, inplace=True)\nto_test = to_test.drop(\"stock_id\", axis = 1)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T03:54:20.119442Z","iopub.execute_input":"2021-06-30T03:54:20.119931Z","iopub.status.idle":"2021-06-30T03:54:20.20832Z","shell.execute_reply.started":"2021-06-30T03:54:20.119889Z","shell.execute_reply":"2021-06-30T03:54:20.207538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"execution":{"iopub.status.busy":"2021-06-30T03:54:27.390578Z","iopub.execute_input":"2021-06-30T03:54:27.390909Z","iopub.status.idle":"2021-06-30T03:54:27.486517Z","shell.execute_reply.started":"2021-06-30T03:54:27.390876Z","shell.execute_reply":"2021-06-30T03:54:27.485602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"to_test","metadata":{"execution":{"iopub.status.busy":"2021-06-30T03:54:33.099929Z","iopub.execute_input":"2021-06-30T03:54:33.10024Z","iopub.status.idle":"2021-06-30T03:54:33.128392Z","shell.execute_reply.started":"2021-06-30T03:54:33.10021Z","shell.execute_reply":"2021-06-30T03:54:33.127578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial , X = X , y = y):\n    if keep_stock_id: \n        params = {\n            'reg_alpha' : trial.suggest_loguniform('reg_alpha' , 1e-5 , 1),\n            'reg_lambda' : trial.suggest_loguniform('reg_lambda' , 3 , 9),\n            'num_leaves' : trial.suggest_int('num_leaves' , 20 , 60),\n            'learning_rate' : trial.suggest_uniform('learning_rate' , 0.02 , 0.08),\n            'max_depth' : trial.suggest_int('max_depth', 20 , 60),\n            'n_estimators' : trial.suggest_int('n_estimators', 3000 , 3600),\n            'min_child_weight' : trial.suggest_loguniform('min_child_weight', 0.05 , 0.15),\n            'subsample' : trial.suggest_uniform('subsample' , 0.7 , 1.0),\n            'colsample_bytree' : trial.suggest_loguniform('colsample_bytree', 0.5 , 1),\n            'min_child_samples' : trial.suggest_int('min_child_samples', 10, 40),\n            'metric' : 'rmse', #'rmse'\n            'device_type' : 'gpu',\n        }\n    else:\n        params = {\n            'reg_alpha' : trial.suggest_loguniform('reg_alpha' , 1e-5 , 1),\n            'reg_lambda' : trial.suggest_loguniform('reg_lambda', 1e-5 , 1),\n            'num_leaves' : trial.suggest_int('num_leaves' , 10 , 60),\n            'learning_rate' : trial.suggest_uniform('learning_rate' , 0.02 , 0.08),\n            'max_depth' : trial.suggest_int('max_depth', 10 , 30),\n            'n_estimators' : trial.suggest_int('n_estimators', 60 , 1000),\n            'min_child_weight' : trial.suggest_loguniform('min_child_weight', 0.05 , 0.15),\n            'subsample' : trial.suggest_uniform('subsample' , 0.4 , 1.0),\n            'colsample_bytree' : trial.suggest_loguniform('colsample_bytree', 0.4 , 1),\n            'min_child_samples' : trial.suggest_int('min_child_samples', 10, 40),\n            'metric' : 'rmse', #'rmse'\n            'device_type' : 'gpu',\n        }\n    #pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'rmspe', valid_name = 'valid_0')  \n    score = 0\n    for seed in seed_list: \n        kf = KFold(n_splits = folds ,random_state= seed, shuffle=True)\n        for idx_train,idx_test in kf.split(X, y):\n            X_train,X_test=X.iloc[idx_train],X.iloc[idx_test]\n            y_train,y_test=y.iloc[idx_train],y.iloc[idx_test]\n            model = lgb.LGBMRegressor(**params, random_state = seed, n_jobs = -1)\n            model.fit(X_train, y_train.values.ravel(), eval_set = [(X_test , y_test.values.ravel())] ,eval_metric = rmspe, early_stopping_rounds = early_stopping, \\\n             verbose = 1500\n                    #   ,callbacks = [pruning_callback]\n                     ) \n            y_pred = model.predict(X_test)  \n            score += (my_metrics(y_test.values.ravel(), y_pred) / folds) / len(seed_list)                 \n    del model\n    return score\nimport optuna\nstudy = optuna.create_study(direction = 'minimize' , study_name = 'lgbm'\n                           # , pruner = optuna.pruners.HyperbandPruner()\n                           )\nstudy.optimize(objective , n_trials = 4)\nprint('numbers of the finished trials:' , len(study.trials))\nprint('the best params:' , study.best_trial.params)\nprint('the best value:' , study.best_value)\nprint(\"done\")\ntime.sleep(60)","metadata":{"execution":{"iopub.status.busy":"2021-06-30T03:54:47.111767Z","iopub.execute_input":"2021-06-30T03:54:47.112094Z","iopub.status.idle":"2021-06-30T04:16:37.903343Z","shell.execute_reply.started":"2021-06-30T03:54:47.112063Z","shell.execute_reply":"2021-06-30T04:16:37.902406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {'reg_alpha': 0.028887686028843496, \n          'reg_lambda': 5.609420891429227, \n          'num_leaves': 56, 'learning_rate': 0.07716013360199103, \n          'max_depth': 23, 'n_estimators': 3398,\n          'min_child_weight': 0.11236058184476623, \n          'subsample': 0.8933699572438508, \n          'colsample_bytree': 0.9836129968372216, \n          'min_child_samples': 28} # Best is trial 2 with value: 0.28758503964033905.","metadata":{"execution":{"iopub.status.busy":"2021-06-30T04:20:26.299841Z","iopub.execute_input":"2021-06-30T04:20:26.300165Z","iopub.status.idle":"2021-06-30T04:20:26.305369Z","shell.execute_reply.started":"2021-06-30T04:20:26.300136Z","shell.execute_reply":"2021-06-30T04:20:26.304551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save models","metadata":{}},{"cell_type":"code","source":"score = 0\nfor seed in seed_list: \n    kf = KFold(n_splits = folds ,random_state= seed, shuffle=True)\n    count = 1\n    for idx_train,idx_test in kf.split(X, y):\n        print(\"=\" * 40)\n        print(\"seed\", seed)\n        print(\"fold\", count)\n        print(\"=\" * 30)\n        start_time = time.time()\n        X_train, X_test = X.iloc[idx_train], X.iloc[idx_test]\n        y_train, y_test = y.iloc[idx_train], y.iloc[idx_test]\n        model = lgb.LGBMRegressor(**params, random_state = seed, n_jobs = -1, metric = 'rmse', device_type = 'gpu')\n        model.fit(X_train, y_train, eval_set = [(X_test , y_test.values.ravel())], eval_metric = rmspe,\\\n                  early_stopping_rounds = early_stopping, verbose = False)\n        cv_score = my_metrics(y_test.values.ravel(), model.predict(X_test))\n        score += (cv_score / folds) / len(seed_list)\n        joblib.dump(model, f'LGBM seed_{seed}_fold_{count}_cv_score_{round(cv_score, 3)}.pkl') # save model\n        end_time = time.time()\n        run_time = round(end_time - start_time)\n        print (\"fold\", count, \"took\", run_time , \"seconds to run\")\n        count += 1\n        print (\"The estimated remaining training time in the current seed\", seed, \"are\",\\\n               round(((folds - count) * run_time) / 60, 3), \"minuets\")\n        print(\"Validation score\", cv_score)\nprint(\"Mean RMSPE validation score of\", folds, \"folds\", score)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-30T04:20:31.920059Z","iopub.execute_input":"2021-06-30T04:20:31.920374Z","iopub.status.idle":"2021-06-30T04:25:37.299165Z","shell.execute_reply.started":"2021-06-30T04:20:31.920343Z","shell.execute_reply":"2021-06-30T04:25:37.298365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}