{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Skeleton for training and inference with pytorch-lightning\n\nThis notebook shows how pytorch-lightning can be used to realize the whole processing pipeline from training to inference and submission in some few lines of code.\n\nVarious code snippets are taken from [https://www.kaggle.com/jiashenliu/introduction-to-financial-concepts-and-data] and [https://www.kaggle.com/gunesevitan/optiver-realized-volatility-prediction-1d-cnn]. Many thanks!\n","metadata":{}},{"cell_type":"code","source":"import pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom pytorch_lightning.callbacks import LearningRateMonitor\n\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom pathlib import Path\nimport pyarrow.parquet as pq\nfrom sklearn.metrics import r2_score\n\ndata_path=Path('../input/optiver-realized-volatility-prediction')","metadata":{"execution":{"iopub.status.busy":"2021-08-25T19:50:54.766125Z","iopub.execute_input":"2021-08-25T19:50:54.766566Z","iopub.status.idle":"2021-08-25T19:50:58.873769Z","shell.execute_reply.started":"2021-08-25T19:50:54.766507Z","shell.execute_reply":"2021-08-25T19:50:58.872775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ffill(data_df): \n    data_df = data_df.set_index(['seconds_in_bucket'])\n    data_df = data_df.reindex(np.arange(0,600), method='ffill')\n    return data_df.reset_index()\n\ndef log_return(list_stock_prices):\n    return np.log(list_stock_prices).diff() \n\ndef realized_volatility(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))\n\ndef rmspe(y_true, y_pred):\n    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n","metadata":{"execution":{"iopub.status.busy":"2021-08-25T19:50:58.877889Z","iopub.execute_input":"2021-08-25T19:50:58.87827Z","iopub.status.idle":"2021-08-25T19:50:58.885506Z","shell.execute_reply.started":"2021-08-25T19:50:58.878236Z","shell.execute_reply":"2021-08-25T19:50:58.884676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport pyarrow.parquet as pq\n \nclass OptiverDataset(Dataset):\n    \n    def __init__(self, data_path, mode = \"train\", transform = None, ffill = False): \n        \"\"\" mode must be train or test \"\"\"\n        super().__init__()\n        self.mode = mode\n        self.transform = transform\n        self.ffill = ffill\n        train_df = pd.read_csv(data_path/f\"{mode}.csv\")\n        self.train_grouped = train_df.groupby(['stock_id','time_id'])        \n        book_df = pq.read_table(data_path / f\"book_{mode}.parquet\").to_pandas()         \n        self.book_grouped = book_df.groupby(['stock_id','time_id'])        \n        self.indices = list(self.book_grouped.indices.keys())\n    \n    def __getitem__(self, idx):   \n        grp_name = self.indices[idx]\n        df = self.book_grouped.get_group(grp_name)\n        if self.ffill:\n            df = ffill(df)        \n        if self.transform:\n            x = self.transform(df)\n        else:\n            x = df[['bid_price1', 'ask_price1', 'bid_price2', 'ask_price2']].to_numpy(np.float32)\n            \n        if self.mode == \"test\":\n            row_id = self.train_grouped.get_group(grp_name)['row_id'].values[0]\n            return x, row_id\n        else:\n            y = self.train_grouped.get_group(grp_name)['target'].to_numpy(np.float32)\n            return x, y\n    \n    def __len__(self):\n        return len(self.indices)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-08-25T19:50:58.887078Z","iopub.execute_input":"2021-08-25T19:50:58.887572Z","iopub.status.idle":"2021-08-25T19:50:58.900422Z","shell.execute_reply.started":"2021-08-25T19:50:58.887539Z","shell.execute_reply":"2021-08-25T19:50:58.899204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, random_split\n\nclass OptiverDataModule(pl.LightningDataModule):\n    def __init__(self, data_path, train_batch_size = 32, val_batch_size = 32, transform=None):\n        super().__init__()\n        self.data_path = data_path\n        self.train_batch_size = train_batch_size\n        self.val_batch_size = val_batch_size\n        self.transform = transform\n        self.train_dataset = None\n        self.val_dataset = None\n     \n    def create_datasets(self):\n        dataset = OptiverDataset(self.data_path, mode= \"train\", transform = self.transform)\n        dataset_len = len(dataset)\n        train_dataset_len = int(dataset_len*0.8)\n        val_dataset_len = dataset_len - train_dataset_len\n        self.train_dataset, self.val_dataset = random_split(\n            dataset, [train_dataset_len, val_dataset_len], generator=torch.Generator().manual_seed(42))\n        \n    def train_dataloader(self):\n        if not self.train_dataset:\n            self.create_datasets()\n        dataloader = DataLoader(\n            self.train_dataset, \n            batch_size=self.train_batch_size, \n            shuffle=True,\n            num_workers = 4)\n        return dataloader\n    \n    def val_dataloader(self):\n        if not self.val_dataset:\n            self.create_datasets()\n        dataloader = DataLoader(\n            self.val_dataset, \n            batch_size=self.val_batch_size, \n            shuffle=False,\n            num_workers = 4)\n        return dataloader\n    \n    def test_dataloader(self):\n        dataloader = DataLoader(\n            OptiverDataset(self.data_path, mode= \"test\", transform = self.transform),\n            batch_size=1,\n            num_workers = 4)\n        return dataloader","metadata":{"execution":{"iopub.status.busy":"2021-08-25T19:50:58.901814Z","iopub.execute_input":"2021-08-25T19:50:58.902216Z","iopub.status.idle":"2021-08-25T19:50:58.918148Z","shell.execute_reply.started":"2021-08-25T19:50:58.902183Z","shell.execute_reply":"2021-08-25T19:50:58.917315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim\nimport torch.nn\nimport torch.nn.functional as F\n\nclass SimplestLinearModule(pl.LightningModule):\n    def __init__(self, learning_rate = 0.01):\n        super().__init__()    \n        self.learning_rate = learning_rate\n        self.linear = torch.nn.Linear(1, 1)  # One in and one out\n        \n    def forward(self, input):\n        x = self.linear(input)\n        return F.leaky_relu(x)\n    \n    def training_step(self, batch, batch_idx):\n        x, target = batch\n        prediction = self.forward(x)\n        loss = torch.sqrt( F.mse_loss(prediction, target) + 1e-24)\n        self.log(\"loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)    \n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        x, target = batch\n        prediction = self.forward(x)\n        loss = torch.sqrt( F.mse_loss(prediction, target) + 1e-24)\n        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)   \n        return prediction, target\n    \n    def validation_epoch_end(self, validation_step_outputs):\n        y_pred = [p for p,t in validation_step_outputs]\n        y_true = [t for p,t in validation_step_outputs]                \n        y_pred = torch.cat(y_pred, dim=0).view(-1).cpu().numpy()\n        y_true = torch.cat(y_true, dim=0).view(-1).cpu().numpy()\n        R2 = round(r2_score(y_true, y_pred),3)\n        RMSPE = round(rmspe(y_true, y_pred),3)\n        self.log(\"R2\", R2, on_step=False, on_epoch=True, prog_bar=True, logger=True) \n        self.log(\"RMSPE\", RMSPE, on_step=False, on_epoch=True, prog_bar=True, logger=True)   \n\n    def test_step(self, batch, batch_idx):  \n        x, row_id = batch\n        prediction = self.forward(x)\n        return row_id, prediction.cpu().numpy()\n    \n    def test_epoch_end(self, test_step_outputs):\n        ## write submission file:\n        ## row_id target\n        submission = pd.DataFrame({\n            'row_id' : [row_id[0] for row_id, target in test_step_outputs], # row_id is a tuple\n            'target' : [target[0,0] for row_id, target in test_step_outputs]}) # assumes test batch size is 1\n        submission.to_csv('submission.csv', index=None)\n        submission\n\n    def configure_optimizers(self):\n        #optimizer = torch.optim.SGD(self.linear.parameters(), lr = self.learning_rate )\n        #optimizer =torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n        optimizer = torch.optim.RMSprop(self.linear.parameters(), lr = self.learning_rate )\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'min', patience=5)\n        return {\n            \"optimizer\" : optimizer, \n            \"lr_scheduler\" : {\n                \"scheduler\": scheduler,\n                \"monitor\": \"val_loss\",\n            }}\n\ndef realized_volatility_feature(df):\n    wap = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) /\\\n                  (df['bid_size1'] + df['ask_size1'])\n    r = log_return(wap).to_numpy(dtype=np.float32)\n    r = r[~np.isnan(r)]\n    return np.array([realized_volatility(r)], dtype=np.float32)\n    \ndatamodule = OptiverDataModule(\n    data_path=Path('../input/optiver-realized-volatility-prediction'),\n    train_batch_size = 256, val_batch_size = 256,\n    transform = realized_volatility_feature)\n\nmodule = SimplestLinearModule(learning_rate = 1e-4)\n\ncheckpoint_callback = ModelCheckpoint(monitor='val_loss')\nlr_monitor = LearningRateMonitor(logging_interval='step')\n\ntrainer = pl.Trainer(\n    gpus=0,\n    callbacks=[checkpoint_callback, lr_monitor],\n    #limit_train_batches=0.25,\n    #limit_val_batches=0.25,\n    max_epochs = 20\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-25T19:50:58.919743Z","iopub.execute_input":"2021-08-25T19:50:58.920269Z","iopub.status.idle":"2021-08-25T19:50:58.939129Z","shell.execute_reply.started":"2021-08-25T19:50:58.920234Z","shell.execute_reply":"2021-08-25T19:50:58.937706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.fit(module, datamodule)","metadata":{"execution":{"iopub.status.busy":"2021-08-25T19:50:58.979367Z","iopub.execute_input":"2021-08-25T19:50:58.979816Z","iopub.status.idle":"2021-08-25T20:15:44.773641Z","shell.execute_reply.started":"2021-08-25T19:50:58.97977Z","shell.execute_reply":"2021-08-25T20:15:44.771254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Performance of the Naive Prediction\nAccording to [https://www.kaggle.com/jiashenliu/introduction-to-financial-concepts-and-data], \nperformance of the naive prediction is:\n\nR2 score: 0.628 \n\nRMSPE: 0.341","metadata":{}},{"cell_type":"code","source":"trainer.test(ckpt_path=\"best\")\n\n!cat submission.csv","metadata":{"execution":{"iopub.status.busy":"2021-08-25T20:15:44.781093Z","iopub.execute_input":"2021-08-25T20:15:44.781486Z","iopub.status.idle":"2021-08-25T20:15:46.643435Z","shell.execute_reply.started":"2021-08-25T20:15:44.781451Z","shell.execute_reply":"2021-08-25T20:15:46.64226Z"},"trusted":true},"execution_count":null,"outputs":[]}]}