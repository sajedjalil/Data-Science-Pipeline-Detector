{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## ä»Šå›ã®ç›®çš„\nä¸ãˆã‚‰ã‚ŒãŸ10åˆ†é–“ã®å–å¼•ã«ãŠã‘ã‚‹ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‹ã‚‰æ¬¡ã®10åˆ†ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’äºˆæ¸¬ã™ã‚‹\n\nâ†’stock_idï¼ˆéŠ˜æŸ„ï¼‰ã”ã¨ã®time_idï¼ˆæ™‚é–“ï¼‰ã”ã¨ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’äºˆæ¸¬ã™ã‚‹\n\nâ†’ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã«ã¤ã„ã¦ã®è©³ç´°ã¯ã®ã¡ã«è§£èª¬\n\n================================================================================\n\nâš ï¸kaggleåˆå¿ƒè€…ãŒå¼·å¼•ã«å’Œè¨³ã—ãªãŒã‚‰æµã‚Œã‚’ç¢ºèªã—ãŸã®ã§è§£é‡ˆãŒé–“é•ã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã”æ³¨æ„ãã ã•ã„ã€‚\n\n================================================================================\n\n## ãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦\n### train.csv\nstock_id, time_id, targetï¼ˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼‰ãŒå«ã¾ã‚Œã‚‹\n### test.csv\nstock_idãŒ0ã®ã‚‚ã®ã®ã€time_idãŒ4/32/34ã®3è¡Œã®ã¿\nâ†’row_idã¨ã„ã†åˆ—ã«0-4ãªã©stock_idã¨time_idã‚’ãƒã‚¤ãƒ•ãƒ³ã§æ¥ç¶šã—ãŸã‚‚ã®ãŒå«ã¾ã‚Œã¦ã„ã‚‹\n### sample_submission.csv\nrow_id, targetã®3è¡Œ2åˆ—ã®ã¿ï¼ˆrow_id = 0-4, 0-32, 0-34ï¼‰\n### book_train.parquet/book_test.parquet\nstock_idã”ã¨ã®ã‚ªãƒ¼ãƒ€ãƒ¼ãƒ–ãƒƒã‚¯ã®ãƒ‡ãƒ¼ã‚¿ãŒparquetã¨ã„ã†å½¢ã§å…¥ã£ã¦ã„ã‚‹ï¼ˆtestã¯stock_id=0ã®ã¿ï¼‰\n### trade_train.parquet/trade_test.parquet\nstock_idã”ã¨ã®å®Ÿéš›ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ãŒparquetã¨ã„ã†å½¢ã§å…¥ã£ã¦ã„ã‚‹ï¼ˆtestã¯stock_id=0ã®ã¿ï¼‰","metadata":{}},{"cell_type":"code","source":"# book_train.parquetã®ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèª\nimport pandas as pd\nbook_example = pd.read_parquet('../input/optiver-realized-volatility-prediction/book_train.parquet/stock_id=0')\nbook_example.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:06:45.246904Z","iopub.execute_input":"2021-09-20T03:06:45.247584Z","iopub.status.idle":"2021-09-20T03:06:45.719932Z","shell.execute_reply.started":"2021-09-20T03:06:45.247445Z","shell.execute_reply":"2021-09-20T03:06:45.718951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ã‚ªãƒ¼ãƒ€ãƒ¼ãƒ–ãƒƒã‚¯ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ï¼ˆå…¬å¼ã‚ˆã‚Šï¼‰\n![](https://i.imgur.com/16Qt255l.png)\n- bid_price1:æœ€é«˜å£²å€¤ã€‚ç”»åƒã§ã„ã†ã¨147ã«ã‚ãŸã‚‹\n- ask_price1:æœ€ä½è²·å€¤ã€‚ç”»åƒã§ã„ã†ã¨148ã«ã‚ãŸã‚‹\n- bid_price2:2ç•ªç›®ã«é«˜ã„å£²å€¤ã€‚ç”»åƒã§ã„ã†ã¨146ã«ã‚ãŸã‚‹\n- ask_price2:2ç•ªç›®ã«ä½ã„è²·å€¤ã€‚ç”»åƒã§ã„ã†ã¨149ã«ã‚ãŸã‚‹\n- bid_size1:bid_price1ã®æ™‚ã®æ•°ã€‚ç”»åƒã§ã„ã†ã¨251\n- ask_size1:ask_price1ã®æ™‚ã®æ•°ã€‚ç”»åƒã§ã„ã†ã¨221\n- bid_size2:bid_price2ã®æ™‚ã®æ•°ã€‚ç”»åƒã§ã„ã†ã¨321\n- ask_size2:ask_price2ã®æ™‚ã®æ•°ã€‚ç”»åƒã§ã„ã†ã¨148\n\nseconds_in_bucketã¯å¿…ãš0ã‹ã‚‰å§‹ã¾ã‚Šã€ã‚ªãƒ¼ãƒ€ãƒ¼ãƒ–ãƒƒã‚¯ã«ä½•ã‹ã—ã‚‰ã®å‹•ããŒã‚ã‚‹ã¨éšæ™‚ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒè¿½åŠ ã•ã‚Œã‚‹ã€‚\nseconds_in_bucketãŒ1ã®æ™‚ã¯ask_size1ãŒ226ã‹ã‚‰100ã«å¤‰åŒ–ã—ãŸãŸã‚ã€ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒè¿½åŠ ã•ã‚ŒãŸã€‚","metadata":{}},{"cell_type":"code","source":"# trade_train.parquetã®ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèª\nimport pandas as pd\ntrade_example = pd.read_parquet('../input/optiver-realized-volatility-prediction/trade_train.parquet/stock_id=0')\ntrade_example.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:06:45.722097Z","iopub.execute_input":"2021-09-20T03:06:45.722964Z","iopub.status.idle":"2021-09-20T03:06:45.773932Z","shell.execute_reply.started":"2021-09-20T03:06:45.722927Z","shell.execute_reply":"2021-09-20T03:06:45.773103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ã‚ªãƒ¼ãƒ€ãƒ¼ãƒ–ãƒƒã‚¯ã‚’ã‚‚ã¨ã«å®Ÿéš›ã«å£²è²·ãŒè¡Œã‚ã‚Œã‚‹ã¨tradeãƒ‡ãƒ¼ã‚¿ã«ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒè¿½åŠ ã•ã‚Œã‚‹ã€‚\næœ€åˆã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã§ã¯ã€\ntime_id=5ã®21ç§’ã®æ™‚ã«price=1.002301ã§æ ªå¼æ•°326ã€å–å¼•æ³¨æ–‡12ã®ã‚„ã‚Šã¨ã‚ŠãŒè¡Œã‚ã‚ŒãŸ","metadata":{}},{"cell_type":"markdown","source":"## ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã¨ã¯ï¼Ÿ\n","metadata":{}},{"cell_type":"markdown","source":"ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã¨ã¯ä½•ã‹ã‚’ç†è§£ã™ã‚‹å‰ã«WAPã«ã¤ã„ã¦æ„å‘³åˆã„ã‚’ç†è§£ã™ã‚‹\n### WAP(Weighted averaged price)\næ—¥æœ¬èªè¨³ã§ã¯åŠ é‡å¹³å‡ã€‚\nã‚¦ã‚§ã‚¤ãƒˆã‚’è€ƒæ…®ã—ãŸå¹³å‡å€¤ã®ã‚ˆã†ãªã‚¤ãƒ¡ãƒ¼ã‚¸ã§ä¸‹è¨˜ã®å¼ã§è¨ˆç®—ã•ã‚Œã‚‹\n$$\n    ğ‘Šğ´ğ‘ƒ = \\frac{ğµğ‘–ğ‘‘ğ‘ƒğ‘Ÿğ‘–ğ‘ğ‘’1âˆ—ğ´ğ‘ ğ‘˜ğ‘†ğ‘–ğ‘§ğ‘’1+ğ´ğ‘ ğ‘˜ğ‘ƒğ‘Ÿğ‘–ğ‘ğ‘’1âˆ—ğµğ‘–ğ‘‘ğ‘†ğ‘–ğ‘§ğ‘’1}{ğµğ‘–ğ‘‘ğ‘†ğ‘–ğ‘§ğ‘’1+ğ´ğ‘ ğ‘˜ğ‘†ğ‘–ğ‘§ğ‘’1}\n$$\nğ´ğ‘ ğ‘˜ğ‘†ğ‘–ğ‘§ğ‘’1ã¨ğµğ‘–ğ‘‘ğ‘†ğ‘–ğ‘§ğ‘’1ã«æ³¨ç›®ã—ãŸéš›ã«ã€ğ´ğ‘ ğ‘˜ğ‘†ğ‘–ğ‘§ğ‘’ãŒå¤§ãããªã‚Œã°ğµğ‘–ğ‘‘ğ‘ƒğ‘Ÿğ‘–ğ‘ğ‘’ã‚’æ›ã‘ã‚‹å‰²åˆã‚‚å…¨ä½“ã«å¯¾ã—ã¦å¤§ãããªã‚Šã€è¨ˆç®—ã•ã‚ŒãŸå€¤ã¯ğµğ‘–ğ‘‘ğ‘ƒğ‘Ÿğ‘–ğ‘ğ‘’ã¨ğ´ğ‘ ğ‘˜ğ‘ƒğ‘Ÿğ‘–ğ‘ğ‘’ã§ã¯ğµğ‘–ğ‘‘ğ‘ƒğ‘Ÿğ‘–ğ‘ğ‘’ã«è¿‘ã¥ã\n\nã“ã®ã‚ˆã†ã«ãã‚Œãã‚Œã‚’å¹³ç­‰ã«è€ƒãˆã‚‹ã®ã§ã¯ãªãã€è¦ç´ ã®å¤§ãã•ã‚’è€ƒæ…®ã—ãŸä¸Šã§å¹³å‡å€¤ã‚’å–å¾—ã™ã‚‹è€ƒãˆæ–¹ãŒWAP","metadata":{}},{"cell_type":"markdown","source":"### Log retuen\næ ªä¾¡ã®å‰²åˆã®æ¯”ç‡ã‚’å¯¾æ•°ã§å–å¾—ã—ãŸå€¤ã€‚logã®å‰²ã‚Šç®—ã¯å¼•ãç®—ã«å¤‰æ›ã§ãã‚‹ãŸã‚ã€ã‚ã‚‹æ™‚é–“t2ã§ã®WAPã‹ã‚‰ã‚ã‚‹æ™‚é–“t1ã§ã®WAPã®ãã‚Œãã‚Œã®å¯¾æ•°ã‚’å¼•ã„ãŸå€¤\n$$\nğ‘Ÿğ‘¡1,ğ‘¡2 = \\log(\\frac{WAP t2}{WAPt1})\n$$\n$$\n= \\log(WAP t2) - \\log(WAP t1)\n$$","metadata":{}},{"cell_type":"markdown","source":"## Realized volatility\nä¸Šã§å–å¾—ã—ãŸLog returnã®æ¨™æº–åå·®ã‚’ï¼‘å¹´é–“åˆ†è¨ˆç®—ã—ãŸå€¤ã§ã‚ã‚‹å¹´é–“æ¨™æº–åå·®ã‚’ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã¨ã‚ˆã¶ã€‚\n$$\nğœ = \\sqrt{\\sum_{t}^{}ğ‘Ÿ^2ğ‘¡-1,ğ‘¡\\quad}\n$$\nä»Šå›ã¯10åˆ†ï¼ˆsecond_in_bucketãŒ0ã‹ã‚‰600ï¼‰å˜ä½ã§Log returnã‚’æ±‚ã‚ã“ã¨ã‚’ä¸€å¹´åˆ†è¡Œã„ã€æ¨™æº–åå·®ã‚’æ±‚ã‚ã‚‹ã€‚\n\nãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãŒé«˜ã„ã»ã©å£²è²·ã®å‹•ããŒç››ã‚“ã§ã‚ã‚‹ã¨ã„ã†ã“ã¨ã«ãªã‚Šã€æ‰‹æ•°æ–™ã§ä¼šç¤¾ãŒå„²ã‹ã‚‹ã‹ã‚‰ã„ã„å¸‚å ´ã¨ã„ã†ã“ã¨ï¼ˆï¼Ÿï¼‰","metadata":{}},{"cell_type":"markdown","source":"## lgbm baselineã‚’æ—¥æœ¬èªã§è§£é‡ˆ\nmost votesä¸Šä½ã§ã‚ã£ãŸã€Œlgbm baselineã€ã®åˆ†æã‚’è¸è¥²ã—ã¤ã¤ã€ã‚³ãƒ³ãƒšã®ç†è§£ã‚’æ·±ã‚ã¦ã„ãã€‚\nä¸‹è¨˜ã‹ã‚‰å®Ÿéš›ã®ã‚³ãƒ¼ãƒ‰ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆåˆ†ã¯é©å®œè¿½åŠ ï¼‰","metadata":{}},{"cell_type":"code","source":"# å¥½ããªHTMLã‚’èª­ã¿è¾¼ã‚ã‚‹ã‚ˆã†ã«ãªã‚‹ã‚„ã¤ï¼ˆç”»åƒæŒ¿å…¥ãªã©ã«ä½¿ã†ã®ã‹ï¼Ÿï¼‰\nfrom IPython.core.display import display, HTML\n\nimport pandas as pd\nimport numpy as np # linear algebra\n# ãªãœã‹2å›importã—ã¦ãŸã®ã§ç„¡è¦–\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# å¼•æ•°ã«æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã«ãƒãƒƒãƒã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹åã‚’å–å¾—ã—ã¦ãã‚Œã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«\n# ä»Šå›ã¯ä½¿ã£ã¦ã„ãªã‹ã£ãŸ\nimport glob\n\n# osã«ä¾å­˜ã—ã¦ã„ã‚‹æ©Ÿèƒ½ã‚’åˆ©ç”¨ã™ã‚‹ãŸã‚ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«\n# ä¾‹ãˆã°os.walk()ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä¸€è¦§ã‚’å–å¾—ã§ãã‚‹\n# os.system(\"ls\")ã§Unixã‚³ãƒãƒ³ãƒ‰åŒæ§˜ã®çµæœãŒå¾—ã‚‰ã‚Œã‚‹\n# ä»Šå›ã¯ä½¿ã£ã¦ã„ãªã‹ã£ãŸ\nimport os\n\n# ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¯å®Ÿè¡Œä¸­ã«å¿…è¦ãªãƒ¡ãƒ¢ãƒªé ˜åŸŸã‚’å‹•çš„ã«ç¢ºä¿ã™ã‚‹ãŒã€ä¸è¦ã«ãªã£ãŸãƒ¡ãƒ¢ãƒªé ˜åŸŸã‚’è‡ªå‹•çš„ã«è§£æ”¾ã™ã‚‹æ©Ÿèƒ½ã€‚ï¼‰\nimport gc\n\n# ä¸¦åˆ—åŒ–\n# multiproccessingã¨ã„ã†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚‚ä»–ã«ã‚ã‚‹ã£ã½ã„ãŒä»Šå›ã¯joblib\n# CPUã‚’è¤‡æ•°ä½¿ã£ã¦ãã‚Œã‚‹ã‚ˆã†ã«ãªã‚‹ã‚‰ã—ã„ã€‚ã“ã‚ŒãŒã‚ã‚‹ã®ã¨ç„¡ã„ã®ã¨ã§ã¯å‡¦ç†ã®æ™‚é–“ãŒå…¨ç„¶é•ã†\nfrom joblib import Parallel, delayed\n\nfrom sklearn import preprocessing, model_selection\nfrom sklearn.preprocessing import MinMaxScaler #æ­£è¦åŒ–ï¼ˆæœ€å°0,æœ€å¤§1ã¨ãªã‚‹ã‚ˆã†ã«å¤‰æ›ï¼‰\nfrom sklearn.preprocessing import QuantileTransformer #åˆ†ä½ã«ã‚ˆã‚‹å¤‰æ›\nfrom sklearn.metrics import r2_score #æ±ºå®šä¿‚æ•°ã‚’è¨ˆç®—ã™ã‚‹ç”¨ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy.matlib\n\n# matplotlibã¯ã§ãã‚‹ã“ã¨ãŒå¤šãã¦ã„ã„ã‘ã©ã€æ‰±ã†ã®ãŒè¤‡é›‘ã§é¢å€’\n# seabornã¯matplotlibã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ã¦ã„ã‚‹ã‘ã©ã€ã‚‚ã£ã¨è¦‹ã‚„ã™ãã¦ç¶ºéº—ã§ã€ç°¡å˜ã«ã‹ã‘ã‚‹ã‹ã‚‰æœ€é«˜ã‚‰ã—ã„\n\n# è¨­å®šã—ãŸã‚‚ã®ã®ä»Šå›ã¯ä½¿ã£ã¦ã„ãªã‹ã£ãŸ\npath_submissions = '/'\n\n# submissionã®ã‚«ãƒ©ãƒ åã«åˆã‚ã›ã¦\ntarget_name = 'target'\n# ç©ºã®è¾æ›¸å‹ã‚’ç”¨æ„ï¼ˆãŠãã‚‰ãæå‡ºç”¨ï¼‰\nscores_folds = {}","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-20T03:06:45.775486Z","iopub.execute_input":"2021-09-20T03:06:45.775838Z","iopub.status.idle":"2021-09-20T03:06:46.91055Z","shell.execute_reply.started":"2021-09-20T03:06:45.775806Z","shell.execute_reply":"2021-09-20T03:06:46.909666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## WAPã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°ã‚’ä½œæˆ","metadata":{}},{"cell_type":"code","source":"# data directory\n# Kaggleã‚’ã™ã‚‹éš›ã®ç’°å¢ƒã‚’åŒºåˆ¥ã—ã¦PATHã‚’è¨­å®šã™ã‚‹ã‚³ãƒ¼ãƒ‰\n# ä»Šå›ã¯bookã¨tradeã®ãƒ‡ãƒ¼ã‚¿ãŒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå¤§é‡ã«ã‚ã£ã¦ãã®ä¸­ã«ãã‚Œãã‚Œã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹ãŸã‚pathã‚’æœ€åˆã«æŒ‡å®šã—ã¦ã—ã¾ã†ã®ãŒæ¥½\ndata_dir = '../input/optiver-realized-volatility-prediction/'\n\n# 1ç•ªç›®ã®WAP(åŠ é‡å¹³å‡)ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°ï¼ˆæœ€é«˜å£²å€¤ã¨ãã®å€‹æ•°ã€æœ€ä½è²·å€¤ã¨ãã®å€‹æ•°ã‚’ä½¿ã£ã¦è¨ˆç®—ï¼‰\n# å¼•æ•°ã«dfã‚’è¨­å®š\ndef calc_wap1(df):\n    wap = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) / (df['bid_size1'] + df['ask_size1'])\n    return wap\n\n# 2ç•ªç›®ã®WAP(åŠ é‡å¹³å‡)ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°ï¼ˆ2ç•ªç›®ã«é«˜ã„å£²å€¤ã¨ãã®å€‹æ•°ã€2ç•ªç›®ã«ä½ã„è²·å€¤ã¨ãã®å€‹æ•°ã‚’ä½¿ã£ã¦è¨ˆç®—ï¼‰\ndef calc_wap2(df):\n    wap = (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']) / (df['bid_size2'] + df['ask_size2'])\n    return wap\n\n# WAPã¨ã—ã¦ã„ã‚‹ãŒbidåŒå£«askåŒå£«ã‚’æ›ã‘åˆã‚ã›ã¦ã„ã‚‹ãŸã‚è‹¥å¹²æ„å‘³åˆã„ãŒé•ã†\ndef calc_wap3(df):\n    wap = (df['bid_price1'] * df['bid_size1'] + df['ask_price1'] * df['ask_size1']) / (df['bid_size1'] + df['ask_size1'])\n    return wap\n\n# wap3ã®2ç•ªç›®ver\ndef calc_wap4(df):\n    wap = (df['bid_price2'] * df['bid_size2'] + df['ask_price2'] * df['ask_size2']) / (df['bid_size2'] + df['ask_size2'])\n    return wap","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:06:46.912367Z","iopub.execute_input":"2021-09-20T03:06:46.912688Z","iopub.status.idle":"2021-09-20T03:06:46.921514Z","shell.execute_reply.started":"2021-09-20T03:06:46.912655Z","shell.execute_reply":"2021-09-20T03:06:46.920683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"WAPã¨ã¯åˆ¥ã§bidåŒå£«askåŒå£«ã‚’æ›ã‘åˆã‚ã›ãŸã‚‚ã®ã‚’ãªãœä½œæˆã—ãŸã®ã‹ã¯ä¸æ˜","metadata":{}},{"cell_type":"markdown","source":"## Log returnã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°ã‚’ä½œæˆ","metadata":{}},{"cell_type":"code","source":"# Log returnã®é–¢æ•°ã‚’ä½œæˆ\n# np.log(series).diff() = np.log(series) - np.log(series.shift()) ï¼ˆä¸€å€‹å‰ã®å¯¾æ•°ã®å·®åˆ†ï¼‰\ndef log_return(series):\n    return np.log(series).diff()","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:06:46.922848Z","iopub.execute_input":"2021-09-20T03:06:46.923149Z","iopub.status.idle":"2021-09-20T03:06:46.938155Z","shell.execute_reply.started":"2021-09-20T03:06:46.923111Z","shell.execute_reply":"2021-09-20T03:06:46.937546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ç›®çš„å¤‰æ•°ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°","metadata":{}},{"cell_type":"code","source":"# ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ã®é–¢æ•°\ndef realized_volatility(series):\n    return np.sqrt(np.sum(series**2))","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:06:46.93927Z","iopub.execute_input":"2021-09-20T03:06:46.939901Z","iopub.status.idle":"2021-09-20T03:06:46.950739Z","shell.execute_reply.started":"2021-09-20T03:06:46.939854Z","shell.execute_reply":"2021-09-20T03:06:46.949829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# é‡è¤‡ãªãæ•°ãˆãŸæ™‚ã®å€‹æ•°ã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ã®é–¢æ•°\n# np.unique(series)ã§seriesã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªå€¤ãŒä¸€è¦§ã§å–å¾—ã•ã‚Œã€ãã‚Œã®len()ãªã®ã§å€‹æ•°ãŒå–å¾—ã•ã‚Œã‚‹\ndef count_unique(series):\n    return len(np.unique(series))","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:06:46.952179Z","iopub.execute_input":"2021-09-20T03:06:46.952709Z","iopub.status.idle":"2021-09-20T03:06:46.962731Z","shell.execute_reply.started":"2021-09-20T03:06:46.952677Z","shell.execute_reply":"2021-09-20T03:06:46.962161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"å‰ç½®ãã§è§£èª¬ã—ãŸWAP, Log return, ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’è¨ˆç®—ã™ã‚‹ãŸã‚ã®é–¢æ•°ã‚’è¨­å®š\n\nç¶šã„ã¦ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿","metadata":{}},{"cell_type":"markdown","source":"## è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿","metadata":{}},{"cell_type":"code","source":"# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ãŸã‚ã®é–¢æ•°\ndef read_train_test():\n    train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n    test = pd.read_csv('../input/optiver-realized-volatility-prediction/test.csv')\n    # bookãƒ‡ãƒ¼ã‚¿ã¨tradeãƒ‡ãƒ¼ã‚¿ã‚’çµåˆã™ã‚‹ãŸã‚ã®idã¨ãªã‚‹ã‚«ãƒ©ãƒ ã‚’è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«ãã‚Œãã‚Œã«è¿½åŠ \n    train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n    test['row_id'] = test['stock_id'].astype(str) + '-' + test['time_id'].astype(str)\n    print(f'Our training set has {train.shape[0]} rows')\n    return train, test","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:06:46.96419Z","iopub.execute_input":"2021-09-20T03:06:46.964682Z","iopub.status.idle":"2021-09-20T03:06:46.973967Z","shell.execute_reply.started":"2021-09-20T03:06:46.964652Z","shell.execute_reply":"2021-09-20T03:06:46.973436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trainã¨testã®æ¦‚è¦ã‚’ãƒã‚§ãƒƒã‚¯\nread_train_test()","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:06:46.975403Z","iopub.execute_input":"2021-09-20T03:06:46.975831Z","iopub.status.idle":"2021-09-20T03:06:48.517674Z","shell.execute_reply.started":"2021-09-20T03:06:46.975801Z","shell.execute_reply":"2021-09-20T03:06:48.516534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ãã‚Œãã‚Œã«row_idãŒè¿½åŠ ã•ã‚ŒãŸãŸã‚mergeãŒå¯èƒ½","metadata":{}},{"cell_type":"markdown","source":"## ã‚ªãƒ¼ãƒ€ãƒ¼ãƒ–ãƒƒã‚¯ã¨ãƒˆãƒ¬ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’é›†è¨ˆã—ãŸä¸Šã§çµåˆã™ã‚‹ãŸã‚ã®é–¢æ•°","metadata":{}},{"cell_type":"code","source":"# ã‚ªãƒ¼ãƒ€ãƒ¼ãƒ–ãƒƒã‚¯ã®ãƒ‡ãƒ¼ã‚¿ã‚’åŠ å·¥ã—ã¦ã„ã\n# ãã‚Œãã‚Œã®éŠ˜æŸ„ï¼ˆstock_idï¼‰ã”ã¨ã«å‰å‡¦ç†ã‚’ã™ã‚‹ãŸã‚ã®é–¢æ•°ã‚’è¨­å®š\ndef book_preprocessor(file_path):\n    # ApacheParquetã¨ã¯csvãªã©ã®è¡Œå¿—å‘ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¨é•ã„ã€åˆ—å¿—å‘ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ã€åˆ—å˜ä½ã§ãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šå‡ºã™åˆ†æç”¨é€”ã«å‘ã„ã¦ã‚‹\n    df = pd.read_parquet(file_path)\n    # WAP(åŠ é‡å¹³å‡)ã‚’è¨ˆç®—ã—ãŸä¸Šã§ç‰¹å¾´é‡ã¨ã—ã¦è¿½åŠ \n    df['wap1'] = calc_wap1(df)\n    df['wap2'] = calc_wap2(df)\n    df['wap3'] = calc_wap3(df)\n    df['wap4'] = calc_wap4(df)\n    # Log retuenã‚’è¨ˆç®—ã—ãŸä¸Šã§ç‰¹å¾´é‡ã¨ã—ã¦è¿½åŠ \n    # applyã§dataframeã«å¯¾ã—ã¦å…¨ã¦ã®æ“ä½œã‚’è¡Œã†\n    # ä»Šå›ã¯time_idã”ã¨ã®ãã‚Œãã‚Œã®wapã®åˆ—ã«å¯¾ã—ã¦log_returnã‚’è¡Œã†\n    df['log_return1'] = df.groupby(['time_id'])['wap1'].apply(log_return)\n    df['log_return2'] = df.groupby(['time_id'])['wap2'].apply(log_return)\n    df['log_return3'] = df.groupby(['time_id'])['wap3'].apply(log_return)\n    df['log_return4'] = df.groupby(['time_id'])['wap4'].apply(log_return)\n    # WAP1ã¨WAP2åŒå£«ã®å·®åˆ†ã®çµ¶å¯¾å€¤ã‚’å–å¾—ã—ç‰¹å¾´é‡ã¨ã—ã¦è¿½åŠ \n    df['wap_balance'] = abs(df['wap1'] - df['wap2'])\n    # spreadï¼ˆæœ€é«˜å£²å€¤ã¨æœ€ä½è²·å€¤ã®æ¯”ç‡ã‚’ã¨ã£ã¦è¨ˆç®—ã•ã‚Œã‚‹å€¤ï¼‰ã‚’è¨ˆç®—ã—ã€ç‰¹å¾´é‡ã¨ã—ã¦è¿½åŠ \n    df['price_spread'] = (df['ask_price1'] - df['bid_price1']) / ((df['ask_price1'] + df['bid_price1']) / 2)\n    df['price_spread2'] = (df['ask_price2'] - df['bid_price2']) / ((df['ask_price2'] + df['bid_price2']) / 2)\n    df['bid_spread'] = df['bid_price1'] - df['bid_price2']\n    df['ask_spread'] = df['ask_price1'] - df['ask_price2']\n    df[\"bid_ask_spread\"] = abs(df['bid_spread'] - df['ask_spread'])\n    df['total_volume'] = (df['ask_size1'] + df['ask_size2']) + (df['bid_size1'] + df['bid_size2'])\n    df['volume_imbalance'] = abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2']))\n    \n    # è¾æ›¸å‹ã‚’ç”¨æ„ã™ã‚‹\n    # ã‚«ãƒ©ãƒ åã¨è¡Œã†æ“ä½œã‚’ã‚»ãƒƒãƒˆ\n    create_feature_dict = {\n        'wap1': [np.sum, np.std],\n        'wap2': [np.sum, np.std],\n        'wap3': [np.sum, np.std],\n        'wap4': [np.sum, np.std],\n        'log_return1': [realized_volatility],\n        'log_return2': [realized_volatility],\n        'log_return3': [realized_volatility],\n        'log_return4': [realized_volatility],\n        'wap_balance': [np.sum, np.max],\n        'price_spread':[np.sum, np.max],\n        'price_spread2':[np.sum, np.max],\n        'bid_spread':[np.sum, np.max],\n        'ask_spread':[np.sum, np.max],\n        'total_volume':[np.sum, np.max],\n        'volume_imbalance':[np.sum, np.max],\n        \"bid_ask_spread\":[np.sum,  np.max],\n    }\n    create_feature_dict_time = {\n        'log_return1': [realized_volatility],\n        'log_return2': [realized_volatility],\n        'log_return3': [realized_volatility],\n        'log_return4': [realized_volatility],\n    }\n    \n    # DataFrameã®çµ„ã¿ç›´ã—\n    ## å¼•æ•°ã®add_suffixã¯ä¸‹è¨˜ï¼ˆ*ï¼‰\n    def get_stats_window(fe_dict,seconds_in_bucket, add_suffix = False):\n        # dfã®ä¸­ã§ã‚‚dfã®'seconds_in_bucket'ã‚«ãƒ©ãƒ ã«å…¥ã£ã¦ã„ã‚‹å€¤ãŒseconds_in_bucketã‚ˆã‚Šå¤§ãã„æ™‚\n        # è¾æ›¸å‹ã¨ä½œã£ã¦aggã¨reset_index()ã§æ–°ãŸã«DataFrameã‚’ä½œã‚‹ã‚»ãƒƒãƒˆã®ã‚ˆã†ãªå½¹å‰²ï¼Ÿ\n        # å¼•æ•°ã«ä½•ã‚‚æŒ‡å®šã›ãšreset_index()ã‚’ä½¿ã†ã¨ã€é€£ç•ªãŒæ–°ãŸãªindexã¨ãªã‚Šã€å…ƒã®indexãŒæ–°ãŸãªåˆ—ã¨ã—ã¦æ®‹ã‚‹\n        # ã“ã‚Œã‚’ã‚„ã‚‹ã“ã¨ã§è¾æ›¸å‹ã§è¨­å®šã—ãŸæœ€å¤§å€¤ã‚„å¹³å‡å€¤ãŒè¨ˆç®—ã•ã‚ŒãŸã‚‚ã®ã®DataFrameã¨ãªã‚‹ãŸã‚æ¬ æå€¤ãŒç„¡è¦–ã•ã‚Œã‚‹\n        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(fe_dict).reset_index()\n        # æ¥å°¾è¾ã‚’çµåˆã™ã‚‹åˆ—ã®åå‰ã‚’å¤‰æ›´ã™ã‚‹\n        # wap1 sum â†’ wap1_sumã«ã—ãŸã„\n        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n        \n        # *\n        # add_suffixï¼šã‚«ãƒ©ãƒ ã®ã‚±ãƒ„ã«ã€Œ_ç§’æ•°ã€ã‚’ã¤ã‘ã‚‹\n        if add_suffix:\n            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n        return df_feature\n    \n    # seconds_in_bucketã‚’100ç§’ã”ã¨ã«create_feature_dictã‚’è¨ˆç®—ã—ã¦DataFrameã¨ã™ã‚‹\n    df_feature = get_stats_window(create_feature_dict,seconds_in_bucket = 0, add_suffix = False)\n    df_feature_500 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 500, add_suffix = True)\n    df_feature_400 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 400, add_suffix = True)\n    df_feature_300 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 300, add_suffix = True)\n    df_feature_200 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 200, add_suffix = True)\n    df_feature_100 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 100, add_suffix = True)\n\n    # DataFrameã®çµåˆ\n    df_feature = df_feature.merge(df_feature_500, how = 'left', left_on = 'time_id_', right_on = 'time_id__500')\n    df_feature = df_feature.merge(df_feature_400, how = 'left', left_on = 'time_id_', right_on = 'time_id__400')\n    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n    df_feature = df_feature.merge(df_feature_200, how = 'left', left_on = 'time_id_', right_on = 'time_id__200')\n    df_feature = df_feature.merge(df_feature_100, how = 'left', left_on = 'time_id_', right_on = 'time_id__100')\n    # ä¸è¦ã«ãªã£ãŸçµåˆç”¨ã®ã‚«ãƒ©ãƒ ã‚’å‰Šé™¤\n    df_feature.drop(['time_id__500','time_id__400', 'time_id__300', 'time_id__200','time_id__100'], axis = 1, inplace = True)\n    \n    \n    # ã®ã¡ã«tradeãƒ‡ãƒ¼ã‚¿ã¨çµåˆã™ã‚‹ç”¨ã®row_idã¨ã„ã†ã‚«ãƒ©ãƒ ã‚’ä½œæˆ\n    # stock_id=0ã¨ãªã£ã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®0ã®éƒ¨åˆ†ã ã‘ã‚’å–ã‚Šå‡ºã—ã€stock_idã«ä»£å…¥ã™ã‚‹\n    stock_id = file_path.split('=')[1]\n    # time_idã¨stock_idãŒç¹‹ãŒã£ãŸã€Œ0-32ã€ã®ã‚ˆã†ãªå½¢ã®row_idã‚’ä½œæˆ\n    df_feature['row_id'] = df_feature['time_id_'].apply(lambda x: f'{stock_id}-{x}')\n    df_feature.drop(['time_id_'], axis = 1, inplace = True)\n    return df_feature","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:06:48.521939Z","iopub.execute_input":"2021-09-20T03:06:48.52259Z","iopub.status.idle":"2021-09-20T03:06:48.550466Z","shell.execute_reply.started":"2021-09-20T03:06:48.522549Z","shell.execute_reply":"2021-09-20T03:06:48.549421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ãƒˆãƒ¬ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿\n\n# ã‚ªãƒ¼ãƒ€ãƒ¼ãƒ–ãƒƒã‚¯ã¨åŒã˜ã‚ˆã†ãªæ“ä½œã‚’è¡Œã†\ndef trade_preprocessor(file_path):\n    df = pd.read_parquet(file_path)\n    # dfã‚’time_idã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦ãã®ã†ã¡ã®ã€Œpriceã€ã‚«ãƒ©ãƒ ã«log_returnã‚’é©ç”¨ã™ã‚‹\n    df['log_return'] = df.groupby('time_id')['price'].apply(log_return)\n    #  å–å¼•ã•ã‚ŒãŸåˆè¨ˆé‡‘é¡ã‚’å–å¾—ã—ç‰¹å¾´é‡ã¨ã—ã¦è¿½åŠ \n    df['amount']=df['price']*df['size']\n    # è¾æ›¸å‹ã‚’ç”¨æ„\n    create_feature_dict = {\n        'log_return':[realized_volatility],\n        'seconds_in_bucket':[count_unique],\n        'size':[np.sum, np.max, np.min],\n        'order_count':[np.sum,np.max],\n        'amount':[np.sum,np.max,np.min],\n    }\n    create_feature_dict_time = {\n        'log_return':[realized_volatility],\n        'seconds_in_bucket':[count_unique],\n        'size':[np.sum],\n        'order_count':[np.sum],\n    }\n    \n    def get_stats_window(fe_dict,seconds_in_bucket, add_suffix = False):\n        # bookã¨åŒã˜å‡¦ç†\n        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(fe_dict).reset_index()\n        # ã‚±ãƒ„ã«ã€Œ_df_featureã®ã‚«ãƒ©ãƒ åã€ã‚’ã¤ã‘ã‚‹\n        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n        # ã‚±ãƒ„ã«ã€Œ_ç§’æ•°ã€ã¨ã¤ã‘ã‚‹ãŸã‚ã®è‡ªä½œé–¢æ•° \n        if add_suffix:\n            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n        return df_feature\n    \n\n    df_feature = get_stats_window(create_feature_dict,seconds_in_bucket = 0, add_suffix = False)\n    df_feature_500 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 500, add_suffix = True)\n    df_feature_400 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 400, add_suffix = True)\n    df_feature_300 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 300, add_suffix = True)\n    df_feature_200 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 200, add_suffix = True)\n    df_feature_100 = get_stats_window(create_feature_dict_time,seconds_in_bucket = 100, add_suffix = True)\n    \n    def tendency(price, vol):\n        # priceã®å·®åˆ†\n        df_diff = np.diff(price)\n        # å¢—åŠ ç‡çš„ãª\n        val = (df_diff/price[1:])*100\n        # æŒ‡å®šã—ãŸãƒœãƒªãƒ¥ãƒ¼ãƒ ã«å¢—åŠ ç‡ã‚’ã‹ã‘ãŸã‚‚ã®ã‚’åˆè¨ˆã—ãŸå€¤\n        power = np.sum(val*vol[1:])\n        return(power)\n    \n    lis = []\n    # n_tim_idã¯dfå†…ã®time_idãŒãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚‚ã®\n    for n_time_id in df['time_id'].unique():\n        # ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªtime_idã”ã¨ã«dfã®idã‚’å–å¾—ï¼ˆtime_idãŒ0ã®æ™‚ã®dfã‚’df_id=0ã¨ã™ã‚‹ï¼‰\n        df_id = df[df['time_id'] == n_time_id]\n        # ãã‚Œãã‚Œã®df_idã”ã¨ï¼ˆã¤ã¾ã‚Štime_idã”ã¨ï¼‰ã®å€¤æ®µã¨æ ªå¼æ•°ã‚’ã‹ã‘ãŸåˆè¨ˆå–å¼•é‡‘é¡\n        tendencyV = tendency(df_id['price'].values, df_id['size'].values)\n        # å¹³å‡é‡‘é¡ã‚ˆã‚Šã‚‚å¤§ãã„é‡‘é¡ã‹ã©ã†ã‹\n        f_max = np.sum(df_id['price'].values > np.mean(df_id['price'].values))\n        f_min = np.sum(df_id['price'].values < np.mean(df_id['price'].values))\n        df_max =  np.sum(np.diff(df_id['price'].values) > 0)\n        df_min =  np.sum(np.diff(df_id['price'].values) < 0)\n        # æ¨™æº–åå·®ã®çµ¶å¯¾å€¤ã®ä¸­å¤®å€¤ï¼Ÿçš„ãªã‚¤ãƒ¡ãƒ¼ã‚¸\n        abs_diff = np.median(np.abs( df_id['price'].values - np.mean(df_id['price'].values)))\n        # ãã‚Œãã‚Œã®priceã®2ä¹—ã®å¹³å‡\n        energy = np.mean(df_id['price'].values**2)\n        # å››åˆ†ä½ç‚¹ã®å¼•ãç®—\n        iqr_p = np.percentile(df_id['price'].values,75) - np.percentile(df_id['price'].values,25)\n        \n        # æ ªå¼æ•°ã§ã‚‚åŒã˜æ“ä½œã‚’è¡Œã†\n        \n        abs_diff_v = np.median(np.abs( df_id['size'].values - np.mean(df_id['size'].values)))        \n        energy_v = np.sum(df_id['size'].values**2)\n        iqr_p_v = np.percentile(df_id['size'].values,75) - np.percentile(df_id['size'].values,25)\n        \n        # å…ˆã»ã©ä½œã£ãŸç©ºã®é…åˆ—ã«ç”¨æ„ã—ãŸDataFrameã‚’è¿½åŠ \n        lis.append({'time_id':n_time_id,'tendency':tendencyV,'f_max':f_max,'f_min':f_min,'df_max':df_max,'df_min':df_min,\n                   'abs_diff':abs_diff,'energy':energy,'iqr_p':iqr_p,'abs_diff_v':abs_diff_v,'energy_v':energy_v,'iqr_p_v':iqr_p_v})\n    \n    # DataFrameåŒ–\n    df_lr = pd.DataFrame(lis)\n        \n   # df_featureã«çµåˆ\n    df_feature = df_feature.merge(df_lr, how = 'left', left_on = 'time_id_', right_on = 'time_id')\n    \n    # 100ç§’ã”ã¨ã«åˆ‡ã£ãŸãã‚Œãã‚Œã®dfã‚‚çµåˆ\n    df_feature = df_feature.merge(df_feature_500, how = 'left', left_on = 'time_id_', right_on = 'time_id__500')\n    df_feature = df_feature.merge(df_feature_400, how = 'left', left_on = 'time_id_', right_on = 'time_id__400')\n    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n    df_feature = df_feature.merge(df_feature_200, how = 'left', left_on = 'time_id_', right_on = 'time_id__200')\n    df_feature = df_feature.merge(df_feature_100, how = 'left', left_on = 'time_id_', right_on = 'time_id__100')\n    # mergeç”¨ã®ã‚«ãƒ©ãƒ ã‚’å‰Šé™¤\n    df_feature.drop(['time_id__500','time_id__400', 'time_id__300', 'time_id__200','time_id','time_id__100'], axis = 1, inplace = True)\n    \n    # add_suffixã®å…ˆé ­ã«ã¤ã‘ã‚‹ver\n    df_feature = df_feature.add_prefix('trade_')\n    # ã“ã¡ã‚‰ã‚‚row_idã‚’å–å¾—\n    stock_id = file_path.split('=')[1]\n    df_feature['row_id'] = df_feature['trade_time_id_'].apply(lambda x:f'{stock_id}-{x}')\n    df_feature.drop(['trade_time_id_'], axis = 1, inplace = True)\n    return df_feature","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:06:48.552305Z","iopub.execute_input":"2021-09-20T03:06:48.55269Z","iopub.status.idle":"2021-09-20T03:06:48.580113Z","shell.execute_reply.started":"2021-09-20T03:06:48.552659Z","shell.execute_reply":"2021-09-20T03:06:48.579092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ã‚ªãƒ¼ãƒ€ãƒ¼ãƒ–ãƒƒã‚¯ã¨ãƒˆãƒ¬ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’éŠ˜æŸ„ã”ã¨ã«æ“ä½œã™ã‚‹ãŸã‚ã®é–¢æ•°ã¯è¨­å®šå®Œäº†\n\né“ä¸­ã§è¡Œãªã£ã¦ã„ãŸæ“ä½œã¯å­¦ç¿’ã«å¿…è¦ãªç‰¹å¾´é‡ã‚’è¿½åŠ ã™ã‚‹ãŸã‚ã®ã‚‚ã®ã§ã€ã“ã“ã‚’å¾Œã€…è‡ªåˆ†ã§ã‚‚ã©ã‚“ãªã‚‚ã®ãŒè‰¯ã„ã‹è€ƒãˆã‚‹å¿…è¦ãŒã‚ã‚‹","metadata":{}},{"cell_type":"markdown","source":"## stock_idã¨time_idã”ã¨ã®é›†è¨ˆã‚’è¡Œã†ãŸã‚ã®é–¢æ•°ã‚’è¨­å®š","metadata":{}},{"cell_type":"markdown","source":"stock_id=0ã ã‘ã§ã‚‚ãƒ‡ãƒ¼ã‚¿æ•°ãŒ120ä¸‡ãã‚‰ã„ã‚ã‚‹ãŸã‚ç·æ•°ã§1å„„ã¯è¶…ãˆãã†ã€‚é›†è¨ˆã—ã¦ãŠã‹ãªã„ã¨pcãŒè½ã¡ã‚‹","metadata":{}},{"cell_type":"code","source":"# stock_idã¨time_idã”ã¨ã®é›†è¨ˆã‚’è¡Œã†ãŸã‚ã®é–¢æ•°ã‚’è¨­å®š\ndef get_time_stock(df):\n    # ã‚«ãƒ©ãƒ åã‚’ä¸€æ¬¡å…ƒé…åˆ—ã§æŒ‡å®š\n    vol_cols = ['log_return1_realized_volatility', 'log_return2_realized_volatility', 'log_return1_realized_volatility_400', 'log_return2_realized_volatility_400', \n                'log_return1_realized_volatility_300', 'log_return2_realized_volatility_300', 'log_return1_realized_volatility_200', 'log_return2_realized_volatility_200', \n                'trade_log_return_realized_volatility', 'trade_log_return_realized_volatility_400', 'trade_log_return_realized_volatility_300', 'trade_log_return_realized_volatility_200']\n\n    # stock_idã”ã¨ã«é›†è¨ˆï¼ˆå¹³å‡ã€æ¨™æº–åå·®ã€æœ€å¤§å€¤ã€æœ€å°å€¤ã‚’å–å¾—ï¼‰\n    df_stock_id = df.groupby(['stock_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n    # stockã®æ–¹ã ã¨ã‚ã‹ã‚‹ã‚ˆã†ã«ã‚±ãƒ„ã«ã€Œ_stockã€ã¨è¿½åŠ \n    df_stock_id.columns = ['_'.join(col) for col in df_stock_id.columns]\n    df_stock_id = df_stock_id.add_suffix('_' + 'stock')\n\n    # time_idã”ã¨ã«é›†è¨ˆï¼ˆå¹³å‡ã€æ¨™æº–åå·®ã€æœ€å¤§å€¤ã€æœ€å°å€¤ã‚’å–å¾—ï¼‰\n    df_time_id = df.groupby(['time_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n    # timeã®æ–¹ã ã¨ã‚ã‹ã‚‹ã‚ˆã†ã«ã‚±ãƒ„ã«ã€Œ_timeã€ã¨è¿½åŠ \n    df_time_id.columns = ['_'.join(col) for col in df_time_id.columns]\n    df_time_id = df_time_id.add_suffix('_' + 'time')\n    \n    # dfã«stock_idã”ã¨ã«é›†è¨ˆã—ãŸã‚‚ã®ã¨time_idã”ã¨ã«é›†è¨ˆã—ãŸã‚‚ã®ã‚’çµåˆ\n    df = df.merge(df_stock_id, how = 'left', left_on = ['stock_id'], right_on = ['stock_id__stock'])\n    df = df.merge(df_time_id, how = 'left', left_on = ['time_id'], right_on = ['time_id__time'])\n    df.drop(['stock_id__stock', 'time_id__time'], axis = 1, inplace = True)\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:06:48.583315Z","iopub.execute_input":"2021-09-20T03:06:48.584465Z","iopub.status.idle":"2021-09-20T03:06:48.597369Z","shell.execute_reply.started":"2021-09-20T03:06:48.584424Z","shell.execute_reply":"2021-09-20T03:06:48.596207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ä¸¦åˆ—å‡¦ç†","metadata":{}},{"cell_type":"code","source":"# ä¸¦åˆ—åŒ–\n# ä»Šã¾ã§ã«ä½œã£ãŸå‰å‡¦ç†ç”¨ã®é–¢æ•°ã‚’ä¸¦åˆ—åŒ–ã™ã‚‹ãŸã‚ã®é–¢æ•°\ndef preprocessor(list_stock_ids, is_train = True):\n    \n    # Parallel for loop\n    def for_joblib(stock_id):\n        if is_train:\n            # is_train=Trueã¨æŒ‡å®šã•ã‚ŒãŸå ´åˆtrainãƒ‡ãƒ¼ã‚¿ã®æ–¹ã¸ã®pathã‚’ä½œæˆ\n            file_path_book = data_dir + \"book_train.parquet/stock_id=\" + str(stock_id)\n            file_path_trade = data_dir + \"trade_train.parquet/stock_id=\" + str(stock_id)\n        else:\n            # is_train=Falseã¤ã¾ã‚Štestãƒ‡ãƒ¼ã‚¿ãªã‚‰ã“ã¡ã‚‰ã¸ã®pathã‚’ä½œæˆ\n            file_path_book = data_dir + \"book_test.parquet/stock_id=\" + str(stock_id)\n            file_path_trade = data_dir + \"trade_test.parquet/stock_id=\" + str(stock_id)\n    \n        # bookã¨tradeã‚’å‰å‡¦ç†ã—ãŸä¸Šã§çµåˆã™ã‚‹\n        # äº›ç´°ãªå¤‰åŒ–ã‚‚å…¨ã¦ãƒ¬ã‚³ãƒ¼ãƒ‰ã¨ã—ã¦è¨˜éŒ²ã•ã‚Œã¦ã„ã‚‹bookã®æ–¹ã«row_idã‚’åŸºæº–ã«tradeã‚’å¤–éƒ¨çµåˆã™ã‚‹\n        df_tmp = pd.merge(book_preprocessor(file_path_book), trade_preprocessor(file_path_trade), on = 'row_id', how = 'left')\n        \n        # çµåˆã—ãŸDataFrameã‚’è¿”ã™\n        return df_tmp\n    \n    # ä¸¦åˆ—APIã‚’ä½¿ç”¨ã—ã¦for_joblibé–¢æ•°ã‚’å‘¼ã³å‡ºã™\n    # n_jobs:æœ€å¤§åŒæ™‚å®Ÿè¡Œã‚¸ãƒ§ãƒ–æ•°ã€‚-1ã¨ã™ã‚‹ã¨å…¨ã¦ã®CPUãŒä½¿ç”¨ã•ã‚Œã‚‹\n    # verbose:ãƒ­ã‚°ã®å‡ºåŠ›ãƒ¬ãƒ™ãƒ«ï¼ˆå†—é•·æ€§ï¼‰ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ä½•ã‚‚å‡ºåŠ›ã•ã‚Œãªã„ã€‚å€¤ã‚’å¤§ããã™ã‚‹ã¨å‡ºåŠ›ãƒ¬ãƒ™ãƒ«ãŒä¸ŠãŒã‚‹ï¼ˆå†—é•·æ€§ãŒå¢—ã™ï¼‰ã€‚10ã‚ˆã‚Šå¤§ãã„ã¨ã™ã¹ã¦ã®ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã€50ä»¥ä¸Šã ã¨stdoutï¼ˆæ¨™æº–å‡ºåŠ›ï¼‰ã«å‡ºåŠ›ã•ã‚Œã‚‹ã€‚\n    # delayed(<å®Ÿè¡Œã™ã‚‹é–¢æ•°>)(<é–¢æ•°ã¸ã®å¼•æ•°>) for å¤‰æ•°å in ã‚¤ãƒ†ãƒ©ãƒ–ãƒ«\n    # å®Ÿè¡Œã™ã‚‹é–¢æ•°ï¼ˆbookã¨tradeã‚’å‰å‡¦ç†ã—ã¦çµåˆï¼‰ã‚’stock_idã”ã¨ã«è¡Œã†\n    df = Parallel(n_jobs = -1, verbose = 1)(delayed(for_joblib)(stock_id) for stock_id in list_stock_ids)\n    # Parallelã‹ã‚‰è¿”ã•ã‚Œã‚‹ã™ã¹ã¦ã®DataFrameã‚’çµåˆ\n    # ignore_index=Trueã§indexãŒconcatå‰ã®indexã‚’ç„¡è¦–ã—ã¦é€£ç•ªã§æŒ¯ã‚‰ã‚Œã‚‹\n    df = pd.concat(df, ignore_index = True)\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:06:48.599016Z","iopub.execute_input":"2021-09-20T03:06:48.599352Z","iopub.status.idle":"2021-09-20T03:06:48.61534Z","shell.execute_reply.started":"2021-09-20T03:06:48.599311Z","shell.execute_reply":"2021-09-20T03:06:48.614104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## RMSPEã§ç„¡é§„ãªå‡¦ç†ãŒèµ°ã‚‹ã®ã‚’æ­¢ã‚ã‚‹","metadata":{}},{"cell_type":"code","source":"# RMSPE(å¹³å‡å¹³æ–¹äºŒä¹—èª¤å·®ç‡)\ndef rmspe(y_true, y_pred):\n    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:06:48.616757Z","iopub.execute_input":"2021-09-20T03:06:48.617072Z","iopub.status.idle":"2021-09-20T03:06:48.633781Z","shell.execute_reply.started":"2021-09-20T03:06:48.617043Z","shell.execute_reply":"2021-09-20T03:06:48.632776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RMSPEã§æ—©æœŸåœæ­¢ã™ã‚‹é–¢æ•°\ndef feval_rmspe(y_pred, lgb_train):\n    y_true = lgb_train.get_label()\n    return 'RMSPE', rmspe(y_true, y_pred), False","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:06:48.634996Z","iopub.execute_input":"2021-09-20T03:06:48.63539Z","iopub.status.idle":"2021-09-20T03:06:48.645755Z","shell.execute_reply.started":"2021-09-20T03:06:48.635355Z","shell.execute_reply":"2021-09-20T03:06:48.644589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨testãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ãŸé–¢æ•°ã«ã‚ˆã£ã¦èª­ã¿è¾¼ã‚€","metadata":{}},{"cell_type":"code","source":"# trainãƒ‡ãƒ¼ã‚¿ã¨testãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿\ntrain, test = read_train_test()\n\n# ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªstockã®idã‚’å–å¾—ã™ã‚‹\ntrain_stock_ids = train['stock_id'].unique()\n# ä¸¦åˆ—å‡¦ç†ã«ä½¿ã†ãŸã‚ã«å‰å‡¦ç†ã‚’è¡Œã†\n# ä»Šå›ã¯ä¸¦åˆ—åŒ–ã—ã¦bookã¨tradeã‚’stock_idã”ã¨ã«å‡¦ç†ã‚’ã—ãŸä¸Šã§çµåˆã™ã‚‹\ntrain_ = preprocessor(train_stock_ids, is_train = True)\n# row_idã‚’åŸºæº–ã«left joinã™ã‚‹\ntrain = train.merge(train_, on = ['row_id'], how = 'left')\n\n# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã‚‚åŒã˜å‡¦ç†ã‚’è¡Œã†\ntest_stock_ids = test['stock_id'].unique()\ntest_ = preprocessor(test_stock_ids, is_train = False)\ntest = test.merge(test_, on = ['row_id'], how = 'left')\n\n# time_idã¨stock_idãŒä¸€ç·’ã«ãªã£ãŸãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n# get_time_stockã¯stock_idã¨time_idã”ã¨ã®é›†è¨ˆã‚’è¡Œã†é–¢æ•°\ntrain = get_time_stock(train)\ntest = get_time_stock(test)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:06:48.647334Z","iopub.execute_input":"2021-09-20T03:06:48.647696Z","iopub.status.idle":"2021-09-20T03:07:41.236213Z","shell.execute_reply.started":"2021-09-20T03:06:48.647664Z","shell.execute_reply":"2021-09-20T03:07:41.233802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"kaggleã®notebookã ã¨30~40åˆ†ãã‚‰ã„ã‹ã‹ã‚‹ã€‚ãƒ‡ãƒ¼ã‚¿æ•°ãŒ1å„„è¶…ãˆã¦ã‚‹ã‹ã‚‰ã—ã‚‡ã†ãŒãªã„ã€ã€","metadata":{}},{"cell_type":"markdown","source":"## æ™‚å®šæ•°tauã‚’å®šç¾©","metadata":{}},{"cell_type":"code","source":"# æ™‚å®šæ•°tau\n# ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§å¿…è¦ï¼Ÿ\n# seconds_in_bucket_countãŒã‚ã£ã¦æ¥é ­èªã«ã€Œtrade_ã€ã¨ã€Œ_uniqueã€ã‚’ã¤ã‘ãŸã‚‚ã®\ntrain['size_tau'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique'] )\ntest['size_tau'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique'] )\n#train['size_tau_450'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_450'] )\n#test['size_tau_450'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_450'] )\ntrain['size_tau_400'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_400'] )\ntest['size_tau_400'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_400'] )\ntrain['size_tau_300'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_300'] )\ntest['size_tau_300'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_300'] )\n#train['size_tau_150'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_150'] )\n#test['size_tau_150'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_150'] )\ntrain['size_tau_200'] = np.sqrt( 1/ train['trade_seconds_in_bucket_count_unique_200'] )\ntest['size_tau_200'] = np.sqrt( 1/ test['trade_seconds_in_bucket_count_unique_200'] )","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:07:41.238007Z","iopub.status.idle":"2021-09-20T03:07:41.23882Z","shell.execute_reply.started":"2021-09-20T03:07:41.238534Z","shell.execute_reply":"2021-09-20T03:07:41.238567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['size_tau2'] = np.sqrt( 1/ train['trade_order_count_sum'] )\ntest['size_tau2'] = np.sqrt( 1/ test['trade_order_count_sum'] )\n#train['size_tau2_450'] = np.sqrt( 0.25/ train['trade_order_count_sum'] )\n#test['size_tau2_450'] = np.sqrt( 0.25/ test['trade_order_count_sum'] )\ntrain['size_tau2_400'] = np.sqrt( 0.33/ train['trade_order_count_sum'] )\ntest['size_tau2_400'] = np.sqrt( 0.33/ test['trade_order_count_sum'] )\ntrain['size_tau2_300'] = np.sqrt( 0.5/ train['trade_order_count_sum'] )\ntest['size_tau2_300'] = np.sqrt( 0.5/ test['trade_order_count_sum'] )\n#train['size_tau2_150'] = np.sqrt( 0.75/ train['trade_order_count_sum'] )\n#test['size_tau2_150'] = np.sqrt( 0.75/ test['trade_order_count_sum'] )\ntrain['size_tau2_200'] = np.sqrt( 0.66/ train['trade_order_count_sum'] )\ntest['size_tau2_200'] = np.sqrt( 0.66/ test['trade_order_count_sum'] )\n\n# tauã®ã¡ã‚‡ã£ã¨ã—ãŸå¢—åˆ†ï¼ˆãƒ‡ãƒ«ã‚¿ï¼‰\ntrain['size_tau2_d'] = train['size_tau2_400'] - train['size_tau2']\ntest['size_tau2_d'] = test['size_tau2_400'] - test['size_tau2']","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:07:41.240405Z","iopub.status.idle":"2021-09-20T03:07:41.241172Z","shell.execute_reply.started":"2021-09-20T03:07:41.24089Z","shell.execute_reply":"2021-09-20T03:07:41.240916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ä»ŠtrainãŒæŒã£ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã®ã‚«ãƒ©ãƒ åã‚’é…åˆ—ã«ã—ãŸã‚‚ã®\n# not inãªã®ã§{\"stock_id\", \"time_id\", \"target\", \"row_id\"}ã¯å«ã¾ãªã„\ncolNames = [col for col in list(train.columns)\n            if col not in {\"stock_id\", \"time_id\", \"target\", \"row_id\"}]\n# ä½•å€‹ã®ã‚«ãƒ©ãƒ ãŒã‚ã‚‹ã®ã‹ç¢ºèª\nlen(colNames)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:07:41.24266Z","iopub.status.idle":"2021-09-20T03:07:41.24343Z","shell.execute_reply.started":"2021-09-20T03:07:41.243141Z","shell.execute_reply":"2021-09-20T03:07:41.243168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ç¸¦åˆ—time_id, æ¨ªåˆ—stock_idã§ã‚¯ãƒ­ã‚¹ã™ã‚‹ã‚»ãƒ«ã«ãã‚Œãã‚Œã®time_id,stock_idã®æ™‚ã®targetãŒå…¥ã£ã¦ã„ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«ãŒæ¬²ã—ã„","metadata":{}},{"cell_type":"code","source":"# kè¿‘å‚æ³•\nfrom sklearn.cluster import KMeans\n# making agg features\n\ntrain_p = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n# indexã¨columnsã¨valuesã¨valuesã‚’æŒ‡å®šã—ã¦ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ãƒ”ãƒœãƒƒãƒˆï¼ˆå†å½¢æˆï¼‰\n# ä»Šå›ã¯ç¸¦ãŒtime_id, æ¨ªãŒstock_id, ã‚¯ãƒ­ã‚¹ã™ã‚‹ã‚»ãƒ«ã«å…¥ã‚‹ã®ãŒtime_id,stock_idãŒç‰¹å®šã®å€¤ã®æ™‚ã®targetã®å€¤\ntrain_p = train_p.pivot(index='time_id', columns='stock_id', values='target')\n# ç¢ºèª\ndisplay(train_p.head())\n\n# ãƒ”ãƒœãƒƒãƒˆã—ãŸtrain_pã®å¢—ãˆã‹ãŸã‚’éŠ˜æŸ„ã”ã¨ã«ã¾ã¨ã‚ãŸã‚‚ã®\n# ã©ã®éŠ˜æŸ„åŒå£«ã§ç›¸é–¢ãŒé«˜ã„ã‹ã‚’ç¢ºèªã—ã€ã®ã¡ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æã«é–¢ã‚ã£ã¦ãã‚‹\ncorr = train_p.corr()\n\n# stock_idãŒä¸€æ¬¡å…ƒé…åˆ—ã§æ ¼ç´ã•ã‚ŒãŸã‚‚ã®\n# ids = [0,1,2,3,4,...,111,112]\nids = corr.index\n\n\n# k-meansæ³•, ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ•°7, random_state=0(åŒã˜å€¤)\n# ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã®å¢—ãˆæ–¹ã§éŠ˜æŸ„ã«ç¨®é¡ãŒã‚ã‚‹ã®ã§ã¯ãªã„ã‹ï¼Ÿ\nkmeans = KMeans(n_clusters=7, random_state=0).fit(corr.values)\n# ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ•°ãŒãƒ©ãƒ™ãƒ«ã«ãªã£ã¦0~7ãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹\nprint(kmeans.labels_)\n\nl = []\nfor n in range(7):\n    l.append ( [ (x-1) for x in ( (ids+1)*(kmeans.labels_ == n)) if x > 0] )\n# appendã•ã‚Œã¦ã„ã‚‹ã®ãŒx-1ã®å€¤ã§ã€xãŒ0ä»¥ä¸Šã®æ™‚ã¯kmeans.labels_ã¨0~6ã®é–“ã‚’å‹•ãnãŒç­‰ã—ã„æ™‚ã€ids+1ã‚’è¿”ã™ã€‚\n# appendã•ã‚Œã¦ã„ã‚‹ã®ãŒx-1ãªã®ã§ï¼ˆids + 1ï¼‰-1ã®å€¤ãŒlï¼ˆé…åˆ—ï¼‰ã«æ ¼ç´ã•ã‚Œlã¯stock_idã®ä¸€æ¬¡å…ƒé…åˆ—ã«ãªã‚‹\n# (kmeans.labels_ == n)ãŒTrue,Falseã§è¿”ã£ã¦ãã‚‹ãŒã€pythonã§ã¯True==1,Fales==0ã¨ã—ã¦æ‰±ã‚ã‚Œã‚‹ï¼ˆã ã‹ã‚‰æ›ã‘ç®—ãŒå‡ºæ¥ã¦ã„ãŸï¼‰\ndisplay(l)\n    \nmat = []\nmatTest = []\n\nn = 0\nfor ind in l:\n    print(ind)\n    newDf = train.loc[train['stock_id'].isin(ind) ]\n    newDf = newDf.groupby(['time_id']).agg(np.nanmean) #meanã¨ä¸€ç·’\n    newDf.loc[:,'stock_id'] = str(n)+'c1'\n    mat.append ( newDf )\n    \n    newDf = test.loc[test['stock_id'].isin(ind) ]    \n    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n    newDf.loc[:,'stock_id'] = str(n)+'c1'\n    matTest.append ( newDf )\n    \n    n+=1\n# ã“ã“ã¾ã§foræ–‡ã€‚nãŒ0~6ã¾ã§ï¼ˆå‰²ã‚ŠæŒ¯ã‚‰ã‚ŒãŸå…¨ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ï¼‰ã§time_idã”ã¨ã«stock_idã”ã¨ã«ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãªã©ãªã©ã®å¹³å‡ã‚’ã¨ã£ãŸdataframeã‚’ä½œæˆ\n    \nmat1 = pd.concat(mat).reset_index()\nmat1.drop(columns=['target'],inplace=True)\n\nmat2 = pd.concat(matTest).reset_index()\ndisplay(mat1.head())","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:07:41.244794Z","iopub.status.idle":"2021-09-20T03:07:41.245391Z","shell.execute_reply.started":"2021-09-20T03:07:41.245171Z","shell.execute_reply":"2021-09-20T03:07:41.245199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mat2 = pd.concat([mat2,mat1.loc[mat1.time_id==5]])\nmat1 = mat1.pivot(index='time_id', columns='stock_id')\nmat1.columns = [\"_\".join(x) for x in mat1.columns.ravel()]\nmat1.reset_index(inplace=True)\n\nmat2 = mat2.pivot(index='time_id', columns='stock_id')\nmat2.columns = [\"_\".join(x) for x in mat2.columns.ravel()]\nmat2.reset_index(inplace=True)\ndisplay(mat2.head())","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:07:41.246428Z","iopub.status.idle":"2021-09-20T03:07:41.246976Z","shell.execute_reply.started":"2021-09-20T03:07:41.246769Z","shell.execute_reply":"2021-09-20T03:07:41.246796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ã‚«ãƒ©ãƒ åã‚’ã¾ã¨ã‚ãŸé…åˆ—ã‚’ç”¨æ„\nnnn = ['time_id',\n     'log_return1_realized_volatility_0c1',\n     'log_return1_realized_volatility_1c1',     \n     'log_return1_realized_volatility_3c1',\n     'log_return1_realized_volatility_4c1',     \n     'log_return1_realized_volatility_6c1',\n     'total_volume_sum_0c1',\n     'total_volume_sum_1c1', \n     'total_volume_sum_3c1',\n     'total_volume_sum_4c1', \n     'total_volume_sum_6c1',\n     'trade_size_sum_0c1',\n     'trade_size_sum_1c1', \n     'trade_size_sum_3c1',\n     'trade_size_sum_4c1', \n     'trade_size_sum_6c1',\n     'trade_order_count_sum_0c1',\n     'trade_order_count_sum_1c1',\n     'trade_order_count_sum_3c1',\n     'trade_order_count_sum_4c1',\n     'trade_order_count_sum_6c1',      \n     'price_spread_sum_0c1',\n     'price_spread_sum_1c1',\n     'price_spread_sum_3c1',\n     'price_spread_sum_4c1',\n     'price_spread_sum_6c1',   \n     'bid_spread_sum_0c1',\n     'bid_spread_sum_1c1',\n     'bid_spread_sum_3c1',\n     'bid_spread_sum_4c1',\n     'bid_spread_sum_6c1',       \n     'ask_spread_sum_0c1',\n     'ask_spread_sum_1c1',\n     'ask_spread_sum_3c1',\n     'ask_spread_sum_4c1',\n     'ask_spread_sum_6c1',   \n     'volume_imbalance_sum_0c1',\n     'volume_imbalance_sum_1c1',\n     'volume_imbalance_sum_3c1',\n     'volume_imbalance_sum_4c1',\n     'volume_imbalance_sum_6c1',       \n     'bid_ask_spread_sum_0c1',\n     'bid_ask_spread_sum_1c1',\n     'bid_ask_spread_sum_3c1',\n     'bid_ask_spread_sum_4c1',\n     'bid_ask_spread_sum_6c1',\n     'size_tau2_0c1',\n     'size_tau2_1c1',\n     'size_tau2_3c1',\n     'size_tau2_4c1',\n     'size_tau2_6c1'] \ntrain = pd.merge(train,mat1[nnn],how='left',on='time_id')\ntest = pd.merge(test,mat2[nnn],how='left',on='time_id')","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:07:41.248006Z","iopub.status.idle":"2021-09-20T03:07:41.248555Z","shell.execute_reply.started":"2021-09-20T03:07:41.24836Z","shell.execute_reply":"2021-09-20T03:07:41.248384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ndel mat1,mat2\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:07:41.24957Z","iopub.status.idle":"2021-09-20T03:07:41.250111Z","shell.execute_reply.started":"2021-09-20T03:07:41.249909Z","shell.execute_reply":"2021-09-20T03:07:41.249933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# äº¤å·®æ¤œè¨¼ã‚’ã™ã‚‹æ™‚ã«Kfoldã‚’ä½¿ã†\n# ãƒ‡ãƒ¼ã‚¿ã‚’kå€‹ã«åˆ†ã‘ï¼Œnå€‹ã‚’è¨“ç·´ç”¨ï¼Œk-nå€‹ã‚’ãƒ†ã‚¹ãƒˆç”¨ã¨ã—ã¦ä½¿ã†ï¼\n# åˆ†ã‘ã‚‰ã‚ŒãŸnå€‹ã®ãƒ‡ãƒ¼ã‚¿ãŒãƒ†ã‚¹ãƒˆç”¨ã¨ã—ã¦å¿…ãš1å›ä½¿ã‚ã‚Œã‚‹ã‚ˆã†ã«nå›æ¤œå®šã™ã‚‹ï¼\nfrom sklearn.model_selection import KFold\n# lightgbm\nimport lightgbm as lgb\n\nseed0=2021\nparams0 = {\n    'objective': 'rmse',\n    'boosting_type': 'gbdt',\n    'max_depth': -1,\n    'max_bin':100,\n    'min_data_in_leaf':500,\n    'learning_rate': 0.05,\n    'subsample': 0.72,\n    'subsample_freq': 4,\n    'feature_fraction': 0.5,\n    'lambda_l1': 0.5,\n    'lambda_l2': 1.0,\n    'categorical_column':[0],\n    'seed':seed0,\n    'feature_fraction_seed': seed0,\n    'bagging_seed': seed0,\n    'drop_seed': seed0,\n    'data_random_seed': seed0,\n    'n_jobs':-1,\n    'verbose': -1}\nseed1=42\nparams1 = {\n        'learning_rate': 0.1,        \n        'lambda_l1': 2,\n        'lambda_l2': 7,\n        'num_leaves': 800,\n        'min_sum_hessian_in_leaf': 20,\n        'feature_fraction': 0.8,\n        'feature_fraction_bynode': 0.8,\n        'bagging_fraction': 0.9,\n        'bagging_freq': 42,\n        'min_data_in_leaf': 700,\n        'max_depth': 4,\n        'categorical_column':[0],\n        'seed': seed1,\n        'feature_fraction_seed': seed1,\n        'bagging_seed': seed1,\n        'drop_seed': seed1,\n        'data_random_seed': seed1,\n        'objective': 'rmse',\n        'boosting': 'gbdt',\n        'verbosity': -1,\n        'n_jobs':-1,\n    }\n# rmspeã§æ—©æœŸåœæ­¢ã‚’ã™ã‚‹ãŸã‚ã®é–¢æ•°\ndef rmspe(y_true, y_pred):\n    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n\ndef feval_rmspe(y_pred, lgb_train):\n    y_true = lgb_train.get_label()\n    return 'RMSPE', rmspe(y_true, y_pred), False\n\n# LightGBMã‚’å®Ÿè£…ã™ã‚‹ãŸã‚ã®é–¢æ•°\ndef train_and_evaluate_lgb(train, test, params):\n    \n    # time_id, target, row_idä»¥å¤–ã‚’featuresã«æ ¼ç´\n    features = [col for col in train.columns if col not in {\"time_id\", \"target\", \"row_id\"}]\n    y = train['target']\n    # trainã¨åŒã˜å½¢ã§0ãŒå…¥ã£ãŸé…åˆ—ã‚’ä½œæˆ\n    oof_predictions = np.zeros(train.shape[0])\n    # testã¨åŒã˜å½¢ã§0ãŒå…¥ã£ãŸé…åˆ—ã‚’ä½œæˆ\n    test_predictions = np.zeros(test.shape[0])\n    # kfold\n    kfold = KFold(n_splits = 5, random_state = 2021, shuffle = True)\n    # å„foldã§ç¹°ã‚Šè¿”ã™\n    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train)):\n        print(f'Training fold {fold + 1}')\n        x_train, x_val = train.iloc[trn_ind], train.iloc[val_ind]\n        y_train, y_val = y.iloc[trn_ind], y.iloc[val_ind]\n        # rmspe\n        train_weights = 1 / np.square(y_train)\n        val_weights = 1 / np.square(y_val)\n        train_dataset = lgb.Dataset(x_train[features], y_train, weight = train_weights)\n        val_dataset = lgb.Dataset(x_val[features], y_val, weight = val_weights)\n        model = lgb.train(params = params,\n                          num_boost_round=1000,\n                          train_set = train_dataset, \n                          valid_sets = [train_dataset, val_dataset], \n                          verbose_eval = 250,\n                          early_stopping_rounds=50,\n                          feval = feval_rmspe)\n        # å„foldã«å–å¾—ã—ãŸäºˆæ¸¬å€¤ã‚’è¿½åŠ ã™ã‚‹\n        oof_predictions[val_ind] = model.predict(x_val[features])\n        # ä½œæˆã—ãŸãƒ¢ãƒ‡ãƒ«ã§testãƒ‡ãƒ¼ã‚¿ã‚’äºˆæ¸¬ã™ã‚‹\n        test_predictions += model.predict(test[features]) / 5\n    rmspe_score = rmspe(y, oof_predictions)\n    print(f'Our out of folds RMSPE is {rmspe_score}')\n    lgb.plot_importance(model,max_num_features=20)\n    # testã®äºˆæ¸¬å€¤ã‚’è¿”ã‚Šå€¤ã«è¨­å®š\n    return test_predictions\n\n# å®Ÿéš›ã«å®Ÿè¡Œã—ã¦ã¿ã‚‹\npredictions_lgb= train_and_evaluate_lgb(train, test,params0)\ntest['target'] = predictions_lgb\ntest[['row_id', 'target']].to_csv('submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:07:41.251352Z","iopub.status.idle":"2021-09-20T03:07:41.251695Z","shell.execute_reply.started":"2021-09-20T03:07:41.251516Z","shell.execute_reply":"2021-09-20T03:07:41.25154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"åœ§å€’çš„stock_id","metadata":{}},{"cell_type":"code","source":"train.shape[1]","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:07:41.252637Z","iopub.status.idle":"2021-09-20T03:07:41.252962Z","shell.execute_reply.started":"2021-09-20T03:07:41.252784Z","shell.execute_reply":"2021-09-20T03:07:41.252806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ä¸‹è¨˜ã‚’å®Ÿè¡Œã™ã‚‹ã«ã‚ãŸã£ã¦æœ€åˆ\n```\nfrom keras import backend as K\n```\nã‚’è¡Œãªã£ãŸéš›ã«No moduleã¨ãªã£ã¦ã—ã¾ã£ãŸã®ã§pip listã§èª¿ã¹ãŸã¨ã“ã‚versionãŒ2.6.0ã ã£ãŸã®ã§versionã‚’å¤‰æ›´ã™ã‚‹ã¨å›ã‚‹ã‚ˆã†ã«ãªã£ãŸã®ã§æ³¨æ„\n```\n!pip uninstall -y keras\n!pip install keras==2.3.1\n```","metadata":{}},{"cell_type":"code","source":"!pip install keras==2.3.1","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:07:41.25467Z","iopub.status.idle":"2021-09-20T03:07:41.255054Z","shell.execute_reply.started":"2021-09-20T03:07:41.254862Z","shell.execute_reply":"2021-09-20T03:07:41.254885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numpy.random import seed\nseed(42)\n\n# ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°å‘ã‘ãƒ©ã‚¤ãƒ–ãƒ©ãƒªtensorflow\nimport tensorflow as tf\ntf.random.set_seed(42)\nfrom tensorflow import keras\nimport numpy as np\nfrom keras import backend as K\n\n# rmspeã‚’è¨ˆç®—\ndef root_mean_squared_per_error(y_true, y_pred):\n         return K.sqrt(K.mean(K.square( (y_true - y_pred)/ y_true )))\n\n# kerasã§ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½œæˆã™ã‚‹\n# ã“ã¡ã‚‰ã¯EarlyStopping\n# å­¦ç¿’ãƒ«ãƒ¼ãƒ—ã«åæŸåˆ¤å®šã‚’ä»˜ä¸ã™ã‚‹ã“ã¨ãŒã§ãã€ç›£è¦–ã™ã‚‹å€¤ã‚’è¨­å®šã—ã¦ã€ãã‚ŒãŒåæŸã—ãŸã‚‰è‡ªå‹•çš„ã«ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹å‡¦ç†ã«ãªã‚‹\nes = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', patience=20, verbose=0,\n    mode='min',restore_best_weights=True)\n# ã“ã¡ã‚‰ã¯ReduceLROnPlateau\n# è©•ä¾¡å€¤ã®æ”¹å–„ãŒæ­¢ã¾ã£ãŸæ™‚ã«å­¦ç¿’ç‡ã‚’æ¸›ã‚‰ã™\nplateau = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss', factor=0.2, patience=7, verbose=0,\n    mode='min')","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:07:41.256172Z","iopub.status.idle":"2021-09-20T03:07:41.256522Z","shell.execute_reply.started":"2021-09-20T03:07:41.256345Z","shell.execute_reply":"2021-09-20T03:07:41.256367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# å†åº¦trainãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨ãƒ†ãƒ¼ãƒ–ãƒ«ã®å†å½¢æˆ\nout_train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\nout_train = out_train.pivot(index='time_id', columns='stock_id', values='target')\n\n# æ¬ æå€¤ã‚’å¹³å‡å€¤ã§è£œå®Œ\nout_train = out_train.fillna(out_train.mean())\nout_train.head()\n\n# æœ€åˆã®å®Ÿè¡Œå¾Œã«èª­ã¿å–ã£ãŸãƒ‡ãƒ¼ã‚¿ã ã‘ã‚’è¿½åŠ ã™ã‚‹ã‚³ãƒ¼ãƒ‰\n\n# knnã«åŸºã¥ã„ã¦dataã‚’åˆ†ã‘ã‚‹\nnfolds = 5 # foldã®æ•°\nindex = []\ntotDist = []\nvalues = []\n# out_trainã®å€¤ã§è¡Œåˆ—ã‚’ç”Ÿæˆ\nmat = out_train.values\n\n# æ­£è¦åŒ–\nscaler = MinMaxScaler(feature_range=(-1, 1))\nmat = scaler.fit_transform(mat)\n\nnind = int(mat.shape[0]/nfolds) # foldã”ã¨ã®ãƒ‡ãƒ¼ã‚¿æ•°\n\n# æœ€å¾Œã®åˆ—ã«indexã‚’è¿½åŠ \nmat = np.c_[mat,np.arange(mat.shape[0])]\n\n# np.random.choice()ã§ã‚µã‚¤ã‚³ãƒ­ã‚’ä½œæˆã™ã‚‹\nlineNumber = np.random.choice(np.array(mat.shape[0]), size=nfolds, replace=False)\n\nlineNumber = np.sort(lineNumber)[::-1]\n\n# totDistã«matã®è¡Œæ•° - 5ï¼ˆfoldã®æ•°ï¼‰åˆ†ã®0é…åˆ—ã‚’æŒ¿å…¥\nfor n in range(nfolds):\n    totDist.append(np.zeros(mat.shape[0]-nfolds))\n\n# valuesã«ã¯indexã‚’ä¿å­˜\nfor n in range(nfolds):\n    values.append([lineNumber[n]])\n\ndisplay(mat)\ndisplay(lineNumber)\ndisplay(totDist)\ndisplay(values)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:07:41.25766Z","iopub.status.idle":"2021-09-20T03:07:41.258Z","shell.execute_reply.started":"2021-09-20T03:07:41.257815Z","shell.execute_reply":"2021-09-20T03:07:41.257837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s=[]\nfor n in range(nfolds): #range(5)\n    # sã«matã®(lineNumberã®nè¡Œç›®)ã®é…åˆ—ã®è¦ç´ ã‚’append\n    s.append(mat[lineNumber[n],:])\n    # sã«å…¥ã£ãŸè¦ç´ ã¯matã‹ã‚‰ã¯å‰Šé™¤\n    mat = np.delete(mat, obj=lineNumber[n], axis=0)\n\n# nindã¯foldã”ã¨ã®ãƒ‡ãƒ¼ã‚¿æ•°ï¼ˆint(mat.shape[0]/nfolds)ï¼‰\nfor n in range(nind-1):    \n    # æœ€å°å€¤0, æœ€å¤§å€¤1ã®ä¹±æ•°ã‚’nfoldså€‹ç”Ÿæˆï¼ˆä»Šã¯5å€‹ï¼‰\n    luck = np.random.uniform(0,1,nfolds)\n    \n    for cycle in range(nfolds): #range(5)\n        # np.matlib.repmatã§s[cycle]ã‚’matã®è¡Œæ•°åˆ†ã®è¡Œ*1åˆ—ã®è¡Œåˆ—ã«å¤‰æ›\n        s[cycle] = np.matlib.repmat(s[cycle], mat.shape[0], 1)\n        # matã®å…¨è¡Œå‰åˆ—ã¨sã®å…¨è¡Œå‰åˆ—ã®è¡Œåˆ—å¼ã‚’è¨ˆç®—ã—ãŸå€¤ã‚’2å€ã—ãŸã‚‚ã®ã‚’sumDistã«ä»£å…¥\n        sumDist = np.sum( (mat[:,:-1] - s[cycle][:,:-1])**2 , axis=1)\n        # toDist[cycle] = toDist[cycle] + sumDist\n        totDist[cycle] += sumDist\n        \n        f = totDist[cycle]/np.sum(totDist[cycle]) # totdistã‚’æ­£è¦åŒ–\n        j = 0\n        kn = 0\n        for val in f:\n            j += val\n            if (j > luck[cycle]):\n                break\n            kn +=1\n        lineNumber[cycle] = kn\n        \n        # ä¸Šã§å€¤ãŒè¿½åŠ ã•ã‚ŒãŸãƒ¬ã‚³ãƒ¼ãƒ‰ã¯toDistã‹ã‚‰å‰Šé™¤\n        for n_iter in range(nfolds):\n            \n            totDist[n_iter] = np.delete(totDist[n_iter],obj=lineNumber[cycle], axis=0)\n            j= 0\n        \n        s[cycle] = mat[lineNumber[cycle],:]\n        values[cycle].append(int(mat[lineNumber[cycle],-1]))\n        mat = np.delete(mat, obj=lineNumber[cycle], axis=0)\n\nfor n_mod in range(nfolds):\n    values[n_mod] = out_train.index[values[n_mod]]","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:07:41.259136Z","iopub.status.idle":"2021-09-20T03:07:41.25948Z","shell.execute_reply.started":"2021-09-20T03:07:41.259289Z","shell.execute_reply":"2021-09-20T03:07:41.259323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# è¨ˆç®—ä¸Šå–å¾—ã•ã‚Œã¦ã—ã¾ã£ãŸtrainã¨testã®æ­£è² ç„¡é™ã‚’nanã«ç½®æ›\ntrain.replace([np.inf, -np.inf], np.nan,inplace=True)\ntest.replace([np.inf, -np.inf], np.nan,inplace=True)\nqt_train = []\ntrain_nn=train[colNames].copy()\ntest_nn=test[colNames].copy()\nfor col in colNames:\n    qt = QuantileTransformer(random_state=21,n_quantiles=2000, output_distribution='normal')\n    train_nn[col] = qt.fit_transform(train_nn[[col]])\n    test_nn[col] = qt.transform(test_nn[[col]])    \n    qt_train.append(qt)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:07:41.260433Z","iopub.status.idle":"2021-09-20T03:07:41.26076Z","shell.execute_reply.started":"2021-09-20T03:07:41.26058Z","shell.execute_reply":"2021-09-20T03:07:41.260603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_nn[['stock_id','time_id','target']]=train[['stock_id','time_id','target']]\ntest_nn[['stock_id','time_id']]=test[['stock_id','time_id']]","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:07:41.26194Z","iopub.status.idle":"2021-09-20T03:07:41.262276Z","shell.execute_reply.started":"2021-09-20T03:07:41.262098Z","shell.execute_reply":"2021-09-20T03:07:41.26212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°\nfrom sklearn.cluster import KMeans\ntrain_p = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\ntrain_p = train_p.pivot(index='time_id', columns='stock_id', values='target')\n\ncorr = train_p.corr()\n\nids = corr.index\n\nkmeans = KMeans(n_clusters=7, random_state=0).fit(corr.values)\nprint(kmeans.labels_)\n\nl = []\nfor n in range(7):\n    l.append ( [ (x-1) for x in ( (ids+1)*(kmeans.labels_ == n)) if x > 0] )\n    \n\nmat = []\nmatTest = []\n\nn = 0\nfor ind in l:\n    print(ind)\n    newDf = train_nn.loc[train_nn['stock_id'].isin(ind) ]\n    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n    newDf.loc[:,'stock_id'] = str(n)+'c1'\n    mat.append ( newDf )\n    \n    newDf = test_nn.loc[test_nn['stock_id'].isin(ind) ]    \n    newDf = newDf.groupby(['time_id']).agg(np.nanmean)\n    newDf.loc[:,'stock_id'] = str(n)+'c1'\n    matTest.append ( newDf )\n    \n    n+=1\n    \nmat1 = pd.concat(mat).reset_index()\nmat1.drop(columns=['target'],inplace=True)\n\nmat2 = pd.concat(matTest).reset_index()\nmat2 = pd.concat([mat2,mat1.loc[mat1.time_id==5]])","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:07:41.26334Z","iopub.status.idle":"2021-09-20T03:07:41.263666Z","shell.execute_reply.started":"2021-09-20T03:07:41.263488Z","shell.execute_reply":"2021-09-20T03:07:41.26351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nnn = ['time_id',\n     'log_return1_realized_volatility_0c1',\n     'log_return1_realized_volatility_1c1',     \n     'log_return1_realized_volatility_3c1',\n     'log_return1_realized_volatility_4c1',     \n     'log_return1_realized_volatility_6c1',\n     'total_volume_sum_0c1',\n     'total_volume_sum_1c1', \n     'total_volume_sum_3c1',\n     'total_volume_sum_4c1', \n     'total_volume_sum_6c1',\n     'trade_size_sum_0c1',\n     'trade_size_sum_1c1', \n     'trade_size_sum_3c1',\n     'trade_size_sum_4c1', \n     'trade_size_sum_6c1',\n     'trade_order_count_sum_0c1',\n     'trade_order_count_sum_1c1',\n     'trade_order_count_sum_3c1',\n     'trade_order_count_sum_4c1',\n     'trade_order_count_sum_6c1',      \n     'price_spread_sum_0c1',\n     'price_spread_sum_1c1',\n     'price_spread_sum_3c1',\n     'price_spread_sum_4c1',\n     'price_spread_sum_6c1',   \n     'bid_spread_sum_0c1',\n     'bid_spread_sum_1c1',\n     'bid_spread_sum_3c1',\n     'bid_spread_sum_4c1',\n     'bid_spread_sum_6c1',       \n     'ask_spread_sum_0c1',\n     'ask_spread_sum_1c1',\n     'ask_spread_sum_3c1',\n     'ask_spread_sum_4c1',\n     'ask_spread_sum_6c1',   \n     'volume_imbalance_sum_0c1',\n     'volume_imbalance_sum_1c1',\n     'volume_imbalance_sum_3c1',\n     'volume_imbalance_sum_4c1',\n     'volume_imbalance_sum_6c1',       \n     'bid_ask_spread_sum_0c1',\n     'bid_ask_spread_sum_1c1',\n     'bid_ask_spread_sum_3c1',\n     'bid_ask_spread_sum_4c1',\n     'bid_ask_spread_sum_6c1',\n     'size_tau2_0c1',\n     'size_tau2_1c1',\n     'size_tau2_3c1',\n     'size_tau2_4c1',\n     'size_tau2_6c1']","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:07:41.264613Z","iopub.status.idle":"2021-09-20T03:07:41.26497Z","shell.execute_reply.started":"2021-09-20T03:07:41.264768Z","shell.execute_reply":"2021-09-20T03:07:41.264789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# å…ˆã»ã©mat2ã¯time_idãŒ5ã®æ™‚ã«é™å®šã—ã¦ã„ãŸãŒä»Šå›ã¯å…¨ãƒ‡ãƒ¼ã‚¿\nmat1 = mat1.pivot(index='time_id', columns='stock_id')\nmat1.columns = [\"_\".join(x) for x in mat1.columns.ravel()]\nmat1.reset_index(inplace=True)\n\nmat2 = mat2.pivot(index='time_id', columns='stock_id')\nmat2.columns = [\"_\".join(x) for x in mat2.columns.ravel()]\nmat2.reset_index(inplace=True)\ndisplay(mat2)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:07:41.266771Z","iopub.status.idle":"2021-09-20T03:07:41.267663Z","shell.execute_reply.started":"2021-09-20T03:07:41.267464Z","shell.execute_reply":"2021-09-20T03:07:41.267486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ntrain_nn = pd.merge(train_nn,mat1[nnn],how='left',on='time_id')\ntest_nn = pd.merge(test_nn,mat2[nnn],how='left',on='time_id')\ndel mat1,mat2\ndel train,test\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:07:41.268573Z","iopub.status.idle":"2021-09-20T03:07:41.268905Z","shell.execute_reply.started":"2021-09-20T03:07:41.268729Z","shell.execute_reply":"2021-09-20T03:07:41.268751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯","metadata":{}},{"cell_type":"code","source":"# https://bignerdranch.com/blog/implementing-swish-activation-function-in-keras/\n# sigmoidé–¢æ•°\nfrom keras.backend import sigmoid\ndef swish(x, beta = 1):\n    return (x * sigmoid(beta * x))\n\nfrom keras.utils.generic_utils import get_custom_objects\nfrom keras.layers import Activation\nget_custom_objects().update({'swish': Activation(swish)})\n\nhidden_units = (128,64,32)\nstock_embedding_size = 24\n\ncat_data = train_nn['stock_id']\n\ndef base_model():\n    # ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å…¥åŠ›å±¤ï¼ˆshapeã¯å…¥åŠ›ã®æ¬¡å…ƒï¼‰\n    stock_id_input = keras.Input(shape=(1,), name='stock_id')\n    num_input = keras.Input(shape=(244,), name='num_data')\n\n    #embeddingï¼ˆåŸ‹ã‚è¾¼ã¿ï¼‰, flatenningï¼ˆå¹³å¦åŒ–, concatenatingï¼ˆé€£çµï¼‰\n    stock_embedded = keras.layers.Embedding(max(cat_data)+1, stock_embedding_size, \n                                           input_length=1, name='stock_embedding')(stock_id_input)\n    stock_flattened = keras.layers.Flatten()(stock_embedded)\n    out = keras.layers.Concatenate()([stock_flattened, num_input])\n    \n    # éš ã‚Œå±¤\n    for n_hidden in hidden_units:\n\n        out = keras.layers.Dense(n_hidden, activation='swish')(out)\n        \n\n    # out = keras.layers.Concatenate()([out, num_input])\n    # å‡ºåŠ›å±¤\n    out = keras.layers.Dense(1, activation='linear', name='prediction')(out)\n    \n    model = keras.Model(\n    inputs = [stock_id_input, num_input],\n    outputs = out,\n    )\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:07:41.270001Z","iopub.status.idle":"2021-09-20T03:07:41.270345Z","shell.execute_reply.started":"2021-09-20T03:07:41.270153Z","shell.execute_reply":"2021-09-20T03:07:41.270176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ã‚‚ã†ä¸€åº¦é–¢æ•°ã‚’è¨­å®šã—ã¦ã„ã‚‹\ndef rmspe(y_true, y_pred):\n    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n\ndef feval_rmspe(y_pred, lgb_train):\n    y_true = lgb_train.get_label()\n    return 'RMSPE', rmspe(y_true, y_pred), False","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:07:41.271264Z","iopub.status.idle":"2021-09-20T03:07:41.271612Z","shell.execute_reply.started":"2021-09-20T03:07:41.271429Z","shell.execute_reply":"2021-09-20T03:07:41.271459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_name='target'\nscores_folds = {}\nmodel_name = 'NN'\npred_name = 'pred_{}'.format(model_name)\n\nn_folds = 5\nkf = model_selection.KFold(n_splits=n_folds, shuffle=True, random_state=2020)\nscores_folds[model_name] = []\ncounter = 1\n\nfeatures_to_consider = list(train_nn)\n\nfeatures_to_consider.remove('time_id')\nfeatures_to_consider.remove('target')\ntry:\n    features_to_consider.remove('pred_NN')\nexcept:\n    pass\n\n\ntrain_nn[features_to_consider] = train_nn[features_to_consider].fillna(train_nn[features_to_consider].mean())\ntest_nn[features_to_consider] = test_nn[features_to_consider].fillna(train_nn[features_to_consider].mean())\n\ntrain_nn[pred_name] = 0\ntest_nn[target_name] = 0\ntest_predictions_nn = np.zeros(test_nn.shape[0])\n\nfor n_count in range(n_folds):\n    print('CV {}/{}'.format(counter, n_folds))\n    \n    indexes = np.arange(nfolds).astype(int)    \n    indexes = np.delete(indexes,obj=n_count, axis=0) \n    \n    indexes = np.r_[values[indexes[0]],values[indexes[1]],values[indexes[2]],values[indexes[3]]]\n    \n    X_train = train_nn.loc[train_nn.time_id.isin(indexes), features_to_consider]\n    y_train = train_nn.loc[train_nn.time_id.isin(indexes), target_name]\n    X_test = train_nn.loc[train_nn.time_id.isin(values[n_count]), features_to_consider]\n    y_test = train_nn.loc[train_nn.time_id.isin(values[n_count]), target_name]\n    \n    #############################################################################################\n    # NN\n    #############################################################################################\n    \n    model = base_model()\n    \n    model.compile(\n        keras.optimizers.Adam(learning_rate=0.006),\n        loss=root_mean_squared_per_error\n    )\n    \n    try:\n        features_to_consider.remove('stock_id')\n    except:\n        pass\n    \n    num_data = X_train[features_to_consider]\n    \n    scaler = MinMaxScaler(feature_range=(-1, 1))         \n    num_data = scaler.fit_transform(num_data.values)    \n    \n    cat_data = X_train['stock_id']    \n    target =  y_train\n    \n    num_data_test = X_test[features_to_consider]\n    num_data_test = scaler.transform(num_data_test.values)\n    cat_data_test = X_test['stock_id']\n\n    model.fit([cat_data, num_data], \n              target,               \n              batch_size=2048,\n              epochs=1000,\n              validation_data=([cat_data_test, num_data_test], y_test),\n              callbacks=[es, plateau],\n              validation_batch_size=len(y_test),\n              shuffle=True,\n             verbose = 1)\n\n    preds = model.predict([cat_data_test, num_data_test]).reshape(1,-1)[0]\n    \n    score = round(rmspe(y_true = y_test, y_pred = preds),5)\n    print('Fold {} {}: {}'.format(counter, model_name, score))\n    scores_folds[model_name].append(score)\n    \n    tt =scaler.transform(test_nn[features_to_consider].values)\n    #test_nn[target_name] += model.predict([test_nn['stock_id'], tt]).reshape(1,-1)[0].clip(0,1e10)\n    test_predictions_nn += model.predict([test_nn['stock_id'], tt]).reshape(1,-1)[0].clip(0,1e10)/n_folds\n    #test[target_name] += model.predict([test['stock_id'], test[features_to_consider]]).reshape(1,-1)[0].clip(0,1e10)\n       \n    counter += 1\n    features_to_consider.append('stock_id')","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:07:41.27342Z","iopub.status.idle":"2021-09-20T03:07:41.273769Z","shell.execute_reply.started":"2021-09-20T03:07:41.273589Z","shell.execute_reply":"2021-09-20T03:07:41.273611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_nn[\"row_id\"] = test_nn[\"stock_id\"].astype(str) + \"-\" + test_nn[\"time_id\"].astype(str) \ntest_nn[target_name] = (test_predictions_nn+predictions_lgb)/2\n\nscore = round(rmspe(y_true = train_nn[target_name].values, y_pred = train_nn[pred_name].values),5)\nprint('RMSPE {}: {} - Folds: {}'.format(model_name, score, scores_folds[model_name]))\n\ndisplay(test_nn[['row_id', target_name]].head(3))\ntest_nn[['row_id', target_name]].to_csv('submission.csv',index = False)\n#test[['row_id', target_name]].to_csv('submission.csv',index = False)\n#kmeans N=5 [0.2101, 0.21399, 0.20923, 0.21398, 0.21175]","metadata":{"execution":{"iopub.status.busy":"2021-09-20T03:07:41.275016Z","iopub.status.idle":"2021-09-20T03:07:41.275388Z","shell.execute_reply.started":"2021-09-20T03:07:41.275186Z","shell.execute_reply":"2021-09-20T03:07:41.275209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ä¸€é€šã‚Šæµã‚Œã‚’è¿½ã£ã¦å®Ÿè¡Œã—ã¦ã¿ãŸãŒã€1é€±ç›®ã§ã¯ã‚¤ãƒã‚¤ãƒã‚ã‹ã‚‰ãªã„ç®‡æ‰€ãŒå¤šã‹ã£ãŸã€‚\n\nä»–ã®notebookã‚‚æ‹è¦‹ã•ã›ã¦ã„ãŸã ããªãŒã‚‰å‘¨å›ã—ã¦ã©ã®ã‚ˆã†ãªç‰¹å¾´é‡ã‚’ç”Ÿæˆã—ã¦ã„ã‚‹ã®ã‹ã‚’ä¸­å¿ƒã«å¾©ç¿’ã™ã‚‹ã€‚","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}