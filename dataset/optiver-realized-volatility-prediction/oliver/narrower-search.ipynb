{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This is just another lgbm baseline for this competition, a lot of the work, ideas and function are copied from https://www.kaggle.com/tommy1028/lightgbm-starter-with-feature-engineering-idea\n\nThe features that improve the model are the aggregartions stats using time_id and stock_id using the realized volatility for different windows from the past\n\nCheers and have fun","metadata":{}},{"cell_type":"code","source":"import math","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:51:21.451365Z","iopub.execute_input":"2021-09-03T10:51:21.451777Z","iopub.status.idle":"2021-09-03T10:51:21.462739Z","shell.execute_reply.started":"2021-09-03T10:51:21.451689Z","shell.execute_reply":"2021-09-03T10:51:21.461601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import galearn\nimport os\nimport glob\nfrom joblib import Parallel, delayed\nimport pandas as pd\nimport numpy as np\nimport scipy as sc\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.svm import SVR\nimport lightgbm as lgb\nimport warnings\nwarnings.filterwarnings('ignore')\npd.set_option('max_columns', 300)\n#from galearn import *\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import roc_auc_score\nimport pandas as pd\nimport bqplot\nimport matplotlib.pyplot as plt\nimport time\nimport numpy as np\nfrom tqdm.notebook import tqdm, trange\nimport seaborn as sns\nimport optuna\nimport ipywidgets as widgets\nsns.set({'figure.figsize': (12, 8)})\nsns.set_color_codes(\"pastel\")\nrng = np.random.default_rng()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-03T10:51:21.464466Z","iopub.execute_input":"2021-09-03T10:51:21.464899Z","iopub.status.idle":"2021-09-03T10:51:25.361613Z","shell.execute_reply.started":"2021-09-03T10:51:21.464857Z","shell.execute_reply":"2021-09-03T10:51:25.36058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#generates a dictionary from the pool of genes\ndef generate_parent(gene_pool):\n    parent = dict()\n    for gene in gene_pool.keys():\n        parent[gene] = rng.choice(gene_pool[gene])\n    fitness = get_fitness(estimator(**parent), fitness_function)\n    #print(f\"new individuals fitness is {fitness}\")\n    if math.isnan(fitness):\n        print(\"nan : \", parent)\n    return Individual(parent, fitness)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:51:25.363601Z","iopub.execute_input":"2021-09-03T10:51:25.364Z","iopub.status.idle":"2021-09-03T10:51:25.369933Z","shell.execute_reply.started":"2021-09-03T10:51:25.363956Z","shell.execute_reply":"2021-09-03T10:51:25.369236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mutate(parent, gene_pool):\n    gene = rng.choice(list(params))\n    child = parent.copy()\n    new_gene, alternate = rng.choice(gene_pool[gene], 2)\n    #help make sure the gene get's mutated\n    child[gene] = alternate if new_gene == child[gene] else new_gene\n    return child","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:51:25.371164Z","iopub.execute_input":"2021-09-03T10:51:25.37163Z","iopub.status.idle":"2021-09-03T10:51:25.386636Z","shell.execute_reply.started":"2021-09-03T10:51:25.371597Z","shell.execute_reply":"2021-09-03T10:51:25.385554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Individual:\n    def __init__(self, genes, fitness):\n        self._genes = genes\n        self._fitness = fitness\n        self._fp = 0 #fitness_proportion to be used when selection == fp\n        \n    def __eq__(self, other):\n        return self.genes == other.genes\n\n    def __lt__(self, other):\n        return self.fitness < other.fitness\n    \n    def __gt__(self, other):\n        return self.fitness > other.fitness\n    \n    def __str__(self):\n        return f\"Individual with genes: {self._genes} and fitness:{self._fitness}\"\n        \n    @property    \n    def genes(self):\n        return self._genes\n    \n    @property\n    def fitness(self):\n        return self._fitness\n    \n    #may add cv = cv/skf as an option\n    def set_fitness(self):\n        self._fitness = get_fitness(estimator(**self.genes), fitness_function)\n    \n    def set_gene(self, gene, value):\n        self._genes[gene] = value\n        \n    def get_gene_from_window(self, gene):\n        min_c = gene_pool[gene].min()\n        max_c = gene_pool[gene].max()\n        dist_1 = self._genes[gene] - min_c\n        dist_2 = max_c - self._genes[gene]\n        dist = min(dist_1, dist_2)*gnp_window\n        lb = self._genes[gene] - dist\n        ub = self._genes[gene] + dist\n        new_gene, alternate = rng.choice(gene_pool[gene][(gene_pool[gene] >= lb) & (gene_pool[gene] <= ub)], 2)\n        return new_gene, alternate\n        \n    \n    def mutate(self):\n        gene = rng.choice(list(self._genes))\n        if restrict_gnp and isinstance(gene_pool[gene], float):\n            #give chance of diversity = 1-p_mutate until 10% chance\n            if rng.random() < p_outlier:\n                print(f\"got an outlier\")\n                new_gene, alternate = rng.choice(gene_pool[gene], 2)\n            else:\n                new_gene, alternate = self.get_gene_from_window(gene)\n        else:\n            new_gene, alternate = rng.choice(gene_pool[gene], 2)\n    #help make sure the gene get's mutated\n        self._genes[gene] = alternate if new_gene == self._genes[gene] else new_gene\n        return\n    \n    def get_estimator(self):\n        return estimator(**self._genes)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:51:25.388225Z","iopub.execute_input":"2021-09-03T10:51:25.388765Z","iopub.status.idle":"2021-09-03T10:51:25.408959Z","shell.execute_reply.started":"2021-09-03T10:51:25.388724Z","shell.execute_reply":"2021-09-03T10:51:25.407309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creates a population of size size with parameters from gene_pool\ndef create_population(gene_pool, size = 10):\n    population = []\n    for i in range(size):\n        population.append(generate_parent(gene_pool))\n    population.sort(reverse = True)\n    return population","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:51:25.410459Z","iopub.execute_input":"2021-09-03T10:51:25.410904Z","iopub.status.idle":"2021-09-03T10:51:25.431145Z","shell.execute_reply.started":"2021-09-03T10:51:25.410857Z","shell.execute_reply":"2021-09-03T10:51:25.429773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Population:\n    #create initial population\n    def __init__(self, gene_pool, size = 10):\n        self._population = create_population(gene_pool, size)\n        self._size = size\n      \n    #note that if several individuals have == best fitness anyone of them is returned in the sorted list\n    @property\n    def best_individual(self):\n        return self._population[0]\n    \n    @property\n    def best_fitness(self):\n        return self._population[0].fitness\n    \n    @property\n    def population(self):\n        return self._population\n    \n    @property\n    def size(self):\n        return self._size\n    \n    def replace_generation(self, new_gen):\n        new_gen.sort(reverse = True)\n        self._population = new_gen","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:51:25.434788Z","iopub.execute_input":"2021-09-03T10:51:25.435349Z","iopub.status.idle":"2021-09-03T10:51:25.452669Z","shell.execute_reply.started":"2021-09-03T10:51:25.435282Z","shell.execute_reply":"2021-09-03T10:51:25.451601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_fitness(individual, fitness_function, cv = 3):\n    score = cross_val_score(individual, X_train, y_train, cv=cv, scoring = fitness_function)\n    return score.mean()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:51:25.454515Z","iopub.execute_input":"2021-09-03T10:51:25.454807Z","iopub.status.idle":"2021-09-03T10:51:25.466691Z","shell.execute_reply.started":"2021-09-03T10:51:25.45478Z","shell.execute_reply":"2021-09-03T10:51:25.465601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def select_breeding(population, selection = 'truncation', frac = 0.75):\n    if selection == 'truncation':\n        cut = int(len(population.population)*frac)\n        breeding = population.population[:cut]\n        return breeding\n    elif selection == 'fitness_proportionate' or selection == 'fp':\n        size = int(population.size * frac)\n        return fp_selection(population, size)\n    elif selection == 'tournament':\n        size = int(population.size * frac)\n        return tournament_selection(population, size)\n    elif selection == 'sus':\n        size = int(population.size * frac)\n        return sus_selection(population, size)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:51:25.468026Z","iopub.execute_input":"2021-09-03T10:51:25.468369Z","iopub.status.idle":"2021-09-03T10:51:25.479692Z","shell.execute_reply.started":"2021-09-03T10:51:25.468315Z","shell.execute_reply":"2021-09-03T10:51:25.47861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fp_selection(pop, size):\n    p = np.array([ind.fitness for ind in pop.population])\n    total_fitness = p.sum()\n    p = p / total_fitness\n    #p = np.cumsum(p) nice alternative solution\n    return rng.choice(pop.population, size = size, p = p).tolist()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:51:25.481116Z","iopub.execute_input":"2021-09-03T10:51:25.481531Z","iopub.status.idle":"2021-09-03T10:51:25.49186Z","shell.execute_reply.started":"2021-09-03T10:51:25.481491Z","shell.execute_reply":"2021-09-03T10:51:25.490799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#stochastic universal sampling\ndef sus_selection(pop, size):\n    p = np.array([ind.fitness for ind in pop.population]).cumsum()\n    total_fitness = np.array([ind.fitness for ind in pop.population]).sum()\n    step = total_fitness / size\n    start = rng.uniform(0, step)\n    steps = [(start + i*step) for i in range(size)]\n    i = 0\n    breeding = []\n    for s in steps:\n        while p[i] < s:\n            i = i + 1\n            breeding.append(pop.population[i])\n    return breeding","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:51:25.493416Z","iopub.execute_input":"2021-09-03T10:51:25.493774Z","iopub.status.idle":"2021-09-03T10:51:25.511592Z","shell.execute_reply.started":"2021-09-03T10:51:25.493727Z","shell.execute_reply":"2021-09-03T10:51:25.510659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#add requirement size and elitism have to be even!\n#also elitism is almost unnecessary if tournament, almost!\ndef tournament_selection(pop, size):\n    participants = [ind for ind in pop.population]\n    breeding = []\n    #could implement different rounds here\n    #but I think that's almost the same as calling tournament different times with smaller sizes\n    for i in range(size):\n        a, b = rng.choice(participants, 2)\n        if a > b:\n            breeding.append(a)\n            participants.remove(a)\n        else:\n            breeding.append(b)\n            participants.remove(b)\n    return breeding\n        \n    \n#reverse tournament, eliminates need for elitism\n#could use with parallelism\ndef rev_tournament_selection(pop, size):\n    breeding = [ind for ind in pop.population]\n    num_eliminated = len(breeding) - size\n    for i in range(num_eliminated):\n        a, b = rng.choice(participants, 2)\n        if a > b:\n            breeding.remove(b)\n        else:\n            breeding.remove(a)\n    return breeding\n        ","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:51:25.513027Z","iopub.execute_input":"2021-09-03T10:51:25.513768Z","iopub.status.idle":"2021-09-03T10:51:25.527108Z","shell.execute_reply.started":"2021-09-03T10:51:25.513724Z","shell.execute_reply":"2021-09-03T10:51:25.526081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def breed(parent_1, parent_2, p_cross, p_mutate):\n    # check for recombination\n    # if crossover happens at probability p then not crossover would happen at probability 1-p\n    #rand() will draw a number larger than p_cross 1-p times\n    #and a number < p_cross p times\n    # children are copies of parents by default\n    child_1, child_2 = Individual(parent_1.genes, parent_1.fitness), Individual(parent_2.genes, parent_2.fitness)\n    if np.random.rand() < p_cross: \n        \n        genes = list(child_1.genes)\n        child_1, child_2 = crossover(parent_1, parent_2, child_1, child_2)\n        #mutate if p\n    if np.random.rand() < p_mutate:\n        child_1.mutate()\n    if np.random.rand() < p_mutate:\n        child_2.mutate()\n        \n        child_1.set_fitness()\n        child_2.set_fitness()\n    return child_1, child_2","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:51:25.528899Z","iopub.execute_input":"2021-09-03T10:51:25.529472Z","iopub.status.idle":"2021-09-03T10:51:25.54238Z","shell.execute_reply.started":"2021-09-03T10:51:25.529425Z","shell.execute_reply":"2021-09-03T10:51:25.541563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# crossover two parents to create two children\n# should not be called by itself because it doesn't set fitness \ndef crossover(parent_1, parent_2, child_1, child_2):\n    # children are copies of parents by default\n    genes = list(child_1.genes) #make global to make more efficient!\n    # select crossover point that is not on the end of the string\n    start = rng.choice(range(len(genes) - 1))\n    #no crossover happening\n    if start == len(genes) -1:\n        return [child_1, child_2]\n    cut = rng.choice(range(start, len(genes)))\n    #no crossover happening\n    if cut == start:\n        return [child_1, child_2]\n    # perform crossover\n    for gene in genes[start:cut]:\n        if isinstance(gene_pool[gene], float): #introduce more diversity by modified crossover for continous values\n            #could also solve this with algebra, but I like using the predefined gene_pool\n            lower = parent_1[gene]\n            higher = parnt_2[gene]\n            if parent_1[gene] > parent_2[gene]:\n                lower = parent_2[gene]\n                higher = parent_1[gene]\n                \n            new_gene_1, new_gene_2, = rng.choice(gene_pool[gene][(gene_pool[gene] >= lower) & (gene_pool[gene] <= higher)], 2)\n            child_1.set_gene(gene, new_gene_1)\n            child_2.set_gene(gene, new_gene_2)\n        else:\n            child_1.set_gene(gene, parent_2.genes[gene])\n            child_2.set_gene(gene, parent_1.genes[gene])\n        \n    return child_1, child_2","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:51:25.54389Z","iopub.execute_input":"2021-09-03T10:51:25.544491Z","iopub.status.idle":"2021-09-03T10:51:25.565061Z","shell.execute_reply.started":"2021-09-03T10:51:25.544446Z","shell.execute_reply":"2021-09-03T10:51:25.563936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def simulate(params,\n             scorer,\n             iterations,\n             model,\n             train_set,\n             train_labels,\n             selection = 'fp',\n             p_cross = 1,\n             cv = 3,\n             p_mutate = 1,\n             sim_ann = True, \n             restrict_gene_pool = True, #narrow genes i.e. finetune\n             gene_pool_window = 1.0, #initial size of window\n             decay = None,\n             elitism = 2,\n             population_size = 10):\n    #add some fixed genes\n    global X_train, y_train, estimator, fitness_function, gene_pool, restrict_gnp, gnp_window, rng\n    global p_outlier\n    generations = np.arange(0, iterations)\n    fitness_prog = []\n    p_outlier = 1 - p_mutate\n    rng = np.random.default_rng()\n    X_train, y_train = train_set, train_labels\n    fitness_function = scorer\n    estimator = model\n    gene_pool = params\n    restrict_gnp = restrict_gene_pool\n    gnp_window = gene_pool_window\n    population = Population(gene_pool, size = population_size)\n    best_fitness = population.best_fitness\n    if decay == None:\n        decay = 1 / iterations\n    print(f\"best initial fitness: {population.best_fitness}\")\n    for i in trange(iterations):\n        fitness_prog.append(best_fitness)\n        new_gen = []\n        breeding = select_breeding(population, selection)\n        for elite in range(elitism):\n            new_gen.append(population.population[elite])\n       \n        #elitism to be implemented here\n        while(len(new_gen) < population.size): #let populatin size oscillate +1 -1?\n            parent_1, parent_2 = rng.choice(breeding, 2) #possibility of selecting the same individual\n            child_1, child_2 = breed(parent_1, parent_2, p_cross, p_mutate)\n            new_gen.append(child_1)\n            new_gen.append(child_2)\n        #replace the previous generation\n        population.replace_generation(new_gen)\n        #are you better than the last?\n        if (best_fitness < population.best_fitness):\n            diff = population.best_fitness - best_fitness\n            best_fitness = population.best_fitness\n            display(f\"child {population.best_individual} with fitness {population.best_fitness}, which is {diff} better than before\")\n        if sim_ann:\n            gnp_window = gnp_window - gnp_window*decay\n            p_cross = p_cross - p_cross*decay\n            p_mutate = p_mutate - p_mutate*decay\n            if p_outlier < 0.1:\n                p_outlier = 1 - p_mutate\n    #note if several individuals have same fitness anyone of them is returned\n    return population.best_individual, (generations, fitness_prog)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:51:25.566483Z","iopub.execute_input":"2021-09-03T10:51:25.566795Z","iopub.status.idle":"2021-09-03T10:51:25.585055Z","shell.execute_reply.started":"2021-09-03T10:51:25.566766Z","shell.execute_reply":"2021-09-03T10:51:25.583939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data directory\ndata_dir = '../input/optiver-realized-volatility-prediction/'\n\n# Function to calculate first WAP\ndef calc_wap1(df):\n    wap = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) / (df['bid_size1'] + df['ask_size1'])\n    return wap\n\n# Function to calculate second WAP\ndef calc_wap2(df):\n    wap = (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']) / (df['bid_size2'] + df['ask_size2'])\n    return wap\n\n# Function to calculate the log of the return\n# Remember that logb(x / y) = logb(x) - logb(y)\ndef log_return(series):\n    return np.log(series).diff()\n\n# Calculate the realized volatility\ndef realized_volatility(series):\n    return np.sqrt(np.sum(series**2))\n\n# Function to count unique elements of a series\ndef count_unique(series):\n    return len(np.unique(series))\n\n# Function to read our base train and test set\ndef read_train_test():\n    train = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\n    test = pd.read_csv('../input/optiver-realized-volatility-prediction/test.csv')\n    # Create a key to merge with book and trade data\n    train['row_id'] = train['stock_id'].astype(str) + '-' + train['time_id'].astype(str)\n    test['row_id'] = test['stock_id'].astype(str) + '-' + test['time_id'].astype(str)\n    print(f'Our training set has {train.shape[0]} rows')\n    return train, test\n\n# Function to preprocess book data (for each stock id)\ndef book_preprocessor(file_path):\n    df = pd.read_parquet(file_path)\n    # Calculate Wap\n    df['wap1'] = calc_wap1(df)\n    df['wap2'] = calc_wap2(df)\n    # Calculate log returns\n    df['log_return1'] = df.groupby(['time_id'])['wap1'].apply(log_return)\n    df['log_return2'] = df.groupby(['time_id'])['wap2'].apply(log_return)\n    # Calculate wap balance\n    df['wap_balance'] = abs(df['wap1'] - df['wap2'])\n    # Calculate spread\n    df['price_spread'] = (df['ask_price1'] - df['bid_price1']) / ((df['ask_price1'] + df['bid_price1']) / 2)\n    df['bid_spread'] = df['bid_price1'] - df['bid_price2']\n    df['ask_spread'] = df['ask_price1'] - df['ask_price2']\n    df['total_volume'] = (df['ask_size1'] + df['ask_size2']) + (df['bid_size1'] + df['bid_size2'])\n    df['volume_imbalance'] = abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2']))\n    \n    # Dict for aggregations\n    create_feature_dict = {\n        'wap1': [np.sum, np.mean, np.std],\n        'wap2': [np.sum, np.mean, np.std],\n        'log_return1': [np.sum, realized_volatility, np.mean, np.std],\n        'log_return2': [np.sum, realized_volatility, np.mean, np.std],\n        'wap_balance': [np.sum, np.mean, np.std],\n        'price_spread':[np.sum, np.mean, np.std],\n        'bid_spread':[np.sum, np.mean, np.std],\n        'ask_spread':[np.sum, np.mean, np.std],\n        'total_volume':[np.sum, np.mean, np.std],\n        'volume_imbalance':[np.sum, np.mean, np.std]\n    }\n    \n    # Function to get group stats for different windows (seconds in bucket)\n    def get_stats_window(seconds_in_bucket, add_suffix = False):\n        # Group by the window\n        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(create_feature_dict).reset_index()\n        # Rename columns joining suffix\n        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n        # Add a suffix to differentiate windows\n        if add_suffix:\n            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n        return df_feature\n    \n    # Get the stats for different windows\n    df_feature = get_stats_window(seconds_in_bucket = 0, add_suffix = False)\n    df_feature_450 = get_stats_window(seconds_in_bucket = 450, add_suffix = True)\n    df_feature_300 = get_stats_window(seconds_in_bucket = 300, add_suffix = True)\n    df_feature_150 = get_stats_window(seconds_in_bucket = 150, add_suffix = True)\n    \n    # Merge all\n    df_feature = df_feature.merge(df_feature_450, how = 'left', left_on = 'time_id_', right_on = 'time_id__450')\n    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n    df_feature = df_feature.merge(df_feature_150, how = 'left', left_on = 'time_id_', right_on = 'time_id__150')\n    # Drop unnecesary time_ids\n    df_feature.drop(['time_id__450', 'time_id__300', 'time_id__150'], axis = 1, inplace = True)\n    \n    # Create row_id so we can merge\n    stock_id = file_path.split('=')[1]\n    df_feature['row_id'] = df_feature['time_id_'].apply(lambda x: f'{stock_id}-{x}')\n    df_feature.drop(['time_id_'], axis = 1, inplace = True)\n    return df_feature\n\n# Function to preprocess trade data (for each stock id)\ndef trade_preprocessor(file_path):\n    df = pd.read_parquet(file_path)\n    df['log_return'] = df.groupby('time_id')['price'].apply(log_return)\n    \n    # Dict for aggregations\n    create_feature_dict = {\n        'log_return':[realized_volatility],\n        'seconds_in_bucket':[count_unique],\n        'size':[np.sum],\n        'order_count':[np.mean],\n    }\n    \n    # Function to get group stats for different windows (seconds in bucket)\n    def get_stats_window(seconds_in_bucket, add_suffix = False):\n        # Group by the window\n        df_feature = df[df['seconds_in_bucket'] >= seconds_in_bucket].groupby(['time_id']).agg(create_feature_dict).reset_index()\n        # Rename columns joining suffix\n        df_feature.columns = ['_'.join(col) for col in df_feature.columns]\n        # Add a suffix to differentiate windows\n        if add_suffix:\n            df_feature = df_feature.add_suffix('_' + str(seconds_in_bucket))\n        return df_feature\n    \n    # Get the stats for different windows\n    df_feature = get_stats_window(seconds_in_bucket = 0, add_suffix = False)\n    df_feature_450 = get_stats_window(seconds_in_bucket = 450, add_suffix = True)\n    df_feature_300 = get_stats_window(seconds_in_bucket = 300, add_suffix = True)\n    df_feature_150 = get_stats_window(seconds_in_bucket = 150, add_suffix = True)\n\n    # Merge all\n    df_feature = df_feature.merge(df_feature_450, how = 'left', left_on = 'time_id_', right_on = 'time_id__450')\n    df_feature = df_feature.merge(df_feature_300, how = 'left', left_on = 'time_id_', right_on = 'time_id__300')\n    df_feature = df_feature.merge(df_feature_150, how = 'left', left_on = 'time_id_', right_on = 'time_id__150')\n    # Drop unnecesary time_ids\n    df_feature.drop(['time_id__450', 'time_id__300', 'time_id__150'], axis = 1, inplace = True)\n    \n    df_feature = df_feature.add_prefix('trade_')\n    stock_id = file_path.split('=')[1]\n    df_feature['row_id'] = df_feature['trade_time_id_'].apply(lambda x:f'{stock_id}-{x}')\n    df_feature.drop(['trade_time_id_'], axis = 1, inplace = True)\n    return df_feature\n\n# Function to get group stats for the stock_id and time_id\ndef get_time_stock(df):\n    # Get realized volatility columns\n    vol_cols = ['log_return1_realized_volatility', 'log_return2_realized_volatility', 'log_return1_realized_volatility_450', 'log_return2_realized_volatility_450', \n                'log_return1_realized_volatility_300', 'log_return2_realized_volatility_300', 'log_return1_realized_volatility_150', 'log_return2_realized_volatility_150', \n                'trade_log_return_realized_volatility', 'trade_log_return_realized_volatility_450', 'trade_log_return_realized_volatility_300', 'trade_log_return_realized_volatility_150']\n\n    # Group by the stock id\n    df_stock_id = df.groupby(['stock_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n    # Rename columns joining suffix\n    df_stock_id.columns = ['_'.join(col) for col in df_stock_id.columns]\n    df_stock_id = df_stock_id.add_suffix('_' + 'stock')\n\n    # Group by the stock id\n    df_time_id = df.groupby(['time_id'])[vol_cols].agg(['mean', 'std', 'max', 'min', ]).reset_index()\n    # Rename columns joining suffix\n    df_time_id.columns = ['_'.join(col) for col in df_time_id.columns]\n    df_time_id = df_time_id.add_suffix('_' + 'time')\n    \n    # Merge with original dataframe\n    df = df.merge(df_stock_id, how = 'left', left_on = ['stock_id'], right_on = ['stock_id__stock'])\n    df = df.merge(df_time_id, how = 'left', left_on = ['time_id'], right_on = ['time_id__time'])\n    df.drop(['stock_id__stock', 'time_id__time'], axis = 1, inplace = True)\n    return df\n    \n# Funtion to make preprocessing function in parallel (for each stock id)\ndef preprocessor(list_stock_ids, is_train = True):\n    \n    # Parrallel for loop\n    def for_joblib(stock_id):\n        # Train\n        if is_train:\n            file_path_book = data_dir + \"book_train.parquet/stock_id=\" + str(stock_id)\n            file_path_trade = data_dir + \"trade_train.parquet/stock_id=\" + str(stock_id)\n        # Test\n        else:\n            file_path_book = data_dir + \"book_test.parquet/stock_id=\" + str(stock_id)\n            file_path_trade = data_dir + \"trade_test.parquet/stock_id=\" + str(stock_id)\n    \n        # Preprocess book and trade data and merge them\n        df_tmp = pd.merge(book_preprocessor(file_path_book), trade_preprocessor(file_path_trade), on = 'row_id', how = 'left')\n        \n        # Return the merge dataframe\n        return df_tmp\n    \n    # Use parallel api to call paralle for loop\n    df = Parallel(n_jobs = -1, verbose = 1)(delayed(for_joblib)(stock_id) for stock_id in list_stock_ids)\n    # Concatenate all the dataframes that return from Parallel\n    df = pd.concat(df, ignore_index = True)\n    return df\n\n# Function to calculate the root mean squared percentage error\ndef rmspe(y_true, y_pred):\n    return -np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\n\n# Function to early stop with root mean squared percentage error\ndef feval_rmspe(y_pred, lgb_train):\n    y_true = lgb_train.get_label()\n    return 'RMSPE', rmspe(y_true, y_pred), False","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:51:25.586442Z","iopub.execute_input":"2021-09-03T10:51:25.586729Z","iopub.status.idle":"2021-09-03T10:51:25.632998Z","shell.execute_reply.started":"2021-09-03T10:51:25.586703Z","shell.execute_reply":"2021-09-03T10:51:25.632183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = dict()\nparams['kernel'] = ['rbf', 'poly', 'sigmoid']\nparams['degree'] = [2, 3, 4]\nparams['gamma'] = ['scale', 'auto']\nparams['C'] = np.linspace(0.001, 10, 1000)\nparams['epsilon'] = np.linspace(0.01, 10, 500)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:51:25.634091Z","iopub.execute_input":"2021-09-03T10:51:25.634586Z","iopub.status.idle":"2021-09-03T10:51:25.653646Z","shell.execute_reply.started":"2021-09-03T10:51:25.634549Z","shell.execute_reply":"2021-09-03T10:51:25.652405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import make_scorer","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:51:25.656125Z","iopub.execute_input":"2021-09-03T10:51:25.656529Z","iopub.status.idle":"2021-09-03T10:51:25.671264Z","shell.execute_reply.started":"2021-09-03T10:51:25.656496Z","shell.execute_reply":"2021-09-03T10:51:25.670411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, test = read_train_test()\nx = train.drop(['row_id', 'target', 'time_id'], axis = 1)\ny = train['target']\nx_test = test.drop(['row_id', 'time_id'], axis = 1)\n# Transform stock id to a numeric value\nx['stock_id'] = x['stock_id'].astype(int)\nx_test['stock_id'] = x_test['stock_id'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:51:25.674379Z","iopub.execute_input":"2021-09-03T10:51:25.674755Z","iopub.status.idle":"2021-09-03T10:51:27.204765Z","shell.execute_reply.started":"2021-09-03T10:51:25.674725Z","shell.execute_reply":"2021-09-03T10:51:27.203316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reg = lgb.LGBMRegressor(**nanpams)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:51:27.206223Z","iopub.execute_input":"2021-09-03T10:51:27.206506Z","iopub.status.idle":"2021-09-03T10:51:27.211125Z","shell.execute_reply.started":"2021-09-03T10:51:27.20648Z","shell.execute_reply":"2021-09-03T10:51:27.209856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scorer = make_scorer(rmspe)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:51:27.212411Z","iopub.execute_input":"2021-09-03T10:51:27.212686Z","iopub.status.idle":"2021-09-03T10:51:27.224326Z","shell.execute_reply.started":"2021-09-03T10:51:27.21266Z","shell.execute_reply":"2021-09-03T10:51:27.223294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#np.mean(cross_val_score(reg, x, y, scoring=scorer))","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:51:27.225813Z","iopub.execute_input":"2021-09-03T10:51:27.226429Z","iopub.status.idle":"2021-09-03T10:51:27.236126Z","shell.execute_reply.started":"2021-09-03T10:51:27.226397Z","shell.execute_reply":"2021-09-03T10:51:27.234985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best, history= simulate(params, scorer, 500,\n                        SVR,\n                        x, y,\n                        selection = 'tournament',\n                        p_cross = 1,\n                        p_mutate = 1,\n                        sim_ann = True)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:51:27.237553Z","iopub.execute_input":"2021-09-03T10:51:27.237951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.regplot(x = history[0], y = history[1])\nplt.xlabel('generation')\nplt.ylabel('fitness')\nplt.savefig('svr.png')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test_p = reg.predict(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}