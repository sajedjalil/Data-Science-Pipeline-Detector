{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-03T17:17:44.689616Z","iopub.execute_input":"2021-07-03T17:17:44.689863Z","iopub.status.idle":"2021-07-03T17:17:45.0789Z","shell.execute_reply.started":"2021-07-03T17:17:44.689839Z","shell.execute_reply":"2021-07-03T17:17:45.077957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Lets Start with EDA","metadata":{}},{"cell_type":"code","source":"#import lib\nimport pandas as pd\nimport numpy as np\nimport matplotlib as mpl\n%matplotlib inline\nimport plotly.express as px\nimport plotly.graph_objects as gr_ob\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n","metadata":{"execution":{"iopub.status.busy":"2021-07-03T17:17:45.082153Z","iopub.execute_input":"2021-07-03T17:17:45.082414Z","iopub.status.idle":"2021-07-03T17:17:45.088741Z","shell.execute_reply.started":"2021-07-03T17:17:45.082387Z","shell.execute_reply":"2021-07-03T17:17:45.087927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#import train csv files\ntrain = pd.read_csv('../input/optiver-realized-volatility-prediction/train.csv')\nprint(\"train shape:\",train.shape)\ntrain.sample(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T17:17:51.519637Z","iopub.execute_input":"2021-07-03T17:17:51.51997Z","iopub.status.idle":"2021-07-03T17:17:51.884896Z","shell.execute_reply.started":"2021-07-03T17:17:51.519939Z","shell.execute_reply":"2021-07-03T17:17:51.884029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"group by stock id and see the target distribution","metadata":{}},{"cell_type":"code","source":"train.groupby(['stock_id']).size()\nplt.figure(figsize=(14, 7))\nsns.histplot(train['target'], label = 'Target distribution')","metadata":{"execution":{"iopub.status.busy":"2021-07-03T17:17:55.278662Z","iopub.execute_input":"2021-07-03T17:17:55.279032Z","iopub.status.idle":"2021-07-03T17:17:57.34462Z","shell.execute_reply.started":"2021-07-03T17:17:55.278967Z","shell.execute_reply":"2021-07-03T17:17:57.343799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# time id distribution","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14, 7))\nsns.distplot(train['time_id'], label = 'Time_id distribution')\n#time id vs target distribution\nplt.figure(figsize=(14, 7))\nsns.scatterplot(data=train, x=\"time_id\", y=\"target\")","metadata":{"execution":{"iopub.status.busy":"2021-07-03T17:17:58.537568Z","iopub.execute_input":"2021-07-03T17:17:58.537908Z","iopub.status.idle":"2021-07-03T17:18:01.512171Z","shell.execute_reply.started":"2021-07-03T17:17:58.537877Z","shell.execute_reply":"2021-07-03T17:18:01.511381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets read order books. for more about order books: https://www.kaggle.com/jiashenliu/introduction-to-financial-concepts-and-data","metadata":{}},{"cell_type":"code","source":"#lets read a order book\nstock_id='1'\ntime_id=5\n\n#book read\nbook = pd.read_parquet(f'../input/optiver-realized-volatility-prediction/book_train.parquet/stock_id={stock_id}')\n#trade_read\ntrade =  pd.read_parquet(f'../input/optiver-realized-volatility-prediction/trade_train.parquet/stock_id={stock_id}')\n#define the book\nbook = book[book['time_id']==time_id]\nbook.loc[:,'stock_id'] = stock_id\ntrade = trade[trade['time_id']==time_id]\ntrade.loc[:,'stock_id'] = stock_id\n#see the book now\nbook.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T17:18:04.820928Z","iopub.execute_input":"2021-07-03T17:18:04.821304Z","iopub.status.idle":"2021-07-03T17:18:05.748812Z","shell.execute_reply.started":"2021-07-03T17:18:04.821271Z","shell.execute_reply":"2021-07-03T17:18:05.748022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# see the book histogram","metadata":{}},{"cell_type":"code","source":"book.hist(figsize=(16,10))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T17:18:08.515624Z","iopub.execute_input":"2021-07-03T17:18:08.515945Z","iopub.status.idle":"2021-07-03T17:18:09.841708Z","shell.execute_reply.started":"2021-07-03T17:18:08.515913Z","shell.execute_reply":"2021-07-03T17:18:09.840885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets investigate using pairplot and scatter histograms","metadata":{}},{"cell_type":"code","source":"sns.pairplot(book[['seconds_in_bucket','ask_price1','ask_price2','ask_size1','ask_size2']],  diag_kind=\"hist\",height=4)\nsns.pairplot(book[['seconds_in_bucket','bid_price1','bid_price2','bid_size1','bid_size2']],  diag_kind=\"hist\",height=4)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T17:18:13.867844Z","iopub.execute_input":"2021-07-03T17:18:13.868202Z","iopub.status.idle":"2021-07-03T17:18:23.556811Z","shell.execute_reply.started":"2021-07-03T17:18:13.868172Z","shell.execute_reply":"2021-07-03T17:18:23.555989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# lets investigate timeseries plot","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (10,5)) \nsns.lineplot(x = book[\"seconds_in_bucket\"], y =book[\"ask_price1\"], data = book)\nsns.lineplot(x = book[\"seconds_in_bucket\"], y =book[\"ask_price2\"], data = book)\nplt.legend(labels=['ask_price1', 'ask_price2'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T17:18:23.558404Z","iopub.execute_input":"2021-07-03T17:18:23.5588Z","iopub.status.idle":"2021-07-03T17:18:23.802134Z","shell.execute_reply.started":"2021-07-03T17:18:23.558763Z","shell.execute_reply":"2021-07-03T17:18:23.801159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (10,5)) \nsns.lineplot(x = book[\"seconds_in_bucket\"], y =book[\"ask_size1\"], data = book)\nsns.lineplot(x = book[\"seconds_in_bucket\"], y =book[\"ask_size2\"], data = book)\nplt.legend(labels=['ask_size1', 'ask_size2'])\nplt.show()\n#bid size\nplt.figure(figsize = (10,5)) \nsns.lineplot(x = book[\"seconds_in_bucket\"], y =book[\"bid_size1\"], data = book)\nsns.lineplot(x = book[\"seconds_in_bucket\"], y =book[\"bid_size2\"], data = book)\nplt.legend(labels=['bid_size1', 'bid_size2'])\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-03T17:18:24.46375Z","iopub.execute_input":"2021-07-03T17:18:24.464103Z","iopub.status.idle":"2021-07-03T17:18:24.961259Z","shell.execute_reply.started":"2021-07-03T17:18:24.46407Z","shell.execute_reply":"2021-07-03T17:18:24.960435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets investigate Trade book","metadata":{}},{"cell_type":"code","source":"#plot trade book hist data\ntrade.hist(figsize=(16,12))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T17:18:27.68988Z","iopub.execute_input":"2021-07-03T17:18:27.690266Z","iopub.status.idle":"2021-07-03T17:18:28.435883Z","shell.execute_reply.started":"2021-07-03T17:18:27.690236Z","shell.execute_reply":"2021-07-03T17:18:28.434955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#investigate pairplots\nsns.pairplot(trade[['seconds_in_bucket','price','size']],  diag_kind=\"hist\",height=3)\n# see line plot by seconds and trade size\nplt.figure(figsize = (10,5)) \nsns.lineplot(x = trade[\"seconds_in_bucket\"], y =trade[\"size\"], data = trade)\nplt.legend(labels=['size'])\nplt.show()\n#another one by price\nplt.figure(figsize = (10,5)) \nsns.lineplot(x = trade[\"seconds_in_bucket\"], y =trade[\"price\"], data = trade)\nplt.legend(labels=['price'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T17:18:29.170873Z","iopub.execute_input":"2021-07-03T17:18:29.171249Z","iopub.status.idle":"2021-07-03T17:18:31.235995Z","shell.execute_reply.started":"2021-07-03T17:18:29.171218Z","shell.execute_reply":"2021-07-03T17:18:31.235019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets analyze the order book by WAP- weighted averaged price","metadata":{}},{"cell_type":"code","source":"#sort the book by wap\n#calculate wap price by rules\nbook['wap'] = (book['bid_price1'] * book['ask_size1'] +book['ask_price1'] * book['bid_size1']) / (book['bid_size1']+ book['ask_size1'])\nplt.figure(figsize = (10,5)) \n#lineplot for wap\nsns.lineplot(x = book[\"seconds_in_bucket\"], y =book[\"wap\"], data = book)\nplt.legend(labels=['wap'])\nplt.title(\"WAP of stock_id_1, time_id_5\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-03T17:18:31.237601Z","iopub.execute_input":"2021-07-03T17:18:31.237995Z","iopub.status.idle":"2021-07-03T17:18:31.438242Z","shell.execute_reply.started":"2021-07-03T17:18:31.237918Z","shell.execute_reply":"2021-07-03T17:18:31.437203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Log Returns","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"book.loc[:,'log_return'] = np.log(book['wap']).diff() \nbook = book[~book['log_return'].isnull()]\nbook.head(5)\n#plot the log returns\nplt.figure(figsize = (10,5)) \nsns.lineplot(x = book[\"seconds_in_bucket\"], y =book[\"log_return\"], data = book)\nplt.legend(labels=['log_return'])\nplt.title(\"log_return of stock_id_1, time_id_5\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T17:18:34.264502Z","iopub.execute_input":"2021-07-03T17:18:34.264857Z","iopub.status.idle":"2021-07-03T17:18:34.469798Z","shell.execute_reply.started":"2021-07-03T17:18:34.264825Z","shell.execute_reply":"2021-07-03T17:18:34.469017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now we try to build the prediction model","metadata":{}},{"cell_type":"code","source":"#important lib\nimport plotly.express as px\nfrom sklearn.metrics import r2_score\nimport os\nimport glob\nfrom tqdm import tqdm\nimport lightgbm as lgbm\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import Ridge\n\nfrom joblib import Parallel, delayed","metadata":{"execution":{"iopub.status.busy":"2021-07-03T17:18:36.80471Z","iopub.execute_input":"2021-07-03T17:18:36.805054Z","iopub.status.idle":"2021-07-03T17:18:37.021254Z","shell.execute_reply.started":"2021-07-03T17:18:36.805022Z","shell.execute_reply":"2021-07-03T17:18:37.020398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#some impfunctions\n#https://www.kaggle.com/konradb/naive-optuna-tuned-stacked-ensemble-model\nclass CFG:\n    data_dir = '../input/optiver-realized-volatility-prediction/'\n    nfolds = 5\n    \ndef log_return(list_stock_prices):\n    return np.log(list_stock_prices).diff() \n\ndef rv(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))\n\n\ndef rv2(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))\n\n\n# taken from https://www.kaggle.com/yus002/realized-volatility-prediction-lgbm-train\ndef my_metrics(y_true, y_pred):\n    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\ndef rmspe(y_true, y_pred):  \n    output = my_metrics(y_true, y_pred)\n    return 'rmspe', output, False\ndef get_stock_stat(stock_id : int, dataType = 'train'):\n    \n    df_book = pd.read_parquet(f'../input/optiver-realized-volatility-prediction/book_{dataType}.parquet/stock_id={stock_id}/')\n    df_book.sort_values(by=['time_id', 'seconds_in_bucket'])\n\n    # compute different vwap\n    df_book['wap1'] = (df_book['bid_price1'] * df_book['ask_size1'] + df_book['ask_price1'] * df_book['bid_size1']) / (\n                            df_book['bid_size1']+ df_book['ask_size1'])\n # wap2\n    a = df_book['bid_price2'] * df_book['ask_size2'] + df_book['ask_price2'] * df_book['bid_size2']\n    b = df_book['bid_size2']+ df_book['ask_size2']\n    df_book['wap2'] = a/b\n    \n    # wap3\n    a1 = df_book['bid_price1'] * df_book['ask_size1'] + df_book['ask_price1'] * df_book['bid_size1']\n    a2 = df_book['bid_price2'] * df_book['ask_size2'] + df_book['ask_price2'] * df_book['bid_size2']\n    b = df_book['bid_size1'] + df_book['ask_size1'] + df_book['bid_size2']+ df_book['ask_size2']    \n    df_book['wap3'] = (a1 + a2)/ b\n    \n     # wap4 \n    a = (df_book['bid_price1'] * df_book['ask_size1'] + df_book['ask_price1'] * df_book['bid_size1']) / (\n                                       df_book['bid_size1']+ df_book['ask_size1'])\n    b = (df_book['bid_price2'] * df_book['ask_size2'] + df_book['ask_price2'] * df_book['bid_size2']) / (\n                                       df_book['bid_size2']+ df_book['ask_size2'])\n    df_book['wap4'] = (a + b) / 2\n                    \n    df_book['vol_wap1'] = (df_book.groupby(by = ['time_id'])['wap1'].apply(log_return).reset_index(drop = True).fillna(0))\n    df_book['vol_wap2'] = (df_book.groupby(by = ['time_id'])['wap2'].apply(log_return).reset_index(drop = True).fillna(0))\n    df_book['vol_wap3'] = (df_book.groupby(by = ['time_id'])['wap3'].apply(log_return).reset_index(drop = True).fillna(0))\n    df_book['vol_wap4'] = (df_book.groupby(by = ['time_id'])['wap4'].apply(log_return).reset_index(drop = True).fillna(0))\n    df_book['bas'] = (df_book[['ask_price1', 'ask_price2']].min(axis = 1)\n                                / df_book[['bid_price1', 'bid_price2']].max(axis = 1) - 1)                               \n\n    # different spreads\n    df_book['h_spread_l1'] = df_book['ask_price1'] - df_book['bid_price1']\n    df_book['h_spread_l2'] = df_book['ask_price2'] - df_book['bid_price2']\n    df_book['v_spread_b'] = df_book['bid_price1'] - df_book['bid_price2']\n    df_book['v_spread_a'] = df_book['ask_price1'] - df_book['bid_price2']\n    \n    # attach volatitilies based on different VWAPs\n    stock_stat = pd.merge(\n        df_book.groupby(by = ['time_id'])['vol_wap1'].agg(rv).reset_index(),\n        df_book.groupby(by = ['time_id'], as_index = False)['bas'].mean(),\n        on = ['time_id'], how = 'left'\n    )\n    stock_stat = pd.merge( df_book.groupby(by = ['time_id'])['vol_wap2'].agg(rv).reset_index(),\n        stock_stat, on = ['time_id'], how = 'left'\n    )\n    \n    stock_stat = pd.merge( df_book.groupby(by = ['time_id'])['vol_wap3'].agg(rv).reset_index(),\n        stock_stat, on = ['time_id'], how = 'left'\n    )\n        \n    stock_stat = pd.merge( df_book.groupby(by = ['time_id'])['vol_wap4'].agg(rv).reset_index(),\n        stock_stat, on = ['time_id'], how = 'left'\n    )     \n    \n    # spread summaries\n    stock_stat = pd.merge( df_book.groupby(by = ['time_id'])['h_spread_l1'].agg(max).reset_index(),\n        stock_stat, on = ['time_id'], how = 'left'\n    )     \n    stock_stat = pd.merge( df_book.groupby(by = ['time_id'])['h_spread_l2'].agg(max).reset_index(),\n        stock_stat, on = ['time_id'], how = 'left'\n    )\n    stock_stat = pd.merge( df_book.groupby(by = ['time_id'])['v_spread_b'].agg(max).reset_index(),\n        stock_stat, on = ['time_id'], how = 'left'\n    )   \n    stock_stat = pd.merge( df_book.groupby(by = ['time_id'])['v_spread_a'].agg(max).reset_index(),\n        stock_stat, on = ['time_id'], how = 'left'\n    )   \n        \n    stock_stat['stock_id'] = stock_id\n    return stock_stat\ndef get_dataSet(stock_ids : list, dataType = 'train'):\n\n    stock_stat = Parallel(n_jobs=-1)(\n        delayed(get_stock_stat)(stock_id, dataType) \n        for stock_id in stock_ids\n    )    \n    stock_stat_df = pd.concat(stock_stat, ignore_index = True)\n    return stock_stat_df\n","metadata":{"execution":{"iopub.status.busy":"2021-07-03T17:18:39.058939Z","iopub.execute_input":"2021-07-03T17:18:39.059303Z","iopub.status.idle":"2021-07-03T17:18:39.08324Z","shell.execute_reply.started":"2021-07-03T17:18:39.059274Z","shell.execute_reply":"2021-07-03T17:18:39.08239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#merge the data into train and test\ntrain = pd.read_csv(CFG.data_dir + 'train.csv')\ntrain.loc[train.stock_id == 0].head(3)\n#prpare training dataset\ntrain_stat_df = get_dataSet(stock_ids = train['stock_id'].unique(), dataType = 'train')\ntrain_dataSet = pd.merge(train, train_stat_df, on = ['stock_id', 'time_id'], how = 'left')","metadata":{"execution":{"iopub.status.busy":"2021-07-03T17:18:40.629593Z","iopub.execute_input":"2021-07-03T17:18:40.629914Z","iopub.status.idle":"2021-07-03T17:32:22.073862Z","shell.execute_reply.started":"2021-07-03T17:18:40.629884Z","shell.execute_reply":"2021-07-03T17:32:22.072768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#prepare testdataset\ntest = pd.read_csv('../input/optiver-realized-volatility-prediction/test.csv')\n\ntest_stat_df = get_dataSet(stock_ids = test['stock_id'].unique(), dataType = 'test')\ntest_dataSet = pd.merge(test, test_stat_df, on = ['stock_id', 'time_id'], how = 'left')","metadata":{"execution":{"iopub.status.busy":"2021-07-03T17:34:06.987734Z","iopub.execute_input":"2021-07-03T17:34:06.988101Z","iopub.status.idle":"2021-07-03T17:34:07.080728Z","shell.execute_reply.started":"2021-07-03T17:34:06.988064Z","shell.execute_reply":"2021-07-03T17:34:07.0797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Model\n##","metadata":{}},{"cell_type":"code","source":"covariates = [f for f in train_dataSet.columns if f not in ['time_id', 'target']]\n\n# taken from https://www.kaggle.com/yus002/realized-volatility-prediction-lgbm-train\ndef my_metrics(y_true, y_pred):\n    return np.sqrt(np.mean(np.square((y_true - y_pred) / y_true)))\ndef rmspe(y_true, y_pred):  \n    output = my_metrics(y_true, y_pred)\n    return 'rmspe', output, False\nprval = np.zeros((train_dataSet.shape[0],1))\nprfull = np.zeros((test_dataSet.shape[0],1))\n\nxdat = train_dataSet[covariates].copy()\nydat = train_dataSet['target'].copy()\nxtest = test_dataSet[covariates].copy()\n\nparams = {'metric': 'rmse','reg_alpha': 0.9,  'reg_lambda': 5.61, \n          'num_leaves': 56, 'learning_rate': 0.08, \n          'max_depth': 5, 'n_estimators': 1000, 'min_child_weight': 0.11, \n          'subsample': 0.7, 'colsample_bytree': 0.8,  'min_child_samples': 28}\nkf = KFold(n_splits= CFG.nfolds, shuffle = True, random_state = 42)\nfor (ii, (id0, id1)) in enumerate(kf.split(train_dataSet)):\n    x0, x1 = xdat.loc[id0], xdat.loc[id1]\n    y0, y1 = ydat.loc[id0], ydat.loc[id1]\n    \n    model = lgbm.LGBMRegressor(**params)\n    model.fit(x0, y0, eval_set=[(x0, y0), (x1, y1)], eval_metric = rmspe,\n              early_stopping_rounds= 50,  verbose= 250)\n    prval[id1,0] = model.predict(x1)\n    prfull[:,0] += model.predict(xtest)/CFG.nfolds\n    \ndel x0,x1,y0,y1,id0,id1\n\n#plot\nlgbm.plot_importance(model, max_num_features= 25)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-03T17:34:15.557594Z","iopub.execute_input":"2021-07-03T17:34:15.557955Z","iopub.status.idle":"2021-07-03T17:35:10.222529Z","shell.execute_reply.started":"2021-07-03T17:34:15.557925Z","shell.execute_reply":"2021-07-03T17:35:10.221723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#feeding data\nxref = pd.DataFrame()\nxref['ydat'] = ydat\nxref['prval'] = prval\ndel xdat, ydat\n\nR2 = round(r2_score(y_true = xref['ydat'], y_pred = xref['prval']),3)\na = (xref['ydat'] - xref['prval'])/xref['ydat']\nRMSPE =  np.round((np.sqrt(np.mean(np.square(a )))) ,4)\nprint(f'Performance of the naive prediction: R2 score: {R2}, RMSPE: {RMSPE}')","metadata":{"execution":{"iopub.status.busy":"2021-07-03T17:35:34.727384Z","iopub.execute_input":"2021-07-03T17:35:34.727722Z","iopub.status.idle":"2021-07-03T17:35:34.794524Z","shell.execute_reply.started":"2021-07-03T17:35:34.727689Z","shell.execute_reply":"2021-07-03T17:35:34.793554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# My Submission","metadata":{}},{"cell_type":"code","source":"test_dataSet['target'] = prfull\ntest_dataSet[['row_id', 'target']].to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T17:35:50.880378Z","iopub.execute_input":"2021-07-03T17:35:50.880744Z","iopub.status.idle":"2021-07-03T17:35:50.895492Z","shell.execute_reply.started":"2021-07-03T17:35:50.880713Z","shell.execute_reply":"2021-07-03T17:35:50.894428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ref:\nhttps://www.kaggle.com/damoonshahhosseini/volatility-prediction","metadata":{}}]}