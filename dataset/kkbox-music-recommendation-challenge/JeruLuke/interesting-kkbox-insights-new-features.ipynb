{"cells":[{"metadata":{"_cell_guid":"173cab72-98fa-4fb9-9561-74568bea786f","_uuid":"1cbb40486b31887f8692e4823e98b90f72af0d18"},"source":"# **What I intend to do?** \n\nIn this kernel, my sole intention is to create a highly feature engineered dataframe after merging existing files, which can be fed directly as input for modeling. \n\nBy this I mean dataframes for both the train set and test set which would contain same number of columns with encoded features.\n\nAt a glance I will be looking into the following issues:\n* Merging Dataframes          -> (*completed*)\n* Handling Missing Values   -> (*completed*)\n    * Came across something interesting where number of unique values in column '**source_screen_name**' were different for both test and train set.\n    * Columns like '**genre_ids**' have a combination of more than one genre which must be handled appropriately.\n* Feature Engineering          -> (*in progress*)\n    * number of genres per song\n    * number of lyricists per song\n    * number of composers per song\n    * whether song has features artists\n    * number of artists per song\n    * whether artist and composer are the same\n    * whether artist, composer and lyricist are all the same\n    \n## (thinking of more features)","cell_type":"markdown"},{"metadata":{"_cell_guid":"29910365-512c-44d6-8475-b99794b206e6","_uuid":"85b710a4fd096416721b290b789738837c9c88ee","collapsed":true},"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nimport re\nimport math\nfrom collections import Counter\n\nfrom subprocess import check_output\n\ndf_train = pd.read_csv('../input/train.csv')\ndf_test = pd.read_csv('../input/test.csv')\ndf_songs = pd.read_csv('../input/songs.csv')\ndf_members = pd.read_csv('../input/members.csv')","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"dc6cb2e1-9b24-40dd-a3af-117d9382c85f","_uuid":"cb4debcbe08c3838bfc6472bd15c87bbd633b39f"},"source":"# Merging Dataframes","cell_type":"markdown"},{"metadata":{"_cell_guid":"387ac170-0bba-4da1-a74c-c2bfeab3bd6c","_uuid":"13c1a373d1cb60fecd0d43106d34f8faab4f473f"},"source":"First, we will merge the train and test data with the members and songs data. We can keep the merged data and delete the independant ones, to save memory exhaustion on this kernel.","cell_type":"markdown"},{"metadata":{"_cell_guid":"bbfcc700-c76d-4316-9871-39cb33b7805d","_uuid":"05c503f83c06b1d6199f14e2201088b8f9655239","collapsed":true},"source":"#--- Merging dadtaframes ---\ndf_train_members = pd.merge(df_train, df_members, on='msno', how='inner')\ndf_train_merged = pd.merge(df_train_members, df_songs, on='song_id', how='outer')\n\ndf_test_members = pd.merge(df_test, df_members, on='msno', how='inner')\ndf_test_merged = pd.merge(df_test_members, df_songs, on='song_id', how='outer')\n\n#--- delete unwanted dataframe ---\ndel df_train_members\ndel df_test_members\n\ndel df_songs\ndel df_members","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"a6f3327a-54f8-41cb-a142-c903e296e04e","_uuid":"9ec848e91e2fe93c3e7c984a25026f04b4640ec3"},"source":"## Dropping rows with missing **msno** values\nUpon checking the number of rows in the original train data and the merged train data, they would **not** be the same. ","cell_type":"markdown"},{"metadata":{"_cell_guid":"781dd206-73d3-40f9-afd0-d0d47c045b42","_uuid":"9540df8b564d8c63db26c10b6612583e418433f4","collapsed":true},"source":"print(len(df_train))\nprint(len(df_train_merged))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"092785e4-e658-4590-845e-eb2b0d570296","_uuid":"c8314718dfc156828aa289d906a4a4a3381d84b5"},"source":"The same case goes for the test dataframes as well.","cell_type":"markdown"},{"metadata":{"_cell_guid":"5eac5eb7-6077-4470-875e-1b290331ff69","_uuid":"f4153241022d51bebd2309f35edc3f0ec67d3360","collapsed":true},"source":"print(len(df_test))\nprint(len(df_test_merged))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"e9680c61-6725-4713-8fc6-1c4d7056a014","_uuid":"7d7e85aa2fcbb07b43b21fc99119bdbf5bae18dd"},"source":"This is because rows with missing **msno** have also been included while merging which must be dropped:","cell_type":"markdown"},{"metadata":{"_cell_guid":"395c3884-d1c5-40b3-b6b8-a8a4a890ddc3","_uuid":"9b76de4adc2002e96e374b1ad89a9a9da3749309","collapsed":true},"source":"df_train_merged = df_train_merged[pd.notnull(df_train_merged['msno'])]\ndf_test_merged = df_test_merged[pd.notnull(df_test_merged['msno'])]","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"7983d132-6c66-4a99-a5e5-84c33fdf1d3e","_uuid":"4224ec3349f8fbd54b3d33c085d52977cedeef04"},"source":"Now let's check the length again:","cell_type":"markdown"},{"metadata":{"_cell_guid":"a6d3c2d5-3a1e-4730-a80c-bcacb1838adc","_uuid":"278d855c5dba954a59f939135c14faa85663a194","collapsed":true},"source":"print(len(df_train))\nprint(len(df_train_merged))\n\nprint(len(df_test))\nprint(len(df_test_merged))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"8f528e69-ace3-479d-b4ea-f7f4b71ba5ce","_uuid":"951bfbbd3deefdee81a1e91f666b3315c67f83d3"},"source":"## Saving **target** and **id** columns separately\nWhy? Only then can both the dataframes beconcatenated to perform encoding!\n\nThis is important. Because when train and test data are encoded separately there is a high possibility of variables getting encoded differently. \n\nConsider the following case where a column has three distinct categorical variables (A, B, C) to be encoded in both the train and test data. While encoding they will be converted to numerical form (1, 2, 3). \n\nIn the train data, if 'A' is encountered first it is assigned 1. Then if 'B' is encountered next then it is assigned 2. Likewise 'C' is assigned 3. But in the test data if 'B' is encountered first  it is assigned 1.\n\nSo in order to avoid **misinterpretation** of original information. It is a good habit to concatenate both the train and test data, while using a separate column to distinguish the two.","cell_type":"markdown"},{"metadata":{"_cell_guid":"107682cd-c473-41e9-b553-e651cff91b25","_uuid":"5343cb30f51ea526c214ed1044a0a8130b326a9a","collapsed":true},"source":"df_test_merged.columns","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"d6f566aa-171b-4f66-87b7-58623c2e67b9","_uuid":"3cb438d89d272f7800ac664980dc312c73fa4e62","collapsed":true},"source":"df_train_merged.columns","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"db471668-968f-465f-8600-d61c71ecb7fb","_uuid":"f3733e2efc621a4f73ac3f20397bd307ed916d56"},"source":"Saving the **id** column from test data and **target** column from train data separately; and deleting those respective columns from the dataframes.","cell_type":"markdown"},{"metadata":{"_cell_guid":"569cb0a3-3503-447a-9b7b-a18889a40261","_uuid":"38080e41cc92a36b116480be322972a6308951f5","collapsed":true},"source":"#--- before that save unique columns in train and test set separately ---\ndf_train_target = df_train_merged['target'].astype(np.int8)\ndf_test_id = df_test_merged['id']\n\n#--- now dropping those columns from respective dfs ---\ndf_train_merged.drop('target', axis=1, inplace=True)\ndf_test_merged.drop('id', axis=1, inplace=True)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"035fab27-3e45-4701-b6e3-b7e51c647d71","_uuid":"192bb8fbadeacb4da56ed4b28aba8e840f6be8de"},"source":"Appending another column **is_train** to distinguish between train and test data:","cell_type":"markdown"},{"metadata":{"_cell_guid":"8020eede-39db-4dc2-9de0-c68b04a459b7","_uuid":"6cf3cf49babd1a2f8c4344f20431e1924d7b2209","collapsed":true},"source":"df_train_merged['is_train'] = 1\ndf_test_merged['is_train'] = 0","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"9f20ae11-62a5-441a-b69b-3279d92ff391","_uuid":"92aaf7c95bf70176517bc71cd5eaaad42d04589c"},"source":"# Handling Missing Values\nHandling missing values in an elegant way always boosts the prediction of any algorithm. \n\nFirst we will see which columns have missing values. Later on we will see how to impute them.","cell_type":"markdown"},{"metadata":{"_cell_guid":"f8863905-2699-4e4a-a3a8-8cb4ccb481e3","_uuid":"2cef86f70734fb23121212621db863bf71b8e3f1","collapsed":true},"source":"cols_missing_val_train = df_train_merged.columns[df_train_merged.isnull().any()].tolist()\nprint(cols_missing_val_train)\n\ncols_missing_val_test = df_test_merged.columns[df_test_merged.isnull().any()].tolist()\nprint(cols_missing_val_test)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"804f084c-ac4f-47f6-92c7-090d4070a5a8","_uuid":"dc858b0e5e02824cd41f7caa9d8962a0da34077b"},"source":"We see that the same column have missing values in both the train and test dataset.","cell_type":"markdown"},{"metadata":{"_cell_guid":"e11b9ec8-d6fd-4b8f-9847-859c684c2cce","_uuid":"320a7197e8b54f0f26a2fbcea265291c184bb203"},"source":"## Visualizations","cell_type":"markdown"},{"metadata":{"_cell_guid":"8a903005-459f-4b62-ab23-f8e4d7f1230d","_uuid":"8cbe19ed0382920712a8bfed3f34b361489bd29f","collapsed":true},"source":"msno.bar(df_train_merged[cols_missing_val_train],figsize=(20,8),color=\"#32885e\",fontsize=18,labels=True,)\n\nmsno.bar(df_test_merged[cols_missing_val_test],figsize=(20,8),color=\"#32885e\",fontsize=18,labels=True,)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"1f337a10-db55-41d3-b0d4-af06d2eb15bc","_uuid":"d7d6847f379eb95701e2fdfdf371e7ad9775f32e","collapsed":true},"source":"msno.matrix(df_train_merged[cols_missing_val_train],width_ratios=(10,1),\\\n            figsize=(20,8),color=(0.2,0.2,0.2),fontsize=18,sparkline=True,labels=True)\n\nmsno.matrix(df_test_merged[cols_missing_val_test],width_ratios=(10,1),\\\n            figsize=(20,8),color=(0.2,0.2,0.2),fontsize=18,sparkline=True,labels=True)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"6b261c8c-6792-4f2b-a9ab-33077df03f0a","_uuid":"c7d6483014d8abd01446a52bf964a4184a298176"},"source":"Columns **gender**, **composer** and **lyricist** have high number of missing values.","cell_type":"markdown"},{"metadata":{"_cell_guid":"bd845313-0eef-4172-85fd-60a902e961f7","_uuid":"fb6e01d51045bd27d6a99c1509cfb2a5d8adb060"},"source":"## Imputing Missing Values\n\nIn order to impute missing values, the other unique values in the respective columns must be known as well.\n\nWe will impute missing values for each column individually together for train and test data.","cell_type":"markdown"},{"metadata":{"_cell_guid":"4a521bd5-9f96-420d-9025-1fa8dcb661c2","_uuid":"00a8e1f67f54992deb5eb4b0a8bcb2bec669b2b4"},"source":"### **source_system_tab**","cell_type":"markdown"},{"metadata":{"_cell_guid":"641cf02a-652e-4c6d-872b-dca3b93c4dcd","_uuid":"ff27bdd89056c51c865c07522b37606b8ed50d4f","collapsed":true},"source":"print(df_train_merged.source_system_tab.nunique())\nprint(df_test_merged.source_system_tab.nunique())\n\nprint(df_train_merged.source_system_tab.unique())\nprint(df_test_merged.source_system_tab.unique())","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"9c3c073f-fb20-4982-bc8f-ff0c4deb8e42","_uuid":"5566db9dc43aaba58ddc0d64afa266f55fa7041f"},"source":"The unique values and their count are the same across train and test data. Hence we will impute the missing value with a common string:","cell_type":"markdown"},{"metadata":{"_cell_guid":"96961393-531b-4a4a-a9df-ccc5e59f282c","_uuid":"b43f0e68bd818522858a27b1ba804dfc2801035a","collapsed":true},"source":"df_train_merged.source_system_tab = df_train_merged.source_system_tab.fillna('others')\ndf_test_merged.source_system_tab = df_test_merged.source_system_tab.fillna('others')","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"956489a4-599a-4b79-a18a-8f00ed7d4494","_uuid":"e6241fd7b3adef777720bdd1c32a6936112ad73d"},"source":"### **source_screen_name**","cell_type":"markdown"},{"metadata":{"_cell_guid":"7de456d9-e738-4d90-b033-4b937a5a99f1","_uuid":"355889e39dd49dd82c0b5c223a61f332d92cbed0","collapsed":true},"source":"print(df_train_merged.source_screen_name.nunique())\nprint(df_test_merged.source_screen_name.nunique())\n\nprint(df_train_merged.source_screen_name.unique())\nprint(df_test_merged.source_screen_name.unique())","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"838ea159-6d52-4580-b26a-8ef8419ff0c8","_uuid":"c0b86459188199a2d7b747f9e498829b45badd95"},"source":"Interesting! We can see a change in the number of unique values in this column.","cell_type":"markdown"},{"metadata":{"_cell_guid":"d2115a84-e1ba-4bee-aebf-2087fa968bd7","_uuid":"16cbb8a7f8859eda5c37e9c8834a04e313561e26","collapsed":true},"source":"source_screen_name_uniq_train = list(df_train_merged.source_screen_name.unique())\nsource_screen_name_uniq_test = list(df_test_merged.source_screen_name.unique())","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"ede351ec-8693-4c40-8e81-38fd2abfcc15","_uuid":"ec3eed1b5ac554819d6ab6cadfc2c71607ff92fe","collapsed":true},"source":"#--- common values ---\nprint(set(source_screen_name_uniq_train) & set(source_screen_name_uniq_test))\n\n#--- different values ---\nprint(set(source_screen_name_uniq_train) ^ set(source_screen_name_uniq_test))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"ae0b6df4-0222-496c-99c1-01c2ae9ee595","_uuid":"be05949712c9eabfa808672c1744ca3dce0d407f"},"source":"The values **People local** and **People global** are new in test set.\n\nThe missing values in train and test set can be replaced with **other_sources**. The values of **People local** and **People global** in test data can also be replaced with this because there is not a single occurrence in the train data.","cell_type":"markdown"},{"metadata":{"_cell_guid":"4a770c6e-820f-4928-ba7a-ad01626eb3cc","_uuid":"a370d496257133a0002b9df3e45c0642668b9a28","collapsed":true},"source":"df_train_merged.source_screen_name = df_train_merged.source_screen_name.fillna('other_sources')\ndf_test_merged.source_screen_name = df_test_merged.source_screen_name.fillna('other_sources')\n\ndf_test_merged['source_screen_name'] = df_test_merged['source_screen_name'].replace(['People local', 'People global'], 'other_sources')","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"ce6abfce-dbcf-4abf-a335-aadb41e2a51d","_uuid":"10de5bbafe93344a632acfa6874e7d8a88663261"},"source":"### **source_type**","cell_type":"markdown"},{"metadata":{"_cell_guid":"2af9a6bf-0a3c-4215-a404-9bbacc99da89","_uuid":"ba3cdcc8f81da3fa237bfda75e005904ce3a92d8","collapsed":true},"source":"print(df_train_merged.source_type.nunique())\nprint(df_test_merged.source_type.nunique())\n\nprint(df_train_merged.source_type.unique())\nprint(df_test_merged.source_type.unique())","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"2696724b-db88-4ccb-ac3c-dc22ddd9a4d8","_uuid":"c8e957d5574122d5b56498f14d58a2d0d4e931ef","collapsed":true},"source":"#--- Check whether odd elements are present ---\nprint(set(list(df_train_merged.source_type.unique())) ^ set(list(df_test_merged.source_type.unique())))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"a7efd656-d3a1-4693-b7c5-60ddbaab0c16","_uuid":"2fbb6fbe31bb285a0ae7ad51ecad607a5ff7472a"},"source":"We don't have any. So we can simply impute missing values with a common string.","cell_type":"markdown"},{"metadata":{"_cell_guid":"57e06ee1-494e-42ba-a51d-2aa8bf964728","_uuid":"848b8af6d68fbe7c2faa9a022cc83edc184d9a64","collapsed":true},"source":"df_train_merged.source_type = df_train_merged.source_type.fillna('other_types')\ndf_test_merged.source_type = df_test_merged.source_type.fillna('other_types')","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"c7bbf1fd-018b-470e-b1e0-24532886ca3a","_uuid":"009fc919690967912045ac6f96a9488cd9c82aa9"},"source":"### **gender**","cell_type":"markdown"},{"metadata":{"_cell_guid":"c2437203-cffc-410e-bd62-60422e35f2dd","_uuid":"c0462800705de6fa33e295d9ce0ddf6de1686a25","collapsed":true},"source":"print(df_train_merged.gender.unique())\nprint(df_test_merged.gender.unique())","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"47cdc4b0-303e-472b-88b1-7db0480dd51e","_uuid":"0a89f2d71c473ed56b43aef05d1b43c0eed7c9e5"},"source":"Imputing missing value with common string:","cell_type":"markdown"},{"metadata":{"_cell_guid":"aa27f2b5-4a9b-43d3-84d6-79df989fc2e8","_uuid":"05512edc904d845e9d46742083b25b7c6cf803b6","collapsed":true},"source":"df_test_merged.gender = df_test_merged.gender.fillna('unknown')\ndf_train_merged.gender = df_train_merged.gender.fillna('unknown')","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"835ac503-1360-4a95-85b1-3989c17a6ba1","_uuid":"f37aaa6cce8ac65aecc45757abee6b0f434a874c"},"source":"In this case the missing values can also be randomly chosen between **male** and **female**","cell_type":"markdown"},{"metadata":{"_cell_guid":"b8a0e040-951c-4a86-b71b-4602be538c1d","_uuid":"46b9185a904ff5748894bb67e3bfd9af64b44a63"},"source":"### **song_length**\nImputing missing values with the **mean** of existing values","cell_type":"markdown"},{"metadata":{"_cell_guid":"bf44e748-00d7-4fa2-b32b-4bc1dfceb9d3","_uuid":"d5ee99bc676e545eb14baec8ad87f7e4daff51a8","collapsed":true},"source":"df_train_merged['song_length'].fillna((df_train_merged['song_length'].mean()), inplace=True)\ndf_test_merged['song_length'].fillna((df_test_merged['song_length'].mean()), inplace=True)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"b237b432-594d-40a8-aa0c-9e0cb047cc9d","_uuid":"658283a33d6d8f50b3206f17d0738a0a622b6e20"},"source":"### **language**","cell_type":"markdown"},{"metadata":{"_cell_guid":"47b2b36f-8dec-4ea9-a85a-b7af098db246","_uuid":"cd3c08de94fb326dc96d571467a53ee220a1d53b","collapsed":true},"source":"print(df_train_merged.language.nunique())\nprint(df_test_merged.language.nunique())\n\nprint(df_train_merged.language.unique())\nprint(df_test_merged.language.unique())","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"792bcef2-a246-4e82-8725-b4afb14275bb","_uuid":"743f6ff07dd71db06fdb916681d8bf8a15d6fdd2"},"source":"Imputing nan with value 0","cell_type":"markdown"},{"metadata":{"_cell_guid":"b35e6c29-f4da-419a-9afe-a5c877304ed8","_uuid":"f2b2afa007bb5a683ac4552ebfb6c0e956f3d895","collapsed":true},"source":"df_train_merged.language = df_train_merged.language.fillna(0)\ndf_test_merged.language = df_test_merged.language.fillna(0)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"849fa4ab-9894-4831-bbbd-36680afced4e","_uuid":"755f75bb3e96b89ded81a1e5d91eea2d67e194fa"},"source":"### **genre_ids**","cell_type":"markdown"},{"metadata":{"_cell_guid":"240afabb-b7dc-4d54-b6ed-cbb7ba71cec0","_uuid":"36d220f8d2504f93021c6d71c8916092eecd18ab","collapsed":true},"source":"print(df_train_merged.genre_ids.nunique())\nprint(df_test_merged.genre_ids.nunique())","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"f2d4d918-819d-4223-bc9a-906c7f45a53e","_uuid":"e28ab29418c24d7bd022ddc19e46114e3868b453","collapsed":true},"source":"print(df_train_merged.genre_ids.unique())","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"d6390474-bbe1-460e-9731-91bb090ca0e2","_uuid":"860a0f3a5b9b78d43bbf60148577cdb5540d0092"},"source":"### Inferences:\n* Upon observing the values in the **genre_ids** column below, we see a combination of singlular and mixed genres..We need to know how many **unique individual ** genres are present.\n* Also for rows with more than one genre, they are separated using `|`. The following code snippet obtains unique individual genre_ids present.\n* We can also create a new column mentioning the number of genre_ids used in that particular song","cell_type":"markdown"},{"metadata":{"_cell_guid":"f5d0cc03-f480-419d-9b4a-e90202584cc5","_uuid":"0fbf4308d1e4bf4bfaecf874979ab3f2733feb7b","collapsed":true},"source":"df_train_merged['genre_ids']\n\nj = 'Mary has a lamb'\nj.count('a')","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"fac29d57-9f2e-44a2-9c4a-e01721345c27","_uuid":"bccadf1abd95c11e006c6bd0ca5372fb974d145c","collapsed":true},"source":"print(len(df_train_merged.genre_ids.unique()))\nprint(len(df_train_merged.genre_ids))\n\n#--- List containing unique genre_ids from column inclusive of combinations ---\ngenre = df_train_merged.genre_ids.unique().tolist()\n\n#--- List containing unique individual genre_ids ---\ngenre_new = []\n\nfor i in range(len(genre)):\n    if (type(genre[i]) == str):      #--- to avoid the nan type---\n        lw = genre[i].split('|')\n        #lw = re.findall(r\"[^|]+\", genre[i])\n        for j in range(len(lw)):\n            genre_new.append(lw[j])\n            \nprint(len(genre_new))\nprint(len(set(genre_new)))\n \nletter_counts = Counter(genre_new)\ndfoo = pd.DataFrame.from_dict(letter_counts, orient='index')\ndfoo.plot(kind='bar', figsize=(30,15), title = 'Distribution of frequency of genre_ids')","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"b0afe7e7-30e0-46be-914c-c2ed54bdd7a8","_uuid":"51e676e7be251ef60b4adb5e2a1342dd7264fc8d"},"source":"Genre_ids whose frequency of occurence is equal to or more than 10:","cell_type":"markdown"},{"metadata":{"_cell_guid":"7af316fb-bba5-4737-b950-4cb6c67e4fe3","_uuid":"bfd10aaad33964ed8cc0d9e8903b87454a8e95c6","collapsed":true},"source":"[k for k, v in letter_counts.items() if v >= 10]","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"fe5e1619-4207-454f-aaf6-aa348e36646e","_uuid":"375d11513131dd79bb07008e83be2fd5a8f7df2a"},"source":"We see something strange here:\n* The number of unique elements vary to a large extent in the train and test data.\n* The genre_ids appear be mostly a blend of two or more genres.\n\nWe have our task cut out here. We cannot consider a genre like '465|2213|2215' to be different but a combination of '465' , '2213' and 2215'. \n\nBefore proceeding on imputing missing values, we need to know how many such **individual** genre_ids are present.","cell_type":"markdown"},{"metadata":{"_cell_guid":"9d5db8ae-686f-4a46-83c5-27f0957182ff","_uuid":"8a911fccd32ce1951e1a6b8f3ff21e31b7a59a2e","collapsed":true},"source":"#--- Values in this column are of string type ---\ndf_train_merged.genre_ids.dtype","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"15258d31-d35a-4d7e-ad73-77ae092b4ba3","_uuid":"537ecfc2744fe38cd0b7f0fbd7dc811f75ea76b3","collapsed":true},"source":"genre = df_train_merged.genre_ids.unique().tolist()\n\ngenre_new = []\nfor i in range(len(genre)):\n    if (type(genre[i]) == str):\n        lw = genre[i].split('|')\n        #lw = re.findall(r\"[^|]+\", genre[i])\n        for j in range(len(lw)):\n            genre_new.append(lw[j])\n\nprint('Number of unique genre ids in train set: ',len(genre))\n\ngenre_new = set(genre_new)\nprint('Number of unique genre ids after splitting them individually: ', len(genre_new))\n\nprint('Genre ids used in combination with other genres: ', len(set(genre) & set(genre_new)))\n#print('Genre ids NOT present in both train set OR after splitting: ', len(set(genre) ^ set(genre_new)))\n\nprint('Genre ids not used in combination with other genres', len(genre_new - (set(genre) & set(genre_new))))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"d149244b-5cc8-4bfe-8ff6-f1fa7a09904c","_uuid":"8b554e56284c271010e26fe24e53a3bab146285c"},"source":"Performing the same for the test data as well:","cell_type":"markdown"},{"metadata":{"_cell_guid":"ccf374d6-9acf-4c7b-bacb-5c3071ecbb20","_uuid":"347a6308c6276b5b481a8382748a95cf3e29b3f9","collapsed":true},"source":"genre_test = df_test_merged.genre_ids.unique().tolist()\n\ngenre_test_new = []\nfor i in range(len(genre_test)):\n    if (type(genre_test[i]) == str):\n        lw = genre_test[i].split('|')\n        #lw = re.findall(r\"[^|]+\", genre[i])\n        for j in range(len(lw)):\n            genre_test_new.append(lw[j])\n\nprint('Number of unique genre ids in train set: ',len(genre_test))\n\ngenre_test_new = set(genre_test_new)\nprint('Number of unique genre ids after splitting them individually: ', len(genre_test_new))\n\nprint('Genre ids used in combination with other genres: ', len(set(genre_test) & set(genre_test_new)))\n#print('Genre ids NOT present in both train set OR after splitting: ', len(set(genre) ^ set(genre_new)))\n\nprint('Genre ids not used in combination with other genres', len(genre_test_new - (set(genre_test) & set(genre_test_new))))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"7ec1175a-205a-48b1-8cbb-9f7e0ee76066","_uuid":"78b41e0083b0c4df3159575810276781b2b0bc35","collapsed":true},"source":"#--- combination of genre_ids in train and test ---\nprint('Genre_ids combinations present in both train and test set: ', len(set(genre_test) & set(genre)))\n\nprint('Genre_ids combinations present in test but not in train set: ', len(set(genre_test) - (set(genre_test) & set(genre))))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"b29cc7b9-fee2-4add-964c-61f6786ea862","_uuid":"089bdc22cb6977416268dafaa49074c08307044d","collapsed":true},"source":"#--- Intersection between unique genre_ids in train and test set ---\nprint('Genre_ids present in both train and test set: ', len(set(genre_test_new) & set(genre_new)))\n\nprint('New genre_ids present in both train or test set: ', len(set(genre_test_new) ^ set(genre_new)))\n\nprint('Total number of unique genre_ids present in both train and test set: ', len(set(genre_test_new) | set(genre_new)))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"d86acf72-56c9-473f-a985-65476f106bca","_uuid":"7a94198906cef685ae79a12721915e112acfdb84"},"source":"","cell_type":"markdown"},{"metadata":{"_cell_guid":"0c77c88d-21f2-492e-a843-7b49e20cdd0e","_uuid":"c7b538abdf4fb10c289e39bb1d8d2a5877a0742b"},"source":"Now since we have the count of all possible genre_ids we can go ahead with imputing missing values:\n* Here we can impute missing values based on the **song_id** if present in another row \n* If the above phenomenon does not persist, then we can create a new value for all missing ones.\n\nThe following code snippet checks whether same song_id of genre_ids with missing values are present elsewhere.","cell_type":"markdown"},{"metadata":{"_cell_guid":"40fe2e42-15e9-466e-aede-b3bd08bb63bf","_uuid":"1617c52a01d7452b29d4fb31c1c3e83b43ae2fea","collapsed":true},"source":"print('rows without Nan values:', df_train_merged.genre_ids.count())      \nprint('rows with Nan values: ', len(df_train_merged) - df_train_merged.genre_ids.count() )    \n\ngenre = df_train_merged[['song_id', 'genre_ids']]          #--- df containing all song id and artists ---\ngenre_wo_nan = genre.drop_duplicates().ix[~df_train_merged['genre_ids'].isnull(), :]       #--- df with unique song id and artist name where artist name is not nana\ngenre_w_nan = genre.drop_duplicates().ix[df_train_merged['genre_ids'].isnull(), :]          #--- df with unique song id and artist name where artist name is nan\n\n#--- if it is zero means there are no intersections between \nprint('Whether intersections are present or not : ',np.intersect1d(genre_wo_nan['song_id'], genre_w_nan['song_id']) )","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"a3954945-c20b-42b8-be21-f76ce20f139c","_uuid":"94642973a0fb5b355e90fcb629a50764d700af13"},"source":"Working out the same for the test set as well: (commented because it has no intersections and to save kernel run time)","cell_type":"markdown"},{"metadata":{"_cell_guid":"cce4ea6c-eeb0-4516-9dda-3021990309c0","_uuid":"262df0ecd6bd4db9af7d073cdd61f0931c5e2a92","collapsed":true},"source":"''' \nprint('rows without Nan values:', df_test_merged.genre_ids.count())      \nprint('rows with Nan values: ', len(df_test_merged) - df_test_merged.genre_ids.count() )    \n\ngenre = df_test_merged[['song_id', 'genre_ids']]          #--- df containing all song id and artists ---\ngenre_wo_nan = genre.drop_duplicates().ix[~df_test_merged['genre_ids'].isnull(), :]       #--- df with unique song id and artist name where artist name is not nana\ngenre_w_nan = genre.drop_duplicates().ix[df_test_merged['genre_ids'].isnull(), :]          #--- df with unique song id and artist name where artist name is nan\n\n#--- if it is zero means there are no intersections between \nprint('Whether intersections are present or not : ',np.intersect1d(genre_wo_nan['song_id'], genre_w_nan['song_id']) )\n\n'''","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"ec2c33ad-a767-4380-971a-3c5f72745867","_uuid":"0f1a1f2ef647a9f84592a881c0f8a3ea72fb7ad6"},"source":"The missing values in **genre_ids** column of both train and test set can be imputed using a common string:","cell_type":"markdown"},{"metadata":{"_cell_guid":"95a0b545-6146-4551-9888-6615c4d22810","_uuid":"2012bb264a21413a9474d3f5e3a5c38eb02138f0","collapsed":true},"source":"df_train_merged.genre_ids = df_train_merged.genre_ids.fillna('no_genre_id')\ndf_test_merged.genre_ids = df_test_merged.genre_ids.fillna('no_genre_id')","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"461e860f-64e6-4909-a338-eb417159b65d","_uuid":"a82820f109686929acd3ec099a32a29b2b90a198"},"source":"### **composer**","cell_type":"markdown"},{"metadata":{"_cell_guid":"df2f39e2-d23e-4c12-86c7-75b3108cfd36","_uuid":"3552e354f07ab2da5a2478f43be2d7dae4618f70","collapsed":true},"source":"print(df_train_merged.composer.nunique())\nprint(df_test_merged.composer.nunique())","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"861b042e-574b-4eee-ae55-cf43d24cfd7a","_uuid":"4a7468c1d05d0f00041ab735b1029ce43e6976b6","collapsed":true},"source":"print(df_train_merged.composer.unique())","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"39f37318-c615-4972-b5fb-d13370009dc2","_uuid":"d845df0b799dc9bfa410a11ed62298c6e0fd9d93"},"source":"We can see something similar to what we ust saw with column **genre_ids**.\n\nBefore proceeding on imputing missing values, we need to know how many such **individual** composers are present.","cell_type":"markdown"},{"metadata":{"_cell_guid":"c4afd0ec-792d-4d62-a543-b9555dbc4aa8","_uuid":"ffe012e8b762f3cdcee1692dbd91009183e8a96e","collapsed":true},"source":"composer = df_train_merged.composer.unique().tolist()\n\ncomposer_new = []\nfor i in range(len(composer)):\n    if (type(composer[i]) == str):\n        lw = composer[i].split('|')\n        #lw = re.findall(r\"[^|]+\", genre[i])\n        for j in range(len(lw)):\n            composer_new.append(lw[j])\n\nprint('Number of unique composers in train set: ',len(composer))\n\ncomposer_new = set(composer_new)\nprint('Number of unique composers after splitting them individually: ', len(composer_new))\n\nprint('composers in combination with other composers: ', len(set(composer) & set(composer_new)))\n#print('Genre ids NOT present in both train set OR after splitting: ', len(set(genre) ^ set(genre_new)))\n\nprint('composers not in combination with other composers', len(composer_new - (set(composer) & set(composer_new))))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"92ade138-cb86-43a7-8381-274a262d7c9d","_uuid":"3c0c5941517f0fee176595bf516d431bc0717997"},"source":"For test data:","cell_type":"markdown"},{"metadata":{"_cell_guid":"a9c06886-655b-4080-a289-99f410a9e8f8","_uuid":"0d51743c8e4389f5b94dc22f9e82245b69f2c20f","collapsed":true},"source":"composer_test = df_test_merged.composer.unique().tolist()\n\ncomposer_test_new = []\nfor i in range(len(composer_test)):\n    if (type(composer_test[i]) == str):\n        lw = composer_test[i].split('|')\n        #lw = re.findall(r\"[^|]+\", genre[i])\n        for j in range(len(lw)):\n            composer_test_new.append(lw[j])\n\nprint('Number of unique composers in train set: ',len(composer_test))\n\ncomposer_test_new = set(composer_test_new)\nprint('Number of unique composers after splitting them individually: ', len(composer_test_new))\n\nprint('composers used in combination with other composers: ', len(set(composer_test) & set(composer_test_new)))\n#print('Genre ids NOT present in both train set OR after splitting: ', len(set(genre) ^ set(genre_new)))\n\nprint('composers not used in combination with other composers', len(composer_test_new - (set(composer_test) & set(composer_test_new))))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"42242efd-d691-4e5b-bbbd-e215c87b0608","_uuid":"d573c38650cec4f3761f7fb548d8695ebc2a20f0","collapsed":true},"source":"#--- Intersection between unique composers in train and test set ---\nprint('composers present in both train and test set: ', len(set(composer_test_new) & set(composer_new)))\n\nprint('New composers present in both train or test set: ', len(set(composer_test_new) ^ set(composer_new)))\n\nprint('Total number of unique composers present in both train and test set: ', len(set(composer_test_new) | set(composer_new)))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"dd80db4f-a921-4df9-b8b3-9e3f3158228a","_uuid":"6b7c40fa1634ccb2d4bb3fa6227994f1905bf20f"},"source":"Since we have the count of composers let us fill the missing values:","cell_type":"markdown"},{"metadata":{"_cell_guid":"72bf74e2-8368-4254-98c3-61ebc467730f","_uuid":"c073557d9ee78d3d783461948931cfcbaaca0047","collapsed":true},"source":"print('rows without Nan values:', df_train_merged.composer.count())      \nprint('rows with Nan values: ', len(df_train_merged) - df_train_merged.composer.count() )    \n\ncomposer = df_train_merged[['song_id', 'composer']]          #--- df containing all song id and artists ---\ncomposer_wo_nan = composer.drop_duplicates().ix[~df_train_merged['composer'].isnull(), :]       #--- df with unique song id and artist name where artist name is not nana\ncomposer_w_nan = composer.drop_duplicates().ix[df_train_merged['composer'].isnull(), :]          #--- df with unique song id and artist name where artist name is nan\n\n#--- if it is zero means there are no intersections between \nprint('Whether intersections are present or not : ',np.intersect1d(composer_wo_nan['song_id'], composer_w_nan['song_id']) )","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"af0ffeee-d519-41cb-83c7-b324fa972835","_uuid":"5449bc33316a6c1331add1e7a146a50e14e6211a"},"source":"Here also we do not have any intersections, hence we can impute with a common string:","cell_type":"markdown"},{"metadata":{"_cell_guid":"396a2992-1651-40b5-9fd2-9e9c0c160806","_uuid":"570f85839b6d4fb1f646368f3fb3470189d6b388","collapsed":true},"source":"df_train_merged.composer = df_train_merged.composer.fillna('no_composer')\ndf_test_merged.composer = df_test_merged.composer.fillna('no_composer')","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"b495a7da-83b3-4656-a88c-022378ed3752","_uuid":"8c4ea39ef94f31e502a46120ccf493aac470a310"},"source":"### **artist_name**","cell_type":"markdown"},{"metadata":{"_cell_guid":"f6a26087-5aed-44da-880f-27150bf835e3","_uuid":"2768254bf87469fb72d467fbfa4c89add4b8895e","collapsed":true},"source":"print(df_train_merged.artist_name.nunique())\nprint(df_test_merged.artist_name.nunique())","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"026588e7-62e2-4bb3-8c5c-68aa5fa4e4b2","_uuid":"793632617c919b431bb9abcb44687b9f8b5ad5c1"},"source":"There are no intersections present here either, hence we will impute missing values with a common string.","cell_type":"markdown"},{"metadata":{"_cell_guid":"93652dec-eb36-4129-af90-e2d90fdc2c85","_uuid":"cdeb6d11cefddd1a2e754feafc40edb157b868e5","collapsed":true},"source":"df_train_merged.artist_name = df_train_merged.artist_name.fillna('no_artist')\ndf_test_merged.artist_name = df_test_merged.artist_name.fillna('no_artist')","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"fe6ca243-766a-466f-a997-f9c47b2e2127","_uuid":"5a02f653868eb141c911bc7db7b3d96016da4135"},"source":"### **lyricist**","cell_type":"markdown"},{"metadata":{"_cell_guid":"79979ee1-73d9-47b3-bb37-2b10639a8b45","_uuid":"c85ebbdffc988bfcfd0b158707979fe1de061d9b","collapsed":true},"source":"print(df_train_merged.lyricist.nunique())\nprint(df_test_merged.lyricist.nunique())","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"31fe926f-2e04-4564-a3f5-90f4a92ed142","_uuid":"d2d814940bcd66ddf3f1020c166ed78a11c61f91","collapsed":true},"source":"print(df_train_merged.lyricist.unique())","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"410a6ba4-2a6a-44b7-bd0b-13d642698761","_uuid":"c217cbfa4fe8711777c6f47722399dcff0ac4fbc"},"source":"In this column we too have the same occurrence of multiple lyricists.","cell_type":"markdown"},{"metadata":{"_cell_guid":"243f5321-ec8a-43cd-b027-8e19401c36a8","_uuid":"cf65b46af60999eb533fa13fdd1a345160bcfdb0","collapsed":true},"source":"lyricist = df_train_merged.lyricist.unique().tolist()\n\nlyricist_new = []\nfor i in range(len(lyricist)):\n    if (type(lyricist[i]) == str):\n        lw = lyricist[i].split('|')\n        #lw = re.findall(r\"[^|]+\", genre[i])\n        for j in range(len(lw)):\n            lyricist_new.append(lw[j])\n\nprint('Number of unique lyricists in train set: ',len(lyricist))\n\nlyricist_new = set(lyricist_new)\nprint('Number of unique lyricists after splitting them individually: ', len(lyricist_new))\n\nprint('lyricists in combination with other lyricists: ', len(set(lyricist) & set(lyricist_new)))\n#print('Genre ids NOT present in both train set OR after splitting: ', len(set(genre) ^ set(genre_new)))\n\nprint('lyricists not in combination with other lyricists', len(lyricist_new - (set(lyricist) & set(lyricist_new))))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"5484b9a3-dba8-44ff-89cb-add645ca48ed","_uuid":"0d8112d433a4e48c7b5ec696702b1e4ff8014a8b"},"source":"For the test data:","cell_type":"markdown"},{"metadata":{"_cell_guid":"6c2b728e-db18-46fe-94a9-7981b3a857e3","_uuid":"84c93189c8bb0af0771e2c33bdda1c4f56821615","collapsed":true},"source":"lyricist_test = df_test_merged.lyricist.unique().tolist()\n\nlyricist_test_new = []\nfor i in range(len(lyricist_test)):\n    if (type(lyricist_test[i]) == str):\n        lw = lyricist_test[i].split('|')\n        #lw = re.findall(r\"[^|]+\", genre[i])\n        for j in range(len(lw)):\n            lyricist_test_new.append(lw[j])\n\nprint('Number of unique lyricists in _test set: ',len(lyricist_test))\n\nlyricist_test_new = set(lyricist_test_new)\nprint('Number of unique lyricists after splitting them individually: ', len(lyricist_test_new))\n\nprint('lyricists in combination with other lyricists: ', len(set(lyricist_test) & set(lyricist_test_new)))\n#print('Genre ids NOT present in both train set OR after splitting: ', len(set(genre) ^ set(genre_new)))\n\nprint('lyricists not in combination with other lyricists', len(lyricist_test_new - (set(lyricist_test) & set(lyricist_test_new))))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"3c2bd623-20e6-4d7d-9e00-13a17915e876","_uuid":"e5564d551647ec7895e3a615b66e6b4cf439bf7d","collapsed":true},"source":"#--- Intersection between unique lyricists in train and test set ---\nprint('lyricists present in both train and test set: ', len(set(lyricist_test_new) & set(lyricist_new)))\n\nprint('New lyricists present in both train or test set: ', len(set(lyricist_test_new) ^ set(lyricist_new)))\n\nprint('Total number of unique lyricists present in both train and test set: ', len(set(lyricist_test_new) | set(lyricist_new)))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"3220ccea-f183-46f2-a880-a45198c172bc","_uuid":"2b5ff9117de30a16b22563045c72042a40324148"},"source":"Now that the count is obtained let us see how to impute missing values:","cell_type":"markdown"},{"metadata":{"_cell_guid":"abd28b91-495d-411d-a328-366e3ff1a002","_uuid":"2f94efc8d3e29be1cd0d01382886b679c23cf137","collapsed":true},"source":"print('rows without Nan values:', df_train_merged.lyricist.count())      \nprint('rows with Nan values: ', len(df_train_merged) - df_train_merged.lyricist.count() )    \n\nlyricist = df_train_merged[['song_id', 'lyricist']]          #--- df containing all song id and artists ---\nlyricist_wo_nan = lyricist.drop_duplicates().ix[~df_train_merged['lyricist'].isnull(), :]       #--- df with unique song id and artist name where artist name is not nana\nlyricist_w_nan = lyricist.drop_duplicates().ix[df_train_merged['lyricist'].isnull(), :]          #--- df with unique song id and artist name where artist name is nan\n\n#--- if it is zero means there are no intersections between \nprint('Whether intersections are present or not : ',np.intersect1d(lyricist_wo_nan['song_id'], lyricist_w_nan['song_id']) )","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"13a61d63-a8cd-4ecf-a260-99ccea72405b","_uuid":"7beea78b5886b9e77557c4e5640a9a4f47982399"},"source":"Since there are no intersections as usual, we will impute missing values with a common string:","cell_type":"markdown"},{"metadata":{"_cell_guid":"dc279d77-e114-49b0-b423-f13785cc10d2","_uuid":"24c4e1874dd877fb4a75769694d665caf94473e6","collapsed":true},"source":"df_train_merged.lyricist = df_train_merged.lyricist.fillna('no_lyricist')\ndf_test_merged.lyricist = df_test_merged.lyricist.fillna('no_lyricist')","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"8a733cec-878c-42a1-8392-4a7f131523bc","_uuid":"9f5e84fd1f4831156621a6ddbaafea0206c0ee53"},"source":"# Feature Engineering","cell_type":"markdown"},{"metadata":{"_cell_guid":"4bf39420-e91f-4024-8483-76effd277f36","_uuid":"29e9571e591df901b4e52a3cf3683219e96e52d5"},"source":"## Feature 1 : **genre_ids_total**\n\nThis column contains the number of different genres used in the song. This was created while analyzing the **genre_ids** column in both the test and train data set","cell_type":"markdown"},{"metadata":{"_cell_guid":"d99552bd-5c55-4cc7-9e35-aec6f34ad76f","_uuid":"b61e25accb4b73d4806350ce56bdbe1ebb3c29f6"},"source":"The following snippet:\n* puts 0 when string `no_genre_id` is encountered, which was filled to impute missing values.\n* otherwise the number of genres is summed up.","cell_type":"markdown"},{"metadata":{"_cell_guid":"8d6b3cd1-79f8-4050-8307-78e4cd613c9f","_uuid":"e8666dfa2de1be56e44da28ab958f9dc58b4cd61","collapsed":true},"source":"def genre_id_count(x):\n    if x == 'no_genre_id':\n        return 0\n    else:\n        return x.count('|') + 1\n\ndf_train_merged['genre_ids_count'] = df_train_merged['genre_ids'].apply(genre_id_count).astype(np.int8)\ndf_test_merged['genre_ids_count'] = df_test_merged['genre_ids'].apply(genre_id_count).astype(np.int8)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"98044c5c-6bcd-4987-90b6-344b70579535","_uuid":"5cac530161771a7cd8be9a473b9290d8c740b95d"},"source":"## Feature 2 : **lyricists_count**\nThis column reveals the number of lyricists for a particular song.\n\nUnlike the previous case where we had occurrences of `|`, here we have to deal with the following: `|`, `/`, `\\\\` `;`. \n\nTake a look below to see what I mean!\n\nOccurrences with `|`:\n* `'Andy Cato| Tom Findlay| Julie McAlpine'`\n* `'Max Martin| Shellback| Tiffany Amber'`\n\nOccurrences with `/` and/or `|`:\n* `'Korean Lyrics by Lee| Seu Ran (12.5%) Greg Paul Stephen Bonnick / Hayden Chapman / Jeremy Tyrone Jasper / Adrian McKinnon'`\n* `'Misfit / Karen Poole / Stuart Crichton'`\n\nOccurrences with `\\\\`:\n* `'張震嶽 Ayal Komod\\\\陳昱榕 E-SO\\\\周文傑 KENZY\\\\林睦淵 MUTA'`\n* `'黃煜俊\\\\黃揚哲'`\n\nOccurrences with `;`:\n* `'Hiroyuki Himeno;Zheng ShuFei;Ikoman'`\n\nTo make matters worse there are combinations of these as well! See below:\n* `'克麗絲叮(Christine Welch)/\"李惠群 Li| Hui-Qun\"/\"易家揚 Yi| Jia-Yang\"'`\n* `'CA: DAVID| MACK/ LOUIGUY、中文詞：小玉 林忠諭 '`\n* `'Yasunori| Kawauchi \\\\黃東焜'`\n\nSometimes you also encounter weird strings like:\n* `'Korean Lyrics by Lee| Ha Jin /Amber J. Liu / Gen Neo'`\n* `'Korean Lyrics by Lee| Chae Yoon / Teddy Riley / DOM / Richard Garcia / Dantae Johnson / Labyron “Miko” Walton'`\n* `'BoA (35%) / Harvey Mason Jr. (12.5%) / Mike Daley (17.5%) / Andrew Hey (17.5%) / Tiffany Fred (17.5%)'`\n* `'Korean Lyrics by Cho| Yun Kyoung / January 8th / Kim| Dong Hyun / Teddy Riley| DOM| Lee| Hyun Seung for (TRX) / J.SOL (Jason J Lopez) / Dantae Johnson'`\n* `'m-flo + Matt Cab for STAR BASE MUSIC'`\n* `'Koji Tamaki and Tetsuya Komuro'`","cell_type":"markdown"},{"metadata":{"_cell_guid":"8d99b3af-e787-4bc0-a017-ef345b388707","_uuid":"7afeddd51c68cbde4851e811cdb4da7b8e685b9d","collapsed":true},"source":"list(df_train_merged.lyricist.unique())","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"1f857a39-deca-414f-9735-dec3fa99af42","_uuid":"ed37a5b866854a6667d4593c5fbcd890343fdd32","collapsed":true},"source":"def lyricist_count(x):\n    if x == 'no_lyricist':\n        return 0\n    else:\n        return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n    return sum(map(x.count, ['|', '/', '\\\\', ';']))\n\ndf_train_merged['lyricists_count'] = df_train_merged['lyricist'].apply(lyricist_count).astype(np.int8)\ndf_test_merged['lyricists_count'] = df_test_merged['lyricist'].apply(lyricist_count).astype(np.int8)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"bebd3ffc-eaba-4bee-a76d-46ebabd8be6b","_uuid":"f5a591f77eaed0ed10189f3b8146c3c4765f77d8"},"source":"## Feature 3 : **composers_count**\n\nThis column contains the number of composers.","cell_type":"markdown"},{"metadata":{"_cell_guid":"11fa16e1-d89f-4f39-9fe4-cac8241e5ef7","_uuid":"01778d932c80c4ce7b2e8c007b260a7c9db9212f","collapsed":true},"source":"list(df_train_merged['composer'].unique())","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"67daf473-2772-496f-b2cb-ebba4f333ddf","_uuid":"6daa5b89a51b762c8eca6bca6596d5767921071b"},"source":"We have similar occurrences of separation as the previous case.","cell_type":"markdown"},{"metadata":{"_cell_guid":"419f682c-5a83-410a-a38c-fb14b5b9af70","_uuid":"f449f650c8359e4f7cc3b340408f6d74fb43f65d","collapsed":true},"source":"def composer_count(x):\n    if x == 'no_composer':\n        return 0\n    else:\n        return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n\ndf_train_merged['composer_count'] = df_train_merged['composer'].apply(composer_count).astype(np.int8)\ndf_test_merged['composer_count'] = df_test_merged['composer'].apply(composer_count).astype(np.int8)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"eefdbfb2-9e6c-468e-86b0-d1f31feba813","_uuid":"fe7d617c92a0e7398e3cb085975d5f502aabeee4"},"source":"## Feature 4 : **is_featured**\nThis is a binary column emphasizing whether featured artists have performed or not.","cell_type":"markdown"},{"metadata":{"_cell_guid":"19d0fb0f-0e25-4f0b-8419-23cf8e9f4c17","_uuid":"faa65b62f343f76705ead05b8e3f2cc323102c4a","collapsed":true},"source":"list(df_train_merged['artist_name'].unique())","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"0b50340e-044a-4b79-9c03-65d3a8147cad","_uuid":"aa43cd0d81f5d4db290ab27c301b39975ec4378f"},"source":"To count featured artists strings like `feat.` and `featuring` must be taken into account.","cell_type":"markdown"},{"metadata":{"_cell_guid":"68083dcd-e4fe-4bc3-8a72-fb8e62f5369d","_uuid":"b82f1a3699a958b68a5a62984d79554f22ca08b2","collapsed":true},"source":"def is_featured(x):\n    if ((x.find('feat.') == True) | (x.find('featuring') == True)):\n        return 1\n    else:\n        return 0\n\ndf_train_merged['is_featured'] = df_train_merged['artist_name'].apply(is_featured).astype(np.int8)\ndf_test_merged['is_featured'] = df_test_merged['artist_name'].apply(is_featured).astype(np.int8)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"6679635a-8e12-48c1-8e65-41f121af4eb4","_uuid":"ce8dc9cb875deb148682d0786473c3a97573c671"},"source":"## Feature 5 : **artist_count**\nThis column stores the number of artists who performed the song including the featured artists  ","cell_type":"markdown"},{"metadata":{"_cell_guid":"91553d1f-ead2-4073-bbd0-4974dcfb3f4d","_uuid":"55c1e59e534d0ef4badfeda38e82f366062e5b84","collapsed":true},"source":"def artist_count(x):\n    if x == 'no_artist':\n        return 0\n    else:\n        return sum(map(x.count, ['&', 'and', 'feat.', 'featuring'])) + 1\n\ndf_train_merged['artist_count'] = df_train_merged['artist_name'].apply(artist_count).astype(np.int8)\ndf_test_merged['artist_count'] = df_test_merged['artist_name'].apply(artist_count).astype(np.int8)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"d08e06a6-4470-46a4-a490-1e5f8b0aa859","_uuid":"567828607b0e961a7e4105cef95b4f944abf60b4"},"source":"## Feature 6 : **artist_composer**\n\nNew column to check whther the artist and composer is the same person.","cell_type":"markdown"},{"metadata":{"_cell_guid":"f66c9596-87a1-4bb2-b40d-f0e45c3e8cfe","_uuid":"a34b96ea47663aeb6e93191f7a108c09b0a8551a","collapsed":true},"source":"df_train_merged['artist_composer'] = (df_train_merged['artist_name'] == df_train_merged['composer']).astype(np.int8)\ndf_test_merged['artist_composer'] = (df_test_merged['artist_name'] == df_test_merged['composer']).astype(np.int8)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"527a7159-80b7-487f-ae67-9d94fba44720","_uuid":"52fcb9725234a59a61f49f612f855c5ebc8c3041"},"source":"## Feature 7 : **artist_composer_lyricist**\n\nNew column to check whther the artist, composer and lyricist is the same person.","cell_type":"markdown"},{"metadata":{"_cell_guid":"ffed666a-5ddb-4c0e-98a7-f28a271a0e23","_uuid":"d31e2f9f1395c412fe051fa0d78b3c1ae0d5b074","collapsed":true},"source":"df_train_merged['artist_composer_lyricist'] = ((df_train_merged['artist_name'] == df_train_merged['composer']) & (df_train_merged['artist_name'] == df_train_merged['lyricist']) & (df_train_merged['composer'] == df_train_merged['lyricist'])).astype(np.int8)\ndf_test_merged['artist_composer_lyricist'] = ((df_test_merged['artist_name'] == df_test_merged['composer']) & (df_test_merged['artist_name'] == df_test_merged['lyricist']) & (df_test_merged['composer'] == df_test_merged['lyricist'])).astype(np.int8)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"41ac9065-4cc7-4dc5-be1c-619b152a91df","_uuid":"6ce2b306b20393ad5fc8f6cf6ce1897fcd034f26","collapsed":true},"source":"print(df_train_merged.shape)\nprint(df_test_merged.shape)\ndf_train_merged['artist_composer_lyricist'].unique()","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"ab434d0e-b30f-4d7a-8182-ef802ec8d419","_uuid":"f1010efc8e99efd99c82e70c81e21a529b31231a"},"source":"# *TO BE CONTINUED ....*","cell_type":"markdown"}],"nbformat":4,"nbformat_minor":1,"metadata":{"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","pygments_lexer":"ipython3","name":"python","version":"3.6.3"},"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"}}}