{"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"nbconvert_exporter":"python","name":"python","pygments_lexer":"ipython3","version":"3.6.3","file_extension":".py","codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python"}},"cells":[{"metadata":{"_uuid":"c8542907ead88c658cfe43c79118b30fc19487bf","_cell_guid":"216be500-721f-45ac-ab63-6b0b67ec5fb9"},"execution_count":null,"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nimport datetime\nimport math\nimport gc\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","cell_type":"code","outputs":[]},{"metadata":{"_uuid":"81f223f194c6f6f8fb54b908a434a527a3f66c8c","_cell_guid":"91dfcb80-f6a5-48b8-b889-2b4df0e4a4e1"},"execution_count":null,"source":"print('Loading data...')\ndata_path = '../input/'\ntrain = pd.read_csv(data_path + 'train.csv', dtype={'msno' : 'category',\n                                                'source_system_tab' : 'category',\n                                                  'source_screen_name' : 'category',\n                                                  'source_type' : 'category',\n                                                  'target' : np.uint8,\n                                                  'song_id' : 'category'})\ntest = pd.read_csv(data_path + 'test.csv', dtype={'msno' : 'category',\n                                                'source_system_tab' : 'category',\n                                                'source_screen_name' : 'category',\n                                                'source_type' : 'category',\n                                                'song_id' : 'category'})\nsongs = pd.read_csv(data_path + 'songs.csv',dtype={'genre_ids': 'category',\n                                                  'language' : 'category',\n                                                  'artist_name' : 'category',\n                                                  'composer' : 'category',\n                                                  'lyricist' : 'category',\n                                                  'song_id' : 'category'})\nmembers = pd.read_csv(data_path + 'members.csv',dtype={'city' : 'category',\n                                                      'bd' : np.uint8,\n                                                      'gender' : 'category',\n                                                      'registered_via' : 'category'},\n                     parse_dates=['registration_init_time','expiration_date'])\nsongs_extra = pd.read_csv(data_path + 'song_extra_info.csv')\nprint('Done loading...')","cell_type":"code","outputs":[]},{"metadata":{"_uuid":"95fae49636554eeb26dde3370054fbf6788335a8","_cell_guid":"24e253c9-b8f8-4c56-b1a5-5faa9bb17c8d"},"execution_count":null,"source":"print('Data merging...')\n\n\ntrain = train.merge(songs, on='song_id', how='left')\ntest = test.merge(songs, on='song_id', how='left')\n\nmembers['membership_days'] = members['expiration_date'].subtract(members['registration_init_time']).dt.days.astype(int)\n\nmembers['registration_year'] = members['registration_init_time'].dt.year\nmembers['registration_month'] = members['registration_init_time'].dt.month\nmembers['registration_date'] = members['registration_init_time'].dt.day\n\nmembers['expiration_year'] = members['expiration_date'].dt.year\nmembers['expiration_month'] = members['expiration_date'].dt.month\nmembers['expiration_date'] = members['expiration_date'].dt.day\nmembers = members.drop(['registration_init_time'], axis=1)\n\ndef isrc_to_year(isrc):\n    if type(isrc) == str:\n        if int(isrc[5:7]) > 17:\n            return 1900 + int(isrc[5:7])\n        else:\n            return 2000 + int(isrc[5:7])\n    else:\n        return np.nan\n        \nsongs_extra['song_year'] = songs_extra['isrc'].apply(isrc_to_year)\nsongs_extra.drop(['isrc', 'name'], axis = 1, inplace = True)\n\ntrain = train.merge(members, on='msno', how='left')\ntest = test.merge(members, on='msno', how='left')\n\ntrain = train.merge(songs_extra, on = 'song_id', how = 'left')\ntrain.song_length.fillna(200000,inplace=True)\ntrain.song_length = train.song_length.astype(np.uint32)\ntrain.song_id = train.song_id.astype('category')\n\n\ntest = test.merge(songs_extra, on = 'song_id', how = 'left')\ntest.song_length.fillna(200000,inplace=True)\ntest.song_length = test.song_length.astype(np.uint32)\ntest.song_id = test.song_id.astype('category')\n\n# import gc\n# del members, songs; gc.collect();\n\nprint('Done merging...')","cell_type":"code","outputs":[]},{"metadata":{"collapsed":true},"execution_count":null,"source":"song_extra=\"\"\nmembers=''\nsongs=''","cell_type":"code","outputs":[]},{"metadata":{},"execution_count":null,"source":"for col in test.columns:\n    if test[col].dtype == 'int64':\n        test[col] = test[col].astype('int8')\n","cell_type":"code","outputs":[]},{"metadata":{},"execution_count":null,"source":"for col in test.columns:\n    if str(test[col].dtype) in \"category\":\n        test[col] = test[col].astype(object)\n        ","cell_type":"code","outputs":[]},{"metadata":{},"execution_count":null,"source":"test.dtypes","cell_type":"code","outputs":[]},{"metadata":{"_uuid":"2f5475aa07fa7f4b59e8e8928d03f67bbcac9347","_cell_guid":"6d0e7314-91f0-4ff5-9081-ebdcb9b1406d"},"execution_count":null,"source":"#print (\"Adding new features\")\n\ndef genre_id_count(x):\n    if x == 'no_genre_id':\n        return 0\n    else:\n        return x.count('|') + 1\n\ntrain['genre_ids'].fillna('no_genre_id',inplace=True)\ntest['genre_ids'].fillna('no_genre_id',inplace=True)\ntrain['genre_ids_count'] = train['genre_ids'].apply(genre_id_count).astype(np.int8)\ntest['genre_ids_count'] = test['genre_ids'].apply(genre_id_count).astype(np.int8)\n\ndef lyricist_count(x):\n    if x == 'no_lyricist':\n        return 0\n    else:\n        return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n    return sum(map(x.count, ['|', '/', '\\\\', ';']))\n\ntrain['lyricist'].fillna('no_lyricist',inplace=True)\ntest['lyricist'].fillna('no_lyricist',inplace=True)\ntrain['lyricists_count'] = train['lyricist'].apply(lyricist_count).astype(np.int8)\ntest['lyricists_count'] = test['lyricist'].apply(lyricist_count).astype(np.int8)\n\ndef composer_count(x):\n    if x == 'no_composer':\n        return 0\n    else:\n        return sum(map(x.count, ['|', '/', '\\\\', ';'])) + 1\n\ntrain['composer'].fillna('no_composer',inplace=True)\ntest['composer'].fillna('no_composer',inplace=True)\ntrain['composer_count'] = train['composer'].apply(composer_count).astype(np.int8)\ntest['composer_count'] = test['composer'].apply(composer_count).astype(np.int8)\n\ndef is_featured(x):\n    if 'feat' in str(x) :\n        return 1\n    return 0\n\ntrain['artist_name'].fillna('no_artist',inplace=True)\ntest['artist_name'].fillna('no_artist',inplace=True)\ntrain['is_featured'] = train['artist_name'].apply(is_featured).astype(np.int8)\ntest['is_featured'] = test['artist_name'].apply(is_featured).astype(np.int8)\n\ndef artist_count(x):\n    if x == 'no_artist':\n        return 0\n    else:\n        return x.count('and') + x.count(',') + x.count('feat') + x.count('&')\n\ntrain['artist_count'] = train['artist_name'].apply(artist_count).astype(np.int8)\ntest['artist_count'] = test['artist_name'].apply(artist_count).astype(np.int8)\n\n# if artist is same as composer\ntrain['artist_composer'] = (train['artist_name'] == train['composer']).astype(np.int8)\ntest['artist_composer'] = (test['artist_name'] == test['composer']).astype(np.int8)\n\n\n# if artist, lyricist and composer are all three same\ntrain['artist_composer_lyricist'] = ((train['artist_name'] == train['composer']) & (train['artist_name'] == train['lyricist']) & (train['composer'] == train['lyricist'])).astype(np.int8)\ntest['artist_composer_lyricist'] = ((test['artist_name'] == test['composer']) & (test['artist_name'] == test['lyricist']) & (test['composer'] == test['lyricist'])).astype(np.int8)\n\n# is song language 17 or 45. \ndef song_lang_boolean(x):\n    if '17.0' in str(x) or '45.0' in str(x):\n        return 1\n    return 0\n\ntrain['song_lang_boolean'] = train['language'].apply(song_lang_boolean).astype(np.int8)\ntest['song_lang_boolean'] = test['language'].apply(song_lang_boolean).astype(np.int8)\n\n\n_mean_song_length = np.mean(train['song_length'])\ndef smaller_song(x):\n    if x < _mean_song_length:\n        return 1\n    return 0\n\ntrain['smaller_song'] = train['song_length'].apply(smaller_song).astype(np.int8)\ntest['smaller_song'] = test['song_length'].apply(smaller_song).astype(np.int8)\n\n# number of times a song has been played before\n_dict_count_song_played_train = {k: v for k, v in train['song_id'].value_counts().iteritems()}\n_dict_count_song_played_test = {k: v for k, v in test['song_id'].value_counts().iteritems()}\ndef count_song_played(x):\n    try:\n        return _dict_count_song_played_train[x]\n    except KeyError:\n        try:\n            return _dict_count_song_played_test[x]\n        except KeyError:\n            return 0\n    \n\ntrain['count_song_played'] = train['song_id'].apply(count_song_played).astype(np.int64)\ntest['count_song_played'] = test['song_id'].apply(count_song_played).astype(np.int64)\n\n# number of times the artist has been played\n_dict_count_artist_played_train = {k: v for k, v in train['artist_name'].value_counts().iteritems()}\n_dict_count_artist_played_test = {k: v for k, v in test['artist_name'].value_counts().iteritems()}\ndef count_artist_played(x):\n    try:\n        return _dict_count_artist_played_train[x]\n    except KeyError:\n        try:\n            return _dict_count_artist_played_test[x]\n        except KeyError:\n            return 0\n\ntrain['count_artist_played'] = train['artist_name'].apply(count_artist_played).astype(np.int64)\ntest['count_artist_played'] = test['artist_name'].apply(count_artist_played).astype(np.int64)\n\n\n#print \"Done adding features\"","cell_type":"code","outputs":[]},{"metadata":{},"execution_count":null,"source":"import gc\ngc.collect()","cell_type":"code","outputs":[]},{"metadata":{"_uuid":"577e8f31dccc7262514f854b96bb213396aea8f6","_cell_guid":"05ee917e-dc12-4201-8fe6-0b515286253c"},"execution_count":null,"source":"print (\"Train test and validation sets\")\nfor col in train.columns:\n    if train[col].dtype == object:\n        train[col] = train[col].astype('category')\n        test[col] = test[col].astype('category')\n\n\nX_train = train.drop(['target'], axis=1)\ny_train = train['target'].values\n\n\nX_test = test.drop(['id'], axis=1)\nids = test['id'].values\n\n\n# del train, test; gc.collect();\n\nd_train_final = lgb.Dataset(X_train, y_train)\nwatchlist_final = lgb.Dataset(X_train, y_train)\nprint('Processed data...')","cell_type":"code","outputs":[]},{"metadata":{"_uuid":"42e044686bd89948d06c2471892c9542605a8a05","_cell_guid":"8a7cfb94-afdb-47b1-94d7-88791baa47e5"},"execution_count":null,"source":"params = {\n        'objective': 'binary',\n        'metric': 'binary_logloss',\n        'boosting': 'gbdt',\n        'learning_rate': 0.3 ,\n        'verbose': 0,\n        'num_leaves': 108,\n        'bagging_fraction': 0.95,\n        'bagging_freq': 1,\n        'bagging_seed': 1,\n        'feature_fraction': 0.9,\n        'feature_fraction_seed': 1,\n        'max_bin': 256,\n        'max_depth': 10,\n        'num_rounds': 200,\n        'metric' : 'auc'\n    }\n\n%time model_f1 = lgb.train(params, train_set=d_train_final,  valid_sets=watchlist_final, verbose_eval=5)","cell_type":"code","outputs":[]},{"metadata":{},"execution_count":null,"source":"gc.collect()","cell_type":"code","outputs":[]},{"metadata":{"_uuid":"a2e8293a6c5ff0c0efdb52fb82f053cfb773e55c","_cell_guid":"10895c7a-73f8-45a0-a9b7-e4e489b06268"},"execution_count":null,"source":"params = {\n        'objective': 'binary',\n        'metric': 'binary_logloss',\n        'boosting': 'dart',\n        'learning_rate': 0.3 ,\n        'verbose': 0,\n        'num_leaves': 108,\n        'bagging_fraction': 0.95,\n        'bagging_freq': 1,\n        'bagging_seed': 1,\n        'feature_fraction': 0.9,\n        'feature_fraction_seed': 1,\n        'max_bin': 256,\n        'max_depth': 10,\n        'num_rounds': 200,\n        'metric' : 'auc',\n        'early_stopping_rounds':20\n\n    }\n\n%time model_f2 = lgb.train(params, train_set=d_train_final,  valid_sets=watchlist_final, verbose_eval=10)","cell_type":"code","outputs":[]},{"metadata":{"_uuid":"ea33e6b678757c4f45e1cddfac4a37ce06962d33","_cell_guid":"89048be8-a137-4e0d-811c-740645c17d1a"},"execution_count":null,"source":"print('Making predictions')\np_test_1 = model_f1.predict(X_test)\np_test_2 = model_f2.predict(X_test)\np_test_avg = np.mean([p_test_1, p_test_2], axis = 0)\n\n\nprint('Done making predictions')","cell_type":"code","outputs":[]},{"metadata":{"_uuid":"28888fb62a1efccb51efb762ac1266695bb82002","_cell_guid":"e7b31f60-187f-4744-9416-3c9c876fa838","_kg_hide-output":true},"execution_count":null,"source":"print ('Saving predictions Model model of gbdt')\n\nsubm = pd.DataFrame()\nsubm['id'] = ids\nsubm['target'] = p_test_avg\nsubm.to_csv('submission.csv', index=False, float_format = '%.5f')\n\nprint('Done!')","cell_type":"code","outputs":[]},{"metadata":{"collapsed":true},"execution_count":null,"source":"","cell_type":"code","outputs":[]}],"nbformat_minor":1,"nbformat":4}