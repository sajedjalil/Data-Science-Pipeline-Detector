{"cells":[{"source":"# Days instead of Dates\nOn this notebook I will show you how I improve the score by replacing date data, and converting it into number of days.\nIn this case specifically I will use ALL the fields on the datasets, but only replace the **expiration_date** and **registration_init_time** fields by calculating the difference in days between the two dates.\n\n$$ expiration\\_date - registration\\_init\\_time = membership\\_days$$\n\n## Acknowledgements:\nThis notebook is primarily based on the grate [TalySacc's Script](https://www.kaggle.com/talysacc/simple-lgbm-starter-with-3-fold-cv-lb-0-65249). The modifications are mainly for make understanding easier. I also tried to comment the code as much as I could.","cell_type":"markdown","metadata":{"_uuid":"852024499e3c3fa41427fd92c3ee094ee775e34f","_cell_guid":"058c5db8-be49-465b-90de-fcf78b698eb3"}},{"source":"# Settings\nThis cell contains the main settings for the notebook.","cell_type":"markdown","metadata":{"_uuid":"b918da766e7772d49de4cafea78ff94fb0f0528c","_cell_guid":"229a0ae7-b4bf-4b53-be1a-2904ae6ae5b6"}},{"source":"# This value stores the path where all the input data is stored. \n# This is in case you run the notebook on your local computer.\nINPUT_DATA_PATH = '../input/'","execution_count":null,"cell_type":"code","metadata":{"trusted":true,"_uuid":"e8b1cdf69f2d313b77c5d5543e3473d2b0d65c6c","collapsed":true,"_cell_guid":"65931667-f2ec-471e-b312-f9e81fb0c43f"},"outputs":[]},{"source":"#  Libraries Import\nFirst, we will import the required libraries.","cell_type":"markdown","metadata":{"_uuid":"2a5411c8c1ccd8f633a873de7c5da2952b6d5e21","_cell_guid":"9188d75f-f9c6-42f5-9df8-93f5707ef2f0"}},{"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# SKLEARN\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import log_loss\n","execution_count":null,"cell_type":"code","metadata":{"trusted":true,"_uuid":"5a05c399dce033e4fc3d6e4cc46d18e32e14bc22","collapsed":true,"_cell_guid":"2889c032-26b8-4fcb-9e85-820dec22e389"},"outputs":[]},{"source":"# Read datasets\nNext we read all the datasets into dataframes.","cell_type":"markdown","metadata":{"_uuid":"a1f57ea2e61d298116bb792787a3249f32532a37","_cell_guid":"1605b555-908f-40c0-a795-9396304a9948"}},{"source":"\ndf_test = pd.read_csv(INPUT_DATA_PATH + 'test.csv',dtype={'msno' : 'category',\n                                                'source_system_tab' : 'category',\n                                                'source_screen_name' : 'category',\n                                                'source_type' : 'category',\n                                                'song_id' : 'category'})\n\ndf_train = pd.read_csv(INPUT_DATA_PATH + 'train.csv',dtype={'msno' : 'category',\n                                                 'source_system_tab' : 'category',\n                                                  'source_screen_name' : 'category',\n                                                  'source_type' : 'category',\n                                                  'target' : np.uint8,\n                                                  'song_id' : 'category'})\n\ndf_members = pd.read_csv(INPUT_DATA_PATH + 'members.csv',dtype={'city' : 'category',\n                                                      'bd' : np.uint8,\n                                                      'gender' : 'category',\n                                                      'registered_via' : 'category'},\n                                                      parse_dates=['registration_init_time','expiration_date'])\nprint(\"OK\")","execution_count":null,"cell_type":"code","metadata":{"trusted":true,"_uuid":"7bdb77e774e38fa897c919bdb06ce47b1fa9a443","_cell_guid":"ee1d35e7-34f2-4e81-b263-a5e4e2c53e09"},"outputs":[]},{"source":"# Convert dates to number of days\n### $ expiration\\_date - registration\\_init\\_time = membership\\_days$\nThis is the part where we will convert the dates into days, by calculating the total membership days.","cell_type":"markdown","metadata":{"_uuid":"7c0ab024865d435b3f9ddc079d4b32978b8da9f3","_cell_guid":"807a1a09-0ceb-410c-8678-4303eaeb8ff0"}},{"source":"# Convert date to number of days\ndf_members['membership_days'] = (df_members['expiration_date'] - df_members['registration_init_time']).dt.days.astype(int)\n\n# Remove both date fieldsa since we already have the number of days between them\ndf_members = df_members.drop(['registration_init_time','expiration_date'], axis=1)\nprint(\"OK\")","execution_count":null,"cell_type":"code","metadata":{"trusted":true,"_uuid":"4eacd12508233d07a8a278595f677f36e021c409","_cell_guid":"d677d32e-ffe6-46f0-837d-6f812187a9ca"},"outputs":[]},{"source":"# Merge Dataframes\nLet's merge all the data into the test and train dataframes","cell_type":"markdown","metadata":{"_uuid":"c409c1394305c6838359d126328c4a0d830f09a5","_cell_guid":"7a4fe679-bb09-4aff-b34b-67bcfb48d5e0"}},{"source":"## Members\nWe will now merge the test and train dataframes with the members dataframe.","cell_type":"markdown","metadata":{"_uuid":"aaeef4c3e87ff961d3b77da263054409d09370f1","_cell_guid":"c7e3d04b-58e6-413e-a1f3-d73045b2d797"}},{"source":"# Merge the members dataframe into the test dataframe\ndf_test = pd.merge(left = df_test,right = df_members,how='left',on='msno')\ndf_test.msno = df_test.msno.astype('category')\n\n# Merge the member dataframe into the train dataframe\ndf_train = pd.merge(left = df_train,right = df_members,how='left',on='msno')\ndf_train.msno = df_train.msno.astype('category')\n\n# Release memory\ndel df_members\nprint(\"OK\")","execution_count":null,"cell_type":"code","metadata":{"trusted":true,"_uuid":"d0222f14fb9a32596d640e130e87a2fe83f9a685","_cell_guid":"8d2cf342-5688-42e9-b697-164c4127e0a2"},"outputs":[]},{"source":"## Songs\nNow we will merge the songs dataframe into the test and train dataframes.","cell_type":"markdown","metadata":{"_uuid":"c73c1d5a1e11305579d9aa74299b7bd08d50eaa5","collapsed":true,"_cell_guid":"88fb46eb-8cb4-4094-bba0-17f30b158aaa"}},{"source":"# Load the songs dataframe\ndf_songs = pd.read_csv(INPUT_DATA_PATH + 'songs.csv',dtype={'genre_ids': 'category',\n                                                  'language' : 'category',\n                                                  'artist_name' : 'category',\n                                                  'composer' : 'category',\n                                                  'lyricist' : 'category',\n                                                  'song_id' : 'category'})\n\n# Merge the Test Dataframe with the SONGS dataframe\ndf_test = pd.merge(left = df_test,right = df_songs,how = 'left',on='song_id')\ndf_test.song_length.fillna(200000,inplace=True)\ndf_test.song_length = df_test.song_length.astype(np.uint32)\ndf_test.song_id = df_test.song_id.astype('category')\n\n# Merge the Train dataframe with the SONGS dataframe\ndf_train = pd.merge(left = df_train,right = df_songs,how = 'left',on='song_id')\ndf_train.song_length.fillna(200000,inplace=True)\ndf_train.song_length = df_train.song_length.astype(np.uint32)\ndf_train.song_id = df_train.song_id.astype('category')\n\n# Release memory\ndel df_songs\nprint(\"OK\")","execution_count":null,"cell_type":"code","metadata":{"trusted":true,"_uuid":"5c59815adbe56e4fd017f46c44ddac48df4472bb","_cell_guid":"9f7c7585-7041-4281-888d-3ea72c469464"},"outputs":[]},{"source":"# LightGBM\nFinally, we create the model, train it, and make the final predictions.","cell_type":"markdown","metadata":{"_uuid":"868fc59ed7439b029f45249e944cd5e22b823415","_cell_guid":"9078694b-76c2-43d7-b0d3-0a999303073b"}},{"source":"import lightgbm as lgb\n\n# Create a Cross Validation with 3 splits\nkf = KFold(n_splits=3)\n\n# This array will store the predictions made.\npredictions = np.zeros(shape=[len(df_test)])\n\n# For each KFold\nfor train_indices ,validate_indices in kf.split(df_train) : \n    train_data = lgb.Dataset(df_train.drop(['target'],axis=1).loc[train_indices,:],label=df_train.loc[train_indices,'target'])\n    val_data = lgb.Dataset(df_train.drop(['target'],axis=1).loc[validate_indices,:],label=df_train.loc[validate_indices,'target'])\n    \n    # Create the parameters for LGBM\n    params = {\n        'objective': 'binary',\n        'metric': 'binary_logloss',\n        'boosting': 'gbdt',\n        'learning_rate': 0.2 ,\n        'verbose': 0,\n        'num_leaves': 108,\n        'bagging_fraction': 0.95,\n        'bagging_freq': 1,\n        'bagging_seed': 1,\n        'feature_fraction': 0.9,\n        'feature_fraction_seed': 1,\n        'max_bin': 128,\n        'max_depth': 12,\n        'num_rounds': 100,\n        'metric' : 'auc',\n        } \n    \n    # Train the model\n    bst = lgb.train(params, train_data, 100, valid_sets=[val_data])\n    \n    # Make the predictions storing them on the predictions array\n    predictions += bst.predict(df_test.drop(['id'],axis=1))\n    \n    # Release the model from memory for the next iteration\n    del bst\n\nprint('Training process finished. Generating Output...')\n\n# We get the ammount of predictions from the prediction list, by dividing the predictions by the number of Kfolds.\npredictions = predictions/3\n\n# Read the sample_submission CSV\nsubmission = pd.read_csv(INPUT_DATA_PATH + '/sample_submission.csv')\n# Set the target to our predictions\nsubmission.target=predictions\n# Save the submission file\nsubmission.to_csv('submission.csv',index=False)\n\nprint('Output created.')","execution_count":null,"cell_type":"code","metadata":{"trusted":true,"_uuid":"912df754769c6329b01431349b7a138849116fb0","_cell_guid":"2efbb855-ab71-4dd5-a6c2-a6f62ed97822"},"outputs":[]},{"source":"from IPython.display import FileLink, FileLinks\n","execution_count":null,"cell_type":"code","metadata":{"trusted":true,"_uuid":"5fd14b35de48e6c64ff0fbb5c90c53358a877ced","collapsed":true,"_cell_guid":"3faafb92-f21e-43ed-ba29-d34eddf88ef0"},"outputs":[]},{"source":"FileLinks('.')","execution_count":null,"cell_type":"code","metadata":{"trusted":true,"_uuid":"57688eb1d624c11d9f24a2cc8d2ad1b1ee479b68","_cell_guid":"78caaf0d-4807-4cd3-9e14-ed92b14e9b91"},"outputs":[]},{"source":"def nize(t):\n    if t > 0.7:\n        return 1\n    elif t < 0.3:\n        return 0\n    else:\n        return 0.5\n    \npredictions = np.vectorize(nize)(predictions)\n\n","execution_count":null,"cell_type":"code","metadata":{"trusted":true,"_uuid":"6823a6d8492a8ad82091ac2508419058d500c639","_cell_guid":"e9d74db6-d440-4a76-a265-1270dc907f0e"},"outputs":[]},{"source":"predictions[0]","execution_count":null,"cell_type":"code","metadata":{"trusted":true,"_uuid":"8f567d1339548e0730df37d3b47eb8799b4712be","_cell_guid":"4e83eec4-5993-466c-9a6e-070f9d944df4"},"outputs":[]},{"source":"","execution_count":null,"cell_type":"code","metadata":{"trusted":false,"_uuid":"b8f1a5881ac4354334b5975d04a778546fd72f37","collapsed":true,"_cell_guid":"770b44c6-0e0c-415a-960e-b99466a51ff9"},"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"file_extension":".py","pygments_lexer":"ipython3","mimetype":"text/x-python","nbconvert_exporter":"python","version":"3.6.3","name":"python"}},"nbformat":4,"nbformat_minor":1}