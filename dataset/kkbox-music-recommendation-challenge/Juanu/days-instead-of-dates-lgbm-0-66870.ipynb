{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"version":"3.6.1","pygments_lexer":"ipython3","name":"python","mimetype":"text/x-python","file_extension":".py","nbconvert_exporter":"python"}},"cells":[{"metadata":{},"cell_type":"markdown","source":"# Days instead of Dates\nOn this notebook I will show you how I improve the score by replacing date data, and converting it into number of days.\nIn this case specifically I will use ALL the fields on the datasets, but only replace the **expiration_date** and **registration_init_time** fields by calculating the difference in days between the two dates.\n\n$$ expiration\\_date - registration\\_init\\_time = membership\\_days$$\n\n## Acknowledgements:\nThis notebook is primarily based on the grate [TalySacc's Script](https://www.kaggle.com/talysacc/simple-lgbm-starter-with-3-fold-cv-lb-0-65249). The modifications are mainly for make understanding easier. I also tried to comment the code as much as I could."},{"metadata":{},"cell_type":"markdown","source":"# Settings\nThis cell contains the main settings for the notebook."},{"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code","source":"# This value stores the path where all the input data is stored. \n# This is in case you run the notebook on your local computer.\nINPUT_DATA_PATH = '../input/'","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#  Libraries Import\nFirst, we will import the required libraries."},{"execution_count":null,"metadata":{"_cell_guid":"2889c032-26b8-4fcb-9e85-820dec22e389","_uuid":"5a05c399dce033e4fc3d6e4cc46d18e32e14bc22","collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# SKLEARN\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import log_loss\n","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read datasets\nNext we read all the datasets into dataframes."},{"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code","source":"\ndf_test = pd.read_csv(INPUT_DATA_PATH + 'test.csv',dtype={'msno' : 'category',\n                                                'source_system_tab' : 'category',\n                                                'source_screen_name' : 'category',\n                                                'source_type' : 'category',\n                                                'song_id' : 'category'})\n\ndf_train = pd.read_csv(INPUT_DATA_PATH + 'train.csv',dtype={'msno' : 'category',\n                                                 'source_system_tab' : 'category',\n                                                  'source_screen_name' : 'category',\n                                                  'source_type' : 'category',\n                                                  'target' : np.uint8,\n                                                  'song_id' : 'category'})\n\ndf_members = pd.read_csv(INPUT_DATA_PATH + 'members.csv',dtype={'city' : 'category',\n                                                      'bd' : np.uint8,\n                                                      'gender' : 'category',\n                                                      'registered_via' : 'category'},\n                                                      parse_dates=['registration_init_time','expiration_date'])\n","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Convert dates to number of days\n### $ expiration\\_date - registration\\_init\\_time = membership\\_days$\nThis is the part where we will convert the dates into days, by calculating the total membership days."},{"execution_count":null,"metadata":{"_cell_guid":"d677d32e-ffe6-46f0-837d-6f812187a9ca","_uuid":"4eacd12508233d07a8a278595f677f36e021c409","collapsed":true},"cell_type":"code","source":"# Convert date to number of days\ndf_members['membership_days'] = (df_members['expiration_date'] - df_members['registration_init_time']).dt.days.astype(int)\n\n# Remove both date fieldsa since we already have the number of days between them\ndf_members = df_members.drop(['registration_init_time','expiration_date'], axis=1)","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Merge Dataframes\nLet's merge all the data into the test and train dataframes"},{"metadata":{},"cell_type":"markdown","source":"## Members\nWe will now merge the test and train dataframes with the members dataframe."},{"execution_count":null,"metadata":{"_cell_guid":"8d2cf342-5688-42e9-b697-164c4127e0a2","_uuid":"d0222f14fb9a32596d640e130e87a2fe83f9a685","collapsed":true},"cell_type":"code","source":"# Merge the members dataframe into the test dataframe\ndf_test = pd.merge(left = df_test,right = df_members,how='left',on='msno')\ndf_test.msno = df_test.msno.astype('category')\n\n# Merge the member dataframe into the train dataframe\ndf_train = pd.merge(left = df_train,right = df_members,how='left',on='msno')\ndf_train.msno = df_train.msno.astype('category')\n\n# Release memory\ndel df_members","outputs":[]},{"metadata":{"collapsed":true},"cell_type":"markdown","source":"## Songs\nNow we will merge the songs dataframe into the test and train dataframes."},{"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code","source":"# Load the songs dataframe\ndf_songs = pd.read_csv(INPUT_DATA_PATH + 'songs.csv',dtype={'genre_ids': 'category',\n                                                  'language' : 'category',\n                                                  'artist_name' : 'category',\n                                                  'composer' : 'category',\n                                                  'lyricist' : 'category',\n                                                  'song_id' : 'category'})\n\n# Merge the Test Dataframe with the SONGS dataframe\ndf_test = pd.merge(left = df_test,right = df_songs,how = 'left',on='song_id')\ndf_test.song_length.fillna(200000,inplace=True)\ndf_test.song_length = df_test.song_length.astype(np.uint32)\ndf_test.song_id = df_test.song_id.astype('category')\n\n# Merge the Train dataframe with the SONGS dataframe\ndf_train = pd.merge(left = df_train,right = df_songs,how = 'left',on='song_id')\ndf_train.song_length.fillna(200000,inplace=True)\ndf_train.song_length = df_train.song_length.astype(np.uint32)\ndf_train.song_id = df_train.song_id.astype('category')\n\n# Release memory\ndel df_songs","outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LightGBM\nFinally, we create the model, train it, and make the final predictions."},{"execution_count":null,"metadata":{},"cell_type":"code","source":"import lightgbm as lgb\n\n# Create a Cross Validation with 3 splits\nkf = KFold(n_splits=3)\n\n# This array will store the predictions made.\npredictions = np.zeros(shape=[len(df_test)])\n\n# For each KFold\nfor train_indices ,validate_indices in kf.split(df_train) : \n    train_data = lgb.Dataset(df_train.drop(['target'],axis=1).loc[train_indices,:],label=df_train.loc[train_indices,'target'])\n    val_data = lgb.Dataset(df_train.drop(['target'],axis=1).loc[validate_indices,:],label=df_train.loc[validate_indices,'target'])\n    \n    # Create the parameters for LGBM\n    params = {\n        'objective': 'binary',\n        'metric': 'binary_logloss',\n        'boosting': 'gbdt',\n        'learning_rate': 0.1 ,\n        'verbose': 0,\n        'num_leaves': 108,\n        'bagging_fraction': 0.95,\n        'bagging_freq': 1,\n        'bagging_seed': 1,\n        'feature_fraction': 0.9,\n        'feature_fraction_seed': 1,\n        'max_bin': 128,\n        'max_depth': 10,\n        'num_rounds': 200,\n        'metric' : 'auc',\n        } \n    \n    # Train the model\n    bst = lgb.train(params, train_data, 100, valid_sets=[val_data])\n    \n    # Make the predictions storing them on the predictions array\n    predictions += bst.predict(df_test.drop(['id'],axis=1))\n    \n    # Release the model from memory for the next iteration\n    del bst\n\nprint('Training process finished. Generating Output...')\n\n# We get the ammount of predictions from the prediction list, by dividing the predictions by the number of Kfolds.\npredictions = predictions/3\n\n# Read the sample_submission CSV\nsubmission = pd.read_csv(INPUT_DATA_PATH + '/sample_submission.csv')\n# Set the target to our predictions\nsubmission.target=predictions\n# Save the submission file\nsubmission.to_csv('submission.csv',index=False)\n\nprint('Output created.')","outputs":[]},{"execution_count":null,"metadata":{"collapsed":true},"cell_type":"code","source":"","outputs":[]}],"nbformat":4,"nbformat_minor":1}