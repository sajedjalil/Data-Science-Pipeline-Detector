{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python","nbconvert_exporter":"python","pygments_lexer":"ipython3","file_extension":".py","name":"python","version":"3.6.3"}},"nbformat_minor":1,"nbformat":4,"cells":[{"metadata":{"_uuid":"083e9b82a6673f344a4b3e18c00ac7a3d092e1ec","_cell_guid":"78b52421-0b20-4fe4-9fda-81e96f716b11"},"cell_type":"code","execution_count":null,"source":"import numpy as np\nimport pandas as pd \nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n","outputs":[]},{"metadata":{"scrolled":true,"_uuid":"72501829e5043ff173e1fd80bd896520efca017f","_cell_guid":"50af8c59-a5d6-4254-b81f-7c62709164d8"},"cell_type":"code","execution_count":null,"source":"from sklearn.preprocessing import LabelEncoder\nfrom tqdm import tqdm\n\n\nfrom scipy.sparse import coo_matrix, csr_matrix\ndef read_data(filename):\n    \"\"\" Reads in the last.fm dataset, and returns a tuple of a pandas dataframe\n    and a sparse matrix of song/user/playcount \"\"\"\n    # read in triples of user/song/playcount from the input dataset\n    data = pd.read_csv(filename,\n                             usecols=[0,1,5],        #[36, 11, 10] vrk_pat_primkey,prd_atc_primkey,vdp_aantal\n                             names=['user', 'song','plays'],skiprows=1) #[:1000000]   # user = patient, or prescriptionnr song=atc\n\n    data=data.dropna(axis=0, how='any')  #drop nan\n    data['plays']=data['plays']+1\n    print(data.head())\n    # map each song and user to a unique numeric value\n    data['user'] = data['user'].astype(\"category\")\n    data['song'] = data['song'].astype(\"category\")\n\n    # create a sparse matrix of all the users/plays\n    plays = coo_matrix((data['plays'].astype(float),\n                       (data['song'].cat.codes.copy(),\n                        data['user'].cat.codes.copy())))\n    data['song_nr']=data['song'].cat.codes.copy()\n    return data, plays,data.groupby(['song_nr','song']).plays.sum(),data['user'].cat.codes.copy()\n\ndata,matrix,songsd,user=read_data('../input/train.csv')\ndata.head()","outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"collapsed":true,"scrolled":true,"_uuid":"70c5db1268f82e4b004b7e4242c6ea17f79add9e","_cell_guid":"46bd4d3c-fde9-413e-b94f-c1a3dcf54ecf"},"cell_type":"code","execution_count":null,"source":"from sklearn.preprocessing import normalize\n\n\ndef cosine(plays):\n    normalized = normalize(plays)\n    return normalized.dot(normalized.T)\n\n\ndef bhattacharya(plays):\n    plays.data = np.sqrt(plays.data)\n    return cosine(plays)\n\n\ndef ochiai(plays):\n    plays = csr_matrix(plays)\n    plays.data = np.ones(len(plays.data))\n    return cosine(plays)\n\n\ndef bm25_weight(data, K1=1.2, B=0.8):\n    \"\"\" Weighs each row of the matrix data by BM25 weighting \"\"\"\n    # calculate idf per term (user)\n    N = float(data.shape[0])\n    idf = np.log(N / (1 + np.bincount(data.col)))\n\n    # calculate length_norm per document (artist)\n    row_sums = np.squeeze(np.asarray(data.sum(1)))\n    average_length = row_sums.sum() / N\n    length_norm = (1.0 - B) + B * row_sums / average_length\n\n    # weight matrix rows by bm25\n    ret = coo_matrix(data)\n    ret.data = ret.data * (K1 + 1.0) / (K1 * length_norm[ret.row] + ret.data) * idf[ret.col]\n    return ret\n\n\ndef bm25(plays):\n    plays = bm25_weight(plays)\n    return plays.dot(plays.T)\n\ndef get_largest(row, N=10):\n    if N >= row.nnz:\n        best = zip(row.data, row.indices)\n    else:\n        ind = np.argpartition(row.data, -N)[-N:]\n        best = zip(row.data[ind], row.indices[ind])\n    return sorted(best, reverse=True)\n\n\ndef calculate_similar_artists(similarity, artists, artistid):\n    neighbours = similarity[artistid]\n    top = get_largest(neighbours)\n    return [(artists[other], score, i) for i, (score, other) in enumerate(top)]\n\n\nsongsd = dict(enumerate(data['song'].cat.categories))\nuser_count = data.groupby('song').size()\nto_generate = sorted(list(songsd), key=lambda x: -user_count[x])\n\n","outputs":[]},{"metadata":{"collapsed":true},"cell_type":"code","execution_count":null,"source":"","outputs":[]},{"metadata":{"collapsed":true,"_uuid":"ed1dc9b7eeb45417f89d83b670407c2d37a7d161","_cell_guid":"0c640e6d-d2dc-4658-b53c-2fc6ecd68cef"},"cell_type":"code","execution_count":null,"source":"from sklearn.decomposition import TruncatedSVD\nsvd = TruncatedSVD(n_components=3, n_iter=3, random_state=42)\nXr=svd.fit_transform(bm25(matrix))  \nprint(svd.explained_variance_ratio_)  \nprint(svd.explained_variance_ratio_.sum())\n","outputs":[]},{"metadata":{"collapsed":true,"_uuid":"cdd57ebc06f36aaaaf154192fbcfa06434ab1475","_cell_guid":"923c8b90-82c0-4815-aab5-5528ea09a511"},"cell_type":"code","execution_count":null,"source":"from sklearn.metrics.pairwise import cosine_similarity\nUdf=pd.DataFrame(cosine_similarity(Xr[:200]))","outputs":[]},{"metadata":{"collapsed":true,"_uuid":"50ab33927b2e03280db80165504f26e48cc2b503","_cell_guid":"288c1087-d0e8-439d-a3c2-692eba2c3107"},"cell_type":"code","execution_count":null,"source":"booknr=156\nprint(Udf[booknr].sort_values(ascending=False)[:10])\nbooks[books['id'].isin( Udf[booknr].sort_values(ascending=False)[:10].index )]r_u.index(test.msno[xi])]))","outputs":[]},{"metadata":{"_uuid":"95bac41d0e4271ab3acd179855348617dd10ad64","_cell_guid":"5a0a5a6d-cb71-4b7c-b4ea-9cdbabd0096a"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"6dbc69f395778f34959f4c22633a6ff99febe6c5","_cell_guid":"9aca6122-0fd0-4385-a75c-0203c1f6067b"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"100bd5203bd478740cf84e858ad0fc1c12efa4aa","_cell_guid":"c2063f48-9ab0-4d5d-ac7e-a5d94a0514ea"},"cell_type":"markdown","source":""}]}