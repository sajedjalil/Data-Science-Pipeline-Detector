{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"%matplotlib inline\nimport matplotlib\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn.metrics import log_loss, auc, roc_auc_score\nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler\nfrom nolearn.lasagne import NeuralNet\nfrom lasagne.layers import DenseLayer\nfrom lasagne.layers import InputLayer\nfrom lasagne.layers import DropoutLayer\nfrom lasagne.updates import adagrad, nesterov_momentum\nfrom lasagne.nonlinearities import softmax\nfrom lasagne.objectives import binary_crossentropy, binary_accuracy\nimport theano\n"},{"cell_type":"markdown","metadata":{},"source":"### Preprocessing Homesite Data"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"train = pd.read_csv('../input/train.csv')\n\ny = train.QuoteConversion_Flag.values\nencoder = LabelEncoder()\ny = encoder.fit_transform(y).astype(np.int32)\n\n\ntrain = train.drop(['QuoteNumber', 'QuoteConversion_Flag'], axis=1)\n\n# Lets take out some dates\ntrain['Date'] = pd.to_datetime(pd.Series(train['Original_Quote_Date']))\ntrain = train.drop('Original_Quote_Date', axis=1)\ntrain['Year'] = train['Date'].apply(lambda x: int(str(x)[:4]))\ntrain['Month'] = train['Date'].apply(lambda x: int(str(x)[5:7]))\ntrain['weekday'] = train['Date'].dt.dayofweek\ntrain = train.drop('Date', axis=1)\n\n# we fill the NA's and encode categories\ntrain = train.fillna(-1)\n\nfor f in train.columns:\n    if train[f].dtype=='object':\n        # print(f)\n        lbl = LabelEncoder()\n        lbl.fit(list(train[f].values))\n        train[f] = lbl.transform(list(train[f].values))\n\n"},{"cell_type":"markdown","metadata":{},"source":"### Get the data in shape for Lasagne"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Now we prep the data for a neural net\nX = train\nnum_classes = len(encoder.classes_)\nnum_features = X.shape[1]\n\n# Convert to np.array to make lasagne happy\nX = np.array(X)\nX = X.astype(np.float32)\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\n# Take the first 200K to train, rest to validate\nsplit = 200000 \nepochs = 10\nval_auc = np.zeros(epochs)"},{"cell_type":"markdown","metadata":{},"source":"### Train the Neural Net on the train set"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Comment out second layer for run time.\nlayers = [('input', InputLayer),\n           ('dense0', DenseLayer),\n           ('dropout0', DropoutLayer),\n           #('dense1', DenseLayer)\n           #('dropout1', DropoutLayer),\n           ('output', DenseLayer)\n           ]\n           \nnet1 = NeuralNet(layers=layers,\n                 input_shape=(None, num_features),\n                 dense0_num_units=200, # 512, - reduce num units to make faster\n                 dropout0_p=0.1,\n                 # dense1_num_units=256,\n                 # dropout1_p=0.1,\n                 output_num_units=num_classes,\n                 output_nonlinearity=softmax,\n                 update=adagrad,\n                 update_learning_rate=0.04,\n                 eval_size=0.0,\n                 objective_loss_function = binary_accuracy,\n                 verbose=1,\n                 max_epochs=1)\nfor i in range(epochs):\n    net1.fit(X[:split], y[:split])\n    pred = net1.predict_proba(X[split:])[:,1]\n    val_auc[i] = roc_auc_score(y[split:],pred)\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from matplotlib import pyplot\npyplot.plot(val_auc, linewidth=3, label=\"first attempt\")\npyplot.grid()\npyplot.legend()\npyplot.xlabel(\"epoch\")\npyplot.ylabel(\"validation auc\")\npyplot.show()"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}