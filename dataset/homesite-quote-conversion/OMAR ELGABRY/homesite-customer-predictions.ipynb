{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Imports\n\n# pandas\nimport pandas as pd\nfrom pandas import Series,DataFrame\n\n# numpy, matplotlib, seaborn\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n%matplotlib inline\n\n# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# get homesite & test csv files as a DataFrame\nhomesite_df = pd.read_csv('../input/train.csv')\ntest_df     = pd.read_csv('../input/test.csv')\n\n# preview the data\nhomesite_df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"homesite_df.info()\nprint(\"----------------------------\")\ntest_df.info()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# drop unnecessary columns, these columns won't be useful in analysis and prediction\nhomesite_df = homesite_df.drop(['QuoteNumber'], axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# date\n\nhomesite_df['Year']  = homesite_df['Original_Quote_Date'].apply(lambda x: int(str(x)[:4]))\nhomesite_df['Month'] = homesite_df['Original_Quote_Date'].apply(lambda x: int(str(x)[5:7]))\nhomesite_df['Week']  = homesite_df['Original_Quote_Date'].apply(lambda x: int(str(x)[8:10]))\n\ntest_df['Year']  = test_df['Original_Quote_Date'].apply(lambda x: int(str(x)[:4]))\ntest_df['Month'] = test_df['Original_Quote_Date'].apply(lambda x: int(str(x)[5:7]))\ntest_df['Week']  = test_df['Original_Quote_Date'].apply(lambda x: int(str(x)[8:10]))\n\nhomesite_df.drop(['Original_Quote_Date'], axis=1,inplace=True)\ntest_df.drop(['Original_Quote_Date'], axis=1,inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# customers purchased \n\nsns.countplot(x=\"QuoteConversion_Flag\", data=homesite_df)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# year\n\nfig, (axis1,axis2) = plt.subplots(1,2,figsize=(15,5))\n\nsns.countplot(x=\"QuoteConversion_Flag\",hue=\"Year\", data=homesite_df, ax=axis1)\nsns.countplot(x=homesite_df[\"Year\"].loc[homesite_df[\"QuoteConversion_Flag\"] == 1], order=[2013,2014,2015], ax=axis2)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# month\n\nsns.countplot(x=homesite_df[\"Month\"].loc[homesite_df[\"QuoteConversion_Flag\"] == 1], order=[1,2,3,4,5,6,7,8,9,10,11,12])"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# fill NaN values\n\nhomesite_df.fillna(-1, inplace=True)\ntest_df.fillna(-1, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"from sklearn import preprocessing\n\nfor f in homesite_df.columns:\n    if homesite_df[f].dtype=='object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(homesite_df[f].values) + list(test_df[f].values))\n        homesite_df[f] = lbl.transform(list(homesite_df[f].values))\n        test_df[f] = lbl.transform(list(test_df[f].values))"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# define training and testing sets\n\nX_train = homesite_df.drop(\"QuoteConversion_Flag\",axis=1)\nY_train = homesite_df[\"QuoteConversion_Flag\"]\nX_test  = test_df.drop(\"QuoteNumber\",axis=1).copy()"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Random Forests\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\n\nrandom_forest.fit(X_train, Y_train)\n\nY_pred = random_forest.predict_proba(X_test)\n\nrandom_forest.score(X_train, Y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Logistic Regression\n\nlogreg = LogisticRegression()\n\nlogreg.fit(X_train, Y_train)\n\nY_pred = logreg.predict(X_test)\n\nlogreg.score(X_train, Y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"Y_pred[:,1][0:10]"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}