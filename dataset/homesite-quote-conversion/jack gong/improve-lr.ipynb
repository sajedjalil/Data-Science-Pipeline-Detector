{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Imports\n\n# pandas\nimport pandas as pd\nfrom pandas import Series,DataFrame\n\n# numpy, matplotlib, seaborn\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n\n%matplotlib inline\n\n# machine learning\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.preprocessing import maxabs_scale\nimport xgboost as xgb\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# get homesite & test csv files as a DataFrame\nhomesite_df = pd.read_csv(\"../input/train.csv\")\ntest_df     = pd.read_csv(\"../input/test.csv\")\n\n# preview the data\n#homesite_df.head()\n\n# drop unnecessary columns, these columns won't be useful in analysis and prediction\nhomesite_df = homesite_df.drop(['QuoteNumber'], axis=1)\n# date\n\n# Convert Date to Year, Month, and Week\nhomesite_df['Year']  = homesite_df['Original_Quote_Date'].apply(lambda x: int(str(x)[:4]))\nhomesite_df['Month'] = homesite_df['Original_Quote_Date'].apply(lambda x: int(str(x)[5:7]))\nhomesite_df['Week']  = homesite_df['Original_Quote_Date'].apply(lambda x: int(str(x)[8:10]))\n\ntest_df['Year']  = test_df['Original_Quote_Date'].apply(lambda x: int(str(x)[:4]))\ntest_df['Month'] = test_df['Original_Quote_Date'].apply(lambda x: int(str(x)[5:7]))\ntest_df['Week']  = test_df['Original_Quote_Date'].apply(lambda x: int(str(x)[8:10]))\n\nhomesite_df.drop(['Original_Quote_Date'], axis=1,inplace=True)\ntest_df.drop(['Original_Quote_Date'], axis=1,inplace=True)\n\n\n# There are some columns with non-numerical values(i.e. dtype='object'),\n# So, We will create a corresponding unique numerical value for each non-numerical value in a column of training and testing set.\n\nfrom sklearn import preprocessing\n\nfor f in homesite_df.columns:\n    if homesite_df[f].dtype=='object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(np.unique(list(homesite_df[f].values) + list(test_df[f].values)))\n        homesite_df[f] = lbl.transform(list(homesite_df[f].values))\n        test_df[f] = lbl.transform(list(test_df[f].values))"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# fill NaN values\nhomesite_df.fillna(homesite_df.mean(), inplace=True)\ntest_df.fillna(test_df.mean(), inplace=True)\n     \n# define training and testing sets\nX_train = homesite_df.drop(\"QuoteConversion_Flag\",axis=1)\nY_train = homesite_df[\"QuoteConversion_Flag\"]\nX_test  = test_df.drop(\"QuoteNumber\",axis=1).copy()\n\nX_train = maxabs_scale(X_train)\nX_test = maxabs_scale(X_test)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"\n#Xgboost \nparams = {\"objective\": \"binary:logistic\"}\n\nT_train_xgb = xgb.DMatrix(X_train, Y_train)\nX_test_xgb  = xgb.DMatrix(X_test)\n\ngbm = xgb.train(params, T_train_xgb, 20)\nY_pred = gbm.predict(X_test_xgb)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":"# Create submission\n\nsubmission = pd.DataFrame()\nsubmission[\"QuoteNumber\"]          = test_df[\"QuoteNumber\"]\nsubmission[\"QuoteConversion_Flag\"] = Y_pred\n\nsubmission.to_csv('homesite.csv', index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":false},"outputs":[],"source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":0}