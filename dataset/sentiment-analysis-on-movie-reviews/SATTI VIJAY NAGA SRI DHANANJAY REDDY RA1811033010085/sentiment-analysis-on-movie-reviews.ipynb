{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport random\nimport gc\n\nfrom tqdm import tqdm\nimport pandas as pd\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom transformers import AutoModel, AutoTokenizer, AutoConfig, AdamW\n\ngc.collect()\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-12T12:17:48.069347Z","iopub.execute_input":"2021-12-12T12:17:48.069733Z","iopub.status.idle":"2021-12-12T12:17:48.249937Z","shell.execute_reply.started":"2021-12-12T12:17:48.069686Z","shell.execute_reply":"2021-12-12T12:17:48.248935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.seed(42)\ntorch.manual_seed(42)\nnp.random.seed(42)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:17:48.252043Z","iopub.execute_input":"2021-12-12T12:17:48.25465Z","iopub.status.idle":"2021-12-12T12:17:48.260163Z","shell.execute_reply.started":"2021-12-12T12:17:48.254604Z","shell.execute_reply":"2021-12-12T12:17:48.259342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***Prepare data***","metadata":{}},{"cell_type":"code","source":"!apt-get install unzip\n!unzip ../input/sentiment-analysis-on-movie-reviews/test.tsv.zip test.tsv\n!unzip ../input/sentiment-analysis-on-movie-reviews/train.tsv.zip train.tsv","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:17:48.261492Z","iopub.execute_input":"2021-12-12T12:17:48.263257Z","iopub.status.idle":"2021-12-12T12:17:52.354865Z","shell.execute_reply.started":"2021-12-12T12:17:48.263215Z","shell.execute_reply":"2021-12-12T12:17:52.353905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nsample_submission = pd.read_csv('../input/sentiment-analysis-on-movie-reviews/sampleSubmission.csv')\n\ntrain_df = pd.read_csv('train.tsv', sep='\\t')\nprint(train_df.shape)\nprint(train_df.info())\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:17:52.357592Z","iopub.execute_input":"2021-12-12T12:17:52.357827Z","iopub.status.idle":"2021-12-12T12:17:52.665904Z","shell.execute_reply.started":"2021-12-12T12:17:52.357798Z","shell.execute_reply":"2021-12-12T12:17:52.664855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('test.tsv', sep='\\t')\nprint(test_df.shape)\nprint(test_df.info())\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:17:52.667491Z","iopub.execute_input":"2021-12-12T12:17:52.667864Z","iopub.status.idle":"2021-12-12T12:17:52.763535Z","shell.execute_reply.started":"2021-12-12T12:17:52.667821Z","shell.execute_reply":"2021-12-12T12:17:52.762591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Text Processing****","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', lower=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:17:52.765206Z","iopub.execute_input":"2021-12-12T12:17:52.765518Z","iopub.status.idle":"2021-12-12T12:17:57.935737Z","shell.execute_reply.started":"2021-12-12T12:17:52.765477Z","shell.execute_reply":"2021-12-12T12:17:57.934972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MovieReviewsDataset(Dataset):\n    def __init__(self, df, max_len, test_only=False):\n        self.max_len = max_len\n        self.test_only = test_only\n        self.text = df['Phrase'].tolist()\n        if not self.test_only:\n            self.sentiments = df['Sentiment'].values\n            \n        self.encode = tokenizer.batch_encode_plus(\n            self.text,\n            padding='max_length',\n            max_length=self.max_len,\n            truncation=True,\n            return_attention_mask=True\n        )\n        \n    def __getitem__(self, i):\n        input_ids = torch.tensor(self.encode['input_ids'][i])\n        attention_mask = torch.tensor(self.encode['attention_mask'][i])\n        \n        if self.test_only:\n            return (input_ids, attention_mask)\n        else:\n            sentiments = self.sentiments[i]\n            return (input_ids, attention_mask, sentiments)\n    \n    def __len__(self):\n        return len(self.text)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:17:57.937063Z","iopub.execute_input":"2021-12-12T12:17:57.93731Z","iopub.status.idle":"2021-12-12T12:17:57.946978Z","shell.execute_reply.started":"2021-12-12T12:17:57.937276Z","shell.execute_reply":"2021-12-12T12:17:57.945561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_len = 64\ntrain_dataset = MovieReviewsDataset(train_df, max_len)\ntest_dataset = MovieReviewsDataset(test_df, max_len, test_only=True)\n\nlengths = [int(len(train_dataset) * 0.8), int(len(train_dataset) * 0.2)]\ntrain_dataset, valid_dataset = random_split(train_dataset, lengths=lengths, generator=torch.Generator().manual_seed(42))\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\nval_dataloader = DataLoader(valid_dataset, batch_size=128)\ntest_dataloader = DataLoader(test_dataset, batch_size=128)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:17:57.94889Z","iopub.execute_input":"2021-12-12T12:17:57.949531Z","iopub.status.idle":"2021-12-12T12:18:12.635487Z","shell.execute_reply.started":"2021-12-12T12:17:57.949488Z","shell.execute_reply":"2021-12-12T12:18:12.634724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Modeling****","metadata":{}},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n\n        bert_base_config = AutoConfig.from_pretrained('bert-base-uncased')\n        self.bert_base = AutoModel.from_pretrained('bert-base-uncased', config=bert_base_config)\n        self.classifier = nn.Linear(bert_base_config.hidden_size, 5)\n\n    def forward(self, input_ids, attention_mask):\n        bert_base_output = self.bert_base(input_ids=input_ids, attention_mask=attention_mask)\n        # get last hidden state\n        # bert_base_last_hidden_state = bert_base_output[0]\n        # or\n        # roberta_base_last_hidden_state = roberta_base_output.hidden_states[-1]\n\n        # pooler_output â€“ Last layer hidden-state of the first token of the sequence \n        # (classification token) further processed by a Linear layer and a Tanh activation function\n        pooler_output = bert_base_output[1] # [batch_size, hidden] \n        out = self.classifier(pooler_output)\n        return out\n\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:18:12.636653Z","iopub.execute_input":"2021-12-12T12:18:12.637403Z","iopub.status.idle":"2021-12-12T12:18:13.553956Z","shell.execute_reply.started":"2021-12-12T12:18:12.637362Z","shell.execute_reply":"2021-12-12T12:18:13.553122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model()\nmodel.to(device)\noptimizer = AdamW(model.parameters(), lr=2e-5)\ncriteron = nn.CrossEntropyLoss()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:18:13.556474Z","iopub.execute_input":"2021-12-12T12:18:13.556798Z","iopub.status.idle":"2021-12-12T12:18:32.528388Z","shell.execute_reply.started":"2021-12-12T12:18:13.556762Z","shell.execute_reply":"2021-12-12T12:18:32.527693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_loss = []\ntotal_val_acc = []\nfor epoch in range(3):\n    model.train()\n    epoch_loss = []\n    for input_ids, attention_mask, target in tqdm(train_dataloader):\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)            \n        target = target.to(device)\n        \n        optimizer.zero_grad()\n        \n        y_pred = model(input_ids, attention_mask)\n        \n        loss = criteron(y_pred, target)\n        loss.backward()\n        optimizer.step()\n        epoch_loss.append(loss.item())\n\n    input_ids = input_ids.to(torch.device('cpu'))\n    attention_mask = attention_mask.to(torch.device('cpu'))            \n    target = target.to(torch.device('cpu'))\n    gc.collect()\n\n    val_accs = []\n    model.eval()\n    for input_ids, attention_mask, target in tqdm(val_dataloader):\n        input_ids = input_ids.to(device)\n        attention_mask = attention_mask.to(device)        \n        y_pred = model(input_ids, attention_mask)\n        _, y_pred = torch.max(y_pred, -1)\n        acc = torch.mean((torch.tensor(y_pred.cpu() == target.cpu(), dtype=torch.float)))\n        val_accs.append(acc.cpu())\n        \n    el = sum(epoch_loss)/len(epoch_loss)\n    total_loss.append(el)\n    acc = np.array(val_accs).mean()\n    total_val_acc.append(acc)\n    print(\"Epoch:\", epoch+1, \"-- loss:\", el, \"-- acc:\", acc)\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:18:32.529548Z","iopub.execute_input":"2021-12-12T12:18:32.530005Z","iopub.status.idle":"2021-12-12T12:55:31.564254Z","shell.execute_reply.started":"2021-12-12T12:18:32.529965Z","shell.execute_reply":"2021-12-12T12:55:31.563494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Prepare Submission****","metadata":{}},{"cell_type":"code","source":"model.eval()\npredictions = []\nfor text, attention_mask in tqdm(test_dataloader):\n    text = text.to(device)\n    attention_mask = attention_mask.to(device)\n    preds = model(text, attention_mask)\n    _, preds = torch.max(preds, -1)\n    for pred in preds: predictions.append(pred.item())\nprint(len(predictions))","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:56:29.09334Z","iopub.execute_input":"2021-12-12T12:56:29.094259Z","iopub.status.idle":"2021-12-12T12:58:32.193629Z","shell.execute_reply.started":"2021-12-12T12:56:29.094213Z","shell.execute_reply":"2021-12-12T12:58:32.192925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame()\nsubmission['PhraseId'] = test_df['PhraseId']\nsubmission['Sentiment'] = predictions\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"Sumbssion is ready!\")","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:58:54.546339Z","iopub.execute_input":"2021-12-12T12:58:54.547193Z","iopub.status.idle":"2021-12-12T12:58:54.692237Z","shell.execute_reply.started":"2021-12-12T12:58:54.547155Z","shell.execute_reply":"2021-12-12T12:58:54.69149Z"},"trusted":true},"execution_count":null,"outputs":[]}]}