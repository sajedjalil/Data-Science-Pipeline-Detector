{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1a94f658-c089-257b-dfe4-bf61fa4a1c86"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\\\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageChops\nimport cv2\nimport numpy as np\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"948e65e2-3a8b-d01e-e3e1-8808680331c3"},"outputs":[],"source":"from glob import glob\nbasepath = '../input/train/'\n\nall_cervix_images = []\n\nfor path in sorted(glob(basepath + \"*\")):\n    cervix_type = path.split(\"/\")[-1]\n    cervix_images = sorted(glob(basepath + cervix_type + \"/*\"))\n    all_cervix_images = all_cervix_images + cervix_images\n\nall_cervix_images = pd.DataFrame({'imagepath': all_cervix_images})\nall_cervix_images['filetype'] = all_cervix_images.apply(lambda row: row.imagepath.split(\".\")[-1], axis=1)\nall_cervix_images['type'] = all_cervix_images.apply(lambda row: row.imagepath.split(\"/\")[-2], axis=1)\nall_cervix_images.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e3d43ff1-2d35-e4d3-016f-3e7087e666f9"},"outputs":[],"source":"def trim(im):\n    bg = Image.new(im.mode, im.size, im.getpixel((0,0)))\n    diff = ImageChops.difference(im, bg)\n    diff = ImageChops.add(diff, diff, 2.0, -100)\n    bbox = diff.getbbox()\n    if bbox:\n        return im.crop(bbox)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"02a2c0d6-0afe-5ed8-157a-2b984c86cea2"},"outputs":[],"source":"fig = plt.figure(figsize=(12,8))\n\ni = 1\nfor t in all_cervix_images['type'].unique():\n    ax = fig.add_subplot(1,3,i)\n    f = all_cervix_images[all_cervix_images['type'] == t]['imagepath'].values[0]\n    #plt.imshow(plt.imread(f))\n    #plt.title('sample for cervix {}'.format(t))\n    \n    im = Image.open(f).convert(\"L\")\n    im = trim(im)\n    arr = np.asarray(im)\n    #if (i==2):\n        #print(arr.tolist())\n    plt.imshow(arr, cmap='gray')\n    #plt.title('sample for cervix {}'.format(t))\n    \n    i+=1"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3998cf51-fed4-1214-70c0-42da8ee94df0"},"outputs":[],"source":"import sys\nfrom scipy.misc import imread\nfrom scipy.misc import imshow\nfrom scipy import sum, average"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"96e5c9aa-900c-76a0-d725-24166562ee88"},"outputs":[],"source":"def to_grayscale(arr):\n    \"If arr is a color image (3D array), convert it to grayscale (2D array).\"\n    if len(arr.shape) == 3:\n        return average(arr, -1)  # average over the last axis (color channels)\n    else:\n        return arr"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d14ef94f-a156-59fa-5386-d55738b0be69"},"outputs":[],"source":"data = []\ntarget = []\nfeature_names = ['image_array']\n\nnumpy_array = np.empty()\n\nfor t in all_cervix_images['type'].unique():\n    i = 1\n    for i in range(1):\n        image_name = all_cervix_images[all_cervix_images['type'] == t]['imagepath'].values[i]\n        image_array = to_grayscale(imread(image_name).astype(float))\n        data.append(image_array)\n        target.append(t)\n        \n        print(imread(image_name))\n\nprint(data)\n#df = pd.DataFrame(data)\n#df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bb395733-c149-910f-3072-ee854676acac"},"outputs":[],"source":"print(img1.min())\nprint(img2.min())\nprint(img3.min())\n\nprint(img1.max())\nprint(img2.max())\nprint(img3.max())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f323a89f-5e05-beef-7f37-f9cecdaecf75"},"outputs":[],"source":"from sklearn.datasets import load_iris\niris = load_iris()\nprint(iris)\ndf = pd.DataFrame(iris.data, columns=iris.feature_names)\ndf"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5cf3fd26-73aa-4682-6161-3d846b0c0b08"},"outputs":[],"source":"from sklearn import datasets\ndigits = datasets.load_digits()\nlen(digits.images[4])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d76521ec-fc35-51df-ec9d-2e6bb1de539f"},"outputs":[],"source":"import cv2\nimport math\nfrom sklearn import mixture\nfrom sklearn.utils import shuffle\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.misc import imread\nfrom scipy.misc import imshow\nfrom scipy import sum, average\nfrom skimage import feature\nfrom skimage.transform import resize\nfrom sklearn import datasets, svm, metrics\nfrom sklearn.ensemble import (RandomForestClassifier, ExtraTreesClassifier,\n                              AdaBoostClassifier)\n\nfrom glob import glob\nbasepath = '../input/train/'"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5e0a9385-4e3b-504f-26ad-233eac96814c"},"outputs":[],"source":"def to_grayscale(arr):\n    \"If arr is a color image (3D array), convert it to grayscale (2D array).\"\n    if len(arr.shape) == 3:\n        return average(arr, -1)  # average over the last axis (color channels)\n    else:\n        return arr"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dcceda2c-8f88-4003-d23e-113d159ec419"},"outputs":[],"source":"all_cervix_images = []\n\nfor path in sorted(glob(basepath + \"*\")):\n    cervix_type = path.split(\"/\")[-1]\n    cervix_images = sorted(glob(basepath + cervix_type + \"/*\"))\n    all_cervix_images = all_cervix_images + cervix_images\n\nall_cervix_images = pd.DataFrame({'imagepath': all_cervix_images})\nall_cervix_images['filetype'] = all_cervix_images.apply(lambda row: row.imagepath.split(\".\")[-1], axis=1)\nall_cervix_images['type'] = all_cervix_images.apply(lambda row: row.imagepath.split(\"/\")[-2], axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"75f93d15-873a-27a4-d6ca-252cd0d34ff7"},"outputs":[],"source":"train_data = []\ntrain_target = []\ntest_data = []\ntest_target = []\nraw_data = []\nfeature_names = ['image_array']\n\nall_samples = 10\ntrain_samples = 7\n\nfor t in all_cervix_images['type'].unique():\n    i = 1\n    for i in range(all_samples):\n        image_name = all_cervix_images[all_cervix_images['type'] == t]['imagepath'].values[i]\n        image_array = resize(to_grayscale(imread(image_name).astype(float)), (200, 200))\n        sample=imread(image_name)\n        raw_data.append(imread(image_name))\n        if i > train_samples:\n            test_data.append(image_array.flatten())\n            test_target.append(t)\n        else:\n            train_data.append(image_array.flatten())\n            train_target.append(t)\n\nprint(train_target)\nprint(test_target)\nprint(len(train_data))\nprint(len(test_data))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1df3f4ed-2e36-cf07-9d01-631864eafb61"},"outputs":[],"source":"frame = raw_data[0]\n\nconverted = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n\nlower = np.array([0, 48, 80], dtype = \"uint8\")\nupper = np.array([20, 255, 255], dtype = \"uint8\")\nskinMask = cv2.inRange(converted, lower, upper)\n \n# apply a series of erosions and dilations to the mask\n# using an elliptical kernel\nkernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))\nskinMask = cv2.erode(skinMask, kernel, iterations = 2)\nskinMask = cv2.dilate(skinMask, kernel, iterations = 2)\n\nskinMask = cv2.GaussianBlur(skinMask, (3, 3), 0)\nskin = cv2.bitwise_and(frame, frame, mask = skinMask)\n\ncv2.imshow(\"images\", np.hstack([frame, skin]))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e1bc12d8-a21c-7969-cae1-55bc4d0b26a8"},"outputs":[],"source":"def Ra_space(img, Ra_ratio, a_threshold):\n    imgLab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB);\n    w = img.shape[0]\n    h = img.shape[1]\n    Ra = np.zeros((w*h, 2))\n    for i in range(w):\n        for j in range(h):\n            R = math.sqrt((w/2-i)*(w/2-i) + (h/2-j)*(h/2-j))\n            Ra[i*h+j, 0] = R\n            Ra[i*h+j, 1] = min(imgLab[i][j][1], a_threshold)\n            \n    Ra[:,0] /= max(Ra[:,0])\n    Ra[:,0] *= Ra_ratio\n    Ra[:,1] /= max(Ra[:,1])\n\n    return Ra"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1073d5c6-0490-1822-7b4a-5385619514d7"},"outputs":[],"source":"mask_color = [0, 0, 0]\nimage = raw_data[4]\n\n# a channel saturation threshold\na_threshold = 300\n\n# creating the R-a feature for the image\nRa_array = Ra_space(image, 1.0, a_threshold)\n\n# k-means gaussian mixture model\ng = mixture.GaussianMixture(n_components = 2, covariance_type = 'diag', random_state = 0, init_params = 'kmeans')\nimage_array_sample = shuffle(Ra_array, random_state=0)[:1000]\ng.fit(image_array_sample)\nlabels = g.predict(Ra_array)\n\n# creating the mask array and assign the correct cluster label\nboolean_image_mask = np.array(labels).reshape(image.shape[0], image.shape[1])\nouter_cluster_label = boolean_image_mask[0,0]\n\nnew_image = image.copy()\n\nfor i in range(boolean_image_mask.shape[0]):\n    for j in range(boolean_image_mask.shape[1]):\n        if boolean_image_mask[i, j] == outer_cluster_label:\n            new_image[i, j] = mask_color\n\na = np.hstack([image, new_image])\n\nplt.imshow(a)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}