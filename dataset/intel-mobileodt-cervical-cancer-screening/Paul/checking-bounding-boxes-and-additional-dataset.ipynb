{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"858598d1-a80a-8c7f-dc1c-31af0fe5f9ba"},"source":"## First part: display bounding boxes\nThis kernel is linked to the discussion thread: https://www.kaggle.com/c/intel-mobileodt-cervical-cancer-screening/discussion/31565#174995 where I give three files with bounding boxes.\n\nI merged all files into one called annot.tsv\n\nI said that there could be a need to account for window resizing, so I show here what is working.\nImports"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ca505ab9-6fd7-e006-1798-bf0cec34efe7"},"outputs":[],"source":"import pandas as pd\nimport PIL\nfrom PIL import Image"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dc6de224-f703-4348-16e1-80936ecf477f"},"outputs":[],"source":"DATA_HOME_DIR = '../input/'\n%matplotlib inline\ndata_path = DATA_HOME_DIR + '/' \ntrain_path = data_path + 'train/'\nnb_full_train_samples = 1481\nbb_json = {}\n\n### dict with boxes: use this for your local verification\n#j = pd.read_table('https://kaggle2.blob.core.windows.net/forum-message-attachments/174995/6330/Type_1_bbox.tsv',sep = \" \",\n#                header = None,\n#                usecols = range(6),\n#                names = ['filename','nbox','x','y','width','height'])\n#j['y']=j['ymin']+j['height']\n#filenames=[]\n#for index, l in j.iterrows():\n#     filenames.append(l['filename'])\n#     bb_json[l['filename'].split('/')[-1]] = sorted(\n#           [l[['height', 'width', 'x', 'y']].to_dict()],\n#         key = lambda var: var['width']*var['height']\n#         )\n#print(l[['x','y','width','height']].to_dict())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"611b7c01-220f-e892-efa4-b02934a9a86c"},"outputs":[],"source":"from matplotlib import pyplot as plt\ndef to_plot(img):\n    return np.rollaxis(img, 0, 3).astype(np.uint8)\ndef plot(img):\n    plt.imshow(img)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1e2eca95-8474-a3db-30b0-c2cc2a48e60c"},"outputs":[],"source":"def show_bb(i):\n    img = PIL.Image.open(train_path+filenames[i])\n    bb = bb_json[filenames[i].split('/')[-1]][0]\n    plt.figure(figsize=(6,6))\n    s = img.size\n    plot(img)\n    ax=plt.gca()\n    ax.add_patch(create_rect([bb['x'],bb['y'],bb['width'],bb['height']], 'yellow'))\ndef create_rect(bb, color='red'):\n    return plt.Rectangle((bb[0], bb[1]), bb[2], bb[3], color=color, fill=False, lw=3)"},{"cell_type":"markdown","metadata":{"_cell_guid":"1b33ef25-24e4-1550-dc92-2cd37854b484"},"source":"Since I cannot read the file on Kaggle kernel, I am manually creating the dict here.\n\n          filename  nbox    x     y  width  height\n          Type_1\\0.jpg     2  882   961   1042    1106\n          Type_1\\10.jpg     1  972  2349   1052     715\n          Type_1\\1013.jpg     1  606  1437    774     825\n          Type_1\\1014.jpg     1  930  1090   1310    1384\n          Type_1\\1019.jpg     1  620  1304    982    1168\n          Type_1\\102.jpg     1  722  1486    546     495\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"88c21880-46b2-5d34-59b5-8cf503a3e38c"},"outputs":[],"source":"filenames = [ \"Type_1/0.jpg\",\n      \"Type_1/10.jpg\",\n    \"Type_1/1013.jpg\"]\nbb_json = {}\n\nbb_json[\"0.jpg\"] = sorted(\n           [{'x': 882,\n           'y':972,\n           'width':1042,\n           'height': 1106\n            }],\n    key = lambda var: var['width']*var['height']\n         )\nbb_json[\"10.jpg\"] = sorted(\n           [{'x': 972,\n           'y':2349,\n           'width':1022,\n           'height':725}]\n         ,key = lambda var: var['width']*var['height'])\nprint(bb_json['0.jpg'][0])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2bd8f5a7-63ee-f5c2-4e8b-2d6ad09cb016"},"outputs":[],"source":"show_bb(0)\nshow_bb(1)"},{"cell_type":"markdown","metadata":{"_cell_guid":"f1d9e7d6-b7ee-52a8-9eef-630793571436"},"source":"## Second part: showing abnormal images in additional dataset"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d69f1b04-8139-fd47-5fb1-8cc8120ecdd0"},"outputs":[],"source":"add_path = '../input/additional/'\ndef plot_from_path(path):\n    img = PIL.Image.open(add_path+path)\n    plt.figure(figsize=(6,6))\n    plot(img)"},{"cell_type":"markdown","metadata":{"_cell_guid":"d09facde-359d-a745-ceb0-d0b71e28e49b"},"source":"### Timeseries of treatment"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"22bf1f9f-c233-0c4d-5a19-7c4015474dac"},"outputs":[],"source":"plot_from_path('Type_3/5684.jpg')\nplot_from_path('Type_3/5683.jpg')\nplot_from_path('Type_3/5685.jpg')\nplot_from_path('Type_3/5688.jpg')"},{"cell_type":"markdown","metadata":{"_cell_guid":"13e743fa-0546-d1e2-b25b-bf81bd15fe5b"},"source":"###Other examples of timeseries:"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"08246641-f8ab-d2bc-0dfb-9bf58010fa1b"},"outputs":[],"source":"plot_from_path('Type_2/1816.jpg')\nplot_from_path('Type_2/2946.jpg')\nplot_from_path('Type_2/3803.jpg')\nplot_from_path('Type_2/2971.jpg')\nplot_from_path('Type_2/6893.jpg')\nplot_from_path('Type_2/6894.jpg')\nplot_from_path('Type_2/6892.jpg')\nplot_from_path('Type_2/6891.jpg')"},{"cell_type":"markdown","metadata":{"_cell_guid":"ad17723b-4684-cffa-82c2-b4dc4be233c5"},"source":"### Unrelated images: \nFound a hand, a bag,..."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0348d813-1200-2314-f26b-8c6c8ee6f589"},"outputs":[],"source":"plot_from_path('Type_2/1813.jpg')\nplot_from_path('Type_1/746.jpg')\nplot_from_path('Type_1/2030.jpg')\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"6fd4c8f2-c0dc-4889-7b00-69b87b6c4a28"},"source":"### Conclusions:\n\nAdditional dataset can easily be purged of 2/3 of images either because of duplicates (triplicates, n-plicates), unrelated images, or blurry images."},{"cell_type":"markdown","metadata":{"_cell_guid":"58d58236-4b84-59da-7af6-b423ec2043ec"},"source":"### Bonus\nSome advertisement for a cell phone company."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"db340a7f-2354-e5b7-be02-f06fda7dde99"},"outputs":[],"source":"plot_from_path('Type_1/4065.jpg')\n"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}