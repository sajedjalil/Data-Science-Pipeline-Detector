{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\n\n# There are two ways to load the data from the PANDA dataset:\n# Option 1: Load images using openslide\nimport openslide\n# Option 2: Load images using skimage (requires that tifffile is installed)\nimport skimage.io\nimport random\nimport seaborn as sns\nimport cv2\n\n# General packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport PIL\nfrom IPython.display import Image, display\nimport skimage.io\nfrom tqdm.notebook import tqdm\nimport random\nimport zipfile\nplt.rcParams['figure.figsize'] = [15,8]\n\n# Plotly for the interactive viewer (see last section)\nimport plotly.graph_objs as go\nimport re","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Location of the training images\n\nBASE_PATH = '/kaggle/input/prostate-cancer-grade-assessment/'\n\n# image and mask directories\ntrain_dir = f'{BASE_PATH}/train_images/'\nmask_dir = f'{BASE_PATH}/train_label_masks/' #'/kaggle/input/prostate-cancer-grade-assessment/train_images/'\n\n# Location of training labels\ntrain = pd.read_csv(f'{BASE_PATH}train.csv').set_index('image_id')\ntest = pd.read_csv(f'{BASE_PATH}test.csv')\nsubmission = pd.read_csv(f'{BASE_PATH}/sample_submission.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_count(df, feature, title='', size=2):\n    f, ax = plt.subplots(1,1, figsize=(4*size,3*size))\n    total = float(len(df))\n    sns.countplot(df[feature],order = df[feature].value_counts().index, palette='Set2')\n    plt.title(title)\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()/2.,\n                height + 3,\n                '{:1.2f}%'.format(100*height/total),\n                ha=\"center\") \n    plt.show()\n    \ndef plot_relative_distribution(df, feature, hue, title='', size=2):\n    f, ax = plt.subplots(1,1, figsize=(4*size,3*size))\n    total = float(len(df))\n    sns.countplot(x=feature, hue=hue, data=df, palette='Set2')\n    plt.title(title)\n    for p in ax.patches:\n        height = p.get_height()\n        ax.text(p.get_x()+p.get_width()/2.,\n                height + 3,\n                '{:1.2f}%'.format(100*height/total),\n                ha=\"center\") \n    plt.show()\ndef display_images(slides): \n    f, ax = plt.subplots(5,3, figsize=(18,22))\n    for i, slide in enumerate(slides):\n        image = openslide.OpenSlide(os.path.join(train_dir, f'{slide}.tiff'))\n        spacing = 1 / (float(image.properties['tiff.XResolution']) / 10000)\n        patch = image.read_region((0,0), 0, (256, 256))\n        ax[i//3, i%3].imshow(patch) \n        image.close()       \n        ax[i//3, i%3].axis('off')\n        image_id = slide\n        data_provider = train.loc[slide, 'data_provider']\n        isup_grade = train.loc[slide, 'isup_grade']\n        gleason_score = train.loc[slide, 'gleason_score']\n        ax[i//3, i%3].set_title(f\"ID: {image_id}\\nSource: {data_provider} ISUP: {isup_grade} Gleason: {gleason_score}\")\n    plt.show() \ndef overlay_mask_on_slide(images, center='radboud', alpha=0.8, max_size=(800, 800)):\n    \"\"\"Show a mask overlayed on a slide.\"\"\"\n    f, ax = plt.subplots(5,3, figsize=(18,22))\n    \n    \n    for i, image_id in enumerate(images):\n        slide = openslide.OpenSlide(os.path.join(data_dir, f'{image_id}.tiff'))\n        mask = openslide.OpenSlide(os.path.join(mask_dir, f'{image_id}_mask.tiff'))\n        slide_data = slide.read_region((0,0), slide.level_count - 1, slide.level_dimensions[-1])\n        mask_data = mask.read_region((0,0), mask.level_count - 1, mask.level_dimensions[-1])\n        mask_data = mask_data.split()[0]\n        \n        \n        # Create alpha mask\n        alpha_int = int(round(255*alpha))\n        if center == 'radboud':\n            alpha_content = np.less(mask_data.split()[0], 2).astype('uint8') * alpha_int + (255 - alpha_int)\n        elif center == 'karolinska':\n            alpha_content = np.less(mask_data.split()[0], 1).astype('uint8') * alpha_int + (255 - alpha_int)\n\n        alpha_content = PIL.Image.fromarray(alpha_content)\n        preview_palette = np.zeros(shape=768, dtype=int)\n\n        if center == 'radboud':\n            # Mapping: {0: background, 1: stroma, 2: benign epithelium, 3: Gleason 3, 4: Gleason 4, 5: Gleason 5}\n            preview_palette[0:18] = (np.array([0, 0, 0, 0.5, 0.5, 0.5, 0, 1, 0, 1, 1, 0.7, 1, 0.5, 0, 1, 0, 0]) * 255).astype(int)\n        elif center == 'karolinska':\n            # Mapping: {0: background, 1: benign, 2: cancer}\n            preview_palette[0:9] = (np.array([0, 0, 0, 0, 1, 0, 1, 0, 0]) * 255).astype(int)\n\n        mask_data.putpalette(data=preview_palette.tolist())\n        mask_rgb = mask_data.convert(mode='RGB')\n        overlayed_image = PIL.Image.composite(image1=slide_data, image2=mask_rgb, mask=alpha_content)\n        overlayed_image.thumbnail(size=max_size, resample=0)\n\n        \n        ax[i//3, i%3].imshow(overlayed_image) \n        slide.close()\n        mask.close()       \n        ax[i//3, i%3].axis('off')\n        \n        data_provider = train.loc[image_id, 'data_provider']\n        isup_grade = train.loc[image_id, 'isup_grade']\n        gleason_score = train.loc[image_id, 'gleason_score']\n        ax[i//3, i%3].set_title(f\"ID: {image_id}\\nSource: {data_provider} ISUP: {isup_grade} Gleason: {gleason_score}\")\ndef tile(img):\n    sz = 128\n    bs = 2\n    N = 12\n    nworkers = 2\n    shape = img.shape\n    pad0,pad1 = (sz - shape[0]%sz)%sz, (sz - shape[1]%sz)%sz\n    img = np.pad(img,[[pad0//2,pad0-pad0//2],[pad1//2,pad1-pad1//2],[0,0]],\n                 constant_values=255)\n    img = img.reshape(img.shape[0]//sz,sz,img.shape[1]//sz,sz,3)\n    img = img.transpose(0,2,1,3,4).reshape(-1,sz,sz,3)\n    if len(img) < N:\n        img = np.pad(img,[[0,N-len(img)],[0,0],[0,0],[0,0]],constant_values=255)\n    idxs = np.argsort(img.reshape(img.shape[0],-1).sum(-1))[:N]\n    img = img[idxs]\n    return img\ndef rgb2gray(rgb):\n    return np.dot(rgb[...,:3], [0.2989, 0.5871, 0.1140])/255.0\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rgb2gray(rgb):\n    return np.dot(rgb[...,:3], [0.2989, 0.5871, 0.1140])/255.0\n    #plt.imshow(gray, cmap=plt.get_cmap('gray'), vmin=0, vmax=1)\n    #plt.show()\n\ndef rmpad(img,seed=5):\n    t=pd.DataFrame(img[:,:,0]<200)\n    t1=t.sum(axis=0)\n    t1=t1[t1>seed]\n    col1,col2 = t1.index[0], t1.index[-1]\n    \n    t1=t.sum(axis=1)\n    t1=t1[t1>seed]\n    row1,row2 = t1.index[0], t1.index[-1]\n    return img[row1:row2,col1:col2,:]\n\ndef rmpad2(img,seed=10,lb=10,ub=250):\n    t=pd.DataFrame((img[:,:,0]<ub) & (img[:,:,0]>lb))\n    t1=t.sum(axis=0)\n    t1=t1[t1>seed]\n    col1,col2 = t1.index[0], t1.index[-1]\n    \n    t1=t.sum(axis=1)\n    t1=t1[t1>seed]\n    row1,row2 = t1.index[0], t1.index[-1]\n    return img[row1:row2,col1:col2,:]\n\ndef display(img_name='',sub=-1,path='/kaggle/input/prostate-cancer-grade-assessment/train_images/'):\n    img=skimage.io.MultiImage(path +  img_name + '.tiff')[sub]\n    plt.imshow(img) \ndef display_sharp(img_name,pad_rem=True,enh=True,unsharp=True,sub=-1,path='/kaggle/input/prostate-cancer-grade-assessment/train_images/'):\n    img = skimage.io.MultiImage(path +  img_name + '.tiff')[sub]\n    if pad_rem:\n        img=rmpad2(img)\n    if  enh:\n        img=enhance_image(img)\n    if unsharp:\n        img=unsharp_masking(img)\n    plt.imshow(img)  \ndef sharp(img,pad_rem=True,enh=True,unsharp=True):\n    if pad_rem:\n        img=rmpad2(img)\n    if  enh:\n        img=enhance_image(img)\n    if unsharp:\n        img=unsharp_masking(img)\n    return img\ndef enhance_image(img, contrast=1, brightness=15):\n    \"\"\"\n    Enhance constrast and brightness of images\n    \"\"\"\n    img = cv2.addWeighted(img, contrast, img, 0, brightness)\n    return img\ndef unsharp_masking(img):\n    \"\"\" Unsharp masking of an RGB image\"\"\"\n    img_gaussian = cv2.GaussianBlur(img, (21,21), 10.0)\n    return cv2.addWeighted(img, 1.8, img_gaussian, -0.75, -0.05, img)\n\nfind=lambda x:list(np.where(x)[0][:]) if isinstance(x,np.ndarray) else (\n            list(np.where(x)[0][:]) if isinstance(x,list) else (\n            list(np.where(np.array(x)[0][:])) if not isinstance(x,bool) else np.where(x)[0]))\n\n#######################################Function###################################################\ndef flatten(y):\n    t=lambda x: [x] if type(x) is not list else x\n    z=lambda x: sum([t(i) for i in x],[])\n    for i,j in enumerate(y):\n        if isinstance(j,np.ndarray):\n            y[i]=list(j.flatten())\n        elif isinstance(j,tuple):\n            y[i]=list(j)\n    h=t(z(y));\n    if any([isinstance(i,list) | isinstance(i,tuple)  for i in h ]):\n        return flatten(h)\n    else:\n        return h;\n    \ndef randi(x,p=1,full_rep_prop=.85):\n    \n    from random import shuffle,sample\n    import numpy as np\n    \n    if isinstance(x,int) or isinstance(x,float):\n        x=[i for i in range(round(x))]\n    \n    if isinstance(x,np.ndarray):\n        x=list[x]\n\n    if not isinstance(p,float):\n        if len(x)==p:\n            shuffle(x)\n            return x\n        if len(x)>p:\n            return sample(x,p)\n        else: # over sampling\n            len_x=len(x)\n            list0=[]\n            while p>len_x:\n                p=p-len_x\n                shuffle(x)\n                list0.extend(x)\n            list0.extend(sample(x,p))\n            return list0\n   \n    # if it is a proportion\n    if isinstance(p,float):\n        len_x=len(x)\n        list0=[]\n        while p>1:\n            p=p-1\n            if full_rep_prop==1:\n                shuffle(x)\n                list0.extend(x)\n            else:\n                list0.extend(sample(x,int(round(full_rep_prop*len_x))))  \n        list0.extend(sample(x,int(round(p*len_x))))\n        return list0\n    \ndef splitstrat(X,Y,alpha=.65,verbose=True,data_proportion=1.,random_seed=7): \n    import random \n    data_proportion=float(data_proportion) \n\n    # select proportion of data \n    num_samples=X.shape[0] \n\n    u=np.unique(Y) \n    num_class=len(u) \n    idx=[list(np.array(np.where(Y==u[i])).flatten()) for i in range(len(u))] \n    idx=[random.Random(random_seed).sample(idx[i],int(round(data_proportion*len(idx[i])))) \n         for i in range(num_class)]  \n    factors=[len(idx[i]) for i in range(num_class)] \n\n\n    if isinstance (alpha,float): \n        alpha=[alpha]*num_class \n    if isinstance(alpha,list): \n        if len(alpha)!= num_class: \n            alpha=[alpha[0]]*num_class\n\n\n    f=[int(round(factors[i]*alpha[i])) for i in range(num_class) ]\n\n    # create indexes \n    idx_train=[idx[i][0:f[i]] for i in range(num_class)]\n    idx_val=[idx[i][f[i]:] for i in range(num_class) ]\n\n    # flatten list of arrays\n    idx_train,idx_val=list(),list()\n    [idx_train.extend(idx[i][0:f[i]]) for i in range(num_class)]\n    [idx_val.extend(idx[i][f[i]:]) for i in range(num_class)]\n\n    # create datasets \n    x_train=X.iloc[idx_train]\n    x_val=X.iloc[idx_val]\n    y_train=Y[idx_train] \n    y_val=Y[idx_val] \n    \n    #update date frame with new field\n    #X[\"split\"].iloc[idx_train]=\"train\"\n    #X[\"split\"].iloc[idx_val]=\"val\" \n    \n    # to avoid panda warning we use loc instead of iloc\n    X[\"split\"]=\"not_used\"\n    X.loc[X.index[idx_train],\"split\"]=\"train\"\n    X.loc[X.index[idx_val],\"split\"]=\"val\"\n    \n    #X[\"split\"].iloc[idx_val].apply(lambda x:[x+\"val\"])\n\n    if verbose==1: \n            print('class names: %s' % [i for i in u])  \n            print('each class#: %s' % [i for i in factors])  \n            print('num of samples of each class in training samples...')\n            print('-->>>>>>>>: %s' % [i for i in f])    \n            print('<<<<<<<<-----x_val, x_train is %s  ------------>>>>>>' % [len(idx_val),len(idx_train)]) \n            print(f'all data is  {X.shape}  and all lables is {Y.shape}') \n            #print('alpha and data proportion is %s'% [alpha,data_proportion] ) \n            print(f'{data_proportion*100}% of data were used to create stratified samples,')\n            print(f'{alpha[0]*100}% of employed samples is for training and the rest if for validation')\n    return (x_train,y_train,x_val,y_val) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create new binary lable\ntrain.isnull().sum()\ntrain[\"blabel\"]=train.isup_grade>3\n\n# create ordered lables from 0:8 corresponding to 9 levels of severity from Normal to End-level\nlevels=list(np.unique(train.gleason_score))\nlevels.insert(0,levels.pop(-1))# move the last item in the list (\"negative\") to the first position\ntrain[\"glabel\"]=train.apply(lambda x: levels.index(x.gleason_score),axis=1)\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pen_marked_images = [\n    'fd6fe1a3985b17d067f2cb4d5bc1e6e1',\n    'ebb6a080d72e09f6481721ef9f88c472',\n    'ebb6d5ca45942536f78beb451ee43cc4',\n    'ea9d52d65500acc9b9d89eb6b82cdcdf',\n    'e726a8eac36c3d91c3c4f9edba8ba713',\n    'e90abe191f61b6fed6d6781c8305fe4b',\n    'fd0bb45eba479a7f7d953f41d574bf9f',\n    'ff10f937c3d52eff6ad4dd733f2bc3ac',\n    'feee2e895355a921f2b75b54debad328',\n    'feac91652a1c5accff08217d19116f1c',\n    'fb01a0a69517bb47d7f4699b6217f69d',\n    'f00ec753b5618cfb30519db0947fe724',\n    'e9a4f528b33479412ee019e155e1a197',\n    'f062f6c1128e0e9d51a76747d9018849',\n    'f39bf22d9a2f313425ee201932bac91a',\n]\nidx_to_include=[i for i in train.index if i not in pen_marked_images]\nmask_image_names=[re.sub('_mask.*','',name) for name in os.listdir(mask_dir)]\nidx_with_masks=[i for i in mask_image_names if i in idx_to_include]\nprint(\"number of masks:\",len(mask_image_names))\nprint(\"number of image with masks and no pen marks:\",len(idx_with_masks))\nprint(\"number of images in training data:\",len(train.index))\n\nrandom_seed=7\nrandom.Random(random_seed).shuffle(idx_with_masks)\nidx=idx_with_masks[:100]# select only 50 images for now\n\ntrain2=train.loc[idx] \ntrain2.head(5)\n\ntrain2_data=list()\nfor i in range(len(idx)):\n    train2_data.append(sharp(skimage.io.MultiImage(train_dir + train2.index[i] + '.tiff')[-1]))\n    #print(f'image:{i}',i+1)\n    \nprint(f'Reading {len(train2_data)} images finished')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_relative_distribution(df=train2, feature='data_provider', hue='blabel', \n                           title = 'relative count plot of isup_grade with data_provider', size=3)\nplot_relative_distribution(df=train, feature='data_provider', hue='blabel', \n                           title = 'relative count plot of isup_grade with data_provider', size=3)\nplot_relative_distribution(df=train2, feature='glabel', hue='data_provider', \n                           title = 'relative count plot of isup_grade with data_provider', size=3)\nplot_relative_distribution(df=train, feature='glabel', hue='data_provider', \n                           title = 'relative count plot of isup_grade with data_provider', size=3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(x_train,y_train,x_val,y_val) = splitstrat(train2,train2.glabel,.65,random_seed= random_seed)\nplot_relative_distribution(df=train2, feature='split', hue='blabel', \n                           title = 'relative count plot of binary label over data splits', size=3)\nplot_relative_distribution(df=train2, feature='split', hue='glabel', \n                           title = 'relative count plot of all labels over data splits', size=3)\nplot_relative_distribution(df=train2, feature='split', hue='data_provider', \n                           title = 'relative count plot of splits over data provider', size=3)\n\nplot_count(df=train, feature='glabel', \n                           title = ' count plot of all labels over original data', size=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=train2.tail(5)\nX.iloc[[1,2,3],[3,4]]=None\nX.iloc[[4],[3,5]]=None\n\nt=X.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def repall(X,val=None,rep=None,replace=False):\n    #replace different values in provided columns\n    #repall(X,rep={'split':{'val':'validation',None:'not_used'},'glabel':{0:1,5:25,None:-10}},replace=True)\n    if val==None:\n        x=X.isnull().sum(axis=0).reset_index()\n    else:\n        x=X.applymap(lambda x: [True if type(val)==type(x) and val==x else False][0]).sum(axis=0).reset_index()\n    x.rename(columns={\"index\":\"col_name\",0:\"hit_num\"},inplace=True)\n    x[\"hit_rate\"]=x.miss_num/X.shape[0]\n    \n    if  sum(x.hit_num)>0 and replace:\n        if type(rep)!=dict : # all data\n            if rep is not None:\n                X.replace(rep)\n            else:\n                X.fillna(rep) \n        else: # some columns\n            cols=list(rep.keys())\n            rep_val=list(rep.values())\n            _=[X[cols[i]].replace(rep_val[i],inplace=True) for i,j in enumerate(cols)]\n            #if val==None:\n            #X.fillna(rep,inplace=True) \n        #else: #type(rep)!=dict:\n            #else:\n            #X=X.applymap(lambda x: [rep if type(val)==type(x) and val==x else x][0])\n            \n\n    print(f'number of search results: {sum(x.hit_num)} ')\n    print(f'number of columns having search value: {sum(x.hit_num>0)}')\n    print(f'columns are: {x.col_name[x.hit_num>0].values}')\n    return x\ndef rmnull(X,rep=None):\n    #example:t=rmnull(t,{'blabel':0,'split':'not_used'})\n    x=X.isnull().sum(axis=0).reset_index()\n    x.rename(columns={\"index\":\"col_name\",0:\"miss_num\"},inplace=True)\n    x[\"miss_rate\"]=x.miss_num/X.shape[0]\n    \n    if  sum(x.miss_num)>0 and (rep is not None):\n        #X=X.applymap(lambda x: [rep if x is None else x][0])\n        X.fillna(rep,inplace=True)\n    \n    print(f'number of null values: {sum(x.miss_num)} ')\n    print(f'number of columns having nulls: {sum(x.miss_num>0)}')\n    print(f'columns are: {x.col_name[x.miss_num>0].values}')\n    return (x,X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rep={'split':{'val':'validation',None:'not_used'},'glabel':{0:1,5:25,None:-10}}\nrep_key=list(rep.keys())\nrep_val=list(rep.values())\nrep_val[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=X.copy()\n[y[rep_key[i]].replace(rep_val[i],inplace=True) for i,j in enumerate(rep_val)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t=X.copy()\ntt=repall(t,{'blabel':0,'split':'not_used'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t=X.copy()\ntt=rmnull(t,{'blabel':0,'split':'not_used'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.isna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tt[1].head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.iloc[0,1]=24\nX.iloc[1,1]=27\nX.iloc[2,1]=-37\nX.iloc[3,1]=None\nX.iloc[4,1]=None\nt=X\nt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a=[X[X.columns[i]].dtype in [type(1),type(.1)] for i in range(len(X.columns))]\na\nt=X\nX[X.columns[a]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t[t.columns[a]].apply(lambda x:[x.mode() if x>20 else x],axis=0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X.apply(lambda x:x.fillna([-11 if type(x) in [type(1),type(.1)]  else \"fuck\"][0]),axis=0)\n#x=X[X.columns[ i in X.columns if  X.i.dtype=type(1)]].apply(lambda x:[x.mode() if x is None else x])\n#x\n#X.iloc[:,a]\nt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.loc[:,a]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.isup_grade.median()\nX.split.mode()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.isup_grade","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rep=-1\nval=None\nx=X.applymap(lambda x: [True if type(val)==type(x) and val==x else False][0]).sum().reset_index()\nx.rename(columns={\"index\":\"col_name\",0:\"miss_num\"},inplace=True)\nx[\"miss_rate\"]=x.miss_num/X.shape[0]\n#sum(x.miss_num)\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = skimage.io.MultiImage(DATA_DIR + 'train_images/' + data_karolinska.image_id[800] + '.tiff')[-1]\nimg[:4,1,:]\nimg=np.array(img)\nimg[:4,1,:]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's check for relative distribution of isup_grade and gleason_scoreÂ¶\nplot_relative_distribution(df=train, feature='isup_grade', hue='gleason_score', \n                           title = 'relative count plot of isup_grade with gleason_score', size=2)\nplot_relative_distribution(df=train, feature='isup_grade', hue='data_provider', \n                           title = 'relative count plot of isup_grade with data_provider', size=3)\nplot_count(df=train[train.data_provider==\"karolinska\"], feature='gleason_score', title = 'gleason_score count for karolinska')\nplot_count(df=train[train.data_provider==\"radboud\"], feature='gleason_score', title = 'gleason_score count for radboud')\nplot_count(df=train[train.data_provider==\"radboud\"], feature='isup_grade', title = 'isup_grade count for radboud')\nplot_count(df=train[train.data_provider==\"karolinska\"], feature='isup_grade', title = 'isup_grade count for karolinska')\nplot_count(df=train, feature='isup_grade', title = 'isup_grade count and %age plot')\nplot_count(df=train, feature='data_provider', title = 'data_provider count and %age plot')\n\n#plot over new created labels\nplot_count(df=train[train.data_provider!=\"karolinska\"], feature='label', title = 'label count for Radbound')\nplot_count(df=train[train.data_provider==\"karolinska\"], feature='label', title = 'label count for karolinska')\nplot_count(df=train, feature='label', title = 'label count')\nplot_count(df=train, feature='glabel', title = 'glabel count ')\n\n\ndisplay(train.head())\nprint(\"Shape of training data :\", train.shape)\nprint(\"unique data provider :\", len(train.data_provider.unique()))\nprint(\"unique isup_grade(target) :\", len(train.isup_grade.unique()))\nprint(\"unique gleason_score :\", len(train.gleason_score.unique()))\n\ntrain.isna().sum()\n\n\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}