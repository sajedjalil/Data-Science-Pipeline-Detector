{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Data visualization to help find the threshold"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import cohen_kappa_score\nfrom scipy.stats import mode\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.model_selection import train_test_split\n\nimport lightgbm as lgb\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import KFold\nfrom tqdm import tqdm\nimport json\n\ntrain=pd.read_csv('../input/data-science-bowl-2019/train.csv')\ntrain_labels=pd.read_csv('../input/data-science-bowl-2019/train_labels.csv')\ntest = pd.read_csv('../input/data-science-bowl-2019/test.csv')\nsubmission=pd.read_csv('../input/data-science-bowl-2019/sample_submission.csv')\n\n# train dataset with only installation_id that are in train_labels:\nnot_req=(set(train.installation_id.unique()) - set(train_labels.installation_id.unique()))\ntrain_new=~train['installation_id'].isin(not_req)\ntrain.where(train_new,inplace=True)\ntrain.dropna(inplace=True)\ntrain['event_code']=train.event_code.astype(int)\n\ndef extract_time_features(df):\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    return df\nextract_time_features(train)\nextract_time_features(test)\n\n# encode title\n# make a list with all the unique 'titles' from the train and test set\nlist_of_user_activities = list(set(train['title'].value_counts().index).union(set(test['title'].value_counts().index)))\n# make a list with all the unique 'event_code' from the train and test set\nlist_of_event_code = list(set(train['event_code'].value_counts().index).union(set(test['event_code'].value_counts().index)))\n# create a dictionary numerating the titles\nactivities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\nactivities_labels = dict(zip(np.arange(len(list_of_user_activities)), list_of_user_activities))\nassess_titles = list(set(train[train['type'] == 'Assessment']['title'].value_counts().index).union(set(test[test['type'] == 'Assessment']['title'].value_counts().index)))\n\n# replace the text titles withing the number titles from the dict\ntrain['title'] = train['title'].map(activities_map)\ntest['title'] = test['title'].map(activities_map)\ntrain_labels['title'] = train_labels['title'].map(activities_map)\n\nwin_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\n# then, it set one element, the 'Bird Measurer (Assessment)' as 4110, 10 more than the rest\nwin_code[activities_map['Bird Measurer (Assessment)']] = 4110\n\n# this is the function that convert the raw data into processed features\ndef get_data(user_sample, test_set=False):\n    '''\n    The user_sample is a DataFrame from train or test where the only one \n    installation_id is filtered\n    And the test_set parameter is related with the labels processing, that is only requered\n    if test_set=False\n    '''\n    # Constants and parameters declaration\n    last_activity = 0\n    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n    \n    # news features: time spent in each activity\n    time_spent_each_act = {actv: 0 for actv in list_of_user_activities}\n    event_code_count = {eve: 0 for eve in list_of_event_code}\n    last_session_time_sec = 0\n    \n    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n    all_assessments = []\n    accumulated_accuracy_group = 0\n    accumulated_accuracy=0\n    accumulated_correct_attempts = 0 \n    accumulated_uncorrect_attempts = 0 \n    accumulated_actions = 0\n    \n    last_accuracy_title = {'acc_' + title[0:4]: -1 for title in assess_titles}\n    last_game_time_title = {'lgt_' + title[0:4]: 0 for title in assess_titles}\n    ac_game_time_title = {'agt_' + title[0:4]: 0 for title in assess_titles}\n    ac_true_attempts_title = {'ata_' + title[0:4]: 0 for title in assess_titles}\n    ac_false_attempts_title = {'afa_' + title[0:4]: 0 for title in assess_titles}\n    \n    counter = 0\n    time_first_activity = float(user_sample['timestamp'].values[0])\n    durations = []\n    time_play = 0\n    title_just_before = 0\n    title_assessment_before = 0\n    assessment_before_accuracy = 0\n    dif2030 = 0\n    dif4070 = 0\n    dif3010 = 0\n    dif3020 = 0\n    dif4030 = 0\n    dif3110 = 0\n    dif4025 = 0\n    dif4035 = 0\n    dif3120 = 0\n    dif2010 = 0\n    somme_clip_game_activity = 0\n    title_just_before = 0\n    actions_dif = 0\n    \n    # 'Cauldron Filler (Assessment)'\n    Cauldron_Filler_misses = 0\n    Cauldron_Filler_time = 0\n    count_CFA = 0\n    \n    # itarates through each session of one instalation_id\n    for i, session in user_sample.groupby('game_session', sort=False):\n        # i = game_session_id\n        # session is a DataFrame that contain only one game_session\n        \n        # get some sessions information\n        session_type = session['type'].iloc[0]\n        session_title = session['title'].iloc[0]\n        \n        # get current session time in seconds\n        if session_type != 'Assessment':\n            time_spent = int(session['game_time'].iloc[-1] / 1000)\n            time_spent_each_act[activities_labels[session_title]] += time_spent\n            time_play += time_spent\n            \n            title_just_before = session_title\n            session_title_text = activities_labels[session_title]\n                    \n        # for each assessment, and only this kind off session, the features below are processed\n        # and a register are generated\n        if (session_type == 'Assessment') & (test_set or len(session)>1):\n            # search for event_code 4100, that represents the assessments trial\n            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n            # then, check the numbers of wins and the number of losses\n            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n            # copy a dict to use as feature template, it's initialized with some itens: \n            # {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n            features = user_activities_count.copy()\n            \n            features.update(last_accuracy_title.copy())\n            features.update(last_game_time_title.copy())\n            features.update(ac_game_time_title.copy())\n            features.update(ac_true_attempts_title.copy())\n            features.update(ac_false_attempts_title.copy())\n            \n            session_title = session['title'].iloc[0]\n            time_spent = int(session['game_time'].iloc[-1] / 1000)\n            time_spent_each_act[activities_labels[session_title]] += time_spent\n            \n            features.update(time_spent_each_act.copy())\n            features.update(event_code_count.copy())\n            # add title as feature, remembering that title represents the name of the game\n            features['session_title'] = session['title'].iloc[0] \n            # the 4 lines below add the feature of the history of the trials of this player\n            # this is based on the all time attempts so far, at the moment of this assessment\n            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n            accumulated_correct_attempts += true_attempts \n            accumulated_uncorrect_attempts += false_attempts\n            \n            session_title_text = activities_labels[session_title]\n            ac_true_attempts_title['ata_' + session_title_text[0:4]] += true_attempts\n            ac_false_attempts_title['afa_' + session_title_text[0:4]] += false_attempts\n            last_game_time_title['lgt_' + session_title_text[0:4]] = session['game_time'].iloc[-1]\n            ac_game_time_title['agt_' + session_title_text[0:4]] += session['game_time'].iloc[-1]\n            \n            # the time spent in the app so far\n            if durations == []:\n                features['duration_mean'] = 0\n            else:\n                features['duration_mean'] = np.mean(durations)\n            durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n            \n            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n            accumulated_accuracy += accuracy\n            last_accuracy_title['acc_' + session_title_text[0:4]] = accuracy\n            # a feature of the current accuracy categorized\n            # it is a counter of how many times this player was in each accuracy group\n            \n            # assessment_before_accuracy\n            features['assessment_before_accuracy'] = assessment_before_accuracy\n                     \n            if accuracy == 0:\n                features['accuracy_group'] = 0\n                assessment_before_accuracy = 0\n            elif accuracy == 1:\n                features['accuracy_group'] = 3\n                assessment_before_accuracy = 3\n            elif accuracy == 0.5:\n                features['accuracy_group'] = 2\n                assessment_before_accuracy = 2\n            else:\n                features['accuracy_group'] = 1\n                assessment_before_accuracy = 1\n                \n            features.update(accuracy_groups)\n            accuracy_groups[features['accuracy_group']] += 1\n            # mean of the all accuracy groups of this player\n            features['accumulated_accuracy_group'] = accumulated_accuracy_group/counter if counter > 0 else 0\n            accumulated_accuracy_group += features['accuracy_group']\n            # how many actions the player has done so far, it is initialized as 0 and updated some lines below\n            features['accumulated_actions'] = accumulated_actions\n            \n            # encode installation_id\n            features['installation_id'] = session['installation_id'].iloc[0]\n            \n            # time play on the app\n            features['time_play'] = time_play\n            time_play += int(session['game_time'].iloc[-1] / 1000)\n            \n            # title_assessment_before\n            features['title_assessment_before'] = title_assessment_before\n            \n            # concat (session_title + title_assessment_before) / title_assessment_before is the title of the previous assessment :\n            features['title_title_assessment_before'] = int( str(session['title'].iloc[0]) + str(title_assessment_before) )\n            title_assessment_before = session['title'].iloc[0]\n            \n            # concat (session_title + title_just_before) / title_just_before is title game play just before the assessment :\n            features['title_title_just_before'] = int( str(session['title'].iloc[0]) + str(title_just_before) )\n            title_just_before = session['title'].iloc[0]\n            \n            \n            # 4070 dif\n            if features['Assessment'] == 0:\n                features['4070_dif'] = features[4070]\n                dif4070 = features[4070]\n            else:\n                features['4070_dif'] = features[4070] - dif4070\n                dif4070 = features[4070]\n                \n            # 2030 dif\n            if features['Assessment'] == 0:\n                features['2030_dif'] = features[2030]\n                dif2030 = features[2030]\n            else:\n                features['2030_dif'] = features[2030] - dif2030\n                dif2030 = features[2030]\n                \n            # 3010 dif\n            if features['Assessment'] == 0:\n                features['3010_dif'] = features[3010]\n                dif3010 = features[3010]\n            else:\n                features['3010_dif'] = features[3010] - dif3010\n                dif3010 = features[3010]\n                \n            # 3020 dif\n            if features['Assessment'] == 0:\n                features['3020_dif'] = features[3020]\n                dif3020 = features[3020]\n            else:\n                features['3020_dif'] = features[3020] - dif3020\n                dif3020 = features[3020]\n                \n            # 4030 dif\n            if features['Assessment'] == 0:\n                features['4030_dif'] = features[4030]\n                dif4030 = features[4030]\n            else:\n                features['4030_dif'] = features[4030] - dif4030\n                dif4030 = features[4030]\n                \n            # 3110 dif\n            if features['Assessment'] == 0:\n                features['3110_dif'] = features[3110]\n                dif3110 = features[3110]\n            else:\n                features['3110_dif'] = features[3110] - dif3110\n                dif3110 = features[3110]\n                \n            # 4035 dif\n            if features['Assessment'] == 0:\n                features['4035_dif'] = features[4035]\n                dif4035 = features[4035]\n            else:\n                features['4035_dif'] = features[4035] - dif4035\n                dif4035 = features[4035]\n                \n            # 4025 dif\n            if features['Assessment'] == 0:\n                features['4025_dif'] = features[4025]\n                dif4025 = features[4025]\n            else:\n                features['4025_dif'] = features[4025] - dif4025\n                dif4025 = features[4025]\n                \n            # 3120 dif\n            if features['Assessment'] == 0:\n                features['3120_dif'] = features[3120]\n                dif3120 = features[3120]\n            else:\n                features['3120_dif'] = features[3120] - dif3120\n                dif3120 = features[3120]\n                \n            # 2010 dif\n            if features['Assessment'] == 0:\n                features['2010_dif'] = features[2010]\n                dif2010 = features[2010]\n            else:\n                features['2010_dif'] = features[2010] - dif2010\n                dif2010 = features[2010]\n                \n                \n            # time play assessment\n            features['time_play_assessment'] = sum(durations)\n            \n            # clip+game+activity before assessment\n            somme = features['Clip']+features['Game']+features['Activity']\n            features['somme_clip_game_activity'] = somme - somme_clip_game_activity\n            somme_clip_game_activity = somme\n            \n            # somme actions 4070 + 2030 + 4030 / accumulated_actions :\n            mean_actions = (features[4070] + features[4030] + features[2030]) / (features['accumulated_actions']+1)\n            features['mean_actions'] = mean_actions\n            \n            # actions dif\n            if features['Assessment'] == 0:\n                features['actions_dif'] = features['accumulated_actions']\n                actions_dif = features['accumulated_actions']\n            else:\n                features['actions_dif'] = features['accumulated_actions'] - actions_dif\n                actions_dif = features['accumulated_actions']\n            \n            # somme actions 4070_dif + 2030_dif + 4030_dif / actions_dif :\n            mean_actions = (features['4070_dif'] + features['4030_dif'] + features['2030_dif']) / (features['actions_dif']+1)\n            features['mean_actions_dif'] = mean_actions\n            \n            \n            # new features :\n\n            features['Cauldron_Filler_misses'] = Cauldron_Filler_misses\n            features['Cauldron_Filler_time'] = Cauldron_Filler_time\n            \n            if count_CFA == 0:\n                if session['title'].iloc[0] == activities_map['Cauldron Filler (Assessment)']:\n                    L = session.event_id.unique()\n                    if '392e14df' in L:\n                        if json.loads(session[session.event_id.isin(['392e14df'])].iloc[0]['event_data'])['correct'] == True:\n                            Cauldron_Filler_misses = 2\n                        else:\n                            Cauldron_Filler_misses = 1       \n                        Cauldron_Filler_time= session[session.event_id.isin(['392e14df'])].iloc[0]['game_time'] / 1000\n                    else:\n                        Cauldron_Filler_misses = -1\n                    count_CFA = 1\n                    \n            # there are some conditions to allow this features to be inserted in the datasets\n            # if it's a test set, all sessions belong to the final dataset\n            # it it's a train, needs to be passed throught this clausule: session.query(f'event_code == {win_code[session_title]}')\n            # that means, must exist an event_code 4100 or 4110\n            if test_set:\n                all_assessments.append(features)\n            elif true_attempts+false_attempts > 0:\n                all_assessments.append(features)\n                \n            counter += 1\n        \n        # this piece counts how many actions was made in each event_code so far\n        n_of_event_codes = Counter(session['event_code'])\n        \n        for key in n_of_event_codes.keys():\n            event_code_count[key] += n_of_event_codes[key]\n\n        # counts how many actions the player has done so far, used in the feature of the same name\n        accumulated_actions += len(session)\n        if last_activity != session_type:\n            user_activities_count[session_type] += 1\n            last_activitiy = session_type\n    # if it't the test_set, only the last assessment must be predicted, the previous are scraped\n    if test_set:\n        return all_assessments[-1]\n    # in the train_set, all assessments goes to the dataset\n    return all_assessments[:-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"from tqdm import tqdm_notebook as tqdm\nfrom collections import Counter\n# here the get_data function is applyed to each installation_id and added to the compile_data list\ncompiled_data = []\ncompiled_data_last = []\n# tqdm is the library that draws the status bar below\nfor i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort=False)), total=3614):\n    # user_sample is a DataFrame that contains only one installation_id\n    L = get_data(user_sample)\n    compiled_data += L\n    a = get_data(user_sample,test_set=True )\n    compiled_data_last.append(a)\n\n# the compiled_data is converted to DataFrame and deleted to save memmory\nfinal_train = pd.DataFrame(compiled_data)\n# final_train_last brings together every last assessment of installation_id from train dataset :\nfinal_train_last = pd.DataFrame(compiled_data_last)\n\npd.set_option('display.max_columns', None)\n\n# final_train_last2 brings together every second last assessment of installation_id from train dataset :\n#    equivalent to bring together every last assessment of installation_id from final_train\n\n# add a column index_t helping the separation between last assessment of final_train and others assessment\nfinal_train = final_train.reset_index()\nfinal_train.rename(columns={'index':'index_t'},inplace=True)\n\n# every last assessment of installation_id from final_train\nfinal_train_last2 = final_train.groupby('installation_id', sort=False,as_index=False).last()\n\n# final_train2 = final_train  - final_train_last2\n\nnot_req=(set(final_train.index_t.unique()) - set(final_train_last2.index_t.unique()))\nfinal_train2=final_train['index_t'].isin(not_req)\nfinal_train2 = final_train.where(final_train2,try_cast=True)\nfinal_train2.dropna(inplace=True)\nfinal_train2['index_t']=final_train2.index.astype(int)\n\ncolonne = list(final_train2)\ncolonne_float = ['accumulated_accuracy_group','duration_mean','accumulated_accuracy','mean_actions','mean_actions_dif','installation_id']\nfor name in colonne:\n    if name not in colonne_float:\n        final_train2[name] = final_train2[name].astype(int)\n        \n# We do exactly the same to get every third last assessment of installation_id from train dataset:\n#    equivalent to bring together every last assessment of installation_id from final_train2\n\nfinal_train_last3 = final_train2.groupby('installation_id', sort=False,as_index=False).last()\n\nnot_req=(set(final_train2.index_t.unique()) - set(final_train_last3.index_t.unique()))\nfinal_train3=final_train2['index_t'].isin(not_req)\nfinal_train3 = final_train2.where(final_train3,try_cast=True)\nfinal_train3.dropna(inplace=True)\nfinal_train3['index_t']=final_train3.index.astype(int)\n\ncolonne = list(final_train3)\nfor name in colonne:\n    if name not in colonne_float:\n        final_train3[name] = final_train3[name].astype(int)\n        \nfinal_train_last4 = final_train3.groupby('installation_id', sort=False,as_index=False).last()\n        \nnot_req=(set(final_train3.index_t.unique()) - set(final_train_last4.index_t.unique()))\nfinal_train4=final_train3['index_t'].isin(not_req)\nfinal_train4 = final_train3.where(final_train4,try_cast=True)\nfinal_train4.dropna(inplace=True)\nfinal_train4['index_t']=final_train4.index.astype(int)\n\ncolonne = list(final_train4)\nfor name in colonne:\n    if name not in colonne_float:\n        final_train4[name] = final_train4[name].astype(int)\n        \nfinal_train = final_train.drop(['index_t'],1)\nfinal_train2 = final_train2.drop(['index_t'],1)\nfinal_train3 = final_train3.drop(['index_t'],1)\nfinal_train4 = final_train4.drop(['index_t'],1)\nfinal_train_last2 = final_train_last2.drop(['index_t'],1)\nfinal_train_last3 = final_train_last3.drop(['index_t'],1)\nfinal_train_last4 = final_train_last4.drop(['index_t'],1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**final_train** is the train_label without the last assessment of every installation_id (no data of the test dataset)\n\n**final_train_last** brings together last assesment of every installation_id of train_label\n*****\n**final_train2** is the train_label without the second and last assessments of every installation_id\n\n**final_train_last2** brings together second assessment of every installation_id of train_label\n*****\n**final_train3** is the train_label without the third, second and last assessments of every installation_id\n\n**final_train_last3** brings together third assessment of every installation_id of train_label\n******\n**final_train4** is the train_label without the fourth,third, second and last assessments of every installation_id\n\n**final_train_last4** brings together fourth assessment of every installation_id of train_label\n\n# **final_train_lastx can be see as an example of private test**"},{"metadata":{},"cell_type":"markdown","source":"# Accuracy_group distribution of final_train and final_train_last"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize = (30, 8))\nplt.subplot(1,2,1)\nfinal_train['accuracy_group'].plot(kind='hist', title=\"Accuracy_group distribution of final_train\")\nplt.subplot(1,2,2)\nfinal_train_last['accuracy_group'].plot(kind='hist',colormap='magma', title=\"Accuracy_group distribution of final_train_last\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Percentage distribution"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"table_train = pd.concat([round(final_train['accuracy_group'].value_counts() / len(final_train),2),round(final_train_last['accuracy_group'].value_counts() / len(final_train_last),2)],axis=1)\ntable_train.columns = ['final_train','final_train_last']\ntable_train['dif'] = table_train['final_train_last'] - table_train['final_train'] \ntable_train['final_train_last without_0_previous_assess'] = round(final_train_last[~final_train_last.Assessment.isin([0])]['accuracy_group'].value_counts() / len(final_train_last[~final_train_last.Assessment.isin([0])]),2)\ntable_train['dif2'] = table_train['final_train_last without_0_previous_assess'] - table_train['final_train'] \ntable_train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Look out! The difference for 0 and 3 accuracy is significant"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print(\"Distribution in final_train_last:\")\nprint('Cases where sessions have no previous assessment : {}'.format(round(len(final_train_last[final_train_last.Assessment.isin([0])])/len(final_train_last),2)))\nprint('Cases where sessions have 1 previous assessment : {}'.format(round(len(final_train_last[final_train_last.Assessment.isin([1])])/len(final_train_last),2)))\nprint('Cases where sessions have 2 or more previous assessments: : {}'.format(round(len(final_train_last[~final_train_last.Assessment.isin([0,1])])/len(final_train_last),2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Accuracy_group distribution of final_train2 and final_train_last2"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize = (30, 8))\nplt.subplot(1,2,1)\nfinal_train2['accuracy_group'].plot(kind='hist', title=\"Accuracy_group distribution of final_train2\")\nplt.subplot(1,2,2)\nfinal_train_last2['accuracy_group'].plot(kind='hist',colormap='magma', title=\"Accuracy_group distribution of final_train_last2\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"table_train2 = pd.concat([round(final_train2['accuracy_group'].value_counts() / len(final_train2),3),round(final_train_last2['accuracy_group'].value_counts() / len(final_train_last2),3)],axis=1)\ntable_train2.columns = ['final_train2','final_train_last2']\ntable_train2['dif'] = table_train2['final_train_last2'] - table_train2['final_train2']\ntable_train2['final_train_last2 without_0_previous_assess'] = round(final_train_last2[~final_train_last2.Assessment.isin([0])]['accuracy_group'].value_counts() / len(final_train_last2[~final_train_last2.Assessment.isin([0])]),3)\ntable_train2['dif2'] = table_train2['final_train_last2 without_0_previous_assess'] - table_train2['final_train2'] \ntable_train2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"installation_id are the same in **final_train2** and **final_train_last2 without_0_previous_assess** and here the average of accuracy_group improved."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print(\"Distribution in final_train_last2:\")\nprint('Cases where sessions have no previous assessment : {}'.format(round(len(final_train_last2[final_train_last2.Assessment.isin([0])])/len(final_train_last2),2)))\nprint('Cases where sessions have 1 previous assessment : {}'.format(round(len(final_train_last2[final_train_last2.Assessment.isin([1])])/len(final_train_last2),2)))\nprint('Cases where sessions have 2 or more previous assessments: : {}'.format(round(len(final_train_last2[~final_train_last2.Assessment.isin([0,1])])/len(final_train_last2),2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Accuracy_group distribution of final_train3 and final_train_last3"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize = (30, 8))\nplt.subplot(1,2,1)\nfinal_train3['accuracy_group'].plot(kind='hist', title=\"Accuracy_group distribution of final_train3\")\nplt.subplot(1,2,2)\nfinal_train_last3['accuracy_group'].plot(kind='hist',colormap='magma', title=\"Accuracy_group distribution of final_train_last3\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"table_train3 = pd.concat([round(final_train3['accuracy_group'].value_counts() / len(final_train3),3),round(final_train_last3['accuracy_group'].value_counts() / len(final_train_last3),3)],axis=1)\ntable_train3.columns = ['final_train3','final_train_last3']\ntable_train3['dif'] = table_train3['final_train_last3'] - table_train3['final_train3']\ntable_train3['final_train_last3 without_0_previous_assess'] = round(final_train_last3[~final_train_last3.Assessment.isin([0])]['accuracy_group'].value_counts() / len(final_train_last3[~final_train_last3.Assessment.isin([0])]),3)\ntable_train3['dif2'] = table_train3['final_train_last3 without_0_previous_assess'] - table_train3['final_train3']\ntable_train3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print(\"Distribution in final_train_last3:\")\nprint('Cases where sessions have no previous assessment : {}'.format(round(len(final_train_last3[final_train_last3.Assessment.isin([0])])/len(final_train_last3),2)))\nprint('Cases where sessions have 1 previous assessment : {}'.format(round(len(final_train_last3[final_train_last3.Assessment.isin([1])])/len(final_train_last3),2)))\nprint('Cases where sessions have 2 or more previous assessments: : {}'.format(round(len(final_train_last3[~final_train_last3.Assessment.isin([0,1])])/len(final_train_last3),2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Accuracy_group distribution of final_train4 and final_train_last4"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (30, 8))\nplt.subplot(1,2,1)\nfinal_train4['accuracy_group'].plot(kind='hist', title=\"Accuracy_group distribution of final_train4\")\nplt.subplot(1,2,2)\nfinal_train_last4['accuracy_group'].plot(kind='hist',colormap='magma', title=\"Accuracy_group distribution of final_train_last4\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"table_train4 = pd.concat([round(final_train4['accuracy_group'].value_counts() / len(final_train4),3),round(final_train_last4['accuracy_group'].value_counts() / len(final_train_last4),3)],axis=1)\ntable_train4.columns = ['final_train4','final_train_last4']\ntable_train4['dif'] = table_train4['final_train_last4'] - table_train4['final_train4']\ntable_train4['final_train_last4 without_0_previous_assess'] = round(final_train_last4[~final_train_last4.Assessment.isin([0])]['accuracy_group'].value_counts() / len(final_train_last4[~final_train_last4.Assessment.isin([0])]),3)\ntable_train4['dif2'] = table_train4['final_train_last4 without_0_previous_assess'] - table_train4['final_train4']\ntable_train4","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"Distribution in final_train_last4:\")\nprint('Cases where sessions have no previous assessment : {}'.format(round(len(final_train_last4[final_train_last4.Assessment.isin([0])])/len(final_train_last4),2)))\nprint('Cases where sessions have 1 previous assessment : {}'.format(round(len(final_train_last4[final_train_last4.Assessment.isin([1])])/len(final_train_last4),2)))\nprint('Cases where sessions have 2 or more previous assessments: : {}'.format(round(len(final_train_last4[~final_train_last4.Assessment.isin([0,1])])/len(final_train_last4),2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Engineering test data**"},{"metadata":{},"cell_type":"markdown","source":"**final_test** contains test data which have to be predict.\n\n**before_test** brings together other data of test dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"# process test set, the same that was done with the train set\nnew_test = []\ntest_to_train = []\nfor ins_id, user_sample in tqdm(test.groupby('installation_id', sort=False), total=1000):\n    L = get_data(user_sample)\n    a = get_data(user_sample,test_set=True )\n    new_test.append(a)\n    test_to_train += L\n    \nfinal_test = pd.DataFrame(new_test)\n# test_to_train contains data that we don't use for final_test:\nbefore_test = pd.DataFrame(test_to_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Accuracy_group distribution of before_test"},{"metadata":{"trusted":true},"cell_type":"code","source":"before_test['accuracy_group'].plot(kind='hist', title=\"Accuracy_group distribution of before_test\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The distribution is similar than other final_trainx"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"table_test = pd.DataFrame(round(before_test['accuracy_group'].value_counts() / len(before_test),2))\ntable_test.columns = ['before_test']\ntable_test['test'] = 'unknown'\ntable_test['dif'] = ['d3','d0','d1','d2']\ntable_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can maybe predict an estimation of d0,d1,d2,d3 with the LB."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print(\"Distribution in before_test:\")\nprint('Cases where sessions have no previous assessment : {}'.format(round(len(before_test[before_test.Assessment.isin([0])])/len(before_test),2)))\nprint('Cases where sessions have 1 previous assessment : {}'.format(round(len(before_test[before_test.Assessment.isin([1])])/len(before_test),2)))\nprint('Cases where sessions have 2 previous assessment : {}'.format(round(len(before_test[~before_test.Assessment.isin([0,1])])/len(before_test),2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print(\"Distribution in final_test:\")\nprint('Cases where sessions have no previous assessment : {}'.format(round(len(final_test[final_test.Assessment.isin([0])])/len(final_test),2)))\nprint('Cases where sessions have 1 previous assessment : {}'.format(round(len(final_test[final_test.Assessment.isin([1])])/len(final_test),2)))\nprint('Cases where sessions have 2 previous assessment : {}'.format(round(len(final_test[~final_test.Assessment.isin([0,1])])/len(final_test),2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\n\n* It seems in each data visualization that d1 and d2 are close to 0.\n\n* final_train_last,final_train_last2,final_train_last3,final_train_last4 have almost the same distribution of number of Assessments but the distribution of accuracy_group of** final_train_last is really different from others. **\n\n **So it seems not good to use a fix threshold in case of the private test have an accuracy_group distribution more like final_train_last.**\n \n* Investigate on the difference of distribution between final_train_last and others can maybe help for threshold.\n \n* If we put aside the distribution of final_train_last, it seems to be interesting for the threshold to give **+(0.005 to 0.02) for group 3 accuracy and -(0.005 to 0.2) for 0 accuracy from train distribution, only for installation_id that have 1 or more previous assessments**. Maybe also -(0.005 to 0.01) for group 1 accuracy"},{"metadata":{},"cell_type":"markdown","source":"<font size=4 color='red'> Upvote if you think this kernel was helpful !</font>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}