{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom xgboost import plot_importance\nfrom catboost import CatBoostRegressor\nfrom matplotlib import pyplot\nimport shap\n\nfrom time import time\nfrom tqdm import tqdm_notebook as tqdm\nfrom collections import Counter\nfrom scipy import stats\nimport lightgbm as lgb\nfrom sklearn.metrics import cohen_kappa_score, mean_squared_error\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport gc\nimport json\n\nfrom pandas.io.json import json_normalize\nimport json","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pandas.io.json import json_normalize\nimport json\nfrom tqdm import tqdm_notebook as tqdm\nfrom collections import Counter\nfrom scipy import stats as sp\nfrom scipy import optimize as spoptimize","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom functools import partial\nfrom sklearn import metrics\n#import scipy as sp\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom scipy.stats import boxcox, skew, randint, uniform\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.linear_model import Lasso, ElasticNet, Ridge, LinearRegression\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import InputLayer\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nimport gc\nimport joblib\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import metrics, preprocessing\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras import callbacks\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras import utils\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras import regularizers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/data-science-bowl-2019/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/data-science-bowl-2019/test.csv\")\ntrain_labels = pd.read_csv(\"/kaggle/input/data-science-bowl-2019/train_labels.csv\")\nspecs = pd.read_csv(\"/kaggle/input/data-science-bowl-2019/specs.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[train.installation_id.isin(train_labels.installation_id.unique())]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def json_parser(dataframe, column):\n    dataframe.reset_index(drop=True, inplace=True)\n    parsed_set = dataframe[column].apply(json.loads)\n    parsed_set = json_normalize(parsed_set)\n    parsed_set.drop(columns=['event_count', 'event_code', 'game_time'], inplace=True)\n    merged_set = pd.merge(\n        dataframe,\n        parsed_set,\n        how='inner',\n        left_index= True,\n        right_index=True\n    )\n\n    del merged_set[column]\n\n    return merged_set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode_title(train, test):\n\n    train[\"title_event_code\"] = list(map(lambda x, y : str(x) + '_' + str(y), train[\"title\"], train[\"event_code\"]))\n    test[\"title_event_code\"] = list(map(lambda x, y : str(x) + '_' + str(y), test[\"title\"], test[\"event_code\"]))\n    unique_title_event_code = list(set(train[\"title_event_code\"].unique()).union(set(test[\"title_event_code\"].unique())))\n\n    unique_titles = list(set(train[\"title\"].unique()).union(set(test[\"title\"].unique())))\n\n    unique_event_codes = list(set(train[\"event_code\"].unique()).union(set(test[\"event_code\"].unique())))\n\n    unique_worlds = list(set(train['world'].unique()).union(set(test['world'].unique())))\n\n    unique_event_ids = list(set(train['event_id'].unique()).union(set(test['event_id'].unique())))\n\n    unique_assessments = list(set(train[train['type'] == 'Assessment']['title'].value_counts().index).union(set(test[test['type'] == 'Assessment']['title'].value_counts().index)))\n\n    unique_games = list(set(train[train['type'] == 'Game']['title'].value_counts().index).union(set(test[test['type'] == 'Game']['title'].value_counts().index)))\n\n    unique_clips = list(set(train[train['type'] == 'Clip']['title'].value_counts().index).union(set(test[test['type'] == 'Clip']['title'].value_counts().index)))\n\n    unique_activitys = list(set(train[train['type'] == 'Activity']['title'].value_counts().index).union(set(test[test['type'] == 'Activity']['title'].value_counts().index)))\n\n    # convert text into datetime\n    train[\"timestamp\"] = pd.to_datetime(train[\"timestamp\"])\n    test[\"timestamp\"]  = pd.to_datetime(test[\"timestamp\"])\n\n    unique_data = {\n        \"unique_title_event_code\" : unique_title_event_code,\n        \"unique_titles\" : unique_titles,\n        \"unique_event_codes\" : unique_event_codes,\n        \"unique_worlds\" : unique_worlds,\n        \"unique_event_ids\" : unique_event_ids,\n        \"unique_assessments\" : unique_assessments,\n        \"unique_games\" : unique_games,\n        \"unique_clips\" : unique_clips,\n        \"unique_activitys\" : unique_activitys\n    }\n\n    return train, test, unique_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test, unique_data = encode_title(train, test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_data(user_sample,unique_data ,test=False):\n\n    final_features = []\n\n    features = {}\n\n    Assessments_count = {\"count_\"+ass : 0 for ass in unique_data[\"unique_assessments\"]}\n    Clips_count = {\"count_\"+clip : 0 for clip in unique_data[\"unique_clips\"]}\n    Games_count = {\"count_\"+game : 0 for game in unique_data[\"unique_games\"]}\n    Activitys_count = {\"count_\"+activity:0 for activity in unique_data[\"unique_activitys\"]}\n    Worlds_count = {\"count_\"+world:0 for world in unique_data[\"unique_worlds\"]}\n    Title_event_code_count = {etc:0 for etc in unique_data[\"unique_title_event_code\"]}\n    Event_ids_count = {uei:0 for uei in unique_data[\"unique_event_ids\"]}\n    Event_code_count = {code: 0 for code in unique_data[\"unique_event_codes\"]}\n\n    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n    accuracy_groups_game = {'game_0':0, 'game_1':0, 'game_2':0, 'game_3':0}\n\n    features[\"accumulated_false\"] = 0\n    features[\"accumulated_true\"] = 0\n    features[\"accumulated_false_ass\"] = 0\n    features[\"accumulated_true_ass\"] = 0\n\n    Clip_duration_accumulated = {\"accu_duration_\"+clip : 0 for clip in unique_data[\"unique_clips\"]}\n    Clip_duration = {\"duration_\"+clip : 0 for clip in unique_data[\"unique_clips\"]}\n\n    Games_duration_accumulated = {\"accu_duration_\"+game : 0 for game in unique_data[\"unique_games\"]}\n    Games_duration = {\"duration_\"+game : 0 for game in unique_data[\"unique_games\"]}\n\n    Activitys_duration_accumulated = {\"accu_duration_\"+activity:0 for activity in unique_data[\"unique_activitys\"]}\n    Activitys_duration = {\"duration_\"+activity:0 for activity in unique_data[\"unique_activitys\"]}\n\n    Assessments_duration_accumulated = {\"accu_duration_\"+ass : 0 for ass in unique_data[\"unique_assessments\"]}\n    Assessments_duration = {\"duration_\"+ass : 0 for ass in unique_data[\"unique_assessments\"]}\n\n    features.update(accuracy_groups)\n    features.update(accuracy_groups_game)\n\n    for i, session in user_sample.groupby(\"game_session\", sort=False):\n        \n        # i = game_session_id\n\n        session_type = session.type.iloc[0]\n        session_title = session.title.iloc[0]\n        session_world = session.world.iloc[0]\n\n        Worlds_count[\"count_\"+session_world] += 1\n\n        if session_type == \"Clip\":\n            # count\n            Clips_count[\"count_\"+session_title] += 1\n\n            # duration\n            try:\n                index = session.index.values[0]\n                duration = (user_sample.timestamp.loc[index+1] - user_sample.timestamp.loc[index]).seconds\n                Clip_duration[\"duration_\"+session_title] = duration\n                Clip_duration_accumulated[\"accu_duration_\"+session_title] += duration\n            except:\n                pass\n\n            features[\"predicted_before_title\"] = session_title\n\n        if session_type == \"Activity\":\n            # count\n            Activitys_count[\"count_\"+session_title] += 1\n\n            # duration\n            duration = round(session.game_time.iloc[-1] / 1000, 2)\n            Activitys_duration[\"duration_\"+session_title] = duration\n            Activitys_duration_accumulated[\"accu_duration_\"+session_title] += duration\n\n            features[\"predicted_before_title\"] = session_title\n\n\n        if session_type == \"Game\":\n            # count\n            Games_count[\"count_\"+session_title] += 1\n\n            # duration\n            duration = round(session.game_time.iloc[-1] / 1000, 2)\n            Games_duration[\"duration_\"+session_title] = duration\n            Games_duration_accumulated[\"accu_duration_\"+session_title] += duration\n\n            features[\"predicted_before_title\"] = session_title\n\n        if (session_type == \"Assessment\") & (test or len(session) > 1):\n            \n            predicted_title = session[\"title\"].iloc[0]\n            predicted_game_session = session[\"game_session\"].iloc[0]\n            predicted_timestamp_session = session[\"timestamp\"].iloc[0]\n\n            features[\"predicted_title\"] = predicted_title\n            features[\"installation_id\"] = session[\"installation_id\"].iloc[0]\n            features[\"game_session\"] = predicted_game_session\n            features[\"timestamp_session\"] = predicted_timestamp_session\n\n            pred_title_df = user_sample[user_sample.title == predicted_title]\n            pred_title_df = pred_title_df[pred_title_df.timestamp < predicted_timestamp_session]\n\n            predicted_assessment = {\"pred_bef_attampt\":0,\n                            \"pred_bef_true\" : np.nan,\n                            \"pred_bef_false\" : np.nan,\n                            \"pred_bef_acc_group\": np.nan,\n                            \"pred_bef_accuracy\": np.nan,\n                            \"pred_bef_timespent\" : np.nan,\n                            \"pred_bef_time_diff\":np.nan\n                            }\n            try:\n                if len(pred_title_df) > 2:\n                    for i, pred_session in pred_title_df.groupby(\"game_session\", sort=False):\n                        predicted_assessment[\"pred_bef_attampt\"] += 1\n                        predicted_assessment[\"pred_bef_timespent\"] = round(pred_session.game_time.iloc[-1] / 1000, 2)\n                        \n                        if predicted_title == \"Bird Measurer (Assessment)\":\n                            predicted_data = pred_session[pred_session.event_code == 4110]\n                        else:\n                            predicted_data = pred_session[pred_session.event_code == 4100]\n\n                        true_attempts = predicted_data[predicted_data.correct == True]['correct'].count()\n                        false_attempts = predicted_data[predicted_data.correct == False]['correct'].count()\n                        accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n                        group = accuracy_groups_def(accuracy)\n\n                        predicted_assessment[\"pred_bef_true\"] = true_attempts\n                        predicted_assessment[\"pred_bef_false\"] = false_attempts\n                        predicted_assessment[\"pred_bef_accuracy\"] = accuracy\n                        predicted_assessment[\"pred_bef_acc_group\"] = group\n\n                    predicted_assessment[\"pred_bef_time_diff\"] = (predicted_timestamp_session - pred_title_df.timestamp.iloc[-1]).seconds\n            except:\n                pass\n\n            \n            counter_df = user_sample[user_sample.timestamp < predicted_timestamp_session]\n            \n            Title_event_code_count = update_counters(Title_event_code_count, \"title_event_code\", counter_df)\n            Event_ids_count = update_counters(Event_ids_count, \"event_id\", counter_df)\n            Event_code_count = update_counters(Event_code_count,\"event_code\", counter_df)\n\n            features.update(Title_event_code_count.copy())\n            features.update(Event_ids_count.copy())\n            features.update(Event_code_count.copy())\n\n            ed = AllEventDataFeatures(features, counter_df)\n            try:\n                ed.event_code_2000()\n            except:\n                pass\n            try:\n                ed.event_code_2010()\n            except:\n                pass\n            try:\n                ed.event_code_2020()\n            except:\n                pass\n\n            try:\n                ed.event_code_2030()\n            except:\n                pass\n            try:\n                ed.event_code_2025()\n            except:\n                pass\n            try:\n                ed.event_code_2035()\n            except:\n                pass\n            try:\n                ed.event_code_2040()\n            except:\n                pass\n            try:\n                ed.event_code_2050()\n            except:\n                pass\n            try:\n                ed.event_code_2060()\n            except:\n                pass\n            try:\n                ed.event_code_2070()\n            except:\n                pass\n            try:\n                ed.event_code_2075()\n            except:\n                pass\n            try:\n                ed.event_code_2080()\n            except:\n                pass\n            try:\n                ed.event_code_2081()\n            except:\n                pass\n            try:\n                ed.event_code_2083()\n            except:\n                pass\n            try:\n                ed.event_code_3010()\n            except:\n                pass\n            try:\n                ed.event_code_3020()\n            except:\n                pass\n            try:\n                ed.event_code_3021()\n            except:\n                pass\n            try:\n                ed.event_code_3110()\n            except:\n                pass\n            try:\n                ed.event_code_3120()\n                ed.event_code_3121()\n                ed.event_code_4010()\n                ed.event_code_4020()\n                ed.event_code_4021()\n                ed.event_code_4022()\n                ed.event_code_4025()\n                ed.event_code_4030()\n                ed.event_code_4031()\n                ed.event_code_4035()\n                ed.event_code_4040()\n                ed.event_code_4045()\n                ed.event_code_4050()\n                ed.event_code_4070()\n                ed.event_code_4080()\n                ed.event_code_4090()\n                ed.event_code_4095()\n                ed.event_code_4100()\n                ed.event_code_4110()\n                ed.event_code_4220()\n                ed.event_code_4230()\n                ed.event_code_4235()\n                ed.event_code_5000()\n                ed.event_code_5010()\n            except:\n                pass\n\n            edf = ed.Event_features\n            features_ed = ed.features\n\n            features.update(edf.copy())\n            features.update(features_ed.copy())\n\n\n\n            \n            features.update(predicted_assessment.copy())\n\n            features.update(Clips_count.copy())\n            features.update(Clip_duration.copy())\n            features.update(Clip_duration_accumulated.copy())\n            features.update(Games_count.copy())\n            features.update(Games_duration.copy())\n            features.update(Games_duration_accumulated.copy())\n            features.update(Activitys_count.copy())\n            features.update(Activitys_duration.copy())\n            features.update(Activitys_duration_accumulated.copy())\n            features.update(Assessments_count.copy())\n            features.update(Assessments_duration.copy())\n            features.update(Assessments_duration_accumulated.copy())\n\n\n            final_features.append(features.copy())\n\n            try:\n                # last Assessment\n                last_assessment = {\n                                \"last_bef_true\" : np.nan,\n                                \"last_bef_false\" : np.nan,\n                                \"last_bef_acc_group\": np.nan,\n                                \"last_bef_accuracy\": np.nan,\n                                \"last_bef_timespent\" : np.nan,\n                                \"last_bef_title\" : np.nan\n                                }\n\n                last_assessment[\"last_bef_timespent\"] = round(session.game_time.iloc[-1] / 1000, 2)\n\n                if predicted_title == \"Bird Measurer (Assessment)\":\n                    predicted_data = session[session.event_code == 4110]\n                else:\n                    predicted_data = session[session.event_code == 4100]\n                \n                true_attempts = predicted_data[predicted_data.correct == True]['correct'].count()\n                false_attempts = predicted_data[predicted_data.correct == False]['correct'].count()\n                accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n                group = accuracy_groups_def(accuracy)\n\n                last_assessment[\"last_bef_true\"] = true_attempts\n                last_assessment[\"last_bef_false\"] = false_attempts\n                last_assessment[\"last_bef_accuracy\"] = accuracy\n                last_assessment[\"last_bef_acc_group\"] = group\n                last_assessment[\"last_bef_title\"] = predicted_title\n\n\n                features.update(last_assessment.copy())\n        \n            except:\n                pass\n            \n\n            # count\n            Assessments_count[\"count_\"+session_title] += 1\n\n            # duration\n            duration = round(session.game_time.iloc[-1] / 1000, 2)\n            Assessments_duration[\"duration_\"+session_title] = duration\n            Assessments_duration_accumulated[\"accu_duration_\"+session_title] += duration\n\n        ed = EventDataFeatures(features, session, user_sample, session_type, session_title)\n        try:\n            ed.event_code_2000()\n        except:\n            pass\n        try:\n            ed.event_code_2010()\n        except:\n            pass\n        try:\n            ed.event_code_2020()\n        except:\n            pass\n\n        try:\n            ed.event_code_2030()\n        except:\n            pass\n        try:\n            ed.event_code_2025()\n        except:\n            pass\n        try:\n            ed.event_code_2035()\n        except:\n            pass\n        try:\n            ed.event_code_2040()\n        except:\n            pass\n        try:\n            ed.event_code_2050()\n        except:\n            pass\n        try:\n            ed.event_code_2060()\n        except:\n            pass\n        try:\n            ed.event_code_2070()\n        except:\n            pass\n        try:\n            ed.event_code_2075()\n        except:\n            pass\n        try:\n            ed.event_code_2080()\n        except:\n            pass\n        try:\n            ed.event_code_2081()\n        except:\n            pass\n        try:\n            ed.event_code_2083()\n        except:\n            pass\n        try:\n            ed.event_code_3010()\n        except:\n            pass\n        try:\n            ed.event_code_3020()\n        except:\n            pass\n        try:\n            ed.event_code_3021()\n        except:\n            pass\n        try:\n            ed.event_code_3110()\n        except:\n            pass\n        try:\n            ed.event_code_3120()\n            ed.event_code_3121()\n            ed.event_code_4010()\n            ed.event_code_4020()\n            ed.event_code_4021()\n            ed.event_code_4022()\n            ed.event_code_4025()\n            ed.event_code_4030()\n            ed.event_code_4031()\n            ed.event_code_4035()\n            ed.event_code_4040()\n            ed.event_code_4045()\n            ed.event_code_4050()\n            ed.event_code_4070()\n            ed.event_code_4080()\n            ed.event_code_4090()\n            ed.event_code_4095()\n            ed.event_code_4100()\n            ed.event_code_4110()\n            ed.event_code_4220()\n            ed.event_code_4230()\n            ed.event_code_4235()\n            ed.event_code_5000()\n            ed.event_code_5010()\n        except:\n            pass\n\n        edf = ed.Event_features\n        features_ed = ed.features\n\n        features.update(edf.copy())\n        features.update(features_ed.copy())\n\n\n\n    if test:\n        return final_features[-1]\n    else:\n        return final_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy_groups_def(accuracy):\n    if accuracy == 0:\n        return 0\n    elif accuracy == 1:\n        return 3\n    elif accuracy == 0.5:\n        return 2\n    else:\n        return 1\n\ndef update_counters(counter: dict, col:str, counter_df):\n\n    num_of_session_count = Counter(counter_df[col])\n\n    for k in num_of_session_count.keys():\n        x = k\n        counter[x] += num_of_session_count[k]\n    return counter\n\n\n\n\nclass EventDataFeatures(object):\n    def __init__(self, features, session, user_sample, session_type, session_title):\n        self.features = features\n        self.session = session\n        self.user_sample = user_sample\n        self.session_type = session_type\n        self.session_title = session_title\n        self.Event_features = {}\n        self.unique_event_codes = self.session.event_code.unique()\n\n    def event_code_2000(self):\n        pass\n\n    def event_code_2010(self):\n        \"\"\"\n        ['The exit game event is triggered when the game is quit. \n        This is used to compute things like time spent in game. \n        Depending on platform this may / may not be possible. \n        NOTE: “quit” also means navigating away from game.']\n        \"\"\"\n        if 2010 in self.unique_event_codes:\n            session_duration = self.session[self.session.event_code == 2010][\"session_duration\"].values[0]\n            self.Event_features[\"session_duration_\"+self.session_title] = round(session_duration / 1000, 2)\n\n    def event_code_2020(self):\n        \"\"\"\n        ['The start round event is triggered at the start of a round when \n        the player is prompted to weigh and arrange the chests. There is only one round per playthrough.\n         This event provides information about the game characteristics of the round (i.e. resources, objectives, setup). \n         It is used in calculating things like time spent in a round (for speed and accuracy), attempts at \n        solving a round, and the number of rounds the player has visited (exposures).']\n        \"\"\"\n        pass\n\n    def event_code_2025(self):\n        \"\"\"\n        ['The reset dinosaurs event is triggered when the player has placed the last dinosaur, \n        but not all dinosaurs are in the correct position. \n        This event provides information about the game characteristics of the round (i.e. resources, objectives, setup). \n        It is used to indicate a significant change in state during play.']\n        \n        This event is used for calculating time spent in a round and \n        the number of rounds the player has completed (completion).\n        \"\"\"\n        pass\n\n    def event_code_2030(self):\n        \"\"\"\n        ['The beat round event is triggered when the player finishes a round by filling the jar.\n         This event is used for calculating time spent in a round and\n          the number of rounds the player has completed (completion).']\n\n        \"\"\"\n        if 2030 in self.unique_event_codes:\n            rounds = self.session[self.session.event_code == 2030]\n\n            round_duration = rounds[\"duration\"].values\n            self.Event_features[\"round_duration_2030_sum_\"+self.session_title] = round_duration.sum()\n            self.Event_features[\"round_duration_2030_avg_\"+self.session_title] = round_duration.mean()\n            self.Event_features[\"round_duration_2030_std_\"+self.session_title] = round_duration.std()\n            self.Event_features[\"round_duration_2030_max_\"+self.session_title] = round_duration.max()\n            self.Event_features[\"round_duration_2030_min_\"+self.session_title] = round_duration.min()\n            self.Event_features[\"number_of_attempts_2030_\"+self.session_title] = round_duration.count()\n\n            try:\n                round_rounds = rounds[\"round\"].values\n                self.Event_features[\"round_2030_max_\"+self.session_title] = round_rounds.max()\n            except:\n                pass\n\n            try:\n                round_misses = rounds[\"misses\"].values\n                self.Event_features[\"misses_2030_sum_\"+self.session_title] = round_misses.sum()\n                self.Event_features[\"misses_2030_avg_\"+self.session_title] = round_misses.mean()\n                self.Event_features[\"misses_2030_max_\"+self.session_title] = round_misses.max()\n            except:\n                pass\n    \n    def event_code_2035(self):\n        \"\"\"\n        ['The finish filling tub event is triggered after the player finishes filling up the tub. \n        It is used to separate a section of gameplay that is different from the estimation section of the game.']\n        \"\"\"\n        if 2035 in self.unique_event_codes:\n            rounds = self.session[self.session.event_code == 2035]\n\n            round_duration = rounds[\"duration\"].values\n            self.Event_features[\"round_duration_2035_sum_\"+self.session_title] = round_duration.sum()\n            self.Event_features[\"round_duration_2035_avg_\"+self.session_title] = round_duration.mean()\n    \n    def event_code_2040(self):\n        \"\"\"\n        ['The start level event is triggered when a new level begins \n        (at the same time as the start round event for the first round in the level). \n        This event is used for calculating time spent in a level (for speed and accuracy), \n        and the number of levels the player has completed (completion).']\n        \"\"\"\n        pass\n\n    def event_code_2050(self):\n        \"\"\"\n        ['The beat level event is triggered when a level has been completed and \n        the player has cleared all rounds in the current layout (occurs at the same time as \n        the beat round event for the last round in the previous level). This event is used for \n        calculating time spent in a level (for speed and accuracy), \n        and the number of levels the player has completed (completion).']\n        \"\"\"\n        if 2050 in self.unique_event_codes:\n            level = self.session[self.session.event_code == 2050]\n\n            level_duration = level[\"duration\"].values\n            self.Event_features[\"level_duration_2050_sum_\"+self.session_title] = level_duration.sum()\n            self.Event_features[\"level_duration_2050_avg_\"+self.session_title] = level_duration.mean()\n            self.Event_features[\"level_duration_2050_std_\"+self.session_title] = level_duration.std()\n            self.Event_features[\"level_duration_2050_max_\"+self.session_title] = level_duration.max()\n            self.Event_features[\"level_duration_2050_min_\"+self.session_title] = level_duration.min()\n\n            try:\n                level_rounds = level[\"level\"].values\n                self.Event_features[\"level_2050_max_\"+self.session_title] = level_rounds.max()\n            except:\n                pass\n\n            try:\n                level_misses = level[\"misses\"].values\n                self.Event_features[\"level_misses_2050_sum_\"+self.session_title] = level_misses.sum()\n                self.Event_features[\"level_misses_2050_avg_\"+self.session_title] = level_misses.mean()\n                self.Event_features[\"level_misses_2050_sum_\"+self.session_title] = level_misses.std()\n            except:\n                pass\n\n    def event_code_2060(self):\n        \"\"\"\n        ['The start tutorial event is triggered at the start of the tutorial. \n        It is used in calculating time spent in the tutorial.']\n        \"\"\"\n        pass\n\n    def event_code_2070(self):\n        \"\"\"\n        ['The beat round event is triggered when the player finishes the tutorial. \n        This event is used for calculating time spent in the tutorial.']\n        \"\"\"\n        if 2070 in self.unique_event_codes:\n            tutorial = self.session[self.session.event_code == 2070]\n\n            tutorial_duration = tutorial[\"duration\"].values\n            self.Event_features[\"tutorial_duration_2070_sum_\"+self.session_title] = tutorial_duration.sum()\n            self.Event_features[\"tutorial_duration_2070_avg_\"+self.session_title] = tutorial_duration.mean()\n            self.Event_features[\"tutorial_duration_2070_std_\"+self.session_title] = tutorial_duration.std()\n            self.Event_features[\"tutorial_duration_2070_max_\"+self.session_title] = tutorial_duration.max()\n            self.Event_features[\"tutorial_duration_2070_min_\"+self.session_title] = tutorial_duration.min()\n    \n    def event_code_2075(self):\n        \"\"\"\n        ['The beat round event is triggered when the player skips the tutorial by clicking on the skip button.\n         This event is used for calculating time spent in the tutorial.']\n        \"\"\"\n        if 2075 in self.unique_event_codes:\n\n            tutorial = self.session[self.session.event_code == 2075]\n\n            self.Event_features[\"tutorial_skiping_count_2075_\"+self.session_title] = tutorial[\"duration\"].count()\n\n    def event_code_2080(self):\n        \"\"\"\n        ['The movie started event triggers when an intro or outro movie starts to play. \n        It identifies the movie being played. This is used to determine how long players \n        spend watching the movies (more relevant after the first play \n        through when the skip option is available).']\n        \"\"\"\n        if 2080 in self.unique_event_codes:\n\n            movie = self.session[self.session.event_code == 2080]\n\n            movie_duration = movie[\"duration\"].values\n            self.Event_features[\"movie_duration_2080_sum_\"+self.session_title] = movie_duration.sum()\n            self.Event_features[\"movie_duration_2080_avg_\"+self.session_title] = movie_duration.mean()\n            self.Event_features[\"movie_duration_2080_std_\"+self.session_title] = movie_duration.std()\n            self.Event_features[\"movie_duration_2080_max_\"+self.session_title] = movie_duration.max()\n            self.Event_features[\"movie_duration_2080_min_\"+self.session_title] = movie_duration.min()\n\n    def event_code_2081(self):\n        \"\"\"\n        ['The movie started event triggers when an intro or outro movie starts to play. \n        It identifies the movie being played. This is used to determine how long players \n        spend watching the movies (more relevant after the first play \n        through when the skip option is available).']\n        \"\"\"\n        if 2081 in self.unique_event_codes:\n\n            movie = self.session[self.session.event_code == 2081]\n\n            self.Event_features[\"movie_skiping_count_2081_\"+self.session_title] = movie[\"duration\"].count()\n    \n    def event_code_2083(self):\n        \"\"\"\n        ['The movie started event triggers when an intro or outro movie starts to play. \n        It identifies the movie being played. This is used to determine how long players \n        spend watching the movies (more relevant after the first play \n        through when the skip option is available).']\n        \"\"\"\n        if 2083 in self.unique_event_codes:\n\n            movie = self.session[self.session.event_code == 2083]\n\n            movie_duration = movie[\"duration\"].values\n            self.Event_features[\"movie_duration_2083_sum_\"+self.session_title] = movie_duration.sum()\n            self.Event_features[\"movie_duration_2083_avg_\"+self.session_title] = movie_duration.mean()\n    \n    def event_code_3010(self):\n        \"\"\"\n        ['The system-initiated instruction event occurs when the game delivers instructions to the player.\n         It contains information that describes the content of the instruction. This event differs from events 3020\n          and 3021 as it captures instructions that are not given in response to player action. \n          These events are used to determine the effectiveness of the instructions. We can answer questions like,\n         \"did players who received instruction X do better than those who did not?\"']\n        \"\"\"\n        if 3010 in self.unique_event_codes:\n\n            instruction = self.session[self.session.event_code == 3010]\n\n            instruction_duration = instruction[\"total_duration\"].values\n            self.Event_features[\"instruction_duration_3010_sum_\"+self.session_title] = instruction_duration.sum()\n            self.Event_features[\"instruction_duration_3010_avg_\"+self.session_title] = instruction_duration.mean()\n        \n            #self.Event_features[\"instruction_media_type_3010_\"+self.session_title] = instruction[\"media_type\"].values_count().index[0]\n            \n            self.Event_features[\"instruction_media_type_3010_count_\"+self.session_title] = instruction[\"media_type\"].count()\n\n    def event_code_3020(self):\n        \"\"\"\n        ['The system-initiated feedback (Incorrect) event occurs when the game starts delivering feedback \n        to the player in response to an incorrect round attempt (pressing the go button with the incorrect answer). \n        It contains information that describes the content of the instruction. These events are used to determine \n        the effectiveness of the feedback. We can answer questions like \n        \"did players who received feedback X do better than those who did not?\"']\n        \"\"\"\n        if 3020 in self.unique_event_codes:\n\n            Incorrect = self.session[self.session.event_code == 3020]\n\n            Incorrect_duration = Incorrect[\"total_duration\"].values\n            self.Event_features[\"Incorrect_duration_3020_sum_\"+self.session_title] = Incorrect_duration.sum()\n            self.Event_features[\"Incorrect_duration_3020_avg_\"+self.session_title] = Incorrect_duration.mean()\n            #self.Event_features[\"Incorrect_duration_3020_std_\"+self.session_title] = Incorrect_duration.std()\n            #self.Event_features[\"Incorrect_duration_3020_max_\"+self.session_title] = Incorrect_duration.max()\n            #self.Event_features[\"Incorrect_duration_3020_min_\"+self.session_title] = Incorrect_duration.min()\n        \n            #self.Event_features[\"Incorrect_media_type_3020_\"+self.session_title] = Incorrect[\"media_type\"].values[0]\n            \n            self.Event_features[\"Incorrect_media_type_3020_count_\"+self.session_title] = Incorrect[\"media_type\"].count()\n    \n\n    def event_code_3021(self):\n        \"\"\"\n        ['The system-initiated feedback (Correct) event occurs when the game \n        starts delivering feedback to the player in response to a correct round attempt \n        (pressing the go button with the correct answer). It contains information that describes the\n         content of the instruction, and will likely occur in conjunction with a beat round event. \n         These events are used to determine the effectiveness of the feedback. We can answer questions like, \n        \"did players who received feedback X do better than those who did not?\"']\n        \"\"\"\n        if 3021 in self.unique_event_codes:\n\n            Correct = self.session[self.session.event_code == 3021]\n\n            Correct_duration = Correct[\"total_duration\"].values\n            self.Event_features[\"Correct_duration_3021_sum_\"+self.session_title] = Correct_duration.sum()\n            self.Event_features[\"Correct_duration_3021_avg_\"+self.session_title] = Correct_duration.mean()\n            #self.Event_features[\"Correct_duration_3021_std_\"+self.session_title] = Correct_duration.std()\n            #self.Event_features[\"Correct_duration_3021_max_\"+self.session_title] = Correct_duration.max()\n            #self.Event_features[\"Correct_duration_3021_min_\"+self.session_title] = Correct_duration.min()\n        \n            #self.Event_features[\"Correct_media_type_3021_\"+self.session_title] = Correct[\"media_type\"].values[0]\n            \n            self.Event_features[\"Correct_media_type_3021_count_\"+self.session_title] = Correct[\"media_type\"].count()\n\n    def event_code_3110(self):\n        \"\"\"\n        ['The end of system-initiated instruction event occurs when the game finishes \n        delivering instructions to the player. It contains information that describes the\n         content of the instruction including duration. These events are used to determine the \n         effectiveness of the instructions and the amount of time they consume. We can answer questions like, \n        \"how much time elapsed while the game was presenting instruction?\"']\n        \"\"\"\n        if 3110 in self.unique_event_codes:\n\n            Instuction = self.session[self.session.event_code == 3110]\n\n            Instuction_duration = Instuction[\"duration\"].values\n            self.Event_features[\"Instuction_duration_3110_sum_\"+self.session_title] = Instuction_duration.sum()\n            self.Event_features[\"Instuction_duration_3110_avg_\"+self.session_title] = Instuction_duration.mean()\n            #self.Event_features[\"Instuction_duration_3110_std_\"+self.session_title] = Instuction_duration.std()\n            #self.Event_features[\"Instuction_duration_3110_max_\"+self.session_title] = Instuction_duration.max()\n            #self.Event_features[\"Instuction_duration_3110_min_\"+self.session_title] = Instuction_duration.min()\n        \n            #self.Event_features[\"Instuction_media_type_3110_\"+self.session_title] = Instuction[\"media_type\"].values[0]\n            \n            self.Event_features[\"Instuction_media_type_3110_count_\"+self.session_title] = Instuction[\"media_type\"].count()\n\n    def event_code_3120(self):\n        \"\"\"\n        ['The end of system-initiated feedback (Incorrect) event \n        occurs when the game finishes delivering feedback to the player in response\n         to an incorrect round attempt (pressing the go button with the incorrect answer). \n         It contains information that describes the content of the instruction. \n         These events are used to determine the effectiveness of the feedback. We can answer questions like,\n         “how much time elapsed while the game was presenting feedback?”']\n        \"\"\"\n        if 3120 in self.unique_event_codes:\n\n            IncorrectInstruction = self.session[self.session.event_code == 3120]\n\n            IncorrectInstruction_duration = IncorrectInstruction[\"duration\"].values\n            self.Event_features[\"IncorrectInstruction_duration_3120_sum_\"+self.session_title] = IncorrectInstruction_duration.sum()\n            self.Event_features[\"IncorrectInstruction_duration_3120_avg_\"+self.session_title] = IncorrectInstruction_duration.mean()\n            #self.Event_features[\"IncorrectInstruction_duration_3120_std_\"+self.session_title] = IncorrectInstruction_duration.std()\n            #self.Event_features[\"IncorrectInstruction_duration_3120_max_\"+self.session_title] = IncorrectInstruction_duration.max()\n            #self.Event_features[\"IncorrectInstruction_duration_3120_min_\"+self.session_title] = IncorrectInstruction_duration.min()\n        \n            #self.Event_features[\"IncorrectInstruction_media_type_3120_\"+self.session_title] = IncorrectInstruction[\"media_type\"].values[0]\n            \n            self.Event_features[\"IncorrectInstruction_media_type_3120_count_\"+self.session_title] = IncorrectInstruction[\"media_type\"].count()\n\n    def event_code_3121(self):\n        \"\"\"\n        ['The end of system-initiated feedback (Correct) event \n        occurs when the game finishes delivering feedback to the player in response\n         to an incorrect round attempt (pressing the go button with the incorrect answer). \n         It contains information that describes the content of the instruction. \n         These events are used to determine the effectiveness of the feedback. We can answer questions like,\n         “how much time elapsed while the game was presenting feedback?”']\n        \"\"\"\n        if 3121 in self.unique_event_codes:\n\n            CorrectInstruction = self.session[self.session.event_code == 3121]\n\n            CorrectInstruction_duration = CorrectInstruction[\"duration\"].values\n            self.Event_features[\"CorrectInstruction_duration_3121_sum_\"+self.session_title] = CorrectInstruction_duration.sum()\n            self.Event_features[\"CorrectInstruction_duration_3121_avg_\"+self.session_title] = CorrectInstruction_duration.mean()\n            #self.Event_features[\"CorrectInstruction_duration_3121_std_\"+self.session_title] = CorrectInstruction_duration.std()\n            #self.Event_features[\"CorrectInstruction_duration_3121_max_\"+self.session_title] = CorrectInstruction_duration.max()\n            #self.Event_features[\"CorrectInstruction_duration_3121_min_\"+self.session_title] = CorrectInstruction_duration.min()\n        \n            #self.Event_features[\"CorrectInstruction_media_type_3121_\"+self.session_title] = CorrectInstruction[\"media_type\"].values[0]\n            \n            self.Event_features[\"CorrectInstruction_media_type_3121_count_\"+self.session_title] = CorrectInstruction[\"media_type\"].count()\n\n\n    def event_code_4010(self):\n        \"\"\"\n\n        ['This event occurs when the player clicks to start \n        the game from the starting screen.']\n        \n        \"\"\"\n\n        if 4010 in self.unique_event_codes:\n            \n\n            click_start = self.session[self.session.event_code == 4010]\n            index = click_start.index.values[0]\n            duration = (self.user_sample.timestamp.loc[index] - self.user_sample.timestamp.loc[index-1]).seconds\n\n            self.Event_features[\"click_start_duration_4010_\"+self.session_title] = duration\n    \n    def event_code_4020(self):\n        \"\"\"\n        ['This event occurs when the player \n        clicks a group of objects. It contains information \n        about the group clicked, the state of the game, and the\n         correctness of the action. This event is \n         to diagnose player strategies and understanding.']\n\n         It contains information about the state of the game and the correctness of the action. This event is used \n         to diagnose player strategies and understanding.\n        \"\"\"\n        \n        if 4020 in self.unique_event_codes:\n\n            event_data = self.session[self.session.event_code == 4020]\n\n            if self.session_title == \"Bottle Filler (Activity)\":\n                true_attempts = event_data[event_data.jar_filled == True]['jar_filled'].count()\n                false_attempts = event_data[event_data.jar_filled == False]['jar_filled'].count()\n                accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n\n                self.Event_features[\"True_attempts_4020_\"+self.session_title] = true_attempts\n                self.Event_features[\"False_attempts_4020_\"+self.session_title] = false_attempts\n                self.Event_features[\"Accuracy_attempts_4020_\"+self.session_title] = accuracy\n                \n                group = accuracy_groups_def(accuracy)\n\n                self.features['game_'+str(group)] += 1\n                self.features[\"accumulated_false\"] += false_attempts\n                self.features[\"accumulated_true\"] += true_attempts\n\n            elif self.session_title == 'Sandcastle Builder (Activity)':\n                sandcastle_duration = event_data[\"duration\"].values\n                self.Event_features[\"sandcastle_duration_4020_sum_\"+self.session_title] = sandcastle_duration.sum()\n                self.Event_features[\"sandcastle_duration_4020_avg_\"+self.session_title] = sandcastle_duration.mean()\n                #self.Event_features[\"sandcastle_duration_4020_std_\"+self.session_title] = sandcastle_duration.std()\n                #self.Event_features[\"sandcastle_duration_4020_max_\"+self.session_title] = sandcastle_duration.max()\n                #self.Event_features[\"sandcastle_duration_4020_min_\"+self.session_title] = sandcastle_duration.min()\n\n            elif self.session_title == \"Cart Balancer (Assessment)\":\n                try:\n                    true_attempts = event_data[event_data.size == 'left']['size'].count()\n                    false_attempts = event_data[event_data.size == 'right']['size'].count()\n                    accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n\n                    self.Event_features[\"Left_attempts_4020_\"+self.session_title] = true_attempts\n                    self.Event_features[\"Right_attempts_4020_\"+self.session_title] = false_attempts\n                    self.Event_features[\"Accuracy_attempts_4020_\"+self.session_title] = accuracy\n                    \n                    \n                    \n                    group = accuracy_groups_def(accuracy)\n                    self.features['game_'+str(group)] += 1\n\n                    self.features[\"accumulated_false\"] += false_attempts\n                    self.features[\"accumulated_true\"] += true_attempts\n                except:\n                    pass\n\n            elif self.session_title == \"Fireworks (Activity)\":\n                true_attempts = event_data[event_data.launched == True]['launched'].count()\n                false_attempts = event_data[event_data.launched == False]['launched'].count()\n                accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n\n                self.Event_features[\"True_attempts_4020_\"+self.session_title] = true_attempts\n                self.Event_features[\"False_attempts_4020_\"+self.session_title] = false_attempts\n                self.Event_features[\"Accuracy_attempts_4020_\"+self.session_title] = accuracy\n                \n                group = accuracy_groups_def(accuracy)\n                self.features['game_'+str(group)] += 1\n                \n                \n                self.features[\"accumulated_false\"] += false_attempts\n                self.features[\"accumulated_true\"] += true_attempts\n\n                rocket_duration = event_data[\"duration\"].values\n                self.Event_features[\"rocket_duration_4020_sum_\"+self.session_title] = rocket_duration.sum()\n                self.Event_features[\"rocket_duration_4020_avg_\"+self.session_title] = rocket_duration.mean()\n                self.Event_features[\"rocket_duration_4020_std_\"+self.session_title] = rocket_duration.std()\n                self.Event_features[\"rocket_duration_4020_max_\"+self.session_title] = rocket_duration.max()\n                self.Event_features[\"rocket_duration_4020_min_\"+self.session_title] = rocket_duration.min()\n\n                rocket_height = event_data[\"height\"].values\n                self.Event_features[\"rocket_height_4020_sum_\"+self.session_title] = rocket_height.sum()\n                self.Event_features[\"rocket_height_4020_avg_\"+self.session_title] = rocket_height.mean()\n                self.Event_features[\"rocket_height_4020_std_\"+self.session_title] = rocket_height.std()\n                self.Event_features[\"rocket_height_4020_max_\"+self.session_title] = rocket_height.max()\n                self.Event_features[\"rocket_height_4020_min_\"+self.session_title] = rocket_height.min()\n\n            elif self.session_title == \"Watering Hole (Activity)\":\n                \n                water_level = event_data[\"water_level\"].values\n                self.Event_features[\"water_level_4020_sum_\"+self.session_title] = water_level.sum()\n                self.Event_features[\"water_level_4020_avg_\"+self.session_title] = water_level.mean()\n                self.Event_features[\"water_level_4020_std_\"+self.session_title] = water_level.std()\n                self.Event_features[\"water_level_4020_max_\"+self.session_title] = water_level.max()\n                self.Event_features[\"water_level_4020_min_\"+self.session_title] = water_level.min()\n\n            elif self.session_title == \"Chicken Balancer (Activity)\":\n                \n                true_attempts = event_data[event_data[\"layout.right.pig\"] == True]['layout.right.pig'].count()\n                false_attempts = event_data[event_data[\"layout.right.pig\"] == False]['layout.right.pig'].count()\n                accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n\n                self.Event_features[\"True_attempts_4020_\"+self.session_title] = true_attempts\n                self.Event_features[\"False_attempts_4020_\"+self.session_title] = false_attempts\n                self.Event_features[\"Accuracy_attempts_4020_\"+self.session_title] = accuracy\n\n            elif self.session_title == 'Flower Waterer (Activity)':\n                \n                flower_duration = event_data[\"duration\"].values\n                self.Event_features[\"flower_duration_4020_sum_\"+self.session_title] = flower_duration.sum()\n                self.Event_features[\"flower_duration_4020_avg_\"+self.session_title] = flower_duration.mean()\n                #self.Event_features[\"flower_duration_4020_std_\"+self.session_title] = flower_duration.std()\n                #self.Event_features[\"flower_duration_4020_max_\"+self.session_title] = flower_duration.max()\n                #self.Event_features[\"flower_duration_4020_min_\"+self.session_title] = flower_duration.min()\n            \n            elif self.session_title == \"Egg Dropper (Activity)\":\n                \n                true_attempts = event_data[event_data[\"gate.side\"] == 'left']['gate.side'].count()\n                false_attempts = event_data[event_data[\"gate.side\"] == 'right']['gate.side'].count()\n                accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n\n                self.Event_features[\"Left_attempts_4020_\"+self.session_title] = true_attempts\n                self.Event_features[\"Right_attempts_4020_\"+self.session_title] = false_attempts\n                self.Event_features[\"Accuracy_attempts_4020_\"+self.session_title] = accuracy\n\n            else:\n                true_attempts = event_data[event_data.correct == True]['correct'].count()\n                false_attempts = event_data[event_data.correct == False]['correct'].count()\n                accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n\n                self.Event_features[\"True_attempts_4020_\"+self.session_title] = true_attempts\n                self.Event_features[\"False_attempts_4020_\"+self.session_title] = false_attempts\n                self.Event_features[\"Accuracy_attempts_4020_\"+self.session_title] = accuracy\n                \n                \n                \n                group = accuracy_groups_def(accuracy)\n                self.features['game_'+str(group)] += 1\n                \n                self.features[\"accumulated_false\"] += false_attempts\n                self.features[\"accumulated_true\"] += true_attempts\n\n    def event_code_4021(self):\n\n        if 4021 in self.unique_event_codes:\n\n            event_data = self.session[self.session.event_code == 4021]\n\n            if self.session_title == \"Sandcastle Builder (Activity)\":\n                amount_sand = event_data[\"sand\"].values\n                self.Event_features[\"amount_sand_4020_sum_\"+self.session_title] = amount_sand.sum()\n                self.Event_features[\"amount_sand_4020_avg_\"+self.session_title] = amount_sand.mean()\n                #self.Event_features[\"amount_sand_4020_std_\"+self.session_title] = amount_sand.std()\n                self.Event_features[\"amount_sand_4020_max_\"+self.session_title] = amount_sand.max()\n                #self.Event_features[\"amount_sand_4020_min_\"+self.session_title] = amount_sand.min()\n            \n            elif self.session_title == 'Watering Hole (Activity)':\n                cloud_size = event_data[\"cloud_size\"].values\n                self.Event_features[\"cloud_size_4020_sum_\"+self.session_title] = cloud_size.sum()\n                self.Event_features[\"cloud_size_4020_avg_\"+self.session_title] = cloud_size.mean()\n                #self.Event_features[\"cloud_size_4020_std_\"+self.session_title] = cloud_size.std()\n                self.Event_features[\"cloud_size_4020_max_\"+self.session_title] = cloud_size.max()\n                #self.Event_features[\"cloud_size_4020_min_\"+self.session_title] = cloud_size.min()\n            else:\n                pass\n    \n    def event_code_4022(self):\n        pass\n\n    def event_code_4025(self):\n        if 4025 in self.unique_event_codes:\n\n            event_data = self.session[self.session.event_code == 4025]\n\n            if self.session_title == \"Cauldron Filler (Assessment)\":\n                true_attempts = event_data[event_data.correct == True]['correct'].count()\n                false_attempts = event_data[event_data.correct == False]['correct'].count()\n                accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n\n                self.Event_features[\"True_attempts_4025_\"+self.session_title] = true_attempts\n                self.Event_features[\"False_attempts_4025_\"+self.session_title] = false_attempts\n                self.Event_features[\"Accuracy_attempts_4025_\"+self.session_title] = accuracy\n                \n                group = accuracy_groups_def(accuracy)\n                self.features['game_'+str(group)] += 1\n                \n                self.features[\"accumulated_false\"] += false_attempts\n                self.features[\"accumulated_true\"] += true_attempts\n            \n            elif self.session_title == \"Bug Measurer (Activity)\":\n\n                self.Event_features[\"Bug_length_max_4025_\"+self.session_title] = event_data[\"buglength\"].max()\n                self.Event_features[\"Number_of_Bugs_4025_\"+self.session_title] = event_data[\"buglength\"].count()\n            \n            else:\n                pass\n\n    def event_code_4030(self):\n        pass\n\n    def event_code_4031(self):\n        pass\n\n    def event_code_4035(self):\n\n        if 4035 in self.unique_event_codes:\n\n            event_data = self.session[self.session.event_code == 4035]\n\n            self.Event_features[\"wrong_place_count_4035_\"+self.session_title] = len(event_data)\n\n            if self.session_title == \"All Star Sorting\":\n\n                wrong_place = event_data[\"duration\"].values\n                self.Event_features[\"wrong_place_duration_4035_sum_\"+self.session_title] = wrong_place.sum()\n                self.Event_features[\"wrong_place_duration_4035_avg_\"+self.session_title] = wrong_place.mean()\n                #self.Event_features[\"wrong_place_duration_4035_std_\"+self.session_title] = wrong_place.std()\n                #self.Event_features[\"wrong_place_duration_4035_max_\"+self.session_title] = wrong_place.max()\n                #self.Event_features[\"wrong_place_duration_4035_min_\"+self.session_title] = wrong_place.min()\n\n            elif self.session_title == \"Bug Measurer (Activity)\":\n\n                wrong_place = event_data[\"duration\"].values\n                self.Event_features[\"wrong_place_duration_4035_sum_\"+self.session_title] = wrong_place.sum()\n                self.Event_features[\"wrong_place_duration_4035_avg_\"+self.session_title] = wrong_place.mean()\n                #self.Event_features[\"wrong_place_duration_4035_std_\"+self.session_title] = wrong_place.std()\n                #self.Event_features[\"wrong_place_duration_4035_max_\"+self.session_title] = wrong_place.max()\n                #self.Event_features[\"wrong_place_duration_4035_min_\"+self.session_title] = wrong_place.min()\n\n            elif self.session_title == \"Pan Balance\":\n                pass\n\n            elif self.session_title == \"Chicken Balancer (Activity)\":\n                wrong_place = event_data[\"duration\"].values\n                self.Event_features[\"wrong_place_duration_4035_sum_\"+self.session_title] = wrong_place.sum()\n                self.Event_features[\"wrong_place_duration_4035_avg_\"+self.session_title] = wrong_place.mean()\n                #self.Event_features[\"wrong_place_duration_4035_std_\"+self.session_title] = wrong_place.std()\n                #self.Event_features[\"wrong_place_duration_4035_max_\"+self.session_title] = wrong_place.max()\n                #self.Event_features[\"wrong_place_duration_4035_min_\"+self.session_title] = wrong_place.min()\n\n            elif self.session_title == \"Chest Sorter (Assessment)\":\n\n                wrong_place = event_data[\"duration\"].values\n                self.Event_features[\"wrong_place_duration_4035_sum_\"+self.session_title] = wrong_place.sum()\n                self.Event_features[\"wrong_place_duration_4035_avg_\"+self.session_title] = wrong_place.mean()\n                #self.Event_features[\"wrong_place_duration_4035_std_\"+self.session_title] = wrong_place.std()\n                #self.Event_features[\"wrong_place_duration_4035_max_\"+self.session_title] = wrong_place.max()\n                #self.Event_features[\"wrong_place_duration_4035_min_\"+self.session_title] = wrong_place.min()\n\n            else:\n\n                try:\n                    wrong_place = event_data[\"duration\"].values\n                    self.Event_features[\"wrong_place_duration_4035_sum_\"+self.session_title] = wrong_place.sum()\n                    self.Event_features[\"wrong_place_duration_4035_avg_\"+self.session_title] = wrong_place.mean()\n                    #self.Event_features[\"wrong_place_duration_4035_std_\"+self.session_title] = wrong_place.std()\n                    #self.Event_features[\"wrong_place_duration_4035_max_\"+self.session_title] = wrong_place.max()\n                    #self.Event_features[\"wrong_place_duration_4035_min_\"+self.session_title] = wrong_place.min()\n                except:\n                    pass\n    \n    def event_code_4040(self):\n        pass\n\n    def event_code_4045(self):\n        pass\n\n    def event_code_4050(self):\n        pass\n\n    def event_code_4070(self):\n        \"\"\"\n        \n        ['This event occurs when the player clicks on\n            something that isn’t covered elsewhere. \n            It can be useful in determining if there are\n            attractive distractions (things the player think\n            should do something, but don’t) in the game, or\n            diagnosing players \n            who are having mechanical difficulties (near misses).']\n        \"\"\"\n        if 4070 in self.unique_event_codes:\n\n            event_data = self.session[self.session.event_code == 4070]\n\n            self.Event_features[\"something_not_covered_count_4070_\"+self.session_title] = len(event_data)\n\n    def event_code_4080(self):\n\n        if 4080 in self.unique_event_codes:\n\n            event_data = self.session[self.session.event_code == 4080]\n\n            self.Event_features[\"mouse_over_count_4080_\"+self.session_title] = len(event_data)\n\n            try:\n\n                dwell_time = event_data[\"dwell_time\"].values\n                self.Event_features[\"dwell_time_duration_4080_sum_\"+self.session_title] = dwell_time.sum()\n                self.Event_features[\"dwell_time_duration_4080_avg_\"+self.session_title] = dwell_time.mean()\n                self.Event_features[\"dwell_time_duration_4080_std_\"+self.session_title] = dwell_time.std()\n                self.Event_features[\"dwell_time_duration_4080_max_\"+self.session_title] = dwell_time.max()\n                self.Event_features[\"dwell_time_duration_4080_min_\"+self.session_title] = dwell_time.min()\n            \n            except:\n                pass\n\n    def event_code_4090(self):\n\n        if 4090 in self.unique_event_codes:\n\n            event_data = self.session[self.session.event_code == 4090]\n\n            self.Event_features[\"Player_help_count_4090_\"+self.session_title] = len(event_data)\n\n    def event_code_4095(self):\n\n        if 4095 in self.unique_event_codes:\n\n            event_data = self.session[self.session.event_code == 4095]\n\n            self.Event_features[\"Plage_again_4095_\"+self.session_title] = len(event_data)\n        \n    def event_code_4100(self):\n        \n        if 4100 in self.unique_event_codes:\n\n            event_data = self.session[self.session.event_code == 4100]\n\n            true_attempts = event_data[event_data.correct == True]['correct'].count()\n            false_attempts = event_data[event_data.correct == False]['correct'].count()\n            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n\n            self.Event_features[\"True_attempts_4100_\"+self.session_title] = true_attempts\n            self.Event_features[\"False_attempts_4100_\"+self.session_title] = false_attempts\n            self.Event_features[\"Accuracy_attempts_4100_\"+self.session_title] = accuracy\n            \n            group = accuracy_groups_def(accuracy)\n            self.features[group] += 1\n            \n            self.features[\"accumulated_false_ass\"] += false_attempts\n            self.features[\"accumulated_true_ass\"] += true_attempts\n\n    def event_code_4110(self):\n        \n\n        if 4110 in self.unique_event_codes:\n\n            event_data = self.session[self.session.event_code == 4110]\n\n            true_attempts = event_data[event_data.correct == True]['correct'].count()\n            false_attempts = event_data[event_data.correct == False]['correct'].count()\n            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n\n            self.Event_features[\"True_attempts_4110_\"+self.session_title] = true_attempts\n            self.Event_features[\"False_attempts_4110_\"+self.session_title] = false_attempts\n            self.Event_features[\"Accuracy_attempts_4110_\"+self.session_title] = accuracy\n            \n            group = accuracy_groups_def(accuracy)\n            self.features[group] += 1\n            \n            self.features[\"accumulated_false_ass\"] += false_attempts\n            self.features[\"accumulated_true_ass\"] += true_attempts\n            \n\n    def event_code_4220(self):\n        pass\n\n    def event_code_4230(self):\n        pass\n\n    def event_code_4235(self):\n        pass\n\n    def event_code_5000(self):\n        pass\n\n    def event_code_5010(self):\n        pass\n\n\ndef FeaturesGeneration(x, feature_name):\n    feature_dict = dict()\n\n    feature_dict['mean'+feature_name] = np.mean(x)\n    feature_dict['max'+feature_name] = np.max(x)\n    feature_dict['min'+feature_name] = np.min(x)\n    feature_dict['std'+feature_name] = np.std(x)\n    feature_dict['var'+feature_name] = np.var(x)\n    feature_dict['ptp'+feature_name] = np.ptp(x)\n    feature_dict['percentile_10'+feature_name] = np.percentile(x, 10)\n    feature_dict['percentile_20'+feature_name] = np.percentile(x, 20)\n    feature_dict['percentile_30'+feature_name] = np.percentile(x, 30)\n    feature_dict['percentile_40'+feature_name] = np.percentile(x, 40)\n    feature_dict['percentile_50'+feature_name] = np.percentile(x, 50)\n    feature_dict['percentile_60'+feature_name] = np.percentile(x, 60)\n    feature_dict['percentile_70'+feature_name] = np.percentile(x, 70)\n    feature_dict['percentile_80'+feature_name] = np.percentile(x, 80)\n    feature_dict['percentile_90'+feature_name] = np.percentile(x, 90)\n\n    # scipy\n    feature_dict['skew'+feature_name] = sp.stats.skew(x)\n    feature_dict['kurtosis'+feature_name] = sp.stats.kurtosis(x)\n    feature_dict['kstat_1'+feature_name] = sp.kstat(x, 1)\n    feature_dict['kstat_2'+feature_name] = sp.kstat(x, 2)\n    feature_dict['kstat_3'+feature_name] = sp.kstat(x, 3)\n    feature_dict['kstat_4'+feature_name] = sp.kstat(x, 4)\n    feature_dict['moment_1'+feature_name] = sp.stats.moment(x, 1)\n    feature_dict['moment_2'+feature_name] = sp.stats.moment(x, 2)\n    feature_dict['moment_3'+feature_name] = sp.stats.moment(x, 3)\n    feature_dict['moment_4'+feature_name] = sp.stats.moment(x, 4)\n\n    return feature_dict\n\n\nclass AllEventDataFeatures(object):\n    def __init__(self, features, user_sample):\n        self.features = features\n        self.user_sample = user_sample\n        self.Event_features = {}\n        self.unique_event_codes = self.user_sample.event_code.unique()\n\n    def event_code_2000(self):\n        pass\n\n    def event_code_2010(self):\n        \"\"\"\n        ['The exit game event is triggered when the game is quit. \n        This is used to compute things like time spent in game. \n        Depending on platform this may / may not be possible. \n        NOTE: “quit” also means navigating away from game.']\n        \"\"\"\n        if 2010 in self.unique_event_codes:\n            session_duration = self.user_sample[self.user_sample.event_code == 2010][\"session_duration\"].values\n            features_2010 = FeaturesGeneration(session_duration, \"_2010\")\n            self.Event_features.update(features_2010.copy())\n\n    def event_code_2020(self):\n        \"\"\"\n        ['The start round event is triggered at the start of a round when \n        the player is prompted to weigh and arrange the chests. There is only one round per playthrough.\n         This event provides information about the game characteristics of the round (i.e. resources, objectives, setup). \n         It is used in calculating things like time spent in a round (for speed and accuracy), attempts at \n        solving a round, and the number of rounds the player has visited (exposures).']\n        \"\"\"\n        pass\n\n    def event_code_2025(self):\n        \"\"\"\n        ['The reset dinosaurs event is triggered when the player has placed the last dinosaur, \n        but not all dinosaurs are in the correct position. \n        This event provides information about the game characteristics of the round (i.e. resources, objectives, setup). \n        It is used to indicate a significant change in state during play.']\n        \n        This event is used for calculating time spent in a round and \n        the number of rounds the player has completed (completion).\n        \"\"\"\n        pass\n\n    def event_code_2030(self):\n        \"\"\"\n        ['The beat round event is triggered when the player finishes a round by filling the jar.\n         This event is used for calculating time spent in a round and\n          the number of rounds the player has completed (completion).']\n\n        \"\"\"\n        if 2030 in self.unique_event_codes:\n            rounds = self.user_sample[self.user_sample.event_code == 2030]\n\n            round_duration = rounds[\"duration\"].values\n            \n            features_2030 = FeaturesGeneration(round_duration, \"_2030\")\n            self.Event_features.update(features_2030.copy())\n            \n\n            try:\n                round_misses = rounds[\"misses\"].values\n\n                features_2030 = FeaturesGeneration(round_misses, \"_2030_misses\")\n                self.Event_features.update(features_2030.copy())\n            except:\n                pass\n    \n    def event_code_2035(self):\n        \"\"\"\n        ['The finish filling tub event is triggered after the player finishes filling up the tub. \n        It is used to separate a section of gameplay that is different from the estimation section of the game.']\n        \"\"\"\n        if 2035 in self.unique_event_codes:\n            rounds = self.user_sample[self.user_sample.event_code == 2035]\n\n            round_duration = rounds[\"duration\"].values\n            features_2035 = FeaturesGeneration(round_duration, \"_2035\")\n            self.Event_features.update(features_2035.copy())\n    \n    def event_code_2040(self):\n        \"\"\"\n        ['The start level event is triggered when a new level begins \n        (at the same time as the start round event for the first round in the level). \n        This event is used for calculating time spent in a level (for speed and accuracy), \n        and the number of levels the player has completed (completion).']\n        \"\"\"\n        pass\n\n    def event_code_2050(self):\n        \"\"\"\n        ['The beat level event is triggered when a level has been completed and \n        the player has cleared all rounds in the current layout (occurs at the same time as \n        the beat round event for the last round in the previous level). This event is used for \n        calculating time spent in a level (for speed and accuracy), \n        and the number of levels the player has completed (completion).']\n        \"\"\"\n        if 2050 in self.unique_event_codes:\n            level = self.user_sample[self.user_sample.event_code == 2050]\n\n            level_duration = level[\"duration\"].values\n            features_2050 = FeaturesGeneration(level_duration, \"_2050\")\n            self.Event_features.update(features_2050.copy())\n\n\n    def event_code_2060(self):\n        \"\"\"\n        ['The start tutorial event is triggered at the start of the tutorial. \n        It is used in calculating time spent in the tutorial.']\n        \"\"\"\n        pass\n\n    def event_code_2070(self):\n        \"\"\"\n        ['The beat round event is triggered when the player finishes the tutorial. \n        This event is used for calculating time spent in the tutorial.']\n        \"\"\"\n        if 2070 in self.unique_event_codes:\n            tutorial = self.user_sample[self.user_sample.event_code == 2070]\n\n            tutorial_duration = tutorial[\"duration\"].values\n            \n            features_2070 = FeaturesGeneration(tutorial_duration, \"_2070\")\n            self.Event_features.update(features_2070.copy())\n    \n    def event_code_2075(self):\n        \"\"\"\n        ['The beat round event is triggered when the player skips the tutorial by clicking on the skip button.\n         This event is used for calculating time spent in the tutorial.']\n        \"\"\"\n        pass\n\n    def event_code_2080(self):\n        \"\"\"\n        ['The movie started event triggers when an intro or outro movie starts to play. \n        It identifies the movie being played. This is used to determine how long players \n        spend watching the movies (more relevant after the first play \n        through when the skip option is available).']\n        \"\"\"\n        if 2080 in self.unique_event_codes:\n\n            movie = self.user_sample[self.user_sample.event_code == 2080]\n\n            movie_duration = movie[\"duration\"].values\n            \n            features_2080 = FeaturesGeneration(movie_duration, \"_2080\")\n            self.Event_features.update(features_2080.copy())\n\n    def event_code_2081(self):\n        \"\"\"\n        ['The movie started event triggers when an intro or outro movie starts to play. \n        It identifies the movie being played. This is used to determine how long players \n        spend watching the movies (more relevant after the first play \n        through when the skip option is available).']\n        \"\"\"\n        if 2081 in self.unique_event_codes:\n\n            movie = self.user_sample[self.user_sample.event_code == 2081]\n\n            self.Event_features[\"accu_movie_skiping_count_2081\"] = movie[\"duration\"].count()\n    \n    def event_code_2083(self):\n        \"\"\"\n        ['The movie started event triggers when an intro or outro movie starts to play. \n        It identifies the movie being played. This is used to determine how long players \n        spend watching the movies (more relevant after the first play \n        through when the skip option is available).']\n        \"\"\"\n        if 2083 in self.unique_event_codes:\n\n            movie = self.user_sample[self.user_sample.event_code == 2083]\n\n            movie_duration = movie[\"duration\"].values\n            features_2083 = FeaturesGeneration(movie_duration, \"_2083\")\n            self.Event_features.update(features_2083.copy())\n    \n    def event_code_3010(self):\n        \"\"\"\n        ['The system-initiated instruction event occurs when the game delivers instructions to the player.\n         It contains information that describes the content of the instruction. This event differs from events 3020\n          and 3021 as it captures instructions that are not given in response to player action. \n          These events are used to determine the effectiveness of the instructions. We can answer questions like,\n         \"did players who received instruction X do better than those who did not?\"']\n        \"\"\"\n        if 3010 in self.unique_event_codes:\n\n            instruction = self.user_sample[self.user_sample.event_code == 3010]\n\n            instruction_duration = instruction[\"total_duration\"].values\n            \n            features_3010 = FeaturesGeneration(instruction_duration, \"_3010\")\n            self.Event_features.update(features_3010.copy())\n\n    def event_code_3020(self):\n        \"\"\"\n        ['The system-initiated feedback (Incorrect) event occurs when the game starts delivering feedback \n        to the player in response to an incorrect round attempt (pressing the go button with the incorrect answer). \n        It contains information that describes the content of the instruction. These events are used to determine \n        the effectiveness of the feedback. We can answer questions like \n        \"did players who received feedback X do better than those who did not?\"']\n        \"\"\"\n        if 3020 in self.unique_event_codes:\n\n            Incorrect = self.user_sample[self.user_sample.event_code == 3020]\n\n            Incorrect_duration = Incorrect[\"total_duration\"].values\n            \n            features_3020 = FeaturesGeneration(Incorrect_duration, \"_3020\")\n            self.Event_features.update(features_3020.copy())\n            \n            self.Event_features[\"accu_Incorrect_media_type_3020_count_\"] = Incorrect[\"media_type\"].count()\n    \n\n    def event_code_3021(self):\n        \"\"\"\n        ['The system-initiated feedback (Correct) event occurs when the game \n        starts delivering feedback to the player in response to a correct round attempt \n        (pressing the go button with the correct answer). It contains information that describes the\n         content of the instruction, and will likely occur in conjunction with a beat round event. \n         These events are used to determine the effectiveness of the feedback. We can answer questions like, \n        \"did players who received feedback X do better than those who did not?\"']\n        \"\"\"\n        if 3021 in self.unique_event_codes:\n\n            Correct = self.user_sample[self.user_sample.event_code == 3021]\n\n            Correct_duration = Correct[\"total_duration\"].values\n            features_3021 = FeaturesGeneration(Correct_duration, \"_3021\")\n            self.Event_features.update(features_3021.copy())\n            \n            self.Event_features[\"accu_Correct_media_type_3021_count_\"] = Correct[\"media_type\"].count()\n\n    def event_code_3110(self):\n        \"\"\"\n        ['The end of system-initiated instruction event occurs when the game finishes \n        delivering instructions to the player. It contains information that describes the\n         content of the instruction including duration. These events are used to determine the \n         effectiveness of the instructions and the amount of time they consume. We can answer questions like, \n        \"how much time elapsed while the game was presenting instruction?\"']\n        \"\"\"\n        if 3110 in self.unique_event_codes:\n\n            Instuction = self.user_sample[self.user_sample.event_code == 3110]\n\n            Instuction_duration = Instuction[\"duration\"].values\n            features_3110 = FeaturesGeneration(Instuction_duration, \"_3110\")\n            self.Event_features.update(features_3110.copy())\n            \n            self.Event_features[\"accu_Instuction_media_type_3110_count_\"] = Instuction[\"media_type\"].count()\n\n    def event_code_3120(self):\n        \"\"\"\n        ['The end of system-initiated feedback (Incorrect) event \n        occurs when the game finishes delivering feedback to the player in response\n         to an incorrect round attempt (pressing the go button with the incorrect answer). \n         It contains information that describes the content of the instruction. \n         These events are used to determine the effectiveness of the feedback. We can answer questions like,\n         “how much time elapsed while the game was presenting feedback?”']\n        \"\"\"\n        if 3120 in self.unique_event_codes:\n\n            IncorrectInstruction = self.user_sample[self.user_sample.event_code == 3120]\n\n            IncorrectInstruction_duration = IncorrectInstruction[\"duration\"].values\n            \n            features_3120 = FeaturesGeneration(IncorrectInstruction_duration, \"_3120\")\n            self.Event_features.update(features_3120.copy())\n            \n            self.Event_features[\"accu_IncorrectInstruction_media_type_3120_count_\"] = IncorrectInstruction[\"media_type\"].count()\n\n    def event_code_3121(self):\n        \"\"\"\n        ['The end of system-initiated feedback (Correct) event \n        occurs when the game finishes delivering feedback to the player in response\n         to an incorrect round attempt (pressing the go button with the incorrect answer). \n         It contains information that describes the content of the instruction. \n         These events are used to determine the effectiveness of the feedback. We can answer questions like,\n         “how much time elapsed while the game was presenting feedback?”']\n        \"\"\"\n        if 3121 in self.unique_event_codes:\n\n            CorrectInstruction = self.user_sample[self.user_sample.event_code == 3121]\n\n            CorrectInstruction_duration = CorrectInstruction[\"duration\"].values\n\n            features_3121 = FeaturesGeneration(CorrectInstruction_duration, \"_3121\")\n            self.Event_features.update(features_3121.copy())\n            \n            self.Event_features[\"accu_CorrectInstruction_media_type_3121_count_\"] = CorrectInstruction[\"media_type\"].count()\n\n\n    def event_code_4010(self):\n        \"\"\"\n\n        ['This event occurs when the player clicks to start \n        the game from the starting screen.']\n        \n        \"\"\"\n\n        pass\n    \n    def event_code_4020(self):\n        \"\"\"\n        ['This event occurs when the player \n        clicks a group of objects. It contains information \n        about the group clicked, the state of the game, and the\n         correctness of the action. This event is \n         to diagnose player strategies and understanding.']\n\n         It contains information about the state of the game and the correctness of the action. This event is used \n         to diagnose player strategies and understanding.\n        \"\"\"\n        \n        if 4020 in self.unique_event_codes:\n\n            event_data = self.user_sample[self.user_sample.event_code == 4020]\n\n            true_attempts = event_data[event_data.correct == True]['correct'].count()\n            false_attempts = event_data[event_data.correct == False]['correct'].count()\n            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n\n            self.Event_features[\"accu_True_attempts_4020_\"] = true_attempts\n            self.Event_features[\"accu_False_attempts_4020_\"] = false_attempts\n            self.Event_features[\"accu_Accuracy_attempts_4020_\"] = accuracy\n\n    def event_code_4021(self):\n        pass\n    \n    def event_code_4022(self):\n        pass\n\n    def event_code_4025(self):\n        pass\n\n    def event_code_4030(self):\n        pass\n\n    def event_code_4031(self):\n        pass\n\n    def event_code_4035(self):\n\n        if 4035 in self.unique_event_codes:\n\n            event_data = self.user_sample[self.user_sample.event_code == 4035]\n\n            self.Event_features[\"accu_wrong_place_count_4035_\"] = len(event_data)\n\n            try:\n                wrong_place = event_data[\"duration\"].values\n\n                features_4035 = FeaturesGeneration(wrong_place, \"_4035\")\n                self.Event_features.update(features_4035.copy())\n            except:\n                pass\n\n    \n    def event_code_4040(self):\n        pass\n\n    def event_code_4045(self):\n        pass\n\n    def event_code_4050(self):\n        pass\n\n    def event_code_4070(self):\n        \"\"\"\n        \n        ['This event occurs when the player clicks on\n            something that isn’t covered elsewhere. \n            It can be useful in determining if there are\n            attractive distractions (things the player think\n            should do something, but don’t) in the game, or\n            diagnosing players \n            who are having mechanical difficulties (near misses).']\n        \"\"\"\n        if 4070 in self.unique_event_codes:\n\n            event_data = self.user_sample[self.user_sample.event_code == 4070]\n            self.Event_features[\"accu_something_not_covered_count_4070_\"] = len(event_data)\n\n    def event_code_4080(self):\n\n        if 4080 in self.unique_event_codes:\n\n            event_data = self.user_sample[self.user_sample.event_code == 4080]\n\n            self.Event_features[\"accu_mouse_over_count_4080_\"] = len(event_data)\n\n            try:\n\n                dwell_time = event_data[\"dwell_time\"].values\n                \n                features_4080 = FeaturesGeneration(dwell_time, \"_4080\")\n                self.Event_features.update(features_4080.copy())\n            \n            except:\n                pass\n\n    def event_code_4090(self):\n        pass\n\n    def event_code_4095(self):\n        pass\n        \n    def event_code_4100(self):\n        \n        if 4100 in self.unique_event_codes:\n\n            event_data = self.user_sample[self.user_sample.event_code == 4100]\n\n            true_attempts = event_data[event_data.correct == True]['correct'].count()\n            false_attempts = event_data[event_data.correct == False]['correct'].count()\n            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n\n            self.Event_features[\"accu_True_attempts_4100_\"] = true_attempts\n            self.Event_features[\"accu_False_attempts_4100_\"] = false_attempts\n            self.Event_features[\"accu_Accuracy_attempts_4100_\"] = accuracy\n\n    def event_code_4110(self):\n        \n\n        if 4110 in self.unique_event_codes:\n\n            event_data = self.user_sample[self.user_sample.event_code == 4110]\n\n            true_attempts = event_data[event_data.correct == True]['correct'].count()\n            false_attempts = event_data[event_data.correct == False]['correct'].count()\n            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n\n            self.Event_features[\"accu_True_attempts_4110_\"+self.user_sample_title] = true_attempts\n            self.Event_features[\"accu_False_attempts_4110_\"+self.user_sample_title] = false_attempts\n            self.Event_features[\"accu_Accuracy_attempts_4110_\"+self.user_sample_title] = accuracy\n            \n\n    def event_code_4220(self):\n        pass\n\n    def event_code_4230(self):\n        pass\n\n    def event_code_4235(self):\n        pass\n\n    def event_code_5000(self):\n        pass\n\n    def event_code_5010(self):\n        pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_train_test(train, test, unique_data):\n    compiled_train = []\n    compiled_test = []\n    \n    \n    if os.path.exists(\"../input/amma-reduce/amma_train.csv\"):\n        reduce_train_file = True\n        reduce_train = pd.read_csv(\"../input/amma-reduce/amma_train.csv\")\n    else:\n        for i, (ins_id, user_sample) in tqdm(enumerate(train.groupby(\"installation_id\", sort=False)), total=len(train.installation_id.unique())):\n\n            if \"Assessment\" in user_sample.type.unique():\n                temp_df = json_parser(user_sample, \"event_data\")\n                temp_df.sort_values(\"timestamp\", inplace=True)\n                temp_df.reset_index(inplace=True, drop=True)\n                temp_df[\"index\"] = temp_df.index.values\n                compiled_train.extend(get_data(temp_df, unique_data))\n\n        reduce_train = pd.DataFrame(compiled_train)\n\n    for i, (ins_id, user_sample) in tqdm(enumerate(test.groupby(\"installation_id\", sort=False)), total=len(test.installation_id.unique())):\n\n        if \"Assessment\" in user_sample.type.unique():\n            temp_df = json_parser(user_sample, \"event_data\")\n            temp_df.sort_values(\"timestamp\", inplace=True)\n            temp_df.reset_index(inplace=True, drop=True)\n            temp_df[\"index\"] = temp_df.index.values\n            compiled_test.append(get_data(temp_df,unique_data, test=True))\n\n    reduce_test = pd.DataFrame(compiled_test)\n\n    return reduce_train, reduce_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reduce_train.to_csv(\"amma_train.csv\", index=False)\n#reduce_test.to_csv(\"amma_test.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_train, reduce_test = get_train_test(train, test, unique_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_train.shape , reduce_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_train = reduce_train[reduce_train.game_session.isin(train_labels.game_session.unique())]\nreduce_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_train.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in reduce_train.columns]\nreduce_test.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in reduce_test.columns]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rem = list(set(reduce_train.columns).intersection(set(reduce_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_train = reduce_train[rem]\nreduce_test = reduce_test[rem]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_train.shape, reduce_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reduce_test.to_csv(\"amma_test1.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train, test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = reduce_train.copy()\ntest = reduce_test.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DataPreprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"useless_features = []\n\nfor colstart in ['skew', 'kstat', 'kurtosis','moment' ]:\n    new = reduce_train.columns[reduce_train.columns.str.startswith(colstart)]\n    useless_features.extend(new.tolist())\n\nreduce_train.drop(columns=useless_features, inplace=True)\nreduce_test.drop(columns=useless_features, inplace=True)\n\n# filling inf and NINF values with nan\n\nreduce_train.replace(np.inf, np.nan, inplace=True)\nreduce_test.replace(np.inf, np.nan, inplace=True)\n\nreduce_train.replace(np.NINF, np.nan, inplace=True)\nreduce_test.replace(np.NINF, np.nan, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# droping duplicate columns\n\ndef drop_duplicate_columns(train_df, test_df):\n    new_df = train_df.T.drop_duplicates()\n    new_df = new_df.T\n    train_df = train_df[new_df.columns]\n    test_df = test_df[new_df.columns]\n    return train_df, test_df\n\nreduce_train, reduce_test = drop_duplicate_columns(reduce_train, reduce_test)\n\nreduce_train.shape , reduce_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combine = [reduce_train, reduce_test]\n\nobject_info = pd.DataFrame()\nnum_info = pd.DataFrame()\n\nfor x in combine[0].columns:\n    # Missing Values Dataframe\n    if combine[0][x].isnull().any() == True:\n        object_info = object_info.append({'Column': x,'dtype': combine[0][x].dtypes,\n        'Count': combine[0][x].count().astype(int),\n        'Missing %':(combine[0][x].isnull().sum()/combine[0].shape[0])*100,\n        'Unique':len(combine[0][x].unique())},ignore_index=True)\n    # Custom Descriptive Statistics Table\n    if combine[0][x].dtype != \"object\" :\n        num_info = num_info.append({'Column': x, 'dtype': combine[0][x].dtypes, 'Count':\n        combine[0][x].count().astype(int), 'Missing %':(combine[0][x].isnull().sum()/combine[0].shape[0])*100,\n        'Unique': len(combine[0][x].unique()), 'Stdev':combine[0][x].std(),\n        'Mean':combine[0][x].mean(), 'Stdev':combine[0][x].std(),\n        'Variance':combine[0][x].var()},ignore_index=True)\n        \nobject_info.sort_values(by=[\"Missing %\"], ascending=False, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Missing_values_cols = num_info[num_info[\"Missing %\"] > 60][\"Column\"]\n\nprint(\"Number of missing values columns > 60 % :\", len(Missing_values_cols))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas.api.types import is_datetime64_any_dtype as is_datetime\nfrom pandas.api.types import is_categorical_dtype\n\ndef reduce_mem_usage(df, use_float16=False):\n    \"\"\"\n    Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.\n    \"\"\"\n\n    start_mem = df.memory_usage().sum() / 1024**2\n    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n\n    for col in df.columns:\n        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n            continue\n        col_type = df[col].dtype\n\n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            #df[col] = df[col].astype(\"category\")\n            pass\n        \n    end_mem = df.memory_usage().sum() / 1024**2\n    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_train = reduce_mem_usage(reduce_train)\nreduce_test = reduce_mem_usage(reduce_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_train.shape, reduce_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# missing values as new features\n\ndef missing_values_as_new_column(train_df, test_df):\n    for col in train_df.columns:\n        if train_df[col].isna().any():\n            train_df[\"Missing_value_\"+col] = np.where(train_df[col].isna(), 1, 0)\n            test_df[\"Missing_value_\"+col] = np.where(test_df[col].isna(), 1, 0)\n    return train_df, test_df\n\nreduce_train, reduce_test = missing_values_as_new_column(reduce_train, reduce_test)\n\nreduce_train.shape , reduce_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Missing_values_filled_cols = reduce_train.columns[reduce_train.columns.str.startswith(\"Missing_value_\")]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(Missing_values_filled_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# impute missing values of continuous features using KNN\n\"\"\"\nfrom fancyimpute import SoftImpute\n\n#get continuous features\ncolnames_numerics_only = reduce_train.select_dtypes(include=np.number).columns.tolist()\n\n#impute missing values of continuous features using KNN\nreduce_train[first_10] = SoftImpute(max_iters=3).fit_transform(reduce_train[first_10])\nprint('missing values of continuous features imputed successfully')\n\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_train.shape, reduce_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_timestamp_features(df):\n    date_time = pd.to_datetime(df[\"timestamp_session\"])\n    df[\"day\"] = date_time.dt.day\n    df[\"month\"] = date_time.dt.month\n    df[\"week_day\"] = date_time.dt.weekday\n    df[\"hour\"] = date_time.dt.hour\n    return df\n\nreduce_train = extract_timestamp_features(reduce_train)\nreduce_test = extract_timestamp_features(reduce_test)\n\nreduce_train.shape , reduce_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_train_tree = reduce_train.copy()\nreduce_test_tree = reduce_test.copy()\n\nreduce_train_linear = reduce_train.copy()\nreduce_test_linear = reduce_test.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"exclude_cols = ['timestamp_session', 'installation_id', 'game_session']\ncat_cols = reduce_train_tree.select_dtypes(include=['object']).columns.tolist()\n\nnum_cols = list(set(reduce_train_tree.columns) - set(cat_cols))\ncat_cols = list(set(cat_cols) - set(exclude_cols))\n\nlen(num_cols) , len(cat_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tree_based_models(train, test, columns_map):\n    \n    for col in columns_map:\n        list_of_values = list(set(train[col].unique()).union(set(test[col].unique())))\n        list_of_values_map = dict(zip(list_of_values, np.arange(len(list_of_values))))\n        train[col] = train[col].map(list_of_values_map)\n        test[col] = test[col].map(list_of_values_map)\n        \n    train.fillna(-999, inplace=True)\n    test.fillna(-999, inplace=True)\n    \n    return train, test\n\nreduce_train_tree, reduce_test_tree = tree_based_models(reduce_train_tree, reduce_test_tree, columns_map=cat_cols)\n\nreduce_train_tree.shape , reduce_test_tree.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def linear_based_models(train, test, cat_cols, numaric_cols):\n    \n    skewd_features = np.array(numaric_cols)[np.abs(skew(train[numaric_cols])) > 0.5]\n    \n    train[skewd_features] = np.log1p(train[skewd_features])\n    test[skewd_features] = np.log1p(test[skewd_features])\n    \n    for col in cat_cols:\n        try:\n            map_encoded = train[col].value_counts(normalize=True, dropna=False)\n            train[col+\"_Encoded\"] = train[col].map(map_encoded)\n            test[col+\"_Encoded\"] = test[col].map(map_encoded)\n        except:\n            pass\n    \n    # One Hot Encoder\n    train = pd.get_dummies(train, columns=cat_cols, prefix=cat_cols)\n    test = pd.get_dummies(test, columns=cat_cols, prefix=cat_cols)\n    \n    rem = list(set(train.columns).intersection(set(test)))\n    \n    train = train[rem]\n    test = test[rem]\n    \n    train.replace(np.inf, np.nan, inplace=True)\n    test.replace(np.inf, np.nan, inplace=True)\n\n    train.replace(np.NINF, np.nan, inplace=True)\n    test.replace(np.NINF, np.nan, inplace=True)\n    \n    train.fillna(0, inplace=True)\n    test.fillna(0, inplace=True)\n    \n    return train, test\n\nreduce_train_linear, reduce_test_linear = linear_based_models(reduce_train_linear, reduce_test_linear, cat_cols, num_cols)\n\nreduce_train_linear.drop(columns=['day', 'month', 'hour'], inplace=True)\nreduce_test_linear.drop(columns=['day', 'month', 'hour'], inplace=True)\n\nreduce_train_linear.shape , reduce_test_linear.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def merge_with_labels(train, train_labels):\n    \n    train = train[train.game_session.isin(train_labels.game_session.unique())]\n    \n    tld = train_labels[['game_session', 'installation_id', 'num_correct','num_incorrect', 'accuracy', 'accuracy_group']]\n    final_train = pd.merge(tld, train, left_on=['game_session', 'installation_id'], right_on=['game_session','installation_id'], how='inner')\n    \n    final_train.sort_values('timestamp_session', inplace=True)\n    col_drop = tld.columns.values\n    col_drop = np.append(col_drop, 'timestamp_session')\n    \n    return final_train, col_drop","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_train_tree, col_drop = merge_with_labels(reduce_train_tree, train_labels)\n\nfinal_train_linear, col_drop = merge_with_labels(reduce_train_linear, train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## remove_Outliers\n\ndef removeOutlier(df, cols):\n    indexes=[]\n    for col in tqdm(cols):\n        if (df[col].dtypes !='object'):\n            if df[col].nunique() > 100:\n                Q1 = df[col].quantile(q=0.01)\n                Q3 = df[col].quantile(q=0.99)\n                df2 = df[(df[col] < Q1/5) | (df[col] > 5*Q3)]\n                indexes.extend(df2.index.tolist())\n                \n    df = df.drop(index=indexes)\n    return df, indexes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_ins, test_ins = train_test_split(final_train_tree.installation_id.unique(), test_size=0.17)\nlen(train_ins) , len(test_ins)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hold_out_tree = final_train_tree[final_train_tree.installation_id.isin(test_ins)]\nfinal_train_tree = final_train_tree[final_train_tree.installation_id.isin(train_ins)]\n\nfinal_train_tree.shape, hold_out_tree.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\n\ndef get_hold_out_set(df):\n\n    final_session = []\n    for ins_id, sample_df in df.groupby(\"installation_id\", sort=False):\n        \n        if len(sample_df) > 0:\n            fs = sample_df.game_session.values[-1]\n            final_session.append(fs)\n\n    last_df = df[df.game_session.isin(final_session)]\n\n    user_idx = []\n\n    for iid in set(df[\"installation_id\"]):\n        list_ = list(df[df[\"installation_id\"] == iid].index)\n\n        cur = random.choices(list_, k = 1)[0]\n        user_idx.append(cur)\n    \n    turncated_df = df.loc[user_idx]\n\n    final_hold_out = pd.concat([last_df, turncated_df])\n\n    return final_hold_out\n\nhold_out_tree = get_hold_out_set(hold_out_tree)\n\nhold_out_tree.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hold_out_tree.drop_duplicates(inplace=True)\nhold_out_tree.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hold_out_linear = final_train_linear[final_train_linear.installation_id.isin(test_ins)]\nfinal_train_linear = final_train_linear[final_train_linear.installation_id.isin(train_ins)]\n\nfinal_train_linear.shape, hold_out_linear.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hold_out_linear = hold_out_linear[hold_out_linear.game_session.isin(hold_out_tree.game_session.unique())]\nhold_out_linear.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def qwk(a1, a2):\n    \"\"\"\n    Source: https://www.kaggle.com/c/data-science-bowl-2019/discussion/114133#latest-660168\n\n    :param a1:\n    :param a2:\n    :param max_rat:\n    :return:\n    \"\"\"\n    max_rat = 3\n    a1 = np.asarray(a1, dtype=int)\n    a2 = np.asarray(a2, dtype=int)\n\n    hist1 = np.zeros((max_rat + 1, ))\n    hist2 = np.zeros((max_rat + 1, ))\n\n    o = 0\n    for k in range(a1.shape[0]):\n        i, j = a1[k], a2[k]\n        hist1[i] += 1\n        hist2[j] += 1\n        o +=  (i - j) * (i - j)\n\n    e = 0\n    for i in range(max_rat + 1):\n        for j in range(max_rat + 1):\n            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n\n    e = e / a1.shape[0]\n\n    return 1 - o / e\n\ndef confusion_matrix1(rater_a, rater_b, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the confusion matrix between rater's ratings\n    \"\"\"\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(rater_a + rater_b)\n    if max_rating is None:\n        max_rating = max(rater_a + rater_b)\n    num_ratings = int(max_rating - min_rating + 1)\n    conf_mat = [[0 for i in range(num_ratings)]\n                for j in range(num_ratings)]\n    for a, b in zip(rater_a, rater_b):\n        first = int(a - min_rating)\n        second = int(b - min_rating)\n        #print(conf_mat[0][0])\n        conf_mat[first][second] += 1\n    return conf_mat\n\ndef histogram(ratings, min_rating=None, max_rating=None):\n    \"\"\"\n    Returns the counts of each type of rating that a rater made\n    \"\"\"\n    if min_rating is None:\n        min_rating = min(ratings)\n    if max_rating is None:\n        max_rating = max(ratings)\n    num_ratings = int(max_rating - min_rating + 1)\n    hist_ratings = [0 for x in range(num_ratings)]\n    for r in ratings:\n        second = int(r - min_rating)\n        hist_ratings[second] += 1\n    return hist_ratings\n\ndef quadratic_weighted_kappa(y, y_pred):\n    \"\"\"\n    Calculates the quadratic weighted kappa\n    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n    value, which is a measure of inter-rater agreement between two raters\n    that provide discrete numeric ratings.  Potential values range from -1\n    (representing complete disagreement) to 1 (representing complete\n    agreement).  A kappa value of 0 is expected if all agreement is due to\n    chance.\n    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n    each correspond to a list of integer ratings.  These lists must have the\n    same length.\n    The ratings should be integers, and it is assumed that they contain\n    the complete range of possible ratings.\n    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n    is the minimum possible rating, and max_rating is the maximum possible\n    rating\n    \"\"\"\n    rater_a = y\n    rater_b = y_pred\n    min_rating=None\n    max_rating=None\n    rater_a = np.array(rater_a, dtype=int)\n    rater_b = np.array(rater_b, dtype=int)\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(min(rater_a), min(rater_b))\n    if max_rating is None:\n        max_rating = max(max(rater_a), max(rater_b))\n        \n    conf_mat = confusion_matrix1(rater_a, rater_b,\n                                min_rating, max_rating)\n    num_ratings = len(conf_mat)\n    num_scored_items = float(len(rater_a))\n\n    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n\n    numerator = 0.0\n    denominator = 0.0\n\n    for i in range(num_ratings):\n        for j in range(num_ratings):\n            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n                              / num_scored_items)\n            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n            numerator += d * conf_mat[i][j] / num_scored_items\n            denominator += d * expected_count / num_scored_items\n\n    return (1.0 - numerator / denominator)\n\n\ndef compression_distance(x,y,l_x=None,l_y=None):\n    if x==y:\n        return 0\n    x_b = x.encode('utf-8')\n    y_b = y.encode('utf-8')\n    if l_x is None:\n        l_x = len(lzma.compress(x_b))\n        l_y = len(lzma.compress(y_b))\n    l_xy = len(lzma.compress(x_b+y_b))\n    l_yx = len(lzma.compress(y_b+x_b))\n    dist = (min(l_xy,l_yx)-min(l_x,l_y))/max(l_x,l_y)\n    return dist\n\ndef get_scores(std_true, y_true):\n    best_diff = np.inf\n    combs = list(combinations_with_replacement([1,2,3,4],3)) + list(combinations_with_replacement([1,2,3,4],4)) + list(combinations_with_replacement([1,2,3,4],5))\n    for item in combs:\n        if np.median(item) == y_true:\n            diff = np.abs(np.std(item) - std_true)\n            if diff < best_diff:\n                best_diff = diff\n                best_match = list(item)\n                if best_diff < 1e-8:\n                    break\n    return best_match","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def very_border_acc(pred_true, y):\n    pred = pred_true.copy()\n    best_score = -999\n    \n    for k1 in tqdm(np.arange(0.5,1.5, 0.01)):\n        c1 = round(k1,2)\n        for k2 in np.arange(1.1,2.1, 0.01):\n            c2 = round(k2,2)\n            for k3 in np.arange(2.0,2.5, 0.01):\n                c3 = round(k3,2)\n                if c1 < c2 and c1 < c3 and c2 < c3:\n                    #print(c1, c2, c3)\n                    tmp_pred = pred.copy()\n                    tmp_pred[tmp_pred <= c1] = 0\n                    tmp_pred[np.where(np.logical_and(tmp_pred > c1, tmp_pred <= c2))] = 1\n                    tmp_pred[np.where(np.logical_and(tmp_pred > c2, tmp_pred <= c3))] = 2\n                    tmp_pred[tmp_pred > c3] = 3\n                    score = quadratic_weighted_kappa(y, tmp_pred)\n                    if score > best_score:\n                        best_score = score\n                        #print(c1, c2, c3)\n                        best_coef = [c1, c2, c3]\n                        best_pred = tmp_pred.copy()\n    return best_pred, best_coef, best_score\n\ndef very_border_acc_cv(pred_true, y):\n    pred = pred_true.copy()\n    best_score = -999\n    \n    for k1 in np.arange(0.5,1.5, 0.1):\n        c1 = round(k1,2)\n        for k2 in np.arange(1.1,2.1, 0.1):\n            c2 = round(k2,2)\n            for k3 in np.arange(2.0,2.5, 0.1):\n                c3 = round(k3,2)\n                if c1 < c2 and c1 < c3 and c2 < c3:\n                    #print(c1, c2, c3)\n                    tmp_pred = pred.copy()\n                    tmp_pred[tmp_pred <= c1] = 0\n                    tmp_pred[np.where(np.logical_and(tmp_pred > c1, tmp_pred <= c2))] = 1\n                    tmp_pred[np.where(np.logical_and(tmp_pred > c2, tmp_pred <= c3))] = 2\n                    tmp_pred[tmp_pred > c3] = 3\n                    score = quadratic_weighted_kappa(y, tmp_pred)\n                    if score > best_score:\n                        best_score = score\n                        #print(c1, c2, c3)\n                        best_coef = [c1, c2, c3]\n                        best_pred = tmp_pred.copy()\n    return best_pred, best_coef, best_score\n\n# qwk optimize coefficients\n\nclass OptimizedRounder(object):\n    def __init__(self, init_coef):\n        self.init_coef_ = init_coef\n        self.coef_ = 0\n    \n    def _kappa_loss(self, coef, X, y):\n        X_p = X.copy()\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0]  and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            else:\n                X_p[i] = 3\n        \n        ll = quadratic_weighted_kappa(y, X_p)\n        return -ll\n    \n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        \n        initial_coef = self.init_coef_\n        \n        self.coef_ = spoptimize.minimize(loss_partial, initial_coef, method=\"nelder-mead\")\n        \n    def predict(self, X, coef):\n        X_p = X.copy()\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            else:\n                X_p[i] = 3\n        return X_p\n    \n    def coefficients(self):\n        return self.coef_['x']\n    \n\ndef apply_border(pred, coefs):\n    c1, c2, c3 = coefs[0], coefs[1], coefs[2]\n    \n    tmp_pred = pred.copy()\n    \n    tmp_pred[tmp_pred <= c1] = 0\n    tmp_pred[np.where(np.logical_and(tmp_pred > c1, tmp_pred <= c2))] = 1\n    tmp_pred[np.where(np.logical_and(tmp_pred > c2, tmp_pred <= c3))] = 2\n    tmp_pred[tmp_pred > c3] = 3\n    \n    return tmp_pred.astype(np.int32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import linear_model\n\ndef linear_models():\n    \n    #ridge = Ridge(alpha=84.0, max_iter=50000)\n    \n    lasso = Lasso(alpha=0.006, max_iter=50000)\n    \n    elasticNet = ElasticNet(alpha=0.006, l1_ratio=0.8, max_iter=50000)\n    \n    #kernal = KernelRidge()\n    \n    #svmr = svm.SVR()\n    \n    liner = linear_model.LinearRegression()\n    \n    brg = linear_model.BayesianRidge(n_iter=50000)\n    \n    return [[\"Lasso\", lasso], [\"elasticNet\", elasticNet], [\"BayesianRidge\", brg]]\n    \n    #return [[\"Linear\" , liner]]\n\n#model_list = linear_models()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass Base_Model(object):\n\n    def __init__(self, train, hold_out, test, col_drop):\n        self.train = train\n        self.hold_out = hold_out\n        self.test = test\n        self.drop_cols = col_drop\n\n    def get_linear_based_data(self):\n        \n        rbSc = MinMaxScaler()\n        train_x = self.train.drop(columns=self.drop_cols)\n\n        x_train = rbSc.fit_transform(self.train.drop(columns=self.drop_cols))\n        y_train = self.train[\"accuracy_group\"]\n\n        x_hold = rbSc.transform(self.hold_out[train_x.columns])\n        y_hold = self.hold_out[\"accuracy_group\"]\n\n        x_test = rbSc.transform(self.test[train_x.columns])\n\n        return x_train, y_train, x_hold, y_hold, x_test\n    \n    def get_tree_based_data(self):\n        \n\n        x_train = self.train.drop(columns=self.drop_cols)\n        y_train = self.train[\"accuracy_group\"]\n\n        x_hold = self.hold_out[x_train.columns]\n        y_hold = self.hold_out[\"accuracy_group\"]\n\n        x_test = self.test[x_train.columns]\n\n        return x_train, y_train, x_hold, y_hold, x_test\n        \n    def get_scores(self, train_pred, y_train, hold_pred, y_hold, test_pred):\n\n        print(\"\\n\")\n        print(\"** Train RMSE : \", mean_squared_error(y_train, train_pred))\n        print(\"** Hold  RMSE : \", mean_squared_error(y_hold, hold_pred))\n        print(\"\\n\")\n\n        train_best_pred, train_best_coef, train_best_score = very_border_acc_cv(train_pred, y_train)\n        print(\"Train Best_Score : \", train_best_score)\n        print(\"Train Best_Coef : \", train_best_coef)\n        print(\"\\n\")\n\n        opt = OptimizedRounder(train_best_coef)\n        opt.fit(train_pred, y_train)\n        coefficients = opt.coefficients()\n\n        print(\"Optmized Coefficients : \", coefficients)\n\n        train_best_pred = opt.predict(train_pred, coefficients)\n        print(\"Optimized Train qwk : \", qwk(train_best_pred, y_train))\n\n\n        hold_best_pred, hold_best_coef, hold_best_score = very_border_acc_cv(hold_pred, y_hold)\n        print(\"Hold Best_Score : \", hold_best_score)\n        print(\"Hold Best_Coef : \", hold_best_coef)\n        print(\"\\n\")\n        \n\n        hold_best_pred_train = opt.predict(hold_pred, coefficients)\n        print(\"\\n\")\n        print(\"Hold QWK Train_Coef : \", qwk(hold_best_pred_train, y_hold))\n\n        test_best_pred = opt.predict(test_pred, coefficients)\n        \n        opt = OptimizedRounder(hold_best_coef)\n        opt.fit(hold_pred, y_hold)\n        coefficients = opt.coefficients()\n        \n        hold_best_pred = opt.predict(hold_pred, coefficients)\n        \n        test_best_pred_hold = opt.predict(test_pred, coefficients)\n        \n        train_best_pred_hold = opt.predict(train_pred, coefficients)\n\n        return train_best_pred, train_best_pred_hold, hold_best_pred_train, hold_best_pred,test_best_pred, test_best_pred_hold\n\n\n    def Lgb_Model(self,x_train, y_train, x_hold, y_hold, x_test):\n\n        lgb_params = {\n            'boosting_type': 'gbdt',\n            'objective': 'regression',\n            'learning_rate': 0.005,\n            'subsample': 0.33577567174,\n            'colsample_bytree': 0.88885216205885169,\n            'min_split_gain': 0.006,\n            'min_child_samples': 157,\n            'min_child_weight': 0.1,\n            'max_depth': -1,\n            'n_estimators': 10000,\n            'num_leaves': 17,\n            'silent': -1,\n            'verbose': -1,\n            #'max_depth': 15,\n            'random_state': 2019,\n            'reg_lambda' : 50,\n            'reg_alpha' : 0\n        }\n\n        model = lgb.LGBMRegressor(**lgb_params)\n        model.fit(\n            x_train, y_train,\n            eval_set=[(x_hold, y_hold)],\n            eval_metric='rmse',\n            verbose=100,\n            early_stopping_rounds=300\n        )\n\n        train_pred = model.predict(x_train, num_iteration=model.best_iteration_)\n        hold_pred = model.predict(x_hold, num_iteration=model.best_iteration_)\n        test_pred = model.predict(x_test, num_iteration=model.best_iteration_)\n\n        print(\"-------- Model : LGB ---------\")\n\n        train_best_pred, train_best_pred_hold, hold_best_pred_train, hold_best_pred,test_best_pred, test_best_pred_hold = self.get_scores(train_pred, y_train, hold_pred, y_hold, test_pred)\n\n        return_dict = {\n            \"train_pred\": train_pred,\n            \"hold_pred\" : hold_pred,\n            \"test_pred\" : test_pred,\n            \"train_best_pred\" : train_best_pred,\n            \"train_best_pred_hold\" : train_best_pred_hold,\n            \"hold_best_pred_train\" : hold_best_pred_train,\n            \"hold_best_pred\" : hold_best_pred,\n            \"test_best_pred\" : test_best_pred,\n            \"test_best_pred_hold\": test_best_pred_hold\n        }\n\n        return return_dict\n    \n    def Catb_Model(self,x_train, y_train, x_hold, y_hold, x_test):\n\n        params = {\n            'loss_function': 'RMSE',\n            'task_type': \"CPU\",\n            'iterations': 5000,\n            'od_type': \"Iter\",\n            'depth': 10,\n            'colsample_bylevel': 0.5, \n            'early_stopping_rounds': 150,\n            'l2_leaf_reg': 18,\n            'random_seed': 42,\n            'use_best_model': True\n        }\n\n        model = CatBoostRegressor(**params)\n        model.fit(\n            x_train, y_train,\n            eval_set=[(x_hold, y_hold)],\n            verbose=100\n        )\n\n        train_pred = model.predict(x_train)\n        hold_pred = model.predict(x_hold)\n        test_pred = model.predict(x_test)\n\n        print(\"-------- Model : CatBoost ---------\")\n\n        train_best_pred, train_best_pred_hold, hold_best_pred_train, hold_best_pred,test_best_pred, test_best_pred_hold = self.get_scores(train_pred, y_train, hold_pred, y_hold, test_pred)\n\n        return_dict = {\n            \"train_pred\": train_pred,\n            \"hold_pred\" : hold_pred,\n            \"test_pred\" : test_pred,\n            \"train_best_pred\" : train_best_pred,\n            \"train_best_pred_hold\" : train_best_pred_hold,\n            \"hold_best_pred_train\" : hold_best_pred_train,\n            \"hold_best_pred\" : hold_best_pred,\n            \"test_best_pred\" : test_best_pred,\n            \"test_best_pred_hold\": test_best_pred_hold\n        }\n\n        return return_dict\n\n    \n    def Xgb_Model(self,x_train, y_train, x_hold, y_hold, x_test):\n\n        params = {\n            'colsample_bytree': 0.8,                 \n            'learning_rate': 0.01,\n            'max_depth': 10,\n            'subsample': 1,\n            'objective':'reg:squarederror',\n            #'eval_metric':'rmse',\n            'min_child_weight':3,\n            'gamma':0.25,\n            'n_estimators':5000\n        }\n\n        train_set = xgb.DMatrix(x_train, y_train)\n        hold_set = xgb.DMatrix(x_hold, y_hold)\n        test_set = xgb.DMatrix(x_test)\n\n        model = xgb.train(params, train_set, \n                         num_boost_round=5000, evals=[(train_set, 'train'), (hold_set, 'hold')], \n                         verbose_eval=100, early_stopping_rounds=300)\n\n        train_pred = model.predict(train_set)\n        hold_pred = model.predict(hold_set)\n        test_pred = model.predict(test_set)\n\n        print(\"-------- Model : XGB ---------\")\n\n        train_best_pred, train_best_pred_hold, hold_best_pred_train, hold_best_pred,test_best_pred, test_best_pred_hold = self.get_scores(train_pred, y_train, hold_pred, y_hold, test_pred)\n\n        return_dict = {\n            \"train_pred\": train_pred,\n            \"hold_pred\" : hold_pred,\n            \"test_pred\" : test_pred,\n            \"train_best_pred\" : train_best_pred,\n            \"train_best_pred_hold\" : train_best_pred_hold,\n            \"hold_best_pred_train\" : hold_best_pred_train,\n            \"hold_best_pred\" : hold_best_pred,\n            \"test_best_pred\" : test_best_pred,\n            \"test_best_pred_hold\": test_best_pred_hold\n        }\n        \n        return return_dict\n\n    def Lasso_Model(self,x_train, y_train, x_hold, y_hold, x_test):\n\n        \n        model = linear_model.Lasso(alpha=0.006, max_iter=50000)\n        model.fit(x_train, y_train)\n\n        train_pred = model.predict(x_train)\n        hold_pred = model.predict(x_hold)\n        test_pred = model.predict(x_test)\n\n        print(\"-------- Model : Lasso ---------\")\n\n        train_best_pred, train_best_pred_hold, hold_best_pred_train, hold_best_pred,test_best_pred, test_best_pred_hold = self.get_scores(train_pred, y_train, hold_pred, y_hold, test_pred)\n\n        return_dict = {\n            \"train_pred\": train_pred,\n            \"hold_pred\" : hold_pred,\n            \"test_pred\" : test_pred,\n            \"train_best_pred\" : train_best_pred,\n            \"train_best_pred_hold\" : train_best_pred_hold,\n            \"hold_best_pred_train\" : hold_best_pred_train,\n            \"hold_best_pred\" : hold_best_pred,\n            \"test_best_pred\" : test_best_pred,\n            \"test_best_pred_hold\": test_best_pred_hold\n        }\n\n        return return_dict\n\n    def ElasticNet_Model(self,x_train, y_train, x_hold, y_hold, x_test):\n\n        \n        model = ElasticNet(alpha=0.006, l1_ratio=0.8, max_iter=50000)\n        model.fit(x_train, y_train)\n\n        train_pred = model.predict(x_train)\n        hold_pred = model.predict(x_hold)\n        test_pred = model.predict(x_test)\n\n        print(\"-------- Model : ElasticNet ---------\")\n\n        train_best_pred, train_best_pred_hold, hold_best_pred_train, hold_best_pred,test_best_pred, test_best_pred_hold = self.get_scores(train_pred, y_train, hold_pred, y_hold, test_pred)\n\n        return_dict = {\n            \"train_pred\": train_pred,\n            \"hold_pred\" : hold_pred,\n            \"test_pred\" : test_pred,\n            \"train_best_pred\" : train_best_pred,\n            \"train_best_pred_hold\" : train_best_pred_hold,\n            \"hold_best_pred_train\" : hold_best_pred_train,\n            \"hold_best_pred\" : hold_best_pred,\n            \"test_best_pred\" : test_best_pred,\n            \"test_best_pred_hold\": test_best_pred_hold\n        }\n        \n        return return_dict\n\n    def BayesianRidge_Model(self,x_train, y_train, x_hold, y_hold, x_test):\n\n        \n        model = linear_model.BayesianRidge(n_iter=50000)\n        model.fit(x_train, y_train)\n\n        train_pred = model.predict(x_train)\n        hold_pred = model.predict(x_hold)\n        test_pred = model.predict(x_test)\n\n        print(\"-------- Model : BayesianRidge ---------\")\n\n\n        train_best_pred, train_best_pred_hold, hold_best_pred_train, hold_best_pred,test_best_pred, test_best_pred_hold = self.get_scores(train_pred, y_train, hold_pred, y_hold, test_pred)\n\n        return_dict = {\n            \"train_pred\": train_pred,\n            \"hold_pred\" : hold_pred,\n            \"test_pred\" : test_pred,\n            \"train_best_pred\" : train_best_pred,\n            \"train_best_pred_hold\" : train_best_pred_hold,\n            \"hold_best_pred_train\" : hold_best_pred_train,\n            \"hold_best_pred\" : hold_best_pred,\n            \"test_best_pred\" : test_best_pred,\n            \"test_best_pred_hold\": test_best_pred_hold\n        }\n\n        return return_dict\n    \n    def HuberRegressor_Model(self,x_train, y_train, x_hold, y_hold, x_test):\n\n        \n        model = linear_model.HuberRegressor(max_iter=300)\n        model.fit(x_train, y_train)\n\n        train_pred = model.predict(x_train)\n        hold_pred = model.predict(x_hold)\n        test_pred = model.predict(x_test)\n\n        print(\"-------- Model : HuberRegressor ---------\")\n\n        train_best_pred, train_best_pred_hold, hold_best_pred_train, hold_best_pred,test_best_pred, test_best_pred_hold = self.get_scores(train_pred, y_train, hold_pred, y_hold, test_pred)\n\n        return_dict = {\n            \"train_pred\": train_pred,\n            \"hold_pred\" : hold_pred,\n            \"test_pred\" : test_pred,\n            \"train_best_pred\" : train_best_pred,\n            \"train_best_pred_hold\" : train_best_pred_hold,\n            \"hold_best_pred_train\" : hold_best_pred_train,\n            \"hold_best_pred\" : hold_best_pred,\n            \"test_best_pred\" : test_best_pred,\n            \"test_best_pred_hold\": test_best_pred_hold\n        }\n        \n        return return_dict\n    \n    def NN_Model(self,x_train, y_train, x_hold, y_hold, x_test):\n        X = x_train\n        y = y_train\n        def create_model(X, y):\n            nn = Sequential()\n\n            # layers\n            nn.add(Dense(units = 1024, kernel_initializer = 'uniform', activation = 'relu',\n                         input_dim = X.shape[1])),\n            nn.add(keras.layers.normalization.BatchNormalization()),\n            nn.add(keras.layers.Dropout(0.3)),\n            nn.add(Dense(units = 512, kernel_initializer = 'uniform', activation = 'relu')),\n            nn.add(keras.layers.normalization.BatchNormalization()),\n            nn.add(keras.layers.Dropout(0.3)),\n            nn.add(Dense(units = 256, kernel_initializer = 'uniform', activation = 'relu')),\n            nn.add(keras.layers.normalization.BatchNormalization()),\n            nn.add(keras.layers.Dropout(0.3)),\n            nn.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'relu')),\n            nn.add(keras.layers.normalization.BatchNormalization()),\n            nn.add(keras.layers.Dropout(0.3)),\n            nn.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'relu')),\n            nn.add(keras.layers.normalization.BatchNormalization()),\n            nn.add(keras.layers.Dropout(0.3)),\n            nn.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu')),\n            nn.add(keras.layers.normalization.BatchNormalization()),\n            nn.add(keras.layers.Dropout(0.3)),\n            nn.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu')),\n            nn.add(keras.layers.normalization.BatchNormalization()),\n            #nn.add(keras.layers.Dropout(0.3)),\n            #nn.add(Dense(units = 2, kernel_initializer = 'uniform', activation = 'relu')),\n            #nn.add(keras.layers.normalization.BatchNormalization()),\n            #nn.add(keras.layers.Dropout(0.3)),\n            nn.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'relu',\n                         kernel_regularizer=regularizers.l2(0.003)))\n\n            nn.compile(loss='mean_squared_error', optimizer='adam')\n\n            return nn\n        \n        model = create_model(x_train, y_train)\n    \n    \n        es = callbacks.EarlyStopping(monitor='val_loss', min_delta=0.001, patience=5, verbose=1,baseline=None, restore_best_weights=True)\n\n        rlr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n                                          patience=3, min_lr=1e-6, verbose=1)\n\n\n        model.fit(x_train,y_train,\n                  validation_data=(x_hold, y_hold),\n                  verbose=1,\n                  batch_size=64,\n                  callbacks=[es, rlr],\n                  epochs=100\n            )\n\n        train_pred = model.predict(x_train)\n        train_pred = np.array([item for sublist in train_pred for item in sublist])\n        hold_pred = model.predict(x_hold)\n        hold_pred = np.array([item for sublist in hold_pred for item in sublist])\n        test_pred = model.predict(x_test)\n        test_pred = np.array([item for sublist in test_pred for item in sublist])\n\n        print(\"-------- Model : NN ---------\")\n\n        train_best_pred, train_best_pred_hold, hold_best_pred_train, hold_best_pred,test_best_pred, test_best_pred_hold = self.get_scores(train_pred, y_train, hold_pred, y_hold, test_pred)\n\n        return_dict = {\n            \"train_pred\": train_pred,\n            \"hold_pred\" : hold_pred,\n            \"test_pred\" : test_pred,\n            \"train_best_pred\" : train_best_pred,\n            \"train_best_pred_hold\" : train_best_pred_hold,\n            \"hold_best_pred_train\" : hold_best_pred_train,\n            \"hold_best_pred\" : hold_best_pred,\n            \"test_best_pred\" : test_best_pred,\n            \"test_best_pred_hold\": test_best_pred_hold\n        }\n\n        return return_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tree based\nbase = Base_Model(final_train_tree, hold_out_tree, reduce_test_tree, col_drop)\nx_train, y_train, x_hold, y_hold, x_test = base.get_tree_based_data()\n\nLGBTree = base.Lgb_Model(x_train, y_train, x_hold,y_hold ,x_test)\nCatTree = base.Catb_Model(x_train, y_train, x_hold,y_hold ,x_test)\n#XGBTree = base.Xgb_Model(x_train, y_train, x_hold,y_hold ,x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# linear based\nbase = Base_Model(final_train_linear, hold_out_linear, reduce_test_linear, col_drop)\nx_train, y_train, x_hold, y_hold, x_test = base.get_linear_based_data()\n\n#LGBLinear = base.Lgb_Model(x_train, y_train, x_hold,y_hold ,x_test)\n#CatLinear = base.Catb_Model(x_train, y_train, x_hold,y_hold ,x_test)\n#XGBLinear = base.Xgb_Model(x_train, y_train, x_hold,y_hold ,x_test)\n\n#Lasso_Model = base.Lasso_Model(x_train, y_train, x_hold,y_hold ,x_test)\n#ElasticNet_Model = base.ElasticNet_Model(x_train, y_train, x_hold,y_hold ,x_test)\n#BayesianRidge_Model = base.BayesianRidge_Model(x_train, y_train, x_hold,y_hold ,x_test)\n#HuberRegressor_Model = base.HuberRegressor_Model(x_train, y_train, x_hold,y_hold ,x_test)\nNN_Model = base.NN_Model(x_train, y_train, x_hold, y_hold, x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_hold.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models_list_predicted = [[\"LGBTree_\", LGBTree],\n                         [\"CatTree_\", CatTree],\n                         #[\"XGBTree_\", XGBTree],\n                         #[\"LGBLinear_\", LGBLinear],\n                         #[\"CatLinear_\", CatLinear],\n                         #[\"XGBLinear_\", XGBLinear],\n                         #[\"LassoLinear_\", Lasso_Model], \n                         #[\"ElasticNetLinear_\", ElasticNet_Model], \n                         #[\"BayesianRidgeLinear_\", BayesianRidge_Model],\n                         #[\"HuberRegressorLinear_\", HuberRegressor_Model],\n                         [\"NNLinear_\", NN_Model],\n                         #[\"LGBLinearUseless_\", LGBLinear_useless],\n                         #[\"CatLinearUseless_\", CatLinear_useless],\n                         #[\"XGBLinearUseless_\", XGBLinear_useless],\n                         #[\"LassoLinearUseless_\", Lasso_Model_useless], \n                         #[\"ElasticNetLinearUseless_\", ElasticNet_Model_useless], \n                         #[\"BayesianRidgeLinearUseless_\", BayesianRidge_Model_useless],\n                         #[\"HuberRegressorLinearUseless_\", HuberRegressor_Model_useless],\n                         #[\"NNLinearUseless_\", NN_Model_useless]\n                        ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hold_df2 = pd.DataFrame()\ntrain_df2 = pd.DataFrame()\ntest_df2 = pd.DataFrame()\nfor model_name, i in models_list_predicted:\n    for j in ['train_pred', 'hold_pred', 'test_pred', 'train_best_pred', 'train_best_pred_hold', 'hold_best_pred_train', 'hold_best_pred', 'test_best_pred', 'test_best_pred_hold']:\n        \n        if j.startswith(\"train\"):\n            train_df2[model_name+j] = i[j]\n        if j.startswith(\"hold\"):\n            hold_df2[model_name+j] = i[j]\n        if j.startswith(\"test\"):\n            test_df2[model_name+j] = i[j]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df2.shape, hold_df2.shape, test_df2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_hold_2 = y_hold.values\ny_train_2 = y_train.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df2.shape, hold_df2.shape, test_df2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x = train_df2.values\ntrain_y = y_train_2\n\nhold_x = hold_df2.values\nhold_y = y_hold_2\n\ntest_x = test_df2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_params = {\n        'boosting_type': 'gbdt',\n        'objective': 'regression'\n    }\nmodel = lgb.LGBMRegressor(**lgb_params)\nmodel.fit(\n        hold_x, hold_y,\n        eval_set=[(train_x, train_y)],\n        eval_metric='rmse',\n        verbose=100,\n        early_stopping_rounds=100\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels[\"accuracy_group\"].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_hold.value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred = model.predict(train_x, num_iteration=model.best_iteration_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_squared_error(train_y, train_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hold_pred = model.predict(hold_x, num_iteration=model.best_iteration_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_squared_error(hold_y, hold_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_best_pred, train_best_coef, train_best_score = very_border_acc_cv(train_pred, train_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_best_score, train_best_coef","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hold_best_pred, hold_best_coef, hold_best_score = very_border_acc_cv(hold_pred, hold_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hold_best_score, hold_best_coef","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = model.predict(test_x, num_iteration=model.best_iteration_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = OptimizedRounder(hold_best_coef)\nopt.fit(hold_pred,hold_y)\ncoefficients = opt.coefficients()\n\nprint(\"Optmized Coefficients : \", coefficients)\n\nhold_best_pred = opt.predict(hold_pred, coefficients)\nprint(\"Optimized Hold qwk : \", qwk(hold_best_pred, hold_y))\n\ntrain_best_pred = opt.predict(train_pred, coefficients)\nprint(\"Optimized Train qwk : \", qwk(train_best_pred, train_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predicted = opt.predict(test_pred, coefficients)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv(\"/kaggle/input/data-science-bowl-2019/sample_submission.csv\")\nsample_submission[\"accuracy_group\"] = test_predicted.astype(\"int\")\nsample_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['accuracy_group'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}