{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport lightgbm as lgb\nimport scipy as sp\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import KFold\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tqdm.pandas()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Only load those columns in order to save space\nkeep_cols = ['event_id', 'game_session', 'installation_id', 'event_count', 'event_code', 'title', 'game_time', 'type', 'world']\n\ntrain = pd.read_csv('/kaggle/input/data-science-bowl-2019/train.csv', usecols=keep_cols)\ntest = pd.read_csv('/kaggle/input/data-science-bowl-2019/test.csv', usecols=keep_cols)\ntrain_labels = pd.read_csv('/kaggle/input/data-science-bowl-2019/train_labels.csv')\nsubmission = pd.read_csv('/kaggle/input/data-science-bowl-2019/sample_submission.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_assess = test[test.type == 'Assessment'].copy()\ntest_labels = submission.copy()\ntest_labels['title'] = test_labels.installation_id.progress_apply(\n    lambda install_id: test_assess[test_assess.installation_id == install_id].iloc[-1].title\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_game_time_stats(group, col):\n    return group[\n        ['installation_id', col, 'event_count', 'game_time']\n    ].groupby(['installation_id', col]).agg(\n        [np.mean, np.sum, np.std]\n    ).reset_index().pivot(\n        columns=col,\n        index='installation_id'\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def group_and_reduce(df, df_labels):\n    \"\"\"\n    Author: https://www.kaggle.com/xhlulu/\n    Source: https://www.kaggle.com/xhlulu/ds-bowl-2019-simple-lgbm-using-aggregated-data\n    \"\"\"\n    \n    # First only filter the useful part of the df\n    df = df[df.installation_id.isin(df_labels.installation_id.unique())]\n    \n    # group1 is am intermediary \"game session\" group,\n    # which are reduced to one record by game session. group_game_time takes\n    # the max value of game_time (final game time in a session) and \n    # of event_count (total number of events happened in the session).\n    group_game_time = df.drop(columns=['event_id', 'event_code']).groupby(\n        ['game_session', 'installation_id', 'title', 'type', 'world']\n    ).max().reset_index()\n\n    # group3, group4 are grouped by installation_id \n    # and reduced using summation and other summary stats\n    title_group = (\n        pd.get_dummies(\n            group_game_time.drop(columns=['game_session', 'event_count', 'game_time']),\n            columns=['title', 'type', 'world'])\n        .groupby(['installation_id'])\n        .sum()\n    )\n\n    event_game_time_group = (\n        group_game_time[['installation_id', 'event_count', 'game_time']]\n        .groupby(['installation_id'])\n        .agg([np.sum, np.mean, np.std, np.min, np.max])\n    )\n    \n    # Additional stats on group1\n    world_time_stats = compute_game_time_stats(group_game_time, 'world')\n    type_time_stats = compute_game_time_stats(group_game_time, 'type')\n    \n    return (\n        title_group.join(event_game_time_group)\n        .join(world_time_stats)\n        .join(type_time_stats)\n        .fillna(0)\n    )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_small = group_and_reduce(train, train_labels)\ntest_small = group_and_reduce(test, test_labels)\n\nprint(train_small.shape)\ntrain_small.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"titles = train_labels.title.unique()\ntitle2mode = {}\n\nfor title in titles:\n    mode = train_labels[train_labels.title == title].accuracy_group.value_counts().index[0]\n    title2mode[title] = mode\n\ntrain_labels['title_mode'] = train_labels.title.apply(lambda title: title2mode[title])\ntest_labels['title_mode'] = test_labels.title.apply(lambda title: title2mode[title])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_train = pd.get_dummies(\n    (\n        train_labels.set_index('installation_id')\n        .drop(columns=['num_correct', 'num_incorrect', 'accuracy', 'game_session'])\n        .join(train_small)\n    ), \n    columns=['title']\n)\n\n# Experimental: only take the last record of each installation\nfinal_train = final_train.reset_index().groupby('installation_id').apply(lambda x: x.iloc[-1])\nfinal_train = final_train.drop(columns='installation_id')\n\nprint(final_train.shape)\nfinal_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_test = pd.get_dummies(test_labels.set_index('installation_id').join(test_small), columns=['title'])\n\nprint(final_test.shape)\nfinal_test.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cv_train(X, y, cv, **kwargs):\n    \"\"\"\n    Author: https://www.kaggle.com/xhlulu/\n    Source: https://www.kaggle.com/xhlulu/ds-bowl-2019-simple-lgbm-using-aggregated-data\n    \"\"\"\n    models = []\n    \n    kf = KFold(n_splits=cv, random_state=2019)\n    \n    for train, test in kf.split(X):\n        x_train, x_val, y_train, y_val = X[train], X[test], y[train], y[test]\n        \n        train_set = lgb.Dataset(x_train, y_train)\n        val_set = lgb.Dataset(x_val, y_val)\n        \n        model = lgb.train(train_set=train_set, valid_sets=[train_set, val_set], **kwargs)\n        models.append(model)\n        \n        if kwargs.get(\"verbose_eval\"):\n            print(\"\\n\" + \"=\"*50 + \"\\n\")\n    \n    return models\n\ndef cv_predict(models, X):\n    \"\"\"\n    Author: https://www.kaggle.com/xhlulu/\n    Source: https://www.kaggle.com/xhlulu/ds-bowl-2019-simple-lgbm-using-aggregated-data\n    \"\"\"\n    return np.mean([model.predict(X) for model in models], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = final_train.drop(columns='accuracy_group').values\ny = final_train['accuracy_group'].values\n\nparams = {\n    'learning_rate': 0.01,\n    'bagging_fraction': 0.95,\n    'feature_fraction': 0.2,\n    'max_height': 3,\n    'lambda_l1': 10,\n    'lambda_l2': 10,\n    'metric': 'multiclass',\n    'objective': 'multiclass',\n    'num_classes': 4,\n    'random_state': 2019\n}\n\nmodels = cv_train(X, y, cv=10, params=params, num_boost_round=1000,\n                  early_stopping_rounds=100, verbose_eval=500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = final_test.drop(columns=['accuracy_group'])\ntest_pred = cv_predict(models=models, X=X_test).argmax(axis=1)\n\nfinal_test['accuracy_group'] = test_pred\nfinal_test[['accuracy_group']].to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for model in models:\n    lgb.plot_importance(model, max_num_features=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}