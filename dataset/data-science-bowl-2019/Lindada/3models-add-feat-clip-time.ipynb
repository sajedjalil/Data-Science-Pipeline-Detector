{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport time\nimport copy\nfrom tqdm import tqdm_notebook as tqdm\nfrom collections import Counter\nfrom scipy import stats\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.model_selection import KFold, StratifiedKFold,GroupKFold\nimport gc\nimport json\nimport lightgbm as lgb\nimport seaborn as sns\nfrom functools import partial\nimport xgboost as xgb\nimport scipy as sp\nfrom numba import jit\npd.set_option('display.max_columns', 1000)\nimport matplotlib.pyplot as plt\nimport random\nkaggle=True\nif kaggle:\n    dirs=\"/kaggle/input/data-science-bowl-2019/\"\nelse:\n    dirs=\"./\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nimport os\ndef SeedEverything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    return\nSeedEverything(1993)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DEBUG = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_data():\n    if DEBUG:\n        print('Reading train.csv file....')\n        train = pd.read_csv(dirs+'train.csv', nrows=100000)\n        print('Training.csv file have {} rows and {} columns'.format(train.shape[0], train.shape[1]))\n\n        print('Reading test.csv file....')\n        test = pd.read_csv(dirs+'test.csv', nrows=100000)\n        print('Test.csv file have {} rows and {} columns'.format(test.shape[0], test.shape[1]))\n    else:\n        print('Reading train.csv file....')\n        train = pd.read_csv(dirs+'train.csv')\n        print('Training.csv file have {} rows and {} columns'.format(train.shape[0], train.shape[1]))\n\n        print('Reading test.csv file....')\n        test = pd.read_csv(dirs+'test.csv')\n        print('Test.csv file have {} rows and {} columns'.format(test.shape[0], test.shape[1]))\n\n    print('Reading train_labels.csv file....')\n    train_labels = pd.read_csv(dirs+'train_labels.csv')\n    print('Train_labels.csv file have {} rows and {} columns'.format(train_labels.shape[0], train_labels.shape[1]))\n\n    print('Reading specs.csv file....')\n    specs = pd.read_csv(dirs+'specs.csv')\n    print('Specs.csv file have {} rows and {} columns'.format(specs.shape[0], specs.shape[1]))\n\n    print('Reading sample_submission.csv file....')\n    sample_submission = pd.read_csv(dirs+'sample_submission.csv')\n    print('Sample_submission.csv file have {} rows and {} columns'.format(sample_submission.shape[0], sample_submission.shape[1]))\n    \n    result=[]\n    for event_id,df in train.groupby('event_id'):\n        if event_id=='27253bdc':\n            result.append({'event_id':event_id,'event_code':df['event_code'].iloc[0],'title':\"ALL Clips\",'type':\"Clip\",'world':\"ALL worlds\"})\n        else:\n            result.append({'event_id':event_id,'event_code':df['event_code'].iloc[0],'title':df['title'].iloc[0],'type':df['type'].iloc[0],'world':df['world'].iloc[0]})\n    title_code=pd.DataFrame(result)\n    specs=pd.merge(specs,title_code,how='outer',right_on='event_id',left_on='event_id')   \n    return train, test, train_labels, specs, sample_submission\n\ntrain, test, train_labels, specs, sample_submission = read_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nmedia_sequence = pd.read_csv(\"../input/dsb2019-external-data/media_sequence.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(media_sequence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[train.installation_id.isin(train_labels.installation_id.unique())].reset_index(drop=True)\ntrain.shape\nspecs2 = pd.read_csv(dirs+'specs.csv')\n\nlist_of_event_args = list(set(specs2['args'].unique()))\nevent_args_map = dict(zip(list_of_event_args, np.arange(len(list_of_event_args))))\nspecs2[\"args\"]=specs2[\"args\"].map(event_args_map)\n\nlist_of_event_info = list(set(specs2['info'].unique()))\nevent_info_map = dict(zip(list_of_event_info, np.arange(len(list_of_event_info))))\nspecs2[\"info\"]=specs2[\"info\"].map(event_info_map)\n\nargs_list=specs2[\"args\"].value_counts().add_prefix('args_').index.tolist()\nargs_label=dict(zip(np.arange(len(args_list)), args_list))\ninfo_list=specs2[\"info\"].value_counts().add_prefix('info_').index.tolist()\ninfo_label=dict(zip(np.arange(len(info_list)), info_list))\n\ntrain=pd.merge(train,specs2,on=[\"event_id\"],how=\"left\")\ntest=pd.merge(test,specs2,on=[\"event_id\"],how=\"left\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode_title(train, test):\n    # make a list with all the unique 'titles' from the train and test set\n    list_of_user_activities = list(set(train['title']))\n    list_of_event_code = list(set(train['event_code']))\n    list_of_event_id = list(set(train['event_id']))\n    list_of_worlds = list(set(train['world']))\n    \n    list_of_user_activities=sorted(list_of_user_activities)\n    list_of_event_code=sorted(list_of_event_code)\n    list_of_event_id=sorted(list_of_event_id)\n    list_of_worlds=sorted(list_of_worlds)\n    # create a dictionary numerating the titles\n    title_enc= dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n    world_enc = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n    \n    assess_titles = list(set(train[train['type'] == 'Assessment']['title'].value_counts().index).union(set(test[test['type'] == 'Assessment']['title'].value_counts().index)))\n    assess_titles = sorted(assess_titles)\n    \n    win_code = dict(zip(list_of_user_activities, (4100*np.ones(len(list_of_user_activities))).astype('int')))\n    win_code['Bird Measurer (Assessment)'] = 4110\n    # convert text into datetime\n    train['timestamp'] = pd.to_datetime(train['timestamp'])\n    test['timestamp'] = pd.to_datetime(test['timestamp'])\n    return train, test,win_code, list_of_user_activities, list_of_event_code, list_of_event_id,list_of_worlds,title_enc,world_enc,assess_titles\n\ntrain, test,win_code, list_of_user_activities, list_of_event_code, list_of_event_id,list_of_worlds,title_enc,world_enc,assess_titles=encode_title(train,test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"| code | argument | method_in_session | method_between_session | 备注 | 含义 |  \n| --- | ---| --- | ---| --- | --- |\n|2030|misses|ema|ema|minmaxscale|beatround\n|2030|round|max|ema|minmaxscale|\n|2030|duration|ema|ema|minmaxscale|\n|4020/4025|correct|count| ema| norm|一次操作\n|4020/4025|round|max|ema|norm|\n|4100/4110|correct|count|\n|4080|duration|ema|ema|norm|\n|4040|duration|ema|ema|norm|一次拖动\n\ndict:  event_id:[argument1,argument2,....]"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"code=[2030,2030,2030,(4020,4025),(4020,4025),(4100,4110),(4040)]\nargument=['\"misses\"','\"round\"','\"duration\"','\"correct\"','\"round\"','\"correct\"','\"duration\"','\"duration\"']\nmethod_in_session=['ema','ema','ema','count_true','count']\n\ninteresting_args=[\n    [2030,'\"misses\"',\"ema\",\"ema\"],\n    [2030,'\"round\"',\"max\",\"ema\"],\n    [2030,'\"duration\"',\"ema\",\"ema\"],\n    [(4020,4025),'\"correct\"',\"count_true\",\"ema\"],\n    [(4020,4025),'\"correct\"',\"count_false\",\"ema\"],\n    [(4020,4025),'\"round\"',\"max\",\"ema\"],\n    [(4100,4110),'\"correct\"',\"count_true\",\"ema\"],\n    [(4100,4110),'\"correct\"',\"count_false\",\"ema\"],\n    [4040,'\"duration\"',\"ema\",\"ema\"]\n]\n\n\n\n\nuseful_codes={2030,4020,4025,4040,4100,4110}\ndef get_event_data_dict(specs,interesting_args,useful_codes):\n    event_id_to_args={}\n    key_set=set()\n    for i in range(len(specs)):\n        args_event_id=[]\n        row=specs.iloc[i]\n        event_code=row['event_code']\n        event_id=row['event_id']\n        title=row['title']\n        if event_code not in useful_codes:\n            continue\n        collect_args=[]\n        for arg in interesting_args:\n            code_match=event_code in arg[0] if type(arg[0])==tuple else event_code==arg[0]\n            if code_match and arg[1] in row['args']:\n                key=title+'_'.join([str(c) for c in arg[0]]) if type(arg[0])==tuple else title+'_'+str(arg[0])\n                key+='_'+arg[1][1:-1]+'_'+arg[2]+'_'+arg[3]\n                collect_args.append([arg[1][1:-1],key,arg[2],arg[3]])\n                #print(\"ID {} code {} add {} to key {}, methods {} {}\".format(event_id,event_code,arg[1][1:-1],key,arg[2],arg[3]))\n                key_set.add(key)\n            else:\n                pass\n                #print(\"ID {} code {} does not have {}\".format(event_id,event_code,arg[1][1:-1]))\n        if collect_args:\n            event_id_to_args[event_id]=collect_args\n    return event_id_to_args,key_set\nevent_id_to_args,key_set=get_event_data_dict(specs,interesting_args,useful_codes)\nprint(len(key_set))\nkey_set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ema_momentum_in_session=0.75\nema_momentum_between_session=0.75\nclass data_logger(object):\n    def __init__(self,event_id_to_args):\n        self.event_id_to_args=event_id_to_args\n        self.installation_status={}\n    \n    def log_data(self,session):\n        session_status={}\n        update_method={}\n        do_count_ids=set()\n        for event_id,data_str in zip(session['event_id'],session['event_data']): \n            args=self.event_id_to_args.get(event_id)\n            if args is None:\n                continue\n            event_data=json.loads(data_str)\n            for arg_pair in args:\n                if arg_pair[2]=='count_true' or arg_pair[2]=='count_false':\n                    do_count_ids.add(event_id)\n                    continue\n                new_val=event_data[arg_pair[0]]\n                if arg_pair[1] not in session_status:\n                    if arg_pair[2]=='mean':\n                        session_status[arg_pair[1]]=[]\n                    else:\n                        session_status[arg_pair[1]]=new_val\n                else:\n                    if arg_pair[2]==\"ema\":\n                        session_status[arg_pair[1]]=ema_momentum_in_session*session_status[arg_pair[1]]+(1-ema_momentum_in_session)*new_val\n                    elif arg_pair[2]=='max':\n                        session_status[arg_pair[1]]=max(session_status[arg_pair[1]],new_val)\n                    elif arg_pair[2]=='min':\n                        session_status[arg_pair[1]]=min(session_status[arg_pair[1]],new_val)\n                    elif arg_pair[2]=='sum':\n                        session_status[arg_pair[1]]=session_status[arg_pair[1]]+new_val\n                    elif arg_pair[2]=='mean':\n                        session_status[arg_pair[1]].append(new_val)\n                    else:\n                        raise NotImplementedError\n                        \n                update_method[arg_pair[1]]=arg_pair[3]  #inter session method\n        #count true false\n        for count_id in do_count_ids:\n            target_df=session[session.event_id==count_id]\n            args=self.event_id_to_args.get(count_id)\n            num_true=0\n            num_false=0\n            save_key=\"\"\n            for arg_pair in args:\n                if arg_pair[2]=='count_true':\n                    num_true=target_df['event_data'].str.contains('true').sum()\n                    session_status[arg_pair[1]]=num_true\n                    update_method[arg_pair[1]]=arg_pair[3]\n                    save_key=arg_pair[1]\n                elif arg_pair[2]=='count_false':\n                    num_false=target_df['event_data'].str.contains('false').sum()    \n                    session_status[arg_pair[1]]=num_false\n                    update_method[arg_pair[1]]=arg_pair[3]\n            session_status['_'.join(save_key.split(\"_\")[:-2]+['accuracy'])]=num_true/(num_false+num_true)\n            update_method['_'.join(save_key.split(\"_\")[:-2]+['accuracy'])]=\"ema\"\n            \n        #update installation_status\n        for key in session_status.keys():\n            if type(session_status[key]) is list:\n                session_status[key]=np.mean(session_status[key])\n            if key not in self.installation_status:\n                if update_method[key]=='mean':\n                    self.installation_status[key]=[]\n                else:\n                    self.installation_status[key]=session_status[key]\n            else:    \n                if update_method[key]=='ema':\n                    self.installation_status[key]=ema_momentum_between_session*self.installation_status[key]+\\\n                                                    (1-ema_momentum_between_session)*session_status[key]\n                elif update_method[key]=='max':\n                    self.installation_status[key]=max(self.installation_status[key],session_status[key])\n                elif update_method[key]=='min':\n                    self.installation_status[key]=min(self.installation_status[key],session_status[key])\n                elif update_method[key]=='sum':\n                    self.installation_status[key]=self.installation_status[key]+session_status[key]\n                elif update_method[key]=='mean':\n                    self.installation_status[key].append(session_status[key])\n                else:\n                    raise NotImplementedError\n             \n    def get_data(self):\n        \n        return {key: self.installation_status[key] if type(self.installation_status[key]) is not list else np.mean(self.installation_status[key]) \\\n                for key in self.installation_status}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_top_city = {\n    \"Tree Top City - Level 1\": 1,\n    \"Ordering Spheres\": 2,\n    \"All Star Sorting\": 3,\n    \"Costume Box\": 4,\n    \"Fireworks (Activity)\": 5,\n    \"12 Monkeys\": 6,\n    \"Tree Top City - Level 2\": 7,\n    \"Flower Waterer (Activity)\": 8,\n    \"Pirate's Tale\": 9,\n    \"Mushroom Sorter (Assessment)\": 10,\n    \"Air Show\": 11,\n    \"Treasure Map\": 12,\n    \"Tree Top City - Level 3\": 13,\n    \"Crystals Rule\": 14,\n    \"Rulers\": 15,\n    \"Bug Measurer (Activity)\": 16,\n    \"Bird Measurer (Assessment)\": 17,\n}\nmagma_peak = {\n    \"Magma Peak - Level 1\": 1,\n    \"Sandcastle Builder (Activity)\": 2,\n    \"Slop Problem\": 3,\n    \"Scrub-A-Dub\": 4,\n    \"Watering Hole (Activity)\": 5,\n    \"Magma Peak - Level 2\": 6,\n    \"Dino Drink\": 7,\n    \"Bubble Bath\": 8,\n    \"Bottle Filler (Activity)\": 9,\n    \"Dino Dive\": 10,\n    \"Cauldron Filler (Assessment)\": 11,\n}\ncrystal_caves = {\n    \"Crystal Caves - Level 1\": 1,\n    \"Chow Time\": 2,\n    \"Balancing Act\": 3,\n    \"Chicken Balancer (Activity)\": 4,\n    \"Lifting Heavy Things\": 5,\n    \"Crystal Caves - Level 2\": 6,\n    \"Honey Cake\": 7,\n    \"Happy Camel\": 8,\n    \"Cart Balancer (Assessment)\": 9,\n    \"Leaf Leader\": 10,\n    \"Crystal Caves - Level 3\": 11,\n    \"Heavy, Heavier, Heaviest\": 12,\n    \"Pan Balance\": 13,\n    \"Egg Dropper (Activity)\": 14,\n    \"Chest Sorter (Assessment)\": 15,\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clip_time = {'Welcome to Lost Lagoon!':19,'Tree Top City - Level 1':17,'Ordering Spheres':61, 'Costume Box':61,\n        '12 Monkeys':109,'Tree Top City - Level 2':25, 'Pirate\\'s Tale':80, 'Treasure Map':156,'Tree Top City - Level 3':26,\n        'Rulers':126, 'Magma Peak - Level 1':20, 'Slop Problem':60, 'Magma Peak - Level 2':22, 'Crystal Caves - Level 1':18,\n        'Balancing Act':72, 'Lifting Heavy Things':118,'Crystal Caves - Level 2':24, 'Honey Cake':142, 'Crystal Caves - Level 3':19,\n        'Heavy, Heavier, Heaviest':61}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_data(user_sample, test_set=False):\n    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n    accuracy_groups = {\"acc_group_0\":0, \"acc_group_1\":0, \"acc_group_2\":0, \"acc_group_3\":0}\n    game_time_dict = {'Clip_gametime':0, 'Game_gametime':0, 'Activity_gametime':0, 'Assessment_gametime':0}\n    accumulated_accuracy_group = 0\n    accumulated_accuracy = 0\n    accumulated_correct_attempts = 0 \n    accumulated_uncorrect_attempts = 0\n    accumulated_actions = 0\n    \n    last_world='NONE'\n    last_activity_type='Clip'\n    time_last_activity=None\n    \n    give_up={\"give_up_\"+assess:0 for assess in assess_titles}\n    \n    durations ={'ema_duration_'+eve:0 for eve in list_of_user_activities}\n    \n    last_accuracy_title = {'acc_' + title: -1 for title in assess_titles}\n    \n    world_count={world:0 for world in list_of_worlds}\n    event_code_count = {ev: 0 for ev in list_of_event_code}\n    event_id_count = {eve: 0 for eve in list_of_event_id}\n    title_count = {eve: 0 for eve in list_of_user_activities} \n    counter = 0\n    assess_durations=[]\n    tree_top_city_list = []\n    magma_peak_list = []\n    crystal_caves_list = []\n    clip_durations = []\n\n    installation_logger=data_logger(event_id_to_args)\n    \n    all_assessments = []\n    for session_id, session in user_sample.groupby('game_session', sort=False):\n        session_type = session['type'].iloc[0]\n        session_title = session['title'].iloc[0]\n        session_world = session['world'].iloc[0]\n        \n        if session_type == 'Clip':\n            clip_durations.append((clip_time[session_title]))\n        \n        if (session_type == 'Assessment') & (test_set or len(session)>1):\n            features={}\n            features['installation_id'] = session['installation_id'].iloc[-1]\n            features['session_id'] = session_id\n            features['session_title'] = session_title\n            features['session_world'] = session_world\n\n            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n            if accuracy == 0:\n                features['accuracy_group'] = 0\n            elif accuracy == 1:\n                features['accuracy_group'] = 3\n            elif accuracy == 0.5:\n                features['accuracy_group'] = 2\n            else:\n                features['accuracy_group'] = 1\n            features.update(accuracy_groups.copy())\n            accuracy_groups[\"acc_group_\"+str(features['accuracy_group'])] += 1   \n            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n            features['ratio']=accumulated_correct_attempts/(accumulated_correct_attempts+accumulated_uncorrect_attempts) if (accumulated_correct_attempts+accumulated_uncorrect_attempts)!=0 else 0\n            accumulated_correct_attempts += true_attempts \n            accumulated_uncorrect_attempts += false_attempts\n    \n            features['accumulated_accuracy'] = accumulated_accuracy/counter if counter > 0 else 0\n            accumulated_accuracy += accuracy\n            features['accumulated_accuracy_group'] = accumulated_accuracy_group/counter if counter > 0 else 0\n            accumulated_accuracy_group += features['accuracy_group']\n            \n            features.update(last_accuracy_title.copy())\n            last_accuracy_title['acc_' + session_title] = accuracy\n        \n            features['accumulated_actions'] = accumulated_actions\n            features['last_world']=last_world\n            features['last_activity_type']=last_activity_type\n            features['time_to_last_activity']=(session.iloc[0, 2]-time_last_activity).seconds if time_last_activity is not None else 0\n            \n            features.update(event_code_count.copy())\n\n            features.update(installation_logger.get_data())\n  \n            features.update(title_count.copy())\n            features.update(durations.copy())\n            features.update(user_activities_count.copy())\n            features.update(event_id_count.copy())\n            features.update(give_up.copy())\n            features.update(world_count.copy())\n            features.update(game_time_dict.copy())\n            \n            if assess_durations == []:\n                features['assess_duration_mean'] = 0\n            else:\n                features['assess_duration_mean'] = np.mean(assess_durations)\n            assess_durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n            \n            \n            if true_attempts+false_attempts==0:\n                give_up[\"give_up_\"+session_title]+=1\n                \n            if tree_top_city_list == []:\n                features['tree_top_city_max'] = 0\n                features['tree_top_city_cnt'] = 0\n                features['tree_top_city_cover'] = 0\n            else:\n                features['tree_top_city_max'] = np.max(tree_top_city_list)\n                features['tree_top_city_cnt'] = len(tree_top_city_list)\n                features['tree_top_city_cover'] = float(len(set(tree_top_city_list))) / len(tree_top_city)\n            if magma_peak_list == []:\n                features['magma_peak_max'] = 0\n                features['magma_peak_cnt'] = 0\n                features['magma_peak_cover'] = 0\n            else:\n                features['magma_peak_max'] = np.max(magma_peak_list)\n                features['magma_peak_cnt'] = len(magma_peak_list)\n                features['magma_peak_cover'] = float(len(set(magma_peak_list))) / len(magma_peak)\n            if crystal_caves_list == []:\n                features['crystal_caves_max'] = 0\n                features['crystal_caves_cnt'] = 0\n                features['crystal_caves_cover'] = 0\n            else:\n                features['crystal_caves_max'] = np.max(crystal_caves_list)\n                features['crystal_caves_cnt'] = len(crystal_caves_list)\n                features['crystal_caves_cover'] = float(len(set(crystal_caves_list))) / len(crystal_caves)\n            if session_title in tree_top_city:\n                last_game = tree_top_city[session_title] - 1\n                if last_game in tree_top_city_list:\n                    features['played_last_game'] = 1\n                else:\n                    features['played_last_game'] = 0\n            elif session_title in magma_peak:\n                last_game = magma_peak[session_title] - 1\n                if last_game in magma_peak_list:\n                    features['played_last_game'] = 1\n                else:\n                    features['played_last_game'] = 0\n            elif session_title in crystal_caves:\n                last_game = crystal_caves[session_title] - 1\n                if last_game in crystal_caves_list:\n                    features['played_last_game'] = 1\n                else:\n                    features['played_last_game'] = 0\n            else:\n                features['played_last_game'] = 0\n            \n            if clip_durations == []:\n                features['Clip_duration_mean'] = 0\n                features['Clip_duration_std'] = 0\n            else:\n                features['Clip_duration_mean'] = np.mean(clip_durations)\n                features['Clip_duration_std'] = np.std(clip_durations)\n            \n            if test_set:\n                all_assessments.append(features)\n            elif true_attempts+false_attempts > 0:\n                all_assessments.append(features)\n            counter += 1\n        \n        #log event data\n\n        installation_logger.log_data(session)\n        #update counters\n        def update_counters(counter: dict, col: str):\n            num_of_session_count = Counter(session[col])\n            for k in num_of_session_count.keys():\n                if counter.get(k) is not None:\n                    counter[k] += num_of_session_count[k]\n            return counter\n        event_code_count = update_counters(event_code_count, \"event_code\")\n        event_id_count = update_counters(event_id_count, \"event_id\")\n        \n        title_count[session_title]+=1\n        #title_event_code_count = update_counters(title_event_code_count, 'title_event_code')\n        \n        session_duration=(session.iloc[-1, 2] - session.iloc[0, 2]).seconds\n        durations['ema_duration_'+session_title]= session_duration if durations['ema_duration_'+session_title]==0 else (0.2*session_duration+0.8*durations['ema_duration_'+session_title])\n        accumulated_actions += len(session)\n\n        user_activities_count[session_type] += 1\n        world_count[session_world]+=1\n        last_world = session_world \n        last_activity_type = session_type\n        time_last_activity= session.iloc[-1, 2]  \n        \n        game_time_dict[session_type+'_gametime'] = (game_time_dict[session_type+'_gametime'] + (session['game_time'].iloc[-1]/1000.0))/2.0\n        \n        # sequence features update\n        if session_title in tree_top_city:\n            tree_top_city_list.append(tree_top_city[session_title])\n        if session_title in magma_peak:\n            magma_peak_list.append(magma_peak[session_title])\n        if session_title in crystal_caves:\n            crystal_caves_list.append(crystal_caves[session_title])\n        \n    # if it't the test_set, only the last assessment must be predicted, the previous are scraped\n    if test_set:\n        return all_assessments[-1]\n    # in the train_set, all assessments goes to the dataset\n    return all_assessments\n\ndef get_train_and_test(train, test):\n    compiled_train = []\n    compiled_test = []\n    for i, (ins_id, user_sample) in enumerate(tqdm(train.groupby('installation_id', sort = False))):\n        compiled_train += get_data(user_sample)\n    for ins_id, user_sample in tqdm(test.groupby('installation_id', sort = False)):\n        test_data = get_data(user_sample, test_set = True)\n        compiled_test.append(test_data)\n    reduce_train = pd.DataFrame(compiled_train)\n    reduce_test = pd.DataFrame(compiled_test)\n    return reduce_train, reduce_test          \n\nreduce_train, reduce_test= get_train_and_test(train, test)\nreduce_train.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in reduce_train.columns]\nreduce_test.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in reduce_test.columns]\nassess_titles=[\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in assess_titles]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type_enc={'Clip':0, 'Activity': 1, 'Assessment': 2, 'Game':3}\nreduce_train['session_title']=reduce_train['session_title'].replace(title_enc).astype(int)\nreduce_train['session_world']=reduce_train['session_world'].replace(world_enc).astype(int)\nreduce_train['last_world']=reduce_train['last_world'].replace(world_enc).astype(int)\nreduce_train['last_activity_type']=reduce_train['last_activity_type'].replace(type_enc).astype(int)\n\nreduce_test['session_title']=reduce_test['session_title'].replace(title_enc).astype(int)\nreduce_test['session_world']=reduce_test['session_world'].replace(world_enc).astype(int)\nreduce_test['last_world']=reduce_test['last_world'].replace(world_enc).astype(int)\nreduce_test['last_activity_type']=reduce_test['last_activity_type'].replace(type_enc).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freq=reduce_train['session_title'].value_counts()\nfrequency_enc=dict(zip(freq.index,freq))\nreduce_train['session_title']=reduce_train['session_title'].replace(frequency_enc).astype(int)\nreduce_test['session_title']=reduce_test['session_title'].replace(frequency_enc).astype(int)\nreduce_train_true=reduce_train.copy()\nreduce_test_true=reduce_test.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get score"},{"metadata":{"trusted":true},"cell_type":"code","source":"del train,test\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_data():\n    if DEBUG:\n        print('Reading train.csv file....')\n        train = pd.read_csv(dirs+'train.csv', nrows=100000)\n        print('Training.csv file have {} rows and {} columns'.format(train.shape[0], train.shape[1]))\n\n        print('Reading test.csv file....')\n        test = pd.read_csv(dirs+'test.csv', nrows=100000)\n        print('Test.csv file have {} rows and {} columns'.format(test.shape[0], test.shape[1]))\n    else:\n        print('Reading train.csv file....')\n        train = pd.read_csv(dirs+'train.csv')\n        print('Training.csv file have {} rows and {} columns'.format(train.shape[0], train.shape[1]))\n\n        print('Reading test.csv file....')\n        test = pd.read_csv(dirs+'test.csv')\n        print('Test.csv file have {} rows and {} columns'.format(test.shape[0], test.shape[1]))\n\n    print('Reading train_labels.csv file....')\n    train_labels = pd.read_csv(dirs+'train_labels.csv')\n    print('Train_labels.csv file have {} rows and {} columns'.format(train_labels.shape[0], train_labels.shape[1]))\n\n    print('Reading specs.csv file....')\n    specs = pd.read_csv(dirs+'specs.csv')\n    print('Specs.csv file have {} rows and {} columns'.format(specs.shape[0], specs.shape[1]))\n\n    print('Reading sample_submission.csv file....')\n    sample_submission = pd.read_csv(dirs+'sample_submission.csv')\n    print('Sample_submission.csv file have {} rows and {} columns'.format(sample_submission.shape[0], sample_submission.shape[1]))\n    return train, test, train_labels, specs, sample_submission\ntrain, test, train_labels, specs, sample_submission = read_data()\ntrain = train[train.installation_id.isin(train_labels.installation_id.unique())].reset_index(drop=True)\nlist_of_event_args = list(set(specs['args'].unique()))\nevent_args_map = dict(zip(list_of_event_args, np.arange(len(list_of_event_args))))\nspecs[\"args\"]=specs[\"args\"].map(event_args_map)\n\nlist_of_event_info = list(set(specs['info'].unique()))\nevent_info_map = dict(zip(list_of_event_info, np.arange(len(list_of_event_info))))\nspecs[\"info\"]=specs[\"info\"].map(event_info_map)\n\nargs_list=specs[\"args\"].value_counts().add_prefix('args_').index.tolist()\nargs_label=dict(zip(np.arange(len(args_list)), args_list))\ninfo_list=specs[\"info\"].value_counts().add_prefix('info_').index.tolist()\ninfo_label=dict(zip(np.arange(len(info_list)), info_list))\n\ntrain=pd.merge(train,specs,on=[\"event_id\"],how=\"left\")\ntest=pd.merge(test,specs,on=[\"event_id\"],how=\"left\")\nprint(train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Credits go to Andrew Lukyanenko\n\ndef encode_title(train, test, train_labels):\n    # encode title\n\n    # make a list with all the unique 'titles' from the train and test set\n    list_of_user_activities = sorted(list(set(train['title'].unique()).union(set(test['title'].unique()))))\n    # make a list with all the unique 'event_code' from the train and test set\n    list_of_event_code = sorted(list(set(train['event_code'].unique()).union(set(test['event_code'].unique()))))\n    list_of_event_id = sorted(list(set(train['event_id'].unique()).union(set(test['event_id'].unique()))))\n    # make a list with all the unique worlds from the train and test set\n    list_of_worlds = sorted(list(set(train['world'].unique()).union(set(test['world'].unique()))))\n    # create a dictionary numerating the titles\n    activities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n    activities_labels = dict(zip(np.arange(len(list_of_user_activities)), list_of_user_activities))\n    activities_world = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n    assess_titles = sorted(list(set(train[train['type'] == 'Assessment']['title'].value_counts().index).union(set(test[test['type'] == 'Assessment']['title'].value_counts().index))))\n    # replace the text titles with the number titles from the dict\n    train['title'] = train['title'].map(activities_map)\n    test['title'] = test['title'].map(activities_map)\n    train['world'] = train['world'].map(activities_world)\n    test['world'] = test['world'].map(activities_world)\n    train_labels['title'] = train_labels['title'].map(activities_map)\n    win_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\n    # then, it set one element, the 'Bird Measurer (Assessment)' as 4110, 10 more than the rest\n    win_code[activities_map['Bird Measurer (Assessment)']] = 4110\n    \n    train['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), train['title'], train['event_code']))\n    test['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), test['title'], test['event_code']))\n    all_title_event_code = sorted(list(set(train[\"title_event_code\"].unique()).union(test[\"title_event_code\"].unique())))\n    # convert text into datetime\n    train['timestamp'] = pd.to_datetime(train['timestamp'])\n    test['timestamp'] = pd.to_datetime(test['timestamp'])\n    return train, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code\n\n# get usefull dict with maping encode\ntrain, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code = encode_title(train, test, train_labels)\n\ncategoricals = ['session_title']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\ndef cnt_miss(df):\n    cnt = 0\n    for e in range(len(df)):\n        x = df['event_data'].iloc[e]\n        y = json.loads(x)['misses']\n        cnt += y\n    return cnt\n\ndef update_counters(counter: dict, col: str,session):\n    num_of_session_count = Counter(session[col])\n    for k in num_of_session_count.keys():\n        x = k\n        counter[x] += num_of_session_count[k]\n    return counter\n\ndef update_counters_event(counter: dict, col: str,session):\n    num_of_session_count = session[col].value_counts().add_prefix(col+'_').to_dict()\n    for k in num_of_session_count.keys():\n        counter[k] += num_of_session_count[k]\n    return counter\n\ndef get_data123(user_sample,lab, test_set=False):\n    all_assessments=[]\n    compiled_data=[]\n    for i, session in user_sample.groupby('game_session', sort=False):\n        # i = game_session_id\n        # session is a DataFrame that contain only one game_session\n        \n        session_type = session['type'].iloc[0]\n        session_title = session['title'].iloc[0]\n        session_title_text = activities_labels[session_title]\n        Assessment_time=session['timestamp'].iloc[0]\n        event_code_count: Dict[str, int] = {ev: 0 for ev in list_of_event_code}\n        event_id_count: Dict[str, int] = {eve: 0 for eve in list_of_event_id}\n        event_info_count: Dict[str, int] = {eve: 0 for eve in info_list}\n        \n        if session_type==lab:\n            features = {}\n            features[\"game_title\"]=session_title\n            features[\"game_event_count\"]=session['event_count'].iloc[-1]\n            features[\"game_game_time\"]=session['game_time'].iloc[-1]\n            event_code_count = update_counters(event_code_count, \"event_code\",session)\n            #event_id_count = update_counters(event_id_count, \"event_id\",session)\n            event_info_count = update_counters_event(event_info_count, \"info\",session)\n\n            \n            features.update(event_code_count.copy())\n            features.update(event_info_count.copy())\n            compiled_data.append(features)\n           \n        if (session_type == 'Assessment') & (test_set or len(session)>1):\n            # search for event_code 4100, that represents the assessments trial\n            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n            # then, check the numbers of wins and the number of losses\n            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n         \n             \n          \n            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n            if accuracy == 0:\n                accuracy_group = 0\n            elif accuracy == 1:\n                accuracy_group = 3\n            elif accuracy == 0.5:\n                accuracy_group = 2\n            else:\n                accuracy_group = 1\n            if test_set:\n                if true_attempts+false_attempts > 0:\n                    reduce_game = pd.DataFrame(compiled_data)\n                    reduce_game['installation_id'] = session['installation_id'].iloc[-1]\n                    reduce_game[\"game_session\"]=session['game_session'].iloc[-1]\n                    reduce_game[\"session_title\"]=session_title\n                    reduce_game[\"true_attempts\"]=true_attempts\n                    reduce_game[\"false_attempts\"]=false_attempts\n                    reduce_game[\"accuracy\"]=accuracy\n                    reduce_game[\"accuracy_group\"]=accuracy_group\n                    all_assessments.append(reduce_game)\n                elif len(session)==1:\n                    reduce_game = pd.DataFrame(compiled_data)\n                    reduce_game['installation_id'] = session['installation_id'].iloc[-1]\n                    reduce_game[\"game_session\"]=session['game_session'].iloc[-1]\n                    reduce_game[\"session_title\"]=session_title\n                    reduce_game[\"true_attempts\"]=666\n                    reduce_game[\"false_attempts\"]=666\n                    reduce_game[\"accuracy\"]=666\n                    reduce_game[\"accuracy_group\"]=666\n                    all_assessments.append(reduce_game)\n                    \n            \n            elif true_attempts+false_attempts > 0:\n                reduce_game = pd.DataFrame(compiled_data)\n                reduce_game['installation_id'] = session['installation_id'].iloc[-1]\n                reduce_game[\"game_session\"]=session['game_session'].iloc[-1]\n                reduce_game[\"session_title\"]=session_title\n                reduce_game[\"true_attempts\"]=true_attempts\n                reduce_game[\"false_attempts\"]=false_attempts\n                reduce_game[\"accuracy\"]=accuracy\n                reduce_game[\"accuracy_group\"]=accuracy_group\n                all_assessments.append(reduce_game)\n    \n    return all_assessments","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compiled_data = []\nfor i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort=False)), total=train.installation_id.nunique(), desc='Installation_id', position=0):\n    compiled_data += get_data123(user_sample,\"Game\")\nreduce_train = pd.concat(compiled_data)\nreduce_train.shape\n\ncompiled_data = []\nfor ins_id, user_sample in tqdm(test.groupby('installation_id', sort=False), total=test.installation_id.nunique(), desc='Installation_id', position=0):\n    compiled_data += get_data123(user_sample,\"Game\", test_set=True)\nreduce_test_all = pd.concat(compiled_data)\nreduce_test_all.shape\n\nreduce_test=reduce_test_all[reduce_test_all[\"accuracy\"]==666].copy().reset_index(drop=True)\nreduce_train=pd.concat([reduce_train,reduce_test_all[reduce_test_all[\"accuracy\"]!=666]]).reset_index(drop=True)\nreduce_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feat=[f for f in reduce_train.columns if f not in ['installation_id', 'game_session','true_attempts', 'false_attempts', 'accuracy', 'accuracy_group']]\nprint(feat)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"from numba import jit\n@jit\ndef qwk(a1, a2):\n    \"\"\"\n    Source: https://www.kaggle.com/c/data-science-bowl-2019/discussion/114133#latest-660168\n\n    :param a1:\n    :param a2:\n    :param max_rat:\n    :return:\n    \"\"\"\n    max_rat = 3\n    a1 = np.asarray(a1, dtype=int)\n    a2 = np.asarray(a2, dtype=int)\n\n    hist1 = np.zeros((max_rat + 1, ))\n    hist2 = np.zeros((max_rat + 1, ))\n\n    o = 0\n    for k in range(a1.shape[0]):\n        i, j = a1[k], a2[k]\n        hist1[i] += 1\n        hist2[j] += 1\n        o +=  (i - j) * (i - j)\n\n    e = 0\n    for i in range(max_rat + 1):\n        for j in range(max_rat + 1):\n            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n\n    e = e / a1.shape[0]\n\n    return 1 - o / e\n\ndef eval_qwk(y_true, y_pred):\n    \n#     y_pred[y_pred <= 1.12232214] = 0\n#     y_pred[np.where(np.logical_and(y_pred > 1.12232214, y_pred <= 1.73925866))] = 1\n#     y_pred[np.where(np.logical_and(y_pred > 1.73925866, y_pred <= 2.22506454))] = 2\n#     y_pred[y_pred > 2.22506454] = 3\n    #coeff=[1.23795619,1.74348425,2.23639873]\n    coeff=[1.12934881,1.69659649,2.204893]\n    y_pred[y_pred <= coeff[0]] = 0\n    y_pred[np.where(np.logical_and(y_pred > coeff[0], y_pred <= coeff[1]))] = 1\n    y_pred[np.where(np.logical_and(y_pred > coeff[1], y_pred <= coeff[2]))] = 2\n    y_pred[y_pred > coeff[2]] = 3\n    \n#     y_pred[y_pred <= 0.94892782] = 0\n#     y_pred[np.where(np.logical_and(y_pred > 0.94892782, y_pred <= 1.69))] = 1\n#     y_pred[np.where(np.logical_and(y_pred > 1.69, y_pred <= 2.16))] = 2\n#     y_pred[y_pred >2.16] = 3\n    \n    return qwk(y_true, y_pred)\nimport lightgbm as lgb\ndef lgb_model(reduce_train,reduce_test,feature,random_state):\n    \n    params = {\n    'boosting_type': 'gbdt',\n    'metric': 'rmse',\n    'objective': 'regression',\n    'eval_metric': 'cappa',\n    #'metric': 'None',\n    'num_threads':-1,\n    'seed': random_state,\n    'learning_rate':0.05,\n    'max_depth': 11,\n    'lambda_l1': 1,\n    'lambda_l2': 1,\n    'bagging_fraction': 0.75,\n    'bagging_freq': 5,\n    'colsample_bytree':0.6,\n    'verbose': 100\n    }\n    # Additional parameters:\n    early_stop = 50\n    verbose_eval = 100\n    num_rounds = 10000\n    n_splits = 5\n\n    from sklearn.model_selection import KFold,GroupKFold,GroupShuffleSplit,StratifiedKFold\n    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n    models = []\n    scores=[]\n    y_trian = reduce_train['accuracy_group']\n    oof_train = np.zeros((reduce_train.shape[0]))\n    oof_test = np.zeros((reduce_test.shape[0]))\n    for train_index,valid_index in kf.split(reduce_train, y_trian):\n    \n        train_features = reduce_train.loc[train_index]\n        train_target = y_trian.loc[train_index]\n    \n        val_features = reduce_train.loc[valid_index]\n        val_target = y_trian.loc[valid_index]\n    \n        X_train = train_features[feature].values\n        X_val = val_features[feature].values\n    \n        d_train = lgb.Dataset(X_train, label=train_target)\n        d_valid = lgb.Dataset(X_val, label=val_target)\n        watchlist = [d_train, d_valid]\n    \n        print('training LGB:')\n        model = lgb.train(params,\n                      train_set=d_train,\n                      num_boost_round=num_rounds,\n                      valid_sets=watchlist,\n                      verbose_eval=verbose_eval,\n                      early_stopping_rounds=early_stop)\n    \n        val_pred = model.predict(X_val, num_iteration=model.best_iteration)\n        test_pred = model.predict(reduce_test[feature].values, num_iteration=model.best_iteration)\n        scores.append(eval_qwk(val_target,copy.deepcopy(val_pred)))\n        print(scores)\n        oof_train[valid_index] = val_pred\n        oof_test += test_pred/n_splits\n    print(np.mean(scores))\n    return oof_train,oof_test\nprint(reduce_train.shape,reduce_test.shape)\noof_train_one,oof_test_one=lgb_model(reduce_train.reset_index(drop=True),reduce_test.copy().reset_index(drop=True),feat,50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_feature_score = reduce_train[['installation_id', 'game_session']].copy()\ntrain_feature_score['score'] = oof_train_one\ntest_feature_score = reduce_test[['installation_id', 'game_session']].copy()\ntest_feature_score['score'] = oof_test_one\nfeature_score = pd.concat([train_feature_score, test_feature_score])\nfeature_agg=feature_score.groupby([\"game_session\",\"installation_id\"]).agg({'score': ['count','mean', 'sum', 'max','min','var']}).reset_index()\nfeature_agg.columns=[\"game_session\",\"installation_id\",'score_count','score_mean', 'score_sum', 'score_max', 'score_min', 'score_var']\nprint(feature_agg.shape)\nfeature_agg.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_feature_score,test_feature_score,feature_score\ndel reduce_train,reduce_test,reduce_test_all,compiled_data\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compiled_data = []\nfor i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort=False)), total=train.installation_id.nunique(), desc='Installation_id', position=0):\n    compiled_data += get_data123(user_sample,\"Activity\")\nreduce_train = pd.concat(compiled_data)\n\ncompiled_data = []\nfor ins_id, user_sample in tqdm(test.groupby('installation_id', sort=False), total=test.installation_id.nunique(), desc='Installation_id', position=0):\n    compiled_data += get_data123(user_sample,\"Activity\", test_set=True)\nreduce_test_all = pd.concat(compiled_data)\n\nreduce_test=reduce_test_all[reduce_test_all[\"accuracy\"]==666].copy().reset_index(drop=True)\nreduce_train=pd.concat([reduce_train,reduce_test_all[reduce_test_all[\"accuracy\"]!=666]]).reset_index(drop=True)\nreduce_train.shape\n\nfeat=[f for f in reduce_train.columns if f not in ['installation_id', 'game_session','true_attempts', 'false_attempts', 'accuracy', 'accuracy_group']]\nprint(feat)\n\nprint(reduce_train.shape,reduce_test.shape)\noof_train_one,oof_test_one=lgb_model(reduce_train.reset_index(drop=True),reduce_test.copy().reset_index(drop=True),feat,50)\n\ntrain_feature_score = reduce_train[['installation_id', 'game_session']].copy()\ntrain_feature_score['score'] = oof_train_one\ntest_feature_score = reduce_test[['installation_id', 'game_session']].copy()\ntest_feature_score['score'] = oof_test_one\nfeature_score = pd.concat([train_feature_score, test_feature_score])\n\nfeature_agg_Activity=feature_score.groupby([\"game_session\",\"installation_id\"]).agg({'score': ['count','mean', 'sum', 'max','min','var']}).reset_index()\nfeature_agg_Activity.columns=[\"game_session\",\"installation_id\",'score_countAct','score_meanAct', 'score_sumAct', 'score_maxAct', 'score_minAct', 'score_varAct']\nprint(feature_agg_Activity.shape)\nfeature_agg_Activity.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_feature_score,test_feature_score,feature_score\ndel reduce_train,reduce_test,reduce_test_all,compiled_data\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_train_true.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduce_train=pd.merge(reduce_train_true,feature_agg,left_on=[\"session_id\",\"installation_id\"],right_on=[\"game_session\",\"installation_id\"],how=\"left\")\nreduce_train=pd.merge(reduce_train,feature_agg_Activity,left_on=[\"session_id\",\"installation_id\"],right_on=[\"game_session\",\"installation_id\"],how=\"left\")\nreduce_test=pd.merge(reduce_test_true,feature_agg,left_on=[\"session_id\",\"installation_id\"],right_on=[\"game_session\",\"installation_id\"],how=\"left\")\nreduce_test=pd.merge(reduce_test,feature_agg_Activity,left_on=[\"session_id\",\"installation_id\"],right_on=[\"game_session\",\"installation_id\"],how=\"left\")\nreduce_test=reduce_test.drop(['game_session_y','game_session_x'],axis=1)\n\nreduce_train.to_csv('reduce_train.csv', index=False)\nreduce_test.to_csv('reduce_test.csv', index=False)\n\nreduce_train=reduce_train[reduce_test.columns]\najusted_test=reduce_test.copy()\nto_exclude=[]\nfor feature in ajusted_test.columns:\n    if feature not in ['installation_id','session_id','accuracy_group','session_title','session_world','last_world','last_activity_type','same_world_with_last']+\\\n                    [\"give_up_\"+assess for assess in assess_titles]+['acc_' + title for title in assess_titles]:\n        data = reduce_train[feature]\n        train_mean = data.mean()\n        data = ajusted_test[feature] \n        test_mean = data.mean()\n        try:\n            ajust_factor = train_mean / test_mean\n            if ajust_factor > 5 or ajust_factor < 0.2:\n                to_exclude.append(feature)\n                print(feature, train_mean, test_mean)\n            else:\n                ajusted_test[feature] *= ajust_factor\n        except:\n            to_exclude.append(feature)\n            print(feature, train_mean, test_mean)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@jit\ndef qwk(a1, a2):\n    \"\"\"\n    Source: https://www.kaggle.com/c/data-science-bowl-2019/discussion/114133#latest-660168\n\n    :param a1:\n    :param a2:\n    :return:\n    \"\"\"\n    max_rat = 3\n    a1 = np.asarray(a1, dtype=int)\n    a2 = np.asarray(a2, dtype=int)\n\n    hist1 = np.zeros((max_rat + 1, ))\n    hist2 = np.zeros((max_rat + 1, ))\n\n    o = 0\n    for k in range(a1.shape[0]):\n        i, j = a1[k], a2[k]\n        hist1[i] += 1\n        hist2[j] += 1\n        o +=  (i - j) * (i - j)\n\n    e = 0\n    for i in range(max_rat + 1):\n        for j in range(max_rat + 1):\n            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n\n    e = e / a1.shape[0]\n\n    return 1 - o / e\n\ndef eval_qwk_lgb_regr(y_true, y_pred):\n    \"\"\"\n    Fast cappa eval function for lgb.\n    \"\"\"\n    y_pred[y_pred <= regression_thresholds[0]] = 0\n    y_pred[np.where(np.logical_and(y_pred >regression_thresholds[0], y_pred <= regression_thresholds[1]))] = 1\n    y_pred[np.where(np.logical_and(y_pred > regression_thresholds[1], y_pred <= regression_thresholds[2]))] = 2\n    y_pred[y_pred > regression_thresholds[2]] = 3\n\n    # y_pred = y_pred.reshape(len(np.unique(y_true)), -1).argmax(axis=0)\n    return 'cappa', qwk(y_true, y_pred), True\n\nclass LGBWrapper_regr(object):\n    \"\"\"\n    A wrapper for lightgbm model so that we will have a single api for various models.\n    \"\"\"\n\n    def __init__(self):\n        self.model = lgb.LGBMRegressor()\n\n    def fit(self, X_train, y_train, X_valid=None, y_valid=None, X_holdout=None, y_holdout=None, params=None):\n        if params['objective'] == 'regression':\n            eval_metric = eval_qwk_lgb_regr\n        else:\n            eval_metric = 'auc'\n\n        eval_set = [(X_train, y_train)]\n        eval_names = ['train']\n        self.model = self.model.set_params(**params)\n\n        if X_valid is not None:\n            eval_set.append((X_valid, y_valid))\n            eval_names.append('valid')\n\n        if X_holdout is not None:\n            eval_set.append((X_holdout, y_holdout))\n            eval_names.append('holdout')\n\n        if 'cat_cols' in params.keys():\n            cat_cols = [col for col in params['cat_cols'] if col in X_train.columns]\n            if len(cat_cols) > 0:\n                categorical_columns = params['cat_cols']\n            else:\n                categorical_columns = 'auto'\n        else:\n            categorical_columns = 'auto'\n        #print(categorical_columns)\n        self.model.fit(X=X_train, y=y_train,\n                       eval_set=eval_set, eval_names=eval_names, eval_metric=eval_metric,\n                       verbose=params['verbose'], early_stopping_rounds=params['early_stopping_rounds'],\n                       categorical_feature=categorical_columns)\n\n        self.best_score_ = self.model.best_score_\n        self.feature_importances_ = self.model.feature_importances_\n\n    def predict(self, X_test):\n        return self.model.predict(X_test, num_iteration=self.model.best_iteration_)\n    \n    \nclass RegressorModel(object):\n    \"\"\"\n    A wrapper class for classification models.\n    It can be used for training and prediction.\n    Can plot feature importance and training progress (if relevant for model).\n    \"\"\"\n\n    def __init__(self, columns: list = None, model_wrapper=None,truncate_valid=False,seed=66):\n        \"\"\"\n        :param original_columns:\n        :param model_wrapper:\n        \"\"\"\n        self.columns = columns\n        self.model_wrapper = model_wrapper\n        self.result_dict = {}\n        self.train_one_fold = False\n        self.preprocesser = None\n        self.truncate_valid=truncate_valid\n        self.truncate_seed=seed\n\n    def fit(self, X: pd.DataFrame, y,\n            X_holdout: pd.DataFrame = None, y_holdout=None,\n            folds=None,\n            params: dict = None,\n            eval_metric='rmse',\n            cols_to_drop: list = None,\n            preprocesser=None,\n            transformers: dict = None,\n            adversarial: bool = False,\n            plot: bool = True):\n        \"\"\"\n        Training the model.\n\n        :param X: training data\n        :param y: training target\n        :param X_holdout: holdout data\n        :param y_holdout: holdout target\n        :param folds: folds to split the data. If not defined, then model will be trained on the whole X\n        :param params: training parameters\n        :param eval_metric: metric for validataion\n        :param cols_to_drop: list of columns to drop (for example ID)\n        :param preprocesser: preprocesser class\n        :param transformers: transformer to use on folds\n        :param adversarial\n        :return:\n        \"\"\"\n\n        if folds is None:\n            folds = KFold(n_splits=3, random_state=42)\n            self.train_one_fold = True\n\n        self.columns = X.columns if self.columns is None else self.columns\n        self.feature_importances = pd.DataFrame(columns=['feature', 'importance'])\n        self.trained_transformers = {k: [] for k in transformers}\n        self.transformers = transformers\n        self.models = []\n        self.folds_dict = {}\n        self.eval_metric = eval_metric\n        n_target = 1\n        self.oof = []\n        self.n_target = n_target\n        random.seed(self.truncate_seed)\n        X = X[self.columns]\n        if X_holdout is not None:\n            X_holdout = X_holdout[self.columns]\n\n        if preprocesser is not None:\n            self.preprocesser = preprocesser\n            self.preprocesser.fit(X, y)\n            X = self.preprocesser.transform(X, y)\n            self.columns = X.columns.tolist()\n            if X_holdout is not None:\n                X_holdout = self.preprocesser.transform(X_holdout)\n\n        for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y, X['installation_id'])):\n\n            if X_holdout is not None:\n                X_hold = X_holdout.copy()\n            else:\n                X_hold = None\n            self.folds_dict[fold_n] = {}\n            if params['verbose']:\n                print(f'Fold {fold_n + 1} started at {time.ctime()}')\n            self.folds_dict[fold_n] = {}\n\n            X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n            \n            if self.truncate_valid:\n                \n                truncated_index=[]\n                for iid in sorted(list(set(X_valid['installation_id']))):\n                    list_ = list(X_valid.loc[X_valid['installation_id'] == iid].index)\n                    cur = random.choices(list_, k=1)[0]\n                    truncated_index.append(cur)\n                X_valid=X_valid.loc[truncated_index]\n                y_valid=y_valid.loc[truncated_index]  \n            \n            if self.train_one_fold:\n                X_train = X[self.original_columns]\n                y_train = y\n                X_valid = None\n                y_valid = None\n\n            datasets = {'X_train': X_train, 'X_valid': X_valid, 'X_holdout': X_hold, 'y_train': y_train}\n            X_train, X_valid, X_hold = self.transform_(datasets, cols_to_drop)\n\n            self.folds_dict[fold_n]['columns'] = X_train.columns.tolist()\n\n            model = copy.deepcopy(self.model_wrapper)\n\n            if adversarial:\n                X_new1 = X_train.copy()\n                if X_valid is not None:\n                    X_new2 = X_valid.copy()\n                elif X_holdout is not None:\n                    X_new2 = X_holdout.copy()\n                X_new = pd.concat([X_new1, X_new2], axis=0)\n                y_new = np.hstack((np.zeros((X_new1.shape[0])), np.ones((X_new2.shape[0]))))\n                X_train, X_valid, y_train, y_valid = train_test_split(X_new, y_new)\n\n            model.fit(X_train, y_train, X_valid, y_valid, X_hold, y_holdout, params=params)\n\n            self.folds_dict[fold_n]['scores'] = model.best_score_\n\n            if not adversarial:\n                self.oof.append([model.predict(X_valid).reshape(-1),y_valid.values])\n\n            fold_importance = pd.DataFrame(list(zip(X_train.columns, model.feature_importances_)),\n                                           columns=['feature', 'importance'])\n            self.feature_importances = self.feature_importances.append(fold_importance)\n            self.models.append(model)\n\n        self.feature_importances['importance'] = self.feature_importances['importance'].astype(int)\n\n        # if params['verbose']:\n        self.calc_scores_()\n\n        if plot:\n            # print(classification_report(y, self.oof.argmax(1)))\n            fig, ax = plt.subplots(figsize=(16, 12))\n            plt.subplot(2, 2, 1)\n            self.plot_feature_importance(top_n=20)\n            plt.subplot(2, 2, 2)\n            self.plot_metric()\n            if not self.truncate_valid:\n                plt.subplot(2, 2, 3)\n                plt.hist(y.values.reshape(-1, 1) - self.oof)\n                plt.title('Distribution of errors')\n                plt.subplot(2, 2, 4)\n                plt.hist(self.oof)\n                plt.title('Distribution of oof predictions')\n\n    def transform_(self, datasets, cols_to_drop):\n        for name, transformer in self.transformers.items():\n            transformer.fit(datasets['X_train'], datasets['y_train'])\n            datasets['X_train'] = transformer.transform(datasets['X_train'])\n            if datasets['X_valid'] is not None:\n                datasets['X_valid'] = transformer.transform(datasets['X_valid'])\n            if datasets['X_holdout'] is not None:\n                datasets['X_holdout'] = transformer.transform(datasets['X_holdout'])\n            self.trained_transformers[name].append(transformer)\n        if cols_to_drop is not None:\n            cols_to_drop = [col for col in cols_to_drop if col in datasets['X_train'].columns]\n\n            datasets['X_train'] = datasets['X_train'].drop(cols_to_drop, axis=1)\n            if datasets['X_valid'] is not None:\n                datasets['X_valid'] = datasets['X_valid'].drop(cols_to_drop, axis=1)\n            if datasets['X_holdout'] is not None:\n                datasets['X_holdout'] = datasets['X_holdout'].drop(cols_to_drop, axis=1)\n        self.cols_to_drop = cols_to_drop\n        print(\"Dropping\",len(set(cols_to_drop)) ,\"columns First 10:\",cols_to_drop[:10])\n        return datasets['X_train'], datasets['X_valid'], datasets['X_holdout']\n\n    def calc_scores_(self):\n        print()\n        datasets = [k for k, v in [v['scores'] for k, v in self.folds_dict.items()][0].items() if len(v) > 0]\n        self.scores = {}\n        for d in datasets:\n            scores = [v['scores'][d][self.eval_metric] for k, v in self.folds_dict.items()]\n            print(f\"CV mean score on {d}: {np.mean(scores):.4f} +/- {np.std(scores):.4f} std.\")\n            self.scores[d] = np.mean(scores)\n\n    def predict(self, X_test, averaging: str = 'usual'):\n        \"\"\"\n        Make prediction\n\n        :param X_test:\n        :param averaging: method of averaging\n        :return:\n        \"\"\"\n        full_prediction = np.zeros((X_test.shape[0],1))\n        if self.preprocesser is not None:\n            X_test = self.preprocesser.transform(X_test)\n        for i in range(len(self.models)):\n            X_t = X_test.copy()\n            for name, transformers in self.trained_transformers.items():\n                X_t = transformers[i].transform(X_t)\n\n            if self.cols_to_drop is not None:\n                cols_to_drop = [col for col in self.cols_to_drop if col in X_t.columns]\n                X_t = X_t.drop(cols_to_drop, axis=1)\n            y_pred = self.models[i].predict(X_t[self.folds_dict[i]['columns']]).reshape(-1, full_prediction.shape[1])\n\n            # if case transformation changes the number of the rows\n            if full_prediction.shape[0] != len(y_pred):\n                full_prediction = np.zeros((y_pred.shape[0], 1))\n\n            if averaging == 'usual':\n                full_prediction += y_pred\n            elif averaging == 'rank':\n                full_prediction += pd.Series(y_pred).rank().values\n\n        return full_prediction / len(self.models)\n\n    def plot_feature_importance(self, drop_null_importance: bool = True, top_n: int = 10):\n        \"\"\"\n        Plot default feature importance.\n\n        :param drop_null_importance: drop columns with null feature importance\n        :param top_n: show top n columns\n        :return:\n        \"\"\"\n\n        top_feats = self.get_top_features(drop_null_importance, top_n)\n        feature_importances = self.feature_importances.loc[self.feature_importances['feature'].isin(top_feats)]\n        feature_importances['feature'] = feature_importances['feature'].astype(str)\n        top_feats = [str(i) for i in top_feats]\n        sns.barplot(data=feature_importances, x='importance', y='feature', orient='h', order=top_feats)\n        plt.title('Feature importances')\n\n    def get_top_features(self, drop_null_importance: bool = True, top_n: int = 10):\n        \"\"\"\n        Get top features by importance.\n\n        :param drop_null_importance:\n        :param top_n:\n        :return:\n        \"\"\"\n        grouped_feats = self.feature_importances.groupby(['feature'])['importance'].mean()\n        if drop_null_importance:\n            grouped_feats = grouped_feats[grouped_feats != 0]\n        return list(grouped_feats.sort_values(ascending=False).index)[:top_n]\n\n    def plot_metric(self):\n        \"\"\"\n        Plot training progress.\n        Inspired by `plot_metric` from https://lightgbm.readthedocs.io/en/latest/_modules/lightgbm/plotting.html\n\n        :return:\n        \"\"\"\n        full_evals_results = pd.DataFrame()\n        for model in self.models:\n            evals_result = pd.DataFrame()\n            for k in model.model.evals_result_.keys():\n                evals_result[k] = model.model.evals_result_[k][self.eval_metric]\n            evals_result = evals_result.reset_index().rename(columns={'index': 'iteration'})\n            full_evals_results = full_evals_results.append(evals_result)\n\n        full_evals_results = full_evals_results.melt(id_vars=['iteration']).rename(columns={'value': self.eval_metric,\n                                                                                            'variable': 'dataset'})\n        sns.lineplot(data=full_evals_results, x='iteration', y=self.eval_metric, hue='dataset')\n        plt.title('Training progress')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class OptimizedRounder(object):\n    \"\"\"\n    An optimizer for rounding thresholds\n    to maximize Quadratic Weighted Kappa (QWK) score\n    # https://www.kaggle.com/naveenasaithambi/optimizedrounder-improved\n    \"\"\"\n    def __init__(self):\n        self.coef_ = 0\n\n    def _kappa_loss(self, coef, X, y):\n        \"\"\"\n        Get loss according to\n        using current coefficients\n        \n        :param coef: A list of coefficients that will be used for rounding\n        :param X: The raw predictions\n        :param y: The ground truth labels\n        \"\"\"\n        X_p = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n\n        return -qwk(y, X_p)\n\n    def fit(self, X, y,initial_coef):\n        \"\"\"\n        Optimize rounding thresholds\n        \n        :param X: The raw predictions\n        :param y: The ground truth labels\n        \"\"\"\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n\n    def predict(self, X, coef):\n        \"\"\"\n        Make predictions with specified thresholds\n        \n        :param X: The raw predictions\n        :param coef: A list of coefficients that will be used for rounding\n        \"\"\"\n        return pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels = [0, 1, 2, 3])\n\n\n    def coefficients(self):\n        \"\"\"\n        Return the optimized coefficients\n        \"\"\"\n        return self.coef_['x']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del_cols = []\nfor col in reduce_train.columns.values:\n    if len(reduce_train[col].value_counts())==0:\n        del_cols.append(col)\n        continue\n    counts = reduce_train[col].value_counts().iloc[0]\n    if (counts / reduce_train.shape[0]) >= 0.9:\n        del_cols.append(col)\nprint(str(len(del_cols)) + \" features removed!\")\ndel_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"counter = 0\nto_remove = []\nneglect_feat=['installation_id','session_id','accuracy_group']\n\nfeatures=[x for x in reduce_train.columns if x not in neglect_feat]\nfor feat_a in features:\n    for feat_b in features:\n        if feat_a != feat_b and feat_a not in to_remove and feat_b not in to_remove:\n            c = np.corrcoef(reduce_train[feat_a], reduce_train[feat_b])[0][1]\n            if c > 0.995:\n                counter += 1\n                to_remove.append(feat_b)\n                print('{}: FEAT_A: {} FEAT_B: {} - Correlation: {}'.format(counter, feat_a, feat_b, c))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"list_of_event_code = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in list_of_event_code]\nlist_of_event_id = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in list_of_event_id]\n\ncols_to_drop = ['session_id', 'installation_id','accuracy_group',\n                'installation_session_count',\n                'installation_duration_mean',\n                'installation_title_nunique',\n                'installation_event_code_count_mean',\n                \"4070\",\n\n               ]\ncols_to_drop+=del_cols\ncols_to_drop+=to_exclude\ncols_to_drop+=to_remove\n#for cols in same_features.values():\n#    cols_to_drop+=cols\nprint(len(set(cols_to_drop)))\ncols_to_drop","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categoricals=['session_title','session_world','last_world','last_activity_type']\n\nparams = {'n_estimators':2000,\n          'boosting_type': 'gbdt',\n          'objective': 'regression',\n          'metric': 'rmse',\n          'subsample': 0.85,\n          'subsample_freq': 1,\n          'learning_rate': 0.01,\n          'feature_fraction': 0.75,\n          'max_depth': 10,\n          'num_leaves':31,\n          'min_data_in_leaf':50,\n          'cat_cols':categoricals,\n          'lambda_l1': 2,\n          'lambda_l2':9,\n          'verbose': 100,\n          'early_stopping_rounds': 200,\n          'eval_metric': 'cappa',\n          'seed':888,\n          'n_jobs':8\n         }\nn_fold=5\nfolds = GroupKFold(n_splits=n_fold)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"#regression_thresholds=np.array([1.18400496,1.65723726,2.13351805])\n#regression_thresholds=np.array([1.1,1.7,2.2])\nregression_thresholds=np.array([0.5,1.5,2.5])\ny = reduce_train['accuracy_group']\nregressor_model1 = RegressorModel(model_wrapper=LGBWrapper_regr(),truncate_valid=False,)\nregressor_model1.fit(X=reduce_train, y=y, folds=folds, params=params, preprocesser=None, transformers={},\n                    eval_metric='cappa', cols_to_drop=cols_to_drop,plot=False)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"oof_predicts=np.concatenate([x[0] for x in regressor_model1.oof],axis=0)\noof_y=np.concatenate([x[1] for x in regressor_model1.oof],axis=0)\n\n#oof_predicts=regressor_model1.oof\n\ncoefficients=[0.5,1.5,2.5]\n\nfor i in range(8):\n    optR = OptimizedRounder()\n    optR.fit(oof_predicts.reshape(-1,), oof_y,initial_coef=coefficients)\n    coefficients = optR.coefficients()\n    oof_rounded=optR.predict(oof_predicts.reshape(-1,),coefficients)\n    qwk_score=qwk(oof_y, oof_rounded)\n    print(\"Round\",i+1,\"    Rounding Coefficients:\",coefficients,\"QWK score:\",qwk_score)\n\ncoef1=coefficients\nqwkscore1=qwk_score\n\noof_predicts=np.concatenate([x[0] for x in regressor_model1.oof],axis=0)\noof_y=np.concatenate([x[1] for x in regressor_model1.oof],axis=0)\ncoefficients=[1.1,1.7,2.2]\n\nfor i in range(8):\n    optR = OptimizedRounder()\n    optR.fit(oof_predicts.reshape(-1,), oof_y,initial_coef=coefficients)\n    coefficients = optR.coefficients()\n    oof_rounded=optR.predict(oof_predicts.reshape(-1,),coefficients)\n    qwk_score=qwk(oof_y, oof_rounded)\n    print(\"Round\",i+1,\"    Rounding Coefficients:\",coefficients,\"QWK score:\",qwk_score)\ncoef2=coefficients\nqwkscore2=qwk_score\nif qwkscore2>qwkscore1:\n    print(\"use coefficient2\",qwkscore2)\n    coefficients=coef2\nelse:\n    print(\"use coefficient1\",qwkscore1)\n    coefficients=coef1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Base_Model(object):\n    \n    def __init__(self, train_df, test_df, features, categoricals=[], n_splits=5, verbose=True):\n        self.train_df = train_df\n        self.test_df = test_df\n        self.features = features\n        self.n_splits = n_splits\n        self.categoricals = categoricals\n        self.target = 'accuracy_group'\n        self.cv = self.get_cv()\n        self.verbose = verbose\n        self.params = self.get_params()\n        self.y_pred, self.score, self.model = self.fit()\n        \n    def train_model(self, train_set, val_set):\n        raise NotImplementedError\n        \n    def get_cv(self):\n        cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n        return cv.split(self.train_df, self.train_df[self.target])\n    \n    def get_params(self):\n        raise NotImplementedError\n        \n    def convert_dataset(self, x_train, y_train, x_val, y_val):\n        raise NotImplementedError\n        \n    def convert_x(self, x):\n        return x\n    \n    def fit(self):\n        oof_pred = np.zeros((len(reduce_train), ))\n        y_pred = np.zeros((len(reduce_test), ))\n        for fold, (train_idx, val_idx) in enumerate(self.cv):\n            x_train, x_val = self.train_df[self.features].iloc[train_idx], self.train_df[self.features].iloc[val_idx]\n            y_train, y_val = self.train_df[self.target][train_idx], self.train_df[self.target][val_idx]\n            train_set, val_set = self.convert_dataset(x_train, y_train, x_val, y_val)\n            model = self.train_model(train_set, val_set)\n            conv_x_val = self.convert_x(x_val)\n            oof_pred[val_idx] = model.predict(conv_x_val).reshape(oof_pred[val_idx].shape)\n            x_test = self.convert_x(self.test_df[self.features])\n            y_pred += model.predict(x_test).reshape(y_pred.shape) / self.n_splits\n            print('Partial score of fold {} is: {}'.format(fold, eval_qwk_lgb_regr(y_val, oof_pred[val_idx])[1]))\n        _, loss_score, _ = eval_qwk_lgb_regr(self.train_df[self.target], oof_pred)\n        if self.verbose:\n            print('Our oof cohen kappa score is: ', loss_score)\n        return y_pred, loss_score, model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Xgb_Model(Base_Model):\n    \n    def train_model(self, train_set, val_set):\n        verbosity = 100 if self.verbose else 0\n        return xgb.train(self.params, train_set, \n                         num_boost_round=5000, evals=[(train_set, 'train'), (val_set, 'val')], \n                         verbose_eval=verbosity, early_stopping_rounds=100)\n        \n    def convert_dataset(self, x_train, y_train, x_val, y_val):\n        train_set = xgb.DMatrix(x_train, y_train)\n        val_set = xgb.DMatrix(x_val, y_val)\n        return train_set, val_set\n    \n    def convert_x(self, x):\n        return xgb.DMatrix(x)\n        \n    def get_params(self):\n        params = {'colsample_bytree': 0.8,                 \n            'learning_rate': 0.01,\n            'max_depth': 10,\n            'subsample': 1,\n            'objective':'reg:squarederror',\n            #'eval_metric':'rmse',\n            'min_child_weight':3,\n            'gamma':0.25,\n            'n_estimators':5000}\n\n        return params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_feature=[x for x in reduce_train.columns if x not in cols_to_drop]\nxgb_model = Xgb_Model(reduce_train, ajusted_test, features, categoricals=categoricals)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostRegressor\nclass Catb_Model(Base_Model):\n    \n    def train_model(self, train_set, val_set):\n        verbosity = 100 if self.verbose else 0\n        clf = CatBoostRegressor(**self.params)\n        clf.fit(train_set['X'], \n                train_set['y'], \n                eval_set=(val_set['X'], val_set['y']),\n                verbose=verbosity, \n                cat_features=self.categoricals\n               )\n        return clf\n        \n    def convert_dataset(self, x_train, y_train, x_val, y_val):\n        train_set = {'X': x_train, 'y': y_train}\n        val_set = {'X': x_val, 'y': y_val}\n        return train_set, val_set\n        \n    def get_params(self):\n        params = {'loss_function': 'RMSE',\n                   'task_type': \"CPU\",\n                   'iterations': 5000,\n                   'od_type': \"Iter\",\n                    'depth': 10,\n                  'colsample_bylevel': 0.5, \n                   'early_stopping_rounds': 100,\n                    'l2_leaf_reg': 18,\n                   'random_seed': 42,\n                    'use_best_model': True\n                    }\n        return params","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ctb_feature=[x for x in reduce_train.columns if x not in cols_to_drop]\nctb_model = Catb_Model(reduce_train, ajusted_test, features, categoricals=categoricals)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_pred = 0.7*regressor_model1.predict(ajusted_test)+0.2*xgb_model.y_pred.reshape(-1,1)+0.1*ctb_model.y_pred.reshape(-1,1)\ndist = Counter(reduce_train['accuracy_group'])\n#dist = Counter(oof_y)\nfor k in dist:\n    dist[k] /= len(reduce_train['accuracy_group'])\nacum = 0\nbound = np.zeros(3).astype(np.float)\nfor i in range(3):\n    acum += dist[i]\n    bound[i] = np.percentile(final_pred, acum * 100)\n    \nprint(bound)\n\ndef classify(x):\n    if x <= bound[0]:\n        return 0\n    elif x <= bound[1]:\n        return 1\n    elif x <= bound[2]:\n        return 2\n    else:\n        return 3\n\nfinal_pred = np.array(list(map(classify, final_pred)))\nsample_submission['accuracy_group'] = final_pred.astype(int)\nsample_submission.to_csv('./submission.csv', index=False)\nsample_submission['accuracy_group'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oof_predicts=np.concatenate([x[0] for x in regressor_model1.oof],axis=0)\noof_y=np.concatenate([x[1] for x in regressor_model1.oof],axis=0)\noof_final_pred=np.array(list(map(classify, oof_predicts)))\nqwk(oof_final_pred,oof_y)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"","execution_count":0,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"04adf37a4c06456f814a52df8c2672e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c23c6873c8e4f489b3a288ec09c2769":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e720af258034819bf703f0df30a5a97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04adf37a4c06456f814a52df8c2672e1","placeholder":"​","style":"IPY_MODEL_87e1de9a93be4aff8595b4316b92e493","value":" 3614/3614 [16:46&lt;00:00,  3.59it/s]"}},"17691b0793e54b1da23b9e4c98e23ded":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e790472494247ed82b25e4630a033f8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b50f54c38ee14007bc0b61674e11da4c","placeholder":"​","style":"IPY_MODEL_17691b0793e54b1da23b9e4c98e23ded","value":" 686/686 [06:40&lt;00:00,  1.71it/s]"}},"206e3337bd134a9bbf9dd6257956aa56":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27bcc0ecf5b3436dbe4f0309035b4ed2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb8cfff26df34db0af3b10bfda694c74","IPY_MODEL_94ba8b3e8be849b29be21643200c78d0"],"layout":"IPY_MODEL_d707f68fa1dc4f148a8c4ce5788f070b"}},"2a12d643c1b84ca3adf68cfbc47a05ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"303589f89d084fcab950038fa613e9cc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a7e04efb0b04fd89e9c6519e2b84aa4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"42c6b5d7f549488cb3ee981b3ffc9fa1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_843f8f5707904a87a10bddf80e708543","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ff92587b70b64b02a6616f092e622117","value":1000}},"440cc4a9391945cca97b46a0ab7c0af4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e2360a0823f44a61a96ddd3c7de26473","IPY_MODEL_1e790472494247ed82b25e4630a033f8"],"layout":"IPY_MODEL_52c9d97b180441e98e4ec84938eae1a9"}},"44cacc19cd5f452c99c316fa58552e83":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4562371b76a249fcaf613076943f6d03":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f473c3c7e02e42b69799f2b05700bc35","IPY_MODEL_fcf8d37d7b634d6289aa80bb5b733d66"],"layout":"IPY_MODEL_80fe0b3bc7e943129896f13415fe0acc"}},"4b32409c9c544cd092ee452bde490c02":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52429c5cb36e435a92bd57f2836324cf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52c9d97b180441e98e4ec84938eae1a9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e5a27dd6a1b42b79169f0f070e87844":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60056dc0635b4bf3ba26c75937d4c2ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6309d3efee7a44118cb6c7767314986b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6777da314ab945559605ae8d9ab87ccc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b2e8d1115834a249b6bb499b76ed418":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76efff09c3ec4c8881129621ff500568":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"80fe0b3bc7e943129896f13415fe0acc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83dca7265a9f45b281b17a0b19a207fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"843f8f5707904a87a10bddf80e708543":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"855b6ce0f5ce4eae9916fa4a8651fbf1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_6309d3efee7a44118cb6c7767314986b","max":3614,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2a12d643c1b84ca3adf68cfbc47a05ad","value":3614}},"87e1de9a93be4aff8595b4316b92e493":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"899649a361e74406bf26395e0a0431e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_855b6ce0f5ce4eae9916fa4a8651fbf1","IPY_MODEL_c2ea7c1a07074716b2eb4f66a857f221"],"layout":"IPY_MODEL_a46a6fd3aa954c15b64076bbcd082f81"}},"90981576f4f04e11a815cd7660945174":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"94ba8b3e8be849b29be21643200c78d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_303589f89d084fcab950038fa613e9cc","placeholder":"​","style":"IPY_MODEL_bd5faff5d94d445fa3563bad80ecba2f","value":" 3614/3614 [16:27&lt;00:00,  3.66it/s]"}},"984271d9221c474b9f0c5940b2413e2d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_42c6b5d7f549488cb3ee981b3ffc9fa1","IPY_MODEL_d57a684d375f4fd1aa2d265f0bb072bd"],"layout":"IPY_MODEL_6b2e8d1115834a249b6bb499b76ed418"}},"99ee13ea664d4ad3a2d68ada43c1f153":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"a46a6fd3aa954c15b64076bbcd082f81":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2976aab972f4ec28e84654952fc01cf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"b3a198b276194c2e848766c69ca7c390":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b50f54c38ee14007bc0b61674e11da4c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7adac73bb454e1c8546d96804bde972":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd5faff5d94d445fa3563bad80ecba2f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c0e23ab71f0d4a08984653114d9d11de":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2ea7c1a07074716b2eb4f66a857f221":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e5a27dd6a1b42b79169f0f070e87844","placeholder":"​","style":"IPY_MODEL_b7adac73bb454e1c8546d96804bde972","value":" 3614/3614 [09:58&lt;00:00,  6.04it/s]"}},"c49b521b804348cf9fbdb5880a89cf53":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b32409c9c544cd092ee452bde490c02","placeholder":"​","style":"IPY_MODEL_90981576f4f04e11a815cd7660945174","value":" 1000/1000 [02:42&lt;00:00,  6.15it/s]"}},"ce513b2fda8a4166a90758ffa458342a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"d57a684d375f4fd1aa2d265f0bb072bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6777da314ab945559605ae8d9ab87ccc","placeholder":"​","style":"IPY_MODEL_83dca7265a9f45b281b17a0b19a207fb","value":" 1000/1000 [01:33&lt;00:00, 10.67it/s]"}},"d59f1167168142228078edd0beb5bad9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_def646a24caa42a5895ceef32270006f","IPY_MODEL_c49b521b804348cf9fbdb5880a89cf53"],"layout":"IPY_MODEL_60056dc0635b4bf3ba26c75937d4c2ae"}},"d707f68fa1dc4f148a8c4ce5788f070b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9ead228275a435c96f03de9a9f52ef5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da3b38a4b18641e5a11c010605a0f6d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e55cd5469f2949889d7ec9d842d815be","IPY_MODEL_0e720af258034819bf703f0df30a5a97"],"layout":"IPY_MODEL_0c23c6873c8e4f489b3a288ec09c2769"}},"def646a24caa42a5895ceef32270006f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Installation_id: 100%","description_tooltip":null,"layout":"IPY_MODEL_b3a198b276194c2e848766c69ca7c390","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b2976aab972f4ec28e84654952fc01cf","value":1000}},"e2360a0823f44a61a96ddd3c7de26473":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"100%","description_tooltip":null,"layout":"IPY_MODEL_edbfbb54182341ae8f4f081cfb065145","max":686,"min":0,"orientation":"horizontal","style":"IPY_MODEL_76efff09c3ec4c8881129621ff500568","value":686}},"e55cd5469f2949889d7ec9d842d815be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Installation_id: 100%","description_tooltip":null,"layout":"IPY_MODEL_44cacc19cd5f452c99c316fa58552e83","max":3614,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a7e04efb0b04fd89e9c6519e2b84aa4","value":3614}},"eb8cfff26df34db0af3b10bfda694c74":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Installation_id: 100%","description_tooltip":null,"layout":"IPY_MODEL_206e3337bd134a9bbf9dd6257956aa56","max":3614,"min":0,"orientation":"horizontal","style":"IPY_MODEL_99ee13ea664d4ad3a2d68ada43c1f153","value":3614}},"edbfbb54182341ae8f4f081cfb065145":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f473c3c7e02e42b69799f2b05700bc35":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"IntProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"IntProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"Installation_id: 100%","description_tooltip":null,"layout":"IPY_MODEL_c0e23ab71f0d4a08984653114d9d11de","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ce513b2fda8a4166a90758ffa458342a","value":1000}},"fcf8d37d7b634d6289aa80bb5b733d66":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52429c5cb36e435a92bd57f2836324cf","placeholder":"​","style":"IPY_MODEL_d9ead228275a435c96f03de9a9f52ef5","value":" 1000/1000 [02:46&lt;00:00,  5.99it/s]"}},"ff92587b70b64b02a6616f092e622117":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":1}