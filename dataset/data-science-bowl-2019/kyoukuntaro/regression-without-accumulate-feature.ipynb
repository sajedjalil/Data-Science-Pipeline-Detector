{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Object\n- In this note book, we treat this task as regression task.\n- We use accuracy instead of accuracy_group.\n- We determine thresholds by cross validation.\n- We do not use accumulate feature.\n\n## Reference\n- https://www.kaggle.com/c/data-science-bowl-2019/discussion/114133#latest-657027"},{"metadata":{},"cell_type":"markdown","source":"## Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport lightgbm as lgb\nfrom sklearn.model_selection import KFold, train_test_split, GroupKFold\nfrom sklearn.metrics import confusion_matrix\nimport os\nimport gc\nfrom sklearn.utils import shuffle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"titles = ['12 Monkeys', 'Treasure Map', 'Lifting Heavy Things', 'Crystal Caves - Level 2', 'Dino Drink', 'Air Show', 'Honey Cake', 'Scrub-A-Dub', \\\n          'Welcome to Lost Lagoon!', 'Heavy, Heavier, Heaviest', 'Rulers', 'Bottle Filler (Activity)', 'Fireworks (Activity)', 'Magma Peak - Level 1', \\\n          'Mushroom Sorter (Assessment)', 'Magma Peak - Level 2', 'Bubble Bath', 'Ordering Spheres', 'Leaf Leader', 'Sandcastle Builder (Activity)', \\\n          'Costume Box', 'Chicken Balancer (Activity)', 'Crystals Rule', 'Tree Top City - Level 1', 'Bug Measurer (Activity)', 'Chow Time', 'Bird Measurer (Assessment)', \\\n          'Watering Hole (Activity)', 'Happy Camel', 'Pan Balance', 'Crystal Caves - Level 1', 'Egg Dropper (Activity)', \"Pirate's Tale\", 'Cauldron Filler (Assessment)', \\\n          'Crystal Caves - Level 3', 'Tree Top City - Level 2', 'Balancing Act', 'Slop Problem', 'Dino Dive', 'All Star Sorting', 'Tree Top City - Level 3', \\\n          'Chest Sorter (Assessment)', 'Flower Waterer (Activity)', 'Cart Balancer (Assessment)']\n\nevents = [['27253bdc'], ['27253bdc'], ['27253bdc'], ['27253bdc'], \\\n          ['7f0836bf', '792530f8', '51311d7a', '6c517a88', 'a29c5338', '6f8106d9', '9ed8f6da', '77ead60d', '4d6737eb', '16dffff1', '4d911100', '1996c610', 'f806dc10', '5be391b5', 'ab4ec3a4', 'c6971acf', '74e5f8a7', 'e5734469', '89aace00'],\\\n          ['65abac75', '6f4bd64e', 'bcceccc6', '9b4001e4', 'd2659ab4', '58a0de5c', '06372577', 'f5b8c21a', 'e04fb33d', 'f28c589a', '28f975ea', '14de4c5d', '15ba1109', 'd88ca108', 'dcb1663e', 'dcb55a27', '7423acbc', '1575e76c', 'a1bbe385'],\\\n          ['27253bdc'], ['f7e47413', '4a09ace1', 'dcaede90', 'c1cac9a2', '6d90d394', '08fd73f3', 'ac92046e', '92687c59', '2b9272f4', '5a848010', '5c3d2b2f', '7040c096', '37c53127', '26fd2d99', 'd88e8f25', 'cf82af56', 'f71c4741', '73757a5e'],\\\n          ['27253bdc'], ['27253bdc'], ['27253bdc'], ['15a43e5b', '67439901', '47efca07', '5f5b2617', 'e9c52111', 'd3f1e122', 'bb3e370b', 'd2278a3b', '90efca10', 'df4940d3', 'b7530680'],\\\n          ['02a42007', 'beb0a7b9', '4901243f', '884228c8', 'b88f38da', 'e694a35b', 'f54238ee', '611485c5'], ['27253bdc'], \\\n          ['9d29771f', '7da34a02', 'c7128948', '83c6c409', 'fbaf3456', '5f0eb72c', '88d4a5be', '160654fd', '3dfd4aa4', 'db02c830', 'eb2c19cd', '28ed704e', '0d18d96c', 'a1e4395d', 'c74f40cd', '6c930e6e', '13f56524', '3bfd1a65', 'a52b92d5', 'a5be6304', '25fa8af4'],\\\n          ['27253bdc'], ['8f094001', '29a42aea', '0413e89d', '1beb320a', 'ecc36b7f', 'ad148f58', '8d84fa81', '3bb91dda', '99abe2bb', '6aeafed4', 'a0faea5d', '85de926c', '55115cbd', '5859dfb6', '857f21c0', 'c54cf6c5', '15eb4a7d', 'd06f75b5', '1340b8d7', '90ea0bac', '6f4adc4b', '895865f3', '1cf54632', '99ea62f3'],\\\n          ['27253bdc'], ['e5c9df6f', '53c6e11a', 'f32856e4', 'e57dd7af', '8ac7cce4', '3afde5dd', '3b2048ee', '01ca3a3c', '7dfe6d8a', '262136f4', 'fd20ea40', '763fc34e', 'b012cd7f', '33505eae', '2a512369', '86ba578b', '67aa2ada', '29f54413'],\\\n          ['84538528', '37937459', '5e812b27', '30df3273', 'c58186bf', '77261ab5', '9ee1c98c', 'b2dba42b', '1325467d', '1bb5fbdb'], ['27253bdc'], \\\n          ['cdd22e43', '56bcd38d', '4bb2f698', 'ea321fb1', '756e5507', '499edb7c', '46cd75b4', '84b0e0c8', '16667cc5', '85d1b0de'], \\\n          ['3ddc79c3', 'e720d930', 'a1192f43', '5154fc30', 'cc5087a3', '93edfe2e', '3babcb9b', '86c924c4', '3323d7e9', '7cf1bc53', '44cb4907', '8b757ab8', '5e3ea25a', '48349b14'],\\\n          ['27253bdc'], ['363c86c9', '565a3990', '8d748b58', '022b4259', '0a08139c', 'e79f3763', '2ec694de', 'c7f7f0e1', '71fe8f75'],\\\n          ['63f13dd7', '2230fab4', '47026d5f', '9e6b7fb5', 'cb6010f8', '6f445b57', 'cfbd47c8', 'd185d3ea', '0330ab6a', '0d1da71f', '7372e1a5', '4ef8cdd3', '19967db1', '7ec0c298', '56817e2b', 'f93fc684', '7d093bf9'],\\\n          ['a76029ee', '7525289a', '3393b68b', 'e37a2b78', '1375ccb7', 'ad2fc29c', '45d01abe', 'a16a373e', 'bdf49a58', 'd38c2fd7', '4a4c3d21', '070a5291', '6077cc36', 'ec138c1c', 'f56e0afc', '8fee50e2', '51102b85', 'f6947f54', '17113b36', '731c0cbe'], \\\n          ['71e712d8', '1b54d27f', 'e7e44842', '49ed92e9', 'c952eb01', '2fb91ec1', 'a6d66e51', 'd2e9262e', 'f50fc6c1', 'bd701df8', 'e64e2cfd'],\\\n          ['d51b1749', '69fdac0a', '46b50ba8', 'a2df0760', '05ad839b', '37db1c2f', 'a8a78786', '3bf1cf26', 'a7640a16', '6bf9e3e1', '8d7e386c', '8af75982', '3d8c61b0', '1af8be29', 'c7fe2a55', 'abc5811c', 'd9c005dd', 'c2baf0bd', 'c189aaf2', '3bb91ced', '0ce40006', '36fa3ebe'], \\\n          ['0086365d', 'a5e9da97', 'e4d32835', 'f3cd5473', '907a054b', 'c51d8688', 'cf7638f3', '9c5ef70c', '804ee27f', '2a444e03', 'a592d54e', '6cf7d25c', 'e7561dd2', 'bc8f2793', '1c178d24', '250513af', 'e080a381', '15f99afc'], \\\n          ['27253bdc'], ['7fd1ac25', '736f9581', '9b23e8ee', '461eace6', '9e34ea74', '08ff79ad', '4c2ec19f', '7ab78247', 'b80e5e84'], ['27253bdc'],\\\n          ['3ee399c3', '2dcad279', 'b5053438', '532a2afb', '5290eab1', '91561152', '90d848e0', '923afab1', '37ee8496', '392e14df', '28520915', '77c76bc5', '9554a50b', '5348fd84', '04df9b66', 'd3268efa', '3edf6747', '30614231', '2b058fe3'],\\\n          ['27253bdc'], ['27253bdc'], ['27253bdc'], ['27253bdc'], \\\n          ['ab3136ba', 'd3640339', '9de5e594', '709b1251', '7d5c30a2', 'e3ff61fb', '832735e1', 'c0415e5c', '00c73085', '87d743c1', '119b5b02', '28a4eb9a', '29bdd9ba', '6088b756', '7961e599', '76babcde'],\\\n          ['2c4e6db0', '587b5989', '6043a2b4', 'ca11f653', '1cc7cfca', 'daac11b0', '26a5a3dd', '9e4c8c7b', 'b7dc8128', '4b5efe37', 'd45ed6a1', '1f19558b', '363d3849', 'b1d5101d', 'c277e121', 'b120f2ac', 'd02b7a8e', '2dc29e21'], \\\n          ['27253bdc'], ['3afb49e6', '38074c54', '155f62a4', '9ce586dd', 'bfc77bd6', 'bd612267', '93b353f2', '222660ff', '3ccd3f02', 'a8efe47b', '5b49460a', 'cb1178ad', 'df4fe8b6', 'ea296733', '3d0b9317', '0db6d71d', 'e4f1efe6', '562cec5f', '3dcdda7f'],\\\n          ['47f43a44', '3a4be871', 'a44b10dc', '598f4598', 'de26c3a6', '9b01374f', '56cd3b43', 'fcfdffb6', 'bbfe0445', '5d042115'], \\\n          ['7ad3efc6', '5e109ec3', 'b74258a0', '31973d56', '65a38bf7', 'd122731b', '5de79a6a', 'ecc6157f', '795e4a37', 'b2e5b0f1', '5c2f29ca', 'acf5c23f', '3d63345e', '4e5fc6f5', '828e68f9', '9d4e7b25', 'a8876db3', 'ecaab346']]","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"title_title = ['Cart Balancer (Assessment)', 'Chest Sorter (Assessment)', 'Cauldron Filler (Assessment)', 'Bird Measurer (Assessment)', 'Mushroom Sorter (Assessment)', 'Chicken Balancer (Activity)', 'Egg Dropper (Activity)', 'Sandcastle Builder (Activity)', 'Bottle Filler (Activity)', 'Watering Hole (Activity)', 'Bug Measurer (Activity)', 'Fireworks (Activity)', 'Flower Waterer (Activity)', 'Crystal Caves - Level 3', 'Honey Cake', 'Lifting Heavy Things', 'Crystal Caves - Level 2', 'Heavy, Heavier, Heaviest', 'Balancing Act', 'Crystal Caves - Level 1', 'Magma Peak - Level 1', 'Slop Problem', 'Magma Peak - Level 2', 'Welcome to Lost Lagoon!', 'Costume Box', \"Pirate's Tale\", 'Tree Top City - Level 2', 'Tree Top City - Level 3', 'Treasure Map', '12 Monkeys', 'Tree Top City - Level 1', 'Ordering Spheres', 'Rulers', 'Happy Camel', 'Leaf Leader', 'Chow Time', 'Pan Balance', 'Scrub-A-Dub', 'Bubble Bath', 'Dino Dive', 'Dino Drink', 'Air Show', 'All Star Sorting', 'Crystals Rule']\ntitle_type = ['Assessment', 'Assessment', 'Assessment', 'Assessment', 'Assessment', 'Activity', 'Activity', 'Activity', 'Activity', 'Activity', 'Activity', 'Activity', 'Activity', 'Clip', 'Clip', 'Clip', 'Clip', 'Clip', 'Clip', 'Clip', 'Clip', 'Clip', 'Clip', 'Clip', 'Clip', 'Clip', 'Clip', 'Clip', 'Clip', 'Clip', 'Clip', 'Clip', 'Clip', 'Game', 'Game', 'Game', 'Game', 'Game', 'Game', 'Game', 'Game', 'Game', 'Game', 'Game']\ntitle_world = ['CRYSTALCAVES', 'CRYSTALCAVES', 'MAGMAPEAK', 'TREETOPCITY', 'TREETOPCITY', 'CRYSTALCAVES', 'CRYSTALCAVES', 'MAGMAPEAK', 'MAGMAPEAK', 'MAGMAPEAK', 'TREETOPCITY', 'TREETOPCITY', 'TREETOPCITY', 'CRYSTALCAVES', 'CRYSTALCAVES', 'CRYSTALCAVES', 'CRYSTALCAVES', 'CRYSTALCAVES', 'CRYSTALCAVES', 'CRYSTALCAVES', 'MAGMAPEAK', 'MAGMAPEAK', 'MAGMAPEAK', 'NONE', 'TREETOPCITY', 'TREETOPCITY', 'TREETOPCITY', 'TREETOPCITY', 'TREETOPCITY', 'TREETOPCITY', 'TREETOPCITY', 'TREETOPCITY', 'TREETOPCITY', 'CRYSTALCAVES', 'CRYSTALCAVES', 'CRYSTALCAVES', 'CRYSTALCAVES', 'MAGMAPEAK', 'MAGMAPEAK', 'MAGMAPEAK', 'MAGMAPEAK', 'TREETOPCITY', 'TREETOPCITY', 'TREETOPCITY']\ntitle_title_id = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]\ntitle_type_id = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\ntitle_world_id = [0, 0, 1, 2, 2, 0, 0, 1, 1, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2]\ntitle = pd.DataFrame(index=range(len(title_title)))\ntitle['title'] = title_title\ntitle['type'] = title_type\ntitle['world'] = title_world\ntitle['title_id'] = title_title_id\ntitle['type_id'] = title_type_id\ntitle['world_id'] = title_world_id","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make Feature"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"def make_test_label(submit_input, test):\n    submit = submit_input.copy()\n    submit['game_session'] = 'game_session'\n    for i in range(len(submit)):\n        idx = submit.loc[i,'installation_id']\n        _test = test.loc[test['installation_id']==idx,:].copy()\n        _test = (_test.sort_values('timestamp')).reset_index(drop=True)\n        submit.loc[i,'game_session'] = _test.loc[_test.index[len(_test.index)-1],'game_session']\n    return submit\n\ndef make_test_label2(submit_input, test):\n    _test = test.loc[test['event_count']==1,:].copy()\n    _test = _test.loc[~_test['installation_id'].duplicated(keep='last'),['installation_id','game_session','timestamp']]\n    submit = submit_input.copy()\n    submit = pd.merge(submit,_test,on='installation_id',how='left')\n    return submit\n\ndef previous_index_col(df_input,col):\n    df = df_input.copy()\n    for c in col:\n        df['previous_'+c] = df[c]\n        df.loc[df.index[1:],'previous_'+c] = np.array(df.loc[df.index[:len(df.index)-1],c])\n    df = df.loc[df.index[1:],:]\n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature 1: Previous Game Event\n- Number of event_id in previous game session"},{"metadata":{"trusted":true},"cell_type":"code","source":"def feature_previous_game_event(df_, title, spec, label,Train=True):\n    df = df_.copy()\n    title_dic = dict(zip(title['title'],title['title_id']))\n    type_dic = dict(zip(title['type'],title['type_id']))\n    world_dic = dict(zip(title['world'],title['world_id']))\n    df['title'] = df['title'].apply(lambda x:title_dic[x] if x in title_dic.keys() else -1)\n    df['type'] = df['type'].apply(lambda x:type_dic[x] if x in type_dic.keys() else -1)\n    df['world'] = df['world'].apply(lambda x:world_dic[x] if x in world_dic.keys() else -1)\n    event_dic = dict(zip(spec['event_id'],spec.index))\n    df['event_id'] = df['event_id'].map(lambda x:event_dic[x])\n    play = df[df['event_count']==1].copy()\n    for e in tqdm(range(len(spec))):\n        _df = df[df['event_id']==e]\n        gr = _df.groupby('game_session').agg({'event_id':'count'})\n        gr = gr.rename(columns={'event_id':'e{}'.format(str(e).zfill(3))})\n        play = pd.merge(play,gr,on='game_session',how='left')\n    df = df[df['event_count']==1].reset_index(drop=True)\n    gttw = df.loc[:,['game_session','title','type','world','installation_id']].copy()\n    df = previous_index_col(df,['installation_id','game_session'])\n    df = df.loc[df['installation_id']==df['previous_installation_id'],:].reset_index(drop=True)\n    df = df.drop(['event_id','timestamp','event_data','game_time','event_count','event_code'],axis=1)\n    if Train:\n        label = label.drop(['installation_id','title'],axis=1)\n    else:\n        label = label.drop(['installation_id'],axis=1)\n    play = play.drop(['event_id','timestamp','event_data','event_count','event_code','game_time','installation_id'],axis=1)\n    play = play.rename(columns={'title':'previous_title','type':'previous_type','world':'previous_world'})\n    play = play.rename(columns={'game_session':'previous_game_session'})\n    feature = pd.merge(label,df,on='game_session',how='left')\n    feature = pd.merge(feature,play,on='previous_game_session',how='left')\n    if Train:\n        feature = feature.drop(['num_correct','num_incorrect','accuracy','accuracy_group','previous_installation_id','title','world','type','installation_id','timestamp'],axis=1)\n    else:\n        feature = feature.drop(['previous_installation_id','title','world','type','installation_id','accuracy_group','timestamp'],axis=1)\n    feature = pd.merge(label,feature,on='game_session',how='left')\n    feature = pd.merge(feature,gttw,on='game_session',how='left')\n    for i in range(386):\n        feature['e{}'.format(str(i).zfill(3))] = feature['e{}'.format(str(i).zfill(3))].fillna(0)\n    feature['eall'] = 0\n    for i in range(386):\n        feature['eall']+=feature['e{}'.format(str(i).zfill(3))]\n    for i in range(386):\n        feature['e{}'.format(str(i).zfill(3))]/=feature['eall']+10\n    return feature","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature 2: Previous Title Event\n- Number of event_id in previous game session of each title"},{"metadata":{"trusted":true},"cell_type":"code","source":"def feature_previous_title_event(df_,label_,titles,events):\n    df = df_.copy()\n    label = label_.copy()\n    insta_v = label['installation_id'].unique()\n    df_insta = df.loc[df['installation_id'].isin(insta_v),:].copy()\n    title_df_v = []\n    for idx,title in tqdm(enumerate(titles)):\n        df_insta_title = df_insta.loc[df_insta['title']==title,:]\n        title_event_id = events[idx]\n        v = []\n        title_df = pd.DataFrame(columns=[title+'_'+x+'_nm' for x in title_event_id])\n        for idx,(game,df) in enumerate(df_insta_title.groupby('game_session')):\n            feature = []\n            for e_id in title_event_id:\n                feature.append((df['event_id']==e_id).sum())\n            title_df.loc[game,:]=feature\n        title_df_v.append(title_df)\n    df_event_cnt1 = df_insta.loc[df_insta['event_count']==1,:]\n    for idx,title in tqdm(enumerate(titles)):\n        title_df = title_df_v[idx]\n        df_event_cnt1_title = df_event_cnt1.loc[df_event_cnt1['title']==title,:]\n        label[title] = None\n        cnt=0\n        for jdx in label.index:\n            insta_id, time = label.loc[jdx,['installation_id','timestamp']]\n            df_event_cnt1_title_insta = df_event_cnt1_title.loc[df_event_cnt1_title['installation_id']==insta_id,:]\n            df_event_cnt1_title_insta_before = df_event_cnt1_title_insta.loc[df_event_cnt1_title_insta['timestamp']<time,:]\n            if len(df_event_cnt1_title_insta_before)>0:\n                previous_index = df_event_cnt1_title_insta_before.index[len(df_event_cnt1_title_insta_before)-1]\n                previous_game = df_event_cnt1_title_insta_before.loc[previous_index,'game_session']\n                label.loc[jdx,title]=previous_game\n    feature = pd.merge(label,df_event_cnt1.drop(['installation_id','title','timestamp'],axis=1),on='game_session',how='left').copy()\n    for idx,title in enumerate(titles):\n        title_df = title_df_v[idx]\n        feature = pd.merge(feature,title_df,left_on=title,right_index=True,how='left')\n    return feature","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make Train Feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/data-science-bowl-2019/train.csv')\ntrain['timestamp'] = pd.to_datetime(train['timestamp'])\ntrain_start = train.loc[train['event_count']==1,['game_session','timestamp']]\ntrain_label = pd.read_csv('../input/data-science-bowl-2019/train_labels.csv')\ntrain_label = pd.merge(train_label, train_start, on='game_session', how='left')\ndel train_start\ngc.collect()\nspec = pd.read_csv('../input/data-science-bowl-2019/specs.csv')\nprint('Train Data Load Done')\nprint('Start Make Train feature_previous_game_event')\nfeature_previous_game_event_train = feature_previous_game_event(train, title, spec, train_label,Train=True)\nprint('Start Make Train feature_previous_title_event')\nfeature_previous_title_event_train = feature_previous_title_event(train,train_label,titles,events)\nfeature_train = pd.merge(feature_previous_game_event_train,feature_previous_title_event_train.drop(['installation_id','title','num_correct','num_incorrect','accuracy','accuracy_group',\n                         'event_id','timestamp','event_data','event_count', 'event_code', 'game_time', 'type', 'world']+titles,axis=1),on='game_session',how='left')\ndel train\ndel feature_previous_title_event_train\ndel feature_previous_geme_event_train\ngc.collect()\nfeature_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make Test Feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/data-science-bowl-2019/test.csv')\ntest['timestamp'] = pd.to_datetime(test['timestamp'])\nsubmit = pd.read_csv('../input/data-science-bowl-2019/sample_submission.csv')\nprint('Test Data Load Done')\nprint('Start Make Test Label')\ntest_label = make_test_label2(submit,test)\nprint('Start Make Test feature_previous_game_event')\nfeature_previous_game_event_test = feature_previous_game_event(test,title,spec,test_label,False)\nprint('Start Make Test feature_previous_title_event')\nfeature_previous_title_event_test = feature_previous_title_event(test, test_label, titles, events)\nfeature_test = pd.merge(feature_previous_game_event_test,feature_previous_title_event_test.drop(['installation_id','accuracy_group','event_id',\\\n                        'timestamp','event_data','event_count', 'event_code', 'game_time', 'type', 'world']+titles,axis=1),on='game_session',how='left')\ngc.collect()\nfeature_test = feature_test.reset_index(drop=True)\ndel test\ndel feature_previous_game_event_test\ndel feature_previous_title_event_test\ngc.collect()\nfeature_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Traing"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = feature_train.drop(['game_session','num_correct','num_incorrect','previous_game_session','previous_title','previous_type','previous_world','timestamp'],axis=1)\nfloat_col = [x for x in dataset.columns[:len(dataset.columns)-1] if not x in ['installation_id','accuracy_group']]\ndataset[float_col] = dataset[float_col].astype(np.float)\ndataset['accuracy'] = dataset['accuracy']*3\ndataset = dataset.rename(columns={'accuracy_group':'y'})\ndataset['y'] = dataset['accuracy']\ndataset = dataset.reset_index(drop=True)\nW = np.array([[0,1,4,9],[1,0,1,4],[4,1,0,1],[9,4,1,0]])/9\nprint('dataset size:',len(dataset))\npara = {'objective':'regression','boosting':'gbdt','metric':{'l2'},'fraction_rate':0.7}\ngkf1 = GroupKFold(n_splits=5)\ngr1 = dataset['installation_id']\ndataset['predict'] = 0\nmodels = []\nfor c in dataset.columns:\n    _c = c.replace(',','')\n    if _c != c:\n        dataset = dataset.rename(columns={c:_c})\ndataset, gr1 = shuffle(dataset,gr1,random_state=42)\nfor idx,(tr1_idx,test_idx) in enumerate(gkf1.split(dataset,groups=gr1)):\n    tr1_X = (dataset.loc[dataset.index[tr1_idx],:]).drop(['y','predict','installation_id','accuracy'],axis=1).copy()\n    test_X = (dataset.loc[dataset.index[test_idx],:]).drop(['y','predict','installation_id','accuracy'],axis=1).copy()\n    tr1_y = dataset.loc[dataset.index[tr1_idx],'accuracy'].copy()\n    test_y = dataset.loc[dataset.index[test_idx],'accuracy'].copy()\n    gkf2 = GroupKFold(n_splits=5)\n    gr2 = gr1[gr1.index[tr1_idx]]\n    for jdx,(tr2_idx,val_idx) in enumerate(gkf2.split(tr1_X,tr1_y,gr2)):\n        tr2_X, val_X = tr1_X.loc[tr1_X.index[tr2_idx],:],tr1_X.loc[tr1_X.index[val_idx],:]\n        tr2_y, val_y = tr1_y[tr1_y.index[tr2_idx]],tr1_y[tr1_y.index[val_idx]]\n        train_lgb = lgb.Dataset(tr2_X, tr2_y)\n        val_lgb = lgb.Dataset(val_X, val_y, reference=train_lgb)\n        model = lgb.train(para,train_lgb,num_boost_round=50,valid_sets=[train_lgb,val_lgb],early_stopping_rounds=10)\n        predict = model.predict(test_X)\n        dataset.loc[dataset.index[test_idx],'predict'] += predict/5\n        models.append(model)\n        if jdx==0:\n            models.append(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Determine Threshold\n- Thresholds are determined by CV."},{"metadata":{"trusted":true},"cell_type":"code","source":"def qwk3(a1, a2, max_rat=3):\n    assert(len(a1) == len(a2))\n    a1 = np.asarray(a1, dtype=int)\n    a2 = np.asarray(a2, dtype=int)\n\n    hist1 = np.zeros((max_rat + 1, ))\n    hist2 = np.zeros((max_rat + 1, ))\n\n    o = 0\n    for k in range(a1.shape[0]):\n        i, j = a1[k], a2[k]\n        hist1[i] += 1\n        hist2[j] += 1\n        o +=  (i - j) * (i - j)\n\n    e = 0\n    for i in range(max_rat + 1):\n        for j in range(max_rat + 1):\n            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n\n    e = e / a1.shape[0]\n\n    return 1 - o / e\n\ndef estimate(dataset):\n    q1s = np.linspace(0.3,1.2,10)\n    q2s = np.linspace(0.5,2.2,18)\n    q3s = np.linspace(1.0,2.2,13)\n    m = 0\n    q1r,q2r,q3r = -1,-1,-1\n    for q1 in q1s:\n        for q2 in q2s:\n            for q3 in q3s:\n                if q2 > q1 and q3 > q2:\n                    dataset['predict2'] = 0\n                    dataset['predict2'] += (dataset['predict']>q1).astype(np.int)\n                    dataset['predict2'] += (dataset['predict']>q2).astype(np.int)\n                    dataset['predict2'] += (dataset['predict']>q3).astype(np.int)\n                    dataset['predict2'] = dataset['predict2'].astype(np.int)\n                    score = qwk3(dataset['y'],dataset['predict2'])\n                    if m < score:\n                        print(q1,q2,q3,qwk3(dataset['y'],dataset['predict2']))\n                        m = score\n                        q1r,q2r,q3r = q1,q2,q3\n    return q1r,q2r,q3r\n\nq1,q2,q3 = estimate(dataset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = feature_test.copy()\ntest_df = test_df.drop(['game_session','installation_id','accuracy_group','previous_game_session',\\\n                        'previous_title','previous_type','previous_world','timestamp'],axis=1)\nfloat_col = [x for x in dataset.columns[:len(dataset.columns)-1] if not x in ['installation_id','accuracy_group']]\n\ntest_df = test_df.astype(np.float)\nfor c in test_df.columns:\n    _c = c.replace(',','')\n    if _c != c:\n        test_df = test_df.rename(columns={c:_c})\nfor k, model in enumerate(models):\n    if k==0:\n        predict = model.predict(test_df)/len(models)\n    else:\n        predict += model.predict(test_df)/len(models)\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['predict2'] = 0\ntest_df['predict2'] += (predict>q1).astype(np.int)\ntest_df['predict2'] += (predict>q2).astype(np.int)\ntest_df['predict2'] += (predict>q3).astype(np.int)\ntest_df['predict2'] = test_df['predict2'].astype(np.int)\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.hist(test_df['predict2'],bins=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = pd.read_csv('../input/data-science-bowl-2019/sample_submission.csv')\nsubmit['accuracy_group'] = test_df['predict2']\nsubmit.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}