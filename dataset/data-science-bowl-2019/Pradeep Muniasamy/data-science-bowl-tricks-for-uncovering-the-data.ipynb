{"cells":[{"metadata":{},"cell_type":"markdown","source":"## About the Competition"},{"metadata":{},"cell_type":"markdown","source":"We are provided with the data for game analytics for the **PBS KIDS Measure Up!** app. In this app, children navigate a map and complete various levels, which may be activities, video clips, games, or assessments. Each assessment is designed to test a child's comprehension of a certain set of measurement-related skills. There are five assessments: \n                    * Bird Measurer\n                    * Cart Balancer\n                    * Cauldron Filler\n                    * Chest Sorter\n                    * Mshroom Sorter.\n\nThe intent of the competition is to use the gameplay data to forecast how many attempts a child will take to pass a given assessment (an incorrect answer is counted as an attempt)."},{"metadata":{},"cell_type":"markdown","source":"**About this kernel**\n\n  This kernel acts as a starter kit. It gives all the essential Key insights on the data as well as modelling\n  \n**Key Takeaways**\n\n* Extensive EDA\n* Effective Story Telling\n* Creative Feature Engineering\n* Modelling\n* Ensembling"},{"metadata":{},"cell_type":"markdown","source":"**Most of the plots made here are interactive please feel free to hover over**"},{"metadata":{},"cell_type":"markdown","source":"**Loading the necessary Packages**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom plotly.offline import iplot\nfrom plotly import tools\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.offline as py\nimport plotly.figure_factory as ff\npy.init_notebook_mode(connected=True)\n\nimport matplotlib.patches as mpatches\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Reading the data**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/data-science-bowl-2019/train.csv')\ntrain_labels = pd.read_csv('../input/data-science-bowl-2019/train_labels.csv')\ntest_df = pd.read_csv('../input/data-science-bowl-2019/test.csv')\nspecs_Df = pd.read_csv('../input/data-science-bowl-2019/specs.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Simple Data Exploration**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**This file demonstrates how to compute the ground truth for the assessments in the training set.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.head()   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As I have mentioned, there are five assesments let's explore the ground truth of each assesment(sucess and failure rate)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.title.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploring the ground truth of each assesment"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#temp=df.drop_duplicates('GameId', keep='last')\ntemp_df = train_labels.groupby([\"title\",\"accuracy_group\"])[\"accuracy_group\"].agg([\"count\"]).reset_index()\ntemp_df.columns = [\"title\",\"accuracy_group\", \"Count\"]\n#temp_df.Country = temp_df[temp_df.Country != 'United Kingdom']\n\nfig = px.scatter(temp_df, x=\"accuracy_group\", y=\"title\", color=\"accuracy_group\", size=\"Count\")\nlayout = go.Layout(\n    title=go.layout.Title(\n        text=\"Accuracy group in each Assesments\",\n        x=0.5\n    ),\n    font=dict(size=14),\n    width=800,\n    height=600,\n    showlegend=False\n)\nfig.update_layout(layout)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now you may wonder what does the **accuracy_group** denotes. No worries as mentioned in the [data description](https://www.kaggle.com/c/data-science-bowl-2019/data), They denote:\n\n**3**: the assessment was solved on the first attempt\n\n**2**: the assessment was solved on the second attempt\n\n**1**: the assessment was solved after 3 or more attempts\n\n**0**: the assessment was never solved"},{"metadata":{},"cell_type":"markdown","source":"**Distribution of the Accuracy group**"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"Accuracy=pd.DataFrame()\nAccuracy['Type']=train_labels.accuracy_group.value_counts().index\nAccuracy['Count']=train_labels.accuracy_group.value_counts().values\n\nimport plotly.offline as pyo\npy.init_notebook_mode(connected=True)\nfig = go.Figure(data=[go.Pie(labels=Accuracy['Type'], values=Accuracy['Count'],hole=0.2)])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Success rate in each group**"},{"metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"Success_Rate_1=pd.DataFrame()\nSuccess_Rate_2=pd.DataFrame()\nSuccess_Rate_3=pd.DataFrame()\nSuccess_Rate_4=pd.DataFrame()\nSuccess_Rate_5=pd.DataFrame()\nMushroom_Sorter=train_labels.loc[train_labels['title'] == 'Mushroom Sorter (Assessment)']\nSuccess_Rate_1['Type']=Mushroom_Sorter.num_correct.value_counts().index\nSuccess_Rate_1['Count']=Mushroom_Sorter.num_correct.value_counts().values\nBird_Measurer=train_labels.loc[train_labels['title'] ==  'Bird Measurer (Assessment)']\nSuccess_Rate_2['Type']=Bird_Measurer.num_correct.value_counts().index\nSuccess_Rate_2['Count']=Bird_Measurer.num_correct.value_counts().values\nCauldron_Filler=train_labels.loc[train_labels['title'] == 'Cauldron Filler (Assessment)']\nSuccess_Rate_3['Type']=Cauldron_Filler.num_correct.value_counts().index\nSuccess_Rate_3['Count']=Cauldron_Filler.num_correct.value_counts().values\nChest_Sorter=train_labels.loc[train_labels['title'] == 'Chest Sorter (Assessment)']\nSuccess_Rate_4['Type']=Chest_Sorter.num_correct.value_counts().index\nSuccess_Rate_4['Count']=Chest_Sorter.num_correct.value_counts().values\nCart_Balancer=train_labels.loc[train_labels['title'] == 'Cart Balancer (Assessment)']\nSuccess_Rate_5['Type']=Cart_Balancer.num_correct.value_counts().index\nSuccess_Rate_5['Count']=Cart_Balancer.num_correct.value_counts().values","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nlabels = [0,1]\n\nfig = make_subplots(3, 2, specs=[[{'type':'domain'}, {'type':'domain'}],[{'type':'domain'}, {'type':'domain'}],[{'type':'domain'}, {'type':'domain'}]],\n                    subplot_titles=['Mushroom Sorter', 'Bird Measurer','Cauldron Filler','Chest Sorter','Cart Balancer'])\nfig.add_trace(go.Pie(labels=Success_Rate_1['Type'], values=Success_Rate_1['Count'], scalegroup='one',\n                     name=\"Success Rate\"), 1, 1)\nfig.add_trace(go.Pie(labels=Success_Rate_2['Type'], values=Success_Rate_2['Count'], scalegroup='one',\n                     name=\"Success Rate\"), 1, 2)\nfig.add_trace(go.Pie(labels=Success_Rate_3['Type'], values=Success_Rate_3['Count'], scalegroup='one',\n                     name=\"Success Rate\"), 2, 1)\nfig.add_trace(go.Pie(labels=Success_Rate_4['Type'], values=Success_Rate_4['Count'], scalegroup='one',\n                     name=\"Success Rate\"), 2, 2)\nfig.add_trace(go.Pie(labels=Success_Rate_5['Type'], values=Success_Rate_5['Count'], scalegroup='one',\n                     name=\"Success Rate\"), 3, 1)\n\nfig.update_layout(title_text='Success Rate of Each Group')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Effective Data Minification"},{"metadata":{},"cell_type":"markdown","source":"The size of the dataset is pretty big, so we are trying to make the dataset smaller without losing information.\n\nReason behind memory Reduction:\n\nInt16: 2 bytes\n\nInt32 and int: 4 bytes\n\nInt64 : 8 bytes\n\nThis is an example how different integer types are occupying the memory. In many cases it is not necessary to represent our integer as int64 and int32 it is just waste of memory. So I am trying to understand the necessaity of every numerical representation and try to convert the unnecessary higher numerical representation to lower one. In that, we can reduce the memory without losing the memory."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df):\n    start_mem_usg = df.memory_usage().sum() / 1024**2 \n    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n    NAlist = [] # Keeps track of columns that have missing values filled in. \n    for col in df.columns:\n        if df[col].dtype != object:  # Exclude strings\n            \n            # make variables for Int, max and min\n            IsInt = False\n            mx = df[col].max()\n            mn = df[col].min()\n            \n            #Integer does not support NA, therefore, NA needs to be filled\n            if not np.isfinite(df[col]).all(): \n               NAlist.append(col)\n               df[col].fillna(-999,inplace=True)  \n                   \n            # test if column can be converted to an integer\n            asint = df[col].fillna(0).astype(np.int64)\n            result = (df[col] - asint)\n            result = result.sum()\n            if result > -0.01 and result < 0.01:\n                IsInt = True\n\n            \n            # Make Integer/unsigned Integer datatypes\n            if IsInt:\n                if mn >= 0:\n                    if mx < 255:\n                        df[col] = df[col].astype(np.uint8)\n                    elif mx < 65535:\n                        df[col] = df[col].astype(np.uint16)\n                    elif mx < 4294967295:\n                        df[col] = df[col].astype(np.uint32)\n                    else:\n                        df[col] = df[col].astype(np.uint64)\n                else:\n                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n                        df[col] = df[col].astype(np.int8)\n                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n                        df[col] = df[col].astype(np.int16)\n                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n                        df[col] = df[col].astype(np.int32)\n                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n                        df[col] =df[col].astype(np.int64)    \n            \n            # Make float datatypes 32 bit\n            else:\n                df[col] = df[col].astype(np.float32)\n            \n    # Print final result\n    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n    mem_usg = df.memory_usage().sum() / 1024**2 \n    print(\"Memory usage is: \",mem_usg,\" MB\")\n    print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n    return df,NAlist","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Reducing Memory For training data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df,train_Na=reduce_mem_usage(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Reducing Memory For test data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df,test_Na=reduce_mem_usage(test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Breaking the Train data to the Fullest!!"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data={'Unique_event':[train_df.event_id.nunique()],\n      'Unique_gamesession':[train_df.game_session.nunique()],\n      'Unique_title':[train_df.title.nunique()]}\nCount_df=pd.DataFrame(data)\nCount_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Important Figure's**\n\nOf total **113441042** records in train data there are, only\n\n1. **384** Unique events happened\n2. **303319** Unique Gamming Session\n3. **44** Uninque Game Titles"},{"metadata":{},"cell_type":"markdown","source":"**Timestamp**\n\nLet's explore the time stamp of the given data and try to find some useful information\n\nThis section was taken from ths amazing [kernel](https://www.kaggle.com/robikscube/2019-data-science-bowl-an-introduction). I just added a how the test and train data are in given timestamps."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Format and make date / hour features\ntrain_df['timestamp'] = pd.to_datetime(train_df['timestamp'])\ntrain_df['date'] = train_df['timestamp'].dt.date\ntrain_df['hour'] = train_df['timestamp'].dt.hour\ntrain_df['weekday_name'] = train_df['timestamp'].dt.weekday_name\n\n# Same for test\ntest_df['timestamp'] = pd.to_datetime(test_df['timestamp'])\ntest_df['date'] = test_df['timestamp'].dt.date\ntest_df['hour'] = test_df['timestamp'].dt.hour\ntest_df['weekday_name'] = test_df['timestamp'].dt.weekday_name","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train_df.groupby('date')['event_id'].agg('count').plot(figsize=(15, 3),title='Numer of Event Observations by Date',\n                                                       color=\"blue\")\ntest_df.groupby('date')['event_id'].agg('count').plot(figsize=(15, 3),title='Numer of Event Observations by Date'\n                                                      ,color=\"yellow\")\ntrain_patch = mpatches.Patch(color='blue', label='Train data')\ntest_patch = mpatches.Patch(color='yellow', label='Test data')\nplt.legend(handles=[train_patch, test_patch])\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.groupby('hour')['event_id'].agg('count').plot(figsize=(15, 3),title='Numer of Event Observations by Hour',color=\"blue\")\ntest_df.groupby('hour')['event_id'].agg('count').plot(figsize=(15, 3),title='Numer of Event Observations by Hour',color=\"yellow\")\ntrain_patch = mpatches.Patch(color='blue', label='Train data')\ntest_patch = mpatches.Patch(color='yellow', label='Test data')\nplt.legend(handles=[train_patch, test_patch])\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.groupby('weekday_name')['event_id'].agg('count').T[['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']].T.plot(figsize=(15, 3),title='Numer of Event Observations by Day of Week',color=\"blue\")\ntest_df.groupby('weekday_name')['event_id'].agg('count').T[['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']].T.plot(figsize=(15, 3),title='Numer of Event Observations by Day of Week',color=\"yellow\")\ntrain_patch = mpatches.Patch(color='blue', label='Train data')\ntest_patch = mpatches.Patch(color='yellow', label='Test data')\nplt.legend(handles=[train_patch, test_patch])\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Distribtuion of Game Type**"},{"metadata":{"trusted":true},"cell_type":"code","source":"Game=pd.DataFrame()\nGame['Type']=train_df.type.value_counts().index\nGame['Count']=train_df.type.value_counts().values\n\nimport plotly.offline as pyo\npy.init_notebook_mode(connected=True)\nfig = go.Figure(data=[go.Pie(labels=Game['Type'], values=Game['Count'],hole=0.2)])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Distribution of Game Title**"},{"metadata":{"trusted":true},"cell_type":"code","source":"Game=pd.DataFrame()\nGame['Title']=train_df.title.value_counts().index\nGame['Count']=train_df.title.value_counts().values\n\nfig = px.bar(Game, x='Title', y='Count',\n             hover_data=['Count'], color='Count',\n             labels={'pop':'Total Number of game titles'}, height=400)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Game Type VS Game Played Time**"},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_time=[]\ntype_=[]\nfor i in train_df.type.unique():\n    type_.append(i)\n    avg_time.append(train_df.loc[train_df['type'] ==i]['game_time'].mean())\n    \nAvg_Timeplayed=pd.DataFrame()\nAvg_Timeplayed['Type']=type_\nAvg_Timeplayed['Average']=avg_time\n\nfig = px.bar(Avg_Timeplayed, x='Type', y='Average',\n             hover_data=['Average'], color='Average',\n             labels={'pop':'Average time played on each types'}, height=400)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Game Title VS Game Played Time**"},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_time=[]\ntitle_=[]\nfor i in train_df.title.unique():\n    title_.append(i)\n    avg_time.append(train_df.loc[train_df['title'] ==i]['game_time'].mean())\n    \nAvg_Timeplayed=pd.DataFrame()\nAvg_Timeplayed['Title']=title_\nAvg_Timeplayed['Average']=avg_time\n\nfig = px.bar(Avg_Timeplayed, x='Title', y='Average',\n             hover_data=['Average'], color='Average',\n             labels={'pop':'Average time played on each titles'}, height=400)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**This kernel is under construction, Stay tuned for more updates**"},{"metadata":{},"cell_type":"markdown","source":"**Please upvote if you find this kernel useful**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}