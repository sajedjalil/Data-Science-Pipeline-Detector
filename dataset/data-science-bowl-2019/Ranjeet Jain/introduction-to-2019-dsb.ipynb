{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"<img src=\"https://bento.cdn.pbs.org/hostedbento-prod/blog/20170114_200556_794501_pk-channel-16x9.jpeg\"/>"},{"metadata":{},"cell_type":"markdown","source":"# What is PBS Kids"},{"metadata":{},"cell_type":"markdown","source":"The Public Broadcasting Service (PBS) is an American public broadcaster and television program distributor..<br>It is a nonprofit organization and the most prominent provider of educational television programming to public television stations in the United States.<br>\n<b>Subsidiary:</b> PBS KIDS, World<br>\n<b>Geographic scope:</b> United States<br>\nPBS Kids is the brand for most of the children's programming aired by the Public Broadcasting Service (PBS) in the United States."},{"metadata":{},"cell_type":"markdown","source":"# Introduction"},{"metadata":{},"cell_type":"markdown","source":"PBS KIDS, a trusted name in early childhood education for decades, aims to gain insights into how media can help children learn important skills for success in school and life. In this challenge, youâ€™ll use anonymous gameplay data, including knowledge of videos watched and games played, from the PBS KIDS Measure Up! app, a game-based learning tool developed as a part of the CPB-PBS Ready To Learn Initiative with funding from the U.S. Department of Education. Competitors will be challenged to predict scores on in-game assessments and create an algorithm that will lead to better-designed games and improved learning outcomes. Your solutions will aid in discovering important relationships between engagement with high-quality educational media and learning processes."},{"metadata":{},"cell_type":"markdown","source":"The outcomes in this competition are grouped into 4 groups (labeled accuracy_group in the data):<br>\n<br>\n3: the assessment was solved on the first attempt<br>\n2: the assessment was solved on the second attempt<br>\n1: the assessment was solved after 3 or more attempts<br>\n0: the assessment was never solved<br>"},{"metadata":{},"cell_type":"markdown","source":"More information about game play can be found in https://www.kaggle.com/c/data-science-bowl-2019/discussion/117019#latest-680222"},{"metadata":{},"cell_type":"markdown","source":"Now we are clear with few things.<br>\nWe will be given information of kids game play data and we need to predict accuracy_group"},{"metadata":{},"cell_type":"markdown","source":"# Let's start with analysis"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom time import time\nimport datetime\nimport numpy as np\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\nfrom plotly.offline import  init_notebook_mode\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud\nfrom catboost import CatBoostClassifier\nfrom sklearn.metrics import confusion_matrix\nimport colorlover as cl\nfrom tqdm import tqdm_notebook as tqdm\nsns.set(rc={'figure.figsize':(11.7,8.27)})\ninit_notebook_mode(connected=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train_labels_df = pd.read_csv(\"/kaggle/input/data-science-bowl-2019/train_labels.csv\")\ntrain_df = pd.read_csv(\"/kaggle/input/data-science-bowl-2019/train.csv\")\nspecs_df = pd.read_csv(\"/kaggle/input/data-science-bowl-2019/specs.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/data-science-bowl-2019/test.csv\")\nsubmission_df = pd.read_csv(\"/kaggle/input/data-science-bowl-2019/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print (\"In train dataset we have total of \" + str(train_df['installation_id'].nunique()) + \" unique Installation ID\")\nprint (\"In test dataset we have total of \" + str(test_df['installation_id'].nunique()) + \" unique Installation ID\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"train.csv & test.csv<br>\nThese are the main data files which contain the gameplay events.<br>\n<br>\nevent_id - Randomly generated unique identifier for the event type. Maps to event_id column in specs table.<br>\ngame_session - Randomly generated unique identifier grouping events within a single game or video play session.<br>\ntimestamp - Client-generated datetime<br>\nevent_data - Semi-structured JSON formatted string containing the events parameters. Default fields are: event_count, event_code, and game_time; otherwise fields are determined by the event type.<br>\ninstallation_id - Randomly generated unique identifier grouping game sessions within a single installed application instance.<br>\nevent_count - Incremental counter of events within a game session (offset at 1). Extracted from event_data.<br>\nevent_code - Identifier of the event 'class'. Unique per game, but may be duplicated across games. E.g. event code '2000' always identifies the 'Start Game' event for all games. Extracted from event_data.<br>\ngame_time - Time in milliseconds since the start of the game session. Extracted from event_data.<br>\ntitle - Title of the game or video.<br>\ntype - Media type of the game or video. Possible values are: 'Game', 'Assessment', 'Activity', 'Clip'.<br>\nworld - The section of the application the game or video belongs to. Helpful to identify the educational curriculum goals of the media. Possible values are: 'NONE' (at the app's start screen), TREETOPCITY' (Length/Height), 'MAGMAPEAK' (Capacity/Displacement), 'CRYSTALCAVES' (Weight).<br>\n<br>\n<br>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nspecs.csv<br>\nThis file gives the specification of the various event types.<br>\n\nevent_id - Global unique identifier for the event type. Joins to event_id column in events table.<br>\ninfo - Description of the event.<br>\nargs - JSON formatted string of event arguments. Each argument contains:<br>\nname - Argument name.<br>\ntype - Type of the argument (string, int, number, object, array).<br>\ninfo - Description of the argument.<br>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"specs_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"train_labels.csv<br>\nThis file demonstrates how to compute the ground truth for the assessments in the training set.<br>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train_labels_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"50% of the kids finsih the assessment in one go.<br>\n23.91% of kids havent solve the assessment<br>\n3: the assessment was solved on the first attempt<br>\n2: the assessment was solved on the second attempt<br>\n1: the assessment was solved after 3 or more attempts<br>\n0: the assessment was never solved<br>"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_df = train_labels_df.accuracy_group.value_counts(normalize = True) *100\ntemp_df = temp_df.round(2)\ntext = [str(x) + \"%\" for x in temp_df.values]\nfig = go.Figure(data = go.Bar(x = temp_df.index,y = temp_df.values, text = text,textposition='auto'))\nfig.update_traces(marker_color='#D95219', marker_line_color='#D95219',marker_line_width=1.5, opacity=0.6)\nfig.update_layout(title={'text': \"Percentage of accuracy group\",'y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'} )\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The game mainy have three worlds <br>\nMAGMAPEAK (Capacity)<br>\nCRYSTALCAVES (Weight)<br>\nTREETOPCITY (Height & Length)<br>\n44.3% of kids spent their time in Magmapeak world"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"temp_df = train_df['world'].value_counts(normalize = True) * 100\ntemp_df = temp_df.round(2)\ntext = [str(x) + \"%\" for x in temp_df.values]\nfig = go.Figure(data = go.Bar(x = temp_df.values,y = temp_df.index, text = text,textposition='auto',orientation='h'))\nfig.update_traces(marker_color='#611F8D', marker_line_color='#611F8D',marker_line_width=1.5, opacity=0.6)\nfig.update_layout(title={'text': \"Percentage of World\",'y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'} )\nfig.show(title = \"Percentage of world\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are totally 4 media types -- activty,game,assessment,clip. lets see how they are distributed in the world"},{"metadata":{},"cell_type":"markdown","source":"NONE indicated the start of the app and it has only one media type which is clip<br>\nMAGMAPEAK & TREETOPCITY have more activites<br>\nCrystalcaves have more games<br>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"temp_df = train_df.groupby('world')['type'].value_counts(normalize = True).reset_index(name=\"percentage\")\ntemp_df['percentage'] = temp_df['percentage'] *100\ntemp_df = temp_df.round(2)\ndata = []\ntype_ = temp_df['type'].unique()\ncolors = [x.replace(\")\",\"\").replace(\"rgb(\",\"\") for x in cl.scales['4']['qual']['Paired']]\ncount = 0\nfor i in type_:\n\n    text = [str(x) + \"%\" for x in temp_df[temp_df['type'] == i]['percentage'].values]\n    data.append(go.Bar(name = i, x =temp_df[temp_df['type'] == i]['world'].values,text = text,textposition='auto',\n                      y =  temp_df[temp_df['type'] == i]['percentage'].values,marker=dict(\n        color='rgba(' + colors[count] + ',0.6)',\n        line=dict(color='rgba(' + colors[count] + ',1.0)', width=1)\n    )))\n    count = count + 1\nfig = go.Figure(data=data)\nfig.update_layout(barmode='stack')\nfig.update_layout(title={'text': \"Percentage of media types in each world\",'y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'} )\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Chow Time is the famous activity"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# lets see the fav title\ntemp_df = train_df['title'].str.replace(\"\\(Activity\\)\",\"\").replace(\"\\(Assessment\\)\",\"\")\ntext = ' ' .join(val for val in temp_df)\nwordcloud = WordCloud(width=1600, height=800, stopwords = {'None','etc','and','other'}).generate(text)\nplt.figure(figsize=(20,10), facecolor='k')\nplt.imshow(wordcloud,interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.tight_layout(pad=0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So from the above three graphs we are sure that Magmapeak is most played world and Sandcastle builder is most famous activity"},{"metadata":{},"cell_type":"markdown","source":"# Time based analysis "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train_df['timestamp'] = pd.to_datetime(train_df.timestamp)\ntrain_df['date'] = train_df['timestamp'].dt.date\ntrain_df['month'] = train_df['timestamp'].dt.month_name()\ntrain_df['weekday_name'] = train_df['timestamp'].dt.weekday_name\ntrain_df['hour'] = train_df['timestamp'].dt.hour\ntrain_df['minute'] = train_df['timestamp'].dt.minute","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Kids are more active from 10 AM till midnight.<br>\n> Kids are more active on Friday (Weekend starts)<br>\n> September has more traffic<br>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"date_df = train_df.groupby(\"date\")['event_id'].count()\nmonth_df = train_df.groupby(\"month\")['event_id'].count().reset_index(name=\"count\")\nmonth_df['month'] = pd.Categorical(month_df['month'],categories=['December','November','October','September','August','July','June','May','April','March','February','January'],ordered=True)\nmonth_df = month_df.sort_values('month',ascending=False)\n\nweekday_df = train_df.groupby(\"weekday_name\")['event_id'].count().reset_index(name=\"count\")\nweekday_df['weekday'] = pd.Categorical(weekday_df['weekday_name'],categories=['Saturday','Friday','Thursday','Wednesday','Tuesday','Monday','Sunday'],ordered=True)\nweekday_df = weekday_df.sort_values('weekday',ascending=False)\n\nhour_df = train_df.groupby(\"hour\")['event_id'].count()\nminute_df = train_df.groupby(\"minute\")['event_id'].count()\nfig = make_subplots(rows = 5,cols = 1)\n\ninstallation_df = train_df.groupby(\"date\")['installation_id'].count()\nfig.append_trace(go.Scatter(x = minute_df.index, y = minute_df.values, mode = \"lines\", name = \"Minute\"),row=1,col=1)\nfig.append_trace(go.Scatter(x = hour_df.index, y = hour_df.values, mode = \"markers\", name = \"Hour\"),row=2,col=1)\nfig.append_trace(go.Scatter(x = weekday_df['weekday'], y = weekday_df['count'], mode = \"lines+markers\", name = \"Week Day\"),row=3,col=1)\nfig.append_trace(go.Scatter(x = date_df.index, y = date_df.values, mode = \"lines+markers\", name = \"Date\"),row=4,col=1)\nfig.append_trace(go.Scatter(x = month_df['month'], y = month_df['count'], mode = \"lines\", name = \"Month\"),row=5,col=1)\n\n\n\n\nfig.update_layout(height=1000)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cart Balancer is the most easily solved assessment.<br>\nMost the kids have not finised the Chest Sorter<br>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"temp_df = train_labels_df.groupby('title')['accuracy_group'].value_counts(normalize=True).reset_index(name=\"percentage\")\ntemp_df['percentage'] = temp_df['percentage']*100\ntemp_df = temp_df.round(2)\ntemp_df['title'] = temp_df['title'].str.replace(\"\\(Assessment\\)\",\"\")\ncolors = [x.replace(\")\",\"\").replace(\"rgb(\",\"\") for x in cl.scales['4']['qual']['Dark2']]\ndata = []\nfor i in range(4):\n    text = [str(x) + \"%\" for x in temp_df[temp_df['accuracy_group'] == i]['percentage'].values]\n    data.append(go.Bar(name = i, x = temp_df[temp_df['accuracy_group'] == i]['title'].values,\n                       text = text,textposition='auto',\n                      y = temp_df[temp_df['accuracy_group'] == i]['percentage'].values,marker=dict(\n        color='rgba(' + colors[i] + ',0.6)',\n        line=dict(color='rgba(' + colors[i] + ',1.0)', width=1)\n    )))\nfig = go.Figure(data=data)\nfig.update_layout(barmode='stack', title={'text': \"Percentage of accuracy group for different type of Assessment\",'y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'})\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"temp_df =  train_labels_df['title'].value_counts()\ndata = go.Bar(x = temp_df.index,y = temp_df.values,text = temp_df.values,  textposition='auto')\nfig = go.Figure(data = data)\nfig.update_traces(marker_color='#C5197D', marker_line_color='#8E0052',marker_line_width=1.5, opacity=0.6)\nfig.update_layout(barmode='stack', title={'text': \"Different typess of Assessment\",'y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'})\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets understand the relationship of installation_id, game_session, event_id"},{"metadata":{},"cell_type":"markdown","source":"Installation_id it is a single app installation instance<br>\nNow lets say the installation ID 0001e90f belongs to Alex\nWe can see that Alex has total of 1357 rows in train data set"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_df = train_df[train_df.installation_id==\"0001e90f\"]\ntemp_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Out of 1357 rows we have \" + str(temp_df.event_id.nunique()) + \" unique event ID and \" + str(temp_df.game_session.nunique()) + \" unique game session\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"game seesion is a total period of time devoted to an activity<br>\nlets take a game session example and see what does it have"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_df[temp_df.game_session == \"0848ef14a8dc6892\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This session entirely belongs to Sandcastle Builder"},{"metadata":{},"cell_type":"markdown","source":"Now lets discuss about event id"},{"metadata":{},"cell_type":"markdown","source":"The event id belongs to a specific table called specs_df.<br>\nThis table has 368 unique events.<br>\nThese events can be anything line users x,y cordinates or when a tutorial is played or when a player clicks someting"},{"metadata":{"trusted":true},"cell_type":"code","source":"specs_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Game time distribution"},{"metadata":{},"cell_type":"markdown","source":"lets understand the data distribution of test set. taking only 1000000 records of the train set<br>\nwe are applying np.log1p to the game time is to understand the skewness to the large value\n\n> for interactive visualization please uncomment the code"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['game_time_log'] = train_df['game_time'].apply(np.log1p)\ntrain_df = train_df.head(1000000)\n# fig = px.box(train_df, y=\"game_time_log\",x = \"type\",color='month',title={'text': \"Distribution of game_time by type based on month\",'y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'},\n#              color_discrete_sequence=cl.scales['3']['qual']['Dark2'])\n# fig.show()\nax = sns.catplot(x=\"type\", y=\"game_time_log\", data=train_df,col=\"month\",kind=\"box\", aspect=.7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fig = px.box(train_df, y=\"game_time_log\",x = \"type\",color='weekday_name',title={'text': \"Distribution of game_time by type based on weekday\",'y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'},\n#              color_discrete_sequence=cl.scales['3']['qual']['Dark2'])\n# fig.show()\nax = sns.catplot(x=\"type\", y=\"game_time_log\", data=train_df,col=\"weekday_name\",kind=\"box\", aspect=.7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fig = px.box(train_df, y=\"game_time_log\",x = \"type\",color='world',title={'text': \"Distribution of game_time by type based on world\",'y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'},\n#              color_discrete_sequence=cl.scales['3']['qual']['Dark2'])\n# fig.show()\nplt.figure(figsize=(16, 6))\n\nax = sns.catplot(x=\"type\", y=\"game_time_log\", data=train_df,col=\"world\",kind=\"strip\", aspect=.7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fig = px.strip(train_df, y=\"game_time_log\",x = \"world\",title={'text': \"Distribution of game_time by world\",'y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'},\n#              color_discrete_sequence=cl.scales['3']['qual']['Dark2'])\n# fig.show()\n\nax = sns.catplot(x=\"world\", y=\"game_time_log\", data=train_df,kind=\"strip\", aspect=.7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# How hard the assignments are?"},{"metadata":{},"cell_type":"markdown","source":"Few notes.\n* For a given assessment and accuracy group 3 it is clear that count of incorrect is equal to count of correct. Example for Bird Measurer(accuracy group = 3) has 693 count for incorrect and it has 693 count for correct\n* Chest sorter is the most toughest assessment.\n* A kid has attempted 85 times to solve Bird Measure"},{"metadata":{"trusted":true},"cell_type":"code","source":"incorrect = train_labels_df.groupby(['title','accuracy_group'])['num_incorrect'].value_counts().reset_index(name=\"count\")\ncorrect = train_labels_df.groupby(['title','accuracy_group'])['num_correct'].value_counts().reset_index(name=\"count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.scatter(incorrect[incorrect['title'] == \"Bird Measurer (Assessment)\"], x=\"accuracy_group\", y=\"count\",color = \"num_incorrect\",size = \"count\",hover_name=\"accuracy_group\",title=\"Bird Measurer incorrect answers\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.scatter(correct[correct['title'] == \"Bird Measurer (Assessment)\"], x=\"accuracy_group\", y=\"count\",color = \"num_correct\",size = \"count\",hover_name=\"accuracy_group\",title=\"Bird Measurer correct answers\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.scatter(incorrect[incorrect['title'] == \"Mushroom Sorter (Assessment)\"], x=\"accuracy_group\", y=\"count\",color = \"num_incorrect\",size = \"count\",hover_name=\"accuracy_group\",title=\"Mushroom Sorter incorrect answers\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.scatter(correct[correct['title'] == \"Mushroom Sorter (Assessment)\"], x=\"accuracy_group\", y=\"count\",color = \"num_correct\",size = \"count\",hover_name=\"accuracy_group\",title=\"Mushroom Sorter correct answers\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.scatter(incorrect[incorrect['title'] == \"Cauldron Filler (Assessment)\"], x=\"accuracy_group\", y=\"count\",color = \"num_incorrect\",size = \"count\",hover_name=\"accuracy_group\",title=\"Cauldron Filler incorrect answers\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.scatter(correct[correct['title'] == \"Cauldron Filler (Assessment)\"], x=\"accuracy_group\", y=\"count\",color = \"num_correct\",size = \"count\",hover_name=\"accuracy_group\",title=\"Cauldron Filler correct answers\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.scatter(incorrect[incorrect['title'] == \"Chest Sorter (Assessment)\"], x=\"accuracy_group\", y=\"count\",color = \"num_incorrect\",size = \"count\",hover_name=\"accuracy_group\",title=\"Chest Sorter incorrect answers\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.scatter(correct[correct['title'] == \"Chest Sorter (Assessment)\"], x=\"accuracy_group\", y=\"count\",color = \"num_correct\",size = \"count\",hover_name=\"accuracy_group\",title=\"Chest Sorter correct answers\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.scatter(incorrect[incorrect['title'] == \"Cart Balancer (Assessment)\"], x=\"accuracy_group\", y=\"count\",color = \"num_incorrect\",size = \"count\",hover_name=\"accuracy_group\",title=\"Cart Balancer incorrect answers\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.scatter(correct[correct['title'] == \"Cart Balancer (Assessment)\"], x=\"accuracy_group\", y=\"count\",color = \"num_correct\",size = \"count\",hover_name=\"accuracy_group\",title=\"Cart Balancer correct answers\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# lets build the model"},{"metadata":{},"cell_type":"markdown","source":"lets use catboost "},{"metadata":{},"cell_type":"markdown","source":"Please upvote this kernel too https://www.kaggle.com/mhviraf/a-new-baseline-for-dsb-2019-catboost-model<br>\n(Feature engineering code is taken from here) @mhviraf thankyou for this amazing kernel"},{"metadata":{},"cell_type":"markdown","source":"Submissions are scored based on the quadratic weighted kappa, which measures the agreement between two outcomes. This metric typically varies from 0 (random agreement) to 1 (complete agreement). In the event that there is less agreement than expected by chance, the metric may go below 0.\n\nThe outcomes in this competition are grouped into 4 groups (labeled accuracy_group in the data):\n\n3: the assessment was solved on the first attempt\n2: the assessment was solved on the second attempt\n1: the assessment was solved after 3 or more attempts\n0: the assessment was never solved"},{"metadata":{},"cell_type":"markdown","source":"More about QWK https://www.kaggle.com/c/data-science-bowl-2019/discussion/114133"},{"metadata":{"trusted":true},"cell_type":"code","source":"def qwk(act,pred,n=4,hist_range=(0,3)):\n    \n    O = confusion_matrix(act,pred)\n    O = np.divide(O,np.sum(O))\n    \n    W = np.zeros((n,n))\n    for i in range(n):\n        for j in range(n):\n            W[i][j] = ((i-j)**2)/((n-1)**2)\n            \n    act_hist = np.histogram(act,bins=n,range=hist_range)[0]\n    prd_hist = np.histogram(pred,bins=n,range=hist_range)[0]\n    \n    E = np.outer(act_hist,prd_hist)\n    E = np.divide(E,np.sum(E))\n    \n    num = np.sum(np.multiply(W,O))\n    den = np.sum(np.multiply(W,E))\n        \n    return 1-np.divide(num,den)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_user_activities = list(set(train_df['title'].unique()).union(set(test_df['title'].unique())))\nactivities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n\ntrain_df['title'] = train_df['title'].map(activities_map)\ntest_df['title'] = test_df['title'].map(activities_map)\ntrain_labels_df['title'] = train_labels_df['title'].map(activities_map)\n\nwin_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\nwin_code[activities_map['Bird Measurer (Assessment)']] = 4110\n\ntrain_df['timestamp'] = pd.to_datetime(train_df['timestamp'])\ntest_df['timestamp'] = pd.to_datetime(test_df['timestamp'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_data(user_sample, test_set=False):\n    last_activity = 0\n    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n    all_assessments = []\n    accumulated_accuracy_group = 0\n    accumulated_accuracy=0\n    accumulated_correct_attempts = 0 \n    accumulated_uncorrect_attempts = 0 \n    accumulated_actions = 0\n    counter = 0\n    durations = []\n    for i, session in user_sample.groupby('game_session', sort=False):\n        session_type = session['type'].iloc[0]\n        session_title = session['title'].iloc[0]\n        if test_set == True:\n            second_condition = True\n        else:\n            if len(session)>1:\n                second_condition = True\n            else:\n                second_condition= False\n            \n        if (session_type == 'Assessment') & (second_condition):\n            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n            features = user_activities_count.copy()\n            features['session_title'] = session['title'].iloc[0] \n            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n            accumulated_correct_attempts += true_attempts \n            accumulated_uncorrect_attempts += false_attempts\n            if durations == []:\n                features['duration_mean'] = 0\n            else:\n                features['duration_mean'] = np.mean(durations)\n            durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n            features['accumulated_accuracy'] = accumulated_accuracy/counter if counter > 0 else 0\n            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n            accumulated_accuracy += accuracy\n            if accuracy == 0:\n                features['accuracy_group'] = 0\n            elif accuracy == 1:\n                features['accuracy_group'] = 3\n            elif accuracy == 0.5:\n                features['accuracy_group'] = 2\n            else:\n                features['accuracy_group'] = 1\n\n            features.update(accuracy_groups)\n            features['accumulated_accuracy_group'] = accumulated_accuracy_group/counter if counter > 0 else 0\n            features['accumulated_actions'] = accumulated_actions\n            accumulated_accuracy_group += features['accuracy_group']\n            accuracy_groups[features['accuracy_group']] += 1\n            if test_set == True:\n                all_assessments.append(features)\n            else:\n                if true_attempts+false_attempts > 0:\n                    all_assessments.append(features)\n                \n            counter += 1\n\n        accumulated_actions += len(session)\n        if last_activity != session_type:\n            user_activities_count[session_type] += 1\n            last_activity = session_type\n\n    if test_set:\n        return all_assessments[-1] \n    return all_assessments","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compiled_data = []\ninstallation_id = train_df['installation_id'].nunique()\nfor i, (ins_id, user_sample) in tqdm(enumerate(train_df.groupby('installation_id', sort=False)), total=installation_id):\n    compiled_data += get_data(user_sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train = pd.DataFrame(compiled_data)\ndel compiled_data\nnew_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_features = [x for x in new_train.columns if x not in ['accuracy_group']]\ncat_features = ['session_title']\nX, y = new_train[all_features], new_train['accuracy_group']\ndel train_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are gonna use CatBoostClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = CatBoostClassifier(loss_function='MultiClass',task_type=\"CPU\",learning_rate=0.05,iterations=3000,od_type=\"Iter\",early_stopping_rounds=500,random_seed=21)\nclf.fit(X, y, verbose=500, cat_features=cat_features)\ndel X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_test = []\nfor ins_id, user_sample in tqdm(test_df.groupby('installation_id', sort=False), total=1000):\n    a = get_data(user_sample, test_set=True)\n    new_test.append(a)\n    \nX_test = pd.DataFrame(new_test)\ndel test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = clf.predict(X_test)\ndel X_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df['accuracy_group'] = np.round(preds).astype('int')\nsubmission_df.to_csv('submission.csv', index=None)\nsubmission_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> WIP<br>\n> Please upvote if you find this kernel intresting"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}