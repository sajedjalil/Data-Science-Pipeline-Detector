{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this competition, we have to use the gameplay data to forecast how many attempts a child will take to pass a given assessment (an incorrect answer is counted as an attempt).\nwe have given an anonymous gameplay data, including knowledge of videos watched and games played, from the PBS KIDS Measure Up! app, a game-based learning tool developed as a part of the CPB-PBS Ready To Learn Initiative with funding from the U.S. Department of Education.\n\nThe outcomes in this competition are grouped into 4 groups (labeled accuracy_group in the data):\n\n* 3: the assessment was solved on the first attempt\n* 2: the assessment was solved on the second attempt\n* 1: the assessment was solved after 3 or more attempts\n* 0: the assessment was never solved"},{"metadata":{},"cell_type":"markdown","source":"### Load packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport gc\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\nfrom numba import jit \n#some essential libraries for data processing!\nimport numpy as np\nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n#some for nice output descriptions\nfrom time import time \nfrom tqdm import tqdm_notebook as tqdm\nfrom collections import Counter\n \nfrom scipy import stats #for some statistical processing\n\n#models which we gonna use in this notebook\nfrom xgboost import XGBClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\n\n#kappa scoring with quadratic weights\nfrom sklearn.metrics import cohen_kappa_score\n\n#some pretty common validation stratigies.\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\n#you already know it all champ!\nimport gc\nimport json\npd.set_option('display.max_columns', 1000)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Read in the data CSV files\ntrain = pd.read_csv('../input/data-science-bowl-2019/train.csv')\ntrain_labels = pd.read_csv('../input/data-science-bowl-2019/train_labels.csv')\ntest = pd.read_csv('../input/data-science-bowl-2019/test.csv')\nspecs = pd.read_csv('../input/data-science-bowl-2019/specs.csv')\nss = pd.read_csv('../input/data-science-bowl-2019/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode_title(train, test, train_labels):\n    # encode title\n    # make a list with all the unique 'titles' from the train and test set\n    list_of_user_activities = list(set(train['title'].unique()).union(set(test['title'].unique())))\n    # make a list with all the unique 'event_code' from the train and test set\n    list_of_event_code = list(set(train['event_code'].unique()).union(set(test['event_code'].unique())))\n    # make a list with all the unique worlds from the train and test set\n    list_of_worlds = list(set(train['world'].unique()).union(set(test['world'].unique())))\n    # create a dictionary numerating the titles\n    activities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n    activities_labels = dict(zip(np.arange(len(list_of_user_activities)), list_of_user_activities))\n    activities_world = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n    # replace the text titles with the number titles from the dict\n    train['title'] = train['title'].map(activities_map)\n    test['title'] = test['title'].map(activities_map)\n    train['world'] = train['world'].map(activities_world)\n    test['world'] = test['world'].map(activities_world)\n    train_labels['title'] = train_labels['title'].map(activities_map)\n    win_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\n    # then, it set one element, the 'Bird Measurer (Assessment)' as 4110, 10 more than the rest\n    win_code[activities_map['Bird Measurer (Assessment)']] = 4110\n    # convert text into datetime\n    train['timestamp'] = pd.to_datetime(train['timestamp'])\n    test['timestamp'] = pd.to_datetime(test['timestamp'])\n    return train, test, train_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get usefull dict with maping encode\n# train1, test1, train_labels1 = encode_title(train, test, train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_time_features(df):\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['date'] = df['timestamp'].dt.date\n    df['month'] = df['timestamp'].dt.month\n    df['hour'] = df['timestamp'].dt.hour\n    df['year'] = df['timestamp'].dt.year\n    df['dayofweek'] = df['timestamp'].dt.dayofweek\n    df['weekofyear'] = df['timestamp'].dt.weekofyear\n    df['dayofyear'] = df['timestamp'].dt.dayofyear\n    df['quarter'] = df['timestamp'].dt.quarter\n    df['is_month_start'] = df['timestamp'].dt.is_month_start    \n    \n    return df\n    \ndef get_object_columns(df, columns):\n    df = df.groupby(['installation_id', columns])['event_id'].count().reset_index()\n    df = df.pivot_table(index = 'installation_id', columns = [columns], values = 'event_id')\n    df.columns = list(df.columns)\n    df.fillna(0, inplace = True)\n    return df\n\ndef get_numeric_columns(df, column):\n    df = df.groupby('installation_id').agg({f'{column}': ['mean', 'sum', 'min', 'max', 'std', 'skew']})\n    df[column].fillna(df[column].mean(), inplace = True)\n    df.columns = [f'{column}_mean', f'{column}_sum', f'{column}_min', f'{column}_max', f'{column}_std', f'{column}_skew']\n    return df\n\ndef get_numeric_columns_add(df, agg_column, column):\n    df = df.groupby(['installation_id', agg_column]).agg({f'{column}': ['mean', 'sum', 'min', 'max', 'std', 'skew']}).reset_index()\n    df = df.pivot_table(index = 'installation_id', columns = [agg_column], values = [col for col in df.columns if col not in ['installation_id', 'type']])\n    df[column].fillna(df[column].mean(), inplace = True)\n    df.columns = list(df.columns)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# result1.shape,test1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def perform_features_engineering(train_df, test_df, train_labels_df):\n    print(f'Perform features engineering')\n    numerical_columns = ['game_time']\n    categorical_columns = ['type', 'world']\n\n    comp_train_df = pd.DataFrame({'installation_id': train_df['installation_id'].unique()})\n    comp_train_df.set_index('installation_id', inplace = True)\n    comp_test_df = pd.DataFrame({'installation_id': test_df['installation_id'].unique()})\n    comp_test_df.set_index('installation_id', inplace = True)\n\n    test_df = extract_time_features(test_df)\n    train_df = extract_time_features(train_df)\n\n    for i in numerical_columns:\n        comp_train_df = comp_train_df.merge(get_numeric_columns(train_df, i), left_index = True, right_index = True)\n        comp_test_df = comp_test_df.merge(get_numeric_columns(test_df, i), left_index = True, right_index = True)\n    \n    for i in categorical_columns:\n        comp_train_df = comp_train_df.merge(get_object_columns(train_df, i), left_index = True, right_index = True)\n        comp_test_df = comp_test_df.merge(get_object_columns(test_df, i), left_index = True, right_index = True)\n    \n#     for i in categorical_columns:\n#         for j in numerical_columns:\n#             comp_train_df = comp_train_df.merge(get_numeric_columns_add(train_df, i, j), left_index = True, right_index = True)\n#             comp_test_df = comp_test_df.merge(get_numeric_columns_add(test_df, i, j), left_index = True, right_index = True)\n    \n    \n    comp_train_df.reset_index(inplace = True)\n    comp_test_df.reset_index(inplace = True)\n    \n    print('Our training set have {} rows and {} columns'.format(comp_train_df.shape[0], comp_train_df.shape[1]))\n\n    # get the mode of the title\n    labels_map = dict(train_labels_df.groupby('title')['accuracy_group'].agg(lambda x:x.value_counts().index[0]))\n    # merge target\n    labels = train_labels_df[['installation_id', 'title', 'accuracy_group']]\n    # replace title with the mode\n    labels['title'] = labels['title'].map(labels_map)\n    # get title from the test set\n    comp_test_df['title'] = test_df.groupby('installation_id').last()['title'].map(labels_map).reset_index(drop = True)\n    # join train with labels\n    comp_train_df = labels.merge(comp_train_df, on = 'installation_id', how = 'left')\n    print('We have {} training rows'.format(comp_train_df.shape[0]))\n    \n    return comp_train_df, comp_test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@jit\ndef qwk3(a1, a2, max_rat=3):\n    assert(len(a1) == len(a2))\n    a1 = np.asarray(a1, dtype=int)\n    a2 = np.asarray(a2, dtype=int)\n    hist1 = np.zeros((max_rat + 1, ))\n    hist2 = np.zeros((max_rat + 1, ))\n    o = 0\n    for k in range(a1.shape[0]):\n        i, j = a1[k], a2[k]\n        hist1[i] += 1\n        hist2[j] += 1\n        o +=  (i - j) * (i - j)\n    e = 0\n    for i in range(max_rat + 1):\n        for j in range(max_rat + 1):\n            e += hist1[i] * hist2[j] * (i - j) * (i - j)\n    e = e / a1.shape[0]\n    return 1 - o / e\ndef run_model(comp_train_df, comp_test_df):\n    print(f'Run model')\n    num_splits = 9\n    kf = KFold(n_splits=num_splits)\n    features = [i for i in comp_train_df.columns if i not in ['accuracy_group', 'installation_id']]\n    target = 'accuracy_group'\n    oof_pred = np.zeros((len(comp_train_df), 4))\n    y_pred = np.zeros((len(comp_test_df), 4))\n    for fold, (tr_ind, val_ind) in enumerate(kf.split(comp_train_df)):\n        print(f'Fold: {fold+1}')\n        x_train, x_val = comp_train_df[features].iloc[tr_ind], comp_train_df[features].iloc[val_ind]\n        y_train, y_val = comp_train_df[target][tr_ind], comp_train_df[target][val_ind]\n        train_set = lgb.Dataset(x_train, y_train)\n        val_set = lgb.Dataset(x_val, y_val)\n\n        params = {\n            'learning_rate': 0.007,\n            'metric': 'multiclass',\n            'objective': 'multiclass',\n            'num_classes': 4,\n            'feature_fraction': 0.45,\n            \"bagging_fraction\": 0.8,\n            \"bagging_seed\": 22,\n        }\n\n        model = lgb.train(params, train_set, num_boost_round = 10000, early_stopping_rounds = 100, \n                          valid_sets=[train_set, val_set], verbose_eval = 100)\n        oof_pred[val_ind] = model.predict(x_val)\n        y_pred += model.predict(comp_test_df[features]) / num_splits\n        \n        val_crt_fold = qwk3(y_val, oof_pred[val_ind].argmax(axis = 1))\n        print(f'Fold: {fold+1} quadratic weighted kappa score: {np.round(val_crt_fold,4)}')\n        \n    res = qwk3(comp_train_df['accuracy_group'], oof_pred.argmax(axis = 1))\n    print(f'Quadratic weighted score: {np.round(res,4)}')\n        \n    return y_pred\n\ndef prepare_submission(comp_test_df, sample_submission_df, y_pred):\n    comp_test_df = comp_test_df.reset_index()\n    comp_test_df = comp_test_df[['installation_id']]\n    comp_test_df['accuracy_group'] = y_pred.argmax(axis = 1)\n    sample_submission_df.drop('accuracy_group', inplace = True, axis = 1)\n    sample_submission_df = sample_submission_df.merge(comp_test_df, on = 'installation_id')\n    sample_submission_df.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"comp_train_df, comp_test_df = perform_features_engineering(train, test, train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_features = [x for x in comp_train_df.columns if x not in ['accuracy_group',\"installation_id\"]]\n# cat_features = ['session_title']\nX, y = comp_train_df[all_features], comp_train_df['accuracy_group']\ndef make_classifier():\n    clf = CatBoostClassifier(\n                               loss_function='MultiClass',\n    #                            eval_metric=\"AUC\",\n                               task_type=\"CPU\",\n                               learning_rate=0.01,\n                               iterations=5000,\n                               od_type=\"Iter\",\n#                                depth=8,\n                               early_stopping_rounds=500,\n    #                            l2_leaf_reg=1,\n    #                            border_count=96,\n                               random_seed=2019\n                              )\n        \n    return clf\noof = np.zeros(len(X))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=2)\nX, y = sm.fit_sample(X, y.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CV\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import KFold\n# preds = np.zeros(len(X_test))\n# train model on all data once\nclf = make_classifier()\nclf.fit(X, y, verbose=500)\n\n# del X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make predictions on test set once\npreds = clf.predict(comp_test_df[all_features])\n# del X_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss['accuracy_group'] = np.round(preds).astype('int')\nss.to_csv('submission.csv', index=None)\nss.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss['accuracy_group'].plot(kind='hist')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss['accuracy_group'].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Missing data analysis\n# totalt = train.isnull().sum().sort_values(ascending=False)\n# percent = (train.isnull().sum()/train.isnull().count()).sort_values(ascending=False)\n# missing_data = pd.concat([totalt, percent], axis=1, keys=['Total', 'Percent'])\n# print (\"Missing Data at Training\")\n# missing_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_labels.accuracy_group.value_counts().plot(\"bar\",title='Target (accuracy_group)')\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for col in test1.columns:\n#     print(\"Column name:\", col)\n#     print(\"Unique values--->\",test1[col].nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for col in result1.columns:\n#     print(\"Column Name:\", col)\n#     print(\"Unique values--->\", result1[col].nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# result = pd.merge(train_, specs, how='left', on='event_id')\n# result1 = pd.merge(result, train_labels, how='inner', on=['game_session', 'installation_id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}