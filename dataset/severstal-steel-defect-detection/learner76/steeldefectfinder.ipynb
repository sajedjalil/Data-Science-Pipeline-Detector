{"cells":[{"metadata":{},"cell_type":"markdown","source":"The idea here is to apply object detection algorithm on custom objects beyond the previously defined (80 or so in YOLO for ImageAI etc.) objects such as people, cars etc.\nThe custom objects would be the four type of defects mentioned in this competion - say defect1, defect2, defect3 and defect 4.\nSome of the inspiration here is from https://www.kaggle.com/robinteuwens/machine-vision-detecting-steel-defects\nThanks for getting started!"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"!cp -r /kaggle/input/imageai/imageai/imageai/ imageai\n\n\n\n# library imports\nimport numpy as np \nimport pandas as pd\nimport random as rn\nimport cv2 as cv \nimport os\nimport sys\nfrom pathlib import Path\nfrom datetime import datetime\nimport time\n# tensorflow for neural networks\nimport tensorflow as tf\nfrom imageai.Detection import ObjectDetection\n\n# visuals\nfrom matplotlib import pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nfrom IPython.display import Image\n\n# for reproducibility\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntf.set_random_seed(RANDOM_SEED)\nrn.seed(RANDOM_SEED)\n# paths\nimg_train_folder = Path('../input/severstal-steel-defect-detection/train_images/')\nimg_test_folder = Path('../input/severstal-steel-defect-detection/test_images/')\nnumberOfSampleExtractionsShown = 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's first explore the training data. A given image can have multiple defects of multiple defect types. If we can first separate all the images into two groups: with and without defects, we can train an intermediate classifier that can first look at future image to see whether or not it has a defect. Given a LARGE number of images do not have defect, this will lead to avoiding loss of data and strengthening our predictions.\nTo separate the images, we first need to add additional columns on training data, especially ImageId. Also for cases where the image does have a defect, we also need to know what class of defect it is and hence we would also like to add ClassId column. Finally, since encondings in many rows are empty, it would be worth adding another column to indicate whether Encoding exists.\nSo, splitting of ImageId_ClassId column into two, which would be the equivalent of doing the following in excel (please open the train.csv in excel to understand this):\n*=LEFT(A2,FIND(\"_\",A2)-1) and =RIGHT(A2,LEN(A2)-FIND(\"_\",A2))*\nAlso, for the purposes of pandas pivot table aggregation, it would be better to have a number instead of true/false for EncodingExists indicator, so excel equivalent will be *=LEN(B2)*\n\nOnce we create a pivot table with ImageId as row and EncodingExists as value to aggregate upon, the pandas pivot will remove all images that have no defects since pandas pivot drops NA values by default. That ways, we can easily separate the images into defects and no_defects groups.\n"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# reading in the training set\ndata = pd.read_csv('/kaggle/input/severstal-steel-defect-detection/train.csv')\n# add new columns ImageId, ClassId and EncodingExists to the data file \n# equivalent of doing the following in excel: =LEFT(A2,FIND(\"_\",A2)-1) and =RIGHT(A2,LEN(A2)-FIND(\"_\",A2))\n# and EncodingExists would be roughly about =LEN(B2) since for pandas pivot table agg will have\n# zero or 1 instead of false or true\ndata['ImageId'], data['ClassId'] = data.ImageId_ClassId.str.split('_', n=1).str\n# change the type of classid to be an integer\ndata['ClassId'] = data['ClassId'].astype(np.uint8)\ndata['EncodingExists'] = data.EncodedPixels.str.len()\n\n# find out which images have no defects\n# create a pivot table with ImageId as row and EncodingExists as value to aggregate upon\nimageDefectPivot = pd.pivot_table(data,index=['ImageId'],values=['EncodingExists'])\n# Those images with all NA values in the defect pivot will get dropped since dropna for pandas pivot is true by default\n# so now you can classify images as withDefect and withoutDefect\nimageIdsWithDefect = imageDefectPivot.index.values\nno_defect_data = data.loc[~data['ImageId'].isin(imageIdsWithDefect)]\nimageIdsWithoutDefect = no_defect_data.ImageId.values\ndefect_data = data.loc[data['ImageId'].isin(imageIdsWithDefect)]\n#defect_data = defect_data.dropna(subset=['EncodedPixels'], axis='rows', inplace=True)\n\n# storing a list of images without defects for later use and testing\nno_defects = data[data['EncodedPixels'].isna()][['ImageId']].drop_duplicates()\n#print (\"No defects\", no_defects)\n# adding the columns so we can append (a sample of) the dataset if need be, later\nno_defects['EncodedPixels'] = ''\nno_defects['ClassId'] = np.empty((len(no_defects), 0)).tolist()\nno_defects['Distinct Defect Types'] = 0\nno_defects.reset_index(inplace=True)\n\n# keep only the images with labels\nsquashed = data.dropna(subset=['EncodedPixels'], axis='rows', inplace=True)\n\n# squash multiple rows per image into a list\nsquashed = data[['ImageId', 'EncodedPixels', 'ClassId']] \\\n            .groupby('ImageId', as_index=False) \\\n            .agg(list) \\\n\n# count the amount of class labels per image\nsquashed['Distinct Defect Types'] = squashed.ClassId.apply(lambda x: len(x))\n\n# display first ten to show new structure\n#squashed.head(10)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def build_mask(encodings, labels):\n    \"\"\" takes a pair of lists of encodings and labels, \n        and turns them into a 3d numpy array of shape (256, 1600, 4) \n    \"\"\"\n    \n    # initialise an empty numpy array \n    mask = np.zeros((256,1600,4), dtype=np.uint8)\n    \n    # building the masks\n    for rle, label in zip(encodings, labels):\n        \n        # classes are [1, 2, 3, 4], corresponding indeces are [0, 1, 2, 3]\n        index = label - 1\n        \n        # fit the mask into the correct layer\n        # note we need to transpose the matrix to account for \n        # numpy and openCV handling width and height in reverse order \n        mask[:,:,index] = rle_to_mask(rle).T\n        \n    \n    return mask\n\ndef build_mask_for_class(encodings, forclass):\n    \"\"\" takes a list of encodings  \n        and turns them into a 2d numpy array of shape (256, 1600) only for the\n        specified class\n    \"\"\"\n    \n    # initialise an empty numpy array \n    mask = np.zeros((256,1600), dtype=np.uint8)\n    mask = rle_to_mask(encodings).T\n    \n    return mask\n\n\ndef mask_to_contours(image, mask_layer, color):\n    \"\"\" converts a mask to contours using OpenCV and draws it on the image\n    \"\"\"\n\n    # https://docs.opencv.org/4.1.0/d4/d73/tutorial_py_contours_begin.html\n    contours, hierarchy = cv.findContours(mask_layer, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n    image = cv.drawContours(image, contours, -1, color, 2)\n        \n    return image\n\ndef mask_to_contours_extraction(image, mask_layer, color,locn,rowIndex):\n    \"\"\" converts a mask to contours using OpenCV and extract them from the image\n    \"\"\"\n    if image is None:\n        return\n    if not os.path.exists(locn):\n        os.makedirs(locn)\n        #print(\"created\", locn)\n    os.chdir(locn)\n    # https://docs.opencv.org/4.1.0/d4/d73/tutorial_py_contours_begin.html\n    contours, hierarchy = cv.findContours(mask_layer, cv.RETR_TREE, cv.CHAIN_APPROX_NONE)\n    #image = cv.drawContours(image, contours, -1, color, 2)\n    for contour in contours:\n        x,y,width,height = cv.boundingRect(contour)\n        defect_image = image[y:y+height,x:x+width]\n        milliseconds = int(round(time.time()*1000))\n        tmpImageName = \"defect\" + str(milliseconds)+\".png\"\n        #print(\"imagename is\", tmpImageName)\n        \n        #image_name = datetime.now()\n        #cv.imwrite(Path.joinpath(locn, str(milliseconds)),defect_image)\n        #Commenting out Image writing just for saving i/o while committing the kernel, the following two lines should be uncommented\n        if not defect_image is None:\n            if (len(defect_image)>1):\n                #cv.imwrite(tmpImageName,defect_image)\n                if (rowIndex<15):\n                    #show a few extractions to get a visual feel\n                    plt.imshow(defect_image, cmap = 'gray', interpolation = 'bicubic')\n                    plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n                    plt.show()\n    return \n\ndef extract_defect_contours(file_name, mask,folder_locn,rowIndex):\n    \"\"\" open an image and extract segments identified by the mask/contours and store them in folder_locn \n    \"\"\"\n    \n    # reading in the image\n    #image = cv.imread(f'{img_train_folder}/{file_name}')\n    image = cv.imread(os.path.join('/kaggle/input/severstal-steel-defect-detection/train_images/',file_name))\n    mask_to_contours_extraction(image, mask, color=palette[1],locn=folder_locn,rowIndex=rowIndex)   \n        \n    return \n\n    \ndef visualise_mask(file_name, mask):\n    \"\"\" open an image and draws clear masks, so we don't lose sight of the \n        interesting features hiding underneath \n    \"\"\"\n    \n    # reading in the image\n    image = cv.imread(os.path.join('/kaggle/input/severstal-steel-defect-detection/train_images/',file_name))\n\n    # going through the 4 layers in the last dimension \n    # of our mask with shape (256, 1600, 4)\n    for index in range(mask.shape[-1]):\n        \n        # indeces are [0, 1, 2, 3], corresponding classes are [1, 2, 3, 4]\n        label = index + 1\n        \n        # add the contours, layer per layer \n        image = mask_to_contours(image, mask[:,:,index], color=palette[label])   \n        \n    return image\n\ndef rle_to_mask(lre, shape=(1600,256)):\n    '''\n    params:  rle   - run-length encoding string (pairs of start & length of encoding)\n             shape - (width,height) of numpy array to return \n    \n    returns: numpy array with dimensions of shape parameter\n    '''    \n    # the incoming string is space-delimited\n    runs = np.asarray([int(run) for run in lre.split(' ')])\n    \n    # we do the same operation with the even and uneven elements, but this time with addition\n    runs[1::2] += runs[0::2]\n    # pixel numbers start at 1, indexes start at 0\n    runs -= 1\n    \n    # extract the starting and ending indeces at even and uneven intervals, respectively\n    run_starts, run_ends = runs[0::2], runs[1::2]\n    \n    # build the mask\n    h, w = shape\n    mask = np.zeros(h*w, dtype=np.uint8)\n    for start, end in zip(run_starts, run_ends):\n        mask[start:end] = 1\n    \n    # transform the numpy array from flat to the original image shape\n    return mask.reshape(shape)\n\ndef rle_decode(mask_rle, shape=(1600,256)):\n    #print('rle_decode(mask_rle = ', mask_rle)\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return\n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        #print(\"hi:\",hi,\"low:\",lo)\n        img[lo:hi] = 1\n    return img.reshape(shape).T  # Needed to align to RLE direction\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To get a visual feel for the defects, let's visualize a few training images by showing the encodings on the image. Simple convert the rle encoding into masks, use openCV to convert mask into contours and then drawing those contours on to the image. "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"\"\"\" use a consistent color palette per label throughout the notebook \"\"\"\nimport colorlover as cl\n\n# see: https://plot.ly/ipython-notebooks/color-scales/\ncolors = cl.scales['4']['qual']['Set3']\nlabels = np.array(range(1,5))\n\n# combining into a dictionary\npalette = dict(zip(labels, np.array(cl.to_numeric(colors))))\n# squash multiple rows per image into a list after removing rows without encoding\ndefect_data.dropna(subset=['EncodedPixels'], axis='rows', inplace=True)\nsquashed_defects = defect_data[['ImageId', 'EncodedPixels', 'ClassId']] \\\n            .groupby('ImageId', as_index=False) \\\n            .agg(list) \\\n\nsample_size_plot=10\nsample = squashed_defects.sample(sample_size_plot)\n# make a subplot+\nfig, axes = plt.subplots(sample_size_plot, 1, figsize=(16, sample_size_plot*3))\nfig.tight_layout()\n    \n# looping over sample\nfor i, (index, row) in enumerate(sample.iterrows()):\n    # current ax\n    ax = axes[i,]\n    # build the mask \n    mask = build_mask(encodings=row.EncodedPixels, labels=row.ClassId)\n    # fetch the image and draw the contours\n    image = visualise_mask(file_name=row.ImageId, mask=mask)\n    # display\n    ax.set_title(f'{row.ImageId}: {row.ClassId}')\n    ax.axis('off')\n    ax.imshow(image);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to train custom computer vision model because we want to train the machine to see defect1, defect2, ...objects. We will use **ImageAI**** library for that.\nImageAI documentation for custom object training says \"Your image dataset must contain at least 2 different classes/types of images (e.g cat and dog) and you must collect at least 500 images for each of the classes to achieve maximum accuracy\".  The dataset provided to train in this competition has 897 images for defect1, 113/1483/49 for defect classes 2/3/4 - so perhaps best to train for defects1 and 3 only for now. Open train.csv in excel and apply data filters to see 897, 113 etc. numbers.\n\nIt would be ideal to give image path and encoding pixels while training the model since that would be i/o efficient but according to the documentation at  https://github.com/OlafenwaMoses/ImageAI/blob/master/imageai/Prediction/CUSTOMTRAINING.md as well as the version dated 31-Aug-2019 of the documentation at \n https://buildmedia.readthedocs.org/media/pdf/imageai/latest/imageai.pdf, it seems the only way to train a custom image prediction (defect1 etc. prediction) is to create a specific folder structure.\nSo, we will create steelDefects/train/defect1/defect1-train-images and steelDefects/train/defect3/defect3-train-images as well as the equivalent test folders. \nWe will extract just the defect part of the image from defect images - that too just defect1 for defect1 training and defect3 for defect3 training. This will minimize noise while training custom image prediction. Further, to ensure fresh extraction of training images and avoid any noise from previously extracted images, we will empty the folders before starting the extraction process.\nFor extraction of defect images of a specific class, we will refer back to defect data (we had separated all data into defect and no_defect) and further filter by ClassId. For each such row filtered, we will first decode the rle encoding into an image mask, then using OpenCV, find contours (potentially multiple in a single image) in the given image. Then, we will find a bounding rectangle for the contour co-ordinates and finally cut out the part of the image within the bounding rectangle. We will store these defect images in corresponding training folders (defect-1-train-images for defect1 and likewise for defect3).\n\nA few sample extractions for both types of defects are shown below (please scroll for viewing the images).\n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#now let us train custom ImageAI model on training images provided. ImageAI custom training says \"Your \n#image dataset must contain at least 2 different classes/types of images (e.g cat and dog) and you must \n#collect at least 500 images for each of the classes to achieve maximum accuracy\". \n#The dataset provided to train\n#has 897 images for defect1, 113/1483/49 for defect classes 2/3/4 - so perhaps best to train for defects1 \n#and 3 only for now\n#before training the model, need to create the following folder structure: \n#steelDefects/train/defect1/defect1-train-images \n#and steelDefects/train/defect3/defect3-train-images; also equivalent test folders\n#instead of having to save defect1 and 3 images in this folder structure, is there an alternative way of \n#giving image path and encoding pixels; that would avoid lots of i/o. Seems like no according to the\n#documentation at github: \n#https://github.com/OlafenwaMoses/ImageAI/blob/master/imageai/Prediction/CUSTOMTRAINING.md\n#also, as of 31Aug2019 doc at https://buildmedia.readthedocs.org/media/pdf/imageai/latest/imageai.pdf\ndefect1_train_folder = Path('/kaggle/working/steelDefects/train/defect1/defect1-train-images/')\ndefect3_train_folder = Path('/kaggle/working/steelDefects/train/defect3/defect3-train-images/')\n# to ensure fresh extraction of training images and avoid any noise from previously extracted images, empty the folders\nif not os.path.exists(defect1_train_folder):\n    os.makedirs(defect1_train_folder)\nif not os.path.exists(defect3_train_folder):\n    os.makedirs(defect3_train_folder)\n\nfor defect_file_name in os.listdir(defect1_train_folder):\n    defectfilepath = os.path.join(defect1_train_folder,defect_file_name)\n    if (os.path.isfile(defectfilepath)):\n        os.remove(defectfilepath)\nfor defect_file_name in os.listdir(defect3_train_folder):\n    defectfilepath = os.path.join(defect3_train_folder,defect_file_name)\n    if (os.path.isfile(defectfilepath)):\n        os.remove(defectfilepath)\n\n#now store just the part that has the defect1 in defect1 train folder \n#defect_data where 'ClassId' is 1\ndefect1_data = defect_data[defect_data['ClassId']==1]\ndefect3_data = defect_data[defect_data['ClassId']==3]\nnumberOfSampleExtractionsShown = 0\n# looping over defect1_data, every time storing the contour image in train folder\nfor i, (index, row) in enumerate(defect1_data.iterrows()):\n    image = extract_defect_contours(file_name=row.ImageId, mask=rle_decode(row.EncodedPixels).T,folder_locn=defect1_train_folder,rowIndex=i)\nnumberOfSampleExtractionsShown = 0\nfor i, (index, row) in enumerate(defect3_data.iterrows()):\n    image = extract_defect_contours(file_name=row.ImageId, mask=rle_decode(row.EncodedPixels).T,folder_locn=defect3_train_folder,rowIndex=i)\n\n#Show a few samples of both defect1 image extraction as well as defect3 image extraction\nnumberOfSampleExtractions = 15\nprint(\"-----------defect1 image extractions-----\")\nfor defect_file_name in os.listdir(defect1_train_folder):\n    img = cv.imread(os.path.join(defect1_train_folder,defect_file_name))\n    if not img is None:\n        if numberOfSampleExtractions>0:\n            plt.imshow(img, cmap = 'gray', interpolation = 'bicubic')\n            plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n            plt.show()\n            numberOfSampleExtractions = numberOfSampleExtractions-1\n            \nprint(\"-----------defect3 image extractions-----\")\n\nnumberOfSampleExtractions = 15\nfor defect3_file_name in os.listdir(defect3_train_folder):\n    img3 = cv.imread(os.path.join(defect3_train_folder,defect3_file_name))\n    if not img3 is None:\n        if numberOfSampleExtractions>0:\n            plt.imshow(img3, cmap = 'gray', interpolation = 'bicubic')\n            plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n            plt.show()\n            numberOfSampleExtractions = numberOfSampleExtractions-1\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Given we have extracted the portions of the images with various defects and segregated them by class, we are now ready to train the custom model for viewing different steel defects.\nOnce we do have the trained models, we will need to find a way of using object detection that comes with ImageAI. A sample usage of ImageAI object detection is as follows, along with parts that we will need to conceptually change highlighted:\n1. detector = ObjectDetection()\n1. detector.setModelTypeAsRetinaNet()\n1. detector.setModelPath(\"../input/imageai/resnet50_coco_best_v2.0.1.h5\") **Instead of resnet50_coco model, we will have to use our own model for viewing defects****\n1. detector.loadModel()\n1. custom_objects = detector.CustomObjects(person=True, car=False) **Instead of custom objects being person and car from coco imageset, we will use defect1 and defect3**\n1. detections = detector.detectCustomObjectsFromImage(input_image=\"../input/imageaitest2/test.png\", output_image_path=\"../pedestrianNew.png\", custom_objects=custom_objects, minimum_percentage_probability=65) **Instead of test.png, we will use the images given in the test data for this competition**\n\nFurther, the custom image prediction model needs a few images in the test folder too (between 100 and 200 as per the documentation). Since the only defect object images we have are the once we extracted in train folder, we will need to move some of those from train folder to test folder. Also, since this block of code maybe run multiple times, it is better to see how many files have already been moved instead of moving 150 every time.\n\nFinally, given that train and test folders for both defect1 and defect3 are ready, simply train the custom model for viewing steel defects just by the following four steps:\n1. model_trainer = ModelTraining()\n1. model_trainer.setModelTypeAsResNet()\n1. model_trainer.setDataDirectory(r\"/kaggle/working/steelDefects\")\n1. model_trainer.trainModel(num_objects=2, and other parameters)"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":false},"cell_type":"code","source":"#now train the custom model for viewing steel defects\nimport shutil\nfrom imageai.Prediction.Custom import ModelTraining\n\n#create test folders and populate with some test images\n#since the only defect object images we have are the once we extracted in train folder, we will need to move some of those from train folder to test folder\ndefect1_test_folder = Path('/kaggle/working/steelDefects/test/defect1/defect1-test-images/')\ndefect3_test_folder = Path('/kaggle/working/steelDefects/test/defect3/defect3-test-images/')\nif not os.path.exists(defect1_test_folder):\n        os.makedirs(defect1_test_folder)\n\nif not os.path.exists(defect3_test_folder):\n        os.makedirs(defect3_test_folder)\n\n#remove all none/blank images before starting to train\nfor defect1_file_name in os.listdir(defect1_train_folder):\n    defectfilepath = os.path.join(defect1_train_folder,defect1_file_name)\n    img3 = cv.imread(defectfilepath)\n    if img3 is None:\n        if (os.path.isfile(defectfilepath)):\n            os.remove(defectfilepath)\n\nfor defect3_file_name in os.listdir(defect3_train_folder):\n    defectfilepath = os.path.join(defect3_train_folder,defect3_file_name)\n    img3 = cv.imread(defectfilepath)\n    if img3 is None:\n        if (os.path.isfile(defectfilepath)):\n            os.remove(defectfilepath)\nfor defect1_file_name in os.listdir(defect1_test_folder):\n    defectfilepath = os.path.join(defect1_test_folder,defect1_file_name)\n    img3 = cv.imread(defectfilepath)\n    if img3 is None:\n        if (os.path.isfile(defectfilepath)):\n            os.remove(defectfilepath)\nfor defect3_file_name in os.listdir(defect3_test_folder):\n    defectfilepath = os.path.join(defect3_test_folder,defect3_file_name)\n    img3 = cv.imread(defectfilepath)\n    if img3 is None:\n        if (os.path.isfile(defectfilepath)):\n            os.remove(defectfilepath)\n            \nprint(\"number of defect 1 train images:\",len(os.listdir(defect1_train_folder)))\nprint(\"number of defect 3 images:\",len(os.listdir(defect3_train_folder)))\n#since the competition train data seems to have over 1000 defect 1 images and over 6000 defect 3 images, we can move 150 of both to test folders\n#since this block of code maybe run multiple times, it is better to see how many files have already been moved instead of moving 150 every time\nno_of_defect1_files_to_move = 150 - len(os.listdir(defect1_test_folder))\nprint(\"will move:\",no_of_defect1_files_to_move, \" defect1 images from train to test\" )\nfor defect_file_name in os.listdir(defect1_train_folder):\n    srcFile = os.path.join(defect1_train_folder,defect_file_name)\n    destFile = os.path.join(defect1_test_folder,defect_file_name)\n    if (no_of_defect1_files_to_move>0):\n        shutil.move(srcFile, destFile)\n    no_of_defect1_files_to_move = no_of_defect1_files_to_move - 1\n\nno_of_defect3_files_to_move = 150 - len(os.listdir(defect3_test_folder))\nprint(\"will move:\",no_of_defect3_files_to_move, \" defect3 images from train to test\" )\nfor defect_file_name in os.listdir(defect3_train_folder):\n    srcFile = os.path.join(defect3_train_folder,defect_file_name)\n    destFile = os.path.join(defect3_test_folder,defect_file_name)\n    if (no_of_defect3_files_to_move>0):\n        shutil.move(srcFile, destFile)\n    no_of_defect3_files_to_move = no_of_defect3_files_to_move - 1\n#print(\"number of defect 1 train images:\",len(os.listdir(defect1_train_folder)))\n#print(\"number of defect 3 images:\",len(os.listdir(defect3_train_folder)))\n\nprint(\"model training will now start - can take a day without GPU, so might be commented out - please uncomment .trainModel when you are ready to run\")\nprint(\"various output models will be in models folder with accuracy mentioned in the file name and extension .h5\")\n#now that train and test folders for both defect1 and defect3 are ready, train the custom model\nmodel_trainer = ModelTraining()\nmodel_trainer.setModelTypeAsResNet()\nmodel_trainer.setDataDirectory(r\"/kaggle/working/steelDefects\")\n#the following line on training model is commented to avoid training on every kernel commit - takes about a day without GPU and about an hour with GPU!\n#model_trainer.trainModel(num_objects=2, num_experiments=100, enhance_data=True, batch_size=32, show_network_summary=True)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}