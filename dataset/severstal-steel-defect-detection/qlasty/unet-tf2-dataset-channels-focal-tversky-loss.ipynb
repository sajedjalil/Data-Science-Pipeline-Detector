{"cells":[{"metadata":{},"cell_type":"markdown","source":"This kernel is a core of the middle part in a two step solution, which was a common pattern in this competition if you look at other kernels. It does semantic segmentation on images, which were classified as 'with defect' by binary classifier from my another kernel. In third kernel, those results were combined for final submission.   \n\nKey parts of the kernel:\n* usage of tf.data.Dataset pipeline also for mask generation  \n* image-mask aware augmentations  \n* channels-aware focal tversky loss function within single model for all classes of defects\n* comparison of regular vs channels aware loss function training results\n\nAlso I was taking so much mainly from these kernels:  \nhttps://www.kaggle.com/ateplyuk/keras-starter-segmentation  \nhttps://www.kaggle.com/paulorzp/eda-and-opencv-starter  \nhttps://www.kaggle.com/seriousran/xception-beseline-model-for-starter-in-keras  \nhttps://www.kaggle.com/titericz/building-and-visualizing-masks  "},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":true},"cell_type":"code","source":"!pip install gast==0.2.2\n!pip install git+https://github.com/qubvel/segmentation_models","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":false,"_kg_hide-input":true},"cell_type":"code","source":"import os\nimport gc\nimport numpy as np \nimport pandas as pd \nimport random as rn\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n\nimport segmentation_models as sm\nsm.set_framework('tf.keras')\n\n%matplotlib inline\nprint('TF version:',tf.__version__)\nprint('Eager execution:', tf.executing_eagerly())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_path = '../input/severstal-steel-defect-detection/'\ntrain = pd.read_csv(os.path.join(base_path, 'train.csv'))\n\ntrain['ImageId'] = train['ImageId_ClassId'].map(lambda x: x.split('.')[0]+'.jpg')\ntrain2 = pd.DataFrame({'ImageId':train['ImageId'][::4]})\ntrain2['class_rle1'] = train['EncodedPixels'][::4].values\ntrain2['class_rle2'] = train['EncodedPixels'][1::4].values\ntrain2['class_rle3'] = train['EncodedPixels'][2::4].values\ntrain2['class_rle4'] = train['EncodedPixels'][3::4].values\ntrain2.reset_index(inplace=True,drop=True)\ntrain2.fillna('',inplace=True); \ntrain2['count'] = np.sum(train2.iloc[:,1:]!='',axis=1).map(str)\ntrain2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# How many images are there with given defect in original training set\nprint(np.sum(train2[['class_rle1','class_rle2','class_rle3','class_rle4']]!=''))\nprint('Total images:', len(train2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# selecting images classified by binary classifier as 'with defect'\noutput_path = '../input/unet-dataset-for-binary-classification/'\nfiltered_train = pd.read_csv(os.path.join(output_path, 'train_filter.csv'))\ntrain2 = train2[train2['ImageId'].isin(filtered_train['ImageId'].values)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# How many images are left after application of binary classifier\nprint(np.sum(train2[['class_rle1','class_rle2','class_rle3','class_rle4']]!=''))\nprint('Total images:', len(train2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(2019)\nrn.seed(2019)\n\ntrain2 = train2.sample(frac=1).reset_index(drop=True)\ntrain2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# extract pixel positions and patch lengths - preprocessing before passing to Dataset\ndef convertEP(class_rle, idx):                       \n    array = np.asarray([int(x) for x in class_rle.split()])\n    starts = '' if len(array)==0 else \" \".join(map(str, array[0::2] + 1600*256*idx ))+ \" \"\n    lengths = '' if len(array)==0 else \" \".join(map(str, array[1::2]))+ \" \"\n\n    isPresent = '1' if len(starts)>0 else '0'\n    \n    return starts, lengths, isPresent","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"depth = 4\ntrain2['starts'], train2['lengths'] = \"\", \"\"\n\n# as many defect classes that many layers would have our output image\nfor idx in range(1,depth+1):\n    start, length, presence, class_rle = 'starts{}'.format(idx), 'lengths{}'.format(idx), \\\n                                         'isPresent{}'.format(idx), 'class_rle{}'.format(idx)    \n    train2[start], train2[length], train2[presence] = zip(*train2[class_rle].apply(convertEP, idx=idx-1))\n\n    train2['starts'] += train2[start]\n    train2['lengths'] += train2[length]\n    del train2[class_rle], train2[start], train2[length]    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Main dataset pipeline operations"},{"metadata":{"trusted":true},"cell_type":"code","source":"def rle_tf(mydf):\n    image_path, class_count, starts, lengths = mydf['ImageId'], mydf['count'], mydf['starts'], mydf['lengths']    \n    class_count = tf.strings.to_number(class_count, out_type=tf.dtypes.int32)                        \n    classes_one_hot = tf.strings.to_number([mydf['isPresent1'],mydf['isPresent2'],mydf['isPresent3'],mydf['isPresent4']], out_type=tf.dtypes.int32)\n\n    height, width, factor = 256, 1600, 2                \n    \n    def generate_mask():                 \n        starts_tensor = tf.strings.to_number( tf.strings.split([starts]).values, out_type=tf.dtypes.int32)\n        lengths_tensor = tf.strings.to_number( tf.strings.split([lengths]).values, out_type=tf.dtypes.int32)    \n\n        ranges = tf.ragged.range(starts_tensor, starts_tensor+lengths_tensor-1).values        \n        ranges = tf.expand_dims(ranges, axis=-1)        \n        \n        mask = tf.scatter_nd(ranges,\n                             tf.ones(tf.shape(ranges)[0], dtype=tf.dtypes.int16), \n                             tf.constant([width*height*depth]))                        \n\n        mask = tf.reshape(mask, [depth, width, height])  \n        mask = tf.transpose(mask, [2, 1, 0])\n        mask = tf.image.resize(mask, [height//factor, width//factor])        \n        mask = tf.dtypes.cast(mask, tf.dtypes.float32)        \n        \n        return mask                 \n    \n    def empty_mask():         \n        return tf.zeros((height//factor, width//factor, depth), dtype=tf.dtypes.float32)\n    \n    return image_path, tf.cond(tf.math.greater(class_count, 0), generate_mask, empty_mask), class_count, classes_one_hot\n    \ndef imag_proc_tf(image_path, mask, class_count, classes_one_hot):     \n    height, width, channels, factor = 256, 1600, 3, 2\n    \n    im = tf.io.read_file(im_path+image_path)\n    im = tf.image.decode_jpeg(im, channels=channels)    \n    im = tf.image.resize(im, [height//factor, width//factor])            \n    im = tf.dtypes.cast(im, tf.dtypes.int16)        \n    \n    return im, mask, class_count, classes_one_hot\n\n#https://www.wouterbulten.nl/blog/tech/data-augmentation-using-tensorflow-data-dataset/    \ndef augmentations(im, mask, class_count, classes_one_hot):    \n    im = tf.dtypes.cast(im, tf.dtypes.float32)        \n    \n    # rgb image only augmentations        \n    im = tf.image.random_brightness(im, 0.001)\n    im = tf.image.random_contrast(im, 0.7, 1.3)\n\n    images = tf.concat([im, mask], axis=-1)\n\n    # joint mask-image augmentations\n    images = tf.image.random_flip_left_right(images)\n    images = tf.image.random_flip_up_down(images)                        \n        \n    im = tf.dtypes.cast(tf.clip_by_value(images[:,:,:3], 0, 255), tf.dtypes.int16)\n    mask = tf.clip_by_value(images[:,:,3:], 0, 1)\n      \n    return im, mask, class_count, classes_one_hot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dataset pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_dataset(mydf, batch_size = 16, do_augment = False, filter_specific = None, isTrain = True):\n\n    dataset = tf.data.Dataset.from_tensor_slices(dict(mydf))\n    dataset = dataset.map(rle_tf, num_parallel_calls=tf.data.experimental.AUTOTUNE)            \n    dataset = dataset.map(imag_proc_tf, num_parallel_calls=tf.data.experimental.AUTOTUNE)         \n    \n    if do_augment:\n        dataset = dataset.map(augmentations, num_parallel_calls=tf.data.experimental.AUTOTUNE)                                   \n                   \n    if filter_specific is not None:\n        dataset = dataset.filter(lambda image, mask, class_count, cl1h: \n                                 tf.reshape( tf.reduce_all( tf.equal( cl1h, filter_specific)),[]))\n        \n    # image-110 part is a preprocessing required by the selected segmentation model\n    dataset = dataset.map(lambda image, mask, class_count, cl1h:\n                          (image-110, mask), num_parallel_calls=tf.data.experimental.AUTOTUNE)          \n    if isTrain:\n        dataset = dataset.shuffle(batch_size*10, reshuffle_each_iteration=True).batch(batch_size)\n    else:\n        dataset = dataset.batch(batch_size)\n    dataset = dataset.apply(tf.data.experimental.prefetch_to_device('/gpu:0'))  \n        \n    return dataset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test augmentation module"},{"metadata":{"trusted":true},"cell_type":"code","source":"im_path = os.path.join(base_path,'train_images/')\n\n# Repeat selected image with defect\nselected_image = train2[train2['count']=='1'].iloc[0:1]\ntest_df = pd.concat([selected_image]*16, ignore_index=True)\n\nminibatch = 16\nds = get_dataset(test_df, batch_size=minibatch, do_augment=True)\n\nfor images, masks in ds.take(1):\n    columns, rows = 1, minibatch\n    fig = plt.figure(figsize=(10,40))\n\n    for idx, (img, mask) in enumerate(zip(images.numpy(), masks.numpy())):    \n        fig.add_subplot(rows, columns, idx+1)        \n\n        img = (img+110).astype(int)            \n        emask = np.zeros(img.shape, dtype=int)  \n\n        for nc in range(depth):\n            if nc==0:\n                emask[mask[:,:,0]==1,0] = 255\n            elif nc==1:\n                emask[mask[:,:,1]==1,1] = 255        \n            elif nc==2:\n                emask[mask[:,:,2]==1,2] = 255        \n            elif nc==3:\n                emask[mask[:,:,3]==1,0] = 255        \n                emask[mask[:,:,3]==1,1] = 255        \n\n        plt.imshow(img)      \n        plt.imshow(emask, alpha=0.25)      ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get training and validation sets\ntotal_samples = len(train2)\nratio = 0.8\n\ntrain_df = train2.iloc[:int(ratio*total_samples)]\nvalid_df = train2.iloc[int(ratio*total_samples):]\n\ndel ds, test_df, train2\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_ds(tr_df, val_df, minibatch=32, filter_specific=None, do_augment=False):    \n    dstr = get_dataset(tr_df, batch_size=minibatch, filter_specific=filter_specific, isTrain=True, do_augment=do_augment)\n    dsva = get_dataset(val_df, batch_size=minibatch, filter_specific=filter_specific, isTrain=False, do_augment=False)    \n        \n    return dstr, dsva","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loss functions and metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef2(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\n#https://github.com/nabsabraham/focal-tversky-unet\ndef tversky(y_true, y_pred, smooth=1):\n    y_true_pos = K.flatten(y_true)\n    y_pred_pos = K.flatten(y_pred)\n    true_pos = K.sum(y_true_pos * y_pred_pos)\n    false_neg = K.sum(y_true_pos * (1-y_pred_pos))\n    false_pos = K.sum((1-y_true_pos)*y_pred_pos)\n    alpha = 0.7\n    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n\ndef tversky_loss(y_true, y_pred):\n    return 1 - tversky(y_true,y_pred)\n\ndef focal_tversky_loss_r(y_true,y_pred):\n    pt_1 = tversky(y_true, y_pred)\n    gamma = 0.75\n    return K.pow((1-pt_1), gamma)\n\n\n# https://github.com/nabsabraham/focal-tversky-unet/issues/3\ndef class_tversky(y_true, y_pred):\n    smooth = 1\n\n    y_true = K.permute_dimensions(y_true, (3,1,2,0))\n    y_pred = K.permute_dimensions(y_pred, (3,1,2,0))\n\n    y_true_pos = K.batch_flatten(y_true)\n    y_pred_pos = K.batch_flatten(y_pred)\n    true_pos = K.sum(y_true_pos * y_pred_pos, 1)\n    false_neg = K.sum(y_true_pos * (1-y_pred_pos), 1)\n    false_pos = K.sum((1-y_true_pos)*y_pred_pos, 1)\n    alpha = 0.7\n    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n\n# channels sensitive loss function\ndef focal_tversky_loss_c(y_true,y_pred):\n    pt_1 = class_tversky(y_true, y_pred)\n    gamma = 0.75\n    return K.sum(K.pow((1-pt_1), gamma))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_callbacks(model_name, val_metric='val_dice_coef2'):\n\n    RRc = ReduceLROnPlateau(monitor = val_metric, \n                            factor = 0.5, \n                            patience = 15, \n                            min_lr=0.000001, \n                            verbose=1, \n                            mode='max')\n\n    MCc = ModelCheckpoint(model_name,\n                          monitor=val_metric,\n                          save_best_only=True, \n                          verbose=1,                       \n                          mode='max')    \n    return [RRc, MCc]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Models training\nTwo models with different loss functions."},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"from segmentation_models import Unet\nmodel = Unet('resnet34', input_shape=(128, 800, 3), classes=depth, activation='sigmoid', encoder_weights='imagenet')\nmodel.save_weights('imagenet.h5')\n\nsettings = zip(['regular_ftl.h5', 'channeles_ftl.h5'],\n               [focal_tversky_loss_r, focal_tversky_loss_c])\n\nhist=[]\nfor model_name, loss_fcn in settings:    \n    opt = tf.keras.optimizers.Adam(0.0001,  clipnorm=1.0)\n    model.load_weights('imagenet.h5')\n    model.compile(optimizer=opt, loss=loss_fcn, metrics=[dice_coef2])    \n    \n    minibatch = 30\n    dstr, dsva = get_ds(tr_df=train_df, val_df=valid_df, minibatch=minibatch, do_augment=False)\n            \n    history = model.fit(dstr,                  \n                      epochs=60,\n                      verbose=2,\n                      validation_data=dsva,                   \n                      callbacks = get_callbacks(model_name))\n                        \n    hist.append(history)        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.plot(1+np.arange(len(hist[0].history['dice_coef2'])), hist[0].history['dice_coef2'], '-xr', label='train regular')\nplt.plot(1+np.arange(len(hist[0].history['val_dice_coef2'])), hist[0].history['val_dice_coef2'], '-b', label='valid regular')\nplt.plot(1+np.arange(len(hist[1].history['dice_coef2'])), hist[1].history['dice_coef2'], '-xk', label='train channels')\nplt.plot(1+np.arange(len(hist[1].history['val_dice_coef2'])), hist[1].history['val_dice_coef2'], '-m', label='valid channels')\nplt.ylabel('dice score [a.u.]')\nplt.xlabel('epoch [n]')\nplt.legend()\nplt.grid()\n\nprint('Best valid dice score regular: {0:.4f}'.format(max(hist[0].history['val_dice_coef2'])))\nprint('Best valid dice score channels: {0:.4f}'.format(max(hist[1].history['val_dice_coef2'])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's get configuration of defects within the validation set and make models evaluation with respect to them, applying proper filters."},{"metadata":{"trusted":true},"cell_type":"code","source":"minibatch = 4\nconfig_list = []\nfor gr, l in valid_df.groupby(['isPresent1','isPresent2','isPresent3','isPresent4']):\n    if len(l)>=minibatch:        \n        config_list.append([[int(c) for c in gr], len(l)])\n        print(*config_list[-1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Take a look if these two loss functions work differently with our imbalanced dataset:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import defaultdict\nscores = defaultdict(list)\n\nsettings = zip(['regular_ftl.h5', 'channeles_ftl.h5'],\n               [focal_tversky_loss_r, focal_tversky_loss_c])\n\nfor model_name, loss_fcn in settings: \n    print('\\n\\n')\n    model.load_weights(model_name)          \n    for cur_filt, quant in config_list:        \n        _, dsva = get_ds(tr_df=train_df, val_df=valid_df, minibatch=minibatch, filter_specific=cur_filt)\n        loss, dice = model.evaluate(dsva, verbose = 0)         \n        scores[model_name].append((cur_filt, dice, quant))\n        \n    print('\\nLoss:',loss_fcn.__name__)\n    scores[model_name] = sorted(scores[model_name], key=lambda x: x[2], reverse=True)\n    for cur_filt, dice, step in scores[model_name]:\n        print('Config: {0} (steps={1}) =>\\t dice_coef: {2:.5f}'.format(cur_filt, step, dice))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"settings = zip(['regular_ftl.h5', 'channeles_ftl.h5'],\n               [focal_tversky_loss_r, focal_tversky_loss_c],\n               ['.','x'])\nfig = plt.figure(figsize=(10,5))\n\nfor model_name, loss_fcn, marker in settings:     \n    x = [rec[2] for rec in scores[model_name]]\n    y = [rec[1] for rec in scores[model_name]]    \n    plt.semilogx(x,y, marker,  markersize=22, label = loss_fcn.__name__)\n    \nplt.ylabel('dice score [a.u.]')\nplt.xlabel('quantity [n]')\nplt.legend()\nplt.grid()    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}