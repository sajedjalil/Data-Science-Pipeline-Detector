{"cells":[{"metadata":{},"cell_type":"markdown","source":"The problem in this competition is to get a prediction on defects (masks) of 256x1600 top snapshot of steel surface images.\nDefects are of 4 class and as per my understading can be classfied roughly as cracking of steel\n1.  Multiple chips on the surface \n2.  Single Vertical crack\n3.  Multiple vertical cracks\n4.  Muliptle large surface patches\n\nMask is provided as a RLE (Encoded String)\n\nFormat is like below\n\n1234 3 1239 16\n\nThis means flatten image mask exists at index [1234:1234+3] [1239:1239+16]etc.\n\nNeed to decode the RLE to get the mask on the image\n\nThe notebook here trains array of 4 models, all custom unet \n(based on different loss function and atrous convs of different sized)\nEach of the model is shown a certain typeof defect and not shown all other\nFinal prediction is a combination of the prediction of each of the above model\n- > Note the submission is not complete yet.\n"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"# imports\nimport os \nimport numpy as np\nimport pandas as pd \nfrom mpl_toolkits.mplot3d import axes3d\nfrom tqdm import tqdm_notebook \nfrom mpl_toolkits.mplot3d import Axes3D\nfrom matplotlib.ticker import LinearLocator, FormatStrFormatter\nimport matplotlib.pyplot as plt\nimport cv2\nimport time\nimport seaborn as sns\nimport datetime\n\ndef timin():\n    ts = time.time()\n    st = str(datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S'))\n    print (st.replace(\" \",\"-\"))\ntimin()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On analysis we find that 7095 entries for RLE based encoded strings with roughly highest precentage of type 3 defect"},{"metadata":{"trusted":false},"cell_type":"code","source":"trainImgPath = \"/kaggle/input/severstal-steel-defect-detection/train_images/\"\ntrainCsv = \"/kaggle/input/severstal-steel-defect-detection/train.csv\"\ndfFull = pd.read_csv(trainCsv)\ndfFullEncodedOnly = dfFull[~dfFull['EncodedPixels'].isnull()]# get only image with labeled data for defects\nprint(dfFullEncodedOnly.shape)\nprint(dfFull.shape)\ntimin()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will try to visualize the original image after applying convolution matrices on top of the image to visualize the image post convolutions"},{"metadata":{"trusted":false},"cell_type":"code","source":"from skimage.io import imread\nfrom scipy.ndimage.filters import convolve\nemboss_kernel = np.array([  [0, 0, 0],\n                            [0, 0, 1],\n                            [0, 1, 1]])\n\nemboss_kernel1 = np.array([ [1, 1, 0],\n                            [1, 0, 0],\n                            [0, 0, 0]])\n                             \nedge_kernel = np.array([    [-1,-1,-1],\n                            [-1,4, -1],\n                            [-1, -1, -1]])\n\nhorizontal  = np.array([    [-1,-2,-1],\n                            [0, 0, 0],\n                            [1, 2, 1]])\n                             \nvertSobel = np.array([      [-1,0,1],\n                            [-2, 0, 2],\n                            [-1, 0, 1]])\n\nsharp = np.array([          [-1/9,-1/9,-1/9],\n                            [-1/9, 1, -1/9],\n                            [-1/9,-1/9, -1/9]])\n\nedgeexce = np.array([        [1,1,1],\n                            [1, -7, 1],\n                            [1,1, 1]])\n\nconfilter = np.zeros((3,3,3))\n\n\nmul = np.multiply(np.transpose(horizontal),np.transpose(vertSobel))\n\n# have fun convolving on different channels\ndef convolves(image_copy):\n    for i in range(0,3):\n        image_copy[:,:,i] = convolve(image_copy[:,:,i], edgeexce)\n        image_copy[:,:,i] = convolve(image_copy[:,:,i], edge_kernel)\n    return image_copy\n#x, y =next(getRandomBatch(4,validation_data=False))   \n#plt.figure(figsize=(35,10))\n#plt.imshow(x[0], cmap = 'Greys', interpolation = 'bicubic')\n#plt.figure(figsize=(35,10))\n#plt.imshow(y[0,:,:,0], cmap = 'Greys', interpolation = 'bicubic')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Contour identification on a colour range may give us some hints about the defect areas. "},{"metadata":{"trusted":false},"cell_type":"code","source":"import cv2 \nimport numpy as np \nfrom skimage.io import imread\ndef drawContours(image):\n    edged = cv2.Canny(image, 230, 240) \n    contours, hierarchy = cv2.findContours(edged, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) \n    cv2.drawContours(image, contours, -1, (0, 255, 0),1) \n    return image\nplt.figure(figsize=(35,10))\nplt.imshow(drawContours(cv2.imread(trainImgPath+\"0002cc93b.jpg\")), cmap = 'Greys', interpolation = 'bicubic')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is a utlity generator function that outputs a batch of images"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\nimport random\nimport threading\ntrainImgPath = \"/kaggle/input/severstal-steel-defect-detection/train_images/\"\ntrainCsv = \"/kaggle/input/severstal-steel-defect-detection/train.csv\"\ndf1 = pd.read_csv(trainCsv)\ndf2 = df1[~df1['EncodedPixels'].isnull()].head(7000)\ndf3 = df1[df1['EncodedPixels'].isnull()].head(200)\ndf1 = pd.concat([df2,df3])\ndf1['ImageId'] = df1['ImageId_ClassId'].apply(lambda s:s.split(\"_\")[0])\ndf1['Labels'] =  df1['ImageId_ClassId'].apply(lambda s:int(s.split(\"_\")[1]))\ndf1.sample(frac=1)\n\ngetmask  = lambda x: getMaskByClass(x.EncodedPixels, x.Labels)\ngetimage = lambda img: cv2.resize(cv2.imread(trainImgPath+img),(800,128))\n\ntimin()\nclass ThreadSafeDataGenerator:\n    def __init__(self, it):\n        self.it = it\n        self.lock = threading.Lock()\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        with self.lock:\n            return self.it.__next__()\n\ndef safeItrWrap(f):\n    def g(*a, **kw):\n        return ThreadSafeDataGenerator(f(*a, **kw))\n    return g\n\ndef getDataSlice(labelPassed,  batch_size1, validation_data):\n    df = df1.copy()\n    if labelPassed is not None:\n        df = df[df['Labels']==labelPassed]\n    if validation_data:\n        randIndex = int(random.randint(df.shape[0]//1.7,df.shape[0] - 70))\n        batch_size1=batch_size1*2\n    else:\n        randIndex = random.randint(0,df.shape[0]//1.5) \n    dfSlice = df.iloc[randIndex:randIndex+batch_size1].copy()\n    dfSlice.drop(columns=\"ImageId_ClassId\", inplace=True)\n    return dfSlice\n\ndef getMaskByClass(listEncodedString, listLabels):\n    mask = np.zeros((256, 1600, 4), dtype=np.int8)\n    for encodedString,labels in zip (listEncodedString, listLabels):\n        if len(str(encodedString))==0:\n            mask[:,:,labels-1] =  np.zeros((256, 1600), dtype=np.int16)\n        else:\n            encodedString = str(encodedString).split(\" \")\n            flatmask = np.zeros(1600*256, dtype=np.int8)\n            for i in range(0,len(encodedString)//2):\n                start = int(encodedString[2*i])\n                end = int(encodedString[2*i]) +int(encodedString[2*i+1])\n                flatmask[start:end-1] =  1\n            mask[:,:,labels-1] = np.transpose(flatmask.reshape(1600,256))\n    return mask\n\n@safeItrWrap\ndef getRandomBatch(labelPassed=None, batch_size1=24, validation_data=False):\n    while True:\n        dfSlice = getDataSlice(labelPassed,  batch_size1, validation_data)\n        dfAgg = dfSlice.groupby(['ImageId']).agg({'Labels':list, 'EncodedPixels':list}).reset_index()\n        dfAgg[\"EncodedPixels\"] = dfAgg.apply(getmask, axis=1)\n        dfAgg = dfAgg.head(batch_size1)\n        labels = np.array(dfAgg[\"EncodedPixels\"].tolist()).reshape(dfAgg.shape[0],256,1600,4)\n        data =  dfAgg.ImageId.apply(getimage)\n        data = np.array(data.tolist(), dtype=np.int16)\n        if labelPassed is not None:\n            yield data, labels[:,:,:,labelPassed-1].reshape(dfAgg.shape[0],256,1600,1)\n        else:\n            yield data, labels\n\n@safeItrWrap\ndef getRandomTestBatch( batch_size1=24):\n    testImgPath = \"/kaggle/input/severstal-steel-defect-detection/test_images/\"\n    k = os.listdir(testImgPath)\n    while True:\n        index = random.randint(0,len(k))\n        data =[]\n        for iimgh in k[index:index+batch_size1]:\n            p = cv2.resize(cv2.imread(testImgPath+iimgh),(800,128))\n            data.append(p)\n        yield np.array(data).reshape(batch_size1, 800,128,3)\n          \n            \n            \nx, y =next(getRandomBatch(1,validation_data=False))   \ntimin()\nplt.figure(figsize=(35,10))\nplt.imshow(x[0], cmap = 'Greys')\nplt.figure(figsize=(35,10))\nplt.imshow(y[0,:,:,0], cmap = 'Greys', interpolation = 'bicubic')\n#plt.figure(figsize=(35,10))\n#plt.imshow(y[0,:,:,1], cmap = 'Greys', interpolation = 'bicubic')\n#plt.figure(figsize=(35,10))\n#plt.imshow(y[0,:,:,2], cmap = 'Greys', interpolation = 'bicubic')\n#plt.figure(figsize=(35,10))\n#plt.imshow(y[0,:,:,3], cmap = 'Greys', interpolation = 'bicubic')\ntimin()\naug  =  ImageDataGenerator(\n\n                                             brightness_range=(0.8,1.2), \n                                            # shear_range=0.2, \n                                            # channel_shift_range=0.2, \n                                             fill_mode='nearest', \n                                            # cval=0.0, \n                                             horizontal_flip=True, \n                                            # vertical_flip=True, \n                                             rescale=1. / 255, \n                                         #    preprocessing_function=None, \n                                           #  data_format=None, \n                                           #  validation_split=0.0, \n                                             dtype=np.int16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from keras.losses import binary_crossentropy\nimport tensorflow as tf\nfrom keras import backend as K\n\ndef dice_coef(y_true, y_pred):\n    smooth = 1.\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2*intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef bce_dice_loss(y_true, y_pred):\n    return 2 * binary_crossentropy(y_true, y_pred) - dice_coef(y_true, y_pred)\n\ndef diff(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    return K.abs( K.sum( y_true_f-y_pred_f))\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input, Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D, Conv2D, Conv2DTranspose, LeakyReLU, UpSampling2D, concatenate, DepthwiseConv2D\nfrom keras import optimizers\nfrom keras.layers.normalization import BatchNormalization \nfrom keras.regularizers import l2\nfrom keras.layers import Lambda, Reshape, Add, AveragePooling2D, MaxPooling2D, Concatenate, SeparableConv2D\nfrom keras.initializers import RandomUniform\nconst1 = tf.convert_to_tensor (  np.full((16,128,800,24), 10) )\n\ndef antirectifier(x):\n    x = np.where(x[0,:,:,0]>0.5,1,0)\n    return x\n\ndef conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True, dilation_rate=(1,1)):\n    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n    # first layer\n    x = Conv2DTranspose(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n              kernel_initializer = RandomUniform(minval=-1.1, maxval=1.1, seed=4), padding = 'same', dilation_rate=dilation_rate, kernel_regularizer=l2(0.0003))(input_tensor)\n    if batchnorm:\n        x = BatchNormalization()(x)\n    x = Activation('tanh')(x)\n    \n    # second layer\n    \n    x =Conv2D(filters = n_filters, kernel_size = ( kernel_size, kernel_size),\\\n              kernel_initializer =  RandomUniform(minval=-1.2, maxval=1.2, seed=4), dilation_rate=dilation_rate, kernel_regularizer=l2(0.0003), padding = 'same')(input_tensor)\n    if batchnorm:\n        x = BatchNormalization()(x)\n    x = Activation('tanh')(x)\n    \n    return x\n\n\ndef get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True, dilation_rate=(1,1)):\n    # Contracting Path\n    c1 = conv2d_block(input_img, n_filters * 1, kernel_size =8, batchnorm = batchnorm, dilation_rate=dilation_rate)\n    p1 = AveragePooling2D((2, 2))(c1)\n    p1 = Dropout(dropout)(p1)\n    \n    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 4, batchnorm = batchnorm)\n    p2 = AveragePooling2D((2, 2))(c2)\n    p2 = Dropout(dropout)(p2)\n    \n    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 2, batchnorm = batchnorm)\n    p3 = MaxPooling2D((2, 2))(c3)\n    p3 = Dropout(dropout)(p3)\n    \n   \n    c5 = conv2d_block(p3, n_filters = n_filters * 16, kernel_size = 2, batchnorm = batchnorm)\n    \n    # Expansive Path\n   \n    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c5)\n    u7 = concatenate([u7, c3])\n    u7 = Dropout(dropout)(u7)\n    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 2, batchnorm = batchnorm)\n    \n    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n    u8 = concatenate([u8, c2])\n    u8 = Dropout(dropout)(u8)\n    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 4, batchnorm = batchnorm)\n    \n    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n    u9 = concatenate([u9, c1])\n    u9 = Dropout(dropout)(u9)\n    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 8, batchnorm = batchnorm)\n    \n    u10 = UpSampling2D()(c9)\n   # cl1 = Lambda(antirectifier)(u10)\n\n\n    outputs = Conv2D(1, (1, 1), activation='sigmoid')(u10)\n    model = Model(inputs=[input_img], outputs=[outputs])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\nfrom keras.layers import Dense, Activation, Conv2D, Input\nfrom keras.layers.normalization import BatchNormalization as BN\nfrom keras.optimizers import Adam\nfrom keras import layers\nimport tensorflow as tf\nimport os\nimport datetime\nfrom tensorflow.keras.metrics import TruePositives, TrueNegatives\nimport time\nimport gc\ngc.collect()\nfrom tensorflow import set_random_seed\nset_random_seed(7)\nepoches = 20\ndilation_rate=(1,1)\nlearning_rate = 0.005\nsep = 16 \nvs = 24\n\nfrom keras.models import load_model\nimport numpy as np\nimport pandas as pd\nif (True):\n    timin()\n    model1 = load_model('../input/noaugs/model1111.h5',custom_objects={'diff': diff})\n    timin()\n    model2 = load_model('../input/noaugs/model2111.h5',custom_objects={'diff': diff})\n    timin()\n    model3 = load_model('../input/noaugs/model3111.h5',custom_objects={'diff': diff})\n    timin()\n    model4 = load_model('../input/noaugs/model4111.h5',custom_objects={'diff': diff})    \n    timin()\n\n\nif(False):\n    model1 = get_unet(Input(shape=(128, 800, 3),dtype='float32'),dilation_rate=(2,2))\n    model1.compile(optimizer=Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), \n                   loss='binary_crossentropy', \n                   metrics=[diff,'binary_accuracy'])\n\n\n    model2 = get_unet(Input(shape=(128, 800, 3)),dilation_rate=(2,2))\n    model2.compile(optimizer=Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), \n                   loss='binary_crossentropy', \n                   metrics=[diff,'binary_accuracy'])\n    \n    model3 = get_unet(Input(shape=(128, 800, 3)),  dilation_rate=dilation_rate)\n    model3.compile(optimizer=Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), \n                   loss='binary_crossentropy', \n                   metrics=[diff,'binary_accuracy'])\n\n    model4 = get_unet(Input(shape=(128, 800, 3)), dilation_rate=(5,5))\n    model4.compile(optimizer=Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), \n                   loss='binary_crossentropy', \n                   metrics=[diff,'binary_accuracy'])\n\n\nif(False):\n    ts = time.time()\n    st = str(datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S'))\n    print (st.replace(\" \",\"-\"))\n\n    history1 = model1.fit_generator(aug.flow(next(getRandomBatch(1,validation_data=False)), batch_size = 24),\n                                    steps_per_epoch=sep, \n                                    epochs=epoches*1, \n                                    verbose=1, callbacks=None, \n                                    validation_data=getRandomBatch(1, validation_data=True),\n                                    validation_steps=vs,  \n                                    workers=4)\n    ts = time.time()\n    st = str(datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S'))\n    print (st.replace(\" \",\"-\"))\n\n    history2 = model2.fit_generator(aug.flow(next(getRandomBatch(2,validation_data=False)), batch_size = 16),\n                                    steps_per_epoch=sep, \n                                    epochs=epoches*1, \n                                    verbose=0, callbacks=None, \n                                    validation_data=getRandomBatch(2, validation_data=True),\n                                    validation_steps=vs,  \n                                    workers=4)\n    ts = time.time()\n    st = str(datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S'))\n    print (st.replace(\" \",\"-\"))\n\n    history3 = model3.fit_generator(aug.flow(next(getRandomBatch(3,validation_data=False)), batch_size = 16),\n                                    steps_per_epoch=sep, \n                                    epochs=epoches*4, \n                                    verbose=0, callbacks=None, \n                                    validation_data=getRandomBatch(3, validation_data=True),\n                                    validation_steps=vs*2,  \n                                    workers=4)\n    ts = time.time()\n    st = str(datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S'))\n    print (st.replace(\" \",\"-\"))\n\n    history4 = model4.fit_generator(aug.flow(next(getRandomBatch(4,validation_data=False)), batch_size = 16),\n                                    steps_per_epoch=sep, \n                                    epochs=epoches*2, \n                                    verbose=0, callbacks=None, \n                                    validation_data=getRandomBatch(4, validation_data=True),\n                                    validation_steps=vs,  \n                                    workers=4)\n    ts = time.time()\n    st = str(datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S'))\n    print (st.replace(\" \",\"-\"))\nif (False):\n    model1.save(\"model1111.h5\")\n    model2.save(\"model2111.h5\")\n    model3.save(\"model3111.h5\")\n    model4.save(\"model4111.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import random\nimport cv2\nimport numpy as np\nimport urllib.request\nimport os\nsubmission =  pd.read_csv(\"/kaggle/input/severstal-steel-defect-detection/sample_submission.csv\")\ntestImgPath = \"/kaggle/input/severstal-steel-defect-detection/test_images/\"\nk = os.listdir(testImgPath)\n\ni =0 \n\nmodels = [model1,model2,model3,model4]\nlabels = [\"1\",\"2\",\"3\",\"4\"]\nlabelsInt = [1,2,3,4]\nresults = []\n\ndef mask2rle(img):\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef getResults(x, image,models):\n    inputImg = np.array(cv2.resize(cv2.imread(testImgPath+image),(800,128))).reshape(128, 800, 3).reshape(1, 128, 800, 3)\n    prediction = models[x-1].predict(inputImg,batch_size=None, verbose=0, steps=None)\n    return  np.where(cv2.blur(cv2.blur(prediction[0,:,:,0],(5,5)),(5,5))>0.9991,1,0)\n\ndef getResult(image):\n    return [getResults( x, image, models) for x in labelsInt]\n    \n\nfor image in k:\n    results =  getResult(image)\n    i = i +1\n    for l,r in zip(labels, results):\n        if (len(r))>0:\n            submission.loc[submission['ImageId_ClassId']==image+\"_\"+l,[\"EncodedPixels\"]] =  mask2rle(r).strip()\n    if (i%50==0):\n        print(\"done\",i)\n\n       \n\nsubmission.to_csv(\"submission.csv\",index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"img = cv2.imread(testImgPath+k[0]) \nprint(np.array(img).shape)\nx, y =next(getRandomBatch(3,validation_data=False))   \nprint(x[0].shape)\ncv2.line(x[0],(0,64),(800,64),(255,255,255),5)\ncv2.line(x[0],(400,0),(400,128),(255,255,255),5)\ncv2.line(x[0],(0,84),(800,84),(0,0,0),5)\ncv2.line(x[0],(600,0),(600,128),(0,0,0),5)\npredict = model1.predict(x,batch_size=None, verbose=0, steps=None)\npredict2 = model2.predict(x,batch_size=None, verbose=0, steps=None)\npredict3 = model3.predict(x,batch_size=None, verbose=0, steps=None)\npredict4 = model4.predict(x,batch_size=None, verbose=0, steps=None)\nplt.figure(figsize=(35,10))\nplt.imshow(x[0], cmap = 'Greys', interpolation = 'bicubic')\nplt.figure(figsize=(35,10))\nplt.imshow(y[0,:,:,0], cmap = 'Greys', interpolation = 'bicubic')\nplt.figure(figsize=(35,10))\nplt.imshow(predict[0,:,:,0], cmap = 'Greys', interpolation = 'bicubic')\nplt.figure(figsize=(35,10))\nplt.imshow(predict4[0,:,:,0], cmap = 'Greys', interpolation = 'bicubic')\nplt.figure(figsize=(35,10))\nplt.imshow(predict2[0,:,:,0], cmap = 'Greys', interpolation = 'bicubic')\nplt.figure(figsize=(35,10))\nplt.imshow(predict3[0,:,:,0], cmap = 'Greys', interpolation = 'bicubic')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#clss = [1,2,3,4]\n#modelss = [model1,model2,model3,model4]\n#for m in modelss:\n#    for c in clss:\n#        print(\"Evaluate for model\",c, m)\n#        print(m.evaluate_generator(getRandomBatch(c,validation_data=False), steps=16,   verbose=1))\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}