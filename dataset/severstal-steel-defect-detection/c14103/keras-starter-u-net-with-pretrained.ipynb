{"cells":[{"metadata":{},"cell_type":"markdown","source":"Simple example of U-net for segmentation in Keras"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nfrom tqdm import tqdm_notebook\nimport cv2\n\nimport keras\nfrom keras.applications.vgg19 import VGG19\nfrom keras.layers.convolutional import Conv2DTranspose\nfrom keras.layers.merge import concatenate\nfrom keras.layers import UpSampling2D, Conv2D, Activation, Input, Dropout, MaxPooling2D\nfrom keras import layers\nfrom keras import Model\nfrom keras import backend as K\nfrom keras.layers.core import Lambda","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = VGG19(weights='imagenet', include_top=False)\n \nfor layer in model.layers:\n    print(layer)\n\nmodel.save(\"severstal_vgg19.h5\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Load_vgg19(img_input):\n    #block 1\n    x = layers.Conv2D(64, (3, 3),\n                      activation='relu',\n                      padding='same',\n                      name='block1_conv1')(img_input)\n    x = layers.Conv2D(64, (3, 3),\n                      activation='relu',\n                      padding='same',\n                      name='block1_conv2')(x)\n    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n    #block 2\n    x = layers.Conv2D(128, (3, 3),\n                      activation='relu',\n                      padding='same',\n                      name='block2_conv1')(x)\n    x = layers.Conv2D(128, (3, 3),\n                      activation='relu',\n                      padding='same',\n                      name='block2_conv2')(x)\n    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n\n    #block 3\n    x = layers.Conv2D(256, (3, 3),\n                      activation='relu',\n                      padding='same',\n                      name='block3_conv1')(x)\n    x = layers.Conv2D(256, (3, 3),\n                      activation='relu',\n                      padding='same',\n                      name='block3_conv2')(x)\n    x = layers.Conv2D(256, (3, 3),\n                      activation='relu',\n                      padding='same',\n                      name='block3_conv3')(x)\n    \n    x = layers.Conv2D(256, (3, 3),\n                          activation='relu',\n                          padding='same',\n                          name='block3_conv4')(x)\n    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n\n    #block 4\n    x = layers.Conv2D(512, (3, 3),\n                      activation='relu',\n                      padding='same',\n                      name='block4_conv1')(x)\n    x = layers.Conv2D(512, (3, 3),\n                      activation='relu',\n                      padding='same',\n                      name='block4_conv2')(x)\n    x = layers.Conv2D(512, (3, 3),\n                      activation='relu',\n                      padding='same',\n                      name='block4_conv3')(x)\n   \n    x = layers.Conv2D(512, (3, 3),\n                          activation='relu',\n                          padding='same',\n                          name='block4_conv4')(x)\n    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n\n    #block 5\n    x = layers.Conv2D(512, (3, 3),\n                      activation='relu',\n                      padding='same',\n                      name='block5_conv1')(x)\n    x = layers.Conv2D(512, (3, 3),\n                      activation='relu',\n                      padding='same',\n                      name='block5_conv2')(x)\n    x = layers.Conv2D(512, (3, 3),\n                      activation='relu',\n                      padding='same',\n                      name='block5_conv3')(x)\n  \n    x = layers.Conv2D(512, (3, 3),\n                          activation='relu',\n                          padding='same',\n                          name='block5_conv4')(x)\n    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n\n    model = Model(inputs=[img_input], outputs=x)\n\n    # Load pretrained\n    pretrained_model = VGG19(include_top=False)\n\n    for layer, pretrained_layer in zip(\n            model.layers[2:], pretrained_model.layers[2:]):\n        layer.set_weights(pretrained_layer.get_weights())\n        \n    imagenet_weights = pretrained_model.layers[1].get_weights()\n    init_bias = imagenet_weights[1]\n    init_kernel = np.average(imagenet_weights[0], axis=2)\n    #print(init_kernel.shape)\n    init_kernel = np.reshape(\n        init_kernel,\n        (init_kernel.shape[0],\n            init_kernel.shape[1],\n            1,\n            init_kernel.shape[2]))\n    init_kernel = np.dstack([init_kernel] * img_input.shape.as_list()[-1])  # input image is grayscale\n    model.layers[1].set_weights([init_kernel, init_bias])\n    return model\n\n\nif 1:\n    img = layers.Input(shape=(128, 128, 4))\n    pretrained = Load_vgg19(img)\n    for layer in pretrained.layers:\n        print(layer.name, pretrained.get_layer(layer.name))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr = pd.read_csv('../input/train.csv')\nprint(len(tr))\ntr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_train = tr[tr['EncodedPixels'].notnull()].reset_index(drop=True)\n#print(len(df_train))\ndf_train = tr\ndf_train['ImageId'], df_train['ClassId'] = zip(*df_train['ImageId_ClassId'].str.split('_')) #split imageId and classId\ndf_train['ClassId'] = df_train['ClassId'].astype(int)\ndf_train = df_train.pivot(index='ImageId',columns='ClassId',values='EncodedPixels') #remap\ndf_train['defects'] = df_train.count(axis=1) #count on defect type\ndf_train = df_train[df_train['defects'] > 0]\nprint(len(df_train))\ndf_train.head()\n#print(df_train.iloc[6666-1].name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rle2mask(rle, imgshape):\n    width = imgshape[0]\n    height= imgshape[1]\n    \n    mask= np.zeros( width*height ).astype(np.uint8)\n    if rle is not np.nan:\n        array = np.asarray([int(x) for x in rle.split()])\n        starts = array[0::2]\n        lengths = array[1::2]\n\n        current_position = 0\n        for index, start in enumerate(starts):\n            mask[int(start):int(start+lengths[index])] = 1\n            current_position += lengths[index]\n        \n    return np.flipud( np.rot90( mask.reshape(height, width), k=1 ) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_scale = 2\nimg_size = (1600 // img_scale,256 // img_scale)\nclasses_num = 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#contrast enhancing\n\ndo_enhance = True\n\ngamma = 1.2\ninverse_gamma = 1.0 / gamma\nlook_up_table = np.array([((i/255.0) ** inverse_gamma) * 255.0 for i in np.arange(0,256,1)]).astype(\"uint8\")\nclahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n\ndef contrast_enhancement(img):\n    if not do_enhance:\n        return img\n    img = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n    img[:,:,0] = clahe.apply(img[:,:,0])\n    img = cv2.cvtColor(img, cv2.COLOR_YUV2RGB)\n    return img\n\ndef gamma_correction(img):\n    if not do_enhance:\n        return img\n    return cv2.LUT(img.astype('uint8'), look_up_table)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\ndef keras_generator(batch_size):\n    while True:\n        x_batch = []\n        y_batch = []\n        \n        for i in range(batch_size): \n            flip = int(100)\n            if random.uniform(0,1) > 0.5:\n                flip = random.randint(-1,1)\n            #print(flip)\n                \n            \n            fn = df_train.iloc[i].name\n            img = cv2.imread( '../input/train_images/'+fn )\n            #plt.subplot(3,1,1)\n            #plt.imshow(img)\n            img = gamma_correction(img)\n            #plt.subplot(3,1,2)\n            #plt.imshow(img)\n            img = contrast_enhancement(img)\n            #plt.subplot(3,1,3)\n            #plt.imshow(img)\n            #break\n            #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)     \n            #mask_gt = np.zeros( shape = img.shape[0:2] ).astype(np.uint8) + 1\n            #mask_gt = cv2.resize(mask_gt, img_size,cv2.INTER_NEAREST)\n            #if flip != 100:\n            #    mask_gt = cv2.flip(mask_gt,flip)\n            #mask_gt = np.expand_dims(mask_gt,-1) #background\n            #masks = [mask_gt]\n            masks = []\n            for cls in range(0,classes_num):\n                mask = rle2mask(df_train[cls+1].iloc[i], img.shape)\n                mask = np.squeeze(mask)\n                mask = cv2.resize(mask, img_size,cv2.INTER_NEAREST)\n                if flip != 100:\n                    mask = cv2.flip(mask,flip)\n                mask = np.expand_dims(mask,-1)\n               # mask_gt[mask != 0] = 0 #move pixel from gt\n                masks.append(mask)\n\n            mask = np.concatenate(masks,axis=-1)\n            img = cv2.resize(img, img_size,cv2.INTER_AREA)\n            if flip != 100:\n                img = cv2.flip(img,flip)\n            x_batch += [img]\n            y_batch += [mask]\n                                    \n        x_batch = np.array(x_batch) / 255.0\n        y_batch = np.array(y_batch)\n\n        #yield x_batch, np.expand_dims(y_batch, -1)\n        yield x_batch, y_batch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x, y in keras_generator(4):\n    break\n    \nprint(x.shape, y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_image_id = 3\nplt.subplot(classes_num+1,1,1)\nplt.imshow(x[test_image_id])\nfor k in range(classes_num):\n    plt.subplot(classes_num+1,1,k+2)\n    plt.imshow(np.squeeze(y[test_image_id,:,:,k]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def segment_cross_entropy(features, labels):\n    features = K.softmax(features, axis=1)\n    features = K.reshape(features,[-1])\n    labels = K.reshape(labels,[-1])\n    return K.categorical_crossentropy(labels, features, axis=-1)\n        \n#true_dist, coding_dist = np.ones((4,5,6,6))/2, np.ones((4,5,6,6))/2\n#loss = segment_cross_entropy(coding_dist, coding_dist)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model\ndef get_net_raw(img_size,classes_num):\n    inputs = Input((img_size[1], img_size[0], 3))\n    #s = Lambda(lambda x: x / 255) (inputs)\n\n    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (inputs)\n    c1 = Dropout(0.1) (c1)\n    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n    p1 = MaxPooling2D((2, 2)) (c1)\n\n    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n    c2 = Dropout(0.1) (c2)\n    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n    p2 = MaxPooling2D((2, 2)) (c2)\n\n    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n    c3 = Dropout(0.2) (c3)\n    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n    p3 = MaxPooling2D((2, 2)) (c3)\n\n    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n    c4 = Dropout(0.2) (c4)\n    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\n    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n    c5 = Dropout(0.3) (c5)\n    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n\n    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n    u6 = concatenate([u6, c4])\n    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n    c6 = Dropout(0.2) (c6)\n    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n\n    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n    u7 = concatenate([u7, c3])\n    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n    c7 = Dropout(0.2) (c7)\n    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n\n    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n    u8 = concatenate([u8, c2])\n    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n    c8 = Dropout(0.1) (c8)\n    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n\n    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n    u9 = concatenate([u9, c1], axis=3)\n    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n    c9 = Dropout(0.1) (c9)\n    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n\n    #outputs = Conv2D(4, (1, 1), activation='sigmoid') (c9)\n    outputs = Conv2D(classes_num,(1,1),activation = 'sigmoid')(c9)  #todos: try softmax\n\n    model = Model(inputs=[inputs], outputs=[outputs])\n    #model.compile(optimizer='adam', loss='binary_crossentropy')\n    #model.compile(optimizer='adam',loss='categorical_crossentropy')\n    return model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model\nfrom keras import optimizers\ndef get_net_pretrained(img_size,classes_num):\n    layers_feat = 'block1_conv2,block2_conv2,block3_conv4,block4_conv4,block5_conv4'.split(',')\n    \n    inputs = Input((img_size[1], img_size[0], 3))\n    #s = Lambda(lambda x: x / 255) (inputs)\n    pretrained = Load_vgg19(inputs)\n    for layer in pretrained.layers:\n        layer.trainable=False #freeze\n    c1 = pretrained.get_layer(layers_feat[0]).output #1x\n    c2 = pretrained.get_layer(layers_feat[1]).output #2x\n    c3 = pretrained.get_layer(layers_feat[2]).output #4x\n    c4 = pretrained.get_layer(layers_feat[3]).output #8x\n    c5 = pretrained.get_layer(layers_feat[4]).output #16x\n    c5 = Dropout(0.3) (c5)\n    \n    #decoder\n    u6 = Conv2DTranspose(128*2, (2, 2), strides=(2, 2), padding='same') (c5) #8x\n    u6 = concatenate([u6, c4])\n    c6 = Conv2D(128*2, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n    c6 = Dropout(0.2) (c6)\n    c6 = Conv2D(128*2, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n\n    u7 = Conv2DTranspose(64*2, (2, 2), strides=(2, 2), padding='same') (c6) #4x\n    u7 = concatenate([u7, c3])\n    c7 = Conv2D(64*2, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n    c7 = Dropout(0.2) (c7)\n    c7 = Conv2D(64*2, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n\n    u8 = Conv2DTranspose(32*2, (2, 2), strides=(2, 2), padding='same') (c7) #2x\n    u8 = concatenate([u8, c2])\n    c8 = Conv2D(32*2, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n    c8 = Dropout(0.1) (c8)\n    c8 = Conv2D(32*2, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n\n    u9 = Conv2DTranspose(16*2, (2, 2), strides=(2, 2), padding='same') (c8) #1x\n    u9 = concatenate([u9, c1], axis=3)\n    c9 = Conv2D(16*2, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n    c9 = Dropout(0.1) (c9)\n    c9 = Conv2D(16*2, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n\n    #outputs = Conv2D(4, (1, 1), activation='sigmoid') (c9)\n    outputs = Conv2D(classes_num,(1,1),activation = 'sigmoid')(c9)  #todos: try softmax\n\n    model = Model(inputs=[inputs], outputs=[outputs])\n\n    #model.compile(optimizer='adam', loss='binary_crossentropy')\n    #model.compile(optimizer='adam',loss='categorical_crossentropy')\n    return model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = get_net_pretrained(img_size,classes_num)\nsgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\nmodel.compile(optimizer=sgd, loss='binary_crossentropy')\nfor layer in model.layers:\n    print(layer.name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n# Fit model\nbatch_size = 32\nresults = model.fit_generator(keras_generator(batch_size), \n                              steps_per_epoch=100,\n                              epochs=1) \n\nmodel.save(\"severstal_s4.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(x)\nprint(pred.shape,)\nplt.imshow(np.squeeze(pred[3,:,:,3]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testfiles=os.listdir(\"../input/test_images/\")\nlen(testfiles)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nif 0:\n    import gc\n    #del pred\n    #del x\n    gc.collect()\n\n    test_img = []\n    for fn in tqdm_notebook(testfiles):\n            img = cv2.imread( '../input/test_images/'+fn )\n            img = cv2.resize(img,img_size)       \n            test_img.append(img)\n\n    print(len(test_img))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nif 0:\n    predict = model.predict(np.asarray(test_img))\n    print(len(predict)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndef mask2rle(img):\n    tmp = np.rot90( np.flipud( img ), k=3 )\n    rle = []\n    lastColor = 0;\n    startpos = 0\n    endpos = 0\n\n    tmp = tmp.reshape(-1,)   \n    inds = np.argwhere(tmp == 1)\n    if len(inds) == 0:\n        return ' '.join([])\n    inds = list(map(lambda x: x[0], inds))\n    last = inds[0]\n   # pdb.set_trace()\n    for k in range(1,len(inds)):\n        if inds[k] == inds[k-1] + 1:\n            continue\n        rle.append( str(last)+' '+str(inds[k-1]-last+1) )\n        last = inds[k]\n    return \" \".join(rle)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nimport pdb\nthresh_score = 0.8\nthresh_num = 3500\npred_rle = []\n\ntest_img = []\nfor fn in tqdm_notebook(testfiles):\n        img = cv2.imread( '../input/test_images/'+fn )\n        img = gamma_correction(img)\n        img = contrast_enhancement(img)\n        img = cv2.resize(img,img_size)       \n        #test_img.append(img)   \n        scores = model.predict(np.asarray([img]))\n        scores = np.squeeze(scores)\n        pred = np.argmax(scores,axis=-1)\n        #print(scores.shape)\n        for cls in range(0, classes_num):\n            mask = np.squeeze(pred == cls).astype(np.uint8)\n            score = scores[:,:,cls]\n            #print(mask.shape,'---')\n            mask[score < thresh_score] = 0\n            if np.sum(mask) < thresh_num:\n                mask = mask * 0\n            mask = cv2.resize(mask, (1600, 256), cv2.INTER_NEAREST)\n            rle = mask2rle(mask)\n            #print(rle)\n            pred_rle.append(rle)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nif 0:\n    import pdb\n    thresh_score = 0.8\n    thresh_num = 100\n    pred_rle = []\n    for fn, scores in enumerate(tqdm_notebook(predict)):  \n        pred = np.argmax(scores,axis=-1)\n        for cls in range(0, classes_num):\n            mask = np.squeeze(pred == cls).astype(np.uint8)\n            score = scores[:,:,cls]\n            mask[score < thresh_score] = 0\n            if np.sum(mask) < thresh_num:\n                mask = mask * 0\n            mask = cv2.resize(mask, (1600, 256), cv2.INTER_NEAREST)\n            rle = mask2rle(mask)\n            #print(rle)\n            pred_rle.append(rle)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_image_ind = 5\nimg_t = cv2.imread( '../input/test_images/'+ testfiles[test_image_ind])\nplt.subplot(classes_num+1,1,1)\nplt.imshow(img_t)\n\nfor cls in range(classes_num):\n    mask_t = rle2mask(pred_rle[test_image_ind*4 + cls], img_t.shape)\n    plt.subplot(classes_num+1,1,cls + 2)\n    plt.imshow(mask_t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv( '../input/sample_submission.csv' )\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nprint(len(pred_rle)/4)\nfor fn_ind,fn in enumerate(testfiles):\n    for cls in range(0, classes_num):\n       # if fn_ind == 4 and cls == 4:\n       #     idx = sub['ImageId_ClassId'] == \"{}_{}\".format(fn,cls)\n       #     print(sub['EncodedPixels'][idx])\n       #     print(fn)\n        sub['EncodedPixels'][sub['ImageId_ClassId'] == \"{}_{}\".format(fn,cls+1)] = pred_rle[fn_ind * 4 + cls]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_s = cv2.imread( '../input/test_images/'+ sub['ImageId_ClassId'][4].split('_')[0])\nplt.imshow(img_s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}