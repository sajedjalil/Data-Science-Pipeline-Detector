{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Reference:**\n\nhttps://www.kaggle.com/go1dfish/clear-mask-visualization-and-simple-eda\n\nhttps://www.kaggle.com/titericz/building-and-visualizing-masks\n\nhttps://www.kaggle.com/cdeotte/keras-unet-with-eda"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"pd.set_option(\"display.max_rows\", 101)\nimport cv2\nimport json\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.rcParams[\"font.size\"] = 15\nimport seaborn as sns\nfrom collections import Counter\nfrom PIL import Image\nimport math\nimport seaborn as sns\nfrom collections import defaultdict\nfrom pathlib import Path\nimport cv2\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/train.csv\")\nsample_df = pd.read_csv(\"../input/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check number of each class\n\nclass_dict = defaultdict(int)\n\nkind_class_dict = defaultdict(int)\n\nno_defects_num = 0\ndefects_num = 0\n\nfor col in range(0, len(train_df), 4):\n    img_names = [str(i).split(\"_\")[0] for i in train_df.iloc[col:col+4, 0].values]\n    if not (img_names[0] == img_names[1] == img_names[2] == img_names[3]):\n        raise ValueError\n        \n    labels = train_df.iloc[col:col+4, 1]\n    if labels.isna().all():\n        no_defects_num += 1\n    else:\n        defects_num += 1\n    \n    kind_class_dict[sum(labels.isna().values == False)] += 1\n        \n    for idx, label in enumerate(labels.isna().values.tolist()):\n        if label == False:\n            class_dict[idx+1] += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"the number of images with no defects: {}\".format(no_defects_num))\nprint(\"the number of images with defects: {}\".format(defects_num))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nsns.barplot(x=list(class_dict.keys()), y=list(class_dict.values()), ax=ax)\nax.set_title(\"the number of images for each class\")\nax.set_xlabel(\"class\")\nclass_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nsns.barplot(x=list(kind_class_dict.keys()), y=list(kind_class_dict.values()), ax=ax)\nax.set_title(\"Number of classes included in each image\");\nax.set_xlabel(\"number of classes in the image\")\nkind_class_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size_dict = defaultdict(int)\ntrain_path = Path(\"../input/train_images/\")\n\nfor img_name in train_path.iterdir():\n    img = Image.open(img_name)\n    train_size_dict[img.size] += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_size_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_size_dict = defaultdict(int)\ntest_path = Path(\"../input/test_images/\")\n\nfor img_name in test_path.iterdir():\n    img = Image.open(img_name)\n    test_size_dict[img.size] += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_size_dict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualization Masks**"},{"metadata":{"trusted":true},"cell_type":"code","source":"palet = [(249, 192, 12), (0, 185, 241), (114, 0, 218), (249,50,12)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def name_and_mask(start_idx):\n    col = start_idx\n    img_names = [str(i).split(\"_\")[0] for i in train_df.iloc[col:col+4, 0].values]\n    if not (img_names[0] == img_names[1] == img_names[2] == img_names[3]):\n        raise ValueError\n\n    labels = train_df.iloc[col:col+4, 1]\n    mask = np.zeros((256, 1600, 4), dtype=np.uint8)\n\n    for idx, label in enumerate(labels.values):\n        if label is not np.nan:\n            mask_label = np.zeros(1600*256, dtype=np.uint8)\n            label = label.split(\" \")\n            positions = map(int, label[0::2])\n            length = map(int, label[1::2])\n            for pos, le in zip(positions, length):\n                mask_label[pos:(pos+le)] = 1\n            mask[:, :, idx] = mask_label.reshape(256, 1600, order='F')\n    return img_names[0], mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_mask_image(col):\n    name, mask = name_and_mask(col)\n    img = cv2.imread(str(train_path / name))\n    fig, ax = plt.subplots(figsize=(15, 15))\n\n    for ch in range(4):\n        contours, _ = cv2.findContours(mask[:, :, ch], cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n        for i in range(0, len(contours)):\n            cv2.polylines(img, contours[i], True, palet[ch], 2)\n    ax.set_title(name)\n    ax.imshow(img)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 4, figsize=(15, 5))\nfor i in range(4):\n    ax[i].axis('off')\n    ax[i].imshow(np.ones((50, 50, 3), dtype=np.uint8) * palet[i])\n    ax[i].set_title(\"class color: {}\".format(i+1))\nfig.suptitle(\"each class colors\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx_no_defect = []\nidx_class_1 = []\nidx_class_2 = []\nidx_class_3 = []\nidx_class_4 = []\nidx_class_multi = []\nidx_class_triple = []\n\nfor col in range(0, len(train_df), 4):\n    img_names = [str(i).split(\"_\")[0] for i in train_df.iloc[col:col+4, 0].values]\n    if not (img_names[0] == img_names[1] == img_names[2] == img_names[3]):\n        raise ValueError\n        \n    labels = train_df.iloc[col:col+4, 1]\n    if labels.isna().all():\n        idx_no_defect.append(col)\n    elif (labels.isna() == [False, True, True, True]).all():\n        idx_class_1.append(col)\n    elif (labels.isna() == [True, False, True, True]).all():\n        idx_class_2.append(col)\n    elif (labels.isna() == [True, True, False, True]).all():\n        idx_class_3.append(col)\n    elif (labels.isna() == [True, True, True, False]).all():\n        idx_class_4.append(col)\n    elif labels.isna().sum() == 1:\n        idx_class_triple.append(col)\n    else:\n        idx_class_multi.append(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx in idx_no_defect[:5]:\n    show_mask_image(idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx in idx_class_1[:5]:\n    show_mask_image(idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx in idx_class_2[:5]:\n    show_mask_image(idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx in idx_class_3[:5]:\n    show_mask_image(idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx in idx_class_4[:5]:\n    show_mask_image(idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx in idx_class_multi[:5]:\n    show_mask_image(idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx in idx_class_triple:\n    show_mask_image(idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in tqdm(range(0, len(train_df), 4)):\n    name, mask = name_and_mask(col)\n    if (mask.sum(axis=2) >= 2).any():\n        show_mask_image(idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df[ train_df['EncodedPixels'].notnull() ]\nprint( train_df.shape )\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rle2mask(rle, imgshape):\n    width = imgshape[0]\n    height= imgshape[1]\n    \n    mask= np.zeros( width*height ).astype(np.uint8)\n    \n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n        current_position += lengths[index]\n        \n    return np.flipud( np.rot90( mask.reshape(height,width), k=1 ) )\n\nfig=plt.figure(figsize=(20,100))\ncolumns = 2\nrows = 50\nfor i in range(1, 100+1):\n    fig.add_subplot(rows, columns, i)\n    \n    fn = train_df['ImageId_ClassId'].iloc[i].split('_')[0]\n    img = cv2.imread( '../input/train_images/'+fn )\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    mask = rle2mask(train_df['EncodedPixels'].iloc[i], img.shape  )\n    img[mask==1,0] = 255\n    \n    plt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Unet Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\nimport time\nfrom PIL import Image \nimport keras\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.losses import binary_crossentropy\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\npath = '../input/'\ntrain = pd.read_csv(path + 'train.csv')\n\n# RESTRUCTURE TRAIN DATAFRAME\ntrain['ImageId'] = train['ImageId_ClassId'].map(lambda x: x.split('.')[0]+'.jpg')\ntrain2 = pd.DataFrame({'ImageId':train['ImageId'][::4]})\ntrain2['e1'] = train['EncodedPixels'][::4].values\ntrain2['e2'] = train['EncodedPixels'][1::4].values\ntrain2['e3'] = train['EncodedPixels'][2::4].values\ntrain2['e4'] = train['EncodedPixels'][3::4].values\ntrain2.reset_index(inplace=True,drop=True)\ntrain2.fillna('',inplace=True); \ntrain2['count'] = np.sum(train2.iloc[:,1:]!='',axis=1).values\ntrain2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Generator**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/ateplyuk/pytorch-starter-u-net-resnet\n# https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n\nclass DataGenerator(keras.utils.Sequence):\n    def __init__(self, df, batch_size = 16, subset=\"train\", shuffle=False, \n                 preprocess=None, info={}):\n        super().__init__()\n        self.df = df\n        self.shuffle = shuffle\n        self.subset = subset\n        self.batch_size = batch_size\n        self.preprocess = preprocess\n        self.info = info\n        \n        if self.subset == \"train\":\n            self.data_path = path + 'train_images/'\n        elif self.subset == \"test\":\n            self.data_path = path + 'test_images/'\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(np.floor(len(self.df) / self.batch_size))\n    \n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.df))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n    \n    def __getitem__(self, index): \n        X = np.empty((self.batch_size,128,800,3),dtype=np.float32)\n        y = np.empty((self.batch_size,128,800,4),dtype=np.int8)\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        for i,f in enumerate(self.df['ImageId'].iloc[indexes]):\n            self.info[index*self.batch_size+i]=f\n            X[i,] = Image.open(self.data_path + f).resize((800,128))\n            if self.subset == 'train': \n                for j in range(4):\n                    y[i,:,:,j] = rle2maskResize(self.df['e'+str(j+1)].iloc[indexes[i]])\n        if self.preprocess!=None: X = self.preprocess(X)\n        if self.subset == 'train': return X, y\n        else: return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/titericz/building-and-visualizing-masks\ndef rle2maskResize(rle):\n    # CONVERT RLE TO MASK \n    if (pd.isnull(rle))|(rle==''): \n        return np.zeros((128,800) ,dtype=np.uint8)\n    \n    height= 256\n    width = 1600\n    mask= np.zeros( width*height ,dtype=np.uint8)\n\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]-1\n    lengths = array[1::2]    \n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n    \n    return mask.reshape( (height,width), order='F' )[::2,::2]\n\ndef mask2contour(mask, width=3):\n    # CONVERT MASK TO ITS CONTOUR\n    w = mask.shape[1]\n    h = mask.shape[0]\n    mask2 = np.concatenate([mask[:,width:],np.zeros((h,width))],axis=1)\n    mask2 = np.logical_xor(mask,mask2)\n    mask3 = np.concatenate([mask[width:,:],np.zeros((width,w))],axis=0)\n    mask3 = np.logical_xor(mask,mask3)\n    return np.logical_or(mask2,mask3) \n\ndef mask2pad(mask, pad=2):\n    # ENLARGE MASK TO INCLUDE MORE SPACE AROUND DEFECT\n    w = mask.shape[1]\n    h = mask.shape[0]\n    \n    # MASK UP\n    for k in range(1,pad,2):\n        temp = np.concatenate([mask[k:,:],np.zeros((k,w))],axis=0)\n        mask = np.logical_or(mask,temp)\n    # MASK DOWN\n    for k in range(1,pad,2):\n        temp = np.concatenate([np.zeros((k,w)),mask[:-k,:]],axis=0)\n        mask = np.logical_or(mask,temp)\n    # MASK LEFT\n    for k in range(1,pad,2):\n        temp = np.concatenate([mask[:,k:],np.zeros((h,k))],axis=1)\n        mask = np.logical_or(mask,temp)\n    # MASK RIGHT\n    for k in range(1,pad,2):\n        temp = np.concatenate([np.zeros((h,k)),mask[:,:-k]],axis=1)\n        mask = np.logical_or(mask,temp)\n    \n    return mask ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(13.5,2.5))\nbar = plt.bar( [1,2,3,4],100*np.mean( train2.iloc[:,1:5]!='',axis=0) )\nplt.title('Percent Training Images with Defect', fontsize=16)\nplt.ylabel('Percent of Images'); plt.xlabel('Defect Type')\nplt.xticks([1,2,3,4])\nfor rect in bar:\n    height = rect.get_height()\n    plt.text(rect.get_x() + rect.get_width()/2.0, height, '%.1f %%' % height,\n             ha='center', va='bottom',fontsize=16)\nplt.ylim((0,50)); plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DEFECTIVE IMAGE SAMPLES\nfilenames = {}\ndefects = list(train2[train2['e1']!=''].sample(3).index)\ndefects += list(train2[train2['e2']!=''].sample(3).index)\ndefects += list(train2[train2['e3']!=''].sample(7).index)\ndefects += list(train2[train2['e4']!=''].sample(3).index)\n\n# DATA GENERATOR\ntrain_batches = DataGenerator(train2[train2.index.isin(defects)],shuffle=True,info=filenames)\nprint('Images and masks from our Data Generator')\nprint('KEY: yellow=defect1, green=defect2, blue=defect3, magenta=defect4')\n\n# DISPLAY IMAGES WITH DEFECTS\nfor i,batch in enumerate(train_batches):\n    plt.figure(figsize=(14,50)) #20,18\n    for k in range(16):\n        plt.subplot(16,1,k+1)\n        img = batch[0][k,]\n        img = Image.fromarray(img.astype('uint8'))\n        img = np.array(img)\n        extra = '  has defect'\n        for j in range(4):\n            msk = batch[1][k,:,:,j]\n            msk = mask2pad(msk,pad=3)\n            msk = mask2contour(msk,width=2)\n            if np.sum(msk)!=0: extra += ' '+str(j+1)\n            if j==0: # yellow\n                img[msk==1,0] = 235 \n                img[msk==1,1] = 235\n            elif j==1: img[msk==1,1] = 210 # green\n            elif j==2: img[msk==1,2] = 255 # blue\n            elif j==3: # magenta\n                img[msk==1,0] = 255\n                img[msk==1,2] = 255\n        plt.title(filenames[16*i+k]+extra)\n        plt.axis('off') \n        plt.imshow(img)\n    plt.subplots_adjust(wspace=0.05)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install segmentation-models","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**METRIC AND LOSS**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# COMPETITION METRIC\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\n# LOSS FUNCTION\n\ndef dice_loss(y_true, y_pred):\n    loss = 1 - dice_coef(y_true, y_pred)\n    return loss\n\ndef bce_dice_loss(y_true, y_pred):\n    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n    return loss\n\n# Focal Tversky loss, brought to you by:  https://github.com/nabsabraham/focal-tversky-unet\ndef tversky(y_true, y_pred, smooth=1e-6):\n    y_true_pos = tf.keras.layers.Flatten()(y_true)\n    y_pred_pos = tf.keras.layers.Flatten()(y_pred)\n    true_pos = tf.reduce_sum(y_true_pos * y_pred_pos)\n    false_neg = tf.reduce_sum(y_true_pos * (1-y_pred_pos))\n    false_pos = tf.reduce_sum((1-y_true_pos)*y_pred_pos)\n    alpha = 0.7\n    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n\ndef tversky_loss(y_true, y_pred):\n    return 1 - tversky(y_true,y_pred)\n\ndef focal_tversky_loss(y_true,y_pred):\n    pt_1 = tversky(y_true, y_pred)\n    gamma = 0.75\n    return tf.keras.backend.pow((1 - pt_1), gamma)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from segmentation_models import Unet\nfrom segmentation_models.backbones import get_preprocessing\n\n# LOAD UNET WITH PRETRAINING FROM IMAGENET\npreprocess = get_preprocessing('resnet34') # for resnet, img = (img-110.0)/1.0\nmodel = Unet('resnet34', input_shape=(128, 800, 3), classes=4, activation='sigmoid')\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])\n#adam = tf.keras.optimizers.Adam(lr = 0.05, epsilon = 0.1)\n#model.complie(optimizer = adam, loss = focal_tversky_loss, metrics = [tversky, dice_coef])\n\n# TRAIN AND VALIDATE MODEL\nidx = int(0.8*len(train2)); print()\ntrain_batches = DataGenerator(train2.iloc[:idx],shuffle = True, preprocess = preprocess)\nvalid_batches = DataGenerator(train2.iloc[idx:],preprocess=preprocess)\nhistory = model.fit_generator(train_batches, validation_data = valid_batches, epochs = 30, verbose = 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PLOT TRAINING\nplt.figure(figsize=(15,5))\nplt.plot(range(history.epoch[-1]+1),history.history['val_dice_coef'],label='val_dice_coef')\nplt.plot(range(history.epoch[-1]+1),history.history['dice_coef'],label='trn_dice_coef')\nplt.title('Training Accuracy'); plt.xlabel('Epoch'); plt.ylabel('Dice_coef');plt.legend(); \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Prediction EDA**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# PREDICT FROM VALIDATION SET (ONLY IMAGES WITH DEFECTS)\nval_set = train2.iloc[idx:];\ndefects = list(val_set[val_set['e1']!=''].sample(6).index)\ndefects += list(val_set[val_set['e2']!=''].sample(6).index)\ndefects += list(val_set[val_set['e3']!=''].sample(14).index)\ndefects += list(val_set[val_set['e4']!=''].sample(6).index)\n\nvalid_batches = DataGenerator(val_set[val_set.index.isin(defects)],preprocess=preprocess)\npreds = model.predict_generator(valid_batches,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PLOT PREDICTIONS\nvalid_batches = DataGenerator(val_set[val_set.index.isin(defects)])\nprint('Plotting predictions...')\nprint('KEY: yellow=defect1, green=defect2, blue=defect3, magenta=defect4')\n\nfor i,batch in enumerate(valid_batches):\n    plt.figure(figsize=(20,36))\n    for k in range(16):\n        plt.subplot(16,2,2*k+1)\n        img = batch[0][k,]\n        img = Image.fromarray(img.astype('uint8'))\n        img = np.array(img)\n        dft = 0\n        extra = '  has defect '\n        for j in range(4):\n            msk = batch[1][k,:,:,j]\n            if np.sum(msk)!=0: \n                dft=j+1\n                extra += ' '+str(j+1)\n            msk = mask2pad(msk,pad=2)\n            msk = mask2contour(msk,width=3)\n            if j==0: # yellow\n                img[msk==1,0] = 235 \n                img[msk==1,1] = 235\n            elif j==1: img[msk==1,1] = 210 # green\n            elif j==2: img[msk==1,2] = 255 # blue\n            elif j==3: # magenta\n                img[msk==1,0] = 255\n                img[msk==1,2] = 255\n        if extra=='  has defect ': extra =''\n        plt.title('Train '+train2.iloc[16*i+k,0]+extra)\n        plt.axis('off') \n        plt.imshow(img)\n        plt.subplot(16,2,2*k+2) \n        if dft!=0:\n            msk = preds[16*i+k,:,:,dft-1]\n            plt.imshow(msk)\n        else:\n            plt.imshow(np.zeros((128,800)))\n        plt.axis('off')\n        mx = np.round(np.max(msk),3)\n        plt.title('Predict Defect '+str(dft)+'  (max pixel = '+str(mx)+')')\n    plt.subplots_adjust(wspace=0.05)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Error EDA 1**\n\nThe masks above look pretty good. But note that we are only plotting masks corresponding to defects that are present. Below, regardless of what type of defect an image has, we will plot the defect 3 mask. Only the blue contour lines on the left are defect 3. So when we see contours on the left that do not include blue, we should not see defect 3 masks but we still do."},{"metadata":{"trusted":true},"cell_type":"code","source":"# PREDICT FROM VALIDATION SET (ONLY IMAGES WITH DEFECTS 1, 2, 4)\nval_set = train2.iloc[idx:]\nval_set2 = val_set[(val_set['count']!=0)&(val_set['e3']=='')].sample(16)\n\nvalid_batches = DataGenerator(val_set2,preprocess=preprocess)\npreds = model.predict_generator(valid_batches,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PLOT PREDICTIONS\nvalid_batches = DataGenerator(val_set2)\nprint('Plotting predictions...')\nprint('KEY: yellow=defect1, green=defect2, blue=defect3, magenta=defect4')\nfor i,batch in enumerate(valid_batches):\n    plt.figure(figsize=(20,36))\n    for k in range(16):\n        plt.subplot(16,2,2*k+1)\n        img = batch[0][k,]\n        img = Image.fromarray(img.astype('uint8'))\n        img = np.array(img)\n        dft = 0\n        three = False\n        for j in range(4):\n            msk = batch[1][k,:,:,j]\n            if (j==2)&(np.sum(msk)!=0): \n                three=np.sum(msk)\n            msk = mask2pad(msk,pad=2)\n            msk = mask2contour(msk,width=3)\n            if j==0: # yellow\n                img[msk==1,0] = 235 \n                img[msk==1,1] = 235\n            elif j==1: img[msk==1,1] = 210 # green\n            elif j==2: img[msk==1,2] = 255 # blue\n            elif j==3: # magenta\n                img[msk==1,0] = 255\n                img[msk==1,2] = 255\n        extra = ''; extra2 = ''\n        if not three: \n            extra = 'NO DEFECT 3'\n            extra2 = 'ERROR '\n        plt.title('Train '+train2.iloc[16*i+k,0]+'  '+extra)\n        plt.axis('off') \n        plt.imshow(img)\n        plt.subplot(16,2,2*k+2) \n        dft=3\n        if dft!=0:\n            msk = preds[16*i+k,:,:,dft-1]\n            plt.imshow(msk)\n        else:\n            plt.imshow(np.zeros((128,800)))\n        plt.axis('off')\n        mx = np.round(np.max(msk),3)\n        plt.title(extra2+'Predict Defect '+str(dft)+'  (max pixel = '+str(mx)+')')\n    plt.subplots_adjust(wspace=0.05)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Error EDA 2**\n\nWe will plot histograms showing the predicted size of each defect mask. We would hope that if an image does not have a particular defect then UNET would not predict a mask (i.e. predict less than 250 pixel mask). This is not the case. When UNET predicts a mask when a defect isn't present, we call that an \"incorrect\" mask. When UNET predicts a mask when a defect is present, we call that a \"correct\" mask. If UNET predicts less than 250 pixels, we will treat that as no mask predicted. Let's compare the distribution of \"incorrect\" versus \"correct\" masks for each defect type.\n\nUNET outputs masks using all floating point values between 0 and 1 inclusive. When we submit to Kaggle, we need to use only integer 0 and 1. Therefore we must convert mask floating points into integers using a threshold. If pixel >= THRESHOLD then pixel=1 else pixel = 0. We will plot histograms for various thresholds below. We will consider all masks with less than 250 pixels as empty masks (where pixel_count = 4 * pixel count on 128x800).\n\nFrom the plots below, we see that UNET doesn't create more and/or larger masks for images with defects. UNET seems to equally create masks for all images whether there is a defect or not. If we submit the output from UNET to Kaggle, our LB score will be lower than submitting all empty masks (LB 0.85674) because there are more mistake masks than correct masks. Each mistake decreases our LB score by 1/7200 and each correct increases our score by c*(1/7200) where 0<=c<=1 is our average dice score."},{"metadata":{"trusted":true},"cell_type":"code","source":"# PREDICT FROM VALIDATION SET (USE ALL)\nvalid_batches = DataGenerator(train2.iloc[idx:],preprocess=preprocess)\npreds = model.predict_generator(valid_batches,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PLOT RESULTS\nimport seaborn as sns\npix_min = 250\nfor THRESHOLD in [0.1, 0.25, 0.50, 0.75, 0.9]:\n    print('######################################')\n    print('## Threshold =',THRESHOLD,'displayed below ##')\n    print('######################################')\n    correct=[[],[],[],[]]; incorrect=[[],[],[],[]]\n    for i,f in enumerate(train2.iloc[idx:idx+len(preds)]['ImageId']):\n        preds2 = preds[i].copy()\n        preds2[preds2>=THRESHOLD]=1\n        preds2[preds2<THRESHOLD]=0\n        sums = np.sum(preds2,axis=(0,1))\n        for j in range(4):\n            if 4*sums[j]<pix_min: continue\n            if train2.iloc[i,j+1]=='': incorrect[j].append(4*sums[j])\n            else: correct[j].append(4*sums[j])\n    plt.figure(figsize=(20,8))\n    for j in range(4):\n        limit = [10000,10000,100000,100000][j]\n        plt.subplot(2,2,j+1)\n        sns.distplot([x for x in correct[j] if x<limit], label = 'correct')\n        sns.distplot([x for x in incorrect[j] if x<limit], label = 'incorrect')\n        plt.title('Defect '+str(j+1)+' mask sizes with threshold = '+str(THRESHOLD)); plt.legend()\n    plt.show()\n    for j in range(4):\n        c1 = np.array(correct[j])\n        c2 = np.array(incorrect[j])\n        print('With threshold =',THRESHOLD,', defect',j+1,'has',len(c1[c1!=0]),'correct and',len(c2[c2!=0]),'incorrect masks')\n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SAVE MODEL\nmodel.save('UNET.h5')\n\n# LOAD MODEL\nfrom keras.models import load_model\nmodel = load_model('UNET.h5',custom_objects={'dice_coef': dice_coef})\n\n# PREDICT 1 BATCH TEST DATASET\ntest = pd.read_csv(path + 'sample_submission.csv')\ntest['ImageId'] = test['ImageId_ClassId'].map(lambda x: x.split('_')[0])\ntest_batches = DataGenerator(test.iloc[::4],subset='test',batch_size=256,preprocess=preprocess)\ntest_preds = model.predict_generator(test_batches,steps=1,verbose=1)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}