{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport fastai\nfrom fastai.vision import *\nfrom fastai.callbacks import SaveModelCallback\nimport gc\nimport os\nfrom sklearn.model_selection import KFold\nfrom PIL import Image\nimport zipfile\nimport io\nimport cv2\nimport warnings\n#from keras_radam import RAdam\nwarnings.filterwarnings(\"ignore\")\n\nfastai.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sz = 256\nbs = 16\nnfolds = 4\nfold = 0\nSEED = 2019\nTRAIN = '../input/severstal-256x256-images-with-defects/images/'\nMASKS = '../input/severstal-256x256-images-with-defects/masks/'\nTRAIN_N = '../input/severstal-256x256-images-with-defects/images_n/'\nHARD_NEGATIVE = '../input/hard-negative-severstal-crops/pred.csv'\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    #tf.set_random_seed(seed)\nseed_everything(SEED)\ntorch.backends.cudnn.benchmark = True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#the code below modifies fast.ai functions to incorporate Hcolumns into fast.ai Dynamic Unet\n\nfrom fastai.vision.learner import create_head, cnn_config, num_features_model, create_head\nfrom fastai.callbacks.hooks import model_sizes, hook_outputs, dummy_eval, Hook, _hook_inner\nfrom fastai.vision.models.unet import _get_sfs_idxs, UnetBlock\n\nclass Hcolumns(nn.Module):\n    def __init__(self, hooks:Collection[Hook], nc:Collection[int]=None):\n        super(Hcolumns,self).__init__()\n        self.hooks = hooks\n        self.n = len(self.hooks)\n        self.factorization = None \n        if nc is not None:\n            self.factorization = nn.ModuleList()\n            for i in range(self.n):\n                self.factorization.append(nn.Sequential(\n                    conv2d(nc[i],nc[-1],3,padding=1,bias=True),\n                    conv2d(nc[-1],nc[-1],3,padding=1,bias=True)))\n                #self.factorization.append(conv2d(nc[i],nc[-1],3,padding=1,bias=True))\n        \n    def forward(self, x:Tensor):\n        n = len(self.hooks)\n        out = [F.interpolate(self.hooks[i].stored if self.factorization is None\n            else self.factorization[i](self.hooks[i].stored), scale_factor=2**(self.n-i),\n            mode='bilinear',align_corners=False) for i in range(self.n)] + [x]\n        return torch.cat(out, dim=1)\n\nclass DynamicUnet_Hcolumns(SequentialEx):\n    \"Create a U-Net from a given architecture.\"\n    def __init__(self, encoder:nn.Module, n_classes:int, blur:bool=False, blur_final=True, \n                 self_attention:bool=False,\n                 y_range:Optional[Tuple[float,float]]=None,\n                 last_cross:bool=True, bottle:bool=False, **kwargs):\n        imsize = (256,256)\n        sfs_szs = model_sizes(encoder, size=imsize)\n        sfs_idxs = list(reversed(_get_sfs_idxs(sfs_szs)))\n        self.sfs = hook_outputs([encoder[i] for i in sfs_idxs])\n        x = dummy_eval(encoder, imsize).detach()\n\n        ni = sfs_szs[-1][1]\n        middle_conv = nn.Sequential(conv_layer(ni, ni*2, **kwargs),\n                                    conv_layer(ni*2, ni, **kwargs)).eval()\n        x = middle_conv(x)\n        layers = [encoder, batchnorm_2d(ni), nn.ReLU(), middle_conv]\n\n        self.hc_hooks = [Hook(layers[-1], _hook_inner, detach=False)]\n        hc_c = [x.shape[1]]\n        \n        for i,idx in enumerate(sfs_idxs):\n            not_final = i!=len(sfs_idxs)-1\n            up_in_c, x_in_c = int(x.shape[1]), int(sfs_szs[idx][1])\n            do_blur = blur and (not_final or blur_final)\n            sa = self_attention and (i==len(sfs_idxs)-3)\n            unet_block = UnetBlock(up_in_c, x_in_c, self.sfs[i], final_div=not_final, \n                blur=blur, self_attention=sa, **kwargs).eval()\n            layers.append(unet_block)\n            x = unet_block(x)\n            self.hc_hooks.append(Hook(layers[-1], _hook_inner, detach=False))\n            hc_c.append(x.shape[1])\n\n        ni = x.shape[1]\n        if imsize != sfs_szs[0][-2:]: layers.append(PixelShuffle_ICNR(ni, **kwargs))\n        if last_cross:\n            layers.append(MergeLayer(dense=True))\n            ni += in_channels(encoder)\n            layers.append(res_block(ni, bottle=bottle, **kwargs))\n        hc_c.append(ni)\n        layers.append(Hcolumns(self.hc_hooks, hc_c))\n        layers += [conv_layer(ni*len(hc_c), n_classes, ks=1, use_activ=False, **kwargs)]\n        if y_range is not None: layers.append(SigmoidRange(*y_range))\n        super().__init__(*layers)\n\n    def __del__(self):\n        if hasattr(self, \"sfs\"): self.sfs.remove()\n            \ndef unet_learner(data:DataBunch, arch:Callable, pretrained:bool=True, blur_final:bool=True,\n        norm_type:Optional[NormType]=NormType, split_on:Optional[SplitFuncOrIdxList]=None, \n        blur:bool=False, self_attention:bool=False, y_range:Optional[Tuple[float,float]]=None, \n        last_cross:bool=True, bottle:bool=False, cut:Union[int,Callable]=None, \n        hypercolumns=True, **learn_kwargs:Any)->Learner:\n    \"Build Unet learner from `data` and `arch`.\"\n    meta = cnn_config(arch)\n    body = create_body(arch, pretrained, cut)\n    M = DynamicUnet_Hcolumns if hypercolumns else DynamicUnet\n    model = to_device(M(body, n_classes=data.c, blur=blur, blur_final=blur_final,\n        self_attention=self_attention, y_range=y_range, norm_type=norm_type, \n        last_cross=last_cross, bottle=bottle), data.device)\n    learn = Learner(data, model, **learn_kwargs)\n    learn.split(ifnone(split_on, meta['split']))\n    if pretrained: learn.freeze()\n    apply_init(model[2], nn.init.kaiming_normal_)\n    return learn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice(input:Tensor, targs:Tensor, iou:bool=False, eps:float=1e-8)->Rank0Tensor:\n    n,c = targs.shape[0], input.shape[1]\n    input = input.argmax(dim=1).view(n,-1)\n    targs = targs.view(n,-1)\n    intersect,union = [],[]\n    for i in range(1,c):\n        intersect.append(((input==i) & (targs==i)).sum(-1).float())\n        union.append(((input==i).sum(-1) + (targs==i).sum(-1)).float())\n    intersect = torch.stack(intersect)\n    union = torch.stack(union)\n    if not iou: return ((2.0*intersect + eps) / (union+eps)).mean()\n    else: return ((intersect + eps) / (union - intersect + eps)).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SegmentationLabelList(SegmentationLabelList):\n    def open(self, fn): return open_mask(fn, div=True)\n    \nclass SegmentationItemList(SegmentationItemList):\n    _label_cls = SegmentationLabelList\n\n# Setting transformations on masks to False on test set\ndef transform(self, tfms:Optional[Tuple[TfmList,TfmList]]=(None,None), **kwargs):\n    if not tfms: tfms=(None,None)\n    assert is_listy(tfms) and len(tfms) == 2\n    self.train.transform(tfms[0], **kwargs)\n    self.valid.transform(tfms[1], **kwargs)\n    kwargs['tfm_y'] = False # Test data has no labels\n    if self.test: self.test.transform(tfms[1], **kwargs)\n    return self\nfastai.data_block.ItemLists.transform = transform\n\ndef open_mask(fn:PathOrStr, div:bool=True, convert_mode:str='L', cls:type=ImageSegment,\n        after_open:Callable=None)->ImageSegment:\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", UserWarning)\n        #generate empty mask if file doesn't exist\n        x = PIL.Image.open(fn).convert(convert_mode) \\\n          if Path(fn).exists() \\\n          else PIL.Image.fromarray(np.zeros((sz,sz)).astype(np.uint8))\n    if after_open: x = after_open(x)\n    x = pil2tensor(x,np.float32)\n    return cls(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(HARD_NEGATIVE)\ndf['index'] = df.index\ndf.plot(x='index', y='pixels', kind = 'line');\nplt.yscale('log')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}