{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Keras Segmentation Models\nIn this kernel, we learn how to install and use pretrained Keras segmentation models from GitHub [here][1] with docs [here][2]. We also plot EDA showing training examples, UNET prediction examples, and UNET error.\n\n# Data Generator\nFirst let's restructure the train.csv dataframe and build a data generator. We will need to feed our neural network `X_train` of images and `y_train` of masks. We will resize all images by a factor of 0.5 for efficiency. (Convert 256x1600 RGB to 128x800 RGB).\n\n[1]: https://github.com/qubvel/segmentation_models\n[2]: https://segmentation-models.readthedocs.io/en/latest/tutorial.html"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":false},"cell_type":"code","source":"import numpy as np, pandas as pd, os, gc\nimport matplotlib.pyplot as plt, time\nfrom PIL import Image \nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\npath = '../input/'\ntrain = pd.read_csv(path + 'train.csv')\n\n# RESTRUCTURE TRAIN DATAFRAME\ntrain['ImageId'] = train['ImageId_ClassId'].map(lambda x: x.split('.')[0]+'.jpg')\ntrain2 = pd.DataFrame({'ImageId':train['ImageId'][::4]})\ntrain2['e1'] = train['EncodedPixels'][::4].values\ntrain2['e2'] = train['EncodedPixels'][1::4].values\ntrain2['e3'] = train['EncodedPixels'][2::4].values\ntrain2['e4'] = train['EncodedPixels'][3::4].values\ntrain2.reset_index(inplace=True,drop=True)\ntrain2.fillna('',inplace=True); \ntrain2['count'] = np.sum(train2.iloc[:,1:]!='',axis=1).values\ntrain2.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/ateplyuk/pytorch-starter-u-net-resnet\n# https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\nimport keras\n\nclass DataGenerator(keras.utils.Sequence):\n    def __init__(self, df, batch_size = 16, subset=\"train\", shuffle=False, \n                 preprocess=None, info={}):\n        super().__init__()\n        self.df = df\n        self.shuffle = shuffle\n        self.subset = subset\n        self.batch_size = batch_size\n        self.preprocess = preprocess\n        self.info = info\n        \n        if self.subset == \"train\":\n            self.data_path = path + 'train_images/'\n        elif self.subset == \"test\":\n            self.data_path = path + 'test_images/'\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(np.floor(len(self.df) / self.batch_size))\n    \n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.df))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n    \n    def __getitem__(self, index): \n        X = np.empty((self.batch_size,128,800,3),dtype=np.float32)\n        y = np.empty((self.batch_size,128,800,4),dtype=np.int8)\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        for i,f in enumerate(self.df['ImageId'].iloc[indexes]):\n            self.info[index*self.batch_size+i]=f\n            X[i,] = Image.open(self.data_path + f).resize((800,128))\n            if self.subset == 'train': \n                for j in range(4):\n                    y[i,:,:,j] = rle2maskResize(self.df['e'+str(j+1)].iloc[indexes[i]])\n        if self.preprocess!=None: X = self.preprocess(X)\n        if self.subset == 'train': return X, y\n        else: return X","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Utility Functions\nNext we'll need some utility functions. The first converts rle to mask. The second converts a mask to its contour. The third enlarges a mask. The second and third together put blank space between defect and mask contour for better visualization."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"# https://www.kaggle.com/titericz/building-and-visualizing-masks\ndef rle2maskResize(rle):\n    # CONVERT RLE TO MASK \n    if (pd.isnull(rle))|(rle==''): \n        return np.zeros((128,800) ,dtype=np.uint8)\n    \n    height= 256\n    width = 1600\n    mask= np.zeros( width*height ,dtype=np.uint8)\n\n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]-1\n    lengths = array[1::2]    \n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n    \n    return mask.reshape( (height,width), order='F' )[::2,::2]\n\ndef mask2contour(mask, width=3):\n    # CONVERT MASK TO ITS CONTOUR\n    w = mask.shape[1]\n    h = mask.shape[0]\n    mask2 = np.concatenate([mask[:,width:],np.zeros((h,width))],axis=1)\n    mask2 = np.logical_xor(mask,mask2)\n    mask3 = np.concatenate([mask[width:,:],np.zeros((width,w))],axis=0)\n    mask3 = np.logical_xor(mask,mask3)\n    return np.logical_or(mask2,mask3) \n\ndef mask2pad(mask, pad=2):\n    # ENLARGE MASK TO INCLUDE MORE SPACE AROUND DEFECT\n    w = mask.shape[1]\n    h = mask.shape[0]\n    \n    # MASK UP\n    for k in range(1,pad,2):\n        temp = np.concatenate([mask[k:,:],np.zeros((k,w))],axis=0)\n        mask = np.logical_or(mask,temp)\n    # MASK DOWN\n    for k in range(1,pad,2):\n        temp = np.concatenate([np.zeros((k,w)),mask[:-k,:]],axis=0)\n        mask = np.logical_or(mask,temp)\n    # MASK LEFT\n    for k in range(1,pad,2):\n        temp = np.concatenate([mask[:,k:],np.zeros((h,k))],axis=1)\n        mask = np.logical_or(mask,temp)\n    # MASK RIGHT\n    for k in range(1,pad,2):\n        temp = np.concatenate([np.zeros((h,k)),mask[:,:-k]],axis=1)\n        mask = np.logical_or(mask,temp)\n    \n    return mask ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train EDA\nLet's confirm our Data Generator works and view some training images. We will only show examples with defects. Note that all mask contours are plotted with a little blank space around the defect to aid visualization. Below we show examples of each type but note that in the training set only 7.1%, 2.0%, 41.0%, 6.4% of images have defects 1, 2, 3, 4 respectively."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(13.5,2.5))\nbar = plt.bar( [1,2,3,4],100*np.mean( train2.iloc[:,1:5]!='',axis=0) )\nplt.title('Percent Training Images with Defect', fontsize=16)\nplt.ylabel('Percent of Images'); plt.xlabel('Defect Type')\nplt.xticks([1,2,3,4])\nfor rect in bar:\n    height = rect.get_height()\n    plt.text(rect.get_x() + rect.get_width()/2.0, height, '%.1f %%' % height,\n             ha='center', va='bottom',fontsize=16)\nplt.ylim((0,50)); plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# DEFECTIVE IMAGE SAMPLES\nfilenames = {}\ndefects = list(train2[train2['e1']!=''].sample(3).index)\ndefects += list(train2[train2['e2']!=''].sample(3).index)\ndefects += list(train2[train2['e3']!=''].sample(7).index)\ndefects += list(train2[train2['e4']!=''].sample(3).index)\n\n# DATA GENERATOR\ntrain_batches = DataGenerator(train2[train2.index.isin(defects)],shuffle=True,info=filenames)\nprint('Images and masks from our Data Generator')\nprint('KEY: yellow=defect1, green=defect2, blue=defect3, magenta=defect4')\n\n# DISPLAY IMAGES WITH DEFECTS\nfor i,batch in enumerate(train_batches):\n    plt.figure(figsize=(14,50)) #20,18\n    for k in range(16):\n        plt.subplot(16,1,k+1)\n        img = batch[0][k,]\n        img = Image.fromarray(img.astype('uint8'))\n        img = np.array(img)\n        extra = '  has defect'\n        for j in range(4):\n            msk = batch[1][k,:,:,j]\n            msk = mask2pad(msk,pad=3)\n            msk = mask2contour(msk,width=2)\n            if np.sum(msk)!=0: extra += ' '+str(j+1)\n            if j==0: # yellow\n                img[msk==1,0] = 235 \n                img[msk==1,1] = 235\n            elif j==1: img[msk==1,1] = 210 # green\n            elif j==2: img[msk==1,2] = 255 # blue\n            elif j==3: # magenta\n                img[msk==1,0] = 255\n                img[msk==1,2] = 255\n        plt.title(filenames[16*i+k]+extra)\n        plt.axis('off') \n        plt.imshow(img)\n    plt.subplots_adjust(wspace=0.05)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Download UNET\nWe will download a pretrained Keras UNET from GitHub [here][1] with docs [here][2]. In this repository, there are many different architectures and pretrained backbones. Although the bottom is pretrained, the top of the model needs to be trained to our data. We will train for 90 minutes. To use this model in Kaggle's Steel competition, we'll need to save this trained model to a Kaggle dataset and load it into another kernel (called an inference kernel). The second kernel will make predictions on the test set. We can submit this second kernel because it will execute under an hour and have internet turned off thus satifying the comp rules.\n\n[1]: https://github.com/qubvel/segmentation_models\n[2]: https://segmentation-models.readthedocs.io/en/latest/tutorial.html"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"! pip install segmentation-models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"from keras import backend as K\n# https://www.kaggle.com/xhlulu/severstal-simple-keras-u-net-boilerplate\n\n# COMPETITION METRIC\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from segmentation_models import Unet\nfrom segmentation_models.backbones import get_preprocessing\n\n# LOAD UNET WITH PRETRAINING FROM IMAGENET\npreprocess = get_preprocessing('resnet34') # for resnet, img = (img-110.0)/1.0\nmodel = Unet('resnet34', input_shape=(128, 800, 3), classes=4, activation='sigmoid')\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef])\n\n# TRAIN AND VALIDATE MODEL\nidx = int(0.8*len(train2)); print()\ntrain_batches = DataGenerator(train2.iloc[:idx],shuffle=True,preprocess=preprocess)\nvalid_batches = DataGenerator(train2.iloc[idx:],preprocess=preprocess)\nhistory = model.fit_generator(train_batches, validation_data = valid_batches, epochs = 30, verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# PLOT TRAINING\nplt.figure(figsize=(15,5))\nplt.plot(range(history.epoch[-1]+1),history.history['val_dice_coef'],label='val_dice_coef')\nplt.plot(range(history.epoch[-1]+1),history.history['dice_coef'],label='trn_dice_coef')\nplt.title('Training Accuracy'); plt.xlabel('Epoch'); plt.ylabel('Dice_coef');plt.legend(); \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction EDA\nIn the images below (which all contain defects), we will display one prediction mask for a defect that is present. Note that `matplotlib` scales the mask's largest pixel value to yellow and smallest to blue. Therefore the presense of yellow doesn't indicate that the mask achieved a pixel value 1.0. The maximum pixel value is indicated in the titles and is a measure of mask confidence."},{"metadata":{"trusted":true},"cell_type":"code","source":"# PREDICT FROM VALIDATION SET (ONLY IMAGES WITH DEFECTS)\nval_set = train2.iloc[idx:];\ndefects = list(val_set[val_set['e1']!=''].sample(6).index)\ndefects += list(val_set[val_set['e2']!=''].sample(6).index)\ndefects += list(val_set[val_set['e3']!=''].sample(14).index)\ndefects += list(val_set[val_set['e4']!=''].sample(6).index)\n\nvalid_batches = DataGenerator(val_set[val_set.index.isin(defects)],preprocess=preprocess)\npreds = model.predict_generator(valid_batches,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# PLOT PREDICTIONS\nvalid_batches = DataGenerator(val_set[val_set.index.isin(defects)])\nprint('Plotting predictions...')\nprint('KEY: yellow=defect1, green=defect2, blue=defect3, magenta=defect4')\n\nfor i,batch in enumerate(valid_batches):\n    plt.figure(figsize=(20,36))\n    for k in range(16):\n        plt.subplot(16,2,2*k+1)\n        img = batch[0][k,]\n        img = Image.fromarray(img.astype('uint8'))\n        img = np.array(img)\n        dft = 0\n        extra = '  has defect '\n        for j in range(4):\n            msk = batch[1][k,:,:,j]\n            if np.sum(msk)!=0: \n                dft=j+1\n                extra += ' '+str(j+1)\n            msk = mask2pad(msk,pad=2)\n            msk = mask2contour(msk,width=3)\n            if j==0: # yellow\n                img[msk==1,0] = 235 \n                img[msk==1,1] = 235\n            elif j==1: img[msk==1,1] = 210 # green\n            elif j==2: img[msk==1,2] = 255 # blue\n            elif j==3: # magenta\n                img[msk==1,0] = 255\n                img[msk==1,2] = 255\n        if extra=='  has defect ': extra =''\n        plt.title('Train '+train2.iloc[16*i+k,0]+extra)\n        plt.axis('off') \n        plt.imshow(img)\n        plt.subplot(16,2,2*k+2) \n        if dft!=0:\n            msk = preds[16*i+k,:,:,dft-1]\n            plt.imshow(msk)\n        else:\n            plt.imshow(np.zeros((128,800)))\n        plt.axis('off')\n        mx = np.round(np.max(msk),3)\n        plt.title('Predict Defect '+str(dft)+'  (max pixel = '+str(mx)+')')\n    plt.subplots_adjust(wspace=0.05)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Error EDA 1\nThe masks above look pretty good. But note that we are only plotting masks corresponding to defects that are present. Below, regardless of what type of defect an image has, we will plot the defect 3 mask. Only the blue contour lines on the left are defect 3. So when we see contours on the left that do not include blue, we should not see defect 3 masks but we still do."},{"metadata":{"trusted":true},"cell_type":"code","source":"# PREDICT FROM VALIDATION SET (ONLY IMAGES WITH DEFECTS 1, 2, 4)\nval_set = train2.iloc[idx:]\nval_set2 = val_set[(val_set['count']!=0)&(val_set['e3']=='')].sample(16)\n\nvalid_batches = DataGenerator(val_set2,preprocess=preprocess)\npreds = model.predict_generator(valid_batches,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# PLOT PREDICTIONS\nvalid_batches = DataGenerator(val_set2)\nprint('Plotting predictions...')\nprint('KEY: yellow=defect1, green=defect2, blue=defect3, magenta=defect4')\nfor i,batch in enumerate(valid_batches):\n    plt.figure(figsize=(20,36))\n    for k in range(16):\n        plt.subplot(16,2,2*k+1)\n        img = batch[0][k,]\n        img = Image.fromarray(img.astype('uint8'))\n        img = np.array(img)\n        dft = 0\n        three = False\n        for j in range(4):\n            msk = batch[1][k,:,:,j]\n            if (j==2)&(np.sum(msk)!=0): \n                three=np.sum(msk)\n            msk = mask2pad(msk,pad=2)\n            msk = mask2contour(msk,width=3)\n            if j==0: # yellow\n                img[msk==1,0] = 235 \n                img[msk==1,1] = 235\n            elif j==1: img[msk==1,1] = 210 # green\n            elif j==2: img[msk==1,2] = 255 # blue\n            elif j==3: # magenta\n                img[msk==1,0] = 255\n                img[msk==1,2] = 255\n        extra = ''; extra2 = ''\n        if not three: \n            extra = 'NO DEFECT 3'\n            extra2 = 'ERROR '\n        plt.title('Train '+train2.iloc[16*i+k,0]+'  '+extra)\n        plt.axis('off') \n        plt.imshow(img)\n        plt.subplot(16,2,2*k+2) \n        dft=3\n        if dft!=0:\n            msk = preds[16*i+k,:,:,dft-1]\n            plt.imshow(msk)\n        else:\n            plt.imshow(np.zeros((128,800)))\n        plt.axis('off')\n        mx = np.round(np.max(msk),3)\n        plt.title(extra2+'Predict Defect '+str(dft)+'  (max pixel = '+str(mx)+')')\n    plt.subplots_adjust(wspace=0.05)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Error EDA 2\nWe will plot histograms showing the predicted size of each defect mask. We would hope that if an image does not have a particular defect then UNET would not predict a mask (i.e. predict less than 250 pixel mask). This is not the case. When UNET predicts a mask when a defect isn't present, we call that an \"incorrect\" mask. When UNET predicts a mask when a defect is present, we call that a \"correct\" mask. If UNET predicts less than 250 pixels, we will treat that as no mask predicted. Let's compare the distribution of \"incorrect\" versus \"correct\" masks for each defect type.\n\nUNET outputs masks using all floating point values between 0 and 1 inclusive. When we submit to Kaggle, we need to use only integer 0 and 1. Therefore we must convert mask floating points into integers using a threshold. If `pixel>=THRESHOLD` then `pixel=1` else `pixel=0`. We will plot histograms for various thresholds below. We will consider all masks with less than 250 pixels as empty masks (where `pixel_count = 4 * pixel count` on 128x800).\n\nFrom the plots below, we see that UNET doesn't create more and/or larger masks for images with defects. UNET seems to equally create masks for all images whether there is a defect or not. If we submit the output from UNET to Kaggle, our LB score will be lower than submitting all empty masks (LB 0.85674) because there are more mistake masks than correct masks. Each mistake decreases our LB score by `1/7200` and each correct increases our score by `c*(1/7200)` where `0<=c<=1` is our average dice score."},{"metadata":{"trusted":true},"cell_type":"code","source":"# PREDICT FROM VALIDATION SET (USE ALL)\nvalid_batches = DataGenerator(train2.iloc[idx:],preprocess=preprocess)\npreds = model.predict_generator(valid_batches,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# PLOT RESULTS\nimport seaborn as sns\npix_min = 250\nfor THRESHOLD in [0.1, 0.25, 0.50, 0.75, 0.9]:\n    print('######################################')\n    print('## Threshold =',THRESHOLD,'displayed below ##')\n    print('######################################')\n    correct=[[],[],[],[]]; incorrect=[[],[],[],[]]\n    for i,f in enumerate(train2.iloc[idx:idx+len(preds)]['ImageId']):\n        preds2 = preds[i].copy()\n        preds2[preds2>=THRESHOLD]=1\n        preds2[preds2<THRESHOLD]=0\n        sums = np.sum(preds2,axis=(0,1))\n        for j in range(4):\n            if 4*sums[j]<pix_min: continue\n            if train2.iloc[i,j+1]=='': incorrect[j].append(4*sums[j])\n            else: correct[j].append(4*sums[j])\n    plt.figure(figsize=(20,8))\n    for j in range(4):\n        limit = [10000,10000,100000,100000][j]\n        plt.subplot(2,2,j+1)\n        sns.distplot([x for x in correct[j] if x<limit], label = 'correct')\n        sns.distplot([x for x in incorrect[j] if x<limit], label = 'incorrect')\n        plt.title('Defect '+str(j+1)+' mask sizes with threshold = '+str(THRESHOLD)); plt.legend()\n    plt.show()\n    for j in range(4):\n        c1 = np.array(correct[j])\n        c2 = np.array(incorrect[j])\n        print('With threshold =',THRESHOLD,', defect',j+1,'has',len(c1[c1!=0]),'correct and',len(c2[c2!=0]),'incorrect masks')\n    print()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submit to Kaggle\nIn order to make a submission using Keras pretrained UNET, we'll need to save the trained model from this kernel to a private dataset. Then load the model (dataset) into another kernel, predict test, convert masks to rle, and submit csv to Kaggle. The second kernel will have internet turned off and execute under an hour thus satisying the comp rules.\n\nAll the test masks are large for RAM. 7200 masks where each is 256x1600 of 4 byte floats is 11 Gigabyes!! (128x800 are 3 Gb) So we should be careful not to overflow memory. It's best to predict one batch, convert the masks to rle, add the rle to a dataframe, then delete the masks before predicting another batch. Below we save model, load model, and predict 1 batch as an example.\n\nIn this kernel, we saw that UNET erroneously predicts masks when no defect is present. This hurts our LB score. We'll need to design a way to set masks to empty if no defect is present. Good luck, have fun!!\n\n[1]: https://www.kaggle.com/xhlulu/severstal-simple-2-step-pipeline"},{"metadata":{"trusted":true},"cell_type":"code","source":"# SAVE MODEL\nmodel.save('UNET.h5')\n\n# LOAD MODEL\nfrom keras.models import load_model\nmodel = load_model('UNET.h5',custom_objects={'dice_coef':dice_coef})\n\n# PREDICT 1 BATCH TEST DATASET\ntest = pd.read_csv(path + 'sample_submission.csv')\ntest['ImageId'] = test['ImageId_ClassId'].map(lambda x: x.split('_')[0])\ntest_batches = DataGenerator(test.iloc[::4],subset='test',batch_size=256,preprocess=preprocess)\ntest_preds = model.predict_generator(test_batches,steps=1,verbose=1)\n\n# NEXT CONVERT MASKS TO RLE, ADD TO CSV, PROCESS REMAINING BATCHES, AND SUBMIT !!","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}