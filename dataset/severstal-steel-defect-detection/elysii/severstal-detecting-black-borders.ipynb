{"cells":[{"metadata":{},"cell_type":"markdown","source":"**About this kernel:**\n--------------\n* This kernel was build to investigate wheter a model can succesfully detect and remove black borders in an image\n* **Step 1:** Create a method to detect black borders in an image\n* **Step 2:** Test the method on our dataset\n* **Step 3:** Compare the predictions to the predictions of the kernel [Severstal: fast.ai 256x256 crops (sub)](https://www.kaggle.com/iafoss/severstal-fast-ai-256x256-crops-sub) of [@iafoss](https://www.kaggle.com/iafoss)\n---------------------"},{"metadata":{},"cell_type":"markdown","source":"The method I use was published in this paper: https://onlinelibrary.wiley.com/doi/pdf/10.1002/srin.201600068?casa_token=oz-tLM6kIB8AAAAA:-WkgQwagLClCpo__XMx2MgbUZNJyeBOgC3840cOYTgQO3lNnOEF2rCmrCPXovO-qxgzzzC41lhY72OA\n\n**The main steps are:**\n* Detect wheter the image contains a black border or not as well as the side it is on, comparing the mean of the right and left side of the image to a threshold\n* Build three lines at 1/4, 1/2 and 3/4 of the image height and use a sliding window to find the x-axis value of the border for each line\n* Build a first order polynomial through the closest x-axis values\n* Based on the side of the border and the polynomial, remove all pixels that belong to a black border\n\n**Changes:**\n* I compare only the mean of 1/8 of the right and 1/8 of the left side of the image to a threshold, since a border can only appear on one of the sides\n* Since three lines seemed to be pretty unstable, I use the sum of all lines to 1/4 of the image height for the first line, all lines form 1/4 to 3/4 for the second and all lines from 3/4 to the end for the third line.\n\n**Notes:**\n* I have tried different thresholds and window sizes and t=15, w=100 seem to work well. The threshold is now roughly 1.5 standard deviations away from the mean.\n* ** Feel free to use this method on your models, share your results or give me feedback for this kernel**\n-----------------"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%%capture\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Methods:**\n------------"},{"metadata":{"trusted":true},"cell_type":"code","source":"# taken from https://www.kaggle.com/xhlulu/severstal-simple-keras-u-net-boilerplate\ndef mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle2mask(mask_rle, shape=(256,1600)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape)\n\ndef build_masks(rles, input_shape):\n    depth = len(rles)\n    height, width = input_shape\n    masks = np.zeros((height, width, depth))\n    \n    for i, rle in enumerate(rles):\n        if type(rle) is str:\n            masks[:, :, i] = rle2mask(rle, (width, height))\n    \n    return masks\n\ndef build_rles(masks):\n    width, height, depth = masks.shape\n    \n    rles = [mask2rle(masks[:, :, i])\n            for i in range(depth)]\n    \n    return rles","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def boundary_detection(image, old_mask, t=15, window_size=100):\n    gl = np.mean(image[:,:int(image.shape[1]/8)])\n    gr = np.mean(image[:,int(image.shape[1]*7/8):])\n    if gl<=t and gr>t:\n        mode = 'left'\n    elif gl>t and gr<=t:\n        mode = 'right'\n    elif gl>t and gr>t:\n        return old_mask\n    elif gl<=t and gr<=t:\n        return np.zeros(image.shape)\n    \n    #img_row_sum = np.sum(image, axis=0)\n    l0 = np.sum(image[:int(image.shape[0]/4)], axis=0)\n    l1 = np.sum(image[int(image.shape[0]/4):int(image.shape[0]/4*2)], axis=0)\n    l2 = np.sum(image[int(image.shape[0]/4/2):int(image.shape[0]/4*3)], axis=0)\n    \n    b0 = np.argmax([abs(sum(l0[i-window_size:i])-sum(l0[i+1:window_size+i+1])) for i in range(window_size,int((len(l0)-window_size*2)))]) + window_size\n    b1 = np.argmax([abs(sum(l1[i-window_size:i])-sum(l1[i+1:window_size+i+1])) for i in range(window_size,int((len(l1)-window_size*2)))]) + window_size\n    b2 = np.argmax([abs(sum(l2[i-window_size:i])-sum(l2[i+1:window_size+i+1])) for i in range(window_size,int((len(l2)-window_size*2)))]) + window_size\n    d01 = np.linalg.norm(np.array([b0,int(image.shape[0]/4)])-np.array([b1,int(image.shape[0]/4*2)]))\n    d12 = np.linalg.norm(np.array([b1,int(image.shape[0]/4*2)])-np.array([b2,int(image.shape[0]/4*3)]))\n    \n    if np.argmin([d01,d12]) == 0:\n        coefficients = np.polyfit(np.array([int(image.shape[0]/4),int(image.shape[0]/4*2)]),np.array([b0,b1]), 1)\n    elif np.argmin([d01,d12]) == 1:\n        coefficients = np.polyfit(np.array([int(image.shape[0]/4*2),int(image.shape[0]/4*3)]),np.array([b1,b2]), 1)\n    polynomial = np.poly1d(coefficients)\n    \n    x_axis = [int(polynomial[0]+polynomial[1]*i) for i in range(image.shape[0])]\n    mask = []\n    if mode == 'left':\n        for i in range(image.shape[0]):\n            mask.append([old_mask[i][j] if x_axis[i]<=j else 0 for j in range(image.shape[1])])\n    elif mode == 'right':\n        for i in range(image.shape[0]):\n            mask.append([old_mask[i][j] if x_axis[i]>=j else 0 for j in range(image.shape[1])])\n    return mask","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-----------------"},{"metadata":{},"cell_type":"markdown","source":"**Evaluation:**\n----------------\n* Read the original dataset\n* Detect boundaries using the method above\n* Visualize detected boundaries"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.read_csv('../input/severstal-steel-defect-detection/sample_submission.csv')\nsubmission_df['ImageId'] = submission_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\nsubmission_df['ClassId'] = submission_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\nsubmission_df = submission_df.fillna('')\nprint(submission_df.shape)\nsubmission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/severstal-steel-defect-detection/test_images/'\nencoded = []\nfor i, filename in enumerate(tqdm(submission_df['ImageId'].unique()[0:100])):\n    img_path = f\"{path}/{filename}\"\n    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    mask = boundary_detection(img,np.ones(img.shape),15,100)\n    rle = mask2rle(np.array(mask))\n    encoded.append(rle)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, filename in enumerate(submission_df['ImageId'].unique()[0:100]):\n    img_path = f\"{path}/{filename}\"\n    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    new_mask = rle2mask(encoded[i],(1600,256)).T\n    plt.figure(figsize=(25, 2))\n    plt.subplot(131)\n    plt.imshow(img, 'gray',vmin=0,vmax=255)\n    img_row_sum = np.sum(img,axis=0).tolist()\n    plt.subplot(132)\n    plt.plot(img_row_sum)\n    plt.subplot(133)\n    plt.imshow(img, 'gray')\n    plt.imshow(np.array(new_mask)*255, 'brg', alpha=0.25, vmin=0,vmax=255)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-----------------"},{"metadata":{},"cell_type":"markdown","source":"**Inspect a real model:**\n---------------\n* Load predictions of the kernel [Severstal: fast.ai 256x256 crops (sub)](https://www.kaggle.com/iafoss/severstal-fast-ai-256x256-crops-sub) of [@iafoss](https://www.kaggle.com/iafoss)\n* Detect differences between the predictions of [@iafoss] and our method\n* Visualize the differences"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.read_csv('../input/severstal-fast-ai-256x256-crops-sub/submission.csv')\nsubmission_df['ImageId'] = submission_df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\nsubmission_df['ClassId'] = submission_df['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\nsubmission_df = submission_df.fillna('')\nprint(submission_df.shape)\nsubmission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/severstal-steel-defect-detection/test_images/'\nencoded = []\nfor i, filename in enumerate(tqdm(submission_df['ImageId'])):\n    if submission_df.iloc[i]['EncodedPixels']!='':\n        img_path = f\"{path}/{filename}\"\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        old_mask = rle2mask(submission_df.iloc[i]['EncodedPixels'],(1600,256)).T\n        mask = boundary_detection(img,old_mask,15,100)\n        rle = mask2rle(np.array(mask))\n        encoded.append(rle)\n    else:\n        encoded.append('')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df['EncodedPixels_New'] = encoded\ndiff_df = submission_df[submission_df['EncodedPixels_New']!=submission_df['EncodedPixels']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, filename in enumerate(diff_df['ImageId'].unique()):\n    img_path = f\"{path}/{filename}\"\n    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    old_mask = rle2mask(diff_df.iloc[i]['EncodedPixels'],(1600,256)).T\n    new_mask = rle2mask(diff_df.iloc[i]['EncodedPixels_New'],(1600,256)).T\n    plt.figure(figsize=(25, 2))\n    plt.subplot(151)\n    plt.imshow(img, 'gray',vmin=0,vmax=255)\n    img_row_sum = np.sum(img,axis=0).tolist()\n    plt.subplot(152)\n    plt.plot(img_row_sum)\n    plt.subplot(153)\n    plt.imshow(img, 'gray')\n    plt.imshow(np.array(old_mask)*255, 'brg', alpha=0.25)\n    plt.subplot(154)\n    plt.imshow(img, 'gray')\n    plt.imshow(np.array(new_mask)*255, 'brg', alpha=0.25)\n    plt.subplot(155)\n    plt.imshow(img, 'gray')\n    plt.imshow(np.array(old_mask)*255-np.array(new_mask)*255, 'brg', alpha=0.25)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"------------------"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"**Insights:**\n---------------\n* The implemented method can successfully detect black borders in the dataset\n* The model of [@iafoss](https://www.kaggle.com/iafoss) has no problem detecting black borders"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}