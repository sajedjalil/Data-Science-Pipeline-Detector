{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this kernel we'll train a simple ResNet-34 model using FastAI. This combined with following tricks achieved a score of 0.88+ on LB and I was briefly in top 15 for some time. Which is wonderful considering how simple the code is. \n\n* Use binary classifier to predict defect vs no-defect. Like [this](https://www.kaggle.com/xhlulu/severstal-simple-2-step-pipeline) kernel. \n* Use TTA (FastAI has a wonderful TTA module). \n* Use connected component filter using OpenCV. Thanks to [this](https://www.kaggle.com/rishabhiitbhu/unet-pytorch-inference-kernel) kernel for inspiration. \n* Don't normalize images with imagenet stats: I did this because after visualizing the images most of them were completely black and there was no way the model would learn recognizing masks out of a completely blank picture. So did I just pass a non-preprocessed image to a pretrained model? Yes! and also closed my eyes and prayed BatchNormalization will prevent covariate shift and do the trick: which it did! I might be wrong here in this assumption here but I got good results by not normalizing the images. \n\nI am sharing this kernel since there are some FastAI specific things you ought to do which might not be straight forward to a beginner. Hope you learn something out of this."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom fastai import * \nfrom fastai.vision import *\nimgsz = (256, 1600)\ntoy = False\nbs = 4\npath = Path(\"../input/severstal-steel-defect-detection\")\ntestfolder = path/\"test_images\"\n!mkdir -p /tmp/.cache/torch/checkpoints/\n!cp /kaggle/input/resnet34/resnet34.pth /tmp/.cache/torch/checkpoints/resnet34-333f7ec4.pth","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import fastai\n\ndef transform(self, tfms:Optional[Tuple[TfmList,TfmList]]=(None,None), **kwargs):\n    if not tfms: tfms=(None,None)\n    assert is_listy(tfms) and len(tfms) == 2\n    self.train.transform(tfms[0], **kwargs)\n    self.valid.transform(tfms[1], **kwargs)\n    kwargs['tfm_y'] = False # Test data has no labels\n    if self.test: self.test.transform(tfms[1], **kwargs)\n    return self\n\nfastai.data_block.ItemLists.transform = transform\n\n# change csv so that it has image_id on one column and rles in the 4 others\ndef change_csv(old):\n    df = pd.read_csv(old)\n\n    def group_func(df, i):\n        reg = re.compile(r'(.+)_\\d$')\n        return reg.search(df['ImageId_ClassId'].loc[i]).group(1)\n    group = df.groupby(lambda i: group_func(df, i))\n    df = group.agg({'EncodedPixels': lambda x: list(x)})\n    df['ImageId'] = df.index\n    df = df.reset_index(drop=True)\n    df[[f'EncodedPixels_{k}' for k in range(1, 5)]] = pd.DataFrame(df['EncodedPixels'].values.tolist())\n    df = df.drop(columns='EncodedPixels')\n    df = df.dropna(subset=[\"EncodedPixels_1\", \"EncodedPixels_2\", \"EncodedPixels_3\", \"EncodedPixels_4\"], how=\"all\")\n    df = df.fillna(value=' ') \n    return df\n\nclass MultiClassSegList(SegmentationLabelList):\n    def open(self, id_rles):\n        image_id, rles = id_rles[0], id_rles[1:]\n        shape = open_image(self.path/image_id).shape[-2:]       \n        final_mask = torch.zeros((1, *shape))\n        for k, rle in enumerate(rles):\n            if isinstance(rle, str):\n                mask = open_mask_rle(rle, shape).px.permute(0, 2, 1)\n                final_mask += (k + 1) * mask\n        return ImageSegment(final_mask)\n\ndef load_data(path, df):\n    train_list = (SegmentationItemList\n                  .from_df(df, path=path/\"train_images\")\n                  .split_by_rand_pct(valid_pct=0.2)\n                  .label_from_df(cols=list(range(5)), label_cls=MultiClassSegList, classes=[0, 1, 2, 3, 4])\n                  .add_test(testfolder.ls(), label=None)\n                  .transform(get_transforms(flip_vert=True), size=imgsz, tfm_y=True)\n                  .databunch(bs=bs, num_workers=0))\n    return train_list\n\ndef dice(input:Tensor, targs:Tensor, eps:float=1e-8)->Rank0Tensor:\n    input = input.clone()\n    targs = targs.clone()\n    n = targs.shape[0]\n    input = torch.softmax(input, dim=1).argmax(dim=1)\n    input = input.view(n, -1)\n    targs = targs.view(n, -1)\n    input[input == 0] = -999\n    intersect = (input == targs).sum().float()\n    union = input[input > 0].sum().float() + targs[targs > 0].sum().float()\n    del input, targs\n    gc.collect()\n    return ((2.0 * intersect + eps) / (union + eps)).mean()\n\ndef visualize_one(a, b, c, title):\n    fig, ax = plt.subplots(3, 1, figsize=(15, 7))\n    ax[0].set_title(title)\n    ax[0].imshow(a.permute(1, 2, 0))\n    ax[1].imshow(b.squeeze(), vmin=0, vmax=4)\n    ax[2].imshow(c.squeeze(), vmin=0, vmax=4)\n    ax[0].set_axis_off()\n    ax[1].set_axis_off()\n    ax[2].set_axis_off()\n    plt.show()\n    \ndef visualize_some():\n    n_batch = 0\n    for batch in learn.data.train_dl:\n        x, y = batch\n        n_batch += 1\n        if n_batch > 8:\n            break\n        for idx in range(bs):\n            predimg, pred, _ = learn.predict(Image(x[idx].cpu()))\n            visualize_one(x[idx], y[idx], pred, f\"Index: {idx}\")\n    plt.tight_layout()\n    \ndef print_stats(learn):\n    print(\"Plotting Losses\")\n    learn.recorder.plot_losses()\n    print(\"Plotting metrics\")\n    learn.recorder.plot_metrics()\n    print(\"Plotting LR\")\n    learn.recorder.plot_lr()\n    print(\"Validation losses\")\n    print(learn.recorder.val_losses)\n    print(\"Metrics\")\n    print(learn.recorder.metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = change_csv(path/\"train.csv\")\nif toy:\n    df = df.sample(200)\ndata = load_data(path, df)\ndel df\nimport gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = unet_learner(data, models.resnet34, metrics=[dice], model_dir=\"/kaggle/working\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(7, max_lr=slice(1e-5, 1e-3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save(\"resnet34-stage1\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(6, max_lr=slice(1e-6, 1e-4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save(\"resnet34-stage2\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"visualize_some()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot_lr(show_moms=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot_metrics()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_stats(learn)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}