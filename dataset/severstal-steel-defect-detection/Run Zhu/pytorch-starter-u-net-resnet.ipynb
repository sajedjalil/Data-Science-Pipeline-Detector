{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Steel Defect Detection \n\nThis is basic kernel to start participating in this competition.\nIt shows how to use PyTorch for solving the segmentation problem.\nIf you prefer to use Keras, I also created others basic Kernels: \n1. https://www.kaggle.com/ateplyuk/keras-starter-segmentation\n1. https://www.kaggle.com/ateplyuk/keras-starter-u-net"},{"metadata":{},"cell_type":"markdown","source":"Architecture of Model is U-Net with pretrained encoder. In our case it ResNet18.\n\n![](https://github.com/ushur/Severstal-Steel-Defect-Detection/blob/master/unet.jpg?raw=true)"},{"metadata":{},"cell_type":"markdown","source":"### Import necessary libraries"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nfrom tqdm import tqdm_notebook\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim \nimport torchvision\nfrom torchvision import models\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.utils.data as utils\nfrom torchvision import transforms\nimport torch.nn.functional as F","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Read train dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/severstal-steel-defect-detection/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr = pd.read_csv(path + 'train.csv')\nprint(len(tr))\ntr.head(6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### To simplify and speed up process, n this kernel I use only images with ClassId=4"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = tr[tr['EncodedPixels'].notnull()].reset_index(drop=True)\ndf_train = df_train[df_train['ImageId_ClassId'].apply(lambda x: x.split('_')[1] == '4')].reset_index(drop=True)\nprint(len(df_train))\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decode mask"},{"metadata":{"trusted":true},"cell_type":"code","source":"def rle2mask(rle, imgshape):\n    width = imgshape[0]\n    height= imgshape[1]\n    \n    mask= np.zeros( width*height ).astype(np.uint8)\n    \n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n        current_position += lengths[index]\n        \n    return np.flipud( np.rot90( mask.reshape(height, width), k=1 ) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Display some images"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = 1\nrows = 4\nfig = plt.figure(figsize=(20,columns*rows+6))\nfor i in range(1,columns*rows+1):\n    fn = df_train['ImageId_ClassId'].str[:-2].iloc[i]\n    fig.add_subplot(rows, columns, i).set_title(fn)\n    img = cv2.imread( path + 'train_images/'+fn )\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    mask = rle2mask(df_train['EncodedPixels'].iloc[i], (256, 1600))\n    img[mask==1,0] = 255\n    plt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create train Dataset and DataLoader"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ImageData(Dataset):\n    def __init__(self, df, transform, subset=\"train\"):\n        super().__init__()\n        self.df = df\n        self.transform = transform\n        self.subset = subset\n        \n        if self.subset == \"train\":\n            self.data_path = path + 'train_images/'\n        elif self.subset == \"test\":\n            self.data_path = path + 'test_images/'\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):                      \n        fn = self.df['ImageId_ClassId'].iloc[index].split('_')[0]         \n        img = Image.open(self.data_path + fn)\n        img = self.transform(img)\n\n        if self.subset == 'train': \n            mask = rle2mask(self.df['EncodedPixels'].iloc[index], (256, 1600))\n            mask = transforms.ToPILImage()(mask)            \n            mask = self.transform(mask)\n            return img, mask\n        else: \n            mask = None\n            return img       ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_transf = transforms.Compose([\n                                  transforms.Scale((256, 256)),\n                                  transforms.ToTensor()])\ntrain_data = ImageData(df = df_train, transform = data_transf)\ntrain_loader = DataLoader(dataset = train_data, batch_size=4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Show some image and mask"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(train_data[3][0].permute(1, 2, 0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(np.squeeze(train_data[3][1].permute(1, 2, 0)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create U-Net Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def convrelu(in_channels, out_channels, kernel, padding):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n# copied from 682\n# model = nn.Sequential(\n#     nn.Conv2d(3, 64, 3, padding=1, stride=1),\n#     nn.BatchNorm2d(64),\n#     nn.ELU(),\n#     nn.Conv2d(64, 64, 3, padding=1, stride=1),\n#     nn.BatchNorm2d(64),\n#     nn.ELU(),\n#     nn.MaxPool2d(2), #32/2\n        nn.ReLU(inplace=True),\n    )\n\nclass UNet(nn.Module):\n    def __init__(self, n_class):\n        super().__init__()\n        \n        self.base_model = models.resnet18()\n        self.base_model.load_state_dict(torch.load(\"../input/resnet18/resnet18.pth\"))\n        self.base_layers = list(self.base_model.children())\n\n        self.layer0 = nn.Sequential(*self.base_layers[:3])\n        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n        self.layer1 = nn.Sequential(*self.base_layers[3:5])\n        self.layer1_1x1 = convrelu(64, 64, 1, 0)\n        self.layer2 = self.base_layers[5]\n        self.layer2_1x1 = convrelu(128, 128, 1, 0)\n        self.layer3 = self.base_layers[6]\n        self.layer3_1x1 = convrelu(256, 256, 1, 0)\n        self.layer4 = self.base_layers[7]\n        self.layer4_1x1 = convrelu(512, 512, 1, 0)\n\n        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n\n        self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n        self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n        self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n\n        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n\n        self.conv_last = nn.Conv2d(64, n_class, 1)\n\n    def forward(self, input):\n        x_original = self.conv_original_size0(input)\n        x_original = self.conv_original_size1(x_original)\n\n        layer0 = self.layer0(input)\n        layer1 = self.layer1(layer0)\n        layer2 = self.layer2(layer1)\n        layer3 = self.layer3(layer2)\n        layer4 = self.layer4(layer3)\n\n        layer4 = self.layer4_1x1(layer4)\n        x = self.upsample(layer4)\n        layer3 = self.layer3_1x1(layer3)\n        x = torch.cat([x, layer3], dim=1)\n        x = self.conv_up3(x)\n\n        x = self.upsample(x)\n        layer2 = self.layer2_1x1(layer2)\n        x = torch.cat([x, layer2], dim=1)\n        x = self.conv_up2(x)\n\n        x = self.upsample(x)\n        layer1 = self.layer1_1x1(layer1)\n        x = torch.cat([x, layer1], dim=1)\n        x = self.conv_up1(x)\n\n        x = self.upsample(x)\n        layer0 = self.layer0_1x1(layer0)\n        x = torch.cat([x, layer0], dim=1)\n        x = self.conv_up0(x)\n\n        x = self.upsample(x)\n        x = torch.cat([x, x_original], dim=1)\n        x = self.conv_original_size2(x)\n\n        out = self.conv_last(x)\n\n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = UNet(n_class=1).cuda()\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.SGD(model.parameters(), weight_decay=1e-4, lr = 0.001, momentum=0.9)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfor epoch in range(5):      \n    model.train()         \n    for ii, (data, target) in enumerate(train_loader):                         \n        data, target = data.cuda(), target.cuda()\n        optimizer.zero_grad()\n        output = model(data)  \n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()          \n    print('Epoch: {} - Loss: {:.6f}'.format(epoch + 1, loss.item()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Show prediction on image from train dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(train_data[6][0].permute(1, 2, 0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = train_data[6][0].unsqueeze(0)\no = model(x.cuda())  \no = o.cpu().detach().numpy() * (-1)\ntmp = np.copy(o)\nmn = np.mean(o)*1.2\ntmp[tmp<mn] = 0\ntmp[tmp>mn] = 1\nplt.imshow(np.squeeze(tmp))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Read submit file"},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = pd.read_csv(path + 'sample_submission.csv', converters={'EncodedPixels': lambda e: ' '})\nprint(len(submit))\nsub4 = submit[submit['ImageId_ClassId'].apply(lambda x: x.split('_')[1] == '4')]\nprint(len(sub4))\nsub4.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create test Dataset and DataLoader"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = ImageData(df = sub4, transform = data_transf, subset=\"test\")\ntest_loader = DataLoader(dataset = test_data, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\npredict = []\nmodel.eval()\nfor data in test_loader:\n    data = data.cuda()\n    output = model(data)  \n    output = output.cpu().detach().numpy() * (-1)    \n    predict.append(abs(output[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Encode mask "},{"metadata":{"trusted":true},"cell_type":"code","source":"def mask2rle(img):\n    tmp = np.rot90( np.flipud( img ), k=3 )\n    rle = []\n    lastColor = 0;\n    startpos = 0\n    endpos = 0\n\n    tmp = tmp.reshape(-1,1)   \n    for i in range( len(tmp) ):\n        if (lastColor==0) and tmp[i]>0:\n            startpos = i\n            lastColor = 1\n        elif (lastColor==1)and(tmp[i]==0):\n            endpos = i-1\n            lastColor = 0\n            rle.append( str(startpos)+' '+str(endpos-startpos+1) )\n    return \" \".join(rle)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Resize images"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\npred_rle = []\n  \nfor p in predict:        \n    img = np.copy(p)\n    mn = np.mean(img)*1.2\n    img[img<=mn] = 0\n    img[img>mn] = 1\n    img = cv2.resize(img[0], (1600, 256))\n    \n    pred_rle.append(mask2rle(img))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prepare submission file"},{"metadata":{"trusted":true},"cell_type":"code","source":"submit['EncodedPixels'][submit['ImageId_ClassId'].apply(lambda x: x.split('_')[1] == '4')] = pred_rle\nsubmit.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_s = cv2.imread( path + 'test_images/'+ submit['ImageId_ClassId'][47].split('_')[0])\nplt.imshow(img_s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_s = rle2mask(submit['EncodedPixels'][47], (256, 1600))\nplt.imshow(mask_s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}