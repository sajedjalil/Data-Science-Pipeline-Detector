{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn\nimport os\nimport torch\nimport numpy as np\nimport pandas as pd\nimport csv\nimport glob\nimport sys\nimport math\nimport torch  \nimport torch.nn as nn\nimport time\nclass UNet_down_block(torch.nn.Module):\n    def __init__(self, input_channel, output_channel, down_size):\n        super(UNet_down_block, self).__init__()\n        self.conv1 = torch.nn.Conv2d(input_channel, output_channel, 3, padding=1)\n        self.bn1 = torch.nn.BatchNorm2d(output_channel)\n        self.conv2 = torch.nn.Conv2d(output_channel, output_channel, 3, padding=1)\n        self.bn2 = torch.nn.BatchNorm2d(output_channel)\n        self.conv3 = torch.nn.Conv2d(output_channel, output_channel, 3, padding=1)\n        self.bn3 = torch.nn.BatchNorm2d(output_channel)\n        self.max_pool = torch.nn.MaxPool2d(2, 2)\n        self.relu = torch.nn.ReLU()\n        self.down_size = down_size\n        self.elu = torch.nn.ELU()\n\n\n    def forward(self, x):\n        if self.down_size:\n            x = self.max_pool(x)\n        x = self.elu(self.bn1(self.conv1(x)))\n        x = self.elu(self.bn2(self.conv2(x)))\n        #x = self.relu(self.bn3(self.conv3(x)))\n        return x\n\nclass UNet_up_block(torch.nn.Module):\n    def __init__(self, prev_channel, input_channel, output_channel):\n        super(UNet_up_block, self).__init__()\n        #self.up_sampling = torch.nn.Upsample(scale_factor=2, mode='bilinear',align_corners=False)\n        self.up_sampling = torch.nn.ConvTranspose2d(input_channel,input_channel, 2,stride = 2)\n        self.conv1 = torch.nn.Conv2d(prev_channel + input_channel, output_channel, 3, padding=1)\n        self.bn1 = torch.nn.BatchNorm2d(output_channel)\n        self.conv2 = torch.nn.Conv2d(output_channel, output_channel, 3, padding=1)\n        self.bn2 = torch.nn.BatchNorm2d(output_channel)\n        self.conv3 = torch.nn.Conv2d(output_channel, output_channel, 3, padding=1)\n        self.bn3 = torch.nn.BatchNorm2d(output_channel)\n        self.relu = torch.nn.ReLU()\n        self.elu = torch.nn.ELU()\n\n    def forward(self, prev_feature_map, x):\n        x = self.up_sampling(x)\n        x = torch.cat((x, prev_feature_map), dim=1)\n        x = self.elu(self.bn1(self.conv1(x)))\n        x = self.elu(self.bn2(self.conv2(x)))\n        #x = self.relu(self.bn3(self.conv3(x)))\n        return x\n\n\nclass UNet(torch.nn.Module):\n    def __init__(self):\n        super(UNet, self).__init__()\n\n        self.down_block1 = UNet_down_block(1, 8, False)\n        self.down_block2 = UNet_down_block(8, 16, True)\n        self.down_block3 = UNet_down_block(16, 32, True)\n        self.down_block4 = UNet_down_block(32, 64, True)\n        self.down_block5 = UNet_down_block(64, 128, True)\n\n        self.mid_conv1 = torch.nn.Conv2d(128, 128, 3, padding=1)\n        self.bn1 = torch.nn.BatchNorm2d(128)\n        self.mid_conv2 = torch.nn.Conv2d(128, 128, 3, padding=1)\n        self.bn2 = torch.nn.BatchNorm2d(128)\n        self.mid_conv3 = torch.nn.Conv2d(128, 128, 3, padding=1)\n        self.bn3 = torch.nn.BatchNorm2d(128)\n\n        self.up_block1 = UNet_up_block(64, 128, 64)\n        self.up_block2 = UNet_up_block(32, 64, 32)\n        self.up_block3 = UNet_up_block(16, 32, 16)\n        self.up_block4 = UNet_up_block(8, 16, 8)\n\n\n        self.last_conv1 = torch.nn.Conv2d(8, 8, 3, padding=1)\n        self.last_bn = torch.nn.BatchNorm2d(8)\n        self.last_conv2 = torch.nn.Conv2d(8, 4, 1, padding=0)\n        self.relu = torch.nn.ReLU()\n        self.sigmoid = torch.nn.Sigmoid()\n        self.elu = torch.nn.ELU()\n\n    def forward(self, x):\n        self.x1 = self.down_block1(x)\n        self.x2 = self.down_block2(self.x1)\n        self.x3 = self.down_block3(self.x2)\n        self.x4 = self.down_block4(self.x3)\n        self.x5 = self.down_block5(self.x4)\n        self.x5 = self.elu(self.bn1(self.mid_conv1(self.x5)))\n        self.x5 = self.elu(self.bn2(self.mid_conv2(self.x5)))\n        #self.x5 = self.relu(self.bn3(self.mid_conv3(self.x5)))\n        x = self.up_block1(self.x4, self.x5)\n        x = self.up_block2(self.x3, x)\n        x = self.up_block3(self.x2, x)\n        x = self.up_block4(self.x1, x)\n        x = self.elu(self.last_bn(self.last_conv1(x)))\n        x = self.last_conv2(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SteelDataset(torch.utils.data.Dataset):\n\n\tdef __init__(self,folder, pathlist, labeled , Y_dict = None ,transform = None):\n\n\t\tself.labeled = labeled\n\t\tself.X_path = pathlist\n\t\tself.folder = folder\n\t\tif self.labeled:\n\t\t\tself.Y_dict = Y_dict\n\t\t#self.X_test_path = get_data_path(test_folder)\n\n\tdef __len__(self):\n\t\treturn len(self.X_path)\n\n\tdef __getitem__(self, idx):\n\t\tpath = self.X_path[idx]\n\t\ttry:\n\t\t\tX = get_img(self.folder + '/' + path)\n\t\t\timg = torch.FloatTensor(X).view(1,256,1600)\n\t\texcept:\n\t\t\tprint(self.X_path)\n\t\t\tprint(idx)\n\t\t\tprint(self.X_path[idx])\n\t\t\tprint(path)\n\n\n\t\tif self.labeled:\n\t\t\tlabels = (np.zeros([4,256,1600]))\n\t\t\tif path in self.Y_dict:\n\t\t\t\tfor classID in range(4):\n\t\t\t\t\tlabels[classID,:,:] = rle2mask((self.Y_dict[path])[classID])\n\t\t\tlabel = torch.FloatTensor(labels).view(4,256,1600)\n\t\t\treturn tuple([img , label])\n\t\telse:\n\t\t\treturn tuple([img , path])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n \ndef rle2mask(mask_rle, shape=(1600,256)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sigmoid = nn.Sigmoid()\ndef add_weight_decay(net, l2_value, skip_list=()):\n\tdecay, no_decay = [], []\n\tfor name, param in net.named_parameters():\n\t\tif not param.requires_grad: continue # frozen weights\t\t            \n\t\tif len(param.shape) == 1 or name.endswith(\".bias\") or name in skip_list: no_decay.append(param)\n\t\telse: decay.append(param)\n\treturn [{'params': no_decay, 'weight_decay': 0.}, {'params': decay, 'weight_decay': l2_value}]\n\ndef dice_channel_torch(probability, truth, threshold):\n\tbatch_size = truth.shape[0]\n\tchannel_num = truth.shape[1]\n\tmean_dice_channel = 0.\n\twith torch.no_grad():\n\t\tfor i in range(batch_size):\n\t\t\tfor j in range(channel_num):\n\t\t\t\tchannel_dice = dice_single_channel(probability[i, j,:,:], truth[i, j, :, :], threshold[j])\n\t\t\t\tmean_dice_channel += channel_dice/(batch_size * channel_num)\n\treturn mean_dice_channel\n\n\ndef dice_single_channel(probability, truth, threshold, eps = 1E-9):\n\tp = (probability.view(-1) > threshold).float()\n\tt = (truth.view(-1) > 0.5).float()\n\tdice = (2.0 * (p * t).sum() + eps)/ (p.sum() + t.sum() + eps)\n\treturn dice\n\ndef run_length_decode(rle, height=256, width=1600, fill_value=1):\n\tmask = np.zeros((height,width), np.float32)\n\tif rle != '':\n\t\tmask=mask.reshape(-1)\n\t\tr = [int(r) for r in rle.split(' ')]\n\t\tr = np.array(r).reshape(-1, 2)\n\t\tfor start,length in r:\n\t\t\tstart = start-1  #???? 0 or 1 index ???\n\t\t\tmask[start:(start + length)] = fill_value\n\t\tmask=mask.reshape(width, height).T\n\treturn mask\n\ndef run_length_encode(mask):\n#possible bug for here\n\tm = mask.T.flatten()\n\tif m.sum()==0:\n\t\trle=''\n\telse:\n\t\tm   = np.concatenate([[0], m, [0]])\n\t\trun = np.where(m[1:] != m[:-1])[0] + 1\n\t\trun[1::2] -= run[::2]\n\t\trle = ' '.join(str(r) for r in run)\n\treturn rle\n\n\ndef dice_loss( y_pred,y_true):\n\tweight = [1,1,1,1]\n\tsmooth = 1e-9\n\ty_pred = sigmoid(y_pred)\n\ty_true_f = y_true.view(-1,4,256,1600)\n\ty_pred_f = y_pred.view(-1,4,256,1600)\n\tscore = 0\n\tbatch_size = y_true_f.shape[0]\n\tchannel_num = y_true_f.shape[1]\n\tfor i in range(batch_size):\n\t\tfor j in range(channel_num):\n\t\t\tintersection = y_true_f[i,j,:,:] * y_pred_f[i,j,:,:] \n\t\t\tscore += weight[j] * ( (2. * intersection.sum() + smooth) / (y_true_f[i,j,:,:].sum() + y_pred_f[i,j,:,:].sum() + smooth) ) \n\tscore /= (batch_size )\n\treturn - score\n\ndef bce_dice_loss( y_pred,y_true):\n\treturn weighted_bceloss(y_pred,y_true) + dice_loss(y_pred,y_true)\n\ndef weighted_bceloss(y_pred,y_true):\n\tweight = [1,1,1,1]\n\tloss = 0\n    \n\tfor c in range(4):\n\t\tloss += bceloss(y_pred[:,c,:,:] ,y_true[:,c,:,:]) * weight[c] \n\treturn loss ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import pyvips\nfrom PIL import Image\n#from utils import *\n#from Unet.py import *\ndef get_data_path(folder):\n\tX_path = []\n\t#print(os.listdir(folder))\n\tfor filename in (os.listdir(folder)):\n\t\t#print(filename)\n\t\tX_path.append(filename)\n\n\tX_path = np.array(X_path)\n\treturn X_path\n\ndef get_label(path):\n\tdf = pd.read_csv(path)\n\tYdict = {}\n\tfor image_id in df.ImageId.unique():\n\t\trle = [\n\t\t\tdf.loc[ (df['ImageId']==image_id) & (df['ClassId'] == 1) , 'EncodedPixels'].values,\n\t\t\tdf.loc[ (df['ImageId']==image_id) & (df['ClassId'] == 2) , 'EncodedPixels'].values,\n\t\t\tdf.loc[ (df['ImageId']==image_id) & (df['ClassId'] == 3) , 'EncodedPixels'].values,\n\t\t\tdf.loc[ (df['ImageId']==image_id) & (df['ClassId'] == 4) , 'EncodedPixels'].values\n\t\t]\n\t\tfor classID in range(4):\n\t\t\tif len(rle[classID]) == 0:\n\t\t\t\trle[classID] = ''\n\t\t\telse:\n\t\t\t\trle[classID] = rle[classID][0]\n\n\t\t#print(y[0])\n\t\t#print(y[1])\n\t\t#print(y[2])\n\t\tYdict[image_id ] =  rle\n\tdel df\n\treturn Ydict \n\n\ndef get_img(path):\n\twith Image.open(path) as f:\n\t\timg = np.array(list(f.getdata()))\n\tf.close()\n\t#print('img shape',len(img),img[:,1])\n\treturn img[:,1].reshape(256,1600)\n\n\ndef valid_test(epoch):\n\tmodel.eval()\n\tbatch_size = 10\n\tTotaldice = 0\n\tTotalloss = 0\n\tfor i , (batch_x,batch_y) in enumerate(validloader):\n\t\tbatch_x = batch_x.cuda() \n\t\tbatch_y = batch_y.cuda()\n\t\tpV =  model(batch_x)\n\t\tloss = weighted_bceloss(pV,batch_y).item()\n\t\t#loss = bce_dice_loss(pV,batch_y).item() \n\t\tdice = dice_channel_torch( sigmoid(pV) , batch_y , [0.5,0.5,0.5,0.5] )\n\t\tTotalloss += loss * len(batch_x)\n\t\tTotaldice += dice * len(batch_x)\n\tmeandice = Totaldice / V\n\tmeanloss = Totalloss / V\n\t#print(pV)\n\tprint('epoch:{}   Valid: dice {:.3f} loss: {:.3f}'.format(epoch, meandice,meanloss )) #time.time()-start_time  \n\tmodel.train()\n\treturn meanloss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bceloss = nn.BCEWithLogitsLoss()\nsigmoid = nn.Sigmoid()\n\ntrain_folder = \"../input/severstal-steel-defect-detection/train_images\"\nlabel_path = \"../input/severstal-steel-defect-detection/train.csv\"\n\nX_train_path = get_data_path(train_folder)\nY_train_dict = get_label(label_path)\n\nvalidDataset = SteelDataset(train_folder,X_train_path,labeled=1,Y_dict = Y_train_dict)\n\nV = len(X_train_path)\nvalidloader = torch.utils.data.DataLoader(validDataset , batch_size = 4, shuffle=False,num_workers=4)\nmodel = torch.load(\"../input/model/model2.3.pth\")\nvalid_test(0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"markdown","source":"def Train(model):\n\tepochs = 3\n\tbest = 100\n\tdecay = 1e-4\n\tLR = 0.001\n\t#optim = torch.optim.Adam( add_weight_decay(model,decay) , lr= LR)\n\toptim = torch.optim.Adam( model.parameters(), lr= LR)\n\tprint('train-------------lr:',LR ,'decay:',decay )\n\tmodel.cuda()\n\tfor epoch in range(int(epochs)):\n\t\tmodel.train()\n\t\tfor i , (batch_x , batch_y )in enumerate(trainloader):\n\n\t\t\tbatch_x = batch_x.cuda()\n\t\t\tbatch_y = batch_y.cuda()\n\t\t\t\n\t\t\toptim.zero_grad()\n\t\t\ty_hat = model(batch_x)\n\t\t\tloss = weighted_bceloss(y_hat,batch_y)\n            #loss = bce_dice_loss(y_hat,batch_y)\n\t\t\tloss.backward()\n\t\t\toptim.step()\n\n\t\t\tif i % 100 == 99:\n\t\t\t\tloss = valid_test(epoch)\n\t\t\t\tif loss < best:\n\t\t\t\t\tbest = loss\n\t\t\t\t\tprint(\"saving model with loss: {:.3f}\".format(loss))\n\t\t\t\t\ttorch.save(model, 'model2.pth')\n\nif __name__ == '__main__':\n\t#load = 0\n\tisGPU = torch.cuda.is_available()\n\tprint ('PyTorch GPU device is available: {}'.format(isGPU))\n\ttrain_folder = \"../input/severstal-steel-defect-detection/train_images\"\n\tlabel_path = \"../input/severstal-steel-defect-detection/train.csv\"\n\t\n\t#train_folder , test_folder, label_path = sys.argv[1:]\n\t\n\tX_train_path = get_data_path(train_folder)\n\tY_train_dict = get_label(label_path)\n\t\n        \n\t#print(X_train_path)\n\t#print(Y_train_dict)\n    \n\tV = 100\n\tX_valid_path = X_train_path[:V]\n\tX_train_path = X_train_path[V:]\n\n\ttrainDataset = SteelDataset(train_folder,X_train_path,labeled=1,Y_dict = Y_train_dict)\n\tvalidDataset = SteelDataset(train_folder,X_valid_path,labeled=1,Y_dict = Y_train_dict)\n\n\ttrainloader = torch.utils.data.DataLoader(trainDataset , batch_size = 4, shuffle=True,num_workers=4)\n\tvalidloader = torch.utils.data.DataLoader(validDataset , batch_size = 4, shuffle=False,num_workers=4)\n\n\t#model = UNet()\n\tmodel = torch.load(\"../input/model/model2.3.pth\")\n\tTrain(model)\n\t#Test(model)\n"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"markdown","source":"def Train(model):\n\tepochs = 3\n\tbest = 100\n\tdecay = 1e-4\n\tLR = 0.001\n\t#optim = torch.optim.Adam( add_weight_decay(model,decay) , lr= LR)\n\toptim = torch.optim.Adam( model.parameters(), lr= LR)\n\tprint('train-------------lr:',LR ,'decay:',decay )\n\tmodel.cuda()\n\tfor epoch in range(int(epochs)):\n\t\tmodel.train()\n\t\tfor i , (batch_x , batch_y )in enumerate(trainloader):\n\n\t\t\tbatch_x = batch_x.cuda()\n\t\t\tbatch_y = batch_y.cuda()\n\t\t\t\n\t\t\toptim.zero_grad()\n\t\t\ty_hat = model(batch_x)\n\t\t\tloss = weighted_bceloss(y_hat,batch_y)\n            #loss = bce_dice_loss(y_hat,batch_y)\n\t\t\tloss.backward()\n\t\t\toptim.step()\n\n\t\t\tif i % 100 == 99:\n\t\t\t\tloss = valid_test(epoch)\n\t\t\t\tif loss < best:\n\t\t\t\t\tbest = loss\n\t\t\t\t\tprint(\"saving model with loss: {:.3f}\".format(loss))\n\t\t\t\t\ttorch.save(model, 'model2.pth')\n\nif __name__ == '__main__':\n\t#load = 0\n\tisGPU = torch.cuda.is_available()\n\tprint ('PyTorch GPU device is available: {}'.format(isGPU))\n\ttrain_folder = \"../input/severstal-steel-defect-detection/train_images\"\n\tlabel_path = \"../input/severstal-steel-defect-detection/train.csv\"\n\t\n\t#train_folder , test_folder, label_path = sys.argv[1:]\n\t\n\tX_train_path = get_data_path(train_folder)\n\tY_train_dict = get_label(label_path)\n\t\n        \n\t#print(X_train_path)\n\t#print(Y_train_dict)\n    \n\tV = 100\n\tX_valid_path = X_train_path[:V]\n\tX_train_path = X_train_path[V:]\n\n\ttrainDataset = SteelDataset(train_folder,X_train_path,labeled=1,Y_dict = Y_train_dict)\n\tvalidDataset = SteelDataset(train_folder,X_valid_path,labeled=1,Y_dict = Y_train_dict)\n\n\ttrainloader = torch.utils.data.DataLoader(trainDataset , batch_size = 4, shuffle=True,num_workers=4)\n\tvalidloader = torch.utils.data.DataLoader(validDataset , batch_size = 4, shuffle=False,num_workers=4)\n\n\t#model = UNet()\n\tmodel = torch.load(\"../input/model/model2.3.pth\")\n\tTrain(model)\n\t#Test(model)\n"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"def Test(model):\n\tmodel.eval()\n\t#test_folder = \"../input/severstal-steel-defect-detection/test_images\"\n\t#X_test_path = get_data_path(test_folder)\n\t#X_test_path.sort()\n\tprint(\"X_test size:{}\".format(len(X_test_path)))\n\tprint(X_test_path)\n\ttestDataset = SteelDataset(test_folder,X_test_path,labeled=0)\n\ttestloader = torch.utils.data.DataLoader(testDataset , batch_size = 4, shuffle=False,num_workers=4)\n\toutpath = 'submission.csv'\n\tf=open(outpath,\"w\")\n\tf.write(\"ImageId_ClassId,EncodedPixels\\n\")\n\tthreshhold = [0.5,0.5,0.5,0.5]\n\tfor i , (img,path) in enumerate(testloader):\n\t\tpredlist = sigmoid(model(img.cuda()))\n\t\t#print(len(predlist))\n\t\t#print(predlist)\n\t\tfor n in range(len(predlist)):\n\t\t\t#print(predlist.shape)\n\t\t\tpred = predlist[n]\n\t\t\tfor ClassId in range(0,4):\n\t\t\t\tp = (pred[ClassId].flatten(1) > threshhold[ClassId]).float()\n\t\t\t\tencoded_value = mask2rle(p.cpu())\n\t\t\t\t#if len(encoded_value) > 0:\n\t\t\t\tf.write(\"{}_{},{}\\n\".format(path[n],ClassId + 1,encoded_value ))\n\tf.close()\n\tmodel.train()\n\nif __name__ == '__main__':\n    test_folder = \"../input/severstal-steel-defect-detection/test_images\"\n    X_test_path = get_data_path(test_folder)\n    testDataset = SteelDataset(test_folder,X_test_path,labeled=0)\n    testloader = torch.utils.data.DataLoader(testDataset , batch_size = 4, shuffle=False,num_workers=4)\n\n    model = torch.load(\"../input/model/model2.3.pth\")\n    Test(model)"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"import matplotlib.pyplot as plt\n#model = torch.load(\"../input/model/model2.3.pth\")\nfig, axs = plt.subplots(5, figsize=(12, 12))\n\nsample_img = get_img('../input/severstal-steel-defect-detection/train_images/0025bde0c.jpg')\n#predlist = sigmoid(model(torch.from_numpy(sample_img.astype('float32')).view(-1,1,256,1600).cuda()))\n\nlabel_path = \"../input/severstal-steel-defect-detection/train.csv\"\npath = \"0025bde0c.jpg\"\nY_dict = get_label(label_path)\n\nprint(Y_dict[path])\nlabels = (np.zeros([4,256,1600]))\nfor classID in range(4):\n\trle = (Y_dict[path])[classID]\n\tprint(rle)\n\tlabels[classID,:,:] = rle2mask( (Y_dict[path])[classID] )\n    \npredlist = labels\n\n#print(predlist)\nfor n in range(len(predlist)):\n\tprint(predlist.shape)\n\tpred = predlist[n]\n\tfor ClassId in range(0,4):\n\t\tprint(labels[ClassId].sum())\n\t\t#p = (pred[ClassId].flatten(1) > 0.5).float()\n\t\t#img = np.array(p.cpu()).reshape(256,1600)\n\t\t#encoded_value = mask2rle(p.cpu())\n\t\t\t\t#if len(encoded_value) > 0:\n\t\t#img = rle2mask(encoded_value)\n        #print(img)\n\t\taxs[ClassId+1].imshow(pred)\n\t\taxs[ClassId+1].axis('off')\naxs[0].imshow(sample_img)\naxs[0].axis('off')"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}