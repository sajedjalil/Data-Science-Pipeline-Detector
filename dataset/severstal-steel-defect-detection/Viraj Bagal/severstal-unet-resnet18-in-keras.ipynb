{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1><center><font size=\"6\">SEVERSTAL STEEL </font></center></h1>\n\n\n<img src=\"https://thumbs.dreamstime.com/b/roll-steel-sheet-factory-d-rendering-79415588.jpg\" width=\"800\"></img>\n\n<br>"},{"metadata":{},"cell_type":"markdown","source":"This kernel makes use of **segmentation_models** library for **Keras**. This library makes building segmentation models with different architectures and different backbones really easy. Very friendly for beginners like me ! \n\nBut to progress in this competition it will always help to know the intricacies of model, backbone and various training methods. \nSource of the library : https://github.com/qubvel/segmentation_models\n\n\n**Tip : To change the architecture of the model, just import the particular model from segmentation_models library. The available architectures are FPN, LinkNet, PSPNet. The available backbones are many like ResNets, DenseNets, EfficientNets, etc.** \n\n**If you like the kernel, please upvote it. It motivates me . Happy Kaggling**"},{"metadata":{},"cell_type":"markdown","source":"Some code is borrowed from : https://www.kaggle.com/xhlulu/severstal-simple-2-step-pipeline\n\nThank you xhlulu. All beginners like me are learning a lot from you. "},{"metadata":{},"cell_type":"markdown","source":"# Contents :\n* Importing Libraries\n* Arranging DataSet\n* Utility Functions\n* Building and Training Unet with ResNet18 Backbone\n* Plotting the History of Model"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"pip install segmentation-models","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importing Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport cv2\nimport os\nfrom keras import backend as K\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nimport keras\nimport json\nimport tqdm\nfrom segmentation_models.losses import bce_jaccard_loss\nfrom segmentation_models.metrics import iou_score\nimport gc\nfrom segmentation_models import Unet\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import Sequence\nfrom keras.optimizers import Adam\nimport warnings\nwarnings.filterwarnings('ignore')\nprint(os.listdir('../input'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 2019\nBATCH_SIZE = 8","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Arranging the Dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"traindf = pd.read_csv('../input/severstal-steel-defect-detection/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindf['ImageId'] = traindf['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\ntraindf['ClassId'] = traindf['ImageId_ClassId'].apply(lambda x: x.split('_')[1])\ntraindf['hasMask'] = ~traindf['EncodedPixels'].isna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"traindf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_counts = traindf.groupby('ImageId')['hasMask'].sum().reset_index()\nmask_counts.sort_values(by = 'hasMask', ascending = False).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_counts['hasMask'].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_counts.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_counts = mask_counts.reset_index(drop = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Utility Functions"},{"metadata":{},"cell_type":"markdown","source":"**Taken from** : https://www.kaggle.com/xhlulu/severstal-simple-2-step-pipeline"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"def mask2rle(img):\n    '''\n    img: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef rle2mask(rle, input_shape):\n    width, height = input_shape[:2]\n    \n    mask= np.zeros( width*height ).astype(np.uint8)\n    \n    array = np.asarray([int(x) for x in rle.split()])\n    starts = array[0::2]\n    lengths = array[1::2]\n\n    current_position = 0\n    for index, start in enumerate(starts):\n        mask[int(start):int(start+lengths[index])] = 1\n        current_position += lengths[index]\n        \n    return mask.reshape(height, width).T\n\ndef build_masks(rles, input_shape):\n    depth = len(rles)\n    masks = np.zeros((*input_shape, depth))\n    \n    for i, rle in enumerate(rles):\n        if type(rle) is str:\n            masks[:, :, i] = rle2mask(rle, input_shape)\n    \n    return masks\n\ndef build_rles(masks):\n    width, height, depth = masks.shape\n    \n    rles = [mask2rle(masks[:, :, i])\n            for i in range(depth)]\n    \n    return rles","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DataGenerator on the Fly"},{"metadata":{},"cell_type":"markdown","source":"**Taken from** : https://www.kaggle.com/xhlulu/severstal-simple-2-step-pipeline\n\n**Original work** : https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly"},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, df, target_df=None, mode='fit',\n                 base_path='../input/severstal-steel-defect-detection/train_images',\n                 batch_size=32, dim=(256, 1600), n_channels=3,\n                 n_classes=4, random_state=2019, shuffle=True):\n        self.dim = dim\n        self.batch_size = batch_size\n        self.df = df\n        self.mode = mode\n        self.base_path = base_path\n        self.target_df = target_df\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.random_state = random_state\n        \n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_batch = [self.list_IDs[k] for k in indexes]\n        \n        X = self.__generate_X(list_IDs_batch)\n        \n        if self.mode == 'fit':\n            y = self.__generate_y(list_IDs_batch)\n            return X, y\n        \n        elif self.mode == 'predict':\n            return X\n\n        else:\n            raise AttributeError('The mode parameter should be set to \"fit\" or \"predict\".')\n        \n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.seed(self.random_state)\n            np.random.shuffle(self.indexes)\n    \n    def __generate_X(self, list_IDs_batch):\n        'Generates data containing batch_size samples'\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n        \n        # Generate data\n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            img_path = f\"{self.base_path}/{im_name}\"\n            img = self.__load_rgb(img_path)\n            \n            # Store samples\n            X[i,] = img\n\n        return X\n    \n    def __generate_y(self, list_IDs_batch):\n        y = np.empty((self.batch_size, *self.dim, self.n_classes), dtype=int)\n        \n        for i, ID in enumerate(list_IDs_batch):\n            im_name = self.df['ImageId'].iloc[ID]\n            image_df = self.target_df[self.target_df['ImageId'] == im_name]\n            \n            rles = image_df['EncodedPixels'].values\n            masks = build_masks(rles, input_shape=self.dim)\n            \n            y[i, ] = masks\n\n        return y\n    \n    def __load_grayscale(self, img_path):\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = img.astype(np.float32) / 255.\n        img = np.expand_dims(img, axis=-1)\n\n        return img\n    \n    def __load_rgb(self, img_path):\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = img.astype(np.float32) / 255.\n\n        return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_index = mask_counts.index\ntrn_idx, val_idx = train_test_split(all_index, test_size = 0.2, random_state = seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = DataGenerator(\n    trn_idx, \n    df=mask_counts,\n    target_df=traindf,\n    batch_size=BATCH_SIZE, \n    n_classes=4,\n    random_state = seed\n)\n\nval_generator = DataGenerator(\n    val_idx, \n    df=mask_counts,\n    target_df=traindf,\n    batch_size=BATCH_SIZE, \n    n_classes=4,\n    random_state = seed\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Building and Training Unet with Resnet18 as Backbone"},{"metadata":{},"cell_type":"markdown","source":"Other backbones and architectures can be found here : https://github.com/qubvel/segmentation_models"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Unet('resnet18', classes=4, activation='softmax', input_shape = (256,1600,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Jaccard Loss** : This loss is usefull when you have unbalanced classes within a sample such as segmenting each pixel of an image\n\n**Read more** : https://segmentation-models.readthedocs.io/en/latest/api.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(Adam(lr = 0.005), loss=bce_jaccard_loss, metrics=[iou_score, dice_coef])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint(\n    'Unet_resnet18.h5', \n    monitor='val_loss', \n    verbose=1, \n    save_best_only=True, \n    save_weights_only=False,\n    mode='auto'\n)\n\nreducelr = ReduceLROnPlateau(monitor = 'val_loss', min_lr = 1e-6, factor = 0.1, verbose = 1, patience = 5)\n\nhistory = model.fit_generator(\n    train_generator,\n    validation_data=val_generator,\n    callbacks=[checkpoint, reducelr],\n    use_multiprocessing=True,\n    workers=6,\n    epochs=15\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plotting history of the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('history.json', 'w') as f:\n    json.dump(history.history, f)\n    \n\nhistory_df = pd.DataFrame(history.history)\n\nplt.figure(figsize = (15,5))\nplt.title('Plot of Loss')\nhistory_df[['loss', 'val_loss']].plot()\n\nplt.figure(figsize = (15,5))\nplt.title('Plot of Dice Coefficient')\nhistory_df[['dice_coef', 'val_dice_coef']].plot()\n\nplt.figure(figsize = (15,5))\nplt.title('Plot of IOU score')\nhistory_df[['iou_score', 'val_iou_score']].plot()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}