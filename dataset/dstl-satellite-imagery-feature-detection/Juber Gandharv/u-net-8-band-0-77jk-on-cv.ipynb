{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\nimport pandas as pd\nfrom shapely.wkt import loads as wkt_loads\nimport tifffile as tiff\nimport os\nimport random\nfrom keras import backend as K\nfrom sklearn.metrics import jaccard_similarity_score\n#from sklearn.metrics import jaccard_score\nfrom shapely.geometry import MultiPolygon, Polygon\nimport shapely.wkt\nimport shapely.affinity\nfrom collections import defaultdict\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom keras import backend as keras\nimport gc\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N_Cls = 10\ninDir = '../input/dstl-satellite-imagery-feature-detection'\nDF = pd.read_csv(inDir + '/train_wkt_v4.csv')\nGS = pd.read_csv(inDir + '/grid_sizes.csv', names=['ImageId', 'Xmax', 'Ymin'], skiprows=1)\nSB = pd.read_csv(os.path.join(inDir, 'sample_submission.csv'))\nISZ = 160\nsmooth = 1e-12","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir('/kaggle/data/')\nos.mkdir('/kaggle/msk/')\nos.mkdir('/kaggle/weights/')\nos.mkdir('/kaggle/subm/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _convert_coordinates_to_raster(coords, img_size, xymax):\n    # __author__ = visoft\n    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n    Xmax, Ymax = xymax\n    H, W = img_size\n    W1 = 1.0 * W * W / (W + 1)\n    H1 = 1.0 * H * H / (H + 1)\n    xf = W1 / Xmax\n    yf = H1 / Ymax\n    coords[:, 1] *= yf\n    coords[:, 0] *= xf\n    coords_int = np.round(coords).astype(np.int32)\n    return coords_int","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _get_xmax_ymin(grid_sizes_panda, imageId):\n    # __author__ = visoft\n    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n    xmax, ymin = grid_sizes_panda[grid_sizes_panda.ImageId == imageId].iloc[0, 1:].astype(float)\n    return (xmax, ymin)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _get_polygon_list(wkt_list_pandas, imageId, cType):\n    # __author__ = visoft\n    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n    df_image = wkt_list_pandas[wkt_list_pandas.ImageId == imageId]\n    multipoly_def = df_image[df_image.ClassType == cType].MultipolygonWKT\n    polygonList = None\n    if len(multipoly_def) > 0:\n        assert len(multipoly_def) == 1\n        polygonList = wkt_loads(multipoly_def.values[0])\n    return polygonList","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _get_and_convert_contours(polygonList, raster_img_size, xymax):\n    # __author__ = visoft\n    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n    perim_list = []\n    interior_list = []\n    if polygonList is None:\n        return None\n    for k in range(len(polygonList)):\n        poly = polygonList[k]\n        perim = np.array(list(poly.exterior.coords))\n        perim_c = _convert_coordinates_to_raster(perim, raster_img_size, xymax)\n        perim_list.append(perim_c)\n        for pi in poly.interiors:\n            interior = np.array(list(pi.coords))\n            interior_c = _convert_coordinates_to_raster(interior, raster_img_size, xymax)\n            interior_list.append(interior_c)\n    return perim_list, interior_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _plot_mask_from_contours(raster_img_size, contours, class_value=1):\n    # __author__ = visoft\n    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n    img_mask = np.zeros(raster_img_size, np.uint8)\n    if contours is None:\n        return img_mask\n    perim_list, interior_list = contours\n    cv2.fillPoly(img_mask, perim_list, class_value)\n    cv2.fillPoly(img_mask, interior_list, 0)\n    return img_mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_mask_for_image_and_class(raster_size, imageId, class_type, grid_sizes_panda=GS, wkt_list_pandas=DF):\n    # __author__ = visoft\n    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n    xymax = _get_xmax_ymin(grid_sizes_panda, imageId)\n    polygon_list = _get_polygon_list(wkt_list_pandas, imageId, class_type)\n    contours = _get_and_convert_contours(polygon_list, raster_size, xymax)\n    mask = _plot_mask_from_contours(raster_size, contours, 1)\n    return mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def M(image_id):\n    # __author__ = amaia\n    # https://www.kaggle.com/aamaia/dstl-satellite-imagery-feature-detection/rgb-using-m-bands-example\n    filename = os.path.join(inDir, 'sixteen_band', '{}_M.tif'.format(image_id))\n    img = tiff.imread(filename)\n    img = np.rollaxis(img, 0, 3)\n    return img\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''def M(image_id, dims=20, size=512):\n    \"\"\"\n    Loads the tiff-files with different number of bands.\n    \"\"\"\n    if dims==3:\n        filename = os.path.join(inDir, 'three_band', '{}.tif'.format(image_id))\n        img = tiff.imread(filename)\n        img = np.rollaxis(img, 0, 3)\n        img = cv2.resize(img, (size, size))\n        return img\n    elif dims==8:\n        filename = os.path.join(inDir, 'sixteen_band', '{}_M.tif'.format(image_id))\n        img = tiff.imread(filename)\n        img = np.rollaxis(img, 0, 3)\n        img = cv2.resize(img, (size, size))\n    elif dims==20:\n        # path = \"../../www.kaggle.com/c/dstl-satellite-imagery-feature-detection/download/sixteen_band\"\n        # img_M = np.transpose(tiff.imread(path+\"/{}_M.tif\".format(image_id)), (1,2,0))\n        img_M = np.transpose(tiff.imread(\"../input/dstl-satellite-imagery-feature-detection/sixteen_band/{}_M.tif\".format(image_id)), (1,2,0))\n        img_M = cv2.resize(img_M, (size, size))\n\n        # img_A = np.transpose(tiff.imread(path + \"/{}_A.tif\".format(image_id)), (1, 2, 0))\n        img_A = np.transpose(tiff.imread(\"../input/dstl-satellite-imagery-feature-detection/sixteen_band/{}_A.tif\".format(image_id)), (1,2,0))\n        img_A = cv2.resize(img_A, (size, size))\n\n        # img_P = tiff.imread(path+\"/{}_P.tif\".format(image_id))\n        img_P = tiff.imread(\"../input/dstl-satellite-imagery-feature-detection/sixteen_band/{}_P.tif\".format(image_id))\n        img_P = cv2.resize(img_P, (size, size))\n\n        filename = \"../input/dstl-satellite-imagery-feature-detection/three_band/{}.tif\".format(image_id)\n        # filename = \"../../kaggle.com/c/dstl-satellite-imagery-feature-detection/download/three_band/{}.tif\".format(image_id)\n        img_RGB = tiff.imread(filename)\n        img_RGB = np.rollaxis(img_RGB, 0, 3)\n        img_RGB = cv2.resize(img_RGB, (size, size))\n\n        img = np.zeros((img_RGB.shape[0], img_RGB.shape[1], dims), \"float32\")\n        img[..., 0:3] = img_RGB\n        img[..., 3] = img_P\n        img[..., 4:12] = img_M\n        img[..., 12:21] = img_A\n    return img\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def stretch_n(bands, lower_percent=2, higher_percent=98):\n    out = np.zeros_like(bands).astype(np.float32)\n    n = bands.shape[2]\n    for i in range(n):\n        a = 0  # np.min(band)\n        b = 1  # np.max(band)\n        c = np.percentile(bands[:, :, i], lower_percent)\n        d = np.percentile(bands[:, :, i], higher_percent)\n        t = a + (bands[:, :, i] - c) * (b - a) / (d - c)\n        t[t < a] = a\n        t[t > b] = b\n        out[:, :, i] = t\n\n    return out.astype(np.float32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def jaccard_coef(y_true, y_pred):\n    # __author__ = Vladimir Iglovikov\n    intersection = K.sum(y_true * y_pred, axis=[0, -1, -2])\n    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n\n    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n\n    return K.mean(jac)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def jaccard_coef_int(y_true, y_pred):\n     # __author__ = Vladimir Iglovikov\n    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n\n    intersection = K.sum(y_true * y_pred_pos, axis=[0, -1, -2])\n    sum_ = K.sum(y_true + y_pred_pos, axis=[0, -1, -2])\n    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n    return K.mean(jac)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def stick_all_train():\n    print (\"let's stick all imgs together\")\n    s = 835\n\n    x = np.zeros((5 * s, 5 * s, 8))\n    y = np.zeros((5 * s, 5 * s, N_Cls))\n\n    ids = sorted(DF.ImageId.unique())\n    print (len(ids))\n    for i in range(5):\n        for j in range(5):\n            id = ids[5 * i + j]\n\n            img = M(id)\n            img = stretch_n(img)\n            print (img.shape, id, np.amax(img), np.amin(img))\n            x[s * i:s * i + s, s * j:s * j + s, :] = img[:s, :s, :]\n            for z in range(N_Cls):\n                y[s * i:s * i + s, s * j:s * j + s, z] = generate_mask_for_image_and_class(\n                    (img.shape[0], img.shape[1]), id, z + 1)[:s, :s]\n\n    print (np.amax(y), np.amin(y))\n\n    np.save('/kaggle/data/x_trn_%d' % N_Cls, x)\n    np.save('/kaggle/data/y_trn_%d' % N_Cls, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_patches(img, msk, amt=2000, aug=True):\n    is2 = int(1.0 * ISZ)\n    xm, ym = img.shape[0] - is2, img.shape[1] - is2\n\n    x, y = [], []\n\n    tr = [0.4, 0.1, 0.1, 0.15, 0.3, 0.95, 0.1, 0.05, 0.001, 0.005]\n    for i in range(amt):\n        xc = random.randint(0, xm)\n        yc = random.randint(0, ym)\n\n        im = img[xc:xc + is2, yc:yc + is2]\n        ms = msk[xc:xc + is2, yc:yc + is2]\n\n        for j in range(N_Cls):\n            sm = np.sum(ms[:, :, j])\n            if 1.0 * sm / is2 ** 2 > tr[j]:\n                if aug:\n                    if random.uniform(0, 1) > 0.5:\n                        im = im[::-1]\n                        ms = ms[::-1]\n                    if random.uniform(0, 1) > 0.5:\n                        im = im[:, ::-1]\n                        ms = ms[:, ::-1]\n\n                x.append(im)\n                y.append(ms)\n\n    x, y = 2 * np.transpose(x, (0, 3, 1, 2)) - 1, np.transpose(y, (0, 3, 1, 2))\n    print (x.shape, y.shape, np.amax(x), np.amin(x), np.amax(y), np.amin(y))\n    im = None\n    ms = None\n    xc = None\n    yc = None\n    del(im,ms,xc,yc)\n    gc.collect()\n    return x, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_val():\n    print (\"let's pick some samples for validation\")\n    img = np.load('/kaggle/data/x_trn_%d.npy' % N_Cls)\n    msk = np.load('/kaggle/data/y_trn_%d.npy' % N_Cls)\n    x, y = get_patches(img, msk, amt=2000)\n\n    np.save('/kaggle/data/x_tmp_%d' % N_Cls, x)\n    np.save('/kaggle/data/y_tmp_%d' % N_Cls, y)\n    \n    img = None\n    msk = None\n    x = None\n    y = None\n    del(img,msk,x,y)\n    gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def jaccard_loss(y_true, y_pred):\n    return -jaccard_coef(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_unet():\n    inputs = Input((8, ISZ, ISZ))\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',data_format='channels_first')(inputs)\n    conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',data_format='channels_first')(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2),data_format='channels_first')(conv1)\n    conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',data_format='channels_first')(pool1)\n    conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',data_format='channels_first')(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2),data_format='channels_first')(conv2)\n    conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',data_format='channels_first')(pool2)\n    conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',data_format='channels_first')(conv3)\n    pool3 = MaxPooling2D(pool_size=(2, 2),data_format='channels_first')(conv3)\n    conv4 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',data_format='channels_first')(pool3)\n    conv4 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',data_format='channels_first')(conv4)\n    drop4 = Dropout(0.5)(conv4)\n    pool4 = MaxPooling2D(pool_size=(2, 2),data_format='channels_first')(drop4)\n\n    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',data_format='channels_first')(pool4)\n    conv5 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',data_format='channels_first')(conv5)\n    drop5 = Dropout(0.5)(conv5)\n\n    up6 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',data_format='channels_first')(UpSampling2D(size = (2,2),data_format='channels_first')(drop5))\n    merge6 = concatenate([drop4,up6], axis = 1)\n    conv6 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',data_format='channels_first')(merge6)\n    conv6 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',data_format='channels_first')(conv6)\n\n    up7 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',data_format='channels_first')(UpSampling2D(size = (2,2),data_format='channels_first')(conv6))\n    merge7 = concatenate([conv3,up7], axis = 1)\n    conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',data_format='channels_first')(merge7)\n    conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',data_format='channels_first')(conv7)\n\n    up8 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',data_format='channels_first')(UpSampling2D(size = (2,2),data_format='channels_first')(conv7))\n    merge8 = concatenate([conv2,up8], axis = 1)\n    conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',data_format='channels_first')(merge8)\n    conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',data_format='channels_first')(conv8)\n\n    up9 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',data_format='channels_first')(UpSampling2D(size = (2,2),data_format='channels_first')(conv8))\n    merge9 = concatenate([conv1,up9], axis = 1)\n    conv9 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',data_format='channels_first')(merge9)\n    conv9 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',data_format='channels_first')(conv9)\n    conv9 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',data_format='channels_first')(conv9)\n    conv10 = Conv2D(N_Cls, (1, 1),strides=1, activation = 'sigmoid',data_format='channels_first')(conv9)\n\n    model = Model(inputs = inputs, outputs = conv10)\n    model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=[jaccard_coef, jaccard_coef_int, 'accuracy'])\n    #model.compile(optimizer=Adam(lr=1e-4), loss = jaccard_loss, metrics=[jaccard_coef, jaccard_coef_int, 'accuracy'])\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calc_jacc(model):\n    img = np.load('/kaggle/data/x_tmp_%d.npy' % N_Cls)\n    msk = np.load('/kaggle/data/y_tmp_%d.npy' % N_Cls)\n\n    prd = model.predict(img, batch_size=4)\n    print (prd.shape, msk.shape)\n    avg, trs = [], []\n\n    for i in range(N_Cls):\n        t_msk = msk[:, i, :, :]\n        t_prd = prd[:, i, :, :]\n        t_msk = t_msk.reshape(msk.shape[0] * msk.shape[2], msk.shape[3])\n        t_prd = t_prd.reshape(msk.shape[0] * msk.shape[2], msk.shape[3])\n\n        m, b_tr = 0, 0\n        for j in range(10):\n            tr = j / 10.0\n            pred_binary_mask = t_prd > tr\n\n            jk = jaccard_similarity_score(t_msk, pred_binary_mask)\n            if jk > m:\n                m = jk\n                b_tr = tr\n        #print (i, m, b_tr)\n        avg.append(m)\n        trs.append(b_tr)\n\n    score = sum(avg) / 10.0\n    \n    img = None\n    msk = None\n    prd = None\n    t_msk = None\n    t_prd = None\n    b_tr = None\n    del(img,msk,prd,t_msk,t_prd,b_tr)\n    gc.collect()\n    \n    return score, trs\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mask_for_polygons(polygons, im_size):\n    # __author__ = Konstantin Lopuhin\n    # https://www.kaggle.com/lopuhin/dstl-satellite-imagery-feature-detection/full-pipeline-demo-poly-pixels-ml-poly\n    img_mask = np.zeros(im_size, np.uint8)\n    if not polygons:\n        return img_mask\n    int_coords = lambda x: np.array(x).round().astype(np.int32)\n    exteriors = [int_coords(poly.exterior.coords) for poly in polygons]\n    interiors = [int_coords(pi.coords) for poly in polygons\n                 for pi in poly.interiors]\n    cv2.fillPoly(img_mask, exteriors, 1)\n    cv2.fillPoly(img_mask, interiors, 0)\n    \n    int_coords = None\n    exteriors = None\n    interiors = None\n    del(int_coords,exteriors,interiors)\n    gc.collect()\n    return img_mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mask_to_polygons(mask, epsilon=5, min_area=1.):\n    # __author__ = Konstantin Lopuhin\n    # https://www.kaggle.com/lopuhin/dstl-satellite-imagery-feature-detection/full-pipeline-demo-poly-pixels-ml-poly\n\n    # first, find contours with cv2: it's much faster than shapely\n    contours, hierarchy = cv2.findContours(((mask == 1) * 255).astype(np.uint8), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_TC89_KCOS)\n    # create approximate contours to have reasonable submission size\n    approx_contours = [cv2.approxPolyDP(cnt, epsilon, True)\n                       for cnt in contours]\n    if not contours:\n        return MultiPolygon()\n    # now messy stuff to associate parent and child contours\n    cnt_children = defaultdict(list)\n    child_contours = set()\n    assert hierarchy.shape[0] == 1\n    # http://docs.opencv.org/3.1.0/d9/d8b/tutorial_py_contours_hierarchy.html\n    for idx, (_, _, _, parent_idx) in enumerate(hierarchy[0]):\n        if parent_idx != -1:\n            child_contours.add(idx)\n            cnt_children[parent_idx].append(approx_contours[idx])\n    # create actual polygons filtering by area (removes artifacts)\n    all_polygons = []\n    for idx, cnt in enumerate(approx_contours):\n        if idx not in child_contours and cv2.contourArea(cnt) >= min_area:\n            assert cnt.shape[1] == 1\n            poly = Polygon(\n                shell=cnt[:, 0, :],\n                holes=[c[:, 0, :] for c in cnt_children.get(idx, [])\n                       if cv2.contourArea(c) >= min_area])\n            all_polygons.append(poly)\n    # approximating polygons might have created invalid ones, fix them\n    all_polygons = MultiPolygon(all_polygons)\n    if not all_polygons.is_valid:\n        all_polygons = all_polygons.buffer(0)\n        # Sometimes buffer() converts a simple Multipolygon to just a Polygon,\n        # need to keep it a Multi throughout\n        if all_polygons.type == 'Polygon':\n            all_polygons = MultiPolygon([all_polygons])\n    return all_polygons","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_scalers(im_size, x_max, y_min):\n    # __author__ = Konstantin Lopuhin\n    # https://www.kaggle.com/lopuhin/dstl-satellite-imagery-feature-detection/full-pipeline-demo-poly-pixels-ml-poly\n    h, w = im_size  # they are flipped so that mask_for_polygons works correctly\n    h, w = float(h), float(w)\n    w_ = 1.0 * w * (w / (w + 1))\n    h_ = 1.0 * h * (h / (h + 1))\n    return w_ / x_max, h_ / y_min","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_net():\n    print (\"start train net\")\n    x_val, y_val = np.load('/kaggle/data/x_tmp_%d.npy' % N_Cls), np.load('/kaggle/data/y_tmp_%d.npy' % N_Cls)\n    img = np.load('/kaggle/data/x_trn_%d.npy' % N_Cls)\n    msk = np.load('/kaggle/data/y_trn_%d.npy' % N_Cls)\n\n    x_trn, y_trn = get_patches(img, msk)\n\n    model = get_unet()\n    #model.load_weights('../input/trained-weight/unet_10_jk0.7565')\n    model_checkpoint = ModelCheckpoint('unet_tmp.hdf5', monitor='loss', save_best_only=True)\n    for i in range(1):\n        model.fit(x_trn, y_trn, batch_size=64, epochs=10, verbose=1, shuffle=True,\n                  callbacks=[model_checkpoint], validation_data=(x_val, y_val))\n        del x_trn\n        del y_trn\n        #x_trn, y_trn = get_patches(img, msk)\n        score, trs = calc_jacc(model)\n        print ('val jk'+ str(score))\n        model.save_weights('unet_10_jk%.4f' % score)\n    \n    x_val = None\n    y_val = None\n    x_trn = None\n    y_trn = None\n    del(x_val,y_val,x_trn,y_trn)\n    gc.collect()\n    \n    return model, score, trs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_id(id, model, trs):\n    img = M(id)\n    x = stretch_n(img)\n\n    cnv = np.zeros((960, 960, 8)).astype(np.float32)\n    prd = np.zeros((N_Cls, 960, 960)).astype(np.float32)\n    cnv[:img.shape[0], :img.shape[1], :] = x\n\n    for i in range(0, 6):\n        line = []\n        for j in range(0, 6):\n            line.append(cnv[i * ISZ:(i + 1) * ISZ, j * ISZ:(j + 1) * ISZ])\n\n        x = 2 * np.transpose(line, (0, 3, 1, 2)) - 1\n        tmp = model.predict(x, batch_size=4)\n        for j in range(tmp.shape[0]):\n            prd[:, i * ISZ:(i + 1) * ISZ, j * ISZ:(j + 1) * ISZ] = tmp[j]\n\n    trs = [0.4, 0.1, 0.4, 0.3, 0.3, 0.5, 0.3, 0.6, 0.1, 0.1]\n    for i in range(N_Cls):\n        prd[i] = prd[i] > trs[i]\n\n    return prd[:, :img.shape[0], :img.shape[1]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_test(model, trs):\n    print (\"predict test\")\n    for i, id in enumerate(sorted(set(SB['ImageId'].tolist()))):\n        msk = predict_id(id, model, trs)\n        np.save('/kaggle/msk/10_%s' % id, msk)\n        #if i % 100 == 0: print (i, id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_submit():\n    print (\"make submission file\")\n    df = pd.read_csv(os.path.join(inDir, 'sample_submission.csv'))\n    print (df.head())\n    for idx, row in df.iterrows():\n        id = row[0]\n        kls = row[1] - 1\n\n        msk = np.load('/kaggle/msk/10_%s.npy' % id)[kls]\n        pred_polygons = mask_to_polygons(msk)\n        x_max = GS.loc[GS['ImageId'] == id, 'Xmax'].as_matrix()[0]\n        y_min = GS.loc[GS['ImageId'] == id, 'Ymin'].as_matrix()[0]\n\n        x_scaler, y_scaler = get_scalers(msk.shape, x_max, y_min)\n\n        scaled_pred_polygons = shapely.affinity.scale(pred_polygons, xfact=1.0 / x_scaler, yfact=1.0 / y_scaler,\n                                                      origin=(0, 0, 0))\n\n        df.iloc[idx, 2] = shapely.wkt.dumps(scaled_pred_polygons)\n        if idx % 1000 == 0: print (idx)\n    print (df.head())\n    df.to_csv('/kaggle/subm/1.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def check_predict(id='6120_2_3'):\n    model = get_unet()\n    model.load_weights('/kaggle/working/unet_10_jk%.4f' % score)\n\n    msk = predict_id(id, model, [0.4, 0.1, 0.4, 0.3, 0.3, 0.5, 0.3, 0.6, 0.1, 0.1])\n    m = M(id)\n    print(m.shape)\n    class_list = [\"Buildings\", \"Misc.Manmade structures\" ,\"Road\",\\\n                  \"Track\",\"Trees\",\"Crops\",\"Waterway\",\"Standing water\",\\\n                  \"Vehicle Large\",\"Vehicle Small\"]\n    \n    img = np.zeros((m.shape[0],m.shape[1],3))\n    img[:,:,0] = m[:,:,4] #red\n    img[:,:,1] = m[:,:,2] #green\n    img[:,:,2] = m[:,:,1] #blue\n    for i in range(10):\n        plt.figure(figsize=(20,20))\n        ax1 = plt.subplot(131)\n        ax1.set_title('image ID:6120_2_3')\n        ax1.imshow(stretch_n(img))\n        ax2 = plt.subplot(132)\n        ax2.set_title(\"predict \"+ class_list[i] +\" pixels\")\n        ax2.imshow(msk[i], cmap=plt.get_cmap('gray'))\n        ax3 = plt.subplot(133)\n        ax3.set_title(\"predict \" + class_list[i] + \" polygones\")\n        ax3.imshow(mask_for_polygons(mask_to_polygons(msk[i], epsilon=1), img.shape[:2]), cmap=plt.get_cmap('gray'))\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''def check_predict(id='6120_2_3'):\n    model = get_unet()\n    model.load_weights('/kaggle/working/unet_10_jk%.4f' % score)\n\n    msk = predict_id(id, model, [0.4, 0.1, 0.4, 0.3, 0.3, 0.5, 0.3, 0.6, 0.1, 0.1])\n    img = M(id)\n\n    plt.figure(figsize=(20,20))\n    ax1 = plt.subplot(1031)\n    ax1.set_title('image ID:6120_2_3')\n    ax1.imshow(img[:, :, 5], cmap=plt.get_cmap('gist_ncar'))\n    ax2 = plt.subplot(1032)\n    ax2.set_title('predict bldg pixels')\n    ax2.imshow(msk[0], cmap=plt.get_cmap('gray'))\n    ax3 = plt.subplot(1033)\n    ax3.set_title('predict bldg polygones')\n    ax3.imshow(mask_for_polygons(mask_to_polygons(msk[0], epsilon=1), img.shape[:2]), cmap=plt.get_cmap('gray'))\n\n    plt.show()'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stick_all_train()\nDF = None\nx = None\ny = None\nimg = None\nids = None\ndel(DF,x,y,img,ids)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"make_val()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model, score, trs = train_net()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_predict('6120_2_2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_test(model, trs)\n\nimg = None\ncnv = None\ndel(img,cnv)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"make_submit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abc = pd.read_csv('/kaggle/subm/1.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abc[50:100]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}