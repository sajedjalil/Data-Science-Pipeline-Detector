{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"97bd7735-a2dd-a770-e9fe-fd2bf63508d8"},"outputs":[],"source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom pylab import plot, show, subplot, specgram, imshow, savefig\nimport numpy as np\nimport cv2\nimport pandas as pd\nfrom shapely.wkt import loads as wkt_loads\nimport tifffile as tiff\nimport os\nimport random\nfrom keras.models import Model\nfrom keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom keras import backend as K\nfrom sklearn.metrics import jaccard_similarity_score\nfrom shapely.geometry import MultiPolygon, Polygon\nimport shapely.wkt\nimport shapely.affinity\nfrom collections import defaultdict\n\nN_Cls = 1 #10\nN_ToPredict = 1000\ninDir = '../input'\nDF = pd.read_csv(inDir + '/train_wkt_v4.csv')\nGS = pd.read_csv(inDir + '/grid_sizes.csv', names=['ImageId', 'Xmax', 'Ymin'], skiprows=1)\nSB = pd.read_csv(os.path.join(inDir, 'sample_submission.csv'))\nISZ = 160\nsmooth = 1e-12\n\n\ndef _convert_coordinates_to_raster(coords, img_size, xymax):\n    # __author__ = visoft\n    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n    Xmax, Ymax = xymax\n    H, W = img_size\n    W1 = 1.0 * W * W / (W + 1)\n    H1 = 1.0 * H * H / (H + 1)\n    xf = W1 / Xmax\n    yf = H1 / Ymax\n    coords[:, 1] *= yf\n    coords[:, 0] *= xf\n    coords_int = np.round(coords).astype(np.int32)\n    return coords_int\n\n\ndef _get_xmax_ymin(grid_sizes_panda, imageId):\n    # __author__ = visoft\n    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n    xmax, ymin = grid_sizes_panda[grid_sizes_panda.ImageId == imageId].iloc[0, 1:].astype(float)\n    return (xmax, ymin)\n\n\ndef _get_polygon_list(wkt_list_pandas, imageId, cType):\n    # __author__ = visoft\n    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n    df_image = wkt_list_pandas[wkt_list_pandas.ImageId == imageId]\n    multipoly_def = df_image[df_image.ClassType == cType].MultipolygonWKT\n    polygonList = None\n    if len(multipoly_def) > 0:\n        assert(len(multipoly_def) == 1)\n        polygonList = wkt_loads(multipoly_def.values[0])\n    return polygonList\n\n\ndef _get_and_convert_contours(polygonList, raster_img_size, xymax):\n    # __author__ = visoft\n    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n    perim_list = []\n    interior_list = []\n    if polygonList is None:\n        return None\n    for k in range(len(polygonList)):\n        poly = polygonList[k]\n        perim = np.array(list(poly.exterior.coords))\n        perim_c = _convert_coordinates_to_raster(perim, raster_img_size, xymax)\n        perim_list.append(perim_c)\n        for pi in poly.interiors:\n            interior = np.array(list(pi.coords))\n            interior_c = _convert_coordinates_to_raster(interior, raster_img_size, xymax)\n            interior_list.append(interior_c)\n    return perim_list, interior_list\n\n\ndef _plot_mask_from_contours(raster_img_size, contours, class_value=1):\n    # __author__ = visoft\n    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n    img_mask = np.zeros(raster_img_size, np.uint8)\n    if contours is None:\n        return img_mask\n    perim_list, interior_list = contours\n    cv2.fillPoly(img_mask, perim_list, class_value)\n    cv2.fillPoly(img_mask, interior_list, 0)\n    return img_mask\n\n\ndef generate_mask_for_image_and_class(raster_size, imageId, class_type, grid_sizes_panda=GS, wkt_list_pandas=DF):\n    # __author__ = visoft\n    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n    xymax = _get_xmax_ymin(grid_sizes_panda, imageId)\n    polygon_list = _get_polygon_list(wkt_list_pandas, imageId, class_type)\n    contours = _get_and_convert_contours(polygon_list, raster_size, xymax)\n    mask = _plot_mask_from_contours(raster_size, contours, 1)\n    return mask\n\n\ndef M(image_id):\n    # __author__ = amaia\n    # https://www.kaggle.com/aamaia/dstl-satellite-imagery-feature-detection/rgb-using-m-bands-example\n    filename = os.path.join(inDir, 'sixteen_band', '{}_M.tif'.format(image_id))\n    img = tiff.imread(filename)\n    img = np.rollaxis(img, 0, 3)\n    return img\n\n\ndef stretch_n(bands, lower_percent=5, higher_percent=95):\n    out = np.zeros_like(bands)\n    n = bands.shape[2]\n    for i in range(n):\n        a = 0  # np.min(band)\n        b = 1  # np.max(band)\n        c = np.percentile(bands[:, :, i], lower_percent)\n        d = np.percentile(bands[:, :, i], higher_percent)\n        t = a + (bands[:, :, i] - c) * (b - a) / (d - c)\n        t[t < a] = a\n        t[t > b] = b\n        out[:, :, i] = t\n\n    return out.astype(np.float32)\n\n\ndef jaccard_coef(y_true, y_pred):\n    # __author__ = Vladimir Iglovikov\n    intersection = K.sum(y_true * y_pred, axis=[0, -1, -2])\n    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n\n    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n\n    return K.mean(jac)\n\n\ndef jaccard_coef_int(y_true, y_pred):\n    # __author__ = Vladimir Iglovikov\n    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n\n    intersection = K.sum(y_true * y_pred_pos, axis=[0, -1, -2])\n    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n    return K.mean(jac)\n\n\ndef stick_all_train():\n    print(\"let's stick all imgs together\")\n    s = 835\n\n    x = np.zeros((5 * s, 5 * s, 8))\n    y = np.zeros((5 * s, 5 * s, N_Cls))\n\n    ids = sorted(DF.ImageId.unique())\n    print(len(ids))\n    for i in range(5):\n        for j in range(5):\n            id = ids[5 * i + j]\n\n            img = M(id)\n            img = stretch_n(img)\n            print(img.shape, id, np.amax(img), np.amin(img))\n            x[s * i:s * i + s, s * j:s * j + s, :] = img[:s, :s, :]\n            for z in range(N_Cls):\n                y[s * i:s * i + s, s * j:s * j + s, z] = generate_mask_for_image_and_class(\n                    (img.shape[0], img.shape[1]), id, z + 1)[:s, :s]\n\n    print(np.amax(y), np.amin(y))\n\n    #np.save('data_x_trn_%d' % N_Cls, x)\n    #np.save('data_y_trn_%d' % N_Cls, y)\n    return x, y\n\n\ndef get_patches(img, msk, amt=10000, aug=True):\n    is2 = int(1.0 * ISZ)\n    xm, ym = img.shape[0] - is2, img.shape[1] - is2\n\n    x, y = [], []\n\n    tr = [0.4, 0.1, 0.1, 0.15, 0.3, 0.95, 0.1, 0.05, 0.001, 0.005]\n    for i in range(amt):\n        xc = random.randint(0, xm)\n        yc = random.randint(0, ym)\n\n        im = img[xc:xc + is2, yc:yc + is2]\n        ms = msk[xc:xc + is2, yc:yc + is2]\n\n        for j in range(N_Cls):\n            sm = np.sum(ms[:, :, j])\n            if 1.0 * sm / is2 ** 2 > tr[j]:\n                if aug:\n                    if random.uniform(0, 1) > 0.5:\n                        im = im[::-1]\n                        ms = ms[::-1]\n                    if random.uniform(0, 1) > 0.5:\n                        im = im[:, ::-1]\n                        ms = ms[:, ::-1]\n\n                x.append(im)\n                y.append(ms)\n\n    x, y = 2 * np.transpose(x, (0, 3, 1, 2)) - 1, np.transpose(y, (0, 3, 1, 2))\n    print(x.shape, y.shape, np.amax(x), np.amin(x), np.amax(y), np.amin(y))\n    return x, y\n\n\ndef make_val(img, msk):\n    print(\"let's pick some samples for validation\")\n    #img = np.load('data_x_trn_%d.npy' % N_Cls)\n    #msk = np.load('data_y_trn_%d.npy' % N_Cls)\n    x, y = get_patches(img, msk, amt=3000)\n\n    #np.save('data_x_tmp_%d' % N_Cls, x)\n    #np.save('data_y_tmp_%d' % N_Cls, y)\n    return x, y\n\n\ndef get_unet():\n    inputs = Input((8, ISZ, ISZ))\n    conv1 = Convolution2D(8, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(inputs)\n    conv1 = Convolution2D(8, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\")(conv1)\n\n    #conv2 = Convolution2D(64, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(pool1)\n    #conv2 = Convolution2D(64, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(conv2)\n    #pool2 = MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\")(conv2)\n\n    #conv3 = Convolution2D(128, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(pool2)\n    #conv3 = Convolution2D(128, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(conv3)\n    #pool3 = MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\")(conv3)\n\n    #conv4 = Convolution2D(256, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(pool3)\n    #conv4 = Convolution2D(256, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(conv4)\n    #pool4 = MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\")(conv4)\n\n    #conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(pool4)\n    #conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(conv5)\n    conv5 = Convolution2D(16, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(pool1)\n    conv5 = Convolution2D(16, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(conv5)\n\n    #up6 = merge([UpSampling2D(size=(2, 2), dim_ordering=\"th\")(conv5), conv4], mode='concat', concat_axis=1)\n    #conv6 = Convolution2D(256, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(up6)\n    #conv6 = Convolution2D(256, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(conv6)\n\n    #up7 = merge([UpSampling2D(size=(2, 2), dim_ordering=\"th\")(conv6), conv3], mode='concat', concat_axis=1)\n    #conv7 = Convolution2D(128, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(up7)\n    #conv7 = Convolution2D(128, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(conv7)\n\n    #up8 = merge([UpSampling2D(size=(2, 2), dim_ordering=\"th\")(conv7), conv2], mode='concat', concat_axis=1)\n    #conv8 = Convolution2D(64, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(up8)\n    #conv8 = Convolution2D(64, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(conv8)\n\n    up9 = merge([UpSampling2D(size=(2, 2), dim_ordering=\"th\")(conv5), conv1], mode='concat', concat_axis=1)\n    conv9 = Convolution2D(8, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(up9)\n    conv9 = Convolution2D(8, 3, 3, activation='relu', border_mode='same', dim_ordering=\"th\")(conv9)\n\n    conv10 = Convolution2D(N_Cls, 1, 1, activation='sigmoid', dim_ordering=\"th\")(conv9)\n\n    model = Model(input=inputs, output=conv10)\n    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=[jaccard_coef, jaccard_coef_int, 'accuracy'])\n    return model\n\n\ndef calc_jacc(model, img, msk):\n    #img = np.load('data_x_tmp_%d.npy' % N_Cls)\n    #msk = np.load('data_y_tmp_%d.npy' % N_Cls)\n\n    prd = model.predict(img, batch_size=4)\n    print(prd.shape, msk.shape)\n    avg, trs = [], []\n\n    for i in range(N_Cls):\n        t_msk = msk[:, i, :, :]\n        t_prd = prd[:, i, :, :]\n        t_msk = t_msk.reshape(msk.shape[0] * msk.shape[2], msk.shape[3])\n        t_prd = t_prd.reshape(msk.shape[0] * msk.shape[2], msk.shape[3])\n\n        m, b_tr = 0, 0\n        for j in range(10):\n            tr = j / 10.0\n            pred_binary_mask = t_prd > tr\n\n            jk = jaccard_similarity_score(t_msk, pred_binary_mask)\n            if jk > m:\n                m = jk\n                b_tr = tr\n        print(i, m, b_tr)\n        avg.append(m)\n        trs.append(b_tr)\n\n    score = sum(avg) / 10.0\n    return score, trs\n\n\ndef mask_for_polygons(polygons, im_size):\n    # __author__ = Konstantin Lopuhin\n    # https://www.kaggle.com/lopuhin/dstl-satellite-imagery-feature-detection/full-pipeline-demo-poly-pixels-ml-poly\n    img_mask = np.zeros(im_size, np.uint8)\n    if not polygons:\n        return img_mask\n    int_coords = lambda x: np.array(x).round().astype(np.int32)\n    exteriors = [int_coords(poly.exterior.coords) for poly in polygons]\n    interiors = [int_coords(pi.coords) for poly in polygons\n                 for pi in poly.interiors]\n    cv2.fillPoly(img_mask, exteriors, 1)\n    cv2.fillPoly(img_mask, interiors, 0)\n    return img_mask\n\n\ndef mask_to_polygons(mask, epsilon=5, min_area=1.):\n    # __author__ = Konstantin Lopuhin\n    # https://www.kaggle.com/lopuhin/dstl-satellite-imagery-feature-detection/full-pipeline-demo-poly-pixels-ml-poly\n\n    # first, find contours with cv2: it's much faster than shapely\n    image, contours, hierarchy = cv2.findContours(\n        ((mask == 1) * 255).astype(np.uint8),\n        cv2.RETR_CCOMP, cv2.CHAIN_APPROX_TC89_KCOS)\n    # create approximate contours to have reasonable submission size\n    approx_contours = [cv2.approxPolyDP(cnt, epsilon, True)\n                       for cnt in contours]\n    if not contours:\n        return MultiPolygon()\n    # now messy stuff to associate parent and child contours\n    cnt_children = defaultdict(list)\n    child_contours = set()\n    assert(hierarchy.shape[0] == 1)\n    # http://docs.opencv.org/3.1.0/d9/d8b/tutorial_py_contours_hierarchy.html\n    for idx, (_, _, _, parent_idx) in enumerate(hierarchy[0]):\n        if parent_idx != -1:\n            child_contours.add(idx)\n            cnt_children[parent_idx].append(approx_contours[idx])\n    # create actual polygons filtering by area (removes artifacts)\n    all_polygons = []\n    for idx, cnt in enumerate(approx_contours):\n        if idx not in child_contours and cv2.contourArea(cnt) >= min_area:\n            assert(cnt.shape[1] == 1)\n            poly = Polygon(\n                shell=cnt[:, 0, :],\n                holes=[c[:, 0, :] for c in cnt_children.get(idx, [])\n                       if cv2.contourArea(c) >= min_area])\n            all_polygons.append(poly)\n    # approximating polygons might have created invalid ones, fix them\n    all_polygons = MultiPolygon(all_polygons)\n    if not all_polygons.is_valid:\n        all_polygons = all_polygons.buffer(0)\n        # Sometimes buffer() converts a simple Multipolygon to just a Polygon,\n        # need to keep it a Multi throughout\n        if all_polygons.type == 'Polygon':\n            all_polygons = MultiPolygon([all_polygons])\n    return all_polygons\n\n\ndef get_scalers(im_size, x_max, y_min):\n    # __author__ = Konstantin Lopuhin\n    # https://www.kaggle.com/lopuhin/dstl-satellite-imagery-feature-detection/full-pipeline-demo-poly-pixels-ml-poly\n    h, w = im_size  # they are flipped so that mask_for_polygons works correctly\n    h, w = float(h), float(w)\n    w_ = 1.0 * w * (w / (w + 1))\n    h_ = 1.0 * h * (h / (h + 1))\n    return w_ / x_max, h_ / y_min\n\ndef batch_generator(X, y, batch_size, shuffle):\n    #chenglong code for fiting from generator (https://www.kaggle.com/c/talkingdata-mobile-user-demographics/forums/t/22567/neural-network-for-sparse-matrices)\n    number_of_batches = np.ceil(X.shape[0]/batch_size)\n    counter = 0\n    sample_index = np.arange(X.shape[0])\n    if shuffle:\n        np.random.shuffle(sample_index)\n    while True:\n        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n        X_batch = X[batch_index,:]\n        y_batch = y[batch_index]\n        counter += 1\n        yield X_batch, y_batch\n        if (counter == number_of_batches):\n            if shuffle:\n                np.random.shuffle(sample_index)\n            counter = 0\n\ndef batch_generatorp(X, batch_size, shuffle):\n    number_of_batches = X.shape[0] / np.ceil(X.shape[0]/batch_size)\n    counter = 0\n    sample_index = np.arange(X.shape[0])\n    while True:\n        batch_index = sample_index[batch_size * counter:batch_size * (counter + 1)]\n        X_batch = X[batch_index, :]\n        counter += 1\n        yield X_batch\n        if (counter == number_of_batches):\n            counter = 0\n\ndef train_net(img, msk, x_val, y_val):\n    print(\"start train net\")\n    #x_val, y_val = np.load('data_x_tmp_%d.npy' % N_Cls), np.load('data_y_tmp_%d.npy' % N_Cls)\n    #img = np.load('data_x_trn_%d.npy' % N_Cls)\n    #msk = np.load('data_y_trn_%d.npy' % N_Cls)\n\n    print(\"get_patches {}, {}...\".format(img.shape, msk.shape))\n    x_trn, y_trn = get_patches(img, msk)\n\n    print(\"model...\")\n    model = get_unet()\n    #model.load_weights('weights/unet_10_jk0.7878')\n    model_checkpoint = ModelCheckpoint('weights_unet_tmp.hdf5', monitor='loss', save_best_only=True)\n    for i in range(1):\n        print(\"fit {}, {}...\".format(x_trn.shape, x_val.shape))\n        model.fit(x_trn, y_trn, batch_size=64, nb_epoch=4, verbose=1, shuffle=True,\n                  callbacks=[model_checkpoint], validation_data=(x_val, y_val))\n        #model.fit_generator(generator=batch_generator(x_trn, y_trn, 64, False),\n        #                 nb_epoch=1, samples_per_epoch=x_trn.shape[0],\n        #                 callbacks=[model_checkpoint],\n        #                 validation_data=batch_generator(x_val, y_val, 64, False), nb_val_samples=x_val.shape[0], verbose=2\n        #                 )\n        del x_trn\n        del y_trn\n        x_trn, y_trn = get_patches(img, msk)\n        score, trs = calc_jacc(model, x_val, y_val)\n        print('val jk', score)\n        model.save_weights('weights_unet_10_jk%.4f' % score)\n\n    return model\n\n\ndef predict_id(id, model, trs):\n    img = M(id)\n    x = stretch_n(img)\n\n    cnv = np.zeros((960, 960, 8)).astype(np.float32)\n    prd = np.zeros((N_Cls, 960, 960)).astype(np.float32)\n    cnv[:img.shape[0], :img.shape[1], :] = x\n\n    for i in range(0, 6):\n        line = []\n        for j in range(0, 6):\n            line.append(cnv[i * ISZ:(i + 1) * ISZ, j * ISZ:(j + 1) * ISZ])\n\n        x = 2 * np.transpose(line, (0, 3, 1, 2)) - 1\n        tmp = model.predict(x, batch_size=4)\n        #tmp = model.predict_generator(generator=batch_generatorp(x, 4, False), val_samples=x.shape[0])\n        for j in range(tmp.shape[0]):\n            prd[:, i * ISZ:(i + 1) * ISZ, j * ISZ:(j + 1) * ISZ] = tmp[j]\n\n    # trs = [0.4, 0.1, 0.4, 0.3, 0.3, 0.5, 0.3, 0.6, 0.1, 0.1]\n    for i in range(N_Cls):\n        prd[i] = prd[i] > trs[i]\n\n    return prd[:, :img.shape[0], :img.shape[1]]\n\n\ndef predict_test(model, trs):\n    print(\"predict test\")\n    for i, id in enumerate(sorted(set(SB['ImageId'].tolist()))):\n        msk = predict_id(id, model, trs)\n        np.save('msk_10_%s' % id, msk)\n        if i % 100 == 0: print(i, id)\n\n\ndef make_submit(model, trs):\n    print(\"make submission file\")\n    df = pd.read_csv(os.path.join(inDir, 'sample_submission.csv'))\n    print(df.head())\n    for idx, row in df.iterrows():\n        id = row[0]\n        kls = row[1] - 1\n        if idx % 100 == 0: print(idx)\n        \n        if idx >= N_ToPredict:\n            continue\n        \n        if kls < N_Cls:\n            #print('Predicting {}, {}, {}, {}'.format(idx, id, kls, row))\n            try:\n                msk = predict_id(id, model, trs)[kls]\n                #np.save('msk_10_%s' % id, msk)\n                #msk = np.load('msk_10_%s.npy' % id)[kls]\n                pred_polygons = mask_to_polygons(msk)\n                #print('pred_polygons {}'.format(pred_polygons))\n                x_max = GS.loc[GS['ImageId'] == id, 'Xmax'].as_matrix()[0]\n                y_min = GS.loc[GS['ImageId'] == id, 'Ymin'].as_matrix()[0]\n\n                x_scaler, y_scaler = get_scalers(msk.shape, x_max, y_min)\n\n                scaled_pred_polygons = shapely.affinity.scale(pred_polygons, xfact=1.0 / x_scaler, yfact=1.0 / y_scaler,\n                                                              origin=(0, 0, 0))\n\n                df.iloc[idx, 2] = shapely.wkt.dumps(scaled_pred_polygons)\n                #print('Got pred: {}'.format(df.iloc[idx, 2]))\n            except:\n                print(\"Unexpected error:\", sys.exc_info()[0])\n                raise\n    print(df.head())\n    df.to_csv('subm_1.csv', index=False)\n\n\ndef check_predict(id='6120_2_3'):\n    model = get_unet()\n    #model.load_weights('weights/unet_10_jk0.7878')\n\n    msk = predict_id(id, model, [0.4, 0.1, 0.4, 0.3, 0.3, 0.5, 0.3, 0.6, 0.1, 0.1])\n    img = M(id)\n\n    plt.figure()\n    ax1 = plt.subplot(131)\n    ax1.set_title('image ID:6120_2_3')\n    ax1.imshow(img[:, :, 5], cmap=plt.get_cmap('gist_ncar'))\n    ax2 = plt.subplot(132)\n    ax2.set_title('predict bldg pixels')\n    ax2.imshow(msk[0], cmap=plt.get_cmap('gray'))\n    ax3 = plt.subplot(133)\n    ax3.set_title('predict bldg polygones')\n    ax3.imshow(mask_for_polygons(mask_to_polygons(msk[0], epsilon=1), img.shape[:2]), cmap=plt.get_cmap('gray'))\n\n    plt.show()\n    #savefig('plot.png')\n    #plt.gcf().clear()\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"de83125c-f5e5-547a-1c43-c1cd0833cb97"},"outputs":[],"source":"x, y = stick_all_train()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"13b68910-9102-40f4-8a8b-b455b2904586"},"outputs":[],"source":"x_val, y_val = make_val(x, y)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6f208d38-e92d-4521-89f4-a6facf89a9f3"},"outputs":[],"source":"model = train_net(x, y, x_val, y_val)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f7b25789-bcd2-a569-99b0-bd9b70c35d41"},"outputs":[],"source":"# score, trs = calc_jacc(model, x_val, y_val)\nprint (\"done\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"063f66ff-d897-87d6-341b-99e76b687bde"},"outputs":[],"source":"check_predict('6120_2_3')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"53a11fd6-f7fb-d054-d64c-bac72b5bce8c"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}