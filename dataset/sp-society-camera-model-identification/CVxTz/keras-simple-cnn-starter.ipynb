{"metadata":{"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"nbconvert_exporter":"python","file_extension":".py","mimetype":"text/x-python","name":"python","version":"3.6.3","pygments_lexer":"ipython3"},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"nbformat":4,"cells":[{"metadata":{"_uuid":"c17b461b803801610e2eabc2e6f492301f9084c6","_cell_guid":"8e119507-463b-4349-bf53-a0d70f59d0e1","collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom PIL import Image\nfrom skimage.transform import resize\nfrom random import shuffle\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"metadata":{"_uuid":"a7e4afe4d4802460f236159cce4b73b031932c77","_cell_guid":"941710b6-33b6-4c40-89c5-c30452eeba7e","collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"list_paths = []\nfor subdir, dirs, files in os.walk(\"../input\"):\n    for file in files:\n        #print os.path.join(subdir, file)\n        filepath = subdir + os.sep + file\n        list_paths.append(filepath)"},{"metadata":{"_uuid":"a7d575b964899e261ec2c53da6804a90383309ca","_cell_guid":"80eefe0c-1783-48d4-b54e-542665e761b6","collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"list_train = [filepath for filepath in list_paths if \"train/\" in filepath]\nshuffle(list_train)\nlist_test = [filepath for filepath in list_paths if \"test/\" in filepath]\n\nlist_train = list_train\nlist_test = list_test\nindex = [os.path.basename(filepath) for filepath in list_test]"},{"metadata":{"_uuid":"a9c632622efc366a3d2b44b3b5b114f879072a18","_cell_guid":"7c57e7f2-fab6-4a3a-90f7-2ce782a2d71d","collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"list_classes = list(set([os.path.dirname(filepath).split(os.sep)[-1] for filepath in list_paths if \"train\" in filepath]))"},{"metadata":{"_uuid":"c240ac230937cebdddc9ccc44024bac7dc217302","_cell_guid":"f8d6f230-5713-4834-be75-58ffe39a04ec","collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"list_classes = ['Sony-NEX-7',\n 'Motorola-X',\n 'HTC-1-M7',\n 'Samsung-Galaxy-Note3',\n 'Motorola-Droid-Maxx',\n 'iPhone-4s',\n 'iPhone-6',\n 'LG-Nexus-5x',\n 'Samsung-Galaxy-S4',\n 'Motorola-Nexus-6']"},{"metadata":{"_uuid":"489137510fe433950f5a0d85dc62df8ddacb8cf1","_cell_guid":"552dba70-8a9f-4b70-98e7-6b75fff4a21f","collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"def get_class_from_path(filepath):\n    return os.path.dirname(filepath).split(os.sep)[-1]\n\ndef read_and_resize(filepath):\n    im_array = np.array(Image.open((filepath)), dtype=\"uint8\")\n    pil_im = Image.fromarray(im_array)\n    new_array = np.array(pil_im.resize((256, 256)))\n    return new_array/255\n\ndef label_transform(labels):\n    labels = pd.get_dummies(pd.Series(labels))\n    label_index = labels.columns.values\n\n    return labels, label_index\n\n    "},{"metadata":{"_uuid":"9bc5aa343ed8073e42447929fe6ad61bd85dbcfb","_cell_guid":"24a0b700-1efc-4467-8b6f-9451c1217884","collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"X_train = np.array([read_and_resize(filepath) for filepath in list_train])\nX_test = np.array([read_and_resize(filepath) for filepath in list_test])"},{"metadata":{"_uuid":"2300063312fd5e66a3595a8a8946308986fcaf2c","_cell_guid":"a0530d63-31fd-4f61-97d1-c3fa45e42a8d","collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"labels = [get_class_from_path(filepath) for filepath in list_train]\ny, label_index = label_transform(labels)\ny = np.array(y)"},{"metadata":{"_uuid":"c42bc888bc35530ad0320c1a0dabe14b4f3353f0","_cell_guid":"a040cbdb-6176-43be-9f97-47e6b877e33a","collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\nfrom keras import optimizers, losses, activations, models\nfrom keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, GlobalMaxPool2D, Concatenate\ninput_shape = (256, 256, 3)\nnclass = len(label_index)\ndef get_model():\n\n    nclass = len(label_index)\n    inp = Input(shape=input_shape)\n    norm_inp = BatchNormalization()(inp)\n    img_1 = Convolution2D(16, kernel_size=3, activation=activations.relu, padding=\"same\")(norm_inp)\n    img_1 = Convolution2D(16, kernel_size=3, activation=activations.relu, padding=\"same\")(img_1)\n    img_1 = MaxPooling2D(pool_size=(3, 3))(img_1)\n    img_1 = Dropout(rate=0.2)(img_1)\n    img_1 = Convolution2D(32, kernel_size=3, activation=activations.relu, padding=\"same\")(img_1)\n    img_1 = Convolution2D(32, kernel_size=3, activation=activations.relu, padding=\"same\")(img_1)\n    img_1 = MaxPooling2D(pool_size=(3, 3))(img_1)\n    img_1 = Dropout(rate=0.2)(img_1)\n    img_1 = Convolution2D(64, kernel_size=2, activation=activations.relu, padding=\"same\")(img_1)\n    img_1 = Convolution2D(20, kernel_size=2, activation=activations.relu, padding=\"same\")(img_1)\n    img_1 = GlobalMaxPool2D()(img_1)\n    img_1 = Dropout(rate=0.2)(img_1)\n    dense_1 = Dense(20, activation=activations.relu)(img_1)\n    dense_1 = Dense(nclass, activation=activations.softmax)(dense_1)\n\n    model = models.Model(inputs=inp, outputs=dense_1)\n    opt = optimizers.Adam()\n\n    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n    model.summary()\n    return model"},{"metadata":{"_uuid":"63c6c88123cc34dc144b7ac34403941cb5d03f3b","_cell_guid":"a93fd2f8-6a74-45f9-8cc9-f4e9e35fb292","collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"\nmodel = get_model()\nfile_path=\"weights.best.hdf5\"\n\ncheckpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n\nearly = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=1)\n\ncallbacks_list = [checkpoint, early] #early\n\nhistory = model.fit(X_train, y, validation_split=0.1, epochs=3, shuffle=True, verbose=2,\n                              callbacks=callbacks_list)\n\n#print(history)\n\nmodel.load_weights(file_path)\n"},{"metadata":{"_uuid":"1066acd65fb9df98c94f6c2265e48f8bdba39385","_cell_guid":"faa1a8ab-794e-49b9-9872-bc3ceda550b0","collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"predicts = model.predict(X_test)\npredicts = np.argmax(predicts, axis=1)\npredicts = [label_index[p] for p in predicts]\n\n"},{"metadata":{"_uuid":"1f4c1fc81a326ccb5d0ed6423a991d7482b860dd","_cell_guid":"cad330e4-bdb0-4ee0-ba38-d7c6bc5888bc","collapsed":true},"outputs":[],"execution_count":null,"cell_type":"code","source":"\ndf = pd.DataFrame(columns=['fname', 'camera'])\ndf['fname'] = index\ndf['camera'] = predicts\ndf.to_csv(\"sub.csv\", index=False)"}],"nbformat_minor":1}