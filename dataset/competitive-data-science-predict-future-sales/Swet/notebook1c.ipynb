{"cells":[{"metadata":{},"cell_type":"markdown","source":"This notebook has been created as part of the Coursera project. Features and ideas have been\ntaken from multiple sources. \n\nEnsembling has been done by stacking linear regression, lightgbm and xgboost predictions."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 100)\n\nfrom itertools import product\nimport xgboost\nimport sklearn\nfrom xgboost import XGBRegressor\nfrom xgboost import plot_importance\n\nimport time\nimport sys\nimport gc\nimport pickle\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path = \"../input/competitive-data-science-predict-future-sales/sales_train.csv\"\ntest_path = \"../input/competitive-data-science-predict-future-sales/test.csv\"\nitems_path = \"../input/competitive-data-science-predict-future-sales/items.csv\"\nshops_path = \"../input/competitive-data-science-predict-future-sales/shops.csv\"\nitem_cat_path = \"../input/competitive-data-science-predict-future-sales/item_categories.csv\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items = pd.read_csv(items_path)\ncats = pd.read_csv(item_cat_path)\nshops = pd.read_csv(shops_path)\ntrain = pd.read_csv( train_path )\ntest = pd.read_csv( test_path )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **EDA**"},{"metadata":{"trusted":true},"cell_type":"code","source":"monthly_sales = train.groupby('date_block_num')['item_cnt_day'].sum()\nmonthly_sales.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize = (10,4))\nplt.xlim(-100, 3000)\nsns.boxplot( x= train.item_cnt_day )\n\nplt.figure( figsize = (10,4) )\nplt.xlim(train.item_price.min(), train.item_price.max())\nsns.boxplot( x = train.item_price )\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing outliers based on boxplots\n\ntrain = train[train.item_price<100000]\ntrain = train[train.item_cnt_day<1100]\n\n#Fix negative price for a item 2973\n\nmedian = np.median(train[train['item_id']==2973].item_price)\ntrain.loc[train['item_price']<0,'item_price'] = median","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales= train.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Feature Engineering**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nshops.loc[shops.shop_name == 'Сергиев Посад ТЦ \"7Я\"', 'shop_name'] = 'СергиевПосад ТЦ \"7Я\"'\nshops['city'] = shops['shop_name'].str.split(' ').map(lambda x: x[0])\nshops.loc[shops.city == '!Якутск', 'city'] = 'Якутск'\nshops['city_code'] = LabelEncoder().fit_transform(shops['city'])\nshops = shops[['shop_id','city_code']]\n\ncats['split'] = cats['item_category_name'].str.split('-')\ncats['type'] = cats['split'].map(lambda x: x[0].strip())\ncats['type_code'] = LabelEncoder().fit_transform(cats['type'])\n# if subtype is nan then type\ncats['subtype'] = cats['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\ncats['subtype_code'] = LabelEncoder().fit_transform(cats['subtype'])\ncats = cats[['item_category_id','type_code', 'subtype_code']]\n\nitems.drop(['item_name'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lag_feature( df,lags, cols ):\n    for col in cols:\n        print(col)\n        tmp = df[[\"date_block_num\", \"shop_id\",\"item_id\",col ]]\n        for i in lags:\n            shifted = tmp.copy()\n            shifted.columns = [\"date_block_num\", \"shop_id\", \"item_id\", col + \"_lag_\"+str(i)]\n            shifted.date_block_num = shifted.date_block_num + i\n            df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_feature(df,grp_cols,feature):\n        new_df = df.groupby(grp_cols).agg({'item_cnt_month': ['mean']})\n        new_df.columns = [feature]\n        new_df.reset_index(inplace = True)\n        df = pd.merge(df,new_df,on = grp_cols,how='left')\n        return(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix = []\ncols  = [\"date_block_num\", \"shop_id\", \"item_id\"]\nfor i in range(34):\n    mat = sales[sales.date_block_num == i]\n    matrix.append( np.array(list( product( [i], mat.shop_id.unique(), mat.item_id.unique() ) ), dtype = np.int16) )\n\nmatrix = pd.DataFrame( np.vstack(matrix), columns = cols )\nmatrix[\"date_block_num\"] = matrix[\"date_block_num\"].astype(np.int8)\nmatrix[\"shop_id\"] = matrix[\"shop_id\"].astype(np.int8)\nmatrix[\"item_id\"] = matrix[\"item_id\"].astype(np.int16)\nmatrix.sort_values( cols, inplace = True )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['date_block_num'] = 34\n#Concatenate train and test dataframes\nmatrix = pd.concat([matrix,test], ignore_index = True)\nmatrix.drop('ID',axis = 1, inplace = True)\nmatrix.fillna(0,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix = pd.merge(matrix, shops, on=['shop_id'], how='left')\nmatrix = pd.merge(matrix, items, on=['item_id'], how='left')\nmatrix = pd.merge(matrix, cats, on=['item_category_id'], how='left')\nmatrix['city_code'] = matrix['city_code'].astype(np.int8)\nmatrix['item_category_id'] = matrix['item_category_id'].astype(np.int8)\nmatrix['type_code'] = matrix['type_code'].astype(np.int8)\nmatrix['subtype_code'] = matrix['subtype_code'].astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmatrix[\"month\"] = matrix[\"date_block_num\"] % 12\nmatrix['year'] = (matrix['date_block_num'] / 12).astype(np.int8)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group = sales.groupby( [\"date_block_num\", \"shop_id\", \"item_id\"] ).agg( {\"item_cnt_day\": [\"sum\"]} )\ngroup.columns = [\"item_cnt_month\"]\ngroup.reset_index( inplace = True)\nmatrix = pd.merge( matrix, group, on = cols, how = \"left\" )\nmatrix[\"item_cnt_month\"] = matrix[\"item_cnt_month\"].fillna(0).clip(0,20).astype(np.float16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb = sales.groupby(['shop_id', 'date_block_num'],as_index=False).agg({'item_cnt_day':[('target_shop','sum')]})\ngb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values]\nmatrix = pd.merge(matrix, gb, how='left', on=['shop_id', 'date_block_num']).fillna(0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb = sales.groupby(['item_id', 'date_block_num'],as_index=False).agg({'item_cnt_day':[('target_item','sum')]})\ngb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values]\nmatrix = pd.merge(matrix, gb, how='left', on=['item_id', 'date_block_num']).fillna(0)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb = sales.groupby(['shop_id','item_id', 'date_block_num'],as_index=False).agg({'item_price':[('item_price_mean','mean')]})\ngb.columns = [col[0] if col[-1]=='' else col[-1] for col in gb.columns.values]\nmatrix = pd.merge(matrix, gb, how='left', on=['shop_id', 'item_id','date_block_num']).fillna(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix[\"revenue\"] = matrix[\"item_price_mean\"]*matrix[\"item_cnt_month\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix = lag_feature( matrix, [1,2,3,6,12], [\"item_cnt_month\"] )\nmatrix = lag_feature( matrix, [1,2,3,6,12], [\"target_shop\"] )\nmatrix = lag_feature( matrix, [1,2,3,6,12], [\"target_item\"] )\nmatrix = lag_feature( matrix, [1,2,3,6,12], [\"revenue\"] )\nmatrix = lag_feature( matrix, [1,2,3,6,12], [\"item_price_mean\"] )\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Mean Encoding**"},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix = add_feature(matrix,['date_block_num', 'shop_id'],'date_shop_avg_cnt')\nmatrix = lag_feature(matrix,[1,2,6,12],['date_shop_avg_cnt'])\n\nmatrix = add_feature(matrix,['date_block_num', 'item_category_id'],'date_cat_avg_cnt')\nmatrix = lag_feature(matrix,[1,2,6,12],['date_cat_avg_cnt'])\n\nmatrix = add_feature(matrix,['date_block_num'],'date_avg_item_cnt')\nmatrix = lag_feature(matrix,[1,2,6,12],['date_avg_item_cnt'])\n\nmatrix = add_feature(matrix,['date_block_num', 'item_id'],'date_item_avg_cnt')\nmatrix = lag_feature(matrix,[1,2,6,12],['date_item_avg_cnt'])\n\nmatrix = add_feature(matrix,['date_block_num', 'city_code'],'date_city_avg_cnt')\nmatrix = lag_feature(matrix,[1,2,6,12],['date_city_avg_cnt'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def optimize_memory(df):\n    start_mem = df.memory_usage().sum() / 1024**2\n    integers = ['int8','int16','int32','int64']\n    floats   = ['float32','float64']\n    int_cols  = [c for c in df if df[c].dtype in integers]\n    float_cols  = [c for c in df if df[c].dtype in floats]\n    for i in int_cols:\n        df[i] = pd.to_numeric(df[i], downcast='integer')\n    for i in float_cols:\n        df[i] = pd.to_numeric(df[i], downcast='float')\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\n\nmatrix.fillna(0,inplace = True)\nmatrix = optimize_memory(matrix)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix = add_feature(matrix,['date_block_num', 'type_code'],'date_type_avg_cnt')\nmatrix = lag_feature(matrix,[1,2,3,12],['date_type_avg_cnt'])\n\nmatrix = add_feature(matrix,['date_block_num', 'subtype_code'],'date_subtype_avg_cnt')\nmatrix = lag_feature(matrix,[1,2,3,12],['date_subtype_avg_cnt'])\n\n\n\nmatrix.fillna(0,inplace = True)\nmatrix = optimize_memory(matrix)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"days = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31])\nmatrix['days'] = matrix['month'].map(days)\n\nmatrix['date_item_day'] = matrix['item_cnt_month'] / matrix['days']\nmatrix = lag_feature(matrix,[1,2,3,12],['date_item_day'])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix.fillna(0,inplace = True)\nmatrix = optimize_memory(matrix)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group = train.groupby(['item_id']).agg({'item_price': ['mean']})\ngroup.columns = ['item_avg_item_price']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['item_id'], how='left')\nmatrix['item_avg_item_price'] = matrix['item_avg_item_price'].astype(np.float16)\n\ngroup = train.groupby(['date_block_num','item_id']).agg({'item_price': ['mean']})\ngroup.columns = ['date_item_avg_item_price']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num','item_id'], how='left')\nmatrix['date_item_avg_item_price'] = matrix['date_item_avg_item_price'].astype(np.float16)\n\nlags = [1,2,3,4,5,6]\nmatrix = lag_feature(matrix, lags, ['date_item_avg_item_price'])\n\nfor i in lags:\n    matrix['delta_price_lag_'+str(i)] = \\\n        (matrix['date_item_avg_item_price_lag_'+str(i)] - matrix['item_avg_item_price']) / matrix['item_avg_item_price']\n\ndef select_trend(row):\n    for i in lags:\n        if row['delta_price_lag_'+str(i)]:\n            return row['delta_price_lag_'+str(i)]\n    return 0\n    \nmatrix['delta_price_lag'] = matrix.apply(select_trend, axis=1)\nmatrix['delta_price_lag'] = matrix['delta_price_lag'].astype(np.float16)\nmatrix['delta_price_lag'].fillna(0, inplace=True)\n\n\nfeatures_to_drop = ['item_avg_item_price', 'date_item_avg_item_price']\nfor i in lags:\n    features_to_drop += ['date_item_avg_item_price_lag_'+str(i)]\n    features_to_drop += ['delta_price_lag_'+str(i)]\n\nmatrix.drop(features_to_drop, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['revenue'] = train['item_cnt_day']*train['item_price']\ngroup = train.groupby(['date_block_num','shop_id']).agg({'revenue': ['sum']})\ngroup.columns = ['date_shop_revenue']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num','shop_id'], how='left')\nmatrix['date_shop_revenue'] = matrix['date_shop_revenue'].astype(np.float32)\n\ngroup = group.groupby(['shop_id']).agg({'date_shop_revenue': ['mean']})\ngroup.columns = ['shop_avg_revenue']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['shop_id'], how='left')\nmatrix['shop_avg_revenue'] = matrix['shop_avg_revenue'].astype(np.float32)\n\nmatrix['delta_revenue'] = (matrix['date_shop_revenue'] - matrix['shop_avg_revenue']) / matrix['shop_avg_revenue']\nmatrix['delta_revenue'] = matrix['delta_revenue'].astype(np.float16)\n\nmatrix = lag_feature(matrix, [1], ['delta_revenue'])\n\nmatrix.drop(['date_shop_revenue','shop_avg_revenue','delta_revenue'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix = matrix[matrix['date_block_num'] > 12]\ndata= matrix.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colsdrop= ['date_item_day','date_item_avg_cnt','date_shop_avg_cnt','date_cat_avg_cnt',\n          'date_avg_item_cnt']\ncolsdrop1= ['target_shop','target_item','item_cnt_month','revenue','item_price_mean',\n           'date_city_avg_cnt','date_type_avg_cnt','date_subtype_avg_cnt']\n\ndropcols= colsdrop+colsdrop1\n#data.drop(colsdrop1, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = data[data.date_block_num < 33].drop(dropcols, axis=1)\nY_train = data[data.date_block_num < 33]['item_cnt_month']\nX_valid = data[data.date_block_num == 33].drop(dropcols, axis=1)\nY_valid = data[data.date_block_num == 33]['item_cnt_month']\nX_test = data[data.date_block_num == 34].drop(dropcols, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_valid.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Model Training**"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = LinearRegression()\nlr.fit(X_train.values, Y_train)\npred_lr = lr.predict(X_valid.values)\n\nprint('Test R-squared for linreg is %f' % r2_score(Y_valid, pred_lr))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_params = {\n               'feature_fraction': 0.75,\n               'metric': 'rmse',\n               'nthread':1, \n               'min_data_in_leaf': 2**7, \n               'bagging_fraction': 0.75, \n               'learning_rate': 0.03, \n               'objective': 'mse', \n               'bagging_seed': 2**7, \n               'num_leaves': 2**7,\n               'bagging_freq':1,\n               'verbose':0 \n              }\n\nmodel = lgb.train(lgb_params, lgb.Dataset(X_train, label=Y_train), 100)\npred_lgb = model.predict(X_valid)\n\nprint('Test R-squared for LightGBM is %f' % r2_score(Y_valid, pred_lgb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del data\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBRegressor\n\nxgb = XGBRegressor(\n    max_depth=8,\n    n_estimators=1000,\n    min_child_weight=300, \n    subsample=0.8,\n    colsample_bytree=0.8,\n    eta = 0.3,\n    seed=42)\n\nxgb.fit(\n    X_train, \n    Y_train, \n    eval_metric=\"rmse\", \n    eval_set=[(X_train, Y_train), (X_valid, Y_valid)], \n    verbose=10, \n    early_stopping_rounds = 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom xgboost import plot_importance\n\ndef plot_features(booster, figsize):    \n    fig, ax = plt.subplots(1,1,figsize=figsize)\n    return plot_importance(booster=booster, ax=ax)\n\nplot_features(xgb, (10,14))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_xgb = xgb.predict(X_valid)\n\nprint('Test R-squared for XGBoost is %f' % r2_score(Y_valid, pred_xgb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\ny_pred = xgb.predict(X_valid).clip(0,20)\ny_pred_tr = xgb.predict(X_train).clip(0,20)\nrmse_tr = mean_squared_error(Y_train, y_pred_tr,squared=False)\nrmse_val = mean_squared_error(Y_valid, y_pred,squared=False)\nprint(\"RMSE Validation: %.5f\" % rmse_val)\nprint(\"RMSE Training: %.5f\" % rmse_tr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Ensembling**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred_lr= lr.predict(X_test)\ntest_pred_lgb= model.predict(X_test)\ntest_pred_xgb= xgb.predict(X_test)\n\nstacked_valid_predictions= np.column_stack((pred_lr, pred_lgb, pred_xgb))\nstacked_test_predictions= np.column_stack((test_pred_lr, test_pred_lgb, test_pred_xgb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_model= LinearRegression()\n\nmeta_model.fit(stacked_valid_predictions, Y_valid)\n\nfinal_predictions= meta_model.predict(stacked_test_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test = final_predictions.clip(0, 20)\n\nsubmission = pd.DataFrame({\n    \"ID\": test.index, \n    \"item_cnt_month\": Y_test\n})\nsubmission.to_csv('1c_submission4.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}