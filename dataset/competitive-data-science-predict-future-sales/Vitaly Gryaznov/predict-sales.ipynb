{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport json\nimport matplotlib.pyplot as plt\nfrom datetime import datetime,timedelta\nimport re as re\nfrom itertools import product\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_path_to_data = '/kaggle/input/competitive-data-science-predict-future-sales/'\ncategories = pd.read_csv(sub_path_to_data + 'item_categories.csv')\nitems = pd.read_csv(sub_path_to_data + 'items.csv')\nsales_train = pd.read_csv(sub_path_to_data + 'sales_train.csv')\nshops = pd.read_csv(sub_path_to_data + 'shops.csv')\ntest = pd.read_csv(sub_path_to_data + 'test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Take an initial look onto the data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categories.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categories.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Explore sales data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"getting numerical columns info","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train.describe(include=[np.number]).T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"checking for missing data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"checking for duplicates","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"duplicate_sales = sales_train.loc[sales_train.duplicated(keep=False)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"duplicate_sales","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Those values could be real duplicates, or we just need to sum them to get the correct value of item_cnt_day.\nAfter comparing score with dropping and summing duplicates, I see that score is better when keep duplicates and sume tham later","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Another assumption is that we shouldhave only one row for each combination of 'date', 'shop_id', 'item_id'. Let's do this check with excluding already found duplicates:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train.loc[sales_train.duplicated(subset= ['date', 'shop_id', 'item_id'], keep=False) &\\\n                ~sales_train.duplicated(keep=False)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I see that sometimes the difference is in price, which looks reasonable. Maybe it's because of selling used/damaged/something else items. Need keep in mind it for later. Now adding 'same price' criteria to the duplicate search ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train.loc[sales_train.duplicated(subset= ['date', 'shop_id', 'item_id', 'item_price'], keep=False) & ~sales_train.duplicated(keep=False)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No other duplicates","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"So, we have nothing to drop ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train.drop_duplicates(keep=\"first\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some data cleaning","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train.loc[sales_train.shop_id == 0, 'shop_id'] = 57\ntest.loc[test.shop_id == 0, 'shop_id'] = 57\n\nsales_train.loc[sales_train.shop_id == 1, 'shop_id'] = 58\ntest.loc[test.shop_id == 1, 'shop_id'] = 58\n\nsales_train.loc[sales_train.shop_id == 10, 'shop_id'] = 11\ntest.loc[test.shop_id == 10, 'shop_id'] = 11","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Converting type of the date to work with it later","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"checking that all dates are in the correct format","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train.loc[~sales_train['date'].str.match('^[0-3]\\d\\.[0-1]\\d\\.20\\d\\d$')]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All dates are good. Converting:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train['date'] =  pd.to_datetime(sales_train['date'], format='%d.%m.%Y')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Taking initial look on the sales dynamics","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We are interested in sales sums for each product separately per month, but it could be useful to take a look at the sum sales for all products and all shops","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Check for outliers first","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Check for outliers","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Looking at dates with number of sales more than 7000","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_sum = sales_train.groupby(['date'])['item_cnt_day'].sum().reset_index().set_index(\"date\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_sum.loc[sales_sum.item_cnt_day > 7000]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"looks good","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Checking for super high prices","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train.loc[sales_train.item_price > 50000]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drop them","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train = sales_train.loc[sales_train.item_price < 50000]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now preparing the diagram","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_sum.plot(kind='bar', color='black', figsize=(24,6))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- we see some peaks\n- May be there is a global trend of sales\n\nBoth things could be useful","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Calculating values of sales per month","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"claculating monthly values and clipping to remove outliers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = sales_train.groupby(['date_block_num', 'shop_id', 'item_id'])['item_cnt_day'].sum().reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.rename(columns={\"item_cnt_day\": \"item_cnt_month\"}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['item_cnt_month'] = train['item_cnt_month'].fillna(0).clip(0,20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Explore total number of sales for each shop","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"shops_list = train['shop_id'].unique()\n\nfig, axs = plt.subplots(30,2, figsize=(20, 200), facecolor='w', edgecolor='k')\nfig.subplots_adjust(hspace = .5, wspace=.1)\naxs = axs.ravel()\n\nfor index, shop_id in enumerate(shops_list):\n    shop_sales = train.loc[train['shop_id'] == shop_id]\n    sales_per_month = shop_sales.groupby('date_block_num')['item_cnt_month'].sum().to_frame()\n    \n    axs[index].plot(sales_per_month.index, sales_per_month['item_cnt_month'], 'o-')\n    axs[index].set_xticks(sales_per_month.index)\n    axs[index].grid()\n    \n    axs[index].title.set_text(\"sales for shop {0}\".format(shop_id))\n    axs[index].set_xlabel('month')\n    axs[index].set_ylabel('number of sales')\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lookin at plots above we can say that:\n1. For some shops data for some month is missing \n2. For some shops we have data only for the first two months. Need to check that those shops are in the test set\n3. The age of the shops is very different\n4. Total dynamic of sales is defferent from shop to shop\n5. For some shops only one month provided\n6. For some shopes last months not provided","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"I think it makes sense to remove shops 0,1,11 if they are not in the test set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"shop_ids_test = test.shop_id.unique()\nfor shop_id in [0,1,11,20,8]:\n    print (shop_id in shop_ids_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train = train.loc[~(train.shop_id.isin([0,1,11,20,8]))]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We can already add test data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test['date_block_num'] = 34\ntrain = pd.concat([train, test.drop('ID', axis=1)], ignore_index=True, sort=False, keys=['date_block_num', 'shop_id', 'item_id'])\ntrain.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Mean encode item_id","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"index_cols = ['shop_id', 'item_id', 'date_block_num']\n\ngrid = [] \nfor block_num in train.date_block_num.unique():\n    cur_shops = train[train['date_block_num']==block_num]['shop_id'].unique()\n    cur_items = train[train['date_block_num']==block_num]['item_id'].unique()\n    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n\ngrid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n\ntrain = pd.merge(grid,train,how='left',on=index_cols).fillna(0)\n\ntrain.sort_values(['date_block_num','shop_id','item_id'],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cumsum = train.groupby('item_id')['item_cnt_month'].cumsum() - train['item_cnt_month']\ncumc = train.groupby('item_id').cumcount() + 1\ntrain['item_target_enc'] = cumsum/cumc\ntrain['item_target_enc'].fillna(0.3343, inplace=True) \n\nencoded_feature = train['item_target_enc'].values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Add date related features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['month'] = train['date_block_num'].map(lambda month: month-12*(month//12))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def number_of_weekens_in_month(first_day):\n    ndays = first_day.daysinmonth\n    weekends = 0\n    for i in range(ndays):\n        if (pd.to_datetime(first_day + timedelta(days=(np.long(i)))).dayofweek in [5, 6]): \n            weekends = weekends + 1\n    return weekends","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"first_days_map = sales_train.groupby('date_block_num')['date'].min().map(lambda date: date.replace(day=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['number_of_weekends'] = train['date_block_num'].map(first_days_map.map(number_of_weekens_in_month))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train['month'] = sales_train['date_block_num'].map(lambda month: month-12*(month//12))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['days_in_month'] = train['date_block_num'].map(first_days_map.map(lambda day: day.daysinmonth))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Calculate target value for the previous months","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def specify_the_accuracy_group(row):\n    num_of_block = row.date_block_num - 1\n    if (num_of_block != -1):\n        values = train.loc[(train['shop_id']==row.shop_id) & (train['item_id']==row.item_id)&\\\n                         (train['date_block_num']==num_of_block),['item_cnt_month']].values\n        return 0 if (values.size==0) else values[0][0]\n    else:\n        return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def previous_months_value(df, collumn, offset):\n    previous_month_values = df.copy()\n    previous_month_values['date_block_num'] = previous_month_values['date_block_num'] + offset\n    previous_month_values.rename(columns={collumn: 'prev_month_' + str(offset) + '_' + collumn}, inplace=True)\n    return pd.merge(df, previous_month_values[['date_block_num','shop_id','item_id','prev_month_' + str(offset) + '_' + collumn]], on=['date_block_num','shop_id','item_id'], how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"offsets = [1,2,3,9]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"column_to_offset = 'item_cnt_month'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for offset in offsets:\n    train = previous_months_value(train, column_to_offset, offset)\n    values = {'prev_month_' + str(offset) + '_' + column_to_offset: 0}\n    train = train.fillna(value=values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Add prices data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"item_price_map = sales_train.loc[sales_train.item_price > 0].groupby(['item_id'])['item_price'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['price'] = train['item_id'].map(item_price_map)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Add feature 'new product'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"first_month_product_appeared = sales_train.groupby(['shop_id', 'item_id'])['date_block_num'].min().reset_index()\nfirst_month_product_appeared.rename(columns={'date_block_num': 'first_appeared'}, inplace=True)\ntrain = pd.merge(train,first_month_product_appeared, on=['shop_id','item_id'], how='left')\ntrain['first_appeared'] = train['date_block_num'] - train['first_appeared'] + 1\ntrain['first_appeared'] = train['first_appeared'].map(lambda n: 0 if (n < 0) else n)\nvalues = {'first_appeared': 0}\ntrain = train.fillna(value=values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Add a featur 'new shop' to compare shops age","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"new_shop = train.groupby('shop_id')['date_block_num'].min().map(lambda month: 1 if (month > 10) else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['new_shop'] = train['shop_id'].map(new_shop)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Add a feature 'incompleate data'","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We saw previously, that data for some shops is incompleat. Use simple criteria, ofcause it's possible to find a better criteria, or select shops with incompleate data manually based on grafs above","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_incompleate_data = train.groupby('shop_id')['date_block_num'].max().map(lambda month: 1 if (month < 33) else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['incompleate_data'] = train['shop_id'].map(sales_incompleate_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Encode categorical features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"shops['city'] = shops['shop_name'].str.split(' ').map(lambda x: x[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops.loc[shops.city == '!Якутск', 'city'] = 'Якутск'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops['city'] = shops['shop_name'].str.split(' ').map(lambda x: x[0])\nshops.loc[shops.city == '!Якутск', 'city'] = 'Якутск'\nshops['city_code'] = LabelEncoder().fit_transform(shops['city'])\nshops = shops[['shop_id','city_code']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categories['split'] = categories['item_category_name'].str.split('-')\ncategories['type'] = categories['split'].map(lambda x: x[0].strip())\ncategories['type_code'] = LabelEncoder().fit_transform(categories['type'])\n\ncategories['subtype'] = categories['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\ncategories['subtype_code'] = LabelEncoder().fit_transform(categories['subtype'])\ncategories = categories[['item_category_id','type_code', 'subtype_code']]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.merge(train, shops, on=['shop_id'], how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop('month', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.merge(train, items, on=['item_id'], how='left')\ntrain = pd.merge(train, categories, on=['item_category_id'], how='left')\ntrain['city_code'] = train['city_code'].astype(np.int8)\ntrain['item_category_id'] = train['item_category_id'].astype(np.int8)\ntrain['type_code'] = train['type_code'].astype(np.int8)\ntrain['subtype_code'] = train['subtype_code'].astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.drop(['item_name'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predate data for training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train[train.date_block_num < 33].drop(['item_cnt_month'], axis=1)\nY_train = train[train.date_block_num < 33]['item_cnt_month']\nX_valid = train[train.date_block_num == 33].drop(['item_cnt_month'], axis=1)\nY_valid = train[train.date_block_num == 33]['item_cnt_month']\nX_test = train[train.date_block_num == 34].drop(['item_cnt_month'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prepare simple baseline","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"baseline_preds = np.full((len(X_valid)), train.loc[train.date_block_num < 33, 'item_cnt_month'].mean())\nrmse_b = np.sqrt(mean_squared_error(Y_valid.values, baseline_preds))\nprint(\"RMSE: %f\" % (rmse_b))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nparameters = {'tree_method': 'exact'}\nmodel = XGBRegressor(\n    max_depth=8,\n    tree_method='exact',\n    n_estimators=1000,\n    min_child_weight=300, \n    colsample_bytree=0.8, \n    subsample=0.8, \n    eta=0.3,    \n    seed=42)\n\nmodel.fit(\n    X_train, \n    Y_train, \n    eval_metric=\"rmse\", \n    eval_set=[(X_train, Y_train), (X_valid, Y_valid)], \n    verbose=True, \n    early_stopping_rounds = 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predict test values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.days_in_month = 30\nX_test.number_of_weekends = 9","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = pd.merge(test.drop('ID', axis=1), X_test, on=['shop_id', 'item_id', 'date_block_num'], how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_test = model.predict(X_test).clip(0, 20)\n\nsubmission = pd.DataFrame({\n    \"ID\": test.index, \n    \"item_cnt_month\": Y_test\n})\nsubmission.to_csv('xgb_submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}