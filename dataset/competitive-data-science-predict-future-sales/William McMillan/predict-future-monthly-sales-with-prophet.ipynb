{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Practicing Basic Time-Series Visualizations\n# & Exploring Forecasting with FB Prophet"},{"metadata":{},"cell_type":"markdown","source":"### Introduction"},{"metadata":{},"cell_type":"markdown","source":"The purpose of this kernel is to get more familiar with time-series data, as well as to test-drive FB Prophet. I do not produce a model to submit to the competition."},{"metadata":{},"cell_type":"markdown","source":"Import the necessary packages."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Basic packages\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random as rd # generating random numbers\nimport datetime # manipulating date formats\n# Viz\nimport matplotlib.pyplot as plt # basic plotting\nimport seaborn as sns # for prettier plots\n\nfrom itertools import product\nfrom sklearn.preprocessing import LabelEncoder\n\nimport gc; gc.enable()\n\n# TIME SERIES\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom pandas.plotting import autocorrelation_plot\nfrom statsmodels.tsa.stattools import adfuller, acf, pacf,arma_order_select_ic\nimport statsmodels.formula.api as smf\nimport statsmodels.tsa.api as smt\nimport statsmodels.api as sm\nfrom scipy import stats\n\n\n# settings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"folder_path = '../input/competitive-data-science-predict-future-sales/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load item_categories, items, shops & train (test & submission data will not be needed).\nitem_cat = pd.read_csv(f'{folder_path}item_categories.csv')\nitems = pd.read_csv(f'{folder_path}items.csv')\nshops = pd.read_csv(f'{folder_path}shops.csv')\n#submission = pd.read_csv(f'{folder_path}sample_submission.csv')\n#test = pd.read_csv(f'{folder_path}test.csv')\ntrain = pd.read_csv(f'{folder_path}sales_train.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Briefly check out the different files."},{"metadata":{"trusted":true},"cell_type":"code","source":"item_cat.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Join the tables to the train data set.\n\ntrain = pd.merge(train, items, on='item_id', how='inner')\ntrain = pd.merge(train, item_cat, on='item_category_id', how='inner')\ntrain = pd.merge(train, shops, on='shop_id', how='inner')\n\ndel item_cat, shops\n\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning & Dealing with Outliers"},{"metadata":{},"cell_type":"markdown","source":"There are two outliers that need to be removed, as well as a negative value that needs to be addressed. One of the outliers has an outrageous 'item_price'; the other one has an extreme 'item_cnt_day'."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['item_price'].sort_values().tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['item_cnt_day'].sort_values().tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train['item_price'] > 300000.00]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the two outliers highlights their respective ridiculousness.\nplt.figure(figsize=(10,4))\nplt.xlim(-100, 2500)\nsns.boxplot(x=train.item_cnt_day)\n\nplt.figure(figsize=(10,4))\nplt.xlim(train.item_price.min(), train.item_price.max()*1.1)\nsns.boxplot(x=train.item_price)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping two outlier values highlighted above:\ntrain = train[train.item_price<300000]\ntrain = train[train.item_cnt_day<2000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the correct median_price value based on other positively valued purchases with the same 'date_block_num', 'shop_id', & 'item_id':\nmedian_price = train[(train['date_block_num']==4)&(train['shop_id']==32)&(train['item_id']==2973)&(train['item_price']>0)].item_price.median()\n\n# Change the 'item_price' value for the entry with a negative value\ntrain.loc[train['item_price']<0, 'item_price'] = median_price","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make sure the value has been changed\ntrain[(train['shop_id']==32)&(train['item_id']==2973)&(train['date_block_num']==4)].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A few shops are duplicates of each other (according to its name). Both the train and test sets need to be fixed.\n# Якутск Орджоникидзе, 56\ntrain.loc[train.shop_id == 0, 'shop_id'] = 57\n#test.loc[test.shop_id == 0, 'shop_id'] = 57\n# Якутск ТЦ \"Центральный\"\ntrain.loc[train.shop_id == 1, 'shop_id'] = 58\n#test.loc[test.shop_id == 1, 'shop_id'] = 58\n# Жуковский ул. Чкалова 39м²\ntrain.loc[train.shop_id == 10, 'shop_id'] = 11\n#test.loc[test.shop_id == 10, 'shop_id'] = 11\n\n# An extra space on a particular shope name needs to be removed in order to set up execution of the split() method.\ntrain.loc[train.shop_name == 'Сергиев Посад ТЦ \"7Я\"', 'shop_name'] = 'СергиевПосад ТЦ \"7Я\"'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Other people on KAGGLE helpfully created a translation of most of the categories."},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_categories = ['Cinema - DVD', 'PC Games - Standard Editions',\n                    'Music - Local Production CD', 'Games - PS3', 'Cinema - Blu-Ray',\n                    'Games - XBOX 360', 'PC Games - Additional Editions', 'Games - PS4',\n                    'Gifts - Stuffed Toys', 'Gifts - Board Games (Compact)',\n                    'Gifts - Figures', 'Cinema - Blu-Ray 3D',\n                    'Programs - Home and Office', 'Gifts - Development',\n                    'Gifts - Board Games', 'Gifts - Souvenirs (on the hinge)',\n                    'Cinema - Collection', 'Music - MP3', 'Games - PSP',\n                    'Gifts - Bags, Albums, Mouse Pads', 'Gifts - Souvenirs',\n                    'Books - Audiobooks', 'Gifts - Gadgets, robots, sports',\n                    'Accessories - PS4', 'Games - PSVita',\n                    'Books - Methodical materials 1C', 'Payment cards - PSN',\n                    'PC Games - Digit', 'Games - Game Accessories', 'Accessories - XBOX 360',\n                    'Accessories - PS3', 'Games - XBOX ONE', 'Music - Vinyl',\n                    'Programs - 1C: Enterprise 8', 'PC Games - Collectible Editions',\n                    'Gifts - Attributes', 'Service Tools',\n                    'Music - branded production CD', 'Payment cards - Live!',\n                    'Game consoles - PS4', 'Accessories - PSVita', 'Batteries',\n                    'Music - Music Video', 'Game Consoles - PS3',\n                    'Books - Comics, Manga', 'Game Consoles - XBOX 360',\n                    'Books - Audiobooks 1C', 'Books - Digit',\n                    'Payment cards (Cinema, Music, Games)', 'Gifts - Cards, stickers',\n                    'Accessories - XBOX ONE', 'Pure media (piece)',\n                    'Programs - Home and Office (Digital)', 'Programs - Educational',\n                    'Game consoles - PSVita', 'Books - Artbooks, encyclopedias',\n                    'Programs - Educational (Digit)', 'Accessories - PSP',\n                    'Gaming consoles - XBOX ONE', 'Delivery of goods',\n                    'Payment Cards - Live! (Figure) ',' Tickets (Figure) ',\n                    'Music - Gift Edition', 'Service Tools - Tickets',\n                    'Net media (spire)', 'Cinema - Blu-Ray 4K', 'Game consoles - PSP',\n                    'Game Consoles - Others', 'Books - Audiobooks (Figure)',\n                    'Gifts - Certificates, Services', 'Android Games - Digit',\n                    'Programs - MAC (Digit)', 'Payment Cards - Windows (Digit)',\n                    'Books - Business Literature', 'Games - PS2', 'MAC Games - Digit',\n                    'Books - Computer Literature', 'Books - Travel Guides',\n                    'PC - Headsets / Headphones', 'Books - Fiction',\n                    'Books - Cards', 'Accessories - PS2', 'Game consoles - PS2',\n                    'Books - Cognitive literature']\n\ndict_shops = ['Moscow Shopping Center \"Semenovskiy\"', \n              'Moscow TRK \"Atrium\"', \n              \"Khimki Shopping Center\",\n              'Moscow TC \"MEGA Teply Stan\" II', \n              'Yakutsk Ordzhonikidze, 56',\n              'St. Petersburg TC \"Nevsky Center\"', \n              'Moscow TC \"MEGA Belaya Dacha II\"',\n              'Voronezh (Plekhanovskaya, 13)', \n              'Yakutsk Shopping Center \"Central\"',\n              'Chekhov SEC \"Carnival\"', \n              'Sergiev Posad TC \"7Ya\"',\n              'Tyumen TC \"Goodwin\"',\n              'Kursk TC \"Pushkinsky\"', \n              'Kaluga SEC \"XXI Century\"',\n              'N.Novgorod Science and entertainment complex \"Fantastic\"',\n              'Moscow MTRC \"Afi Mall\"',\n              'Voronezh SEC \"Maksimir\"', 'Surgut SEC \"City Mall\"',\n              'Moscow Shopping Center \"Areal\" (Belyaevo)', 'Krasnoyarsk Shopping Center \"June\"',\n              'Moscow TK \"Budenovsky\" (pav.K7)', 'Ufa \"Family\" 2',\n              'Kolomna Shopping Center \"Rio\"', 'Moscow Shopping Center \"Perlovsky\"',\n              'Moscow Shopping Center \"New Century\" (Novokosino)', 'Omsk Shopping Center \"Mega\"',\n              'Moscow Shop C21', 'Tyumen Shopping Center \"Green Coast\"',\n              'Ufa TC \"Central\"', 'Yaroslavl shopping center \"Altair\"',\n              'RostovNaDonu \"Mega\" Shopping Center', '\"Novosibirsk Mega \"Shopping Center',\n              'Samara Shopping Center \"Melody\"', 'St. Petersburg TC \"Sennaya\"',\n              \"Volzhsky Shopping Center 'Volga Mall' \",\n              'Vologda Mall \"Marmelad\"', 'Kazan TC \"ParkHouse\" II',\n              'Samara Shopping Center ParkHouse', '1C-Online Digital Warehouse',\n              'Online store of emergencies', 'Adygea Shopping Center \"Mega\"',\n              'Balashikha shopping center \"October-Kinomir\"' , 'Krasnoyarsk Shopping center \"Vzletka Plaza\" ',\n              'Tomsk SEC \"Emerald City\"', 'Zhukovsky st. Chkalov 39m? ',\n              'Kazan Shopping Center \"Behetle\"', 'Tyumen SEC \"Crystal\"',\n              'RostovNaDonu TRK \"Megacenter Horizon\"',\n              '! Yakutsk Ordzhonikidze, 56 fran', 'Moscow TC \"Silver House\"',\n              'Moscow TK \"Budenovsky\" (pav.A2)', \"N.Novgorod SEC 'RIO' \",\n              '! Yakutsk TTS \"Central\" fran', 'Mytishchi TRK \"XL-3\"',\n              'RostovNaDonu TRK \"Megatsentr Horizon\" Ostrovnoy', 'Exit Trade',\n              'Voronezh SEC City-Park \"Grad\"', \"Moscow 'Sale'\",\n              'Zhukovsky st. Chkalov 39m² ',' Novosibirsk Shopping Mall \"Gallery Novosibirsk\"']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.item_category_name = train.item_category_name.map(dict(zip(train.item_category_name.value_counts().index, dict_categories)))\ntrain.shop_name = train.shop_name.map(dict(zip(train.shop_name.value_counts().index, dict_shops)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's helpful to correct some of the shop names."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['shop_name'] = train['shop_name'].replace([' Novosibirsk Shopping Mall \"Gallery Novosibirsk\"'], 'Novosibirsk Shopping Mall \"Gallery Novosibirsk\"')\ntrain['shop_name'] = train['shop_name'].replace(['! Yakutsk Ordzhonikidze, 56 fran'], 'Yakutsk Ordzhonikidze, 56 fran')\ntrain['shop_name'] = train['shop_name'].replace(['! Yakutsk TTS \"Central\" fran   '], 'Yakutsk TTS \"Central\" fran')\ntrain['shop_name'] = train['shop_name'].replace(['! Yakutsk TTS \"Central\" fran'], 'Yakutsk TTS \"Central\" fran')\ntrain['shop_name'] = train['shop_name'].replace(['1C-Online Digital Warehouse'], 'Online Digital Warehouse')\ntrain['shop_name'] = train['shop_name'].replace(['\"Novosibirsk Mega \"Shopping Center'], 'Novosibirsk \"Mega\" Shopping Center')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I create a different dataframe named 'sales' to focus on categories & cities."},{"metadata":{"trusted":true},"cell_type":"code","source":"sales = train.copy()\n\nsales['city'] = sales['shop_name'].str.split(' ').map(lambda x: x[0])\nsales.loc[sales.city == '!Якутск', 'city'] = 'Якутск'\n##sales['city_code'] = LabelEncoder().fit_transform(sales['city'])\n\nsales['split'] = sales['item_category_name'].str.split('-')\nsales['type'] = sales['split'].map(lambda x: x[0].strip())\n##sales['type_code'] = LabelEncoder().fit_transform(sales['type'])\n\n## if subtype is nan then type\nsales['subtype'] = sales['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\n##sales['subtype_code'] = LabelEncoder().fit_transform(sales['subtype'])\nsales = sales.drop(columns=['shop_name', 'split'], inplace=False)\nsales.drop(['item_name'], axis=1, inplace=True)\n\nsales.drop(columns=['item_category_name'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This adjustment to the train data is more for those who plan on using XGBoost to model the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['city'] = train['shop_name'].str.split(' ').map(lambda x: x[0])\ntrain.loc[train.city == '!Якутск', 'city'] = 'Якутск'\ntrain['city_code'] = LabelEncoder().fit_transform(train['city'])\n\ntrain['split'] = train['item_category_name'].str.split('-')\ntrain['type'] = train['split'].map(lambda x: x[0].strip())\ntrain['type_code'] = LabelEncoder().fit_transform(train['type'])\n\n# if subtype is nan then type\ntrain['subtype'] = train['split'].map(lambda x: x[1].strip() if len(x) > 1 else x[0].strip())\ntrain['subtype_code'] = LabelEncoder().fit_transform(train['subtype'])\ntrain = train.drop(columns=['item_category_name', 'shop_name', 'split', 'city', 'type', 'subtype'], inplace=False)\n\ntrain.drop(['item_name'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I prefer 'month' to 'date_block_num'."},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.rename(columns={'date_block_num': 'month'}, inplace=True)\ntrain.rename(columns={'date_block_num': 'month'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Decisions are made to consolidate types of products and reduce the number of categories."},{"metadata":{"trusted":true},"cell_type":"code","source":"sales['type'] = sales['type'].replace(['PC Games', 'Android Games', 'MAC Games','PC', 'Accessories', 'Batteries'], 'Games')\nsales['type'] = sales['type'].replace(['Game consoles', 'Gaming consoles'], 'Game Consoles')\nsales['type'] = sales['type'].replace(['Payment cards', 'Payment cards (Cinema, Music, Games)'], 'Payment Cards')\nsales['type'] = sales['type'].replace(['Games', 'Game Consoles'], 'Gaming')\nsales['type'] = sales['type'].replace(['Cinema'], 'Movies')\nsales['type'] = sales['type'].replace(['Net media (spire)', 'Pure media (piece)', 'Tickets (Figure)', 'Programs'], 'Software')\nsales['type'] = sales['type'].replace(['Service Tools', 'Delivery of goods'], 'Service & Delivery')\nsales['type'] = sales['type'].replace(['Payment Cards', 'Gifts'], 'Gifts & Gift Cards')\nsales['type'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Not familiar with Russian rubles and simply wanting to reduce the values that are displayed, I create a new 'revenue' column called sales."},{"metadata":{"trusted":true},"cell_type":"code","source":"sales['total_sales'] = (sales['item_price'] * sales['item_cnt_day'])/1000\ntrain['total_sales'] = (train['item_price'] * train['item_cnt_day'])/1000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"year_sales = sales.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"year_sales['year'] = sales['date'].str.split('.').map(lambda x: x[2])\nyear_sales.drop(columns=['date'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#formatting the date column correctly\nsales.date = sales.date.apply(lambda x:datetime.datetime.strptime(x, '%d.%m.%Y'))\n# check\nprint(sales.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# type_sales = sales.groupby([\"shop_id\",\"type\"])[\n#     \"year\",\"item_price\",\"item_cnt_day\"].agg({\"year\":[\"min\",'max'],\"item_price\":\"mean\",\"item_cnt_day\":\"sum\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#formatting the date column correctly\ntrain.date = train.date.apply(lambda x:datetime.datetime.strptime(x, '%d.%m.%Y'))\n# check\nprint(train.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# top_ten = top_ten_df.groupby([\"date_block_num\",\"shop_id\",\"item_id\"])[\n#     \"date\",\"item_price\",\"item_cnt_day\"].agg({\"date\":[\"min\",'max'],\"item_price\":\"mean\",\"item_cnt_day\":\"sum\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Aggregate to monthly level the required metrics\n\nmonthly_sales = train.groupby([\"month\",\"shop_id\",\"item_id\"])[\n    \"date\",\"item_price\",\"item_cnt_day\"].agg({\"date\":[\"min\",'max'],\"item_price\":\"mean\",\"item_cnt_day\":\"sum\"})\n\n## Lets break down the line of code here:\n# Aggregate by \"date-block_num\" (month), \"shop_id\", and \"item_id\"\n# Select the columns: \"date\", \"item_price\", and \"item_cnt\" (sales)\n# Provide a dictionary which says what aggregation to perform on which column\n# min and max on the date\n# average of the item_price\n# sum of the sales\n\nmonthly_sales.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of items per category\n\nplt.style.use('fivethirtyeight')\nx = items.groupby(['item_category_id']).count()\nx = x.sort_values(by='item_id',ascending=False)\nx = x.iloc[0:10].reset_index()\nx\n# plot\nplt.figure(figsize=(8,4))\nax = sns.barplot(x.item_category_id, x.item_id)\nplt.title(\"Items per Category\")\nplt.ylabel('# of Items', fontsize=12)\nplt.xlabel('Category', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"year_sales['month'] = year_sales['month'].replace([11, 23], 'Dec')\nyear_sales['month'] = year_sales['month'].replace([10, 22], 'Nov')\nyear_sales['month'] = year_sales['month'].replace([9, 21, 33], 'Oct')\nyear_sales['month'] = year_sales['month'].replace([8, 20, 32], 'Sept')\nyear_sales['month'] = year_sales['month'].replace([7, 19, 31], 'Aug')\nyear_sales['month'] = year_sales['month'].replace([6, 18, 30], 'July')\nyear_sales['month'] = year_sales['month'].replace([5, 17, 29], 'June')\nyear_sales['month'] = year_sales['month'].replace([4, 16, 28], 'May')\nyear_sales['month'] = year_sales['month'].replace([3, 15, 27], 'Apr')\nyear_sales['month'] = year_sales['month'].replace([2, 14, 26], 'Mar')\nyear_sales['month'] = year_sales['month'].replace([1, 13, 25], 'Feb')\nyear_sales['month'] = year_sales['month'].replace([0, 12, 24], 'Jan')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales['month'] = sales['month'] + 1\n# train['month'] = train['month'] + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.rename(columns={'type': 'category'}, inplace=True)\nyear_sales.rename(columns={'type': 'category'}, inplace=True)\ntrain.rename(columns={'type': 'category'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Computing Total Sales of the Company per month & plotting that data:\n\nplt.style.use('fivethirtyeight')\n\ncs = train.groupby([\"month\"])[\"total_sales\"].sum()\ncs.astype('float')\nplt.figure(figsize=(14,7))\nplt.title('1C Company Sales (January 2013 - October 2015)', fontsize=22)\nplt.xlabel('Month & Year', fontsize=14)\nplt.ylabel('Sales/1000 in Russian Rubles', fontsize=14)\nticks = [0, 4, 10, 16, 22, 28, 33]\n\nplt.xticks(ticks, ['January13', 'May13', 'November13', 'May14', 'November14', 'May15', 'October15'])\n           \nplt.plot(cs)\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Assessing the presence of trend & seasonality via Rolling Statistics:\n\nplt.style.use(\"fivethirtyeight\")\nplt.figure(figsize=(14,7))\nplt.plot(cs.rolling(window=12,center=False).mean(),label='Rolling Mean - [Trend Line of Company Sales]');\nplt.plot(cs.rolling(window=12,center=False).std(),label='Rolling Standard Deviation - [Seasonality]');\nplt.legend()\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decomposing Time-Series into Trend, Seasonality, and Residuals\n# Is the seasonality Multiplicative or Additive? \n# That is, does the magnitude of the seasonality increase when the time series increases?\n# Let's check for Multiplicative Seasonality first with statsmodels.tsa (Time Series Analysis):\n\nimport statsmodels.api as sm\nplt.style.use('seaborn-poster')\n\nts_decomposed = sm.tsa.seasonal_decompose(cs.values,freq=12,model=\"multiplicative\")\nplt.figure(figsize=(16,12))\nfig = ts_decomposed.plot()\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"year_sales.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"year_sales['month'] = year_sales['month'].replace(['Dec'], 12)\nyear_sales['month'] = year_sales['month'].replace(['Nov'], 11)\nyear_sales['month'] = year_sales['month'].replace(['Oct'], 10)\nyear_sales['month'] = year_sales['month'].replace(['Sept'], 9)\nyear_sales['month'] = year_sales['month'].replace(['Aug'], 8)\nyear_sales['month'] = year_sales['month'].replace(['July'], 7)\nyear_sales['month'] = year_sales['month'].replace(['June'], 6)\nyear_sales['month'] = year_sales['month'].replace(['May'], 5)\nyear_sales['month'] = year_sales['month'].replace(['Apr'], 4)\nyear_sales['month'] = year_sales['month'].replace(['Mar'], 3)\nyear_sales['month'] = year_sales['month'].replace(['Feb'], 2)\nyear_sales['month'] = year_sales['month'].replace(['Jan'], 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"year_sales.rename(columns={'month': 'Month'}, inplace=True)\nyear_sales.rename(columns={'total_sales': 'Sales'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"year_sales.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.available","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfrom seaborn import FacetGrid\n\nplt.style.use('seaborn-darkgrid')\n\nmonthlyRev = pd.DataFrame(year_sales.groupby([\"Month\", \"year\"], as_index=False)[\"Sales\"].sum())\n\ng = sns.FacetGrid(data = monthlyRev.sort_values(by=\"Month\"), hue = \"year\", size = 7, legend_out=True)\ng = g.map(plt.plot, \"Month\", \"Sales\")\ng.add_legend()\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle('1c - Annual Company Sales', fontsize=22)\ng.set(xticks=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\ng.set_xticklabels(['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'], rotation=35)\ng\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"year_sales.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"category_sales = sales[['month', 'category', 'total_sales']].copy()\nbar_cat_sales = sales[['month', 'category', 'total_sales']].copy()\nz = bar_cat_sales.groupby([\"category\"])[\"total_sales\"].agg({'total_sales': sum})\nz = z.sort_values(by='total_sales',ascending=False)\nz = z.iloc[0:10].reset_index()\nz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nplt.style.use('fivethirtyeight')\n\nsns.barplot(y = z.category, x = \"total_sales\", data = z)\nplt.title(\"Sales Broken Down by Category\")\nplt.xlabel(\"Sales\")\nplt.ylabel(\"Product Category\")\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"item_cat_sales = sales[['month', 'item_category_id', 'category', 'subtype','item_cnt_day']].copy()\n\nitem_category_sales = item_cat_sales.groupby([\"item_category_id\", 'category', 'subtype'])[\"item_cnt_day\"].agg({'item_cnt_day': sum})\n# item_category_sales['cat_sub'] = item_category_sales['category'] + item_category_sales['subtype']\nz = item_category_sales.sort_values(by='item_cnt_day', ascending=False)\nz = z.iloc[0:10].reset_index()\nz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nplt.style.use('fivethirtyeight')\n\nsns.barplot(y = z.subtype, x = \"item_cnt_day\", data = z)\nplt.title(\"Highest Number of Units\")\nplt.xlabel(\"Number of Units\")\nplt.ylabel(\"Category Subtype\")\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"annual_sales = year_sales[['Month', 'year', 'category', 'Sales']].copy()\nannual_sales.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"annual_movies = annual_sales[annual_sales.category=='Movies']\nannual_music = annual_sales[annual_sales.category=='Music']\nannual_software = annual_sales[annual_sales.category=='Software']\n\nannual_eliminate = annual_sales.loc[(annual_sales.category == 'Movies')|(annual_sales.category == 'Music')|(annual_sales.category == 'Programs')]\n\nannual_gaming = annual_sales[annual_sales.category=='Gaming']\n\nannual_gifts = annual_sales[annual_sales.category=='Gifts & Gift Cards']\nannual_books = annual_sales[annual_sales.category=='Books']\n#annual_cards = annual_sales[annual_sales.category=='Payment Cards']\nannual_service = annual_sales[annual_sales.category=='Service & Delivery']\n\nannual_keep = annual_sales.loc[(annual_sales.category=='Gifts & Gift Cards')|(annual_sales.category=='Books')|(annual_sales.category=='Service & Delivery')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Movies decreasing each year\nmonthlySales = pd.DataFrame(annual_movies.groupby([\"Month\", \"year\"], as_index=False)[\"Sales\"].sum())\n\nplt.style.use('fivethirtyeight')\ng = sns.FacetGrid(data = monthlySales.sort_values(by=\"Month\"), hue = \"year\", size = 7, legend_out=True)\ng = g.map(plt.plot, \"Month\", \"Sales\")\ng.add_legend()\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle('Annual Movie Sales', fontsize=22)\ng;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Music decreasing each year\nmonthlySales = pd.DataFrame(annual_music.groupby([\"Month\", \"year\"], as_index=False)[\"Sales\"].sum())\n\ng = sns.FacetGrid(data = monthlySales.sort_values(by=\"Month\"), hue = \"year\", size = 7, legend_out=True)\ng = g.map(plt.plot, \"Month\", \"Sales\")\ng.add_legend()\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle('Annual Music Sales', fontsize=22)\ng;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Programs decreasing each year\nmonthlySales = pd.DataFrame(annual_software.groupby([\"Month\", \"year\"], as_index=False)[\"Sales\"].sum())\n\ng = sns.FacetGrid(data = monthlySales.sort_values(by=\"Month\"), hue = \"year\", size = 7, legend_out=True)\ng = g.map(plt.plot, \"Month\", \"Sales\")\ng.add_legend()\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle('Annual Software Sales', fontsize=22)\ng;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Eliminate categories - annual\nmonthlySales = pd.DataFrame(annual_eliminate.groupby([\"Month\", \"year\"], as_index=False)[\"Sales\"].sum())\n\ng = sns.FacetGrid(data = monthlySales.sort_values(by=\"Month\"), hue = \"year\", size = 7, legend_out=True)\ng = g.map(plt.plot, \"Month\", \"Sales\")\ng.add_legend()\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle('Annual Sales - Movies, Music, Software', fontsize=22)\ng;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gaming each year\nmonthlySales = pd.DataFrame(annual_gaming.groupby([\"Month\", \"year\"], as_index=False)[\"Sales\"].sum())\n\ng = sns.FacetGrid(data = monthlySales.sort_values(by=\"Month\"), hue = \"year\", size = 7, legend_out=True)\ng = g.map(plt.plot, \"Month\", \"Sales\")\ng.add_legend()\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle('Annual Gaming Sales', fontsize=22)\ng;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gifts increasing each year\nmonthlySales = pd.DataFrame(annual_gifts.groupby([\"Month\", \"year\"], as_index=False)[\"Sales\"].sum())\n\ng = sns.FacetGrid(data = monthlySales.sort_values(by=\"Month\"), hue = \"year\", size = 7, legend_out=True)\ng = g.map(plt.plot, \"Month\", \"Sales\")\ng.add_legend()\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle('Annual Gifts Sales', fontsize=22)\ng;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Books increasing each year\nmonthlySales = pd.DataFrame(annual_books.groupby([\"Month\", \"year\"], as_index=False)[\"Sales\"].sum())\n\ng = sns.FacetGrid(data = monthlySales.sort_values(by=\"Month\"), hue = \"year\", size = 7, legend_out=True)\ng = g.map(plt.plot, \"Month\", \"Sales\")\ng.add_legend()\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle('Annual Book Sales', fontsize=22)\ng;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Services & delivery increasing each year\nmonthlySales = pd.DataFrame(annual_service.groupby([\"Month\", \"year\"], as_index=False)[\"Sales\"].sum())\n\ng = sns.FacetGrid(data = monthlySales.sort_values(by=\"Month\"), hue = \"year\", size = 7, legend_out=True)\ng = g.map(plt.plot, \"Month\", \"Sales\")\ng.add_legend()\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle('Services & Delivery - Annual', fontsize=22)\ng;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Keep - Annual\nmonthlySales = pd.DataFrame(annual_keep.groupby([\"Month\", \"year\"], as_index=False)[\"Sales\"].sum())\n\ng = sns.FacetGrid(data = monthlySales.sort_values(by=\"Month\"), hue = \"year\", size = 7, legend_out=True)\ng = g.map(plt.plot, \"Month\", \"Sales\")\ng.add_legend()\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle('Annual Sales: Books, Gifts & Gift Cards, Service & Delivery', fontsize=22)\ng;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"category_sales['month'] = category_sales['month'] - 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eliminate_1 = category_sales[category_sales.category=='Movies']\neliminate_2 = category_sales[category_sales.category=='Music']\neliminate_3 = category_sales[category_sales.category=='Software']\n\neliminate = category_sales.loc[(category_sales.category == 'Movies')|(category_sales.category == 'Music')|(category_sales.category == 'Software')]\n\nkeep_1 = category_sales[category_sales.category=='Gaming']\n\nkeep_2 = category_sales[category_sales.category=='Gifts & Gift Cards']\nkeep_3 = category_sales[category_sales.category=='Books']\nkeep_4 = category_sales[category_sales.category=='Service & Delivery']\n\nkeep = category_sales.loc[(category_sales.category=='Gifts & Gift Cards')|(category_sales.category=='Books')|(category_sales.category=='Service & Delivery')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gaming plotted against Total Company Sales\n\nts = keep_1.groupby([\"month\"])[\"total_sales\"].sum()\nts.astype('float')\nax = cs.plot(figsize=(14,7), title=\"Gaming Sales in Relation to Total Company Sales (January 2013 - October 2015)\", fontsize=16, legend=True)\nts.plot(ax=ax)\n\nplt.xlabel('Time - (month #)', fontsize=14)\nplt.ylabel('Sales', fontsize=14)\nax.legend([\"Total Company Sales\", \"Gaming\"])\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# All 8 Categories Plotted Together\n\nts1 = keep_1.groupby([\"month\"])[\"total_sales\"].sum()\nts2 = keep_2.groupby([\"month\"])[\"total_sales\"].sum()\nts3 = keep_3.groupby([\"month\"])[\"total_sales\"].sum()\nts4 = keep_4.groupby([\"month\"])[\"total_sales\"].sum()\nts5 = eliminate_1.groupby([\"month\"])[\"total_sales\"].sum()\nts6 = eliminate_2.groupby([\"month\"])[\"total_sales\"].sum()\nts7 = eliminate_3.groupby([\"month\"])[\"total_sales\"].sum()\n\nts.astype('float')\nax = cs.plot(figsize=(14,7), title=\"Total Sales & Sales by Category (January 2013 - October 2015)\", fontsize=14, legend=True)\nts1.plot(ax=ax)\nts2.plot(ax=ax)\nts3.plot(ax=ax)\nts4.plot(ax=ax)\nts5.plot(ax=ax)\nts6.plot(ax=ax)\nts7.plot(ax=ax)\n#plt.figure(figsize=(14,7))\n#plt.title('Total Sales Gaming')\nplt.xlabel('Month', fontsize=14)\nplt.ylabel('Sales', fontsize=14)\nax.legend([\"Total Sales\",\"Gaming\", \"Gifts & Gift Cards\", \"Books\", \"Service & Delivery\", \"Movies\", \"Music\", \"Software\"]);\nticks = [0, 4, 10, 16, 22, 28, 33]\n\nplt.xticks(ticks, ['January13', 'May13', 'November13', 'May14', 'November14', 'May15', 'October15'])\n\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gaming Removed from Category Plots\n\n#ts1 = keep_1.groupby([\"month\"])[\"total_sales\"].sum()\nts2 = keep_2.groupby([\"month\"])[\"total_sales\"].sum()\nts3 = keep_3.groupby([\"month\"])[\"total_sales\"].sum()\nts4 = keep_4.groupby([\"month\"])[\"total_sales\"].sum()\nts5 = eliminate_1.groupby([\"month\"])[\"total_sales\"].sum()\nts6 = eliminate_2.groupby([\"month\"])[\"total_sales\"].sum()\nts7 = eliminate_3.groupby([\"month\"])[\"total_sales\"].sum()\n\nts.astype('float')\nax = ts2.plot(figsize=(14,7), title=\"Sales of 1C Company (Jan13 - Oct15) ~ Gaming Removed\", fontsize=14, legend=True)\n#ts2.plot(ax=ax)\nts3.plot(ax=ax)\nts4.plot(ax=ax)\nts5.plot(ax=ax)\nts6.plot(ax=ax)\nts7.plot(ax=ax)\nplt.xlabel('Month', fontsize=14)\nplt.ylabel('Sales', fontsize=14)\nax.legend([\"Gifts & Gift Cards\", \"Books\", \"Service & Delivery\", \"Movies\", \"Music\", \"Software\"])\nticks = [0, 4, 10, 16, 22, 28, 33]\n\nplt.xticks(ticks, ['January13', 'May13', 'November13', 'May14', 'November14', 'May15', 'October15'])\n           \nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = keep_2.groupby([\"month\"])[\"total_sales\"].sum()\nts.astype('float')\nplt.figure(figsize=(14,7))\nplt.title('Total Sales Gifts & Gift Cards')\nplt.xlabel('Month #')\nplt.ylabel('Sales')\nplt.plot(ts);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = keep_3.groupby([\"month\"])[\"total_sales\"].sum()\nts.astype('float')\nplt.figure(figsize=(14,7))\nplt.title('Total Sales Books')\nplt.xlabel('Month #)')\nplt.ylabel('Sales')\nplt.plot(ts);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = keep_4.groupby([\"month\"])[\"total_sales\"].sum()\nts.astype('float')\nplt.figure(figsize=(14,7))\nplt.title('Service & Delivery Total Sales')\nplt.xlabel('Month #)')\nplt.ylabel('Sales')\nplt.plot(ts);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = eliminate_1.groupby([\"month\"])[\"total_sales\"].sum()\nts.astype('float')\nplt.figure(figsize=(14,7))\nplt.title('Total Sales Movies')\nplt.xlabel('Month #')\nplt.ylabel('Sales')\nplt.plot(ts);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = eliminate_2.groupby([\"month\"])[\"total_sales\"].sum()\nts.astype('float')\nplt.figure(figsize=(14,7))\nplt.title('Total Sales Music')\nplt.xlabel('Month #')\nplt.ylabel('Sales')\nplt.plot(ts);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = eliminate_3.groupby([\"month\"])[\"total_sales\"].sum()\nts.astype('float')\nplt.figure(figsize=(14,7))\nplt.title('Software')\nplt.xlabel('Month #')\nplt.ylabel('Sales')\nplt.plot(ts);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting Those in 'Keep' with Gaming Removed [Gifts, Books, Service & Delivery]\n\n#ts1 = keep_1.groupby([\"month\"])[\"total_sales\"].sum()\nts2 = keep_2.groupby([\"month\"])[\"total_sales\"].sum()\nts3 = keep_3.groupby([\"month\"])[\"total_sales\"].sum()\nts4 = keep_4.groupby([\"month\"])[\"total_sales\"].sum()\n\nts.astype('float')\nax = ts2.plot(figsize=(14,7), title=\"Gift, Books & Service Sales (Jan13 - Oct15)\", fontsize=14, legend=True)\n#ts2.plot(ax=ax)\nts3.plot(ax=ax)\nts4.plot(ax=ax)\nplt.xlabel('Month #', fontsize=14)\nplt.ylabel('Sales', fontsize=14)\nax.legend([\"Gifts & Gift Cards\", \"Books\", \"Service & Delivery\"]);\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting 'Keep' versus 'Eliminate'\n\nts1 = keep.groupby([\"month\"])[\"total_sales\"].sum()\nts2 = eliminate.groupby([\"month\"])[\"total_sales\"].sum()\n\nts.astype('float')\nax = ts1.plot(figsize=(14,7), title=\"'Retain' Compared to 'Relinquish' - 1C Company (January 2013 - October 2015)\", fontsize=14, legend=True)\nts2.plot(ax=ax)\n\nplt.xlabel('Month ', fontsize=14)\nplt.ylabel('Sales', fontsize=14)\nax.legend([\"Retain: Gifts, Books, Service\",\"Relinquish: Movies, Music, Software\"]);\nticks = [0, 4, 10, 16, 22, 28, 33]\n\nplt.xticks(ticks, ['January13', 'May13', 'November13', 'May14', 'November14', 'May15', 'October15'])\n\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keepers = keep.groupby([\"month\"])[\"total_sales\"].sum()\nkeepers.astype('float')\nplt.figure(figsize=(14,7))\nplt.title('Total Sales Keepers')\nplt.xlabel('Time - (month #)')\nplt.ylabel('Sales (# of units)')\nplt.plot(keepers);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shed = eliminate.groupby([\"month\"])[\"total_sales\"].sum()\nshed.astype('float')\nplt.figure(figsize=(14,7))\nplt.title('Total Sales Eliminate')\nplt.xlabel('Time - (month #)')\nplt.ylabel('Sales (# of units)')\nplt.plot(shed);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"year_sales.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = sales.groupby('city')['total_sales'].agg({'total_sales': sum})\nx = x.sort_values(by='total_sales', ascending=False)\nx = x.iloc[0:10].reset_index()\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales.city.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"online = year_sales.loc[year_sales.city=='Online']\nonline.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"online2 = sales.loc[year_sales.city=='Online']\nonline2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Programs decreasing each year\nmonthlySales = pd.DataFrame(online.groupby([\"Month\", \"year\"], as_index=False)[\"Sales\"].sum())\n\ng = sns.FacetGrid(data = monthlySales.sort_values(by=\"Month\"), hue = \"year\", size = 7, legend_out=True)\ng = g.map(plt.plot, \"Month\", \"Sales\")\ng.add_legend()\nplt.subplots_adjust(top=0.9)\ng.fig.suptitle('Annual Online Sales', fontsize=22)\ng;","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"on_ts = online2.groupby([\"month\"])[\"total_sales\"].sum()\nts.astype('float')\nplt.figure(figsize=(14,7))\nplt.title('Total Sales Online')\nplt.xlabel('Time - (month #)')\nplt.ylabel('Sales (# of units)')\nplt.plot(on_ts);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = train.groupby([\"month\"])[\"total_sales\"].sum()\nts.astype('float')\nplt.figure(figsize=(14,7))\nplt.title('Total Sales Train Data')\nplt.xlabel('Time - (month #)')\nplt.ylabel('Sales (# of units)')\nplt.plot(ts);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Assessing the presence of trend & seasonality via Rolling Statistics:\n\non_line2 = online2.groupby([\"month\"])[\"total_sales\"].sum()\nplt.figure(figsize=(14,7))\nplt.plot(on_line2.rolling(window=12,center=False).mean(),label='Rolling Mean - Trend for Online Sales');\nplt.plot(on_line2.rolling(window=12,center=False).std(),label='Rolling Standard Deviation - Seasonality for Online Sales');\nplt.legend()\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Assessing the presence of trend & seasonality via Rolling Statistics:\n\nplt.figure(figsize=(14,7))\nplt.plot(shed.rolling(window=12,center=False).mean(),label='Rolling Mean');\nplt.plot(shed.rolling(window=12,center=False).std(),label='Rolling Standard Deviation');\nplt.legend()\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Assessing the presence of trend & seasonality via Rolling Statistics:\n\nplt.figure(figsize=(14,7))\nplt.plot(keepers.rolling(window=12,center=False).mean(),label='Rolling Mean');\nplt.plot(keepers.rolling(window=12,center=False).std(),label='Rolling Standard Deviation');\nplt.legend()\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Decomposing Time-Series into Trend, Seasonality, and Residuals\n# Is the seasonality Multiplicative or Additive? \n# That is, does the magnitude of the seasonality increase when the time series increases?\n# Let's check for Multiplicative Seasonality first with statsmodels.tsa (Time Series Analysis):\n\nimport statsmodels.api as sm\n\nts_decomposed = sm.tsa.seasonal_decompose(on_line2.values,freq=12,model=\"multiplicative\")\nplt.figure(figsize=(16,12))\nfig = ts_decomposed.plot()\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nplt.style.use('seaborn-poster')\n\nts_decomposed = sm.tsa.seasonal_decompose(on_line2.values,freq=12,model=\"additive\")\nplt.figure(figsize=(16,12))\nfig = ts_decomposed.plot()\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.available","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\n\nplt.style.use('ggplot')\nts_decomposed = sm.tsa.seasonal_decompose(keepers.values,freq=12,model=\"multiplicative\")\nplt.figure(figsize=(16,12))\nfig = ts_decomposed.plot()\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\n\nts_decomposed = sm.tsa.seasonal_decompose(keepers.values,freq=12,model=\"additive\")\nplt.figure(figsize=(16,12))\nfig = ts_decomposed.plot()\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\n\nts_decomposed = sm.tsa.seasonal_decompose(shed.values,freq=12,model=\"multiplicative\")\nplt.figure(figsize=(16,12))\nfig = ts_decomposed.plot()\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\n\nts_decomposed = sm.tsa.seasonal_decompose(shed.values,freq=12,model=\"additive\")\nplt.figure(figsize=(16,12))\nfig = ts_decomposed.plot()\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For some reason an additive model is assumed (though, personally, it's hard for me to know why).\n# It must be because there is no discernable increase in magnitude each November/December. There is a seasonal increase,\n# But that occurs in an additive manner on top of the trend of decreasing sales","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stationarity tests\ndef test_stationarity(timeseries):\n    \n    #Perform Dickey-Fuller test:\n    print('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print (dfoutput)\n\ntest_stationarity(ts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The Null Hypothesis for the Dickey-Fuller Test is that the time-series is not stationary.\n# Since the critical value of p=0.05 is not met, the Null Hypothesis cannot be rejected.\n# Hence, the data does not yet meet the assumption of stationarity that is required for time-series analysis.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now testing the stationarity again after de-seasonality, the Null Hypothesis that the time-series\n# Is not stationary can be rejected\ntest_stationarity(keepers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to remove trend\nfrom pandas import Series as Series\n# create a differenced series\ndef difference(dataset, interval=1):\n    diff = list()\n    for i in range(interval, len(dataset)):\n        value = dataset[i] - dataset[i - interval]\n        diff.append(value)\n    return Series(diff)\n\n# invert differenced forecast\ndef inverse_difference(last_ob, value):\n    return value + last_ob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keep = keep.drop(columns=['category'], inplace=False)\nkeep.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kp1 = keep_1.drop(columns=['category'], inplace=False)\nkp1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # ts=sales.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\n# kp.astype('float')\n# plt.figure(figsize=(16,16))\n# plt.subplot(311)\n# plt.title('Original')\n# plt.xlabel('Time')\n# plt.ylabel('Sales')\n# plt.plot(ts)\n# plt.subplot(312)\n# plt.title('After De-trend')\n# plt.xlabel('Time')\n# plt.ylabel('Sales')\n# new_kp=difference(kp)\n# plt.plot(new_kp)\n# plt.plot()\n\n# plt.subplot(313)\n# plt.title('After De-seasonalization')\n# plt.xlabel('Time')\n# plt.ylabel('Sales')\n# new_kp=difference(kp,12)       # assuming the seasonality is 12 months long\n# plt.plot(new_kp)\n# plt.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts_mdl = smt.ARMA(ts.values, order=(1, 1)).fit(method='mle', trend='nc')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(ts_mdl.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Figuring out if the time-series is AR (AutoRegressive) or MA (MovingAverage)\n# AR [Today = constant + (slope * yesterday) + noise]\n# MA [Today = Mean + Noise + (slope * yesterday's noise)]\n\n# We've correctly identified the order of the simulated process as ARMA (p,q), ARMA (1,1):\n# p=1 # of lags for AR (AutoRegressive)\n# q=1 # of lags for MA (Moving Average)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# adding the dates to the Time-series as index\ncs = train.groupby([\"month\"])[\"total_sales\"].sum()\ncs.index = pd.date_range(start = '2013-01-01',end='2015-10-01', freq = 'MS')\ncs = cs.reset_index()\ncs.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# adding the dates to the Time-series as index\nkeep = keep.groupby([\"month\"])[\"total_sales\"].sum()\nkeep.index = pd.date_range(start = '2013-01-01',end='2015-10-01', freq = 'MS')\nkeep = keep.reset_index()\nkeep.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# kp1 = keep_1.groupby([\"month\"])[\"total_sales\"].sum()\n# kp1.index = pd.date_range(start = '2013-01-01',end='2015-10-01', freq = 'MS')\n# kp1 = kp1.reset_index()\n# kp1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# adding the dates to the Time-series as index\n\nshed = eliminate.groupby([\"month\"])[\"total_sales\"].sum()\nshed.index = pd.date_range(start = '2013-01-01',end='2015-10-01', freq = 'MS')\nshed = shed.reset_index()\nshed.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# adding the dates to the Time-series as index\n\non_ts = online2.groupby([\"month\"])[\"total_sales\"].sum()\non_ts.index = pd.date_range(start = '2013-01-01',end='2015-10-01', freq = 'MS')\non_ts = on_ts.reset_index()\non_ts.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet import Prophet\n#prophet reqiures a pandas df at the below config \n# ( date column named as DS and the value column as Y)\n\ncs.columns = ['ds','y'] # Model 1 Company Sales\nkeep.columns = ['ds','y'] # Model 2 Retain Sales\nshed.columns = ['ds','y'] # Model 3 Relinquish Sales\non_ts.columns = ['ds','y'] # Model 4 Online Sales","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = Prophet(yearly_seasonality=True) #instantiate Prophet with only yearly seasonality as our data is monthly \nmodel1.fit(cs) #fit the model with your dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = Prophet(yearly_seasonality=True) #instantiate Prophet with only yearly seasonality as our data is monthly \nmodel2.fit(keep) #fit the model with your dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model3 = Prophet(yearly_seasonality=True) #instantiate Prophet with only yearly seasonality as our data is monthly \nmodel3.fit(shed) #fit the model with your dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model4 = Prophet(yearly_seasonality=True) #instantiate Prophet with only yearly seasonality as our data is monthly \nmodel4.fit(on_ts) #fit the model with your dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict for five months in the future and MS - month start is the frequency\nfuture1 = model1.make_future_dataframe(periods = 12, freq = 'MS')  \n# now lets make the forecasts\nforecast1 = model1.predict(future1)\nforecast1[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict for five months in the future and MS - month start is the frequency\nfuture2 = model2.make_future_dataframe(periods = 12, freq = 'MS')  \n# now lets make the forecasts\nforecast2 = model2.predict(future2)\nforecast2[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict for five months in the future and MS - month start is the frequency\nfuture3 = model3.make_future_dataframe(periods = 12, freq = 'MS')  \n# now lets make the forecasts\nforecast3 = model3.predict(future3)\nforecast3[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict for five months in the future and MS - month start is the frequency\nfuture4 = model4.make_future_dataframe(periods = 12, freq = 'MS')  \n# now lets make the forecasts\nforecast4 = model4.predict(future4)\nforecast4[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.plotting.register_matplotlib_converters()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('fivethirtyeight')\n\nfig1 = model1.plot(forecast1)\nplot = plt.suptitle('1C Company 2013-2015 Sales & 2016 Predicted Sales')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig1 = model1.plot_components(forecast1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig2 = model2.plot(forecast2)\nplot = plt.suptitle(\"2013-215 'Retain' Sales & 2016 Predicted 'Retain' Sales\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig2 = model2.plot_components(forecast2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig3 = model3.plot(forecast3)\nplot = plt.suptitle(\"2013-215 'Relinquish' Sales & 2016 Predicted 'Relinquish' Sales\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig3 = model3.plot_components(forecast3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig4 = model4.plot(forecast4)\nplot = plt.suptitle(\"2013-215 Online Sales & 2016 Predicted '2016 Online Sales\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig4 = model4.plot_components(forecast4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Python\nfrom fbprophet.plot import plot_plotly\nimport plotly.offline as py\npy.init_notebook_mode()\n\nfig = plot_plotly(model1, forecast1)  # This returns a plotly Figure\npy.iplot(fig)\n\n# 1C COMPANY SALES (Forecasted 12 Months Out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plot_plotly(model2, forecast2)  # This returns a plotly Figure\npy.iplot(fig)\n\n# 'RETAIN' CATEGORIES (Forecasted 12 Months Out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plot_plotly(model2, forecast2)  # This returns a plotly Figure\npy.iplot(fig)\n\n# 'RELINQUISH' CATEGORIES (Forecasted 12 Months Out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plot_plotly(model2, forecast2)  # This returns a plotly Figure\npy.iplot(fig)\n\n# ONLINE SALES (Forecasted 12 Months Out)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}