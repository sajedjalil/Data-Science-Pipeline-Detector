{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('dark')\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"items=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/items.csv\")\nshops=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/shops.csv\")\ncats=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv\")\ntrain=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv\")\ntest=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#특이치 제거","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,4))\nplt.xlim(-100, 3000)\nflierprops = dict(marker='o', markerfacecolor='purple', markersize=6,\n                  linestyle='none', markeredgecolor='black')\nsns.boxplot(x=train.item_cnt_day, flierprops=flierprops)\n\nplt.figure(figsize=(10,4))\nplt.xlim(train.item_price.min(), train.item_price.max()*1.1)\nsns.boxplot(x=train.item_price, flierprops=flierprops)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[(train.item_price < 300000 )& (train.item_cnt_day < 1000)] # 1000개이상 팔린 품목 제거, 30만원이상 품목 제거","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[train.item_price > 0].reset_index(drop = True) # 가격이 마이너스인 가격 제거, 환불될 가능성이있음\ntrain.loc[train.item_cnt_day < 1, \"item_cnt_day\"] = 0 # 판매갯수가 0개인건 -1로 변경","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train.shop_id == 0, 'shop_id'] = 57 # 둘이 같은 상점인데 이름에 pah가 껴있음\ntest.loc[test.shop_id == 0, 'shop_id'] = 57\ntrain.loc[train.shop_id == 1, 'shop_id'] = 58\ntest.loc[test.shop_id == 1, 'shop_id'] = 58\ntrain.loc[train.shop_id == 10, 'shop_id'] = 11\ntest.loc[test.shop_id == 10, 'shop_id'] = 11","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shops.loc[ shops.shop_name == 'Сергиев Посад ТЦ \"7Я\"',\"shop_name\" ] = 'СергиевПосад ТЦ \"7Я\"' # 띄어쓰기 되있는 도시 이름 바꾸기\nshops[\"city\"] = shops.shop_name.str.split(\" \").map( lambda x: x[0] ) # 공백을 기준으로 문자를 나누고 0번째\nshops[\"category\"] = shops.shop_name.str.split(\" \").map( lambda x: x[1] ) # 1번째\nshops.loc[shops.city == \"!Якутск\", \"city\"] = \"Якутск\"  # 도시이름에 !가 들어가면 바꿔줌","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"category = []\nfor cat in shops.category.unique(): # category의 문자열 유니크값\n    if len(shops[shops.category == cat]) >= 5: # 만약 shops['category'] 개수가 5가 크거나 같을때\n        category.append(cat) # category안에 유니크값을 넣는다 \nshops.category = shops.category.apply( lambda x: x if (x in category) else \"other\" ) # 5개가 있는 상점이 카테고리 안에있으니까\n                                                                                     # 5개인 상점은 그대로 바꾸고 그 아래것들은 other로 변경","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder \nshops[\"shop_category\"] = LabelEncoder().fit_transform( shops.category ) # category를 숫자로\nshops[\"shop_city\"] = LabelEncoder().fit_transform( shops.city )# shops.city를 숫자로\nshops = shops[[\"shop_id\", \"shop_category\", \"shop_city\"]] # shops안에 shops_name빼고 요렇게","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cleaning Item Category Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"cats[\"type_code\"] = cats.item_category_name.apply( lambda x: x.split(\" \")[0] ).astype(str) #  \" \" 공백기준 문자나누고, 0번째로 바꾸기\ncats.loc[ (cats.type_code == \"Игровые\")| (cats.type_code == \"Аксессуары\"), \"category\" ] = \"Игры\" # type_code가 저거거나 이거거나 만족하면 category열은 만든 후 요걸로 바꿈","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"category = []\nfor cat in cats.type_code.unique(): \n    if len(cats[cats.type_code == cat]) >= 5: # 유니크값의 크기가 5보다 크거나 같을때 \n        category.append( cat ) # category에 유니크값 추가\ncats.type_code = cats.type_code.apply(lambda x: x if (x in category) else \"etc\") # cats['type_code']안에 category 값이 있으면 그대로 아니면 etc 반환","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cats.type_code = LabelEncoder().fit_transform(cats.type_code)\ncats[\"split\"] = cats.item_category_name.apply(lambda x: x.split(\"-\")) # -기준으로 나눠서\ncats[\"subtype\"] = cats.split.apply(lambda x: x[1].strip() if len(x) > 1 else x[0].strip()) # 만약 문자열 x의 크기가 1보다크면 1을 기준으로나눔 아니면 0을 기준으로 나눔\ncats[\"subtype_code\"] = LabelEncoder().fit_transform( cats[\"subtype\"] ) # 라벨인코딩\ncats = cats[[\"item_category_id\", \"subtype_code\", \"type_code\"]] # item_category_name 빼고 나머지로 데이터프레임구성","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cleaning Item Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ndef name_correction(x):\n    x = x.lower() # 소문자로 바꿔\n    x = x.partition('[')[0] # [을 기준으로 문자열나눠\n    x = x.partition('(')[0] # (을 기준으로 문자열나눠\n    x = re.sub('[^A-Za-z0-9А-Яа-я]+', ' ', x) # x의 패턴이외 ' '로 바꾸심\n    x = x.replace('  ', ' ') # 스페이스바 두번누른걸 한번으로바꿈\n    x = x.strip() # 앞뒤 공백지우기\n    return x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Clean item names"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nitems[\"name1\"], items[\"name2\"] = items.item_name.str.split(\"[\", 1).str # 1번에 [을 기준으로 나눔\nitems[\"name1\"], items[\"name3\"] = items.item_name.str.split(\"(\", 1).str # 1번에 (을 기준으로 나눔\n\n\nitems[\"name2\"] = items.name2.str.replace('[^A-Za-z0-9А-Яа-я]+', \" \").str.lower() # 대문자를 소문자로\nitems[\"name3\"] = items.name3.str.replace('[^A-Za-z0-9А-Яа-я]+', \" \").str.lower() # 대문자를 소문자로\n\n\nitems = items.fillna('0') # items에 공백은 0으로 채움\n\nitems[\"item_name\"] = items[\"item_name\"].apply(lambda x: name_correction(x)) # item_name 클리닝\n\nitems.name2 = items.name2.apply( lambda x: x[:-1] if x !=\"0\" else \"0\") # items['name2']에 0이없으면 그대로 아니면 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Clean item type"},{"metadata":{"trusted":true},"cell_type":"code","source":"items[\"type\"] = items.name2.apply(lambda x: x[0:8] if x.split(\" \")[0] == \"xbox\" else x.split(\" \")[0] ) # \" \"을 기준으로 나눠, 0번째가 xbox면 x의 0:8길이 까지만, 아니면 0번째전체\nitems.loc[(items.type == \"x360\") | (items.type == \"xbox360\") | (items.type == \"xbox 360\") ,\"type\"] = \"xbox 360\" # items['type']이 x360 or xbox360 or xbox 360 모두 xbox 360으로 변환\nitems.loc[ items.type == \"\", \"type\"] = \"mac\" # type안에 type이 공백이면 mac으로 \nitems.type = items.type.apply( lambda x: x.replace(\" \", \"\") ) # \" \"이면 공백으로\nitems.loc[ (items.type == 'pc' )| (items.type == 'pс') | (items.type == \"pc\"), \"type\" ] = \"pc\" # 글자가 다름\nitems.loc[ items.type == 'рs3' , \"type\"] = \"ps3\" # 글자가 다름","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group_sum = items.groupby([\"type\"]).agg({\"item_id\": \"count\"}) # type을 기준으로 item_id를 정렬후 group_sum에 저장\ngroup_sum = group_sum.reset_index() #인덱스를 원래대로 \ndrop_cols = []\nfor cat in group_sum.type.unique():\n    if group_sum.loc[(group_sum.type == cat), \"item_id\"].values[0] <40: # item_id에 type값이 cat이랑 같을때 그 값이 40보다 작은경우\n        drop_cols.append(cat) # drop_cols에 추가\nitems.name2 = items.name2.apply( lambda x: \"other\" if (x in drop_cols) else x ) # items['name2']에 drop_cols값이 있으면 other 아니면 그대로\nitems = items.drop([\"type\"], axis = 1) # type을 제거","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group_sum.loc[(group_sum.type == cat), 'item_id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"items.name2 = LabelEncoder().fit_transform(items.name2) # 라벨인코딩\nitems.name3 = LabelEncoder().fit_transform(items.name3)\n\nitems.drop([\"item_name\", \"name1\"],axis = 1, inplace= True) # items에 item_name, name1 컬럼제거\nitems.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import product\nimport time\nts = time.time() # 현재시간이요\nmatrix = []\ncols  = [\"date_block_num\", \"shop_id\", \"item_id\"] \nfor i in range(34):\n    sales = train[train.date_block_num == i] # date_block_num(달마다 숫자로 표현)\n    matrix.append( np.array(list( product( [i], sales.shop_id.unique(), sales.item_id.unique() ) ), dtype = np.int16) )\n    # i, sale['shop_id'], sale['item_id'] 유니크값을 곱집합한걸 리스트로 나타내어 배열로 만든걸 추가\n\nmatrix = pd.DataFrame( np.vstack(matrix), columns = cols ) # matrix를 세로로 결합후 col대로 데이터프레임만듬\nmatrix[\"date_block_num\"] = matrix[\"date_block_num\"].astype(np.int8) # matrix['date_block_num']을 정수형으로\nmatrix[\"shop_id\"] = matrix[\"shop_id\"].astype(np.int8) # matrix['shop_id']를 정수형으로\nmatrix[\"item_id\"] = matrix[\"item_id\"].astype(np.int16) # matrix['item_id']를 정수형으로\nmatrix.sort_values( cols, inplace = True ) # 열을 오름차순으로 정렬\ntime.time()- ts # 아까 시간 - 지금 시간 = 실행시간","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add revenue to train df\ntrain[\"revenue\"] = train[\"item_cnt_day\"] * train[\"item_price\"] # 판갯수 * 판매가격으로 train['revenue'] 컬럼만듬","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\ngroup = train.groupby( [\"date_block_num\", \"shop_id\", \"item_id\"] ).agg( {\"item_cnt_day\": [\"sum\"]} ) # 3개열 기준으로 item_cnt_day를 \ngroup.columns = [\"item_cnt_month\"] # group에 item_cnt_month 열 추가\ngroup.reset_index( inplace = True)\nmatrix = pd.merge( matrix, group, on = cols, how = \"left\" ) # matrix와 group을 cols기준으로 왼쪽으로 병합\nmatrix[\"item_cnt_month\"] = matrix[\"item_cnt_month\"].fillna(0).astype(np.float16) # item_cnt_month의 null값은 0이고 소수점형태로 나타낸다\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create a test set for month34"},{"metadata":{"trusted":true},"cell_type":"code","source":"test[\"date_block_num\"] = 34 # test['date_block_num']에는 34을 넣음\ntest[\"date_block_num\"] = test[\"date_block_num\"].astype(np.int8) # 정수형으로 표현\ntest[\"shop_id\"] = test.shop_id.astype(np.int8) # shop_id를 정수형으로\ntest[\"item_id\"] = test.item_id.astype(np.int16)# item_id를 정수형으로","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Concatenate train and test sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\n\nmatrix = pd.concat([matrix, test.drop([\"ID\"],axis = 1)], ignore_index=True, sort=False, keys=cols)\n# matrix와 drop되는 ID이외에 컬럼들을 합침? 기존 index를 인덱스를 유지하지않고, 내림차순 계층적 인덱스 사용\nmatrix.fillna( 0, inplace = True ) # matrix 공백값은 0으로\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Add shop, items and categories data onto matrix df."},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\nmatrix = pd.merge( matrix, shops, on = [\"shop_id\"], how = \"left\" ) # shop_id를 기준으로 왼쪽 데이터프레임으로 결합\nmatrix = pd.merge(matrix, items, on = [\"item_id\"], how = \"left\") # item_id를 기준으로 왼쪽 데이터프레임으로 결합\nmatrix = pd.merge( matrix, cats, on = [\"item_category_id\"], how = \"left\" ) # item_category_id를 기준으로 왼쪽 데이터프레임으로 결합\nmatrix[\"shop_city\"] = matrix[\"shop_city\"].astype(np.int8) # shop_city 정수형으로\nmatrix[\"shop_category\"] = matrix[\"shop_category\"].astype(np.int8) # shop_category를 정수형으로\nmatrix[\"item_category_id\"] = matrix[\"item_category_id\"].astype(np.int8) # item_category_id를 정수형으로\nmatrix[\"subtype_code\"] = matrix[\"subtype_code\"].astype(np.int8) # subtype_code를 정수형으로\nmatrix[\"name2\"] = matrix[\"name2\"].astype(np.int8) # name2를 정수형으로\nmatrix[\"name3\"] = matrix[\"name3\"].astype(np.int16) # name3를 정수형으로\nmatrix[\"type_code\"] = matrix[\"type_code\"].astype(np.int8) # type_code를 정수형으로\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. # Feature Engineering\nAdd lag features to matrix df."},{"metadata":{"trusted":true},"cell_type":"code","source":"def lag_feature( df,lags, cols ):\n    for col in cols:\n        print(col)\n        tmp = df[[\"date_block_num\", \"shop_id\",\"item_id\",col ]]  # 데이터프레임안에 'item_cnt_month' 값을넣는다.\n        for i in lags:\n            shifted = tmp.copy() # tmp 데이터프레임을 복사\n            shifted.columns = [\"date_block_num\", \"shop_id\", \"item_id\", col + \"_lag_\"+str(i)] # item_cnt_month + _lag_ + str(i)\n            shifted.date_block_num = shifted.date_block_num + i # date_block_num 값에 i값을 더하다\n            print(i)\n            df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left') # df에 3개 열을 기준으로 왼쪽 병합\n            # item_cnt_month + _lag_ + str(1) item_cnt_month + _lag_ + str(2) item_cnt_month + _lag_ + str(3) 이런식으로\n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Add item_cnt_month lag features."},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\nmatrix = lag_feature( matrix, [1,2,3], [\"item_cnt_month\"] )\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Add the previous month's average item_cnt."},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\ngroup = matrix.groupby( [\"date_block_num\"] ).agg({\"item_cnt_month\" : [\"mean\"]}) # date_block_num 을 기준으로 ite_cnt_month의 평균\ngroup.columns = [\"date_avg_item_cnt\"] # date_avg_item_cnt 열 추가\ngroup.reset_index(inplace = True)\n\nmatrix = pd.merge(matrix, group, on = [\"date_block_num\"], how = \"left\") # date_block_num 기준으로 왼쪽 데이터프레임으로 결합\nmatrix.date_avg_item_cnt = matrix[\"date_avg_item_cnt\"].astype(np.float16) # date_avg_item_cnt를 소수형으로\nmatrix = lag_feature( matrix, [1], [\"date_avg_item_cnt\"] )\n# date_avg_item_cnt  + _lag_ + 1, date_avg_item_cnt  + _lag_ + 2, date_avg_item_cnt  + _lag_ + 3 생성 \nmatrix.drop( [\"date_avg_item_cnt\"], axis = 1, inplace = True ) # date_avg_item_cnt 제거 (사용했기 때문에)\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Add lag values of item_cnt_month for month / item_id."},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\ngroup = matrix.groupby(['date_block_num', 'item_id']).agg({'item_cnt_month': ['mean']}) # 두개 열을 기준으로 item_cnt_month의 평균\ngroup.columns = [ 'date_item_avg_item_cnt' ] # date_item_avg_item_cnt 열 생성\ngroup.reset_index(inplace=True) # index를 원래대로 만든다\n\nmatrix = pd.merge(matrix, group, on=['date_block_num','item_id'], how='left') # 두개의 열을 기준으로 왼쪽 데이터프레임으로 결합\nmatrix.date_item_avg_item_cnt = matrix['date_item_avg_item_cnt'].astype(np.float16) # date_item_avg_item_cnt 소수형으로\nmatrix = lag_feature(matrix, [1,2,3], ['date_item_avg_item_cnt']) \n# date_item_avg_item_cnt  + _lag_ + 1, date_item_avg_item_cnt  + _lag_ + 2, date_item_avg_item_cnt  + _lag_ + 3 생성\nmatrix.drop(['date_item_avg_item_cnt'], axis=1, inplace=True)\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Add lag values for item_cnt_month for every month / shop combination."},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\ngroup = matrix.groupby( [\"date_block_num\",\"shop_id\"] ).agg({\"item_cnt_month\" : [\"mean\"]})\ngroup.columns = [\"date_shop_avg_item_cnt\"]\ngroup.reset_index(inplace = True)\n\nmatrix = pd.merge(matrix, group, on = [\"date_block_num\",\"shop_id\"], how = \"left\")\nmatrix.date_avg_item_cnt = matrix[\"date_shop_avg_item_cnt\"].astype(np.float16)\nmatrix = lag_feature( matrix, [1,2,3], [\"date_shop_avg_item_cnt\"] )\nmatrix.drop( [\"date_shop_avg_item_cnt\"], axis = 1, inplace = True )\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Add lag values for item_cnt_month for month/shop/item."},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\ngroup = matrix.groupby( [\"date_block_num\",\"shop_id\",\"item_id\"] ).agg({\"item_cnt_month\" : [\"mean\"]})\ngroup.columns = [\"date_shop_item_avg_item_cnt\"]\ngroup.reset_index(inplace = True)\n\nmatrix = pd.merge(matrix, group, on = [\"date_block_num\",\"shop_id\",\"item_id\"], how = \"left\")\nmatrix.date_avg_item_cnt = matrix[\"date_shop_item_avg_item_cnt\"].astype(np.float16)\nmatrix = lag_feature( matrix, [1,2,3], [\"date_shop_item_avg_item_cnt\"] )\nmatrix.drop( [\"date_shop_item_avg_item_cnt\"], axis = 1, inplace = True )\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Add lag values for item_cnt_month for month/shop/item subtype."},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\ngroup = matrix.groupby(['date_block_num', 'shop_id', 'subtype_code']).agg({'item_cnt_month': ['mean']})\ngroup.columns = ['date_shop_subtype_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'shop_id', 'subtype_code'], how='left')\nmatrix.date_shop_subtype_avg_item_cnt = matrix['date_shop_subtype_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], ['date_shop_subtype_avg_item_cnt'])\nmatrix.drop(['date_shop_subtype_avg_item_cnt'], axis=1, inplace=True)\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Add lag values for item_cnt_month for month/city."},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\ngroup = matrix.groupby(['date_block_num', 'shop_city']).agg({'item_cnt_month': ['mean']})\ngroup.columns = ['date_city_avg_item_cnt']\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', \"shop_city\"], how='left')\nmatrix.date_city_avg_item_cnt = matrix['date_city_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], ['date_city_avg_item_cnt'])\nmatrix.drop(['date_city_avg_item_cnt'], axis=1, inplace=True)\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Add lag values for item_cnt_month for month/city/item."},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\ngroup = matrix.groupby(['date_block_num', 'item_id', 'shop_city']).agg({'item_cnt_month': ['mean']})\ngroup.columns = [ 'date_item_city_avg_item_cnt' ]\ngroup.reset_index(inplace=True)\n\nmatrix = pd.merge(matrix, group, on=['date_block_num', 'item_id', 'shop_city'], how='left')\nmatrix.date_item_city_avg_item_cnt = matrix['date_item_city_avg_item_cnt'].astype(np.float16)\nmatrix = lag_feature(matrix, [1], ['date_item_city_avg_item_cnt'])\nmatrix.drop(['date_item_city_avg_item_cnt'], axis=1, inplace=True)\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Add average item price on to matix df.\n# Add lag values of item price per month.\n# Add delta price values - how current month average pirce relates to global average."},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\ngroup = train.groupby( [\"item_id\"] ).agg({\"item_price\": [\"mean\"]}) # item_id 그룹에 item_price 평균을 group에 저장\ngroup.columns = [\"item_avg_item_price\"] # item_avg_item_price 열에 추가\ngroup.reset_index(inplace = True)\n\nmatrix = matrix.merge( group, on = [\"item_id\"], how = \"left\" ) # matrix에 item_id를 기준으로 group을 결합\nmatrix[\"item_avg_item_price\"] = matrix.item_avg_item_price.astype(np.float16)\n\n\ngroup = train.groupby( [\"date_block_num\",\"item_id\"] ).agg( {\"item_price\": [\"mean\"]} )\n# date_block_num을 기준으로 item_id를 정렬하고 item_id에 대한 item_price의 평균을 정렬\n\ngroup.columns = [\"date_item_avg_item_price\"] # date_item_avg_item_price 열 추가\ngroup.reset_index(inplace = True)\n\nmatrix = matrix.merge(group, on = [\"date_block_num\",\"item_id\"], how = \"left\") \n# matrix에 date_block_num, item_id 기준으로 group병합\n\nmatrix[\"date_item_avg_item_price\"] = matrix.date_item_avg_item_price.astype(np.float16)\n\n\nlags = [1, 2, 3]\nmatrix = lag_feature( matrix, lags, [\"date_item_avg_item_price\"] )\n# date_item_avg_item_price_lag_1, date_item_avg_item_price_lag_2, date_item_avg_item_price_lag_3 생성 \n\nfor i in lags:\n    matrix[\"delta_price_lag_\" + str(i) ] = (matrix[\"date_item_avg_item_price_lag_\" + str(i)]- matrix[\"item_avg_item_price\"] )/ matrix[\"item_avg_item_price\"]\n# delta값 구하기 #  기초자산의 가격변화에 대한 옵션가격의 변화량, delta_price_lag_1, delta_price_lag_2, delta_price_lag3 열 추가\n    \ndef select_trends(row) :\n    for i in lags:\n        if row[\"delta_price_lag_\" + str(i)]: \n            return row[\"delta_price_lag_\" + str(i)]\n    return 0\n\nmatrix[\"delta_price_lag\"] = matrix.apply(select_trends, axis = 1) \nmatrix[\"delta_price_lag\"] = matrix.delta_price_lag.astype( np.float16 )\nmatrix[\"delta_price_lag\"].fillna( 0 ,inplace = True) # null값을 0으로 반환\n\nfeatures_to_drop = [\"item_avg_item_price\", \"date_item_avg_item_price\"] \n\nfor i in lags:\n    features_to_drop.append(\"date_item_avg_item_price_lag_\" + str(i) ) \n    features_to_drop.append(\"delta_price_lag_\" + str(i) ) # 아까 만들었던것들 제거\nmatrix.drop(features_to_drop, axis = 1, inplace = True)\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Add total shop revenue per month to matix df.\n# Add lag values of revenue per month.\n# Add delta revenue values - how current month revenue relates to global average."},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\ngroup = train.groupby( [\"date_block_num\",\"shop_id\"] ).agg({\"revenue\": [\"sum\"] }) # 달별 shopid의 revenue 전체값\ngroup.columns = [\"date_shop_revenue\"] # date_shop_revenue 컬럼생성\ngroup.reset_index(inplace = True)\n\nmatrix = matrix.merge( group , on = [\"date_block_num\", \"shop_id\"], how = \"left\" ) # 두개의 열 기준으로 group을 왼쪽으로 병합\nmatrix['date_shop_revenue'] = matrix['date_shop_revenue'].astype(np.float32) # 소수형으로\n\ngroup = group.groupby([\"shop_id\"]).agg({ \"date_block_num\":[\"mean\"] }) # shop_id에 date_block_num 평균 group 변수에 입력\ngroup.columns = [\"shop_avg_revenue\"] # shop_avg_revenue 열 추가\ngroup.reset_index(inplace = True )\n\nmatrix = matrix.merge( group, on = [\"shop_id\"], how = \"left\" ) # shop_id를 기준으로 group 병합\nmatrix[\"shop_avg_revenue\"] = matrix.shop_avg_revenue.astype(np.float32)\nmatrix[\"delta_revenue\"] = (matrix['date_shop_revenue'] - matrix['shop_avg_revenue']) / matrix['shop_avg_revenue']\n#revenue의 delta값 구하기\n\nmatrix[\"delta_revenue\"] = matrix[\"delta_revenue\"]. astype(np.float32)\n\nmatrix = lag_feature(matrix, [1], [\"delta_revenue\"]) # delta_revenue_lag_1 열 생성\nmatrix[\"delta_revenue_lag_1\"] = matrix[\"delta_revenue_lag_1\"].astype(np.float32) # 소수형으로\nmatrix.drop( [\"date_shop_revenue\", \"shop_avg_revenue\", \"delta_revenue\"] ,axis = 1, inplace = True) # delta_revenue_lag_1 남기고 다 지우는듯\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Add month and number of days in each month to matrix df."},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix[\"month\"] = matrix[\"date_block_num\"] % 12 # 12로 나눈 몫구하기\ndays = pd.Series([31,28,31,30,31,30,31,31,30,31,30,31]) # 각 월의 끝나는 일\nmatrix[\"days\"] = matrix[\"month\"].map(days).astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Add the month of each shop and item first sale."},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\nmatrix[\"item_shop_first_sale\"] = matrix[\"date_block_num\"] - matrix.groupby([\"item_id\",\"shop_id\"])[\"date_block_num\"].transform('min')\n# date_block_num - item_id, shop_id로 묶은 date_block_num의 최소값\nmatrix[\"item_first_sale\"] = matrix[\"date_block_num\"] - matrix.groupby([\"item_id\"])[\"date_block_num\"].transform('min')\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Delete first three months from matrix. They don't have lag values."},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\nmatrix = matrix[matrix[\"date_block_num\"] > 3] # 3을 넘는 date_block_num값들만 추출\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"matrix.head().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 모델링"},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\nimport pickle\nfrom xgboost import XGBRegressor\nfrom matplotlib.pylab import rcParams\nrcParams['figure.figsize'] = 12, 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = matrix.copy() # data 변수에 matrix를 복사\ndel matrix\ngc.collect() # 가비지 콜렉션","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data[\"date_block_num\"]==34].shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Use month 34 as validation for training."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = data[data.date_block_num < 33].drop(['item_cnt_month'], axis=1) \nY_train = data[data.date_block_num < 33]['item_cnt_month'] # 33 아래까지는 train set\nX_valid = data[data.date_block_num == 33].drop(['item_cnt_month'], axis=1)\nY_valid = data[data.date_block_num == 33]['item_cnt_month'] # 33은 vaildation set\nX_test = data[data.date_block_num == 34].drop(['item_cnt_month'], axis=1) # 34는 test set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train = Y_train.clip(0, 20)\nY_valid = Y_valid.clip(0, 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del data\ngc.collect();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\n\nmodel = XGBRegressor(\n    max_depth=10,\n    n_estimators=1000,\n    min_child_weight=0.5, \n    colsample_bytree=0.8, \n    subsample=0.8, \n    eta=0.1,\n#     tree_method='gpu_hist',\n    seed=42)\n\nmodel.fit(\n    X_train, \n    Y_train, \n    eval_metric=\"rmse\", \n    eval_set=[(X_train, Y_train), (X_valid, Y_valid)], \n    verbose=True, \n    early_stopping_rounds = 20)\n\ntime.time() - ts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred = model.predict(X_valid).clip(0, 20)\nY_test = model.predict(X_test).clip(0, 20)\n\nsubmission = pd.DataFrame({\n    \"ID\": test.index, \n    \"item_cnt_month\": Y_test\n})\nsubmission.to_csv('xgb_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import plot_importance\n\ndef plot_features(booster, figsize):    \n    fig, ax = plt.subplots(1,1,figsize=figsize)\n    return plot_importance(booster=booster, ax=ax)\n\nplot_features(model, (10,14))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}