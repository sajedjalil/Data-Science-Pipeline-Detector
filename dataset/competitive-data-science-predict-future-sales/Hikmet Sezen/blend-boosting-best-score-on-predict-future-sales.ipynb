{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Blend Boosting study on Coursera dataset of the Predict Future Sales:\n\nHere I share with you a systematic blend boosting study on Coursera dataset of the Predict Future Sales. (https://www.kaggle.com/c/competitive-data-science-predict-future-sales/). I just collect some submission files on the kaggle.\n\nBasically, I start to analysis of correlations, then decide to sort them according to their sum of correlation values in between. This lets me divide ~10 scores into 4 subgroups. Then I make internal linear calibration in each subgroup by considering their scores on the Kaggle. Finally I make recalling between subgroups to achieve higher scores on the Kaggle by resubmission. Due to daily limitation about number of submission, I am able to get this best result in my first four attempts (5th one is for notebook submission). Of course, if you spend much more time, you can always achieve betters scores, but it is already highest score on Kaggle ;-). In future I can submit much better results, and also plan to make a full model analysis on this dataset.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# loading dummy submission file\nsub_file = pd.read_csv('../input/best-blend/submission_blend_1.csv')\n\n# loading data including 15 (some of them are identical) best scores\ndf_sub = pd.read_csv(r'../input/best-blend/best_blend_1.csv')\ndf_sub = df_sub.iloc[:, :10]\n\n# a rough correlation based visualization of 32 best scores\nplt.figure(figsize=(10,10))\nsns.heatmap(df_sub.corr(), cmap='Spectral')\nplt.ylabel('file index numbers')\nplt.xlabel('file index numbers')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# basic analysis and visualization of subgroups in different color.\nplt.figure(figsize=(12, 5))\ndf_mean_corr = pd.DataFrame({'mean_corr': df_sub.corr().mean()})\ndf_mean_corr = df_mean_corr.sort_values('mean_corr', ascending=False)\ndf_mean_corr = df_mean_corr.reset_index()\n\nplt.plot(df_mean_corr.index[:4], df_mean_corr['mean_corr'].values[:4], 'o', ms=10)\nplt.plot(df_mean_corr.index[4:6], df_mean_corr['mean_corr'].values[4:6], 'o', ms=10)\nplt.plot(df_mean_corr.index[6:8], df_mean_corr['mean_corr'].values[6:8], 'o', ms=10)\nplt.plot(df_mean_corr.index[8:], df_mean_corr['mean_corr'].values[8:], 'o', ms=10)\n\nplt.xticks([*range(len(df_mean_corr))], df_mean_corr['index'].tolist())\nplt.title('determination of sub_groups')\nplt.ylabel('a corelation ralated index')\nplt.xlabel('file index numbers')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# a linear combination to achieve much better scores\ndf_sub['weighted_avg'] = abs(1 * (\n        10 * ( 5 * df_sub['2'] + 5 * df_sub['3'] + 2 * df_sub['6'] + 1 * df_sub['9'] ) / 13 +\n        25 * ( 1 * df_sub['4'] + 1 * df_sub['5'] ) / 2 +\n        2 * ( 2 * df_sub['7'] + 1 * df_sub['8'] ) / 3 +\n        100 * ( 5 * df_sub['0'] + 1 * df_sub['1'] ) / 6\n) / 137 )\n\n\n# create the final submission file\nsubmission = pd.DataFrame({'ID': sub_file.ID, 'item_cnt_month': df_sub['weighted_avg'].tolist()})\nsubmission.to_csv(r'submission_blend_1.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## It gets a 0.83386 as public score, and looks the best score on Kaggle so far ;-)","metadata":{}}]}