{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"print(\"\\n ============ TRAIN DATA===============\\n\")\nprint(\"\\n----------Top-5-Record----------\\n\")\nprint(train.head(5))\nprint(\"\\n-----------Information-----------\\n\")\nprint(train.info())\nprint(\"\\n----------Missing value-----------\\n\")\nprint(train.isnull().sum())\nprint(\"\\n----------Null value-----------\\n\")\nprint(train.isna().sum())\n\nprint(\"\\n----------Shape of Data----------\\n\")\nprint(train.shape)\nprint(\"\\n-----------Columns-----------\\n\")\nprint(train.columns)\nprint(\"\\n-----------Data Types-----------\\n\")\nprint(train.dtypes)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random as rd # generating random numbers\nimport datetime # manipulating date formats\n# Viz\nimport matplotlib.pyplot as plt # basic plotting\nimport seaborn as sns # for prettier plots\n\n\n# TIME SERIES\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom pandas.plotting import autocorrelation_plot\nfrom statsmodels.tsa.stattools import adfuller, acf, pacf,arma_order_select_ic\nimport statsmodels.formula.api as smf\nimport statsmodels.tsa.api as smt\nimport statsmodels.api as sm\nimport scipy.stats as scs\n\n\n# settings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import all of them \nsales=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv\")\n\n# settings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nitem_cat=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv\")\nitem=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/items.csv\")\nsub=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/sample_submission.csv\")\nshops=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/shops.csv\")\ntest=pd.read_csv(\"/kaggle/input/competitive-data-science-predict-future-sales/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(sales.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#formatting the date column correctly or string datetime to datetime object\n#sales.date=sales.date.apply(lambda x:datetime.datetime.strptime(x, '%d.%m.%Y'))\n# check\n#sales.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Aggregate to monthly level the required metrics\n\nmonthly_sales=sales.groupby([\"date_block_num\",\"shop_id\",\"item_id\"]).agg({\"date\":[\"min\",'max'],\"item_price\":\"mean\",\"item_cnt_day\":\"sum\"})\n\n## Lets break down the line of code here:\n# aggregate by date-block(month),shop_id and item_id\n# select the columns date,item_price and item_cnt(sales)\n# Provide a dictionary which says what aggregation to perform on which column\n# min and max on the date\n# average of the item_price\n# sum of the sales","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print first 20 Values\nmonthly_sales.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# number of items per cat \nx=item.groupby(['item_category_id']).count()\nx=x.sort_values(by='item_id',ascending=False)\nx=x.iloc[0:10].reset_index()\nx\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #plot\nplt.figure(figsize=(8,4))\nax= sns.barplot(x.item_category_id, x.item_id, alpha=0.8)\nplt.title(\"Items per Category\")\nplt.ylabel('# of items', fontsize=12)\nplt.xlabel('Category', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The objective requires us to predict sales for the next month at a store-item combination.\n\nSales over time of each store-item is a time-series in itself. Before we dive into all the combinations, first let's understand how to forecast for a single series.\n\nI've chosen to predict for the total sales per month for the entire company.\n\nFirst let's compute the total sales per month and plot that data."},{"metadata":{"trusted":true},"cell_type":"code","source":"ts=sales.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nplt.figure(figsize=(16,8))\nplt.title('Total Sales of the company')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nplt.plot(ts);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Rolling means** (or moving averages) are generally used to smooth out short-term fluctuations in time series data and highlight long-term trends.\nTo use the .rolling() method, you must always use method chaining, first calling .rolling() and then chaining an aggregation method after it. For example, with a Series hourly_data, hourly_data.rolling(window=24).mean() would compute new values for each hourly point, based on a 24-hour window stretching out behind each point. The frequency of the output data is the same: it is still hourly. Such an operation is useful for smoothing time series data.\n\n**In statistics, standard deviation** is a measure that is used to quantify the amount of variation of a set of data from the mean.This is a useful property to differentiate data from 'moving' segments to 'not moving' segments"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,6))\nplt.plot(ts.rolling(window=12,center=False).mean(),label='Rolling Mean');\nplt.plot(ts.rolling(window=12,center=False).std(),label='Rolling sd');\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check that with a quick decomposition into Trend, seasonality and residuals."},{"metadata":{},"cell_type":"markdown","source":"statsmodels.api: Cross-sectional models and methods. Canonically imported using import statsmodels.api as sm.\nhttps://support.minitab.com/en-us/minitab/19/help-and-how-to/modeling-statistics/time-series/supporting-topics/time-series-models/additive-and-multiplicative-models/"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"#Statsmodels is a Python package that provides a complement to scipy for statistical computations including descriptive statistics and estimation and inference for statistical models.\nimport statsmodels.api as sm\n# multiplicative\nres = sm.tsa.seasonal_decompose(ts.values,freq=12,model=\"multiplicative\")\n#plt.figure(figsize=(16,12))\nfig = res.plot()\n#fig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Additive model\nres = sm.tsa.seasonal_decompose(ts.values,freq=12,model=\"additive\")\n#plt.figure(figsize=(16,12))\nfig = res.plot()\n#fig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Check if Time series is stationary or not**\nIn statistics and econometrics, an augmented Dickeyâ€“Fuller test (ADF) tests the null hypothesis that a unit root is present in a time series sample. The alternative hypothesis is different depending on which version of the test is used, but is usually stationarity or trend-stationarity.\n\nImportant:\nhttps://www.machinelearningplus.com/time-series/augmented-dickey-fuller-test/\nhttps://machinelearningmastery.com/time-series-data-stationary-python/"},{"metadata":{},"cell_type":"markdown","source":"**Detrending** is removing a trend from a time series; a trend usually refers to a change in the mean over time. When you detrend data, you remove an aspect from the data that you think is causing some kind of distortion. For example, you might detrend data that shows an overall increase, in order to see subtrends.\n\nFor reference https://www.machinelearningplus.com/time-series/time-series-analysis-python/"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stationarity tests\ndef test_stationarity(timeseries):\n    \n    #Perform Dickey-Fuller test:\n    print('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n        dfoutput['Critical Value (%s)'%key] = value\n    print(dfoutput)\n\ntest_stationarity(ts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to remove trend\nfrom pandas import Series as Series\n# create a differenced series\ndef difference(dataset, interval=1):\n    diff = list()\n    for i in range(interval, len(dataset)):\n        value = dataset[i] - dataset[i - interval]\n        diff.append(value)\n    return Series(diff)\n\n# invert differenced forecast\ndef inverse_difference(last_ob, value):\n    return value + last_ob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to remove trend\nfrom pandas import Series as Series\n# create a differenced series\ndef difference(dataset, interval=1):\n    diff = list()\n    for i in range(interval, len(dataset)):\n        value = dataset[i] - dataset[i - interval]\n        diff.append(value)\n    return Series(diff)\n\n# invert differenced forecast\ndef inverse_difference(last_ob, value):\n    return value + last_ob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ts=sales.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nts.astype('float')\nplt.figure(figsize=(16,16))\nplt.subplot(311)\nplt.title('Original')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nplt.plot(ts)\nplt.subplot(312)\nplt.title('After De-trend')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nnew_ts=difference(ts)\nplt.plot(new_ts)\nplt.plot()\n\nplt.subplot(313)\nplt.title('After De-seasonalization')\nplt.xlabel('Time')\nplt.ylabel('Sales')\nnew_ts=difference(ts,12)       # assuming the seasonality is 12 months long\nplt.plot(new_ts)\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# now testing the stationarity again after de-seasonality\ntest_stationarity(new_ts)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**AR, MA and ARMA models:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def tsplot(y, lags=None, figsize=(10, 8), style='bmh',title=''):\n    if not isinstance(y, pd.Series):\n        y = pd.Series(y)\n    with plt.style.context(style):    \n        fig = plt.figure(figsize=figsize)\n        #mpl.rcParams['font.family'] = 'Ubuntu Mono'\n        layout = (3, 2)\n        ts_ax = plt.subplot2grid(layout, (0, 0), colspan=2)\n        acf_ax = plt.subplot2grid(layout, (1, 0))\n        pacf_ax = plt.subplot2grid(layout, (1, 1))\n        qq_ax = plt.subplot2grid(layout, (2, 0))\n        pp_ax = plt.subplot2grid(layout, (2, 1))\n        \n        y.plot(ax=ts_ax)\n        ts_ax.set_title(title)\n        smt.graphics.plot_acf(y, lags=lags, ax=acf_ax, alpha=0.5)\n        smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax, alpha=0.5)\n        sm.qqplot(y, line='s', ax=qq_ax)\n        qq_ax.set_title('QQ Plot')        \n        scs.probplot(y, sparams=(y.mean(), y.std()), plot=pp_ax)\n\n        plt.tight_layout()\n    return ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"https://www.investopedia.com/terms/a/autoregressive.asp\n\nAn AR(1) autoregressive process is one in which the current value is based on the immediately preceding value, while an AR(2) process is one in which the current value is based on the previous two values. An AR(0) process is used for white noise and has no dependence between the terms. In addition to these variations, there are also many different ways to calculate the coefficients used in these calculations, such as the least squares method."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Simulate an AR(1) process with alpha = 0.6\nnp.random.seed(1)\nn_samples = int(1000)\na = 0.6\nx = w = np.random.normal(size=n_samples)\n\nfor t in range(n_samples):\n    x[t] = a*x[t-1] + w[t]\nlimit=12    \n_ = tsplot(x, lags=limit,title=\"AR(1)process\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**AR(1) process -- has ACF tailing out and PACF cutting off at lag=1**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Simulate an AR(2) process\n\nn = int(1000)\nalphas = np.array([.444, .333])\nbetas = np.array([0.])\n\n# Python requires us to specify the zero-lag value which is 1\n# Also note that the alphas for the AR model must be negated\n# We also set the betas for the MA equal to 0 for an AR(p) model\n# For more information see the examples at statsmodels.org\nar = np.r_[1, -alphas]\nma = np.r_[1, betas]\n\nar2 = smt.arma_generate_sample(ar=ar, ma=ma, nsample=n) \n_ = tsplot(ar2, lags=12,title=\"AR(2) process\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"AR(2) process -- has ACF tailing out and PACF cutting off at lag=2"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Simulate an MA(1) process\nn = int(1000)\n# set the AR(p) alphas equal to 0\nalphas = np.array([0.])\nbetas = np.array([0.8])\n# add zero-lag and negate alphas\nar = np.r_[1, -alphas]\nma = np.r_[1, betas]\nma1 = smt.arma_generate_sample(ar=ar, ma=ma, nsample=n) \nlimit=12\n_ = tsplot(ma1, lags=limit,title=\"MA(1) process\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MA(1) process -- has ACF cut off at lag=1"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Simulate MA(2) process with betas 0.6, 0.4\nn = int(1000)\nalphas = np.array([0.])\nbetas = np.array([0.6, 0.4])\nar = np.r_[1, -alphas]\nma = np.r_[1, betas]\n\nma3 = smt.arma_generate_sample(ar=ar, ma=ma, nsample=n)\n_ = tsplot(ma3, lags=12,title=\"MA(2) process\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"MA(2) process -- has ACF cut off at lag=2"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Simulate an ARMA(2, 2) model with alphas=[0.5,-0.25] and betas=[0.5,-0.3]\nmax_lag = 12\n\nn = int(5000) # lots of samples to help estimates\nburn = int(n/10) # number of samples to discard before fit\n\nalphas = np.array([0.8, -0.65])\nbetas = np.array([0.5, -0.7])\nar = np.r_[1, -alphas]\nma = np.r_[1, betas]\n\narma22 = smt.arma_generate_sample(ar=ar, ma=ma, nsample=n, burnin=burn)\n_ = tsplot(arma22, lags=max_lag,title=\"ARMA(2,2) process\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's use a systematic approach to finding the order of AR and MA processes."},{"metadata":{"trusted":true},"cell_type":"code","source":"# pick best order by aic \n# smallest aic value wins\nbest_aic = np.inf \nbest_order = None\nbest_mdl = None\n\nrng = range(5)\nfor i in rng:\n    for j in rng:\n        try:\n            tmp_mdl = smt.ARMA(arma22, order=(i, j)).fit(method='mle', trend='nc')\n            tmp_aic = tmp_mdl.aic\n            if tmp_aic < best_aic:\n                best_aic = tmp_aic\n                best_order = (i, j)\n                best_mdl = tmp_mdl\n        except: continue\n\n\nprint('aic: {:6.5f} | order: {}'.format(best_aic, best_order))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pick best order by aic \n# smallest aic value wins\nbest_aic = np.inf \nbest_order = None\nbest_mdl = None\n\nrng = range(5)\nfor i in rng:\n    for j in rng:\n        try:\n            tmp_mdl = smt.ARMA(new_ts.values, order=(i, j)).fit(method='mle', trend='nc')\n            tmp_aic = tmp_mdl.aic\n            if tmp_aic < best_aic:\n                best_aic = tmp_aic\n                best_order = (i, j)\n                best_mdl = tmp_mdl\n        except: continue\n\n\nprint('aic: {:6.5f} | order: {}'.format(best_aic, best_order))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# adding the dates to the Time-series as index\nts=sales.groupby([\"date_block_num\"])[\"item_cnt_day\"].sum()\nts.index=pd.date_range(start = '2013-01-01',end='2015-10-01', freq = 'MS')\nts=ts.reset_index()\nts.head(35)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fbprophet import Prophet\n#prophet reqiures a pandas df at the below config \n# ( date column named as DS and the value column as Y)\nts.columns=['ds','y']\nmodel = Prophet( yearly_seasonality=True) #instantiate Prophet with only yearly seasonality as our data is monthly \nmodel.fit(ts) #fit the model with your dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predict for five months in the furure and MS - month start is the frequency\nfuture = model.make_future_dataframe(periods = 5, freq = 'MS')  \n# now lets make the forecasts\nforecast = model.predict(future)\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.plot(forecast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.plot_components(forecast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# 1,1,2 ARIMA Model\nmodel = ARIMA(future, order=(1,1,2))\nmodel_fit = model.fit(disp=0)\nprint(model_fit.summary())"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# 1,1,2 ARIMA Model\nmodel = ARIMA(future, order=(1,1,1))\nmodel_fit = model.fit(disp=0)\nprint(model_fit.summary())"},{"metadata":{},"cell_type":"markdown","source":"Happy Data Science."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}