{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport gc\nimport pickle\nimport time\nfrom joblib import dump, load\nimport lightgbm as lgb\n\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This cell is only for displaying package versions. You can ignore it.\n\nimport pkg_resources\nimport types\ndef get_imports():\n    for name, val in globals().items():\n        if isinstance(val, types.ModuleType):\n            # Split ensures you get root package, \n            # not just imported function\n            name = val.__name__.split(\".\")[0]\n\n        elif isinstance(val, type):\n            name = val.__module__.split(\".\")[0]\n\n        # Some packages are weird and have different\n        # imported names vs. system names\n        if name == \"PIL\":\n            name = \"Pillow\"\n        elif name == \"sklearn\":\n            name = \"scikit-learn\"\n\n        yield name\nimports = list(set(get_imports()))\n\nrequirements = []\nfor m in pkg_resources.working_set:\n    if m.project_name in imports and m.project_name!=\"pip\":\n        requirements.append((m.project_name, m.version))\n\nfor r in requirements:\n    print(\"{}=={}\".format(*r))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading the preprocessed data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_pickle('../input/eda-preprocessing-feature-engineering/all_data.pkl')\n# Dropping the first 6 months because they were used for lags\ndata = data[data.date_block_num > 5]\ntest  = pd.read_csv('../input/competitive-data-science-predict-future-sales/test.csv').set_index('ID')\n\n# dropping some of the columns that didn't give any improvement\ndropcols = [\n            \"item_cnt_month_lag_12\",\n            \"item_cnt_month_lag_12_adv\",\n            \"date_item_target_enc_lag_12\",\n            \"date_shop_target_enc_lag_12\",\n            \"date_city_target_enc_lag_1\",\n            \"date_city_target_enc_lag_2\",\n            \"date_city_target_enc_lag_3\",\n            \"date_type_target_enc_lag_1\",\n            \"date_subtype_target_enc_lag_1\",\n            \"new_item_cat_avg_lag_1\",\n            \"new_item_cat_avg_lag_2\",\n            \"new_item_cat_avg_lag_3\",\n            \"new_item_shop_cat_avg_lag_1\",\n            \"new_item_shop_cat_avg_lag_2\",\n            \"new_item_shop_cat_avg_lag_3\",\n           ]\n\n# Doing the time based train-val-test split\nX_train = data[data.date_block_num < 33].drop(['item_cnt_month']+dropcols, axis=1)\nY_train = data[data.date_block_num < 33]['item_cnt_month']\nX_valid = data[data.date_block_num == 33].drop(['item_cnt_month']+dropcols, axis=1)\nY_valid = data[data.date_block_num == 33]['item_cnt_month']\nX_test = data[data.date_block_num == 34].drop(['item_cnt_month']+dropcols, axis=1)\n\ndel data\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Printing features\nX_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"start_time = time.time()\n\n# https://www.kaggle.com/tylerssssss/feature-engineering-lightgbm\nfeature_name = X_train.columns.tolist()\n\nparams = {\n    'objective': 'mse',\n    'metric': 'rmse',\n    'num_leaves': 2 ** 7 - 1,\n    'learning_rate': 0.005,\n    'feature_fraction': 0.73,\n    'bagging_fraction': 0.75,\n    'bagging_freq': 5,\n    'seed': 0,\n    'verbose': 1\n}\n\nfeature_name_indexes = [ \n                        'country_part', \n                        'city_code',\n                        'type_code',\n                        'subtype_code',\n                        'category_code',\n                        'item_category_id', \n]\n\nlgb_train = lgb.Dataset(X_train[feature_name], Y_train)\nlgb_eval = lgb.Dataset(X_valid[feature_name], Y_valid, reference=lgb_train)\n\nevals_result = {}\ngbm = lgb.train(\n        params, \n        lgb_train,\n        num_boost_round=3000,\n        valid_sets=(lgb_train, lgb_eval), \n        feature_name = feature_name,\n        categorical_feature = feature_name_indexes,\n        verbose_eval=5, \n        evals_result = evals_result,\n        early_stopping_rounds = 100)\n\nprint(f\"Training took {time.time() - start_time} s\")\n\nstart_time = time.time()\nY_train_pred = gbm.predict(X_train).clip(0, 20)\nprint(f\"Predicting on train set took {time.time() - start_time} s\")\n\nstart_time = time.time()\nY_valid_pred = gbm.predict(X_valid).clip(0, 20)\nprint(f\"Predicting on valid set took {time.time() - start_time} s\")\n\nprint(f\"TRAIN RMSE: {round(np.sqrt(mean_squared_error(Y_train, Y_train_pred)), 5)}, VALID RMSE: {round(np.sqrt(mean_squared_error(Y_valid, Y_valid_pred)), 5)}\")\n\n\n# Saving the trained model to disk\ndump(gbm, 'lightgbm_model.joblib') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predicting"},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = time.time()\nY_test = gbm.predict(X_test).clip(0, 20)\nprint(f\"Predicting test set took {time.time() - start_time} s\")\n\n\n\nsubmission = pd.DataFrame({\n    \"ID\": test.index, \n    \"item_cnt_month\": Y_test\n})\nsubmission.to_csv('gbm_y_test.csv', index=False)\n\ntrain_preds = pd.DataFrame({\n    \"ID\": X_train.index, \n    \"item_cnt_month\": Y_train_pred\n})\ntrain_preds.to_csv('gbm_y_train.csv', index=False)\n\nvalid_preds = pd.DataFrame({\n    \"ID\": X_valid.index, \n    \"item_cnt_month\": Y_valid_pred\n})\nvalid_preds.to_csv('gbm_y_valid.csv', index=False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}