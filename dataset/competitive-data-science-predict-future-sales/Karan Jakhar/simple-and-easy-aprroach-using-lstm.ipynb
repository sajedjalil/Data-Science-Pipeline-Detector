{"cells":[{"metadata":{"_uuid":"203fec945d3518c53f50cc1952b9876722576dbf"},"cell_type":"markdown","source":"<h2>Let's Start<h2>"},{"metadata":{"_uuid":"7e5b13f63519b7d38eaac0c06ffd5793e0a43eab"},"cell_type":"markdown","source":"Lets first discuss what we are given and what we have to predict.\nAbout our dataset :\n\nWe have in our training data :- \n1. date - every date of items sold\n2. date_block_num - this number given to every month\n3. shop_id - unique number of every shop\n4. item_id - unique number of every item\n5. item_price - price of every item\n6. item_cnt_day - number of items sold on a particular day \n\nWe have in our testing data :- \n1. ID - unique for every (shop_id,item_id) pair.\n2. shop_id - unique number of every shop\n3. item_id - unique number of every item\n\nNow what we have to predict ?\nwe have to predict how many items of a type from each shop  will be sold in a whole month.\nOur submission should have ID and item_cnt_month columns.\n\nWhat is our approach?\nour approach will be simple.\nOur features will be number of items sold in month from a shop excluding last month data because that will our labels, that we help our model learn to predict next sequence. And for testing will use number of items sold in month from a shop excluding first month like this dimension of our data remains same. Our model will predict the next sequence and that we will be our results. This is pretty simple approach but its good for start. Please try some different approaches also. \nAnd please let me know if I did something wrong. If you like it please vote it up.\n"},{"metadata":{},"cell_type":"markdown","source":"<h3>I would appreciate if you could upvote this kernel.<h3>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"First of all as we know import required libraries"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f63e065519f029cfc2c0e9580fb2e95a146ef0d5"},"cell_type":"code","source":"#loading data \nos.listdir('../input')\nsales_data = pd.read_csv('../input/sales_train.csv')\nitem_cat = pd.read_csv('../input/item_categories.csv')\nitems = pd.read_csv('../input/items.csv')\nshops = pd.read_csv('../input/shops.csv')\nsample_submission = pd.read_csv('../input/sample_submission.csv')\ntest_data = pd.read_csv('../input/test.csv')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4f01c334c611aa85639105835ae6c12968e5f9ab"},"cell_type":"code","source":"def basic_eda(df):\n    print(\"----------TOP 5 RECORDS--------\")\n    print(df.head(5))\n    print(\"----------INFO-----------------\")\n    print(df.info())\n    print(\"----------Describe-------------\")\n    print(df.describe())\n    print(\"----------Columns--------------\")\n    print(df.columns)\n    print(\"----------Data Types-----------\")\n    print(df.dtypes)\n    print(\"-------Missing Values----------\")\n    print(df.isnull().sum())\n    print(\"-------NULL values-------------\")\n    print(df.isna().sum())\n    print(\"-----Shape Of Data-------------\")\n    print(df.shape)\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"40841bde3a83799519bf695f361a62fe03d9e4f1"},"cell_type":"code","source":"#Litle bit of exploration of data\n\nprint(\"=============================Sales Data=============================\")\nbasic_eda(sales_data)\nprint(\"=============================Test data=============================\")\nbasic_eda(test_data)\nprint(\"=============================Item Categories=============================\")\nbasic_eda(item_cat)\nprint(\"=============================Items=============================\")\nbasic_eda(items)\nprint(\"=============================Shops=============================\")\nbasic_eda(shops)\nprint(\"=============================Sample Submission=============================\")\nbasic_eda(sample_submission)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aa425faed80de06ea817c0bab179e47e33a1aa57"},"cell_type":"code","source":"#we can see that 'date' column in sales_data is an object but if we want to manipulate \n#it or want to work on it someway then we have convert it on datetime format\nsales_data['date'] = pd.to_datetime(sales_data['date'],format = '%d.%m.%Y')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f919596e10dd4adafb8825f2c0d42b8c8ddd07a"},"cell_type":"code","source":"#now we will create a pivot tabel by going so we get our data in desired form \n#we want get total count value of an item over the whole month for a shop \n# That why we made shop_id and item_id our indices and date_block_num our column \n# the value we want is item_cnt_day and used sum as aggregating function \ndataset = sales_data.pivot_table(index = ['shop_id','item_id'],values = ['item_cnt_day'],columns = ['date_block_num'],fill_value = 0,aggfunc='sum')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2ab7ea5328f337d2d90477215045bcdd5b3a289c"},"cell_type":"code","source":"# lets reset our indices, so that data should be in way we can easily manipulate\ndataset.reset_index(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"efe0d2b799958be1ed8273ff21b641659671036b"},"cell_type":"code","source":"# lets check on our pivot table\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d3f8cddfa21cd9b07ba1f6d6f243632050a3d07"},"cell_type":"code","source":"# Now we will merge our pivot table with the test_data because we want to keep the data of items we have\n# predict\ndataset = pd.merge(test_data,dataset,on = ['item_id','shop_id'],how = 'left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e8e4c20cdeda9487557f5570461358d919bab72"},"cell_type":"code","source":"# lets fill all NaN values with 0\ndataset.fillna(0,inplace = True)\n# lets check our data now \ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1e16316986055e62840caf762d2dc0cde3e49271"},"cell_type":"code","source":"# we will drop shop_id and item_id because we do not need them\n# we are teaching our model how to generate the next sequence \ndataset.drop(['shop_id','item_id','ID'],inplace = True, axis = 1)\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dc7ca752bc9f265b71861a72499aec3dbcc28dfb"},"cell_type":"code","source":"# X we will keep all columns execpt the last one \nX_train = np.expand_dims(dataset.values[:,:-1],axis = 2)\n# the last column is our label\ny_train = dataset.values[:,-1:]\n\n# for test we keep all the columns execpt the first one\nX_test = np.expand_dims(dataset.values[:,1:],axis = 2)\n\n# lets have a look on the shape \nprint(X_train.shape,y_train.shape,X_test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dba3a0a291adce5f2146455fdb670996224aad70"},"cell_type":"code","source":"# importing libraries required for our model\nfrom keras.models import Sequential\nfrom keras.layers import LSTM,Dense,Dropout","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6c04c796d4b30f7330d97ede3cdca92a7607a4c"},"cell_type":"code","source":"# our defining our model \nmy_model = Sequential()\nmy_model.add(LSTM(units = 64,input_shape = (33,1)))\nmy_model.add(Dropout(0.4))\nmy_model.add(Dense(1))\n\nmy_model.compile(loss = 'mse',optimizer = 'adam', metrics = ['mean_squared_error'])\nmy_model.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a25822391ef2ab412f5abdd2b317d9eec825e19b","scrolled":true},"cell_type":"code","source":"my_model.fit(X_train,y_train,batch_size = 4096,epochs = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab9760e02619d6a3d408e0d4f427adc1f20504c2"},"cell_type":"code","source":"# creating submission file \nsubmission_pfs = my_model.predict(X_test)\n# we will keep every value between 0 and 20\nsubmission_pfs = submission_pfs.clip(0,20)\n# creating dataframe with required columns \nsubmission = pd.DataFrame({'ID':test_data['ID'],'item_cnt_month':submission_pfs.ravel()})\n# creating csv file from dataframe\nsubmission.to_csv('sub_pfs.csv',index = False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}