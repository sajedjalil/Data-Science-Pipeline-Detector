{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"44407a90-211f-5f97-0e9e-2e7d405db392"},"source":"Data Exploration"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bdbea434-5262-c676-da97-c1b6d1767792"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0607758b-468b-0b85-1ba8-8df1132a0af5"},"outputs":[],"source":"df_train = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'])\ndf_test = pd.read_csv(\"../input/test.csv\", parse_dates=['timestamp'])\ndf_macro = pd.read_csv(\"../input/macro.csv\", parse_dates=['timestamp'])\n\ndf_train.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0bbd3757-4026-2051-782e-f6cd38b7055f"},"outputs":[],"source":"df_train.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d5cf2d3f-c7f8-3c2e-dae2-4ffb3999e97a"},"outputs":[],"source":"def feature_summary(data):\n    n_row=data.shape[0]\n    features=pd.DataFrame()\n    features_names=[]\n    features_type = []\n    features_counts=[]\n    features_missing=[]\n    names=data.columns.values\n    for i in names:\n        features_names.append(i)\n        features_type.append(type(data.ix[1,i]))\n        features_counts.append(data[i].value_counts().count())\n        features_missing.append(data[data[i].isnull()].shape[0])\n    features['name']=features_names\n    features['type'] = features_type\n    features['value counts']=features_counts\n    features['missing']=features_missing\n    features['percentage_missing']=features['missing']/n_row\n    return (features)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0fc6d204-3016-3661-d579-684631538287"},"outputs":[],"source":"describe = feature_summary(df_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9189b194-e75f-a17b-5960-fd23adb2efc3"},"outputs":[],"source":"describe"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"abcd4f94-2955-c43d-2e43-bdd4361e92c4"},"outputs":[],"source":"# filter columns that have percentage missing <0.40 \ndescribe['type'].value_counts()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"97da7b4f-0fec-1e39-6950-e817a4da3261"},"outputs":[],"source":"df_train_quant = df_train.select_dtypes(include=['int64', 'floating', 'datetime64'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"599eae57-e98d-c133-8d75-980701e3bbe3"},"outputs":[],"source":"df_train_quant.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4009bd5a-8aab-b43a-569a-5932cff5313e"},"outputs":[],"source":"#now that we have all the quantitative variables "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8f20a849-15b7-28e6-c9d8-1e86c93d0216"},"outputs":[],"source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nf, ax = plt.subplots(figsize=(12, 12))\nsns.heatmap(df_train_quant.corr())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5f713358-7f54-aaee-4fa1-1d3daa6a7086"},"outputs":[],"source":"import numpy as np\nfrom sklearn.decomposition import PCA"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"34985ee2-5c5d-aeed-2b71-5e7cc0f519a4"},"outputs":[],"source":"#PCA = PCA(n_components = 3)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9733d86f-c811-6aaf-de9f-b776c5e34e8d"},"outputs":[],"source":"#handling missing values using mean values? we can explore more methods for this at a later\n#stage\n#df_train_quant = df_train_quant.drop('timestamp', 1)\n#for i in range(1,len(df_train_quant.columns)):\n#       df_train_quant.iloc[:,i] = df_train_quant.iloc[:,i].fillna(df_train_quant.iloc[:,i].mean())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"eb3179a3-f01c-8aa5-52ed-49659abcb974"},"outputs":[],"source":"#y = df_train_quant['price_doc']\n#df_train = df_train_quant.drop('price_doc', 1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"63bd2d53-22f2-3b8a-17f1-66e2f2ca2882"},"outputs":[],"source":"#df_train_quant = df_train_quant.drop('timestamp', 1)\n#PCA.fit(df_train_quant)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e52d8aca-aff9-b26a-3eaa-1922c2bc38cc"},"outputs":[],"source":"#print(PCA.explained_variance_ratio_)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"68c02648-d7a6-9e75-f2fa-f8e377497b9e"},"outputs":[],"source":"#comp1 = PCA.components[:0]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5ec76b23-e0dc-a2c1-671f-0058f5fb8740"},"outputs":[],"source":"#df_train_quant.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"539baac9-89d8-1fa8-dfef-8f20cd66554a"},"outputs":[],"source":"#df_quant = PCA.fit_transform(df_train_quant)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"52a22bc9-cbed-80b0-592a-80831d6a1ee7"},"outputs":[],"source":"#df_quant.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"503ec4b0-a4d0-8fde-1e5a-c647498b8bf8"},"outputs":[],"source":"#we will use the above training data for predictive modeling."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"86524b31-189f-5c82-bd96-890900e0cf19"},"outputs":[],"source":"#y.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"01c31eff-1737-c090-ea2f-c24902ebba88"},"outputs":[],"source":"# simple linear regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import linear_model as lm \n#X_train,X_test,y_train,y_test = train_test_split(df_quant,y,test_size=0.2)# simple linear regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import linear_model as lm \n#X_train,X_test,y_train,y_test = train_test_split(df_quant,y,test_size=0.2)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9073f62c-0ae0-96d3-6d50-a22ea1640090"},"outputs":[],"source":"#X_train = pd.DataFrame(X_train)\n#X_test = pd.DataFrame(X_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3e491266-5d9f-4c54-fab5-b843a77225ea"},"outputs":[],"source":"#model = lm.LinearRegression()\n#model.fit(X_train, y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fc337323-9294-f759-5c68-55d145de6028"},"outputs":[],"source":"#predy = model.predict(X_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"02a134b9-0c98-edb3-2ee5-ffe03ada3deb"},"outputs":[],"source":"#from sklearn.metrics import r2_score\n#r2_score(y_test,predy)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"50f114a1-b842-40cb-551e-1f65749b500b"},"outputs":[],"source":"#y_test"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"97c7fd65-50c8-833c-c7f1-7a2acd5858f6"},"outputs":[],"source":"#df_samplesub = pd.read_csv(\"../input/sample_submission.csv\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"11b32212-2c71-1fd4-9b67-e258a2ded38f"},"outputs":[],"source":"#df_samplesub.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6cb3a4e6-c863-ccec-16da-ae16ecf3afbb"},"outputs":[],"source":"# Transforming the test data\n#df_test_quant = df_test.select_dtypes(include=['int64', 'floating', 'datetime64'])\n#df_test_quant = df_test_quant.drop('timestamp', 1)\n#for i in range(1,len(df_test_quant.columns)):\n#       df_test_quant.iloc[:,i] = df_test_quant.iloc[:,i].fillna(df_test_quant.iloc[:,i].mean())\n#y = df_test_quant['price_doc']\n#df_train = df_train_quant.drop('price_doc', 1) \n#test = PCA.fit_transform(df_test_quant)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4eb38d2d-8bd1-aee0-42f5-6f6d31a1b2b7"},"outputs":[],"source":"#test.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cd6a2a95-e5a4-9e46-b9d4-0fa6110532d9"},"outputs":[],"source":"#y_values = model.predict(test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dc7d56a8-5556-49ec-7e6e-3c8b1592a8e5"},"outputs":[],"source":"#y_values"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4ba57177-e5a3-5c9b-5cdb-19c9d21feae7"},"outputs":[],"source":"##result = pd.DataFrame(y_values)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"588ed25b-66f6-602e-008a-63bff7889212"},"outputs":[],"source":"#result.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"82059ed6-e324-91e7-b7a0-32395e655fd7"},"outputs":[],"source":"#result['id'] = df_test['id']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"33cc30d7-965a-f8af-d69f-8dfa274cae16"},"outputs":[],"source":"#result['price_doc'] = result.iloc[:,0]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"84bd8ec4-de81-f2a1-7570-3ca99f3d7e0e"},"outputs":[],"source":"#result.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0a2e9785-af2d-630f-902f-f0ea04c88e77"},"outputs":[],"source":"#result = result.drop(0,1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3a6d32db-4ef9-6337-28be-0696b5f6705c"},"outputs":[],"source":"#result['price_doc'] = result['price_doc'].round(2)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8665e844-bf5a-62e8-7c6d-9f69a4884fbf"},"outputs":[],"source":"##result.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f6071d9e-5427-7527-c18f-3cabe353a2fd"},"outputs":[],"source":"#result.to_csv(\"output_4.csv\", index = False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ee90208c-5ca5-d34c-d274-39979b0b42ad"},"outputs":[],"source":"#result.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5f0e0f97-8d07-1ed8-14b7-43bec3e26a79"},"outputs":[],"source":"# XG Boost because everyone else is doing it\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cfac5603-68e0-97b7-1b73-1e0600be2277"},"outputs":[],"source":"df_train = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'])\ndf_test = pd.read_csv(\"../input/test.csv\", parse_dates=['timestamp'])\ndf_macro = pd.read_csv(\"../input/macro.csv\", parse_dates=['timestamp'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1c07ba38-c5ae-9676-24d2-cddd2df24f37"},"outputs":[],"source":"def feature_summary(data):\n    n_row=data.shape[0]\n    features=pd.DataFrame()\n    features_names=[]\n    features_type = []\n    features_counts=[]\n    features_missing=[]\n    names=data.columns.values\n    for i in names:\n        features_names.append(i)\n        features_type.append(type(data.ix[1,i]))\n        features_counts.append(data[i].value_counts().count())\n        features_missing.append(data[data[i].isnull()].shape[0])\n    features['name']=features_names\n    features['type'] = features_type\n    features['value counts']=features_counts\n    features['missing']=features_missing\n    features['percentage_missing']=features['missing']/n_row\n    return (features)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"496bf9b4-5a9a-9f81-7f32-6295be147e4c"},"outputs":[],"source":"df_train_quant.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d674126c-2cfb-4c00-096b-243d3e1c03bd"},"outputs":[],"source":"#describe = feature_summary(df_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e8c0c045-7db4-c30a-b499-30f8717f2992"},"outputs":[],"source":"df_train_quant = df_train.select_dtypes(include=['int64', 'floating', 'datetime64'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1b0af63f-5389-2951-5556-9b16fb23501c"},"outputs":[],"source":"import numpy as np\nfrom sklearn.decomposition import PCA\nPCA = PCA(n_components = 275)\n#handling missing values using mean values? we can explore more methods for this at a later\n#stage\ndf_train_quant = df_train_quant.drop('timestamp', 1)\nfor i in range(1,len(df_train_quant.columns)):\n       df_train_quant.iloc[:,i] = df_train_quant.iloc[:,i].fillna(df_train_quant.iloc[:,i].mean())\ny = df_train_quant['price_doc']\ndf_train = df_train_quant.drop('price_doc', 1)\ndf_quant = PCA.fit_transform(df_train_quant)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8d9f32a4-6d1a-1a19-c09b-c472493d16c2"},"outputs":[],"source":"# splitting into training and test data\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(df_quant,y,test_size=0.2)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"727911c3-4782-0527-1b84-3bda1dff131a"},"outputs":[],"source":"import xgboost as xgb\nxgb_params = {\n    'eta': 0.05,\n    'max_depth': 6,\n    'subsample': 0.7,\n    'colsample_bytree': 0.7,\n    'objective': 'reg:linear',\n    'eval_metric': 'rmse',\n    'silent': 0\n}\n\ndtrain = xgb.DMatrix(X_train, y_train)\ndtest = xgb.DMatrix(X_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0cafa793-c676-b827-daf5-9ffa44cac237"},"outputs":[],"source":"model = xgb.train(xgb_params, dtrain, num_boost_round=300)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6b627ba0-699f-ac0b-ec3e-bf13c733efe9"},"outputs":[],"source":"predy = model.predict(dtest)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a27aa22a-7083-1bde-8378-e8bd1dcbae7a"},"outputs":[],"source":"#finding r2 value\nfrom sklearn.metrics import r2_score\nr2_score(y_test,predy)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"686695a9-0ead-ae12-faf4-f47f1e3edc25"},"outputs":[],"source":"# Transforming the test data\ndf_test_quant = df_test.select_dtypes(include=['int64', 'floating', 'datetime64'])\ndf_test_quant = df_test_quant.drop('timestamp', 1)\nfor i in range(1,len(df_test_quant.columns)):\n       df_test_quant.iloc[:,i] = df_test_quant.iloc[:,i].fillna(df_test_quant.iloc[:,i].mean())\n#y = df_test_quant['price_doc']\n#df_train = df_train_quant.drop('price_doc', 1) \ntest = PCA.fit_transform(df_test_quant)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d0e1460f-5a20-0e77-ddb2-1e346265f9d4"},"outputs":[],"source":"dtest = xgb.DMatrix(test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ab71be16-0ac8-4cbb-8955-584a80d76b43"},"outputs":[],"source":"result = model.predict(dtest)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ecc1cc2c-1449-d890-61a3-455d54c3c18c"},"outputs":[],"source":"result = pd.DataFrame(result)\nresult['id'] = df_test['id']\nresult['price_doc'] = result.iloc[:,0]\nresult = result.drop(0,1)\nresult['price_doc'] = result['price_doc'].round(2)\n#result.to_csv(\"output_5.csv\", index = False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4688081a-3fb5-7132-8d5d-0b452d716dbf"},"outputs":[],"source":"result.to_csv(\"output_6.csv\", index = False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}