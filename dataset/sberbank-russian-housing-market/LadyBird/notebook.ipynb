{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9dbf9ec3-4747-c265-b64d-515476c0f855"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e67a2e2f-3dc2-213c-df25-27a339a8f6e4"},"outputs":[],"source":"df_train = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'])\ndf_test = pd.read_csv(\"../input/test.csv\", parse_dates=['timestamp'])\ndf_macro = pd.read_csv(\"../input/macro.csv\", parse_dates=['timestamp'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2ae05567-9225-4566-34d0-99be6a1edea9"},"outputs":[],"source":"def feature_summary(data):\n    n_row=data.shape[0]\n    features=pd.DataFrame()\n    features_names=[]\n    features_type = []\n    features_counts=[]\n    features_missing=[]\n    names=data.columns.values\n    for i in names:\n        features_names.append(i)\n        features_type.append(type(data.ix[1,i]))\n        features_counts.append(data[i].value_counts().count())\n        features_missing.append(data[data[i].isnull()].shape[0])\n    features['name']=features_names\n    features['type'] = features_type\n    features['value counts']=features_counts\n    features['missing']=features_missing\n    features['percentage_missing']=features['missing']/n_row\n    return (features)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"131512a8-3b37-d7e5-1737-cd0e014f40b9"},"outputs":[],"source":"feature_summary(df_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4c28fd0f-e120-3e16-46da-bf931f87b68a"},"outputs":[],"source":"df_train_quant = df_train.select_dtypes(include=['int64', 'floating', 'datetime64'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8f2fbc79-4b05-4712-e52b-3198a98802e7"},"outputs":[],"source":"def normalize(test_series):\n    normalized = (test_series - test_series.mean())/test_series.std()\n    return normalized\ndef denormalize(test_series, std_val, mean_val):\n    denormalized = (test_series*std_val) + mean_val\n    return denormalized"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b8b606c6-92db-ae6e-96d6-d516d1f7dd1a"},"outputs":[],"source":"import numpy as np\nfrom sklearn.decomposition import PCA\nPCA = PCA(n_components = 1)\n#handling missing values using mean values? we can explore more methods for this at a later\n#stage\ndf_train_quant = df_train_quant.drop('timestamp', 1)\nfor i in range(1,len(df_train_quant.columns)):\n       df_train_quant.iloc[:,i] = df_train_quant.iloc[:,i].fillna(df_train_quant.iloc[:,i].mean())\ny = df_train_quant['price_doc']\ndf_train_quant = df_train_quant.drop('price_doc', 1)\ndf_quant = PCA.fit_transform(df_train_quant)\ny_mean = y.mean()\ny_std = y.std()\ny_normalized = normalize(y)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f1075012-c63a-4988-ae7d-76c1de1c07d8"},"outputs":[],"source":"#some PCA analysis\npd.DataFrame(PCA.explained_variance_ratio_).head(100)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bb71acb0-228f-908e-b10c-c6f429cc3e38"},"outputs":[],"source":"# simple linear regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import linear_model as lm \nX_train,X_test,y_train,y_test = train_test_split(df_quant,y_normalized,test_size=0.2)# simple linear regression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import linear_model as lm \n#X_train,X_test,y_train,y_test = train_test_split(df_quant,y,test_size=0.2)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7e070ebf-8be5-bb3a-680d-86e94ad2cd3b"},"outputs":[],"source":"#X_train = pd.DataFrame(X_train)\n#X_test = pd.DataFrame(X_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0cff8e75-0dfa-a356-2770-49425358e45b"},"outputs":[],"source":"#model = lm.LinearRegression()\n#m = model.fit(X_train, y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"df5fd6c5-674f-c686-cefe-c23c07bda6ee"},"outputs":[],"source":"import xgboost as xgb\nxgb_params = {\n    'eta': 0.05,\n    'max_depth': 6,\n    'subsample': 0.7,\n    'colsample_bytree': 0.7,\n    'objective': 'reg:linear',\n    'eval_metric': 'rmse',\n    'silent': 0\n}\n\ndtrain = xgb.DMatrix(X_train, y_train)\ndtest = xgb.DMatrix(X_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fd070883-51b9-d5d2-d6f2-f731160a2b83"},"outputs":[],"source":"# let us try random forests here? \nfrom sklearn.ensemble import RandomForestRegressor\nclf = RandomForestRegressor(n_estimators = 500)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5b2a6c8a-b75a-35dc-7a81-d169bc8b07a4"},"outputs":[],"source":"clf.fit(X_train, y_train)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ebca0637-ec57-421d-7b36-4a916e9b5746"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"027d1707-a9f5-155f-c02e-dde31ecd2955"},"outputs":[],"source":"predy = clf.predict(X_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c7dbf38e-c455-f642-8357-1573ba9ff4a8"},"outputs":[],"source":"from sklearn.metrics import r2_score\nr2_score(y_test,predy)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4011ccbd-251d-5f35-88bf-6e135417fd36"},"outputs":[],"source":"# Transforming the test data\ndf_test_quant = df_test.select_dtypes(include=['int64', 'floating', 'datetime64'])\ndf_test_quant = df_test_quant.drop('timestamp', 1)\nfor i in range(1,len(df_test_quant.columns)):\n       df_test_quant.iloc[:,i] = df_test_quant.iloc[:,i].fillna(df_test_quant.iloc[:,i].mean())\ntest = PCA.fit_transform(df_test_quant)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1528300b-ca2f-6034-5b40-b9658f1cb4ea"},"outputs":[],"source":"y_values = m.predict(test)\ny_values_denormalized = denormalize(y_values, y_std, y_mean)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9442e2e9-c5d8-bba9-22b8-59e3cc50013e"},"outputs":[],"source":"result = pd.DataFrame(y_values_denormalized).abs()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"186fe8cf-2e8f-c9bb-1a76-f767297c2cfb"},"outputs":[],"source":"# fitting results into a csv file\nresult['id'] = df_test['id']\nresult['price_doc'] = result.iloc[:,0]\nresult = result.drop(0,1)\nresult['price_doc'] = result['price_doc'].round(2)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d054c902-bd0e-847c-1460-d7cceec5ff0e"},"outputs":[],"source":"result.to_csv(\"output_7.csv\", index = False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}