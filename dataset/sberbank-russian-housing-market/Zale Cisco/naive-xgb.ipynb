{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"ac06cd79-9189-6d2b-9a83-012d19327beb"},"source":"Load the required libraries and data. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"555a1731-6a24-51ed-f194-a47541b955db"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn import model_selection, preprocessing\nimport xgboost as xgb\nimport datetime\n#now = datetime.datetime.now()\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\nmacro = pd.read_csv('../input/macro.csv')\nid_test = test.id\ntrain.sample(3)\n# Any results you write to the current directory are saved as output."},{"cell_type":"markdown","metadata":{"_cell_guid":"c7c627cd-2b12-e5be-7a88-899fb6aef63d"},"source":"Reynaldo didn't have much success with \"year. month, day,\" but what about ordinal time..."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"26e812eb-e933-d9dc-2a35-9924eb55923f"},"outputs":[],"source":"# refdate = pd.to_datetime(\"2009-01-01\").toordinal()  # Just to make the numbers small\n\n# train[\"time\"] = pd.to_datetime(train[\"timestamp\"]).apply(lambda x: x.toordinal()) - refdate\n\n# test[\"time\"] = pd.to_datetime(train[\"timestamp\"]).apply(lambda x: x.toordinal()) - refdate"},{"cell_type":"markdown","metadata":{"_cell_guid":"97bfd616-afd2-c9e0-7bd8-d7ca49e289c6"},"source":"OK, fine, that didn't help either.  Let's just see if I can reproduce Reynaldo's results.  I won't bother to submit them because, well, there doesn't seem much point in adding nol kopeyek."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"99278d98-cd21-7952-6391-44a01d2d121b"},"outputs":[],"source":"\ny_train = train[\"price_doc\"]\nx_train = train.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1)\nx_test = test.drop([\"id\", \"timestamp\"], axis=1)\n\nfor c in x_train.columns:\n    if x_train[c].dtype == 'object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(x_train[c].values)) \n        x_train[c] = lbl.transform(list(x_train[c].values))\n        #x_train.drop(c,axis=1,inplace=True)\n        \nfor c in x_test.columns:\n    if x_test[c].dtype == 'object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(x_test[c].values)) \n        x_test[c] = lbl.transform(list(x_test[c].values))\n        #x_test.drop(c,axis=1,inplace=True)        "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3da71ccf-e6e2-3147-b79f-78a9329bd71d"},"outputs":[],"source":"x_train.sub_area.value_counts()\nx_train.product_type.value_counts()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"af764b6c-2945-d2e7-f658-0a4016ad6d1b"},"outputs":[],"source":"# Adding sample weights\n# OK, this didn't help\n\n# Note that this means my RMSEs on any part of the training set \n#   are not comparable with Reynaldo's\n# I'm deliberately downweighting points that are hard to fit, \n#   so RMSE will be lower, but this might not mean better performance \n\n# million1 = (y_train==1e6)\n# million2 = (y_train==2e6)\n# million3 = (y_train==3e6)\n# owner_occ = (x_train.product_type==1)\n# nek = (x_train.sub_area==72) # Nekrasovka\n# weights = 5 - 3*million1 - 2*million2 - 1*million3 + owner_occ + nek"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8af6c180-4e30-8c18-9b93-9dc32a242792"},"outputs":[],"source":"xgb_params = {\n    'eta': 0.05,\n    'max_depth': 5,\n    'subsample': 0.7,\n    'colsample_bytree': 0.75,\n    'objective': 'reg:linear',\n    'eval_metric': 'rmse',\n    'silent': 1\n}\n\n#dtrain = xgb.DMatrix(x_train, y_train, weight=weights)\ndtrain = xgb.DMatrix(x_train, y_train)\ndtest = xgb.DMatrix(x_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6fef7514-5663-5363-6083-6d7dfc6fb25e"},"outputs":[],"source":"# OK, put this back.  Maybe we needed it to get a random seed right?\n\n# Why waste time with this?  We know it came up with a lucky guess,\n#   so just remember the guess\n\ncv_output = xgb.cv(xgb_params, dtrain, num_boost_round=1000, early_stopping_rounds=20,\n    verbose_eval=50, show_stdv=False)\ncv_output[['train-rmse-mean', 'test-rmse-mean']].plot()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a96d1965-8328-35b0-d0a3-dfcfa77275ab"},"outputs":[],"source":"num_boost_rounds = len(cv_output)\n#num_boost_rounds = 384\n# but it used to be 455. Not sure what's going on here.\nmodel = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round= num_boost_rounds)\n                "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2a04f7d8-3efa-df54-713e-f6222453c60b"},"outputs":[],"source":"fig, ax = plt.subplots(1, 1, figsize=(8, 13))\nxgb.plot_importance(model, max_num_features=50, height=0.5, ax=ax)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"45eb5658-956d-b238-5f55-e9ad10b0201c"},"outputs":[],"source":"print( num_boost_rounds )"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6f030a26-5bd5-fbe5-a170-cd11173b44f9"},"outputs":[],"source":"y_predict = model.predict(dtest)\ny_predict[(y_predict<=1.5e6)&(x_test.product_type==0)] = 1000000\ny_predict[(y_predict>1.5e6)&(y_predict<2.5e6)&(x_test.product_type==0)] = 2000000\ny_predict[(y_predict>=2.5e6)&(y_predict<3.1e6)&(x_test.product_type==0)] = 3000000"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"27d0831f-df36-2608-b11a-a335c9a79613"},"outputs":[],"source":"output = pd.DataFrame({'id': id_test, 'price_doc': y_predict})\noutput.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0a5dbdee-3e96-aded-9c71-2e2c72af3e5a"},"outputs":[],"source":"output.to_csv('xgbSub.csv', index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"514f9f33-b52a-de56-841a-3241883d2e18"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}