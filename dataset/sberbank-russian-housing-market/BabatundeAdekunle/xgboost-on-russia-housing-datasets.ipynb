{"nbformat":4,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"version":"3.6.1","nbconvert_exporter":"python","file_extension":".py","pygments_lexer":"ipython3","name":"python","codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python"}},"cells":[{"execution_count":null,"source":"In this Scripts, I will be training XGboost on my Random Forest Implementations and feature engineering I did.","cell_type":"markdown","metadata":{"_execution_state":"idle","_cell_guid":"db4af5ad-80b4-4c8f-8d83-84a57afd8bad","_uuid":"844f50c237d48873b5e33e2224f5f699bb211769","collapsed":false},"outputs":[]},{"execution_count":null,"outputs":[],"cell_type":"code","metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"c1c0721d-0b8f-4e35-9f56-e0d0d10b4f3c","_uuid":"ea80cf451fcd619d39b298e6a99171c1a8b21eb2"},"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"execution_count":null,"source":"data = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'])\nprint(\"Done 1\")\n\ndata_test = pd.read_csv(\"../input/test.csv\", parse_dates=['timestamp'])","cell_type":"code","metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"b63f6d8f-4648-477a-ac63-54fdf8fb0dc5","_uuid":"b111bd7dcba73fb9add3470a1a42fb6c3bb94e37","collapsed":false},"outputs":[]},{"execution_count":null,"source":"pd.set_option('display.max_columns', 500) #This is a very handy tool for large column datasets\ndata.head()","cell_type":"code","metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"53796451-b599-4561-9ca0-37630799f48e","_uuid":"ffdd6b2e848b5ac420f4052796a78ce36e286c92","collapsed":false},"outputs":[]},{"execution_count":null,"source":"data_type = data.dtypes.reset_index() #Reset index gives an index to the dataframe\ndata_type.columns=[\"columns\", \"data_type\"]\ndata_type.head()\n\ndata_type.groupby('data_type').aggregate('count').reset_index()","cell_type":"code","metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"2d2644c4-d7ae-4e6b-abe5-9008dfec1f9c","_uuid":"d292c462800c9aaa9b931b8ddc5d2f77cd1af34b","collapsed":false},"outputs":[]},{"execution_count":null,"source":"def isNullCount(data):\n    \"\"\"\n    Function to always compute the nullcount of a dataset\n    \n    Input: Dataframe of Dataset\n    Output: Dataframe of columns and number of nulls, A List of Null_columns\n    \n    \"\"\"\n    data_null = data.isnull().sum().reset_index()\n    data_null.columns = [\"column\", \"null_count\"]\n    null_column = data_null[data_null['null_count'] > 0]['column'].tolist()\n    return data_null, null_column\n\ndata_null, null_column = isNullCount(data)","cell_type":"code","metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"5f6a8345-abff-428c-acb6-b121556f8e40","_uuid":"1da15d6752bd41cb6d11bab48a3d16c939e89da7","collapsed":false},"outputs":[]},{"execution_count":null,"source":"data_null_6000 = data_null[data_null[\"null_count\"] > 6000]\n#Drop the columns of data_null_6000 from main data\nnull_6000_list = data_null_6000.column.values\n\nnull_list = data_null.column.tolist()\n\n#make a copy of the data befor going forward\ndata_copy = data.copy()\n\ndata_copy_notnull = data_copy.drop([null for null in null_6000_list], axis=1)\n\nnew_data = data_copy_notnull.copy()","cell_type":"code","metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"697f0ce9-e5a5-45c5-9fc6-270b8b4986d0","_uuid":"ac79a03550fb59b3fa8149993d5a5e9b856fcb61","collapsed":false},"outputs":[]},{"execution_count":null,"source":"color = sns.diverging_palette\nfig, ax = plt.subplots(figsize=(7,5))\nax.scatter(range(new_data.shape[0]), new_data.price_doc, alpha=0.2)\nplt.xlabel('index', fontsize=12)\nplt.ylabel('price', fontsize=12)\nplt.show()","cell_type":"code","metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"afefd073-e519-4589-9657-9f71ae12b395","_uuid":"e2d01ecb33d23bb8606d49c6e128bac74f3a5a9c","collapsed":false},"outputs":[]},{"execution_count":null,"source":"from sklearn.model_selection import train_test_split\ntrain_set, test_set = train_test_split(new_data, test_size=0.2, random_state=42)\nlen(train_set)","cell_type":"code","metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"2688be03-d591-4646-a176-d9d085be881b","_uuid":"8ce83c586d0e5d28e8c445d3cc626cbe4184495a","collapsed":false},"outputs":[]},{"execution_count":null,"source":"### Training Data after removing Null Values >6000","cell_type":"markdown","metadata":{"_execution_state":"idle","_cell_guid":"9defb615-7d8c-4c44-9c1c-51e596ff2959","_uuid":"e8ce35f125b3a74a9e144b34a240f5ce0edf2356","collapsed":false},"outputs":[]},{"execution_count":null,"source":"prep_train = train_set.drop(['price_doc', 'timestamp'], axis=1)\ny_label = train_set['price_doc'].copy()\n\ndata_type = prep_train.dtypes.reset_index() #Reset index gives an index to the dataframe\ndata_type.columns=[\"columns\", \"data_type\"]\ndata_type.head()\n\ndata_type.groupby('data_type').aggregate('count').reset_index()","cell_type":"code","metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"555360da-6540-465a-b242-3388f0343a35","_uuid":"6b8282ed219aab51e0c7636c37d26eb7af00d286","collapsed":false},"outputs":[]},{"execution_count":null,"source":"#Let's get the columns with numeric values\nprep_train_num = prep_train.select_dtypes(include=[\"int64\", \"float64\"])\n\n#Column with object values\nprep_train_obj = prep_train.select_dtypes(include=[\"object\"])","cell_type":"code","metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"3a83f8a1-75a1-495b-bd86-58c3aaa11e46","_uuid":"d8adcf5e00756cca93450e70c330f26a20a340e2","collapsed":false},"outputs":[]},{"execution_count":null,"source":"from sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.pipeline import TransformerMixin\nfrom sklearn.base import BaseEstimator\n\nnum_attributes = list(prep_train_num)\ncat_attributes = list(prep_train_obj)\n\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.preprocessing import Imputer\n\nclass NewLabelBinarizer(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        arrayed = np.array([])\n        for i in range(X.shape[1]):\n            col = X[:, i].reshape(-1, 1)\n            binarizer = LabelBinarizer().fit_transform(col)\n            arrayed = np.hstack([arrayed, binarizer]) if arrayed.size else binarizer\n        return arrayed\n    def fit_transform(self, X, y=None):\n        return self.fit(X, y).transform(X)","cell_type":"code","metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"12908048-d7c6-4f85-9e92-d3bb487ce2bc","_uuid":"99fb24e1b708b2558268bab7a79e723ac84efa1b","collapsed":false},"outputs":[]},{"execution_count":null,"source":"class DataFrameSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, attribute_names):\n        self.attribute_names = attribute_names\n    def fit(self, X, y=None):\n        return self\n    def transform(self, X):\n        return X[self.attribute_names].values\n    def fit_transform(self, X, y=None):\n        return self.fit(X,y).transform(X)\n\nnum_pipeline = Pipeline([\n        ('selector', DataFrameSelector(num_attributes)),\n        ('imputer', Imputer(strategy=\"median\"))\n    ])\n\ncat_pipeline = Pipeline([\n        ('selector', DataFrameSelector(cat_attributes)),\n        ('binarizer', NewLabelBinarizer())\n        #('cat_binarizer', MultiColumnLabelEncoder())\n    ])\n    \nfull_pipeline = FeatureUnion(transformer_list=[\n        ('num_pipeline', num_pipeline),\n        ('cat_pipeline', cat_pipeline)\n    ])","cell_type":"code","metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"8c1c80e0-e3da-43d8-9da8-bbc639e7e7d3","_uuid":"55ff47dbdbcf1699d66c2a2c34e98c4e5fc2d8b3","collapsed":false},"outputs":[]},{"execution_count":null,"source":"final_prep = full_pipeline.fit_transform(prep_train)","cell_type":"code","metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"c979bbed-a3e5-4263-938f-7cd65c1098aa","_uuid":"2fa8ac7446f9ee27dee6d52e8ec3781f437c75b3","collapsed":false},"outputs":[]},{"execution_count":null,"source":"final_prep.shape","cell_type":"code","metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"c06943ac-3c36-4cd1-a24e-8e4435dc71a6","_uuid":"5e1f959404bed25f245e165d122c3578a4ccd252","collapsed":false},"outputs":[]},{"execution_count":null,"source":"#Make RLSME Scorer\ndef rmsle(predicted, actual):\n    return np.sqrt(np.square(np.log(predicted + 1) - np.log(actual + 1)).mean())\n\nfrom sklearn.metrics import make_scorer\nscorer = make_scorer(rmsle, greater_is_better=False)\n\n#Train some model on the data\ndef display_scores(scores):\n    print(\"Scores:\", scores)\n    print(\"Score_mean\", scores.mean())\n    print(\"Score_std\", scores.std())","cell_type":"code","metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"478c0af0-ace0-4ae6-845a-46274090d1d4","_uuid":"3b12c526bd90f6cd5ee771433f4b1f470f06470e","collapsed":false},"outputs":[]},{"execution_count":null,"source":"from sklearn.model_selection import cross_val_score\nimport xgboost as xgb\n\nmodel1 = xgb.XGBRegressor()\nscores = cross_val_score(model1, final_prep, y_label, scoring=scorer, cv=10)\ndisplay_scores(-scores)","cell_type":"code","metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"05fd50b4-c1d5-4b5e-8c3e-3b3ecd7cecab","_uuid":"69d8e3a40c6e2cdaffb4a30b756dd0aed7acf8ad","collapsed":false},"outputs":[]},{"execution_count":null,"source":"data_test = data_test.drop([null for null in null_6000_list], axis=1)\n\ndata_test.isnull().values.any()","cell_type":"code","metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"3e3b72f2-d56b-4802-afbb-828634d5693f","_uuid":"47cee1002b22b3f2db39a7daae7e84383bcf1c5f","collapsed":false},"outputs":[]},{"execution_count":null,"source":"median = data_test.median()\n\ntest_prep = data_test.fillna(data_test.median())\ntest_prep = test_prep.fillna(method='pad')","cell_type":"code","metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"529273ec-3108-45dc-a4df-2908e3c6ed87","_uuid":"4904945b0aa13104e5387d2b996bb780ae912edb","collapsed":false},"outputs":[]},{"execution_count":null,"source":"prep_test = test_prep.drop('timestamp', axis=1)\nfinal_test = full_pipeline.fit_transform(prep_test)","cell_type":"code","metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"a5a2437e-51a3-464a-8d43-accb092b9fd2","_uuid":"463371481020300d4239dc784c45c226e48b595f","collapsed":false},"outputs":[]},{"execution_count":null,"source":"final_prep.shape, final_test.shape","cell_type":"code","metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"7dbec6dc-63aa-4edf-b573-f881de09fccf","_uuid":"1b0312ce932f489ec627b4803376695739a48bcc","collapsed":false},"outputs":[]},{"execution_count":null,"source":"train_model1 = model1.fit(final_prep, y_label)","cell_type":"code","metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"3a356c24-8425-4891-9be5-e55c09b02950","_uuid":"c1d3e89759e8273a52fec79c05817b5df00d519d","collapsed":false},"outputs":[]},{"execution_count":null,"source":"pred1 = train_model1.predict(final_test)","cell_type":"code","metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"e1874890-7467-4ebd-8939-74b01c298979","_uuid":"84db7b583808d29d3253a8c8ed1e12e63bf68101","collapsed":false},"outputs":[]},{"execution_count":null,"source":"sub = pd.DataFrame(data= {'id': prep_test['id'].ravel()})\nsub['price_doc'] = pred1\nsub.to_csv(\"submission.csv\", index = False, header = True)","cell_type":"code","metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"99501934-8654-4c94-80c3-fec579cd741c","_uuid":"128bf88f633ab25dff43eda188af44c540f01d2e","collapsed":false},"outputs":[]},{"execution_count":null,"source":"### This notebooks scored me 0.337 which is far more better than the 0.358 gotten with the same random Forest Implementation","cell_type":"markdown","metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"364b9049-56c2-467e-bb92-b657a6f5a2b2","_uuid":"5537b88e24ff0a769a1c24b6c3b3621dffa2491d","collapsed":false},"outputs":[]}],"nbformat_minor":0}