{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"89d1da9e-2821-de09-faea-c1af12f56381"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\n#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\nimport numpy as np\nimport pandas as pd\nimport xgboost as xgb\nimport matplotlib.pyplot as plt\ndf_train = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'])\ndf_test = pd.read_csv(\"../input/test.csv\", parse_dates=['timestamp'])\ndf_macro = pd.read_csv(\"../input/macro.csv\", parse_dates=['timestamp'])\n\ndf_train.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b376eaff-9a82-27ab-0db4-98c1a098d126"},"outputs":[],"source":"y_train = df_train['price_doc'].values\nid_test = df_test['id']\n\ndf_train.drop(['id', 'price_doc'], axis=1, inplace=True)\ndf_test.drop(['id'], axis=1, inplace=True)\n\n# Build df_all = (df_train+df_test).join(df_macro)\nnum_train = len(df_train)\ndf_all = pd.concat([df_train, df_test])\ndf_all = pd.merge_ordered(df_all, df_macro, on='timestamp', how='left')\nprint(df_all.shape)\n\n# Add month-year\nmonth_year = (df_all.timestamp.dt.month + df_all.timestamp.dt.year * 100)\nmonth_year_cnt_map = month_year.value_counts().to_dict()\ndf_all['month_year_cnt'] = month_year.map(month_year_cnt_map)\n\n# Add week-year count\nweek_year = (df_all.timestamp.dt.weekofyear + df_all.timestamp.dt.year * 100)\nweek_year_cnt_map = week_year.value_counts().to_dict()\ndf_all['week_year_cnt'] = week_year.map(week_year_cnt_map)\n\n# Add month and day-of-week\ndf_all['month'] = df_all.timestamp.dt.month\ndf_all['dow'] = df_all.timestamp.dt.dayofweek\n\n# Other feature engineering\ndf_all['rel_floor'] = df_all['floor'] / df_all['max_floor'].astype(float)\ndf_all['rel_kitch_sq'] = df_all['kitch_sq'] / df_all['full_sq'].astype(float)\n\n# Remove timestamp column (may overfit the model in train)\ndf_all.drop(['timestamp'], axis=1, inplace=True)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b193948a-cf9a-3277-14ab-e4bd5102359b"},"outputs":[],"source":"# Deal with categorical values\ndf_numeric = df_all.select_dtypes(exclude=['object'])\ndf_obj = df_all.select_dtypes(include=['object']).copy()\n\nfor c in df_obj:\n    df_obj[c] = pd.factorize(df_obj[c])[0]\n\ndf_values = pd.concat([df_numeric, df_obj], axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"93a0e013-f649-dfb3-de5d-ae86cbe621ab"},"outputs":[],"source":"# Convert to numpy values\nX_all = df_values.values\nprint(X_all.shape)\n\nX_train = X_all[:num_train]\nX_test = X_all[num_train:]\n\ndf_columns = df_values.columns"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"877f933e-8c85-e607-9485-24f97efba61f"},"outputs":[],"source":"xgb_params = {\n    'eta': 0.05,\n    'max_depth': 5,\n    'subsample': 0.7,\n    'colsample_bytree': 0.7,\n    'objective': 'reg:linear',\n    'eval_metric': 'rmse',\n    'silent': 1\n}\n\ndtrain = xgb.DMatrix(X_train, y_train, feature_names=df_columns)\ndtest = xgb.DMatrix(X_test, feature_names=df_columns)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"88f78661-fe66-d4ec-e850-b78ffe92deba"},"outputs":[],"source":"# Uncomment to tune XGB `num_boost_rounds`\n\n#cv_result = xgb.cv(xgb_params, dtrain, num_boost_round=1000, early_stopping_rounds=20,\n#    verbose_eval=True, show_stdv=False)\n#cv_result[['train-rmse-mean', 'test-rmse-mean']].plot()\n#num_boost_rounds = len(cv_result)\n#print(num_boost_rounds)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cdabad99-0bff-86bc-2996-bb27b8a5a2f4"},"outputs":[],"source":"num_boost_round = 384\nmodel = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_round)\nprint(\"Model Trained\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3758727a-f679-c190-48c5-07ead700574c"},"outputs":[],"source":"y_pred = model.predict(dtest)\n\ndf_sub = pd.DataFrame({'id': id_test, 'price_doc': y_pred})\n\ndf_sub.to_csv('sub.csv', index=False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}