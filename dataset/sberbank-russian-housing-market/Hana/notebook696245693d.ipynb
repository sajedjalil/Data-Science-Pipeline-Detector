{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"a7f99720-f48f-9740-383d-66fa3be11cb0"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9a0aa742-f689-c5f9-8848-e7c67f126642"},"outputs":[],"source":"from subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\nimport numpy as np \nimport pandas as pd \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\n%matplotlib inline\nfrom sklearn import model_selection, preprocessing\nfrom sklearn.linear_model import LinearRegression\nimport xgboost as xgb\ncolor = sns.color_palette()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"76a8dc36-fa21-22e5-efec-a084eecafe0f"},"outputs":[],"source":"train_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv(\"../input/test.csv\")\nprint ('train_df',train_df.shape)\nprint ('test_df',test_df.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5079974d-2b07-117e-4ee7-e2f6606d38fd"},"outputs":[],"source":"train_df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"648817be-c40e-a8b8-d781-0e7ccd59197f"},"outputs":[],"source":"## Describe the output field\nprint(train_df['price_doc'].describe())\nsns.distplot(train_df['price_doc'])\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e04c0284-447f-4fe1-dd70-b167d1a5456c"},"outputs":[],"source":"#The dependent variable is skewed . The easiest would be to take a log tranformation\ntrain_df['LogAmt']=np.log(train_df.price_doc+1.0)\nprint(train_df['LogAmt'].describe())\nsns.distplot(train_df['LogAmt'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"755a0ec3-1801-7ace-f5da-00d06649fe80"},"outputs":[],"source":"#do a scatter plot to see if there are any outliers in the data.\n\nplt.figure(figsize=(8,6))\nplt.scatter(range(train_df.shape[0]), np.sort(train_df.price_doc.values),color=color[2])\nplt.xlabel('index', fontsize=12)\nplt.ylabel('price', fontsize=12)\nplt.show()\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bae598a4-7403-dcc0-841c-1cd0f14a6480"},"outputs":[],"source":"#get the count of different data types\n\ntrain_df = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'])\ndtype_df = train_df.dtypes.reset_index()\ndtype_df.columns = [\"Count\", \"Column Type\"]\ndtype_df.groupby(\"Column Type\").aggregate('count').reset_index()\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8192ba60-a7f1-96f4-4d29-262f87370448"},"outputs":[],"source":"#explore the number of missing values in each column.\n\nmissing = train_df.isnull().sum(0).reset_index()\nmissing.columns = ['column', 'count']\nmissing = missing.sort_values(by = 'count', ascending = False).loc[missing['count'] > 0]\nmissing['percentage'] = missing['count'] / float(train_df.shape[0]) * 100\nind = np.arange(missing.shape[0])\nwidth = 0.9\nfig, ax = plt.subplots(figsize=(10,18))\nrects = ax.barh(ind, missing.percentage.values, color='g')\nax.set_yticks(ind)\nax.set_yticklabels(missing.column.values, rotation='horizontal')\nax.set_xlabel(\"Precentage of missing values %\")\nax.set_title(\"Number of missing values in each column\")\nplt.show()\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9d9ee942-77fb-e2f9-aed3-ede4c919584b"},"outputs":[],"source":"# convert obj to num\n# train: \n#yes & no \nYNlist = ['culture_objects_top_25', 'thermal_power_plant_raion', 'incineration_raion', 'oil_chemistry_raion',\n          'radiation_raion', 'railroad_terminal_raion', 'big_market_raion', 'nuclear_reactor_raion',\n          'detention_facility_raion', 'water_1line', 'big_road1_1line', 'railroad_1line']\nfor c in YNlist :\n    train_df.ix[train_df[c]=='yes', c]=1\n    train_df.ix[train_df[c]=='no', c]=0\n###ecology column\ntrain_df.ix[train_df[\"ecology\"]=='poor', \"ecology\"]=0\ntrain_df.ix[train_df[\"ecology\"]=='satisfactory', \"ecology\"]=1\ntrain_df.ix[train_df[\"ecology\"]=='good', \"ecology\"]=2\ntrain_df.ix[train_df[\"ecology\"]=='excellent', \"ecology\"]=3\ntrain_df.ix[train_df[\"ecology\"]=='no data', \"ecology\"]=1\n### product_type column\ntrain_df.ix[train_df[\"product_type\"]=='Investment', \"product_type\"]=1\ntrain_df.ix[train_df[\"product_type\"]=='OwnerOccupier', \"product_type\"]=0"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f5074891-6f04-7701-1017-155044a37fc5"},"outputs":[],"source":"# convert obj to num\n# test :  \n#yes & no \nfor i in YNlist :\n    test_df.ix[test_df[i]=='yes', i]=1\n    test_df.ix[test_df[i]=='no', i]=0\n###ecology column\ntest_df.ix[test_df[\"ecology\"]=='poor', \"ecology\"]=0\ntest_df.ix[test_df[\"ecology\"]=='satisfactory', \"ecology\"]=1\ntest_df.ix[test_df[\"ecology\"]=='good', \"ecology\"]=2\ntest_df.ix[test_df[\"ecology\"]=='excellent', \"ecology\"]=3\ntest_df.ix[test_df[\"ecology\"]=='no data', \"ecology\"]=1\n### product_type column\ntest_df.ix[test_df[\"product_type\"]=='Investment', \"product_type\"]=1\ntest_df.ix[test_df[\"product_type\"]=='OwnerOccupier', \"product_type\"]=0"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7465a2a7-126d-acaf-7181-13eac6c11b34"},"outputs":[],"source":"from sklearn.base import TransformerMixin\nclass DataFrameImputer(TransformerMixin):\n    def fit(self, X, y=None):\n        self.fill = pd.Series([X[c].value_counts().index[0]\n        if X[c].dtype == np.dtype('O') else X[c].median() for c in X],\n        index=X.columns)\n        return self\n    def transform(self, X, y=None):\n        return X.fillna(self.fill)\ntest_df = DataFrameImputer().fit_transform(test_df)\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"14a45bad-549e-f1ef-d108-8ec434e4adc6"},"outputs":[],"source":"from sklearn.base import TransformerMixin\nclass DataFrameImputer(TransformerMixin):\n    def fit(self, X, y=None):\n        self.fill = pd.Series([X[c].value_counts().index[0]],index=X.columns)\n        return self\n    def transform(self, X, y=None):\n        return X.fillna(self.fill)\ntrain_df = DataFrameImputer().fit_transform(train_df)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"be518324-86b8-c67d-e12d-81fe4c7be626"},"outputs":[],"source":"# fit the model\ny = train_df.price_doc\ntrain_X = train_df.drop([\"price_doc\",\"id\",\"timestamp\",\"sub_area\"],axis=1)\n\nlinearRegression = LinearRegression()\n\nlinearRegression.fit(train_X, y)\nprint(linearRegression.intercept_)\nprint(linearRegression.coef_)\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"52cb4cef-dcd1-bf1a-50d9-f3de3657baf1"},"outputs":[],"source":"from sklearn import metrics\ntest_X = test_df.drop([\"id\",\"timestamp\",\"sub_area\"],axis=1)\ny_pred = linearRegression.predict(test_X)\nprint (y_pred)\nprint (y_pred.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1f724867-9cb9-c56e-ce0f-1f725e01f18b"},"outputs":[],"source":"submission_df = pd.DataFrame({'id':test_df.id, 'price_doc':y_pred}).set_index('id').to_csv('sub.csv')\nimport os\ncwd = os.getcwd()\nprint (cwd)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}