{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"0f9bc9e7-7663-15f9-43e4-f2f770d1f9f3"},"source":"### Consider the influence of seasonality"},{"cell_type":"markdown","metadata":{"_cell_guid":"8f9f9f0d-ebfc-93b6-4697-b2778a7e0d02"},"source":"### Consider the year of the transaction"},{"cell_type":"markdown","metadata":{"_cell_guid":"86408e65-3cd8-4490-03ff-214c700f380c"},"source":"### Consider smaller set of features in macro\n* eliminate two similar features in macro:\"micex_rgbi_tr\", \"micex_cbi_tr\", and keep \"micex\".\n* eliminate \"balance_trade_growth\", and keep \"balance_trade\". \n* optimize the macro features"},{"cell_type":"markdown","metadata":{"_cell_guid":"84ca4a0a-e775-98a5-b607-eda014183361"},"source":"# Plot some figures"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"15f71760-0a7e-2029-72c0-55074ebd8e21"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn import model_selection, preprocessing\nimport xgboost as xgb\nimport datetime\n#now = datetime.datetime.now()\n\n# From here: https://www.kaggle.com/robertoruiz/sberbank-russian-housing-market/dealing-with-multicollinearity/notebook\n#macro_cols = [\"balance_trade\", \"balance_trade_growth\", \"eurrub\", \"average_provision_of_build_contract\",\n#\"micex_rgbi_tr\", \"micex_cbi_tr\", \"deposits_rate\", \"mortgage_value\", \"mortgage_rate\",\n#\"income_per_cap\", \"rent_price_4+room_bus\", \"museum_visitis_per_100_cap\", \"apartment_build\",\"bandwidth_sports\", \n#             \"micex\", \"net_capital_export\", \"oil_urals\"]\n\nmacro_cols = [\"balance_trade_growth\", \"eurrub\", \"average_provision_of_build_contract\",\"deposits_rate\", \"mortgage_value\", \"mortgage_rate\",\n\"income_per_cap\", \"apartment_build\",\"bandwidth_sports\", \n             \"micex\", \"net_capital_export\", \"oil_urals\"]\n\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n#macro = pd.read_csv('./input/macro.csv')\n\nmacro = pd.read_csv(\"../input/macro.csv\", parse_dates=['timestamp'], usecols=['timestamp'] + macro_cols)\n\n\nid_test = test.id\ntrain.sample(3)\nprint(train.shape)\nprint(test.shape)\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1f4cf79-6d95-2ad5-9c70-e633bd606ea9"},"outputs":[],"source":"#It seems that this doen't improve anything. \n\ntrain[\"timestamp\"] = pd.to_datetime(train[\"timestamp\"])\n#train[\"year\"] = train[\"timestamp\"].dt.year\n#train[\"month\"] = train[\"timestamp\"].dt.month\n\n#train[\"year\"], train[\"month\"], train[\"day\"] = train[\"timestamp\"].dt.year,train[\"timestamp\"].dt.month,train[\"timestamp\"].dt.day\n\ntest[\"timestamp\"] = pd.to_datetime(test[\"timestamp\"])\n#test[\"year\"] = test[\"timestamp\"].dt.year\n#test[\"month\"] = test[\"timestamp\"].dt.month\n#test[\"year\"], test[\"month\"], test[\"day\"] = test[\"timestamp\"].dt.year,test[\"timestamp\"].dt.month,test[\"timestamp\"].dt.day"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"077b6b24-8951-b6fe-601b-2ebff39a1678"},"outputs":[],"source":"train_all = pd.merge_ordered(train, macro, on='timestamp', how='left')\ntest_all = pd.merge_ordered(test, macro, on='timestamp', how = 'left')\n\nprint(train_all.shape)\nprint(test_all.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d25bbf3f-77c6-f82b-095b-0b5bc6240a86"},"outputs":[],"source":"plt.plot(train_all.mortgage_rate, train_all.eurrub, '.')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cc70bbaa-43b1-1db8-ba24-4a6541770938"},"outputs":[],"source":"# Other feature engineering\n#train_all['rel_floor'] = train_all['floor'] / train_all['max_floor'].astype(float)\n#train_all['rel_kitch_sq'] = train_all['kitch_sq'] / train_all['full_sq'].astype(float)\n#train_all['rel_life_sq'] = train_all['life_sq'] / train_all['full_sq'].astype(float)\n\n#test_all['rel_floor'] = test_all['floor'] / test_all['max_floor'].astype(float)\n#test_all['rel_kitch_sq'] = test_all['kitch_sq'] / test_all['full_sq'].astype(float)\n#test_all['rel_life_sq'] = test_all['life_sq'] / test_all['full_sq'].astype(float)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bf7745fb-b1be-1c15-4779-7cec2d28a3f9"},"outputs":[],"source":"#train_all.rel_life_sq > 1\n#train_all.loc[(train_all.rel_life_sq > 1.)]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4a0f52cc-121a-3082-6362-09049d751ff9"},"outputs":[],"source":"y_train = train_all[\"price_doc\"]\nx_train = train_all.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1)\nx_test = test_all.drop([\"id\", \"timestamp\"], axis=1)\n\n#can't merge train with test because the kernel run for very long time\n\nfor c in x_train.columns:\n    if x_train[c].dtype == 'object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(x_train[c].values)) \n        x_train[c] = lbl.transform(list(x_train[c].values))\n        #x_train.drop(c,axis=1,inplace=True)\n        \nfor c in x_test.columns:\n    if x_test[c].dtype == 'object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(x_test[c].values)) \n        x_test[c] = lbl.transform(list(x_test[c].values))\n        #x_test.drop(c,axis=1,inplace=True)       "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7852020a-00ca-0295-6141-438c0687bad9"},"outputs":[],"source":"xgb_params = {\n    'eta': 0.05,\n    'max_depth': 4,\n    'subsample': 0.9,\n    'colsample_bytree': 0.9,\n    'objective': 'reg:linear',\n    'eval_metric': 'rmse',\n    'silent': 1\n}\n\ndtrain = xgb.DMatrix(x_train, y_train)\ndtest = xgb.DMatrix(x_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"617893f1-22c3-3fe0-926e-8f15515f85f5"},"outputs":[],"source":"cv_output = xgb.cv(xgb_params, dtrain, num_boost_round=1000, early_stopping_rounds=20,\n    verbose_eval=50, show_stdv=False)\ncv_output[['train-rmse-mean', 'test-rmse-mean']].plot()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4486d3ca-8a2c-45aa-7c1c-083015ad64e9"},"outputs":[],"source":"num_boost_rounds = len(cv_output)\nmodel = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round= num_boost_rounds)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c6a44684-9381-f5e1-3014-38b05c5febc6"},"outputs":[],"source":"fig, ax = plt.subplots(1, 1, figsize=(8, 20))\nxgb.plot_importance(model, max_num_features=100, height=0.8, ax=ax)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0fbf36c4-a2d0-bf13-6a8f-6c418ea2f7c8"},"outputs":[],"source":"y_predict = model.predict(dtest)\noutput = pd.DataFrame({'id': id_test, 'price_doc': y_predict})\noutput.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"25283e72-35fb-e3a6-ebdd-76720376ad28"},"outputs":[],"source":"output.to_csv('sub10.csv', index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"acdd732e-b2f8-f9a3-17d7-c81f9e5c3a05","collapsed":true},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}