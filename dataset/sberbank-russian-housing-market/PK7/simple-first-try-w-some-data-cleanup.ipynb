{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"1e37bc3c-00da-5c42-69e0-b86c50e7df83"},"source":"# Trying out..."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f2e6397e-462b-b02f-7020-9b5b985da1a4"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn import model_selection, preprocessing\nimport xgboost as xgb\nimport math\n#import datetime"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a0ec5b6b-3e93-6872-3d8b-42e1b525c5d9"},"outputs":[],"source":"train_df = pd.read_csv('../input/train.csv', parse_dates=['timestamp'])\ntest_df = pd.read_csv('../input/test.csv', parse_dates=['timestamp'])\nmacro = pd.read_csv('../input/macro.csv', parse_dates=['timestamp'])"},{"cell_type":"markdown","metadata":{"_cell_guid":"9f75e402-b67b-319b-8b7a-615408d11f23"},"source":"## Some cleanup and correction on most important features... let's see..."},{"cell_type":"markdown","metadata":{"_cell_guid":"cb8028c7-7471-fd0b-95d7-62f492671e0a"},"source":"### cleaning up floors and max_floors  "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ab627620-ea16-8615-1e71-de64b88da982"},"outputs":[],"source":"# Few rows here to drop not much impact...\n\ntrain_df.dropna(axis=0, subset=['floor'], how='any', inplace=True)\ntrain_df.drop(train_df[train_df['floor'] == 0].index, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"46dbc6c7-75e4-0ce8-2182-07a4504bfab4"},"outputs":[],"source":"#Assuming Max_floor is equal to floor when it is not consistent.\ntrain_df['max_floor'] = train_df['max_floor'].fillna(0)\ntrain_df['max_floor'] = np.where(train_df['max_floor'] < train_df['floor'], train_df['floor'], train_df['max_floor'])"},{"cell_type":"markdown","metadata":{"_cell_guid":"a69f40f9-72cf-20e9-f5c2-40f1a0f2a2f5"},"source":"## Cleaning up Full_sq and life_Sq "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"19c303de-0ab9-4ef7-e5bc-f6f497609114"},"outputs":[],"source":"# wierd values corrected\ntrain_df.set_value(train_df[train_df['state'] == 33].index, 'state', 4)\ntrain_df.set_value(train_df[train_df['build_year'] == 20052009].index, 'build_year', 2007)\n# 1 Outlier in full_Sq we will delete for the moment\ntrain_df.drop(train_df[train_df['full_sq'] > 2000].index, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a6a05e11-b80a-881e-9629-64e7c06665ee"},"outputs":[],"source":"#droping rows where lif_sq is greater than full_sq (22 records )\ntrain_df['bad_life'] = train_df['full_sq'] - train_df['life_sq']\ntrain_df.drop(train_df[train_df['bad_life'] < 0].index, inplace=True)\n\n#completing NaN values with mean ratio between Full and Life SQ\ntrain_df['r_life_ful_sq'] = train_df['bad_life'] / train_df['full_sq']\nmean_ratio = train_df['r_life_ful_sq'].mean()\ntrain_df.life_sq.fillna(train_df.full_sq *(1 - mean_ratio), inplace=True)\n\n# droping working columns\ntrain_df.drop(['bad_life', 'r_life_ful_sq'], axis=1, inplace=True)\n\n# Replacing life_sq < 5sq by mean ration full and life as for NaN\ntrain_df['life_sq'] = np.where(train_df['life_sq'] <=5, train_df['full_sq'] * (1 - mean_ratio), train_df['life_sq'] )"},{"cell_type":"markdown","metadata":{"_cell_guid":"fe3dc500-9275-98f0-bd87-031c727bb915"},"source":"## merging macroeconomics data "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2ff69200-e170-8cb9-2c7d-f74d012c3c55"},"outputs":[],"source":"dftrain = pd.merge(train_df, macro, how='left', on='timestamp')\ndftest = pd.merge(test_df, macro, how='left', on='timestamp')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3f64c194-1726-ffab-3885-4ff70c51f46b"},"outputs":[],"source":"#y_train = dftrain[\"price_doc\"]\nx_train = dftrain.drop([\"id\", \"timestamp\"], axis=1)\nx_test = dftest.drop([\"id\", \"timestamp\"], axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a7ad4310-dc6f-7e13-ed67-150d85275537"},"outputs":[],"source":"# these variables are empty in test set or their feat importance is assumed small atm... \n# we will revisit later it will grow bigger for sure\nlist_empty = ['grp','grp_growth','real_dispos_income_per_cap_growth', 'profitable_enterpr_share',\n              'unprofitable_enterpr_share','share_own_revenues','overdue_wages_per_cap', 'fin_res_per_cap',\n              'marriages_per_1000_cap','divorce_rate','construction_value', 'invest_fixed_assets_phys',\n 'pop_migration','pop_total_inc','housing_fund_sqm','lodging_sqm_per_cap', 'water_pipes_share', 'baths_share',\n 'sewerage_share','gas_share', 'hot_water_share', 'electric_stove_share', 'heating_share',\n 'old_house_share', 'infant_mortarity_per_1000_cap', 'perinatal_mort_per_1000_cap', 'incidence_population',\n 'load_of_teachers_preschool_per_teacher', 'child_on_acc_pre_school', 'provision_doctors',\n 'power_clinics', 'hospital_beds_available_per_cap', 'hospital_bed_occupancy_per_year',\n 'provision_retail_space_sqm', 'provision_retail_space_modern_sqm', 'theaters_viewers_per_1000_cap',\n 'museum_visitis_per_100_cap', 'population_reg_sports_share',\n 'students_reg_sports_share', 'apartment_build', 'modern_education_share', 'old_education_build_share', \n              'child_on_acc_pre_school']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a86f2340-595a-7e10-dcb2-cbbe924f61f6"},"outputs":[],"source":"x_train.drop(list_empty, axis=1, inplace=True)\nx_test.drop(list_empty, axis=1, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e05ec983-6bcd-57e4-3cf8-81169b446bf0"},"outputs":[],"source":"for c in x_train.columns:\n    if x_train[c].dtype == 'object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(x_train[c].values)) \n        x_train[c] = lbl.transform(list(x_train[c].values))\n        \nfor c in x_test.columns:\n    if x_test[c].dtype == 'object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(x_test[c].values)) \n        x_test[c] = lbl.transform(list(x_test[c].values))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f6e15636-d089-ba18-cad5-17d345f0258a"},"outputs":[],"source":"def rmsle(preds, dtrain):\n    labels = dtrain.get_label()\n    assert len(preds) == len(labels)\n    labels = labels.tolist()\n    preds = preds.tolist()\n    terms_to_sum = [(math.log(labels[i] + 1) - math.log(max(0, preds[i]) + 1)) ** 2.0 for i, pred in enumerate(labels)]\n    return 'rmsle', (sum(terms_to_sum) * (1.0 / len(preds))) ** 0.5"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"475a1470-bd50-4de3-dedf-ec0746e3dac2"},"outputs":[],"source":"xgb_params = {\n    'eta': 0.05,\n    'max_depth': 8,\n    'subsample': 0.7,\n    'colsample_bytree': 0.7,\n    'objective': 'reg:linear',\n    'silent': 1\n}\n\ny_train = x_train[\"price_doc\"]\nx_train.drop('price_doc', axis=1, inplace=True)\n\n# Train/Valid split\nsplit = 27000\nxx_train, yy_train, xx_valid, yy_valid = x_train[:split], y_train[:split], x_train[split:], y_train[split:]\n\ndtrain = xgb.DMatrix(xx_train, yy_train, feature_names=xx_train.columns.values)\ndvalid = xgb.DMatrix(xx_valid, yy_valid, feature_names=xx_valid.columns.values)\n\nwatchlist = [(dtrain, 'train'), (dvalid, 'valid')]\nmodel = xgb.train(dict(xgb_params), dtrain, 600, watchlist, feval=rmsle, early_stopping_rounds=100)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"53cbdf83-6817-68de-86fd-9744fc3bdb9b"},"outputs":[],"source":"featureImportance = model.get_fscore()\nfeatures = pd.DataFrame()\nfeatures['features'] = featureImportance.keys()\nfeatures['importance'] = featureImportance.values()\nfeatures.sort_values(by=['importance'],ascending=False,inplace=True)\nfig,ax= plt.subplots()\nfig.set_size_inches(20,25)\nplt.xticks(rotation=60)\nsns.set(font_scale=1.5)\nsns.barplot(data=features.head(50),y=\"features\",x=\"importance\",ax=ax,orient=\"h\")\n#b.set_ylabel(\"features\",fontsize=20)\n#sns.plt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b9659d99-f4ab-24b7-823c-4b3b9d7b124c"},"outputs":[],"source":"p_test = model.predict(xgb.DMatrix(x_test))\n\nsub = pd.DataFrame()\nsub['id'] = dftest['id'].values\nsub['price_doc'] = p_test\nsub.to_csv('xgb.csv', index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cab97d6c-18bd-4bd4-dc22-fa95db41c615"},"outputs":[],"source":"sub"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e2570daf-cc29-0a75-47a0-97739a745928"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}