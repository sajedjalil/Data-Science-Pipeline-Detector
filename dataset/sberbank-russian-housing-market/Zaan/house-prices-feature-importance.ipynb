{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"3fc29d38-ee48-fee4-73a7-4b7b59a907ab"},"source":"Trying to identify the top features to utilize in the model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"59a554a6-70f9-80d6-f6b3-ba42bcfaa3fb"},"outputs":[],"source":"import pandas as pd\nimport sklearn.preprocessing as pre\nimport xgboost as xgb\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8165076e-a8fa-8332-9641-e2a17fc15448"},"outputs":[],"source":"#Read data into the training set\ntrain_data = pd.read_csv(\"../input/train.csv\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1a17aae0-fead-8417-899b-7c1e1dd498d1"},"outputs":[],"source":"#Trying to identify NaN values in the variables\ntotal = train_data.isnull().sum().sort_values(ascending = False)\npercent = (train_data.isnull().sum()/train_data.isnull().count()).sort_values(ascending = False)\nmissing_data = pd.concat([total,percent],axis=1,keys = [\"Total\",\"Percentage\"])\nprint(missing_data)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"399f643c-bf52-8967-0975-4e290a6c3dcb"},"outputs":[],"source":"#Delete all NaN values for now\ntrain_data = train_data.drop(missing_data[missing_data[\"Total\"]>0].index,1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"529d74b7-7fb6-e994-6a09-943c8317c1c7"},"outputs":[],"source":"#Identify top features using a basic XGBoost\n# I'd like to thank this from \n#https://www.kaggle.com/sudalairajkumar/sberbank-russian-housing-market/simple-exploration-notebook-sberbank\n#It helped me to understand a simple way to build my feature importance\nfor f in train_data:\n    if train_data[f].dtype == \"object\":\n        lbl=pre.LabelEncoder()\n        lbl.fit(list(train_data[f].values))\n        train_data[f]=lbl.transform(list(train_data[f].values))\n\nxgb_params = {\n    'eta': 0.05,\n    'max_depth': 8,\n    'subsample': 0.7,\n    'colsample_bytree': 0.7,\n    'objective': 'reg:linear',\n    'eval_metric': 'rmse',\n    'silent': 1\n}\n\ny_train = train_data[\"price_doc\"]\nx_train = train_data.drop([\"id\",\"timestamp\",\"price_doc\"],axis = 1)\ndtrain = xgb.DMatrix(x_train,y_train,feature_names = x_train.columns.values)\nmodel = xgb.train(dict(xgb_params,silent=0),dtrain,num_boost_round=100)\n\nfig,ax=plt.subplots(figsize = (12,18))\nxgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\nplt.show"},{"cell_type":"markdown","metadata":{"_cell_guid":"eb95448d-5f64-3648-46d6-dbd3f12beefd"},"source":"The top 10 variables impacting the target are as follows:\n\n 1. full_sq(2023)\n 2. metro_min_avto(344)\n 3. sub_area(332)\n 4. kindergarten_km(294)\n 5. green_zone_km(224)\n 6. school_km(221)\n 7. metro_km_avto(213)\n 8. park_km(206)\n 9. industrial_km(197)\n 10. area_m(195)\n\nOut of these, area_m seems similar to full_sq and metro_min_avto seems similar to metro_km_avto. So I am removing these from my analysis."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bb1c15ce-a996-3907-8595-5e1640f3cf6f"},"outputs":[],"source":"#Change the Price values to log functions\ncols = [\"price_doc\",\"full_sq\",\"metro_min_avto\",\"sub_area\",\"kindergarten_km\",\"green_zone_km\",\"school_km\",\"park_km\",\"industrial_km\"]\ntrain_data[\"price_doc\"]= np.log(train_data[\"price_doc\"])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a768970e-28dd-57ef-eb4b-dc1a9eae2e5d"},"outputs":[],"source":"#Check the plots with each of the variables\ncorrmat = train_data.corr()\nsns.pairplot(train_data[cols],size = 2.5)\nplt.show()"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}