{"nbformat":4,"nbformat_minor":0,"metadata":{"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","name":"python","pygments_lexer":"ipython3","file_extension":".py","version":"3.6.1","codemirror_mode":{"name":"ipython","version":3}},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}},"cells":[{"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\nfrom sklearn import model_selection, preprocessing\n\ntry:\n    df_train = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'])\n    df_test = pd.read_csv(\"../input/test.csv\", parse_dates=['timestamp'])\n    df_macro = pd.read_csv(\"../input/macro.csv\", parse_dates=['timestamp'])\n    print (\"Training Data Loaded with {} samples and {} features\".format(*df_train.shape)) \n    print (\"Testing Data Loaded with {} samples and {} features\".format(*df_test.shape)) \n    print (\"Macro Data Loaded with {} samples and {} features\".format(*df_macro.shape))\nexcept:\n    print (\"Oh snap!\")","execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"3bd438d9-e513-48d9-ab20-a8ea90201657","_uuid":"17ed3d760e85f27039a905b731971b840be23700"}},{"source":"# Round 1) Running raw data through XGB to generate baseline score\n### Score: 0.32305","execution_count":null,"outputs":[],"cell_type":"markdown","metadata":{"collapsed":false,"_execution_state":"idle","_cell_guid":"20fe4cc4-c163-495b-9637-3161126fa459","_uuid":"ec7a5943099e1f8a7d0fecceaf3252596366cf74"}},{"source":"# Deal with categorical features\nfor f in df_train.columns:\n    if df_train[f].dtype=='object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(df_train[f].values)) \n        df_train[f] = lbl.transform(list(df_train[f].values))       \n        \n# Set data as DMatrix\ntrain_y = df_train.price_doc.values\ntrain_X = df_train.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1)\n\nXGB_Train = xgb.DMatrix(train_X,label=train_y,feature_names=train_X.columns.values)\n\n# Set parameters\nxgb_params = {\n    'eta': 0.05,\n    'max_depth': 5,\n    'subsample': 1.0,\n    'colsample_bytree': 0.7,\n    'objective': 'reg:linear',\n    'eval_metric': 'rmse',\n    'silent': 1\n}\n\n# Create model\nmodel = xgb.train(xgb_params, XGB_Train, num_boost_round=100)\n\n# plot the important features #\nfig, ax = plt.subplots(figsize=(12,18))\nxgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\nplt.show()","execution_count":null,"outputs":[],"cell_type":"code","metadata":{"_execution_state":"idle","trusted":false,"_cell_guid":"493814f2-556d-4076-b1a6-adab035809d1","_uuid":"d384047119ff537329f3e34d692193db962aa70c"}},{"source":"# Deal with categorical features in test data\nfor f in df_test.columns:\n    if df_test[f].dtype=='object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(df_test[f].values)) \n        df_test[f] = lbl.transform(list(df_test[f].values))  \n\n# Run raw test data through model to generate baseline predictions\ntest = df_test.drop([\"id\", \"timestamp\"], axis=1)\nXGB_Test = xgb.DMatrix(test)\n\n# Generate baseline predictions\nypred = model.predict(XGB_Test)\n\n# Merge predictions with ID's to create submission\nidCol = df_test[\"id\"].values\nif len(ypred) == len(idCol):\n    sub = np.column_stack((idCol,ypred))\n    df_sub = pd.DataFrame(data=sub,columns=[\"id\",\"price_doc\"])\n    df_sub = df_sub.astype(int)\n    print(\"Final output:\")\n    print(df_sub.head())\nelse:\n    print(\"Oh snap!\")\n\n# Generating first submission and submitting for baseline score\ndf_sub.to_csv('submission1.csv', index=False)\n\n# Score = 0.32305","execution_count":null,"outputs":[],"cell_type":"code","metadata":{"collapsed":false,"_execution_state":"idle","trusted":false,"_cell_guid":"b73b4315-aad6-4785-bc6e-5cf48e261365","_uuid":"9999f958c800d333970b42c8854ed4fa28f35eed"}},{"source":"# Round 2) Joining macro data and doing some basic engineering\n### Score: 0.34993","execution_count":null,"outputs":[],"cell_type":"markdown","metadata":{"collapsed":false,"_execution_state":"idle","_cell_guid":"0c1162a4-b4df-4467-913c-54ec117c81ee","_uuid":"3c4fb10ad4b9ba37949575aae4b5603a4f45f1d0"}},{"source":"# Deal with categorical features in macro data\nfor f in df_macro.columns:\n    if df_macro[f].dtype=='object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(df_macro[f].values)) \n        df_macro[f] = lbl.transform(list(df_macro[f].values)) \n\n# Joining macro data and combining test/train into single dataframe\nnum_train = len(df_train)\ntrain_labels = df_train[['id','price_doc']]\ndf_trainingFeatures = df_train.drop(['price_doc'], axis=1)\ndf_all = pd.concat([df_trainingFeatures, df_test])\n\ndf_all = pd.merge_ordered(df_all, df_macro, on='timestamp', how='left')","execution_count":null,"outputs":[],"cell_type":"code","metadata":{"collapsed":false,"_execution_state":"idle","trusted":false,"_cell_guid":"f157c756-a48e-49da-ab6c-c1c7241b3ebc","_uuid":"26e96de0f65d1999cdc16ac87ae864b5c93a34aa"}},{"source":"# Deal with categorical features in macro data\nfor f in df_macro.columns:\n    if df_macro[f].dtype=='object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(df_macro[f].values)) \n        df_macro[f] = lbl.transform(list(df_macro[f].values)) \n\n# Joining macro data and combining test/train into single dataframe\nnum_train = len(df_train)\ntrain_labels = df_train[['id','price_doc']]\ndf_trainingFeatures = df_train.drop(['price_doc'], axis=1)\ndf_all = pd.concat([df_trainingFeatures, df_test])\n\ndf_all = pd.merge_ordered(df_all, df_macro, on='timestamp', how='left')\n\n# ------\n# Feature engineering the timestamp a bit\n\n# Add month-year\nmonth_year = (df_all.timestamp.dt.month + df_all.timestamp.dt.year * 100)\nmonth_year_cnt_map = month_year.value_counts().to_dict()\ndf_all['month_year_cnt'] = month_year.map(month_year_cnt_map)\n\n# Add week-year count\nweek_year = (df_all.timestamp.dt.weekofyear + df_all.timestamp.dt.year * 100)\nweek_year_cnt_map = week_year.value_counts().to_dict()\ndf_all['week_year_cnt'] = week_year.map(week_year_cnt_map)\n\n# Add month and day-of-week\ndf_all['month'] = df_all.timestamp.dt.month\ndf_all['dow'] = df_all.timestamp.dt.dayofweek\n\n# Splitting back in to test & training sets\ndf_train = df_all[:num_train]\ndf_test = df_all[num_train:]\n\n# Adding price_doc back to training set to remove outliers\ndf_train = pd.merge_ordered(df_train, train_labels, on='id', how='left')\n\nstartingRows = df_train.shape[0]\nstartingColumns = df_train.shape[1]\n\n# removing outlier rows from training set\ntop = df_train[\"price_doc\"].quantile(0.97)\nbottom = df_train[\"price_doc\"].quantile(0.03)\ndf_train = df_train[df_train[\"price_doc\"] < top]\ndf_train = df_train[df_train[\"price_doc\"] > bottom]\n\n# ------\n# Creating new model\n\n# Set data as DMatrix\ntrain_y = df_train.price_doc.values\ntrain_X = df_train.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1)\n\nXGB_Train = xgb.DMatrix(train_X,label=train_y,feature_names=train_X.columns.values)\n\n# Set parameters\nxgb_params = {\n    'eta': 0.05,\n    'max_depth': 5,\n    'subsample': 1.0,\n    'colsample_bytree': 0.7,\n    'objective': 'reg:linear',\n    'eval_metric': 'rmse',\n    'silent': 1\n}\n\n# Create model\nmodel = xgb.train(xgb_params, XGB_Train, num_boost_round=100)\n\n# plot the important features #\nfig, ax = plt.subplots(figsize=(12,18))\nxgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\nplt.show()\n","execution_count":null,"outputs":[],"cell_type":"code","metadata":{"collapsed":false,"_execution_state":"idle","trusted":false,"_cell_guid":"8626877a-90a4-404a-b848-b093d9931e8a","_uuid":"f66ed2658353fde737657fdd43a1d5c7f795f87f"}},{"source":"# Run test data through model to generate a second round of predictions\ntest = df_test.drop([\"id\", \"timestamp\"], axis=1)\nXGB_Test = xgb.DMatrix(test)\n\n# Generate baseline predictions\nypred = model.predict(XGB_Test)\n\n# Merge predictions with ID's to create submission\nidCol = df_test[\"id\"].values\nif len(ypred) == len(idCol):\n    sub = np.column_stack((idCol,ypred))\n    df_sub = pd.DataFrame(data=sub,columns=[\"id\",\"price_doc\"])\n    df_sub = df_sub.astype(int)\n    print(\"Final output:\")\n    print(df_sub.head())\nelse:\n    print(\"Oh snap!\")\n\n# Generating second submission and submitting for score\ndf_sub.to_csv('submission2.csv', index=False)\n\n# Score = 0.34993\n# This is actually worse... Probably need to clean up the data a bit.","execution_count":null,"outputs":[],"cell_type":"code","metadata":{"collapsed":false,"_execution_state":"idle","trusted":false,"_cell_guid":"e7ec8c5f-ca87-40a4-9189-8de984d93055","_uuid":"7a8fc14c7bee93f04815f2567a5a3e002349ae5b"}}]}