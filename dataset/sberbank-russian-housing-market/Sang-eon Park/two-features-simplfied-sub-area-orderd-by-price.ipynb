{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"8eb57189-afea-64fe-cab1-c68d6b74e9aa"},"source":"Two new divided features Simplified and Sub Area Ordered by Price!\nThe Result was more stable than raw feature set."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e77eb50a-5e90-66a1-b7e6-1905fcf5a966"},"outputs":[],"source":"The difference between train-rmse and eval-rmse was not big. It maybe avoid overfitting. But, of course, I\nJust used small variables, the value was not big.\n\n1.  cols = ['full_sq', 'life_sq','tan_sq_0.2',  'floor', 'max_floor', 'floor_label_0.1', 'sub_area_sample'] \ntrain-rmse:0.452406\teval-rmse:0.509475 \n\n2. cols = ['full_sq', 'life_sq','tan_sq_0.2', 'floor', 'max_floor', 'floor_label_0.1', 'sub_area']\ntrain-rmse:0.391513\teval-rmse:0.481048\n\n3. cols = ['full_sq', 'life_sq','tan_sq', 'floor', 'max_floor', 'floor_label_0.1', 'sub_area']\ntrain-rmse:0.379885\teval-rmse:0.481801\n\n4. cols = ['full_sq', 'life_sq','tan_sq', 'floor', 'max_floor', 'tan_floor', 'sub_area']\ntrain-rmse:0.386476\teval-rmse:0.482583\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f0f0f78d-19e1-8a10-ec2e-7a61030da878"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7cd73725-1a7f-e418-f0cc-42e41e121441"},"outputs":[],"source":"house_train = pd.read_csv('../input/train.csv', parse_dates = ['timestamp'])\nhouse_test = pd.read_csv('../input/test.csv', parse_dates = ['timestamp'])\nnum = house_train.shape[0]\ntarget = np.log1p(house_train.price_doc)\n\nhouse_train.drop(['id', 'price_doc'], axis =1, inplace = True)\nhouse_test.drop(['id'], axis = 1, inplace = True)\n\nx_full = pd.concat([house_train, house_test], axis = 0)\nx_full.index = list(range(x_full.shape[0]))\n\ncat_var = x_full.select_dtypes(include = ['object']).columns.tolist()\nnum_var = x_full.select_dtypes(exclude = ['object']).columns.tolist()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"adde8a2b-613b-e196-ceed-464cd3bba14b"},"outputs":[],"source":"for var in cat_var:\n    x_full[var] = pd.factorize(x_full[var])[0]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2ecd45b3-e3f0-f23b-2118-77fe72b29c58"},"outputs":[],"source":"\"\"\"\nfor num_col in num_var:\n    unique_num = x_full[num_col].nunique()\n    if unique_num > 200:\n        print('Col: {}, Number : {}'.format(num_col, unique_num))\n\"\"\""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"16f7df4f-1505-e84e-6198-ca6a5d5b26d8"},"outputs":[],"source":"def divide_function_label(full = None, col_list = None, new_col = None, unit_list = None):\n    #Make relatvie features and separted into intervals\n    full[new_col] = x_full[col_list[0]] / x_full[col_list[1]]\n    new_col_list = []\n    for unit in unit_list:\n        new_col_unit = new_col + '_' + str(unit)\n        full[new_col_unit], _ = divmod(x_full[new_col], unit)\n        new_col_list.append(new_col_unit)\n    \n    return full, new_col_list"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"611a5c6d-976d-ea1b-443c-ae94d222f357"},"outputs":[],"source":"x_full, new_col_tan = divide_function_label(full = x_full, col_list = ['life_sq', 'full_sq'], new_col = 'tan_sq', unit_list = [0.2])\nx_full, new_col_rel = divide_function_label(full = x_full, col_list = ['kitch_sq', 'full_sq'], new_col = 'rel_kitch', unit_list = [0.05])\n\nx_full.max_floor.fillna(1, inplace = True)\nx_full.max_floor[x_full.max_floor == 0] = 1\nx_full.floor.fillna(-1, inplace = True)\nx_full['tan_floor'] = x_full.floor / x_full.max_floor\nno_max = (x_full.tan_floor > 1)\nno_floor = (x_full.tan_floor < 0)\nx_full['floor_label_0.1'],_ = divmod(x_full.tan_floor, 0.1)\nx_full['floor_label_0.1'][no_max] = 11\nx_full['floor_label_0.1'][no_floor] = -1"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8c47df96-9211-d960-6b13-1be59fd61306"},"outputs":[],"source":"def rank_function_part2(train = None, col = None, target = None, rank_unit = None):\n    #Make feature sorted by values with dic\n    col_df = train[col].copy()\n    col_val = pd.concat([col_df, np.expm1(target)], axis = 1)\n\n    col_group = col_val.groupby(col, as_index = False)\n\n    col_mean = col_group.mean().sort_values('price_doc').reset_index()\n    col_mean.drop('index', axis = 1, inplace = True)\n    rank = list(range(col_mean.shape[0]))\n    col_mean['rank'] =  rank\n\n    sam = dict()\n    for itr in rank:\n        key = col_mean[col][itr]\n        value = col_mean['rank'][itr]\n        sam[key] = value\n\n    return sam"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"abe315bd-d52e-ceca-f84f-a36f96ec3331"},"outputs":[],"source":"sam = rank_function_part2(train = house_train, col = 'sub_area', target = target)\nx_full['sub_area_sample'] = x_full.sub_area.map(sam)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ddb93f64-a134-7da4-a04a-2bb63dd6f1a3"},"outputs":[],"source":"house_train = x_full[:num]\nhouse_test =  x_full[num:]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3ffc2f15-44e8-43ec-fa7c-d74d3664cfc4"},"outputs":[],"source":"import xgboost as xgb\ndef learn_xgb(train = None, test = None, target =None):\n    from sklearn.model_selection import train_test_split\n    \n    eta = 0.1\n    max_depth = 10\n    subsample = 0.7\n    colsample_bytree = 0.7\n    random_state = 10\n    params = {\n            \"objectvie\": \"reg:logistic\",\n            \"eval_metric\": \"rmse\",\n            \"eta\": eta,\n            \"max_depth\": max_depth,\n            \"subsample\": subsample,\n            \"colsample_bytree\": colsample_bytree,\n            \"silent\": 1,\n            \"seed\": random_state\n        }\n    num_boost_round = 200\n    early_stopping_rounds = 10\n    test_size = 0.3\n    \n    y_train, y_valid = train_test_split(target, test_size = test_size, random_state = random_state)\n    x_train = train.loc[y_train.index]\n    x_valid = train.loc[y_valid.index]\n    \n    dfull = xgb.DMatrix(train, target)\n    dtrain = xgb.DMatrix(x_train, y_train)\n    dval = xgb.DMatrix(x_valid, y_valid)\n    dtest = xgb.DMatrix(test)\n    watchlist = [(dtrain, 'train'), (dval, 'eval')]\n    \n    gbm = xgb.train(params, dtrain, num_boost_round, evals = watchlist, early_stopping_rounds = early_stopping_rounds, verbose_eval = 30)\n    \n    return gbm"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7196b6c5-3296-80d9-89cb-bfb134a9f630"},"outputs":[],"source":"cols = ['full_sq', 'life_sq','tan_sq_0.2', \n        'floor', 'max_floor', 'floor_label_0.1', 'sub_area_sample']\ntrain = house_train[cols]\ntest = house_test[cols]\ngbm = learn_xgb(train = train, test = test, target = target)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8117a54a-25f3-2a4b-5aa8-7c1ac75ba719"},"outputs":[],"source":"cols = ['full_sq', 'life_sq','tan_sq_0.2',\n        'floor', 'max_floor', 'floor_label_0.1', 'sub_area']\ntrain = house_train[cols]\ntest = house_test[cols]\ngbm = learn_xgb(train = train, test = test, target = target)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ca9c22f8-2a03-293e-2c7e-ce5654e85038"},"outputs":[],"source":"cols = ['full_sq', 'life_sq','tan_sq',\n        'floor', 'max_floor', 'floor_label_0.1', 'sub_area']\ntrain = house_train[cols]\ntest = house_test[cols]\ngbm = learn_xgb(train = train, test = test, target = target)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bcf31c81-b815-d488-bb4a-b4450440247c"},"outputs":[],"source":"cols = ['full_sq', 'life_sq','tan_sq',\n        'floor', 'max_floor', 'tan_floor', 'sub_area']\ntrain = house_train[cols]\ntest = house_test[cols]\ngbm = learn_xgb(train = train, test = test, target = target)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"14e0e81c-3c9d-c60b-a417-6ccb9671c764"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}