{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"f120f3bd-6839-09ce-ff13-86d0cac8ed5d"},"source":"##First we need to import the libraries we are going to use\nHere we need two full libraries:\n**numpy** (linear algebra and mathematics) and **pandas** (data manipulation and i/o)\n\nWe also need some bits from **sklearn** - in particular the RandomForestRegressor and the preprocessing unit.\n\nIt is good practice to only import the bits you need from sklearn as it is quite a memory-intensive library."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"643fb711-439a-08bd-5b89-a0aa108f38d9"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor # import the random forest model\nfrom sklearn import  preprocessing # used for label encoding and imputing NaNs"},{"cell_type":"markdown","metadata":{"_cell_guid":"b68b3e1e-8f6a-fdeb-bf0c-9225290f7881"},"source":"##Next we import the data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3fdfa29c-5223-903c-a080-228793fa561e"},"outputs":[],"source":"train_df = pd.read_csv('../input/train.csv',)\ntest_df = pd.read_csv('../input/test.csv')\nmacro_df = pd.read_csv('../input/macro.csv')"},{"cell_type":"markdown","metadata":{"_cell_guid":"a7388a1f-4422-acb7-5d8e-b8c264131412"},"source":"## We assign our prediction variable and set our training set\nWe also set a column vector containing the id's for our predictions and trim the train and test sets removing the id and timestamp."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6ffd06af-6322-6204-dbc4-19021446b6db"},"outputs":[],"source":"id_test = test_df.id\ny_train = train_df[\"price_doc\"]\nx_train = train_df.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1)\nx_test = test_df.drop([\"id\", \"timestamp\"], axis=1)"},{"cell_type":"markdown","metadata":{"_cell_guid":"3c976d8a-3067-7d7b-b6b0-3ea27458fedd"},"source":"### *The code below can be used to cross-validate the training set. The first piece calculates the cross-validation scores and the second plots them visually based on the number of trees.*"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1b9c0881-992b-f1e6-23ad-5d00c765e9bc"},"outputs":[],"source":"#from sklearn.cross_validation import cross_val_score # We also need the cross validation functionality\n#scores = list()\n#scores_std = list()\n\n#print('Start learning...')\n#n_trees = [10, 50, 75]\n#for n_tree in n_trees:\n#        print(n_tree)\n#        recognizer = RandomForestRegressor(n_tree)\n#        score = cross_val_score(recognizer, x_train, y_train)\n#        scores.append(np.mean(score))\n#        scores_std.append(np.std(score))\n\n#sc_array = np.array(scores)\n#std_array = np.array(scores_std)\n#print('Score: ', sc_array)\n#print('Std  : ', std_array)\n\n\n#plt.plot(n_trees, scores)\n#plt.plot(n_trees, sc_array + std_array, 'b--')\n#plt.plot(n_trees, sc_array - std_array, 'b--')\n#plt.ylabel('CV score')\n#plt.xlabel('# of trees')\n#plt.savefig('cv_trees.png')"},{"cell_type":"markdown","metadata":{"_cell_guid":"ac99119d-9a91-8e14-4f40-f9a2eb6d5d14"},"source":"##Numerical encoding of features\nWe need to assign a numeric value to each of the features in our training and test sets. \nSklearn's preprocessing unit has a tool called LabelEncoder() which can do just that for us. \n\nWe could equally combine train and test here and fit this just once  (Maybe we should?)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9214e935-6c80-b474-f786-6f217748b816"},"outputs":[],"source":"for c in x_train.columns:\n    if x_train[c].dtype == 'object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(x_train[c].values)) \n        x_train[c] = lbl.transform(list(x_train[c].values))\n        \nfor c in x_test.columns:\n    if x_test[c].dtype == 'object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(x_test[c].values)) \n        x_test[c] = lbl.transform(list(x_test[c].values))  "},{"cell_type":"markdown","metadata":{"_cell_guid":"3e0049e1-d287-f74a-c72c-5aff2734cf7a"},"source":"##Addressing problems with NaN in the data\nAs we saw from our EDA there were quite a lot of NaN in the data. Our model won't know what to do with these so we need to replace them with something sensible.\n\nThere are quite a few options we can use - the mean, median, most_frequent, or a numeric value like 0. Playing with these will give different results, for now I have it set to use the mean.\n\n This uses the mean of the column in which the missing value is located. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b2cef487-b99d-5d4d-12e2-2c81c3d9e575"},"outputs":[],"source":"imputer = preprocessing.Imputer(missing_values='NaN', strategy = 'mean', axis = 0)\nx_train = imputer.fit_transform(x_train)\nx_test = imputer.fit_transform(x_test)"},{"cell_type":"markdown","metadata":{"_cell_guid":"7dc9e93f-03e4-9da5-befe-af482fb4517c"},"source":"## The three step process below is common across many sklearn models\n\n**First** we set an object variable \"Model\" equal to the model we want to fit. In this case we are dealing with a regression problem and want to fit a Random Forest model so we choose RandomForestRegressor\n\nThe parameter labelled 3 below indicates the number of trees we would like in our forest. The default is 10 - I have chosen 3 here for speed. \n\nThe **second** step in the process is to train the model. We do this with our x and y training data. Remember that the y_train set is just the prediction we would like to make - in this instance the price price_doc. The x_train data is the information we are going to use to make that prediction. \n\n**Thirdly** once we have fit the model we can then use it to make a prediction. We do this by called Model.Predict. We are looking to predict the house prices for our test data so we pass the test-data to the predict method and assign it to y_predict. This will contain our predicted set of house prices. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a6f7f557-f4b2-87d4-80fa-a015d470f993"},"outputs":[],"source":"Model = RandomForestRegressor(3)\nModel.fit(x_train, y_train)\ny_predict = Model.predict(x_test)"},{"cell_type":"markdown","metadata":{"_cell_guid":"0b58a792-9780-68af-6ec5-7f8cd92483d7"},"source":"##Output the data to CSV for submission\nFinally we take the id_test vector we created earlier and combine it with our y_predictions to create our CSV for output. \n\nWe are utilising the very useful panda's data frame to do this and it's associated method \"to_csv\" can write our file out."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fd911a21-3a25-cf2c-a717-de24ae404462"},"outputs":[],"source":"output = pd.DataFrame({'id': id_test, 'price_doc': y_predict})\n\noutput.to_csv('RandomForest.csv', index=False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}