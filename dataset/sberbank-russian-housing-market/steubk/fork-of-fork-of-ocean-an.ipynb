{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1e899269-6ac1-77cf-849a-b73124ba9972"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn import model_selection, preprocessing\nimport xgboost as xgb\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\nid_test = test.id\n\ny_train = train[\"price_doc\"] * .969 + 10\nx_train = train.drop([\"id\", \"timestamp\",\"price_doc\"], axis=1)\n\nx_test = test.drop([\"id\", \"timestamp\"], axis=1)\nx_all = pd.concat([x_train,x_test])\n\n\n########### clean data\nx_all['build_year'] = x_all['build_year'].map(lambda x: x if x < 2018 else np.nan )\nx_all['build_year'] = x_all['build_year'].map(lambda x: x if x > 1800 else np.nan )\n\nx_all['kitch_sq'] = x_all['kitch_sq'].map(lambda x: x if x < 1000 else np.nan )\nx_all['full_sq'] = x_all['full_sq'].map(lambda x: x if x > 9 else np.nan)\nx_all['life_sq'] = x_all['life_sq'].map(lambda x: x if x > 0 else np.nan)\n\n#adding some nan\ndef kitch_1 (full_sq, life_sq, kitch_sq):\n    if (kitch_sq == full_sq) or (kitch_sq>500):\n        return np.nan\n    elif (kitch_sq < 3.0):\n        return np.nan\n    else:\n        return kitch_sq\n\ndef life_1 (full_sq, life_sq, kitch_sq):\n    if (life_sq >full_sq) :\n        return full_sq\n    elif (life_sq<10.0):\n        return np.nan\n    else:\n        return life_sq\n\ndef max_floor_1 (floor, max_floor):\n    if (floor >max_floor) :\n        return np.nan\n    else:\n        return max_floor\n\ndef full_sq_1 (full_sq, life_sq, kitch_sq):\n    if (full_sq >1000) :\n        return full_sq/100\n    elif (full_sq >300) and full_sq/life_sq > 10:\n        return full_sq/10\n    else:\n        return full_sq\n\n    \nx_all['kitch_sq'] = x_all.apply(lambda row: kitch_1( row.full_sq, row.life_sq, row.kitch_sq ), axis=1 )\nx_all['life_sq'] = x_all.apply(lambda row: life_1( row.full_sq, row.life_sq, row.kitch_sq ), axis=1 )\nx_all['max_floor'] = x_all.apply(lambda row: max_floor_1( row.floor, row.max_floor ), axis=1 )\nx_all['full_sq'] = x_all.apply(lambda row: full_sq_1( row.full_sq, row.life_sq, row.kitch_sq ), axis=1 )\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c67e5a7a-7561-c5a7-06b0-2a641728c9dc"},"outputs":[],"source":"for c in x_all.columns:\n    if x_all[c].dtype == 'object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(x_all[c].values)) \n        x_all[c] = lbl.transform(list(x_all[c].values))\n\nnum_train = len(y_train)\nx_train = x_all[:num_train]\nprint('x_train:', x_train.shape)\nx_test = x_all[num_train:]\nprint('x_test:', x_test.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"03e52296-e86f-0f17-2a50-c18e5c669251"},"outputs":[],"source":"xgb_params = {\n    'eta': 0.05,\n    'max_depth': 5,\n    'subsample': 0.7,\n    'colsample_bytree': 0.7,\n    'objective': 'reg:linear',\n    'eval_metric': 'rmse',\n    'silent': 1\n}\n\n\ndtrain = xgb.DMatrix(x_train, y_train)\ndtest = xgb.DMatrix(x_test)\n\ncv_output = xgb.cv(xgb_params, dtrain, num_boost_round=1000, early_stopping_rounds=20,\n    verbose_eval=50, show_stdv=False)\n\nnum_boost_rounds = len(cv_output)\nprint('num_boost_rounds:',num_boost_rounds)\nmodel = xgb.train(dict(xgb_params, silent=1), dtrain, num_boost_round= num_boost_rounds)\n\n\ny_predict = model.predict(dtest)\noutput = pd.DataFrame({'id': id_test, 'price_doc': y_predict})\n\noutput.to_csv('xgbSub.csv', index=False)\nprint('done!' )"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aaee4d87-5091-4872-0782-4337874c5e14"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}