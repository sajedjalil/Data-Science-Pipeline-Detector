{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1b041ef9-0e89-fd10-0e56-60f2860ca523"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom numpy.polynomial.chebyshev import *\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\npd.options.mode.chained_assignment = None  \npd.set_option('display.max_columns', 500)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"markdown","metadata":{"_cell_guid":"891afb69-180f-44f9-d76c-cb2e2964deb5"},"source":"##Initialize Data"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"771672a2-154c-c359-e027-364dfdf2b0e6"},"outputs":[],"source":"read_columns= ['timestamp', 'oil_urals', 'gdp_quart_growth', 'cpi', 'usdrub', \\\n                'salary_growth', 'unemployment', 'average_provision_of_build_contract_moscow', 'mortgage_rate', \\\n                 'deposits_rate','deposits_growth','rent_price_3room_eco',\\\n                 'rent_price_3room_bus']\ntrain_df = pd.read_csv(\"../input/train.csv\",usecols=['timestamp','price_doc','full_sq'])\nmacro_df = pd.read_csv(\"../input/macro.csv\",usecols=read_columns)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d2c33a6c-5e76-c288-4822-8cbdd2df28e6"},"outputs":[],"source":"# Service Read routines\ndef condition_train(value, col):\n    vals = (macro_df[macro_df['mo_ye'] == value])\n    \n    ret = vals[col].asobject\n  \n    ret = ret[0]\n\n    return ret\n\ndef condition_test(value, col):\n    vals = (macro[macro['mo_ye'] == value])\n\n    ret = vals[col].asobject\n\n    ret = ret[0]\n\n    return ret\n\ndef condition(value,col):\n    vals = (macro_df[macro_df['timestamp'] == value])\n    ret=vals[col].asobject\n    ret=ret[0]\n\n    return ret\n\ndef init_anlz_file():\n\n    anlz_df = train_df\n    for clmn in read_columns:\n        if clmn == 'timestamp':\n            continue\n        anlz_df[clmn] = np.nan\n        anlz_df[clmn] = anlz_df['timestamp'].apply(condition, col=clmn)\n        print(clmn)\n    return anlz_df\n\n### Read Data for macro analysis\nanlz_df=init_anlz_file()"},{"cell_type":"markdown","metadata":{"_cell_guid":"407ba27d-01c7-b986-ffb4-0163fcb2ed3f"},"source":"##Start Analysis"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ffb6971d-c0f8-5f57-3001-8b66cc88907d"},"outputs":[],"source":"methods=['pearson', 'kendall', 'spearman']\n\ndef plot_grouped_trends(df,feat1,feat2,corr_df):\n   \n    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n    x=df.index.values\n    ch=chebfit(x,df[feat1].values,7)\n    trendf1=chebval(x,ch)\n    ax[0].plot(x,df[feat1].values,x,trendf1)\n    ax[0].set_ylabel(feat1)\n    ax[0].set_title('Chart '+feat1+' vs trend' )\n    ax[0].set_xlabel('months count')\n    ch2=chebfit(x,df[feat2].values,7)\n    trendf2=chebval(x,ch2)\n    ax[1].plot(x,df[feat2].values,x,trendf2)\n    ax[1].set_ylabel(feat2)\n    ax[1].set_title('Chart '+feat2+' vs trend' )\n    ax[1].set_xlabel('months count')\n    # do here two charts density distribition\n    \n    ls=[feat2]\n    for method in methods:\n        corr=df[[feat1,feat2]].corr(method=method)\n        ls.append(corr[feat1][1])\n    corr_df.loc[len(corr_df)]=ls"},{"cell_type":"markdown","metadata":{"_cell_guid":"b8152ae4-1979-c2d1-93df-7fb8ca87eec5"},"source":"##Macro-economic factors influence on House pricing in Moscow"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e9927810-64e9-6f08-78e2-26f5fe3f14a1"},"outputs":[],"source":"anlz_df['timestamp']=pd.to_datetime(anlz_df['timestamp'])\nanlz_df['mo_ye']=anlz_df['timestamp'].apply(lambda x: x.strftime('%m-%Y'))\nanlz_df['price_per_sqm']=anlz_df['price_doc']/anlz_df['full_sq']\n\n\nmacro_columns = ['price_doc','price_per_sqm','full_sq','oil_urals', 'gdp_quart_growth', 'cpi', 'usdrub', \\\n                'salary_growth', 'unemployment', 'average_provision_of_build_contract_moscow', 'mortgage_rate', \\\n                 'deposits_rate','deposits_growth','rent_price_3room_eco',\\\n                 'rent_price_3room_bus']\nmacro_df=pd.DataFrame(anlz_df.groupby('mo_ye')[macro_columns].mean())\nmacro_df.reset_index(inplace=True)\n\n\nmacro_df['mo_ye']=pd.to_datetime(macro_df['mo_ye'])\nmacro_df=macro_df.sort_values(by='mo_ye')\n\n\nmacro_df.reset_index(inplace=True)\nmacro_df.drop(['index'],axis=1,inplace=True)"},{"cell_type":"markdown","metadata":{"_cell_guid":"45915c08-85e1-1c3c-c882-8ad69664bb8b"},"source":"###Show influence of economical factors on housing prices"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cfb8cad5-d2be-d898-b130-01c1d094bd14"},"outputs":[],"source":"corr_df=pd.DataFrame(columns=['feature','pearson', 'kendall', 'spearman'])\ncorr=macro_df[macro_columns].corr(method='spearman')\nfig, ax = plt.subplots(figsize=(10,10))         # Sample figsize in inches\nsns.heatmap(corr, annot=True, linewidths=.5, ax=ax)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dbfe30c2-4e77-90b0-c936-d776cb1536f1"},"outputs":[],"source":"for feat in macro_columns:\n    if (feat=='price_doc'):\n        continue\n    plot_grouped_trends(macro_df,'price_doc',feat,corr_df)"},{"cell_type":"markdown","metadata":{"_cell_guid":"9e23c20a-e119-64bc-5c50-16fdad0e483c"},"source":"##Correlation Table of price_doc t by methods :'pearson', 'kendall', 'spearman'"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f70b8812-30ee-0919-d673-81fadce66c6d"},"outputs":[],"source":"print(corr_df)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"98853e52-14cb-cd51-58d2-db060b285115"},"outputs":[],"source":"### Choose significant macroeconomical features by their correlation\nsig_macro_columns=['oil_urals', 'gdp_quart_growth', 'cpi', 'usdrub', \\\n                'salary_growth', 'unemployment', 'mortgage_rate', \\\n                 'deposits_rate','rent_price_3room_bus']"},{"cell_type":"markdown","metadata":{"_cell_guid":"4cf4ee0a-49a0-6833-b84f-c0e70847eff8"},"source":"#Part II-Data Engineenring"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"eb702804-757d-e81b-dff0-7c5ccd2b3d1f"},"outputs":[],"source":"\n# insert in the train data and test the significant macroeconomical features by month-year data\n\n\ntrain = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'])\ntrain['mo_ye']=train['timestamp'].apply(lambda x: x.strftime('%m-%Y'))\n#macro_df['mo_ye']=macro_df['mo_ye'].apply(lambda x: x.strftime('%m-%Y'))\ntest_df = pd.read_csv(\"../input/test.csv\",parse_dates=['timestamp'])\ntest_df['mo_ye']=test_df['timestamp'].apply(lambda x: x.strftime('%m-%Y'))\nmacro=pd.read_csv(\"../input/macro.csv\", parse_dates=['timestamp'])\nmacro['mo_ye'] = macro['timestamp'].apply(lambda x: x.strftime('%m-%Y'))\n\nfor clmn in sig_macro_columns:\n    train[clmn] = train['mo_ye'].apply(condition_train, col=clmn)\n    test_df[clmn] = test_df['mo_ye'].apply(condition_test, col=clmn)\n  \ntrain=train.drop(['timestamp'],1) \n\n  \n                       "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8286c012-7126-93b5-cc19-4e5dadd61415"},"outputs":[],"source":"#free memory\ndel(train_df)\ndel(macro_df)\ndel(anlz_df)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"149b903a-b484-b96e-6464-553cec00e79b"},"outputs":[],"source":"## Initial clean train data\nfrom sklearn import model_selection, preprocessing\n\nx_train = train\n\n\n##  Encode categirical varaibles exclude 'mo_ye'\nfor c in x_train.columns:\n    if c=='mo_ye':\n        continue\n    if x_train[c].dtype == 'object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(x_train[c].values))\n        x_train[c] = lbl.transform(list(train[c].values))\nx_train['mo_ye']=x_train['mo_ye'].apply(lambda x:  100*pd.to_datetime(x).year+pd.to_datetime(x).month)\nx_train['price_doc']=np.log1p(x_train['price_doc'])"},{"cell_type":"markdown","metadata":{"_cell_guid":"0e5cd72b-3f1a-f35d-0840-79c9e06c2eb2"},"source":"## Dealing with missed variables"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"519605cb-bbec-d287-9160-f91c2be47e11"},"outputs":[],"source":"from sklearn.base import TransformerMixin\nclass DataFrameImputer(TransformerMixin):\n    def fit(self, X, y=None):\n        self.fill = pd.Series([X[c].value_counts().index[0]\n        if X[c].dtype == np.dtype('O') else X[c].median() for c in X],\n        index=X.columns)\n        return self\n    def transform(self, X, y=None):\n        return X.fillna(self.fill)\nx_train = DataFrameImputer().fit_transform(x_train)"},{"cell_type":"markdown","metadata":{"_cell_guid":"a9ad8b67-781e-defe-8b8c-bf5593d66db8"},"source":"##Starting importance variables evaluation"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3b0d962a-6b81-117c-da52-8d442ed1cca8"},"outputs":[],"source":"import operator\nimport xgboost as xgb\ntarget = 'price_doc'\nIDcol = 'id'\n\npredictors = [x for x in x_train.columns if x not in [target, IDcol]]\nxgb_params = {\n    'eta': 0.05,\n    'max_depth': 8,\n    'subsample': 0.7,\n    'colsample_bytree': 0.7,\n    'objective': 'reg:linear',\n    'eval_metric': 'rmse',\n    'silent': 1\n}\ntrain_matrix= xgb.DMatrix(x_train[predictors], x_train[target].values, feature_names=x_train[predictors].columns.values)\nmodel = xgb.train(dict(xgb_params, silent=1), train_matrix, num_boost_round=100)\n# plot the important features #\nimportance = model.get_fscore()\nimportance = sorted(importance.items(), key=operator.itemgetter(1))\ndf = pd.DataFrame(importance, columns=['feature', 'fscore'])\ndf['fscore'] =100* df['fscore'] / df['fscore'].max()\ndf=df.sort_values(by=\"fscore\",ascending=False)\ndf.head(50).plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(10, 10))\n\nplt.title('XGBoost Feature Importance( 50 significant)')\n\n#plt.annotate()\nplt.xlabel('relative importance')\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"ccc7ec1c-0ae9-f2c5-1a35-4c64ea38b59e"},"source":"## Check model accuracy according to best parameters"},{"cell_type":"markdown","metadata":{"_cell_guid":"d1321f82-816a-5e34-b899-506ec08c392e"},"source":"Best parameters are searched by GridSearchCV on my Laptop"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"311bb2ba-586c-99c2-7dff-197595b8a860"},"outputs":[],"source":"from sklearn.model_selection import train_test_split\nparams = {\n\n          'n_estimators': 200,\n          'max_depth': 5,\n          'min_child_weight': 100,\n          'subsample': .9,\n          'gamma': 1,\n          'objective': 'reg:linear',\n          'colsample_bytree': .8,\n\n          'nthread':3,\n          'silent':1,\n          'seed':27\n         }\n\ntrain, test = train_test_split(x_train, test_size = 0.2)\npredictors=df['feature'][df['fscore']>0.5].tolist() ## take predictors which score values more as 1%"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d0c88390-f690-8434-0657-af347ed0674b"},"outputs":[],"source":"dtrain = xgb.DMatrix(train[predictors].values,train[target].values)\ndtest = xgb.DMatrix(test[predictors].values,test[target].values)\nalg=xgb.XGBClassifier(**params)\nxgb_param = alg.get_xgb_params()\ncvresult = xgb.cv(xgb_param, dtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=5,  \n                          metrics='rmse', early_stopping_rounds=50, verbose_eval=50)\n\ncvresult[['train-rmse-mean', 'test-rmse-mean']].plot()"},{"cell_type":"markdown","metadata":{"_cell_guid":"b7fc9897-4122-b8c1-89e7-788295100333"},"source":"#Set Model for prediction"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7b2aa9bd-ffed-9687-67e9-e7067cc14158"},"outputs":[],"source":"from sklearn.metrics import  mean_squared_error\nwatchlist=[(dtrain,'train')]\nnum_round=600\n\n#bst = xgb.train(params, dtrain, num_round,verbose_eval=False)\nbst=xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_round)\npreds = bst.predict(dtest)\n\nerr=(mean_squared_error(test[target].values, preds))\nprint('MSE ={}'.format(err)) # No bad"},{"cell_type":"markdown","metadata":{"_cell_guid":"d7f4a6aa-278b-a1d7-fc25-7078d1aad0af"},"source":"#Part III Data Prediction"},{"cell_type":"markdown","metadata":{"_cell_guid":"6c2a49ec-f9a7-a268-8e08-c3b39383442c"},"source":"### Test data preparation"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f35242ff-156f-21f1-7cf6-c8c1595b128c"},"outputs":[],"source":"\n##  Encode categirical varaibles exclude 'mo_ye'\nfor c in test_df.columns:\n    if c=='mo_ye':\n        continue\n    if test_df[c].dtype == 'object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(test_df[c].values))\n        test_df[c] = lbl.transform(list(test_df[c].values))\ntest_df['mo_ye']=test_df['mo_ye'].apply(lambda x:  100*pd.to_datetime(x).year+pd.to_datetime(x).month)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2e7e7a62-d1bb-6118-96c6-c077c9fd2cb8"},"outputs":[],"source":"#dealing with missed varaibles\ntest_df=test_df.drop(['timestamp'],1) \nIdClm=test_df['id']\n#test_df = DataFrameImputer().fit_transform(test_df)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0f2f4ed1-b428-75af-f095-2cdee63bd1e5"},"outputs":[],"source":"test_df = DataFrameImputer().fit_transform(test_df)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4760ce6d-5440-78e0-c0da-d1ffa4d7c878"},"outputs":[],"source":"dtest = xgb.DMatrix(test_df[predictors].values)\npredsr = bst.predict(dtest)\npredsr=np.expm1(predsr)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"63c654b9-4d7f-3862-8dde-7a0a05237d99"},"outputs":[],"source":"### Submiss output\n\noutput=pd.DataFrame({'id': test['id'], 'price_doc': predsr})\noutput.head(10)\noutput.to_csv('xgb_submission.csv', index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"720e4cd3-545d-2ad1-80a6-0a5e6af7cf3d"},"outputs":[],"source":"print(output.head())"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}