{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"2b073d37-762c-af5c-ffe3-d51e0cc11067"},"source":"# Sberbank Russian Housing Prices \nhttps://www.kaggle.com/c/sberbank-russian-housing-market/\n\n## This is a silly model - a quick run to get familiar with uploading & running kernels on Kaggle\n\nIt's yet to have any serious cleaning, transforming, feature engineering, or analysis.\n\nMy goals:\n(1) to get my hands on this new dataset \n(2) upload a kernel to Kaggle"},{"cell_type":"markdown","metadata":{"_cell_guid":"9e21297c-6fde-479a-0794-85916e5316e5"},"source":"## Define the problem\n\nSupervised regression: Predict a continuous target, Sale Price, in Test set given labeled Train Set.\nWe want generalizable model. We don't need to understand deeply how it works or use the coefficients elsewhere.\n\n## Input data\n\nTrain: August 2011 to June 2015\n\nTest: July 2015 to May 2016\n\nTarget: price_doc"},{"cell_type":"markdown","metadata":{"_cell_guid":"c7756c25-5f35-80fd-ece1-56d54979c411"},"source":"## Load up"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"792051e8-c98c-282e-8ce2-1e35e6e11578"},"outputs":[],"source":"import pandas as pd \nimport numpy as np\nimport matplotlib\nfrom scipy.stats import skew\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.model_selection import cross_val_score\n\ntrain = pd.read_csv('../input/train.csv', header=0)\ntest = pd.read_csv('../input/test.csv', header=0)\n\n# Alldata = everything but price_doc, which is only in Train.\nalldata = pd.concat((train.loc[:,:'market_count_5000'],test))\nalldata = alldata.reset_index(drop=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"24f19796-7685-ef82-01c3-346e6000a0f8"},"outputs":[],"source":"train.info()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"176a5d03-8190-fa59-7eac-1022e9f2b406"},"outputs":[],"source":"alldata.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"914352a4-68b4-e4c0-e1f0-9bdd337e0955"},"source":"What've we got?\n  - Train: 30471 rows, 290 features + target + ID\n  - Test: 7662 rows, 290 features + ID\n  - Features: mix of numeric and categorical\n  - Missing values to clean up"},{"cell_type":"markdown","metadata":{"_cell_guid":"984b04b9-4b09-dc23-0b46-8e47ad956f81"},"source":"## Prepare the dataset"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1f2574c6-13a7-9e13-f605-f082919f12b8"},"outputs":[],"source":"def log_transforms(df):\n    \n    minimum_skew=0.75\n   \n    numeric_feats = df.dtypes[df.dtypes != \"object\"].index # Find numeric features\n    skewed_feats = df[numeric_feats].apply(lambda x: skew(x.dropna())) # Compute skewness of non-null rows\n    skewed_feats = skewed_feats[skewed_feats > minimum_skew] # Only look at indices with minimum skew\n    print(\"Number of features with minimum skew\", skewed_feats.shape)\n    skewed_feats = skewed_feats.index\n    df[skewed_feats] = np.log1p(df[skewed_feats]) # Apply log transform to skewed numeric features\n\n    return df"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"da76f498-c2d6-b265-cd6b-1e940c328d04"},"outputs":[],"source":"preprocessed = alldata.copy()\n\nprint(\"Log transform...\")\npreprocessed = log_transforms(preprocessed)\n\nprint(\"Stupid cleaning (placeholder for now)...\")\npreprocessed = preprocessed.fillna(preprocessed.mean())\n\nprint('Entering dummyland:',preprocessed.shape)\npreprocessed = pd.get_dummies(preprocessed, dummy_na=True)\nprint('Leaving dummyland:',preprocessed.shape)\n\npreprocessed.drop(['id'], axis=1,inplace=True) # Drop ID column\nX_train = preprocessed[:train.shape[0]] # Take a train-sized chunk out of alldata\nX_test = preprocessed[train.shape[0]:] # Everything after\ny = np.log1p(train.price_doc)  # log transform the target"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"99b36a9b-3213-8c6f-0c11-c64f4a40f30f"},"outputs":[],"source":"X_train.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"03834c0f-9130-0fee-5b42-90b98006cb45"},"source":"## Analysis: Lasso with cross-validation"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d72e1e1a-42fe-164b-7c03-9ec352114d1e"},"outputs":[],"source":"def writepredictions(prediction_array,output_file_name):\n    Ids=test.id\n    df=pd.DataFrame({\"id\": Ids,\"price_doc\": prediction_array})\n    df.to_csv(output_file_name, header=[\"id\",\"price_doc\"], index=False)"},{"cell_type":"markdown","metadata":{"_cell_guid":"0952822f-3e9e-792b-3406-406e4891ae35"},"source":"https://www.kaggle.com/apapiu/house-prices-advanced-regression-techniques/regularized-linear-models/discussion\n\nDrawing from Alexandru Papiu's excellent notebook on regularized linear regression. \n\nI've made a few small adaptations, like normalizing."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"501f63c8-70fb-202a-7831-b53c0c72f1f0"},"outputs":[],"source":"def rmse_cv(model):\n    rmse= np.sqrt(-cross_val_score(model, X_train, y, scoring=\"neg_mean_squared_error\", cv = 5))\n    return(rmse)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9c49fc08-fec5-f65e-d7fc-81d7a38c39e8"},"outputs":[],"source":"model_lasso = LassoCV(alphas = [1, 0.1, 0.001, 0.0005], normalize=True).fit(X_train, y)\n# model_lasso = LassoCV(alphas = [0.1]).fit(X_train, y)\nrmse_cv(model_lasso).mean()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"700ed318-1b05-6e56-1e29-cb2fcd521642"},"outputs":[],"source":"coef = pd.Series(model_lasso.coef_, index = X_train.columns)\nprint(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"d4de27ec-2492-86bf-8ff8-6c5b1c72ed49"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f3a6a44d-c2f1-28b4-8b93-f7deac04bfcf"},"outputs":[],"source":"imp_coef = pd.concat([coef.sort_values().head(10),coef.sort_values().tail(10)])\nmatplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\nimp_coef.plot(kind = \"barh\")\nplt.title(\"Coefficients in the Lasso Model\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e93c62b0-b9bf-98b4-1679-77760dd8923b"},"outputs":[],"source":"# Peek at residuals\n\nmatplotlib.rcParams['figure.figsize'] = (6.0, 6.0)\n\npreds = pd.DataFrame({\"preds\":model_lasso.predict(X_train), \"true\":y})\npreds[\"residuals\"] = preds[\"true\"] - preds[\"preds\"]\npreds.plot(x = \"preds\", y = \"residuals\",kind = \"scatter\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7abb33d5-2758-ca15-b73e-64af9205cf56"},"outputs":[],"source":"model_lasso.score(X_train, y)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"003c0690-7243-fda4-78dd-85ab1e9825b2"},"outputs":[],"source":"predictions_lasso=np.expm1(model_lasso.predict(X_test))\nwritepredictions(predictions_lasso,\"Lasso_Model.csv\")"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}