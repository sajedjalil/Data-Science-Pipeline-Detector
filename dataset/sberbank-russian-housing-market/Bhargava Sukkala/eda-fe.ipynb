{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"eff31665-8ce8-30d8-6c9c-ea6425c2a304"},"source":"Learning [here][1]\nand [here][2]\n\n\n  [1]: https://stackoverflow.com/questions/36065646/xgboost-attributeerror-dmatrix-object-has-no-attribute-handle\n  [2]: https://www.kaggle.com/sudalairajkumar/simple-exploration-notebook-sberbank"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d66c567c-7b11-8aa0-5724-189ad3700ac7"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n%matplotlib inline\n\n\npd.options.mode.chained_assignment = None  # default='warn'\npd.set_option('display.max_columns', 500)\n\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fe590117-8986-0ee5-1821-69df97130986"},"outputs":[],"source":"tn = pd.read_csv(\"../input/train.csv\",  parse_dates=['timestamp'])\ntt = pd.read_csv(\"../input/test.csv\",  parse_dates=['timestamp'])\nmacro_df = pd.read_csv(\"../input/macro.csv\", parse_dates=['timestamp'])\n\ntn = pd.merge(tn, macro_df, how ='left', on='timestamp')\ntt = pd.merge(tt, macro_df, how ='left', on='timestamp')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b285d6a3-5809-dfd2-a063-5bd532b9a17b"},"outputs":[],"source":"tn.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"6dcb0d79-bc4b-7232-e402-1477933ce5d8"},"source":"Lets's get the estimate of shape, dtypes"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"84430add-ba68-6263-7d9d-f8d15e5b405b"},"outputs":[],"source":"print(\"Shape\")\nprint(tn.shape, tt.shape)\nprint(\"dtypes\")\nprint(tn.dtypes)"},{"cell_type":"markdown","metadata":{"_cell_guid":"e0abccac-2904-e2bd-149b-2b3b0a1846ea"},"source":"Looking at the data set, we see lot's of na's. Let's get a count of them"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"be5eff20-ea54-d8a1-0e24-c693e9e542f7"},"outputs":[],"source":"tn.isnull().sum()"},{"cell_type":"markdown","metadata":{"_cell_guid":"f15f0e18-4f9f-76c8-4e9a-04caedc5ac42"},"source":"Let's make a mental note to make sure we impute values. For now lets continue.\n\nLet's find correlations in property variables"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c990c9cc-d6ba-1b11-3d45-33d2f410a021"},"outputs":[],"source":"import matplotlib.pyplot as plt\nimport seaborn as sns"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fa746bdc-f54f-ae90-7067-d455b3b5c88b"},"outputs":[],"source":"ax =tn.price_doc.hist(bins=50)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5d4de763-58be-8ac8-ffe5-81519fd96bf8"},"outputs":[],"source":"ax = np.log(tn['price_doc']).hist(bins=50)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"93f68721-adcc-a238-a33f-deaecbad4fdc"},"outputs":[],"source":"dtype_df = tn.dtypes.reset_index()\ndtype_df.columns = [\"Count\", \"Column Type\"]\ndtype_df.groupby(\"Column Type\").aggregate('count').reset_index()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d4dd1f12-5044-3d57-a168-c4118e20a01a"},"outputs":[],"source":"null_df = tn.isnull().sum().reset_index()\nnull_df.columns = [\"Column\", \"Null_no\"]\nnull_df=null_df.ix[null_df['Null_no']>0]\nind = np.arange(null_df.shape[0])\nwidth = 0.9\nfig, ax = plt.subplots(figsize=(12,18))\nrects = ax.barh(ind, null_df.Null_no.values, color='y')\nax.set_yticks(ind)\nax.set_yticklabels(null_df.Column.values, rotation='horizontal')\nax.set_xlabel(\"Count of missing values\")\nax.set_title(\"Number of missing values in each column\")\nplt.show()\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"2ebee79a-a000-6a99-ae54-02e869388df3"},"source":"For Feature Importance, lets use XGB"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b0ed1cd7-d077-d2fa-76f4-7f23d4876728"},"outputs":[],"source":"\nfrom sklearn import model_selection, preprocessing\n\nfor o in tn.columns:\n    if tn[o].dtype=='object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(tn[o].values)) \n        tn[o] = lbl.transform(list(tn[o].values))\n        \ntn_Y = tn.price_doc.values\ntn_X = tn.drop([\"id\", \"timestamp\", \"price_doc\"], axis = 1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0867ab6e-027b-9aa6-fc64-c8623c6e5cc8"},"outputs":[],"source":"xgb_params = {\n    'eta': 0.05,\n    'max_depth': 8,\n    'subsample': 0.7,\n    'colsample_bytree': 0.7,\n    'objective': 'reg:linear',\n    'eval_metric': 'rmse',\n    'silent': 1\n}\ndtrain = xgb.DMatrix( tn_X, tn_Y,feature_names=list(tn_X.columns.values))\nmodel = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=100)\n\n# plot the important features #\nfig, ax = plt.subplots(figsize=(12,18))\nxgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\nplt.show()"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}