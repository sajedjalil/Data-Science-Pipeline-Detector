{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5b37e32e-c960-fb69-64eb-89200f7dbfa1"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"957be98d-66df-2d71-7c96-4de7590c06f3"},"outputs":[],"source":"def preprocessing(df):\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['build_year'] = np.where(df['build_year'] < 1500.0, np.nan, df['build_year'])\n    df['build_year'] = np.where(df['build_year'] > 2017.0, np.nan, df['build_year'])\n    df['build_year'] = 'Year_' + df['build_year'].astype(str)\n    df['build_year_flg'] = np.where(pd.isnull(df['build_year']), 'N', 'Y')\n    df['state'] = np.where(df['state'] > 4.0, np.nan, df['state'])\n    df['floor'] = np.where(df['floor'] < 10.0, np.nan, df['floor'])\n    df['num_room'] = np.where(df['num_room'] > 9.0, np.nan, df['num_room'])\n    #df['material'] = np.where(pd.isnull(df['material']), 7.0, df['material'])\n    df['material'] = 'Material_' + df['material'].astype(str)\n    #df['state'] = np.where(pd.isnull(df['state']), 5, df['state'])\n    df['state'] = 'State_' + df['state'].astype(str)\n    df['state_flg'] = np.where(pd.isnull(df['state']), 'N', 'Y')\n    df['hospital_beds_raion_flg'] = np.where(pd.isnull(df['hospital_beds_raion']), 'N', 'Y')\n    df['cafe_500_flg'] = np.where(pd.isnull(df['cafe_sum_500_min_price_avg']), 'N', 'Y')\n    df['floor_flg'] = np.where(pd.isnull(df['max_floor']), 'N', 'Y')\n    df['preschool_quota_flg'] = np.where(pd.isnull(df['preschool_quota']), 'N', 'Y')\n    df['school_quota_flg'] = np.where(pd.isnull(df['school_quota']), 'N', 'Y')\n    df['cafe_1000_flg'] = np.where(pd.isnull(df['cafe_sum_1000_min_price_avg']), 'N', 'Y')\n    df['life_sq_flg'] = np.where(pd.isnull(df['life_sq']), 'N', 'Y')\n    df['build_flg'] = np.where(pd.isnull(df['raion_build_count_with_material_info']), 'N', 'Y')\n    df['cafe_2000_flg'] = np.where(pd.isnull(df['cafe_sum_2000_min_price_avg']), 'N', 'Y')\n    df['cafe_3000_flg'] = np.where(pd.isnull(df['cafe_sum_3000_min_price_avg']), 'N', 'Y')\n    df['cafe_5000_flg'] = np.where(pd.isnull(df['cafe_sum_5000_min_price_avg']), 'N', 'Y')\n    df['metro_flg'] = np.where(pd.isnull(df['metro_min_walk']), 'N', 'Y')\n    df['prom_part_5000'] = np.where(pd.isnull(df['prom_part_5000']), 'N', 'Y')\n    df['floor_flg'] = np.where(pd.isnull(df['floor']), 'N', 'Y')\n\n    df['life_sq'] = np.where(df['life_sq'] > df['full_sq'], np.nan, df['life_sq'])\n    df['kitch_sq'] = np.where(df['kitch_sq'] > df['full_sq'], np.nan, df['kitch_sq'])\n    df['max_floor'] = np.where(df['floor'] > df['max_floor'], df['floor'], df['max_floor'])\n\n    df['year'] = pd.DatetimeIndex(df['timestamp']).year\n    df['month'] = pd.DatetimeIndex(df['timestamp']).month\n    df['day'] = pd.DatetimeIndex(df['timestamp']).day\n    df['weekday'] = pd.DatetimeIndex(df['timestamp']).weekday\n    object = []\n    for i in df.columns:\n        if (df[i].dtype == 'object'): object.append(i)\n\n    #dummies = pd.get_dummies(df[object])\n    number = LabelEncoder()\n    for i in object:\n        df[i] = number.fit_transform(df[i].astype(str))\n    #df = df.drop(object, axis=1)\n    #df = pd.concat([df, dummies], axis=1)\n    imp = Imputer(missing_values='NaN', strategy='most_frequent', axis=0)  ## trying with Most frequent\n    ddfwotime = pd.to_numeric(df['timestamp'])\n    df = df.drop('timestamp', axis=1)\n    df_complete = pd.DataFrame(imp.fit_transform(df), columns= df.columns)\n    #df_complete = df\n    df_complete['timestamp'] = ddfwotime\n    return df_complete"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6e81d7d4-e7d3-944a-0a56-bd61537db20f"},"outputs":[],"source":"def rmsle(y, y_pred):\n\tassert len(y) == len(y_pred)\n\tterms_to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n\treturn (sum(terms_to_sum) * (1.0/len(y))) ** 0.5"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"18f7eb52-0c34-ad71-af38-5f6d5a1b4b5c"},"outputs":[],"source":"def baseline_model():\n\t# create model\n\tmodel = Sequential()\n\tmodel.add(Dense(480, input_dim=480, kernel_initializer='normal', activation='relu'))\n\tmodel.add(Dense(1, kernel_initializer='normal'))\n\t# Compile model\n\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n\treturn model"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1ff0c61b-372e-b519-2b96-55ce1dca3864"},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nimport sklearn.preprocessing as st\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import Imputer\nfrom sklearn.preprocessing import LabelEncoder\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nimport math\nimport xgboost as xg\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\nimport fancyimpute as fc"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"204e69dc-2434-8afa-db45-df4fb283aa0d"},"outputs":[],"source":"df = pd.read_csv(\"../input/train.csv\",sep=',')\ntest = pd.read_csv(\"../input/test.csv\",sep=',')\nmacro = pd.read_csv(\"../input/macro.csv\",sep=',')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e7fc2056-f81f-092b-ab3e-8406e9f4e43d"},"outputs":[],"source":"macro['child_on_acc_pre_school'] = macro['child_on_acc_pre_school'].str.replace(\",\",\"\")\nmacro['old_education_build_share'] = macro['old_education_build_share'].str.replace(\",\",\".\")\nmacro['modern_education_share'] = macro['modern_education_share'].str.replace(\",\",\".\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0c044965-0974-2680-021a-7a76e061a50a"},"outputs":[],"source":"macro['timestamp'] = pd.to_datetime(macro['timestamp'])\nmacro['child_on_acc_pre_school']= pd.to_numeric(macro['child_on_acc_pre_school'],errors='coerce')\nmacro['old_education_build_share']= pd.to_numeric(macro['old_education_build_share'],errors='coerce')\nmacro['modern_education_share']= pd.to_numeric(macro['modern_education_share'],errors='coerce')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"de60b84c-6ab5-d633-3b8d-2f944395cd8d"},"outputs":[],"source":"print(macro[['modern_education_share','timestamp']].groupby(['modern_education_share']).agg(['count']))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7df0b888-6736-9b3c-4ebc-5ae3c00d910d"},"outputs":[],"source":"object =[]\nfor i in macro.columns:\n    if(macro[i].dtype =='object'):\n        lst = []\n        print(i)\n        object.append(i)\n        lst.append(i)\n        lst.append('timestamp')\n        print(macro[lst].groupby([i]).agg(['count']))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ad9a990c-7319-1cb3-7e72-091b9af5c74c"},"outputs":[],"source":"print (object)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b029944a-4c24-e624-a6fb-3b917d3ec2d6"},"outputs":[],"source":"macro_wotimestamp = macro.drop(['timestamp'], axis = 1)\ntk = pd.DataFrame.as_matrix(macro_wotimestamp)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d20884bb-392b-45db-a002-7ee1312a7aea"},"outputs":[],"source":"X_filled_knn = fc.KNN(k=3).complete(tk)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"637501b6-e54a-9086-2ac3-bf200ba0d9f7"},"outputs":[],"source":"varnames = macro_wotimestamp.columns.tolist()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e4e344b4-10c4-6406-4573-d6fadbcaa696"},"outputs":[],"source":"print (varnames)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cdf435a9-4ade-465c-8b53-edc59753a329"},"outputs":[],"source":"macro_fill = pd.DataFrame(X_filled_knn, columns=varnames)\nmacro_fill['timestamp'] = macro['timestamp']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"404b3b35-7b83-b5bc-01a1-7ed1756e2c0c"},"outputs":[],"source":"imp = Imputer(missing_values='NaN', strategy='most_frequent', axis=0)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d44daf00-6eae-314f-daa7-0c4b40c48588"},"outputs":[],"source":"macro = macro_fill"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c3b21765-481a-cfef-358b-28397a66a42f"},"outputs":[],"source":"np.sum(np.sum(pd.isnull(macro)))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a8ecc6d5-6599-80bb-ce33-36777fb5686c"},"outputs":[],"source":"timestam = pd.to_numeric(macro['timestamp'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7e125f57-217f-ae18-cde3-cca4a1257749"},"outputs":[],"source":"\nmacro['timestamp'] =timestam"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aad04c30-e964-f134-be7e-19fc072e5a43"},"outputs":[],"source":"macro.head(3)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5422757a-b9de-deb5-4c61-88e2f8295cd6"},"outputs":[],"source":"df_complete = preprocessing(df)\ntest_complete = preprocessing(test)\ndf_complete_train = pd.merge(df_complete,macro,how ='left' ,on=['timestamp'])\ntest_complete = pd.merge(test_complete,macro,how ='left' ,on=['timestamp'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3f4e4635-0435-d271-f514-34537719ed32"},"outputs":[],"source":"target = df_complete_train.columns.tolist().index('price_doc')\nid = df_complete_train.columns.tolist().index('id')\nnoofcol = len(df_complete_train.columns)\nr =  list(range(0,noofcol))\ndel r[target]\ndel r[id]\nfeatures = df_complete_train.columns[r]\ndata = df_complete_train.values\n#X_filled_knn = fc.KNN(k=3).complete(data)\n#data = X_filled_knn\nY = data[:,target]\ny_log = np.log(data[:,target])\nX = data[:,r]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f1320f2e-552e-9365-0f89-393f7a5728bd"},"outputs":[],"source":"np.sum(np.isnan(X))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8b74d806-0a57-0f26-7f61-908caa71c6ec"},"outputs":[],"source":"testid = test_complete.columns.tolist().index('id')\ntestcol = len(test_complete.columns)\nr =  list(range(0,testcol))\ndel r[id]\nTest_features = test_complete.columns[r]\ntestdata = test_complete.values\n#X_filled_knn = fc.KNN(k=3).complete(testdata)\n#testdata = X_filled_knn\ntestX = testdata[:,r]\n#end"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c53afb7e-9feb-57aa-c2e6-91dd8f941ef9"},"outputs":[],"source":"np.sum(np.isnan(testX))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5fcf5d93-7411-1d2a-cb35-e73056b66123"},"outputs":[],"source":"seed = 7\ntest_size = 0.33\nX_train, X_test, y_train, y_test = train_test_split(X, y_log, test_size=test_size, random_state=seed)\n\nestimators = []\ngbm = xg.XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=.7, gamma=0,\n       learning_rate=0.1, max_delta_step=0, max_depth=3,\n       min_child_weight=1, missing=None, n_estimators=500, nthread=-1,\n       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n       scale_pos_weight=1, seed=0, silent=True, subsample=.7)\nestimators.append(('standardize', st.RobustScaler()))\nestimators.append(('mlp', gbm))\npipeline = Pipeline(estimators)\npipeline.fit(X_train, y_train)\ny_pred = pipeline.predict(X_test)\nres = rmsle(np.exp(y_test),np.exp(y_pred))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9a923880-d8b6-fe95-3a91-a19287cee6c7"},"outputs":[],"source":"print (res)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"36c164e9-e0b8-4f10-bd59-ec1b326d2c4f"},"outputs":[],"source":"testy_pred = pipeline.predict(testX)\npred_ytest = np.exp(testy_pred)\nids = test_complete['id']\n\nresults = pd.DataFrame(columns=list(['id','price_doc']))\nresults['id'] = ids\nresults['id'] = results['id'].astype(int)\nresults['price_doc'] = pred_ytest\nresults.to_csv(\"Results.csv\",index=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"af511a7c-5093-580a-3a61-35b70eccebfd"},"outputs":[],"source":"rt = pd.read_csv(\"Results.csv\",sep=\",\")\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"29ba1490-6f17-35fd-fa5e-3e8819c34539"},"outputs":[],"source":"print(rt)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}