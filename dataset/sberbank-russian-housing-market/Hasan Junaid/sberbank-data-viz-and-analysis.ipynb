{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"f78c436d-0af9-8d6e-b7b3-5b7078e6d8b2"},"source":"We will start with Data Visualization and then continue with data cleaning and transformation"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2ce1daea-386a-91a5-c59b-7f045b8f4260"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ncolor = sns.color_palette()\n%matplotlib inline\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"markdown","metadata":{"_cell_guid":"91b38155-0d49-7214-3b52-1f3b86d1e0b2"},"source":"Basic EDA"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a3435242-1875-9fb2-0e57-d42aedc88500"},"outputs":[],"source":"train_data=pd.read_csv('../input/train.csv',parse_dates=['timestamp'])\ntest_data=pd.read_csv('../input/test.csv',parse_dates=['timestamp'])\nmacro_data=pd.read_csv('../input/macro.csv',parse_dates=['timestamp'])\nprint (train_data.shape)\nprint (test_data.shape)\nprint (macro_data.shape)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6b0c9637-13ea-94d2-9f6d-0bc5f2cb964f"},"outputs":[],"source":"##We will merge the test,train data with macro data\ntrain_data=pd.merge(train_data,macro_data,how='left',on='timestamp')\ntest_data=pd.merge(test_data,macro_data,how='left',on='timestamp')\n\n##Let us visyalize the target variables using a boxplot to see the outliers\nplt.figure(figsize=(10,8))\nsns.boxplot(train_data['price_doc'],orient='v')\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9782d429-24bc-925c-31dd-87e67bc5cce6"},"outputs":[],"source":"##As we can see there are a lot of values which qualify as outliers.We will remove the variables which are more than\n##99 percentile of the data\n\nulimit=np.percentile(train_data['price_doc'].values,99)\nllimit=np.percentile(train_data['price_doc'].values,1)\ntrain_data=train_data[(train_data['price_doc']<ulimit) & (train_data['price_doc']>llimit)]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"823fce94-7ef7-fc9b-3900-c81ceed7e137"},"outputs":[],"source":"##Visualizing the target data\nplt.figure(figsize=(10,6))\nsns.distplot(train_data['price_doc'],kde=False,bins=50)\nplt.xlabel('price')\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"de14f1db-2da8-9dff-6983-dd8bd1740ec9"},"outputs":[],"source":"#We can see the data is positively skewed and the range in large.We can also use the logarithmic plot to visualize the data better.\n##Lets plot log of target variable\nplt.figure(figsize=(10,6))\nsns.distplot(np.log(train_data['price_doc']),kde=False,bins=50)\nplt.xlabel('price')\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ce804187-722d-64a1-a4e3-131822ad59da"},"outputs":[],"source":"train_data['year_str']=train_data['timestamp'].apply(lambda x :  x.strftime('%Y-%m-%d'))\n#test_data['year_str']=test_data['timestamp'].apply(lambda x :  x.strftime('%Y-%m-%d'))\ntrain_data['year_str'].head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"501cee09-e6b3-1bd4-9f90-8e9859caa333"},"outputs":[],"source":"##We can see the data better with the logarithmic plot.\n\n##Lets see the increase of price over time\n\n\ntrain_data['yearmonth']=train_data['year_str'].apply(lambda x:x[:4]+x[5:7])\n\ngrouped_data_yearmonth=train_data.groupby('yearmonth')['price_doc'].aggregate(np.median).reset_index()\ngrouped_data_yearmonth.columns=['yearmonth','median price']\ngrouped_data_yearmonth.head()\n#test_data['yearmonth']=test_data['year_str'].apply(lambda x:x[:4]+x[5:7])\n###Barplot for price increase\nplt.figure(figsize=(10,8))\nsns.barplot(x=grouped_data_yearmonth['yearmonth'],y=grouped_data_yearmonth['median price'],color='b')\nplt.xticks(rotation='vertical')\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"842e8c9a-478b-dc13-d54d-5a0c5edc3117"},"outputs":[],"source":"##We will now visualize the number of houses built each year\ngrouped_data_count=train_data.groupby('build_year')['id'].aggregate('count').reset_index()\ngrouped_data_count.columns=['build_year','count']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"52a49f1e-2d02-2225-949f-e19833e88792"},"outputs":[],"source":"##Lets check the minimum and maximum build year dates\nprint (grouped_data_count.iloc[grouped_data_count['build_year'].idxmax()])\nprint (grouped_data_count.iloc[grouped_data_count['build_year'].idxmin()])\n\ntrain_data=train_data[(train_data['build_year']<2019)&(train_data['build_year']>1690)]\n#test_data=test_data[(test_data['build_year']<2019)&(test_data['build_year']>1690)]\ntrain_data.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4b8c8ec2-259f-fa61-1e80-cf4d55151ca1"},"outputs":[],"source":"train_data.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5d1199bc-9a83-897d-2737-70702b315931"},"outputs":[],"source":"\n##These values clearly suggests that this is not\n#correct and needs to be rectified during our data cleaning process\n\n#Lets visualize this data\ngrouped_data_count=grouped_data_count[(grouped_data_count['build_year']>1950) & (grouped_data_count['build_year']<2018) ]\nplt.figure(figsize=(10,8))\nsns.barplot(grouped_data_count['build_year'],grouped_data_count['count'],color='g')\nplt.xticks(rotation='vertical')\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ab6deffc-3726-3e5a-d069-7643768977c7"},"outputs":[],"source":"##Lets visualize the internal characteristics of the house and its relation with price\nplt.figure(figsize=(10,8))\ninternal_characteristics=['full_sq', 'life_sq', 'floor', 'max_floor', 'material',\n                          'num_room', 'kitch_sq','price_doc']\nheatmap_data=train_data[internal_characteristics].corr()\nsns.heatmap(heatmap_data,annot=True)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2276301e-cb7a-532f-4873-feb154aa68ea"},"outputs":[],"source":"##We can see a high co-relation between the full_sq and the  num of rooms"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d68c79c5-7840-8c0e-fcf7-f735d4c104ec"},"outputs":[],"source":"##Lets start working on data cleaning and removing bad data from dataset\n##We will start by visualizing the missing data in all the columns\n\ntrain_missing=train_data.isnull().sum()/len(train_data)\ntrain_missing=train_missing.drop(train_missing[train_missing==0].index).sort_values(ascending=False).reset_index()\ntrain_missing.columns=['column name','missing percentage']\nplt.figure(figsize=(12,8))\nsns.barplot(train_missing['column name'],train_missing['missing percentage'],palette='inferno')\nplt.xticks(rotation='vertical')\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aab1233d-e035-ffe3-6065-70382ad610cb"},"outputs":[],"source":"##Count of different datatypes\nplt.figure(figsize=(10,8))\nsns.countplot(train_data.dtypes,)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b2acddad-73c4-5af1-b43b-1e40c653ad3f"},"outputs":[],"source":"test_data.head().T"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8a7cb571-e492-85f0-b730-01d806a6d93e"},"outputs":[],"source":"from sklearn.preprocessing import LabelEncoder\n\ndef encodeData(data):\n    for c in data.columns:\n        if data[c].dtype=='object':\n            lbl=LabelEncoder()\n            lbl.fit(list(data[c].values))\n            data[c]=lbl.transform(list(data[c].values))\n    return data \n \ntrain_df=encodeData(train_data)\n#test_df=encodeData(test_data)\n\n\ny_train=train_df['price_doc']\nX_train=train_df.drop(['id','timestamp','price_doc'],axis=1)\n\n#train_y=train_data['price_doc']\n#train_X=train_data.drop(['id','timestamp','price_doc'],axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e612f9a8-d0f4-c3c1-1ee8-cde87c9475fe"},"outputs":[],"source":"import xgboost as xgb\nxgb_params = {\n    'eta': 0.05,\n    'max_depth': 8,\n    'subsample': 0.7,\n    'colsample_bytree': 0.7,\n    'objective': 'reg:linear',\n    'eval_metric': 'rmse',\n    'silent': 1\n}\ndtrain = xgb.DMatrix(X_train, y_train, feature_names=X_train.columns.values)\nmodel = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=100)\n# plot the important features #\n# plot the important features #\nfig, ax = plt.subplots(figsize=(12,25))\nxgb.plot_importance(model,max_num_features=10,  height=0.8, ax=ax)\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6f3d9847-440c-7e5d-20e6-3c92fb6b15f8"},"outputs":[],"source":"##Lets visualize the missing values of these data\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b34dce4f-4e96-7f80-aa06-0643ae345b39"},"outputs":[],"source":"imp_variables=['full_sq','life_sq','floor','build_year','max_floor','kitch_sq','state',\n               'kindergarten_km','railroad_km','micex']\n##We need to add yearmonth to test_data\n\n\ntrain_df1=train_df[imp_variables]\ntest_df1=test_data[imp_variables]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e6da5dd9-6d57-a613-0388-6d35ad7c7cb3"},"outputs":[],"source":"test_df1=encodeData(test_df1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"83e46f4d-56ca-91a2-5008-91cd958a8494"},"outputs":[],"source":"X_train=train_df1\ny_train=train_df['price_doc']\nx_test=test_df1"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"463ee403-9871-9e7f-9b18-7594a5748a54"},"outputs":[],"source":"xgb_params = {\n    'eta': 0.05,\n    'max_depth': 8,\n    'subsample': 0.7,\n    'colsample_bytree': 0.7,\n    'objective': 'reg:linear',\n    'eval_metric': 'rmse',\n    'silent': 1\n}\n\ndtrain = xgb.DMatrix(X_train, y_train)\ndtest = xgb.DMatrix(x_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e68e0387-8ec9-362f-af1c-25d1e0821f42"},"outputs":[],"source":"cv_output = xgb.cv(xgb_params, dtrain, num_boost_round=1000, early_stopping_rounds=20,\n    verbose_eval=50, show_stdv=False)\n\nnum_boost_rounds = len(cv_output)\nmodel = xgb.train(dict(xgb_params, silent=1), dtrain, num_boost_round= num_boost_rounds)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0138dfdd-79fe-7ff1-79e5-cff625642d96"},"outputs":[],"source":"y_predict = model.predict(dtest)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1cea5c98-5c05-05a8-f8e9-fa36aac55116"},"outputs":[],"source":"id_test = test_data.id"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"17c15de6-59c9-3e1f-e874-61b4412ab12d"},"outputs":[],"source":"output = pd.DataFrame({'id': id_test, 'price_doc': y_predict})\n\noutput.to_csv('xgbSub_2.csv', index=False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}