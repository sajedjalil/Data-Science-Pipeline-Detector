{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"6e6f9fc9-f6c1-d645-ffa6-f6615bd5c7a9"},"source":"Exploratory Data Analysis "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dda3ca16-144d-4e3d-5a8e-ca68da7246c2"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\nimport matplotlib.pyplot as plt\nimport seaborn as sns"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6afc94c3-c41f-d4e1-8ae3-4548c4062725"},"outputs":[],"source":"try:\n    train_df = pd.read_csv(\"../input/train.csv\")\n    print (\"Training Data Loaded. It has {} samples and {} features\".format(*train_df.shape))\n    \nexcept:\n    print (\"An error occured\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"99c9f8e2-366b-312f-b60b-e511a1a50f08"},"outputs":[],"source":"try:\n    test_df = pd.read_csv(\"../input/test.csv\")\n    print (\"Testing Data Loaded. It has {} samples and {} features\".format(*test_df.shape))\n    \nexcept:\n    print (\"An error occured\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9407f65e-7fcc-a177-1069-fe4c123981a3"},"outputs":[],"source":"train_df.isnull().values.any()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9a28fc57-de0e-2c53-a4be-5567d541f385"},"outputs":[],"source":"train_df.isnull().sum()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1ee990c7-cfe0-82e0-91d3-56401e909d3e"},"outputs":[],"source":"plt.figure(figsize=(10,8))\nsns.distplot(train_df.price_doc.values,bins=50,kde=True)\nplt.xlabel('Price')\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"74816e60-3084-5cd5-36c2-c929e3772c12"},"source":"The data seems to be skewed. I will apply logarithmic  scale and observe the shape of distribution. "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6e7c3519-c75e-fe7d-01d1-8853f5de7ebe"},"outputs":[],"source":"plt.figure(figsize=(10,8))\nsns.distplot(np.log(train_df.price_doc.values),bins=50,kde=True)\nplt.xlabel('Price')\nplt.show()"},{"cell_type":"markdown","metadata":{"_cell_guid":"a06099c5-577c-0050-c444-3ef222cab898"},"source":"The distribution in the graph above  looks like a normal distribution now.\n\n\n----------\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dec9521d-7e5d-975a-1209-91797a39ca69"},"outputs":[],"source":"train_df.describe()"},{"cell_type":"markdown","metadata":{"_cell_guid":"105da349-0f69-34c2-63e7-2c2df9e93bac"},"source":"We will pre process the data. We will use Label Encoding to handle the categorical variable."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"76837eac-a226-2fe3-a151-91dfdff3e421"},"outputs":[],"source":"from sklearn.preprocessing import LabelEncoder\nfor col in train_df.columns:\n    if train_df[col].dtype=='object':\n        lbl=LabelEncoder()\n        train_df[col]=lbl.fit_transform(list(train_df[col].values))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4146feb8-f093-f57d-b687-7d8308f5817b"},"outputs":[],"source":"train_df.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"36f79af8-0a73-a079-a1d7-4cb7dd4ad318"},"outputs":[],"source":"# Saving the predictor variable in y_train.\ny_train=train_df.price_doc.values\nX_train = train_df.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5596647b-6641-e132-8961-cf0751e09419"},"outputs":[],"source":"import xgboost as xgb"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8078ce7b-6b80-8945-d4cf-4270339edb5d"},"outputs":[],"source":"\nparam = {'max_depth':7, 'eta':1, 'silent':1, 'objective': 'reg:linear','eval_metric': 'rmse' }\nnum_round = 100\ndtrain = xgb.DMatrix(X_train, y_train, feature_names=X_train.columns.values)\nbstmodel = xgb.train(param, dtrain, num_round)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fe8ec7b8-5576-0d44-a3a9-d22e05284115"},"outputs":[],"source":"# Plot important features\nfig, ax = plt.subplots(figsize=(12,15))\nxgb.plot_importance(bstmodel, max_num_features=50, height=0.8, ax=ax)\nplt.show()"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}