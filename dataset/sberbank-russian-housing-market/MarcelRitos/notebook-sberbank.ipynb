{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"0912b1b4-2472-436a-59c1-e726fa41e208"},"source":"Introduction"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8f54a207-296c-be48-33f8-bc833de1ed4c"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Any results you write to the current directory are saved as output.\ndf_macro = pd.read_csv('../input/macro.csv', parse_dates=['timestamp'])\ndf_train = pd.read_csv('../input/train.csv', parse_dates=['timestamp'])\ndf_test = pd.read_csv('../input/test.csv', parse_dates=['timestamp'])\ndf_sample_submission = pd.read_csv('../input/sample_submission.csv')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1dbd3d02-1332-1cfc-ed11-0f79c99ac0e4"},"outputs":[],"source":"weak_model_train = df_train.dropna(axis=1)\nweak_model_macro = df_macro.dropna(axis=1)\nweak_model_test = df_test.dropna(axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1acb0ccb-5b14-479b-cc50-bf6631283b95"},"outputs":[],"source":"i1 = set(weak_model_train.columns)\ni2 = set(weak_model_test.columns)\n\n# new set with element in i1 but not in i2\ni1.difference(i2)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"709c859f-6f77-b8dc-548a-b19da9c25e64"},"outputs":[],"source":"i2.difference(i1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"43e2cfbe-4fdf-6de0-c013-7ce1f97959a9"},"outputs":[],"source":"weak_model_test = weak_model_test.drop(['floor',\n                                          'kitch_sq',\n                                          'material',\n                                          'max_floor',\n                                          'num_room'],\n                                        axis=1)\nweak_model_train = weak_model_train.drop(['green_part_2000',\n                                        'product_type'],\n                                      axis=1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f1511254-4ae6-6fff-9b16-7521609f75c6"},"outputs":[],"source":"weak_model_test.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fc3b77b2-8dd7-67bf-5a44-767591d1d2e4"},"outputs":[],"source":"weak_model_train.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"45ed046e-9347-0c2c-cc59-80ead910ece6"},"outputs":[],"source":"weak_model_union = weak_model_train.merge(weak_model_macro, left_on='timestamp', right_on='timestamp', how='inner')\n\n# We remove id and timestamp\nweak_model_union = weak_model_union.drop(['id', 'timestamp'], axis=1)\n\n# We only keep continuous predictors\nweak_model_union = weak_model_union.select_dtypes([np.number])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"70155caf-4559-c0db-606f-b2cc0d6e4e86"},"outputs":[],"source":"weak_model_test = weak_model_test.merge(weak_model_macro, left_on='timestamp', right_on='timestamp', how='inner')\n\n# We remove id and timestamp\nweak_model_test = weak_model_test.drop(['id', 'timestamp'], axis=1)\n\n# We only keep continuous predictors\nweak_model_test = weak_model_test.select_dtypes([np.number])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"34dbfc7b-1297-b113-51f8-fa0d55cd1afb"},"outputs":[],"source":"index_unions = set(weak_model_union.columns)\nindex_test = set(weak_model_test.columns)\n\n# new set with element in index_unions but not in index_test\nindex_unions.difference(index_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"411c2eb9-2de5-9b68-612a-9029bac8f672"},"outputs":[],"source":"weak_model_union.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4bba3bc3-287d-9e07-57a7-19eabc7e4e88"},"outputs":[],"source":"weak_model_test.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f0b2373d-8a63-ecb6-1a9c-d6b68c7db704"},"outputs":[],"source":"# Machine learning - metrics\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import cross_validation, metrics #Additional scklearn functions\nfrom sklearn.grid_search import GridSearchCV   #Perforing grid search\n\n# Machine learning - algorithms\nfrom sklearn.ensemble import GradientBoostingRegressor\n\n# Machine learning - preprocessing\nfrom sklearn import preprocessing"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"61c77d42-adbb-c59e-bab1-6dfa78b2df6b"},"outputs":[],"source":"X = weak_model_union.drop('price_doc', axis=1).values\nY = weak_model_union['price_doc'].values"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b3876cc2-1141-1169-b018-102b65902ecf"},"outputs":[],"source":"# Normalization\nstd_scale = preprocessing.StandardScaler().fit(X)\nX = std_scale.transform(X)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1c19e198-b22e-78ef-c857-3ec82cd982e3"},"outputs":[],"source":"def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n    \"\"\"\n    Generate a simple plot of the test and training learning curve.\n\n    Parameters\n    ----------\n    estimator : object type that implements the \"fit\" and \"predict\" methods\n        An object of that type which is cloned for each validation.\n\n    title : string\n        Title for the chart.\n\n    X : array-like, shape (n_samples, n_features)\n        Training vector, where n_samples is the number of samples and\n        n_features is the number of features.\n\n    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n        Target relative to X for classification or regression;\n        None for unsupervised learning.\n\n    ylim : tuple, shape (ymin, ymax), optional\n        Defines minimum and maximum yvalues plotted.\n\n    cv : int, cross-validation generator or an iterable, optional\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n          - None, to use the default 3-fold cross-validation,\n          - integer, to specify the number of folds.\n          - An object to be used as a cross-validation generator.\n          - An iterable yielding train/test splits.\n\n        For integer/None inputs, if ``y`` is binary or multiclass,\n        :class:`StratifiedKFold` used. If the estimator is not a classifier\n        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n\n        Refer :ref:`User Guide <cross_validation>` for the various\n        cross-validators that can be used here.\n\n    n_jobs : integer, optional\n        Number of jobs to run in parallel (default 1).\n    \"\"\"\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel(\"Training examples\")\n    plt.ylabel(\"Score\")\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    plt.grid()\n\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n             label=\"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n             label=\"Cross-validation score\")\n\n    plt.legend(loc=\"best\")\n    return plt\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4c758c16-76c5-e70d-6058-2562e5f85579"},"outputs":[],"source":"from sklearn.model_selection import learning_curve\nimport matplotlib.pyplot as plt\n\ntitle = \"Learning Curves (GBR)\"\ncv = 5\nestimator = GradientBoostingRegressor()\nplot_learning_curve(estimator, title, X, Y, ylim=(0.7, 1.01), cv=cv)\n\nplt.show()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cce59928-4ead-3e5c-a158-9a55b33aa657"},"outputs":[],"source":"X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(\nX, Y, test_size = 0.33, random_state = 5)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dd38e77f-bda2-bebf-ffbe-222221ae102b"},"outputs":[],"source":"gbr = GradientBoostingRegressor()\ngbr.fit(X_train, Y_train)\npred_train = gbr.predict(X_train)\npred_test = gbr.predict(X_test)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"47233efe-310d-7e94-d50e-9c01be60d4ec"},"outputs":[],"source":"print(\"Fit a model X_train, and calculate RMSLE with Y_train:\",\n      RMSLE(gbr.predict(X_train), Y_train))\nprint(\"Fit a model X_train, and calculate RMSLE with X_test, Y_test:\",\n      RMSLE(gbr.predict(X_test), Y_test))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8f39bffe-bd3a-9191-38ae-cbb4bbfa0d85"},"outputs":[],"source":"# Root Mean Squared Logarithmic Error\ndef RMSLE(predictions, a):\n    return np.sqrt( (1/a.shape[0]) * np.square(np.sum([np.log(predictions+1), - np.log(a+1)])) )"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b122112e-2747-e033-e625-4e677ae1a916"},"outputs":[],"source":"import xgboost as xgb\nfrom sklearn.cross_validation import KFold, train_test_split\n\nrng = np.random.RandomState(31337)\nkf = KFold(Y.shape[0], n_folds=10, shuffle=True, random_state=rng)\nerr = []\n\nfor train_index, test_index in kf:\n    xgb_model = xgb.XGBRegressor().fit(X[train_index], Y[train_index])\n    predictions = xgb_model.predict(X[test_index])\n    actuals = Y[test_index]\n    err.append(RMSLE(predictions, actuals))\n\nprint(\"xgboost results, mean: {}, std: {}\".format(np.mean(err), np.std(err)))"},{"cell_type":"markdown","metadata":{"_cell_guid":"f806d52a-ddc7-e64f-bf6c-4cf2e09c1149"},"source":"xgb_model = xgb.XGBRegressor()\n\nparam_grid = {'max_depth' : [4],\n              'n_estimators': [50, 100]\n              }\n\ngrid_search = GridSearchCV(xgb_model,\n                           param_grid=param_grid,\n                           cv=kf,\n                           verbose=1)\n\ngrid_search.fit(X, Y)\ngrid_search.best_score_, grid_search.best_params_"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e2b5447f-de46-487b-dedc-72b005ab973d"},"outputs":[],"source":""},{"cell_type":"markdown","metadata":{"_cell_guid":"608eb59d-4f6d-d5b6-9bbd-c6a8c2fdd067"},"source":"# Predict on test set then write on CSV file"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c03d25fc-7536-2403-6717-53561e9d4e55"},"outputs":[],"source":"X_validation = weak_model_test.values"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"591b628f-5dbe-a4ac-7708-3bce04e835f3"},"outputs":[],"source":"xgb_model = xgb.XGBRegressor().fit(X, Y)\npredictions_validation = xgb_model.predict(X_validation)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4e074a6e-2151-62cd-6ab2-857188aa024a"},"outputs":[],"source":"result_csv = pd.DataFrame({'id':df_test.id.values , 'price_doc': predictions_validation})\nresult_csv.to_csv('result.csv', index = False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}