{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6423d8b0-84d0-084c-45a6-0f118ec8efb2"},"outputs":[],"source":"import seaborn as sns\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom matplotlib import pyplot as plt\nfrom pandas import DataFrame,read_csv,isnull,notnull\nfrom sklearn.preprocessing import OneHotEncoder\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Activation\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom numpy import log# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport pandas as pd\nfrom sklearn.model_selection import KFold\nimport numpy as np\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\nfrom sklearn.preprocessing import Normalizer\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"14629450-626b-fe1a-e062-ac3e56bae61d"},"outputs":[],"source":"train=read_csv('../input/train.csv',header='infer')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4808b241-32f5-59a3-c04c-6c37603b7359"},"outputs":[],"source":"def find_category_cols(data):\n    uniques={}\n    for col in data:\n            uniques[col]={'Unique_Values':len(pd.unique(data[col])),'Max':np.max(data[col]),'Min':np.min(data[col]),'Missing':len(data[pd.isnull(data[col])])}\n    return uniques\ndef cat_to_num(data):\n    cat_strings=data.dtypes[data.dtypes=='object'].index\n    cat_strings=cat_strings[cat_strings!='timestamp']\n    for col in cat_strings:\n        data[col]=pd.Categorical.from_array(data[col]).labels\n    return data\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c65317a2-9654-f83f-6243-c09508efb99c"},"outputs":[],"source":"#Unique_Info=pd.DataFrame(find_category_cols(train)).T\n#Unique_Info.sort_values(by='Unique_Values',ascending=True)\ntrain=cat_to_num(train)\ntrain.head()"},{"cell_type":"markdown","metadata":{"_cell_guid":"86733095-f10e-0bca-f2ff-bd85c4cf4132"},"source":"**Getting only the internal house features initially and exploring them.**"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"321f6374-de8c-e69d-0509-84a9c730b94c"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5497841a-bea2-d06b-57b2-63175c92d810"},"outputs":[],"source":"features=train.columns[(train.columns!='id')&(train.columns!='price_doc')&(train.columns!='timestamp')]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e6fcf34d-3373-ddbd-1bbf-e7e7ccd3158e"},"outputs":[],"source":"nn = MLPRegressor(\n    hidden_layer_sizes=(10,),  activation='relu', solver='adam', alpha=0.001, batch_size='auto',\n    learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=True,\n    random_state=9, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n    early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n\n#n = nn.fit(train[features], train['price_doc'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"83c86966-85d1-347e-446a-7a76bff3efd0"},"outputs":[],"source":"np.array(train)"},{"cell_type":"markdown","metadata":{"_cell_guid":"cb3829f9-7e8e-5bd9-e4da-28b4c043641b"},"source":"## Making the following adjustments in the function adjust_sq_ft: ##\n\n 1. Using the observations which have all the sq ft populated obtain average portion of kitch in living area, average portion of living area in full area and average portion of kitchen area in full area. These averages will be later used to impute missing values of kitch area and living area.\n 2. If full_sq=0 then full_sq=life_sq.\n 3. If "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4825b729-9086-3b4b-a65e-15730f0d1596"},"outputs":[],"source":"def adjust_sq_ft(house_feat):\n    no_sq=(house_feat.full_sq==0)|(isnull(house_feat['full_sq']))\n    #missing_full=house_feat[no_sq]\n    no_kitch=(house_feat.kitch_sq==0)|(isnull(house_feat['kitch_sq']))\n    #missing_kitch=house_feat[no_kitch]\n    no_l_sq=(house_feat.life_sq==0)|(isnull(house_feat['life_sq']))\n    #missing_life=house_feat[no_l_sq]\n    has_all_sq_ft=(house_feat.full_sq!=0)&(notnull(house_feat['full_sq']))&(house_feat.kitch_sq!=0)&(notnull(house_feat['kitch_sq']))&(house_feat.life_sq!=0)&(notnull(house_feat['life_sq']))&((house_feat.full_sq-house_feat.kitch_sq)>0)&((house_feat.full_sq-house_feat.life_sq)>0)&((house_feat.life_sq-house_feat.kitch_sq)>0)\n    all_sq_ft=house_feat[has_all_sq_ft]\n    all_sq_ft.loc[:,'% Kitch/Full']=100*all_sq_ft.loc[:,'kitch_sq']/all_sq_ft.loc[:,'full_sq']\n    all_sq_ft.loc[:,'% Kitch/Life']=100*all_sq_ft.loc[:,'kitch_sq']/all_sq_ft.loc[:,'life_sq']\n    all_sq_ft.loc[:,'% Life/Full']=100*all_sq_ft.loc[:,'life_sq']/all_sq_ft.loc[:,'full_sq']\n    final_sq_ft=all_sq_ft[all_sq_ft['% Kitch/Life']<=60]\n    sq_ft_breakage=final_sq_ft.describe()\n    #Adjusting the missing full sq\n    house_feat.loc[no_sq,'full_sq']=house_feat.loc[no_sq,'life_sq']\n    #life_big_than_full=(house_feat.full_sq-house_feat.life_sq)<0\n    #house_feat.loc[life_big_than_full,'full_sq']=house_feat.loc[life_big_than_full,'life_sq']\n    # Adjusting kitch_sq using full_sq\n    too_kitch_in_full=(house_feat.full_sq-house_feat.kitch_sq)<0\n    house_feat.loc[(no_kitch)|(too_kitch_in_full),'kitch_sq']=house_feat.loc[(no_kitch)|(too_kitch_in_full),'full_sq']*sq_ft_breakage.loc['50%','% Kitch/Full']/100\n    #Adjusting the life_sq using full sq\n    too_life_in_full=(house_feat.full_sq-house_feat.life_sq)<0\n    house_feat.loc[(no_l_sq)|(too_life_in_full),'life_sq']=house_feat.loc[(no_l_sq)|(too_life_in_full),'full_sq']*sq_ft_breakage.loc['50%','% Life/Full']/100\n    #too_much=house_feat[(too_kitch_in_life)|(too_life_in_full)|(too_kitch_in_full)]\n    #Adjusting kitch_sq using life_sq\n    too_kitch_in_life=(house_feat.life_sq/house_feat.kitch_sq)>=0.6\n    house_feat.loc[(no_kitch)|(too_kitch_in_life),'kitch_sq']=house_feat.loc[(no_kitch)|(too_kitch_in_life),'life_sq']*sq_ft_breakage.loc['50%','% Kitch/Life']/100\n    return house_feat"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e597e808-44eb-9bf6-d600-870bfa6f7d3e"},"outputs":[],"source":"def adjust_floor(house_feat):\n    too_high_floor=house_feat.floor>house_feat.max_floor\n    house_feat.loc[too_high_floor,'floor']=house_feat.loc[too_high_floor,'max_floor']\n    return house_feat"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5d5c765f-2428-7068-9c58-e3113a9f4fc3"},"outputs":[],"source":"new_house_feat=adjust_floor(adjust_sq_ft(house_features))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"096516ec-89b9-1b36-33a7-c3692e7cc917"},"outputs":[],"source":"new_house_feat.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"680a0242-e0be-2289-4780-f81125ce259d"},"outputs":[],"source":"class neuralnet:        \n    def initialize(self,inp_nodes,hid_nodes,out_nodes,l_rate):\n        self.inodes=inp_nodes\n        self.hnodes=hid_nodes\n        self.onodes=out_nodes\n        self.lr=l_rate\n        self.wih=np.random.rand(hid_nodes,inp_nodes)-0.5\n        self.woh=np.random.rand(out_nodes,hid_nodes)-0.5\n        self.activation_function=lambda x:expit(x)\n        pass\n    def train(self):\n        pass\n    def query(self,input_list):\n        inputs=np.array(input_list,ndmin=2).T\n        hidden_inputs=np.dot(self.wih,inputs)\n        hidden_outputs=self.activation_function(hidden_inputs)\n        final_inputs=np.dot(self.woh,hidden_outputs)\n        final_outputs=self.activation_function(final_inputs)\n        return final_outputs\n        \n        \n        pass\n    def soph_weights(self):\n        self.wih=np.random.normal(0.0,np.power(self.hnodes,-0.5),(self.hnodes,self.inodes))\n        self.woh=np.random.normal(0.0,np.power(self.onodes,-0.5),(self.onodes,self.hnodes))\n    pass\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d821908c-7080-17f9-a461-7530268b8dec"},"outputs":[],"source":"n1=neuralnet()\nn1.initialize(3,5,3,0.5)\nn1.query([1,2,1])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c3156438-eb46-b4f8-7afa-bd054c7e32d1"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}