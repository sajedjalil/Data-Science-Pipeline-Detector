{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"78877ee5-61e4-d87d-07dd-d1da9fb1035e"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport numpy as np # linear algebra\nfrom matplotlib import pyplot as plt\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import OneHotEncoder,LabelEncoder\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Activation\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\nimport seaborn as sns\nfrom statistics import mode\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f6153b63-44e9-afde-fe75-90f1af655aa7"},"outputs":[],"source":"class NeuralNetKeras:\n    def load_data(self,train_data,test_data):\n        self.train=pd.read_csv(train_data)\n        self.test=pd.read_csv(test_data)\n        pass\n    def merge_all(self):\n        all_feat=list(self.train.columns)\n        self.train['Source_data']='train'\n        self.test['price_doc']=0.0\n        self.test['Source_data']='test'\n        self.merged_data=self.train.append(self.test)\n        pass\n    \n    def summary(self):\n        self.summary_info={}\n        for col in self.train:\n            self.summary_info[col]={'Missing':len(self.train[pd.isnull(self.train[col])]),'Min':np.min(self.train[col]),'Max':np.max(self.train[col]),'N_Unique':len(pd.unique(self.train[col]))}\n        pass\n    def boxplots(self,vars_list):\n        for i in range(len(vars_list)):\n            plt.figure(i)\n            sns.boxplot(self.train[vars_list[i]])\n    def HotEncoding(self,col_list):\n        for col in col_list:\n            if self.merged_data[col].dtype=='object':\n                self.merged_data.loc[:,col]=pd.Categorical.from_array(self.merged_data.loc[:,col]).labels\n            if self.summary_info[col]['N_Unique']<=20:\n                hot_encode=OneHotEncoder()\n                hot_encode.fit(np.array(self.merged_data.loc[:,col]))\n                self.merged_data.loc[:,col]=hot_encode.transform(np.array(self.merged_data.loc[:,col]))\n        pass\n    def setFullSq(self,data):\n        missing_full=(data['full_sq']==0)|(pd.isnull(data['full_sq']))\n        data.loc[missing_full,'full_sq']=data.loc[missing_full,'life_sq']\n        return data\n    def setSq(self,data,col,vs_col,imp_criteria):\n        trouble=(data[col]==0)|(pd.isnull(data[col]))|(data[col]>data[vs_col])\n        data.loc[trouble,col]=data.loc[trouble,vs_col]*self.all_area_summary[imp_criteria]['50%']\n        return data\n    def handle_sq_ft(self):\n        area_vars=['full_sq','life_sq','kitch_sq']\n        tr_te_merge=self.merged_data[area_vars]\n        all_sq_ft=(pd.notnull(tr_te_merge['full_sq']))&(pd.notnull(tr_te_merge['life_sq']))&(pd.notnull(tr_te_merge['kitch_sq']))&(tr_te_merge['full_sq']!=0)&(tr_te_merge['life_sq']!=0)&(tr_te_merge['kitch_sq']!=0)\n        tr_te_merge=tr_te_merge.loc[all_sq_ft,:]\n        #remove outliers from each of the sq_ft columns\n        no_outlier=(tr_te_merge['full_sq']<=np.mean(tr_te_merge['full_sq'])+3*np.std(tr_te_merge['full_sq']))&(tr_te_merge['full_sq']>=np.mean(tr_te_merge['full_sq'])-3*np.std(tr_te_merge['full_sq']))&(tr_te_merge['life_sq']<=np.mean(tr_te_merge['life_sq'])+3*np.std(tr_te_merge['life_sq']))&(tr_te_merge['life_sq']>=np.mean(tr_te_merge['life_sq'])-3*np.std(tr_te_merge['life_sq']))&(tr_te_merge['kitch_sq']<=np.mean(tr_te_merge['kitch_sq'])+3*np.std(tr_te_merge['kitch_sq']))&(tr_te_merge['kitch_sq']>=np.mean(tr_te_merge['kitch_sq'])-3*np.std(tr_te_merge['kitch_sq']))\n        tr_te_merge=tr_te_merge.loc[no_outlier,:]\n        # Generate variable %Kitch/Full, %Kitch/Life and %Life/Full\n        tr_te_merge.loc[:,'%Life/Full']=tr_te_merge.loc[:,'life_sq']/tr_te_merge.loc[:,'full_sq']\n        tr_te_merge.loc[:,'%Kitch/Full']=tr_te_merge.loc[:,'kitch_sq']/tr_te_merge.loc[:,'full_sq']\n        tr_te_merge.loc[:,'%Kitch/Life']=tr_te_merge.loc[:,'kitch_sq']/tr_te_merge.loc[:,'life_sq']\n        self.all_area_summary=tr_te_merge.describe()\n        # Impute values for missing sq ft\n        #Full Sq\n        self.merged_data=self.setFullSq(self.merged_data)\n        #Kitch Sq\n        self.merged_data=self.setSq(self.merged_data,'kitch_sq','full_sq','%Kitch/Full')\n        #Life Sq\n        self.merged_data=self.setSq(self.merged_data,'life_sq','full_sq','%Life/Full')\n        pass\n    def impute_mode(self,col_list):        \n        for col in col_list:\n            all_data=self.merged_data[col]\n            all_data=all_data[pd.notnull(all_data)]\n            mode_value=mode(all_data)\n            missing=len(self.merged_data[pd.isnull(self.merged_data[col])])\n            self.merged_data.loc[pd.isnull(self.merged_data[col]),col]=mode_value\n            print('Missing ',col,'=',missing,' out of ',len(self.merged_data[col]) ,'replaced by mode value= ',mode_value)\n            pass\n    def handle_missing(self,impute_cols):\n        # Handles missing sq ft data and imputes data and removes anomaly in the data\n        self.handle_sq_ft()\n        self.impute_mode(impute_cols)\n        #self.handle_missing_categories()\n        #self.handle_missing_continuous()\n        pass   \n    def preprocess_data(self):\n        self.HotEncoding()\n        pass\n    def house_features(self):\n        self.house_feat=list(self.merged_data.iloc[:,2:11].columns)\n        print (self.house_feat)\n    def correlation_mat(self):\n        self.corr_mat=self.train.corr()\n        pass\n    def no_missing_no_string(self):\n        self.no_missing_cols=[]\n        for key in self.summary_info:\n            if self.summary_info[key]['Missing']==0 and key not in ['timestamp','id','price_doc'] and self.train[key].dtype not in ['object']:\n                self.no_missing_cols.append(key)\n        pass\n    def descriptive_stats(self):\n        self.desc_stats=self.train.describe()\n        pass\n    def build_model_skeleton(self,n_nodes,activation_fn,i_dim):\n        self.model=Sequential()\n        self.model.add(Dense(n_nodes,input_dim=i_dim))\n        self.model.add(Activation(activation_fn))\n        self.model.add(Dense(1, kernel_initializer='normal'))  \n        pass\n    def compile_model(self,optimizer_crit,loss_crit):\n        self.model.compile(optimizer=optimizer_crit,loss=loss_crit)\n        pass\n    def fit_model(self,n_epochs,b_size,data_train,data_test):\n        self.model.fit(x=np.array(data_train[self.house_feat]),y=np.array(data_train['price_doc']),epochs=n_epochs,batch_size=b_size)\n    def predict_model(self,b_size,data_train,data_test):\n        self.predictions=self.model.predict(x=np.array(data_test),batch_size=b_size)\n    pass"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"03568b08-1d80-b3d5-f195-da47ade9894a"},"outputs":[],"source":"n1=NeuralNetKeras()\nn1.load_data('../input/train.csv','../input/test.csv')\nn1.summary()\nn1.merge_all()\nn1.house_features()\nn1.HotEncoding(n1.house_feat)\nn1.handle_missing(impute_cols=['floor','max_floor','material','build_year','num_room','state','product_type'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"469573c8-72b1-33af-e1ba-a0f97d21efa1"},"outputs":[],"source":"n1.build_model_skeleton(10,'relu',len(n1.house_feat))\nn1.compile_model('rmsprop','mse')\nn1.train=n1.merged_data.loc[n1.merged_data['Source_data']=='train',n1.house_feat+['price_doc']]\nn1.test=n1.merged_data.loc[n1.merged_data['Source_data']=='test',n1.house_feat]                        \n#n1.fit_model(20000,10000,n1.train,n1.test)\n#n1.predict_model(10000,n1.train,n1.test)\nprint(n1.train.head())\nprint(n1.test.head())"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ff37ba5a-c380-77e5-ebfe-7742515a6e78"},"outputs":[],"source":"#final=pd.DataFrame(n1.merged_data.loc[n1.merged_data['Source_data']=='test','id'])\n#final['prediction']=n1.predictions\n#final.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"20935e99-4758-c9ab-274d-13c7b65ef54c"},"outputs":[],"source":"#final.to_csv('final.csv')"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}