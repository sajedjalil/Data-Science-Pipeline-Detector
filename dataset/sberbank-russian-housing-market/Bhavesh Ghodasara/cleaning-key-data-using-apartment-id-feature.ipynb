{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"8706d3e0-508f-9f3f-209b-87f5e93a4ce7"},"source":"There is need to create an apartment feature(i.e. building in same vicinity). I think flats in same apartment should fetch almost equal value. Also it will help us to clean data as well.\n\nHere I am introducing new feature called apartment. It is obvious that if house is in same area , and same distance from metro station should be in same apartment building. Almost 80% of the house will fall in this category.\n\ne.g. Nekrasovka3.776835959 got 977 houses same distance from metro. see image, there are large apartment blocks in that area.\n\nNow this will help us to clean data as well. id 18344 got full_sq as 634. Now may houses of Nekrasovka and with the same distance from metro are there. But none of them got such huge full_sq. however there are many house in same area with 63 square meters. so this must be typo and we can clean this value. Similarly we can populate missing but important feature like floor, max floor and life_sq from there."},{"cell_type":"markdown","metadata":{"_cell_guid":"971dad0d-9544-de0f-1942-a213bd474971"},"source":"![Map of Nekrasovka][1]\n\n\n  [1]: https://www.google.co.in/maps/place/r-n+Nekrasovka,+Moscow,+Russia/@55.7031455,37.9308046,2749m/data=!3m1!1e3!4m5!3m4!1s0x414ac9cf2ba87c27:0x1a347d594875dd2!8m2!3d55.6828266!4d37.9441291"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"51770158-eb12-350a-d1cd-c1fd8c015d9f"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"726ce09d-cc74-ea1b-806d-82ed4d98b66e"},"outputs":[],"source":"train = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'])\ntest = pd.read_csv(\"../input/test.csv\", parse_dates=['timestamp'])\nmacro = pd.read_csv(\"../input/macro.csv\", parse_dates=['timestamp'])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"058e820c-5f8b-cb93-5d7b-47a07097b91a"},"outputs":[],"source":"# Merging macro data with train and test\ntrain = pd.merge(train, macro, how='left', on='timestamp')\ntest = pd.merge(test, macro, how='left', on='timestamp')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dcebd78a-4949-403d-e7e9-6dd2bb1aef1d"},"outputs":[],"source":"# normalize prize feature and drop it\ntrain[\"price_doc\"] = np.log1p(train[\"price_doc\"])\n# store it as Y\nY_train = train[\"price_doc\"]\n# Dropping price column\ntrain.drop(\"price_doc\", axis=1, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"49501570-4d64-e9e9-4290-2fb1a8c1e66a"},"outputs":[],"source":"# Merging both dataframes\nall_data = pd.concat((train,test))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"77dc95ec-938e-1eff-dc11-d1e1a03af53d"},"outputs":[],"source":"# Creating new apartment_name and month year feature\nall_data['apartment_name'] = all_data[\"sub_area\"] + all_data[\"metro_km_avto\"].astype(str)\nall_data[\"month_year\"]=all_data.timestamp.dt.month + all_data.timestamp.dt.year * 100\n# year and week #\nall_data[\"week_year\"] = all_data[\"timestamp\"].dt.year*100 + all_data[\"timestamp\"].dt.weekofyear\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"0c84841e-3713-73fb-2d6e-d11b84b319ce"},"source":"Problem here is not just about missing values, but incorrect/dirty values as well. We need to identify outliers individually from each important feature. So let's first start with most important column full_sq"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"427c1631-c75e-3285-e69e-a7e7c9cd5811"},"outputs":[],"source":"fig, ax = plt.subplots(figsize=(10,12))\nsns.boxplot(y=\"full_sq\",data=all_data)\nax.set_title(\"Box chart of full_sq\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"7b22fe14-be38-a813-b923-585cec8e331f"},"source":"So we can clearly see some outliers there. Let's use three sigma to identify those."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f52f1b48-518e-ed46-0a05-69263960aa0b"},"outputs":[],"source":"print (all_data.dtypes)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d8c32049-5166-9f02-cdbf-f1f5e1954867"},"outputs":[],"source":"all_data['week_year']=all_data['week_year'].apply(str)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"682f3b7b-db88-6f98-4b55-58329998674b"},"outputs":[],"source":"full_sq_mean = np.mean(all_data.full_sq, axis=0)\nfull_sq_std = np.std(all_data.full_sq, axis=0)\nfull_sq_mean + 6 * full_sq_std"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"831067d5-7128-8791-26b4-3229c91cde26"},"outputs":[],"source":"#Scatter plot\nfig, ax = plt.subplots(figsize=(10,12))\nfig = ax.scatter(x=\"week_year\",y=\"full_sq\",data=all_data[all_data.full_sq<5000])\nplt.xlabel('yearweek', fontsize=12)\n\n#ax.set_title(\"Scatter to identify outliers\")\n'''\nplt.figure(figsize=(12,8))\nsns.pointplot(x='yearweek', y='price_doc', data=train_df)\nplt.ylabel('price_doc', fontsize=12)\nplt.xlabel('yearweek', fontsize=12)\nplt.title('Median Price distribution by year and week_num')\nplt.xticks(rotation='vertical')\nplt.show()'''"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e853c8d3-0354-1bc1-3001-a24eff7bdd5b"},"outputs":[],"source":"all_data[(all_data.full_sq<6) & (all_data.full_sq>300)]['apartment_name']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"adabacaf-f853-6d1e-9406-62747cf792ae"},"outputs":[],"source":"import scipy.stats.mstats as mstats\ndef mode(x):\n    return mstats.mode(x, axis=None)[0]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"bafda3a1-b3db-8f87-d64e-160e256c039a"},"outputs":[],"source":"g_Apartment_col.columns= ['apartment_name','col_mode'] \ng_Apartment_col=all_data.groupby('apartment_name').full_sq.value_counts()\n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3aeef331-c951-21e2-aba8-fe7d8147b485"},"outputs":[],"source":"all_data.groupby('apartment_name')['full_sq'].agg(['mode'])[0]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"08307803-5709-d3d6-f2d0-a9d55bacef65"},"outputs":[],"source":"all_data.groupby(['apartment_name']).apply(pd.DataFrame.mode).reset_index(drop=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2a115811-7004-cb42-a7a0-89d7893f795e"},"outputs":[],"source":"g_Apartment_col=all_data.groupby('apartment_name')['full_sq'].agg(['mean','std','mode'])[0].reset_index()\ng_Apartment_col.columns= ['apartment_name','col_mean','col_std','col_mode'] \n"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a4ea46dd-de15-e059-88f7-f8fb53e077f0"},"outputs":[],"source":"all_data[all_data.apartment_name=='Ljublino1.686566142']"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a8261d22-0b46-1da5-7b92-3320ec97bd32"},"outputs":[],"source":"#Scatter plot\nfig, ax = plt.subplots(figsize=(10,12))\nfig = sns.regplot(x=\"timestamp.dt\",y=\"full_sq\",data=all_data)\nax.set_title(\"Scatter to identify outliers\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"82edf97c-9f28-6a00-0583-8da0daac3503"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}