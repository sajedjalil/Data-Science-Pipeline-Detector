{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f462b3f9-98e6-864f-d0ec-adf045dd8f36"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport xgboost as xgb\nimport matplotlib.pyplot as plt\n\ntrain = pd.read_csv(\"../input/train.csv\", parse_dates=['timestamp'])\ntest = pd.read_csv(\"../input/test.csv\", parse_dates=['timestamp'])\nmacro = pd.read_csv(\"../input/macro.csv\", parse_dates=['timestamp'])\n\n# Merging macro data with train and test\ntrain = pd.merge(train, macro, how='left', on='timestamp')\ntest = pd.merge(test, macro, how='left', on='timestamp')\n\ntrain = train[train.price_doc/train.full_sq <= 600000]\ntrain = train[train.price_doc/train.full_sq >= 10000]\n\n# store it as Y\nY_train = train[\"price_doc\"]\n# Dropping price column\ntrain.drop(\"price_doc\", axis=1, inplace=True)\n\n# Build all_data = (train+test).join(macro)\nnum_train = len(train)\nall_data = pd.concat([train, test])\n\n# Add month-year\nmonth_year = (all_data.timestamp.dt.month + all_data.timestamp.dt.year * 100)\nmonth_year_cnt_map = month_year.value_counts().to_dict()\nall_data['month_year_cnt'] = month_year.map(month_year_cnt_map)\n\n# Add week-year count\nweek_year = (all_data.timestamp.dt.weekofyear + all_data.timestamp.dt.year * 100)\nweek_year_cnt_map = week_year.value_counts().to_dict()\nall_data['week_year_cnt'] = week_year.map(week_year_cnt_map)\n\n# Creating Apartment Name Feature\nall_data['apartment_name'] = pd.factorize(all_data.sub_area + all_data['metro_km_avto'].astype(str))[0]\n\n#cleaning of full_sq\nall_data.loc[((all_data[\"full_sq\"]<=6) | (all_data[\"full_sq\"]>300)) & (all_data[\"life_sq\"]>=6) & (all_data[\"life_sq\"]<300) & ((all_data[\"full_sq\"]>= all_data[\"life_sq\"]*15) | ((all_data[\"full_sq\"]>=0) & (all_data[\"full_sq\"]<all_data[\"life_sq\"]))),\"full_sq\"]=all_data[((all_data[\"full_sq\"]<=6) | (all_data[\"full_sq\"]>300)) & (all_data[\"life_sq\"]>=6) & (all_data[\"life_sq\"]<300) & ((all_data[\"full_sq\"]>= all_data[\"life_sq\"]*15) | ((all_data[\"full_sq\"]>=0) & (all_data[\"full_sq\"]<all_data[\"life_sq\"])))].life_sq\ng_Apartment_col=all_data.groupby('apartment_name')['full_sq'].agg(['mean','median','count']).reset_index()\ng_Apartment_col.columns= ['apartment_name','full_sq_mean','full_sq_median','apartment_count'] \nall_data=all_data.merge(g_Apartment_col, how='left')\nall_data.loc[((all_data[\"full_sq\"]<=6) | (all_data[\"full_sq\"]>300)) & (all_data.apartment_count>3),\"full_sq\"]=all_data[((all_data[\"full_sq\"]<=6) | (all_data[\"full_sq\"]>300)) & (all_data.apartment_count>3)].full_sq_mean\n\n# Other feature engineering\nall_data['rel_floor'] = all_data['floor'] / all_data['max_floor'].astype(float)\nall_data['rel_kitch_sq'] = all_data['kitch_sq'] / all_data['full_sq'].astype(float)\n\n# Remove timestamp column (may overfit the model in train)\nall_data.drop(['timestamp'], axis=1, inplace=True)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e81a3525-ea41-fb70-6d31-ff04105465d8"},"outputs":[],"source":"from sklearn import preprocessing \n#convert objects / non-numeric data types into numeric\nfor f in all_data.columns:\n    if all_data[f].dtype=='object':\n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(all_data[f].values)) \n        print(f)\n        all_data[f] = lbl.transform(list(all_data[f].values))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"511bdd93-1a60-b905-5982-d2940cf70941"},"outputs":[],"source":"X_train = all_data[:num_train]\nX_test = all_data[num_train:]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4baaa553-c5a6-071b-8479-5313e268d271"},"outputs":[],"source":"df_columns = all_data.columns"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"477748b9-caba-247a-c2a7-6abcdb892e26"},"outputs":[],"source":"xgb_params = {\n    'eta': 0.05,\n    'max_depth': 5,\n    'subsample': 0.7,\n    'colsample_bytree': 0.7,\n    'objective': 'reg:linear',\n    'eval_metric': 'rmse',\n    'silent': 1\n}"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"06d29908-df1c-4289-8dbd-3b42c248706b"},"outputs":[],"source":"dtrain = xgb.DMatrix(X_train, y_train, feature_names=df_columns)\ndtest = xgb.DMatrix(X_test, feature_names=df_columns)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a648034b-e49a-79a7-e899-59960954ab34"},"outputs":[],"source":"cv_result = xgb.cv(xgb_params, dtrain, num_boost_round=1000, early_stopping_rounds=20,\n    verbose_eval=20, show_stdv=False)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d443e935-3860-3e58-4027-6ae707332f68"},"outputs":[],"source":"num_boost_rounds = len(cv_result)\ncv_result[['train-rmse-mean', 'test-rmse-mean']].plot()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6ac6361f-69a8-be36-62eb-5b7585edf488"},"outputs":[],"source":"num_boost_rounds # 386"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5234cabb-861b-9f10-1e79-ef4ace65d335"},"outputs":[],"source":"model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_rounds)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d2e13b55-fe14-f8cd-d8c3-c2dc4939eb2f"},"outputs":[],"source":"fig, ax = plt.subplots(1, 1, figsize=(8, 16))\nxgb.plot_importance(model, max_num_features=50, height=0.5, ax=ax)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5a2af4a4-6ef4-f2ac-4a77-326b7cd16d05"},"outputs":[],"source":"y_pred = model.predict(dtest)\n\ndf_sub = pd.DataFrame({'id': id_test, 'price_doc': y_pred})\n\ndf_sub.to_csv('subxgb.csv', index=False)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}