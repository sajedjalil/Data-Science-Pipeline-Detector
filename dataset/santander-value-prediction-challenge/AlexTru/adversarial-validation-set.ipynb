{"cells":[{"metadata":{"_uuid":"e3e6d0230e34a043303d60c374efbfdb956422f6"},"cell_type":"markdown","source":"As many people mentioned, there is difference between train and test distributions. One of way to deal with it is to use Adversarial validation.\nThe main idea is:\n\n*     Train a classifier to identify whether data comes from the train or test set.\n*     Sort the training data by itâ€™s probability of being in the test set.\n*     Select the training data most similar to the test data as  validation set."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Read train and test files\ntrain_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')\n\n#Set labels for train/test data\ntrain_df['TAR'] = 0\ntest_df['TAR'] = 1\n# Get the combined data\ntotal_df = pd.concat([train_df.drop('target', axis=1), test_df], axis=0).drop('ID', axis=1)\n# Train and test\ntrain_idx = range(0, len(train_df))\ntest_idx = range(len(train_df), len(total_df))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"11634a2f9e478b75cdd42326257b10063b26f43a"},"cell_type":"code","source":"#Get labels\ny = total_df.TAR.copy()\ntotal_df.drop('TAR', axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"97e1d278aea0438c5dcdab626c392480340dd5da"},"cell_type":"code","source":"#Shuffle and split our set\nfrom sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(total_df, y, test_size=0.20, shuffle = True, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9406d6fdc2f58a2563dc8b61d501744bf016dc00"},"cell_type":"markdown","source":"Now we training LightGBM classifier to predict train/test set:"},{"metadata":{"trusted":true,"_uuid":"162740287acd5ccf2e55cc42d427438c58fe54ca"},"cell_type":"code","source":"import lightgbm as lgb\nlgbm_params =  {\n    'task': 'train',\n    'boosting_type': 'gbdt',\n    'objective': 'binary',\n    'metric': 'auc',\n    'num_leaves': 32,\n    'learning_rate': 0.02,\n    'verbose': 0,\n    'lambda_l1': 1,\n    'scale_pos_weight': 8  #for unbalanced labels\n} \nlgtrain = lgb.Dataset(X_train, y_train)\n\nlgvalid = lgb.Dataset(X_valid, y_valid)\n\nlgb_clf = lgb.train(\n    lgbm_params,\n    lgtrain,\n    num_boost_round=10000,\n    valid_sets=[lgtrain, lgvalid],\n    valid_names=['train','valid'],\n    early_stopping_rounds=100,\n    verbose_eval=100\n        )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3710573645d6692c0fd292962dbe856a2d46c5fe"},"cell_type":"markdown","source":"Now lets predict and select our valid set:"},{"metadata":{"trusted":true,"_uuid":"e65f2351b1384b2a16358f2cb2c7f83eb0e270f5"},"cell_type":"code","source":"train_preds = lgb_clf.predict(total_df.iloc[train_idx])\ntrain_df['prob_to_test'] = train_preds\nval_set = train_df[train_df.prob_to_test>0.9] #train set with prob more than 90% to be test set\nval_set.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64173cf9df25679371cea036802900a55dc3490e"},"cell_type":"markdown","source":"**Bonus**:\nAs LGBM model can show features importance, we can select and delete features, which make difference between train and test set. So it can make our train and test sets more similar. "},{"metadata":{"trusted":true,"_uuid":"043414d28f372266118008c86ae4cb2bb2463a37"},"cell_type":"code","source":"# feature importance\nprint(\"Features Importance...\")\ngain = lgb_clf.feature_importance('gain')\nfeatureimp = pd.DataFrame({'feature':lgb_clf.feature_name(), \n                   'split':lgb_clf.feature_importance('split'), \n                   'gain':100 * gain / gain.sum()}).sort_values('gain', ascending=False)\nfeatureimp.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f50063bea36370d59d7c222359e7969d3f37df03"},"cell_type":"markdown","source":"Thanks!"},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1cf05779c64bacbc9b4ef2543a275120fae7a519"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}