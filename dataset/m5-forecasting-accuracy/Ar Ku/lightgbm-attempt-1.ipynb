{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Archit Kulkarni, Adhithya Narayanan, Vibhu Ambil, Tyler Youngberg\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"'''\nTitle: M5 Data Preprocessing\nAuthor: Quinn Wang\nDate: March 2020\nAvailability: https://www.kaggle.com/qcw171717/naive-baseline/\n'''\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\nfrom tqdm import tqdm\ndf = pd.read_csv('../input/m5-forecasting-accuracy/sales_train_validation.csv')\nprice_df = pd.read_csv(\"../input/m5-forecasting-accuracy/sell_prices.csv\")\ncal_df = pd.read_csv(\"../input/m5-forecasting-accuracy/calendar.csv\")\ncal_df[\"d\"]=cal_df[\"d\"].apply(lambda x: int(x.split(\"_\")[1]))\nprice_df[\"id\"] = price_df[\"item_id\"] + \"_\" + price_df[\"store_id\"] + \"_validation\"\nfor i in range(1886, 1914):\n    df[\"F_\" + str(i)] = 0\n\n'''end Quinn Wang'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Preprocessing Steps:\n\n1. Convert categorical observations to int format\n2. Shorten training data to last 28 days before predictions (days 1858-1886)\n3. Create validation data from days 1887-1913"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = np.zeros((30490,), dtype=int)\nk = 0\nfor i in df[\"state_id\"]:\n    if i == \"CA\":\n        temp[k] = 0\n    if i == \"TX\":\n        temp[k] = 1\n    if i == \"WI\":\n        temp[k] = 2\n    k+=1\ndf[\"state_id\"] = pd.DataFrame(temp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = np.zeros((30490,), dtype=int)\nk = 0\nfor i in df[\"store_id\"]:\n    if i == \"CA_1\":\n        temp[k] = 0\n    elif i == \"CA_2\":\n        temp[k] = 1\n    elif i == \"CA_3\":\n        temp[k] = 2\n    elif i == \"CA_4\":\n        temp[k] = 3\n    elif i == \"TX_1\":\n        temp[k] = 4\n    elif i == \"TX_2\":\n        temp[k] = 5\n    elif i == \"TX_3\":\n        temp[k] = 6\n    elif i == \"WI_1\":\n        temp[k] = 7\n    elif i == \"WI_2\":\n        temp[k] = 8\n    elif i == \"WI_3\":\n        temp[k] = 9\n    k+=1\ndf[\"store_id\"] = pd.DataFrame(temp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = np.zeros((30490,), dtype=int)\nk = 0\nfor i in df[\"cat_id\"]:\n    if i == \"HOBBIES\":\n        temp[k] = 0\n    if i == \"FOODS\":\n        temp[k] = 1\n    if i == \"HOUSEHOLD\":\n        temp[k] = 2\n    k+=1\ndf[\"cat_id\"] = pd.DataFrame(temp) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = np.zeros((30490,), dtype=int)\nk = 0\nfor i in df[\"dept_id\"]:\n    if i == \"HOBBIES_1\":\n        temp[k] = 0\n    elif i == \"HOBBIES_2\":\n        temp[k] = 1\n    elif i == \"FOODS_1\":\n        temp[k] = 2\n    elif i == \"FOODS_2\":\n        temp[k] = 3\n    elif i == \"FOODS_3\":\n        temp[k] = 4\n    elif i == \"HOUSEHOLD_1\":\n        temp[k] = 5\n    elif i == \"HOUSEHOLD_2\":\n        temp[k] = 6\n    k+=1\ndf[\"dept_id\"] = pd.DataFrame(temp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation = pd.DataFrame()\ntrain = df\nfor x in range(1886, 1914):\n    s = \"d_\" + str(x)\n    f = \"F_\" + str(x)\n    train = train.drop(columns = [s, f])\n    validation[s] = df[s]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(columns=[\"item_id\", \"id\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = pd.DataFrame()\nids[\"dept_id\"] = df[\"dept_id\"]\nids[\"cat_id\"] = df[\"cat_id\"]\nids[\"store_id\"] = df[\"store_id\"]\nids[\"state_id\"] = df[\"state_id\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we will be creating a few models to see which one works the best. We will have 5 time periods, the minimum being the last 28 days, and the maximum being the last 800 days."},{"metadata":{"trusted":true},"cell_type":"code","source":"train1 = pd.concat([ids, pd.DataFrame(train.values[:, -28:])], axis=1) # Last 28 days\ntrain2 = pd.concat([ids, pd.DataFrame(train.values[:, -50:])], axis=1) # Last 50 days\ntrain3 = pd.concat([ids, pd.DataFrame(train.values[:, -200:])], axis=1) # last 200 days\ntrain4 = pd.concat([ids, pd.DataFrame(train.values[:, -400:])], axis=1) # last 400 days\ntrain5 = pd.concat([ids, pd.DataFrame(train.values[:, -800:])], axis=1) # last 800 days\nt = [train1, train2, train3, train4, train5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To add to the complexity and increase the chance of getting a good model, we will also change the parameters through iteration."},{"metadata":{"trusted":true},"cell_type":"code","source":"params_list = [{\n   'task': 'train',\n   'boosting_type': 'gbdt',\n   'objective': 'regression',\n   'metric': 'rmse',\n   'learning_rate': .1,\n    'num_iterations': 75\n},\n{\n   'task': 'train',\n   'boosting_type': 'rf'\n},\n{\n    'task':'train',\n    'boosting_type': 'dart',\n    'metric': 'fair',\n    'learning_rate': .1,\n    'num_iterations': 75    \n},\n{\n    'task':'train',\n    'boosting_type': 'regression',\n    'metric': 'rmse',\n    'tree_learner': 'feature',\n    'num_iterations': 75  \n},\n{\n    'task':'train',\n    'boosting_type': 'regression',\n    'metric': 'rmse',\n    'tree_learner': 'feature',\n    'num_iterations': 50  \n}]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merge ids dataframe with sales data\npd.concat([ids, train1], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error as mse\nimport math\ndef learner(t_data, v_data, params):\n    n = int(t_data.values[0, :].shape[0])\n    for x in range(1886, 1914):    \n        d = pd.DataFrame()\n        \n        # setup for training\n        t = t_data.values\n        v = v_data.values[:, x - 1886]\n        lgbm_data = lgb.Dataset(t, label=v, \n                                feature_name=t_data.columns.tolist(), \n                                categorical_feature=['dept_id', 'cat_id', 'store_id', 'state_id'])\n\n        # train data\n        gbt = lgb.train(params, lgbm_data) \n\n        s = str(n) # string name for day in format d_xxxx\n        x = pd.DataFrame(gbt.predict(t))\n\n        # add new data to training for next iteration\n        t_data[s] = x\n        n+=1\n        \n    forecast = pd.DataFrame(df[\"id\"])\n    for i in range(1886, 1914):\n        d = \"d_\" + str(i)\n        f = \"F\" + str(i-1885)\n        forecast[f] = train[d]\n    print(math.sqrt(mse(v_data.values, forecast.drop(columns=[\"id\"]).values)))\n    f2 = forecast.copy()\n    f2[\"id\"] = f2[\"id\"].apply(lambda x : x.replace('validation', 'evaluation'))\n    forecast = forecast.append(submission_df2).reset_index(drop=True)\n    return forecast","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"j = 1\nfor i in range(0, 5):\n    params = params_list[i]\n    for k in range(0, 5):\n        f = learner(train[k], v_data, params)\n        name = \"learner_\" + str(j) + \".csv\"\n        forecast.to_csv(name, index=False)\n        j+=1","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}