{"cells":[{"metadata":{},"cell_type":"markdown","source":"# M5 - WRMSSE Evaluation Dashboard\n\nThis notebooks shows WRMSSE evaluation Dashboard which I created on the WRMSSEEvaluator class object made by sakami @[Evaluation metric](https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/133834). If you just put the evaluator object into create_dashboard() function in this notebook, it will create the visualizations which give you all the performance details on your created model.\n\nFor this demonstration purpose, I'm just developing very simple LGB model using last (112-28) days (3months) in the provided dataset.\n\n-----\nVersion 3 udates: applied the updated scaling logic in WRMSSEEvaluator from sakami's thread which removes preceding 0 sales from the scale calculation"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns; sns.set()\nimport gc\n\nfrom sklearn import preprocessing\nimport lightgbm as lgb\n\nfrom typing import Union\nfrom tqdm.notebook import tqdm_notebook as tqdm\n\nDATA_DIR = '/kaggle/input/m5-forecasting-accuracy/'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading Datasets\nWe are creating two types of sales dataset: \"sales\" (wide format) and \"sales_mlt\" (long format). \"sales\" is used for WRMSSE evaluation, \"sales_mlt\" is used for LGB training."},{"metadata":{"trusted":true},"cell_type":"code","source":"d_dtypes = {}\nfor i in range(1914):\n    d_dtypes[f'd_{i}'] = np.int32\n    \nsales = pd.read_csv(DATA_DIR + 'sales_train_validation.csv',\n                    dtype=d_dtypes)\n\n# changing wide format to long format for model training\nd = ['d_' + str(i) for i in range(1802,1914)]\nsales_mlt = pd.melt(sales, id_vars=['item_id','dept_id','cat_id','store_id',\n                                    'state_id'], value_vars=d)\nsales_mlt = sales_mlt.rename(columns={'variable':'d', 'value':'sales'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Merging calendar and prices to the sales_mlt dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar = pd.read_csv(DATA_DIR + 'calendar.csv',\n                       dtype={'wm_yr_wk': np.int32, 'wday': np.int32, \n                              'month': np.int32, 'year': np.int32, \n                              'snap_CA': np.int32, 'snap_TX': np.int32,\n                              'snap_WI': np.int32})\n\n# subsetting calender by traning period\ncalendar = calendar.loc[calendar.d.apply(lambda x: int(x[2:])) \\\n                        >= int(sales_mlt.d[0][2:]), :]\n\nprices = pd.read_csv(DATA_DIR + 'sell_prices.csv',\n                          dtype={'wm_yr_wk': np.int32, \n                                 'sell_price': np.float32})\n# subsetting prices by traning period\nprices = prices.loc[prices.wm_yr_wk >= calendar.wm_yr_wk.values[0], :]\n\nsales_mlt = sales_mlt.merge(calendar.drop(['date', 'weekday'], axis=1), \n                         how='left', on='d')\\\n            .merge(prices, how='left', on=['item_id','store_id','wm_yr_wk'])\n\nsales_mlt['snap'] = sales_mlt.apply(lambda x: x.snap_CA if x.state_id == 'CA' \\\n                              else x.snap_TX if x.state_id == 'TX' \\\n                              else x.snap_WI, axis=1)\nsales_mlt.drop(['snap_CA','snap_TX','snap_WI'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Just adding a few moving avarage to improve the performance a little bit"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"sales_mlt.loc[:, 'sales_shift28'] = \\\n    sales_mlt.groupby(['item_id','store_id'])['sales'].shift(periods=28)\n\ngrp = sales_mlt.groupby(['item_id','store_id'])\nsales_mlt.loc[:,f'sales_shift28_mean7'] = \\\n    grp['sales_shift28'].transform(lambda x: x.rolling(7).mean())\nsales_mlt.loc[:,f'sales_shift28_mean30'] = \\\n    grp['sales_shift28'].transform(lambda x: x.rolling(30).mean())\nsales_mlt.loc[:,f'sales_shift28_mean90'] = \\\n    grp['sales_shift28'].transform(lambda x: x.rolling(90).mean())\n\ndel grp\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Converting string into numbers and imputing missing values."},{"metadata":{"trusted":true},"cell_type":"code","source":"cate_ft_lst = ['item_id','dept_id','cat_id','store_id','state_id','event_name_1',\n               'event_type_1','event_name_2','event_type_2']\n\nX = sales_mlt.drop(['d','sales','wm_yr_wk',], axis=1)\ny = sales_mlt[\"sales\"]\n\nfor col in cate_ft_lst:\n    le = preprocessing.LabelEncoder()\n    X.loc[:, col] = le.fit_transform(X[col].astype(str))\n\nX.fillna(-1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Training\nJust creating simple LGB model"},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_params = {'objective': 'regression',\n              'metric': 'rmse',\n              'boosting': 'gbdt',\n              'num_leaves': 32,\n              'bagging_fraction': 0.6,\n              'bagging_freq': 5,\n              'learning_rate': 0.05,\n              'n_estimators': 100\n}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The last 28 days are used for validation. Days before that is used for training"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"train_filter = sales_mlt.d.apply(lambda x: int(x[2:])) < int(sales.columns[-28][2:])\nvalid_filter = sales_mlt.d.apply(lambda x: int(x[2:])) >= int(sales.columns[-28][2:])\n\nX_train, X_valid = X.loc[train_filter, :], X.loc[valid_filter, :]\ny_train, y_valid = y.loc[train_filter], y.loc[valid_filter]\n\nmodel = lgb.LGBMRegressor(**lgb_params)\nmodel.fit(X_train, y_train, verbose=False)\nvalid_pred = model.predict(X_valid)\n\ndel X_train, X_valid ,y_train, y_valid\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## WRMSSEE Evaluation\nUsing WRMSSEEvaluator class object from [Evaluation metric](https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/133834) by sakami. I just made some minor changes to use it for the visualization. So, using this class instead of the original one is necessary for the dashboard."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"class WRMSSEEvaluator(object):\n\n    def __init__(self, train_df: pd.DataFrame, valid_df: pd.DataFrame, \n                 calendar: pd.DataFrame, prices: pd.DataFrame):\n        train_y = train_df.loc[:, train_df.columns.str.startswith('d_')]\n        train_target_columns = train_y.columns.tolist()\n        weight_columns = train_y.iloc[:, -28:].columns.tolist()\n\n        train_df['all_id'] = 'all'  # for lv1 aggregation\n\n        id_columns = train_df.loc[:, ~train_df.columns.str.startswith('d_')]\\\n                     .columns.tolist()\n        valid_target_columns = valid_df.loc[:, valid_df.columns.str.startswith('d_')]\\\n                               .columns.tolist()\n\n        if not all([c in valid_df.columns for c in id_columns]):\n            valid_df = pd.concat([train_df[id_columns], valid_df], \n                                 axis=1, sort=False)\n\n        self.train_df = train_df\n        self.valid_df = valid_df\n        self.calendar = calendar\n        self.prices = prices\n\n        self.weight_columns = weight_columns\n        self.id_columns = id_columns\n        self.valid_target_columns = valid_target_columns\n\n        weight_df = self.get_weight_df()\n\n        self.group_ids = (\n            'all_id',\n            'state_id',\n            'store_id',\n            'cat_id',\n            'dept_id',\n            ['state_id', 'cat_id'],\n            ['state_id', 'dept_id'],\n            ['store_id', 'cat_id'],\n            ['store_id', 'dept_id'],\n            'item_id',\n            ['item_id', 'state_id'],\n            ['item_id', 'store_id']\n        )\n\n        for i, group_id in enumerate(tqdm(self.group_ids)):\n            train_y = train_df.groupby(group_id)[train_target_columns].sum()\n            scale = []\n            for _, row in train_y.iterrows():\n                series = row.values[np.argmax(row.values != 0):]\n                scale.append(((series[1:] - series[:-1]) ** 2).mean())\n            setattr(self, f'lv{i + 1}_scale', np.array(scale))\n            setattr(self, f'lv{i + 1}_train_df', train_y)\n            setattr(self, f'lv{i + 1}_valid_df', valid_df.groupby(group_id)\\\n                    [valid_target_columns].sum())\n\n            lv_weight = weight_df.groupby(group_id)[weight_columns].sum().sum(axis=1)\n            setattr(self, f'lv{i + 1}_weight', lv_weight / lv_weight.sum())\n\n    def get_weight_df(self) -> pd.DataFrame:\n        day_to_week = self.calendar.set_index('d')['wm_yr_wk'].to_dict()\n        weight_df = self.train_df[['item_id', 'store_id'] + self.weight_columns]\\\n                    .set_index(['item_id', 'store_id'])\n        weight_df = weight_df.stack().reset_index()\\\n                   .rename(columns={'level_2': 'd', 0: 'value'})\n        weight_df['wm_yr_wk'] = weight_df['d'].map(day_to_week)\n\n        weight_df = weight_df.merge(self.prices, how='left',\n                                    on=['item_id', 'store_id', 'wm_yr_wk'])\n        weight_df['value'] = weight_df['value'] * weight_df['sell_price']\n        weight_df = weight_df.set_index(['item_id', 'store_id', 'd'])\\\n                    .unstack(level=2)['value']\\\n                    .loc[zip(self.train_df.item_id, self.train_df.store_id), :]\\\n                    .reset_index(drop=True)\n        weight_df = pd.concat([self.train_df[self.id_columns],\n                               weight_df], axis=1, sort=False)\n        return weight_df\n\n    def rmsse(self, valid_preds: pd.DataFrame, lv: int) -> pd.Series:\n        valid_y = getattr(self, f'lv{lv}_valid_df')\n        score = ((valid_y - valid_preds) ** 2).mean(axis=1)\n        scale = getattr(self, f'lv{lv}_scale')\n        return (score / scale).map(np.sqrt) \n\n    def score(self, valid_preds: Union[pd.DataFrame, \n                                       np.ndarray]) -> float:\n        assert self.valid_df[self.valid_target_columns].shape \\\n               == valid_preds.shape\n\n        if isinstance(valid_preds, np.ndarray):\n            valid_preds = pd.DataFrame(valid_preds, \n                                       columns=self.valid_target_columns)\n\n        valid_preds = pd.concat([self.valid_df[self.id_columns], \n                                 valid_preds], axis=1, sort=False)\n\n        all_scores = []\n        for i, group_id in enumerate(self.group_ids):\n\n            valid_preds_grp = valid_preds.groupby(group_id)[self.valid_target_columns].sum()\n            setattr(self, f'lv{i + 1}_valid_preds', valid_preds_grp)\n            \n            lv_scores = self.rmsse(valid_preds_grp, i + 1)\n            setattr(self, f'lv{i + 1}_scores', lv_scores)\n            \n            weight = getattr(self, f'lv{i + 1}_weight')\n            lv_scores = pd.concat([weight, lv_scores], axis=1, \n                                  sort=False).prod(axis=1)\n            \n            all_scores.append(lv_scores.sum())\n            \n        self.all_scores = all_scores\n\n        return np.mean(all_scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preparing prediction dataset in wide format, and then evaluating it."},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_pred_df = sales_mlt.loc[valid_filter, ['item_id','store_id', 'd']]\nvalid_pred_df['pred'] = valid_pred\nvalid_pred_df = valid_pred_df.set_index(['item_id','store_id','d']).unstack()\nvalid_pred_df.columns = valid_pred_df.columns.droplevel()\nvalid_cols = list(sales.columns[-28:])\nvalid_pred_df = valid_pred_df.loc[zip(sales.item_id, sales.store_id), valid_cols]\n\ntrain_df = sales.iloc[:, :-28]\nvalid_df = sales.iloc[:, -28:]\n\nevaluator = WRMSSEEvaluator(train_df, valid_df, calendar, prices)\nWRMSSEE = evaluator.score(valid_pred_df.values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating Dashboard\nThe dashboard shows WRMSSE at each aggregation level (12 levels total) in the top. In the following sections, it shows RMSSE and weights on each component at each aggregation level along with time series visualizations on each corresponding element. As level 7-12 have too many elements to show the time series viz, it just shows the first 9 elements on each level. Please note the weights shown in this viz is level-wise weights not divided by the number of levels (12).\n\nIf you are not familiar with the evaluation metric, you can find all the details in [the official doc](https://mk0mcompetitiont8ake.kinstacdn.com/wp-content/uploads/2020/02/M5-Competitors-Guide_Final-1.pdf).\n\nThe function below (create_dashboard) just accepts evaluator class object from WRMSSEEvaluator and it will create all the visualizations for you."},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_viz_df(df,lv):\n    \n    df = df.T.reset_index()\n    if lv in [6,7,8,9,11,12]:\n        df.columns = [i[0] + '_' + i[1] if i != ('index','') \\\n                      else i[0] for i in df.columns]\n    df = df.merge(calendar.loc[:, ['d','date']], how='left', \n                  left_on='index', right_on='d')\n    df['date'] = pd.to_datetime(df.date)\n    df = df.set_index('date')\n    df = df.drop(['index', 'd'], axis=1)\n    \n    return df\n\ndef create_dashboard(evaluator):\n    \n    wrmsses = [np.mean(evaluator.all_scores)] + evaluator.all_scores\n    labels = ['Overall'] + [f'Level {i}' for i in range(1, 13)]\n\n    ## WRMSSE by Level\n    plt.figure(figsize=(12,5))\n    ax = sns.barplot(x=labels, y=wrmsses)\n    ax.set(xlabel='', ylabel='WRMSSE')\n    plt.title('WRMSSE by Level', fontsize=20, fontweight='bold')\n    for index, val in enumerate(wrmsses):\n        ax.text(index*1, val+.01, round(val,4), color='black', \n                ha=\"center\")\n        \n    # configuration array for the charts\n    n_rows = [1, 1, 4, 1, 3, 3, 3, 3, 3, 3, 3, 3]\n    n_cols = [1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n    width = [7, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n    height = [4, 3, 12, 3, 9, 9, 9, 9, 9, 9, 9, 9]\n    \n    for i in range(1,13):\n        \n        scores = getattr(evaluator, f'lv{i}_scores')\n        weights = getattr(evaluator, f'lv{i}_weight')\n        \n        if i > 1 and i < 9:\n            if i < 7:\n                fig, axs = plt.subplots(1, 2, figsize=(12, 3))\n            else:\n                fig, axs = plt.subplots(2, 1, figsize=(12, 8))\n                \n            ## RMSSE plot\n            scores.plot.bar(width=.8, ax=axs[0], color='g')\n            axs[0].set_title(f\"RMSSE\", size=14)\n            axs[0].set(xlabel='', ylabel='RMSSE')\n            if i >= 4:\n                axs[0].tick_params(labelsize=8)\n            for index, val in enumerate(scores):\n                axs[0].text(index*1, val+.01, round(val,4), color='black', \n                            ha=\"center\", fontsize=10 if i == 2 else 8)\n            \n            ## Weight plot\n            weights.plot.bar(width=.8, ax=axs[1])\n            axs[1].set_title(f\"Weight\", size=14)\n            axs[1].set(xlabel='', ylabel='Weight')\n            if i >= 4:\n                axs[1].tick_params(labelsize=8)\n            for index, val in enumerate(weights):\n                axs[1].text(index*1, val+.01, round(val,2), color='black', \n                            ha=\"center\", fontsize=10 if i == 2 else 8)\n                    \n            fig.suptitle(f'Level {i}: {evaluator.group_ids[i-1]}', size=24 ,\n                         y=1.1, fontweight='bold')\n            plt.tight_layout()\n            plt.show()\n\n        trn = create_viz_df(getattr(evaluator, f'lv{i}_train_df')\\\n                            .iloc[:, -28*3:], i)\n        val = create_viz_df(getattr(evaluator, f'lv{i}_valid_df'), i)\n        pred = create_viz_df(getattr(evaluator, f'lv{i}_valid_preds'), i)\n\n        n_cate = trn.shape[1] if i < 7 else 9\n\n        fig, axs = plt.subplots(n_rows[i-1], n_cols[i-1], \n                                figsize=(width[i-1],height[i-1]))\n        if i > 1:\n            axs = axs.flatten()\n\n        ## Time series plot\n        for k in range(0, n_cate):\n\n            ax = axs[k] if i > 1 else axs\n\n            trn.iloc[:, k].plot(ax=ax, label='train')\n            val.iloc[:, k].plot(ax=ax, label='valid')\n            pred.iloc[:, k].plot(ax=ax, label='pred')\n            ax.set_title(f\"{trn.columns[k]}  RMSSE:{scores[k]:.4f}\", size=14)\n            ax.set(xlabel='', ylabel='sales')\n            ax.tick_params(labelsize=8)\n            ax.legend(loc='upper left', prop={'size': 10})\n\n        if i == 1 or i >= 9:\n            fig.suptitle(f'Level {i}: {evaluator.group_ids[i-1]}', size=24 , \n                         y=1.1, fontweight='bold')\n        plt.tight_layout()\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_dashboard(evaluator)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}