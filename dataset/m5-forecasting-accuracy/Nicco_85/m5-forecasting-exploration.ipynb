{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# Source: https://www.kaggle.com/nictosi/m5-forecasting-starter-data-exploration/edit\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\nfrom itertools import cycle\npd.set_option('max_columns', 50)\nplt.style.use('bmh')\ncolor_pal = plt.rcParams['axes.prop_cycle'].by_key()['color']\ncolor_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Some useful functions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# RSME\nfrom sklearn.metrics import mean_squared_error\ndef rmse(y_true, y_pred):\n    return np.sqrt(mean_squared_error(y_true, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read in the data\nINPUT_DIR = '../input/m5-forecasting-accuracy'\ncal = pd.read_csv(f'{INPUT_DIR}/calendar.csv')\nstv = pd.read_csv(f'{INPUT_DIR}/sales_train_validation.csv')\nss = pd.read_csv(f'{INPUT_DIR}/sample_submission.csv')\nsellp = pd.read_csv(f'{INPUT_DIR}/sell_prices.csv')\nss = ss.set_index('id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Add new 'item_store_id' column and set it as index","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"stv['item_store_id'] = stv['item_id'] + '_'+  stv['store_id']\nstv = stv.set_index('item_store_id')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Merge date from calendar and create past_sales DF with date as index\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"d_cols = [c for c in stv.columns if 'd_' in c] # sales data columns\npast_sales = stv[d_cols] \\\n    .T \\\n    .merge(cal.set_index('d')['date'],\n           left_index=True,\n           right_index=True,\n            validate='1:1') \\\n    .set_index('date')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plot single item","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_single_product(item_store_id):\n    d_cols = [c for c in stv.columns if 'd_' in c] # sales data columns\n\n    # Below we are chaining the following steps in pandas:\n    stv.loc[item_store_id] \\\n        [d_cols[-365:]] \\\n        .T \\\n        .plot(figsize=(15, 5),\n              title=item_store_id  + ' sales by \"d\" number',\n              color=next(color_cycle))\n    plt.legend('')\n    plt.show()\n    \nplot_single_product('FOODS_3_120_CA_3')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Compute additional variables to have more insight on the variability of each item","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"feat = stv.copy()\nfeat['Mean'] = np.mean(feat,axis=1)\nfeat['Std'] = np.std(feat,axis=1)\nfeat['Total'] = np.sum(feat,axis=1)\nfeat = feat.sort_values(['Total'], ascending=False)\n#feat = feat.set_index('item_store_id')\nfeat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(40,10))  \nplt.scatter(feat['Mean'],np.log(feat['Std']/feat['Mean']),marker = 'd', s=3)\nplt.ylabel('log(Std/Mean)')\nplt.xlabel('Mean')\nax.set_xlim(0,20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Explore sales by cat","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in stv['cat_id'].unique():\n    items_col = [c for c in past_sales.columns if i in c]\n    past_sales[items_col] \\\n        .sum(axis=1) \\\n        .plot(figsize=(15, 5),\n              alpha=0.8,\n              title='Total Sales by Item Category')\nplt.legend(stv['cat_id'].unique())\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction with Ridge regression and time shift","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n\nmodel = Ridge()\ndef ridge_predict2(data, label, predicted_days = 30, n_days_back=60, verbose = False):\n    \n    if (verbose):\n        print('Fitting ' + label + \" ...\")\n    \n    # format ucdata and extend dates to the \n    ucdata = pd.DataFrame(data.copy())\n    ucdata['date'] = pd.to_datetime(ucdata.index)\n    \n    ucdata = ucdata.append(pd.DataFrame({'date': pd.date_range(start=ucdata.index[-1], periods=predicted_days, freq='D', closed='right')}), sort=True)\n    ucdata = ucdata.set_index('date')\n    \n    # compute shifts\n    shifts = np.arange(predicted_days,predicted_days+n_days_back)\n    for i in shifts:\n        ucdata['lag_{}'.format(i)] = ucdata[label].shift(i).fillna(0)\n    \n    Y = ucdata[label]\n    ucdata = ucdata.drop(label,1)\n    \n    ## fit ridge regression\n    X_train = ucdata[:-predicted_days]\n    X_test = ucdata[-predicted_days:]\n    y_train = Y[:-predicted_days]\n    y_test = Y[-predicted_days:]\n    ground_truth = Y[-predicted_days:]\n    model.fit(X_train, y_train)\n    pred = model.predict(X_test)\n    pred[pred<0] = 0\n    \n    \n    if(verbose):\n        fig, ax = plt.subplots(figsize=(40, 5))\n        plt.title(\"Prediction of \" + label + \" with Ridge regression looking \" + str(n_days_back) + \" days back\")\n        plt.plot(X_train.index, y_train, color='b', label='train set')\n        plt.plot(X_train.index, model.predict(X_train), color='c', label='prediction on train set')\n        plt.plot(X_test.index, pred, color='r', label='future prediction')\n        plt.legend()\n        plt.xticks(rotation=90)\n    \n    \n    \n    return pred\n \ndef avg_predict(data, label, predicted_days = 30, n_days_back=60, verbose = False):\n        pred = np.ones(predicted_days) * np.nanmean(data[-28:]) # preding with avg\n        \n        if(verbose):\n            fig, ax = plt.subplots(figsize=(40, 5))\n            plt.title(\"Prediction of \" + label + \" with Ridge regression looking \" + str(n_days_back) + \" days back\")\n            plt.plot(data[:-predicted_days].index, data[:-predicted_days].values, color='b', label='train set')\n            plt.plot(data[-predicted_days:].index, pred, color='r', label='future prediction')\n            plt.legend()\n            plt.xticks(rotation=90)\n            \n        return pred","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test of prediction time","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# timer test\nimport time\n\nn = 10\ntimelist = []\nfor i in np.arange(0,n):\n    tic = time.perf_counter()  \n    item = feat.index[i]\n    print(item)\n    ucdata_raw = past_sales[item][-365:].interpolate('linear')\n    ridge_predict2(ucdata_raw, item, 28,120,False)\n    toc = time.perf_counter()\n    timelist.append(toc-tic)    \n    \navg_time = np.mean(timelist) \nprint(f\"average time: {avg_time:0.3f}s\")    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Compute predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#save submission for d_1914 - d_1941\nfrom datetime import timedelta  \nfrom datetime import datetime\nimport math\n\ndays_to_predict = 28\nitems_to_predict = 3 # set to inf if you want to predict the whole dataset\nzero_threshold = 0.3 # percentage of zero values in the train set to activate the baseline prediction\nsub = pd.DataFrame(ss.copy())\n#sub = sub.set_index('id')\n\nitems = [i.replace('_validation','') for i in sub.index[sub.index.str.contains(\"validation\")]]\n\ntot_items = np.min([items_to_predict, len(items)])\nprint('predicting: ' + str(tot_items) + ' items')\ncount = 0\ncount_avg = 0\ncount_ridge = 0\nfor prod in items[0: tot_items]:    \n    if(count % 5000 == 0):\n        print('Predicting ... ' + str(count) + \" / \" + str(items_to_predict) + ' completed')\n        print(f'ETA: {avg_time * (items_to_predict - count):0.4f}s')\n       \n    try:\n        ucdata_raw = past_sales[prod][-365:]\n        if((ucdata_raw.values == 0).sum() > zero_threshold * len(ucdata_raw)):\n            pred = avg_predict(ucdata_raw, prod, days_to_predict,120, True)\n            count_avg += 1\n        else:        \n            # predict next month\n            ucdata = ucdata_raw.interpolate('linear')\n            pred = ridge_predict2(ucdata, prod, days_to_predict,120, True) \n            count_ridge += 1\n        \n        for i in np.arange(0,days_to_predict):\n            sub.loc[prod + '_validation','F' + str(i+1)] = pred[i]        \n    except:\n          print(\"issue with item \" + prod)\n       \n    count += 1\n\nprint(str(count_ridge) + ' items predicted with Ridge')\nprint(str(count_avg) + ' items predicted with avg baseline')\n\nfilename = 'submission_ridge' + str(datetime.now()) + \"_zero_th_\" + str(zero_threshold) + '.csv'\nprint('saving ' + filename)\nsub.to_csv(filename, index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# quantify error and order by error\nimport random\n\nverbose = False\n\nitems_to_predict = 2\nprint('predicting: ' + str(items_to_predict) + ' items')\n\nitems = [i for i in feat.index]\nrandom.shuffle(items)\n\nres = pd.DataFrame(columns=['prod' , 'ridge_rmse', 'baseline_rmse', 'zeros_perc' , 'mean' , 'std'])\n\ncount = 0\nfor prod in items[0:items_to_predict]:\n    if(count % 1000 == 0):\n        print('Comparing items ... ' + str(count) + \" / \" + str(items_to_predict) + ' completed') \n        \n    d = past_sales[prod][-365:-28]\n    actual = past_sales[prod][-28:]\n        \n    # predict next month\n    baseline = np.ones(days_to_predict) * np.mean(d[-28:])\n    pred = ridge_predict2(d, prod, days_to_predict,120, False)   \n    zeros_perc = (d.values == 0).sum()/ len(d)\n    avg = np.nanmean(d.values)\n    std = np.nanstd(d.values)\n    \n    rms = rmse(pred, actual)\n    blrms = rmse(baseline, actual)   \n    res = res.append({'prod' : prod , 'ridge_rmse' : rms, 'baseline_rmse' : blrms, 'zeros_perc' : zeros_perc, 'mean' : avg, 'std' : std} , ignore_index=True)\n    count +=1\n    \nres['ridge-baseline'] = res['ridge_rmse'] - res['baseline_rmse']    \nprint('done!')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sp = sellp.copy()\nsp = sp[sp['wm_yr_wk'] == np.max(sp['wm_yr_wk'])]\nsp['item_store_id'] = sp['item_id'] +'_' +  sp['store_id']\nres = pd.merge(res,sp[['item_store_id','sell_price']], how='inner', left_on='prod', right_on = 'item_store_id' )\nres.to_csv('error_analysis.csv', index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot error analysis\nfig, ax = plt.subplots(figsize=(40, 20))\nplt.scatter(res['ridge_rmse'], res['sell_price_x']*res['mean'],marker='o')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate_wrmsse(y_train, y_test, y_pred, sell_prices):\n    y_train_weight = y_train.iloc[:,-30:].sum(axis = 1)\n    sell_prices_weight = sell_prices[sell_prices.wm_yr_wk == 11621] # imprecise, I'm assuming same price last 5 weeks\n    weights = y_train_weight.to_numpy() * sell_prices_weight.sell_price.to_numpy()\n    weights_sum = sum(weights)\n    weights = [x/weights_sum for x in weights]\n    numerators = [np.sum((y_test.iloc[i,:].to_numpy() - y_pred.iloc[i,:].to_numpy())**2) for i in range(y_test.shape[0])]\n    rmsse = [np.sqrt(1/30 * numerators[i] / denominators[i]) for i in range(len(numerators))]\n    wrmsse = np.sum(np.array(weights) * np.array(rmsse))\n    return wrmsse\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Simple submission","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}