{"cells":[{"metadata":{},"cell_type":"markdown","source":"# NOTEBOOK CONTENTS\n1. Data visualization\n2. Noise reduction Tehniques\n3. Comparison between SARIMA and NN"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom pandas_profiling import ProfileReport\n\nfrom scipy import signal\nfrom scipy.signal import butter, deconvolve\nimport pywt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sample_submission.csv')\ndt.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dates = [d for d in df.columns if 'd_' in d]\nprint('dates in the training set: ', dates[:5], ' ... ', dates[-5:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**We need to predcit for every item id the next n dates.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = sorted(list(set(df['id'])))\n\nall_sales = df[dates].sum(axis=0).values\n\nx1_sales = (df['store_id'] == 'CA_2').values\nx1_sales = np.where(x1_sales == True)\nx1_sales = df.iloc[x1_sales[0]][dates].sum(axis=0).values\n\nx2_sales = df.loc[df['id'] == ids[2]].set_index('id')[dates].values[0]\n\nfig, ax = plt.subplots(3, figsize=(15,15))\nax[0].plot([x for x in range(len(all_sales))], all_sales, 'tab:green')\nax[0].set_title('All sales / day')\nax[0].set(xlabel='days', ylabel='sales')\n\nax[1].plot([x for x in range(len(x1_sales))], x1_sales, 'tab:red')\nax[1].set_title('Sales of a store / day')\nax[1].set(xlabel='days', ylabel='sales')\n\nax[2].plot([x for x in range(len(x2_sales))], x2_sales, 'tab:blue')\nax[2].set_title('Sales of an item / day')\nax[2].set(xlabel='days', ylabel='sales')\n\nfig.tight_layout()\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reducing noise\n1. Fast Fourier Transform"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.fftpack import fft, ifft","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def maxN(elements, n):\n    return sorted(elements, reverse=True)[:n]\ndef apply_fft(data, n):\n    fourier = fft(data)\n    power = [int((abs(x) ** (2 / fourier.shape[0])) * 1000) for x in fourier]\n    limit  = min(maxN(power, n))\n    for i in range(fourier.shape[0]):\n        if (power[i] < limit):\n            fourier[i] = 0\n    inv_fourier = ifft(fourier).real\n    return inv_fourier\n\nfft_sales_small = apply_fft(x2_sales, 5)\nfft_sales_medium = apply_fft(x2_sales, 10)\nfig, ax = plt.subplots(2, figsize=(15,10))\nax[0].plot([x for x in range(len(fft_sales_small))], fft_sales_small, 'coral')\nax[0].set_title('FFT with high noise reduction for the second graph above')\nax[0].set(xlabel='days', ylabel='sales')\n\nax[1].plot([x for x in range(len(fft_sales_medium))], fft_sales_medium, 'crimson')\nax[1].set_title('FFT with medium noise reduction for the second graph above')\nax[1].set(xlabel='days', ylabel='sales')\n\nfig.tight_layout()\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. Moving Averages"},{"metadata":{"trusted":true},"cell_type":"code","source":"rolling_mean1 = pd.DataFrame({'y':x1_sales})\nrolling_mean1 = rolling_mean1.y.rolling(window=14).mean()\n\nrolling_mean2 = pd.DataFrame({'y':x2_sales})\nrolling_mean2 = rolling_mean2.y.rolling(window=20).mean()\n\nrolling_mean3 = pd.DataFrame({'y':all_sales})\nrolling_mean3 = rolling_mean3.y.rolling(window=20).mean()\n\nprint('The graphs below are the first 3 graphs with MA noise reduction')\n\nfig, ax = plt.subplots(3, figsize=(15,15))\nax[0].plot([x for x in range(len(rolling_mean3))], rolling_mean3, 'coral')\nax[0].set_title('Moving averages noise reduction')\nax[0].set(xlabel='days', ylabel='sales')\n\nax[1].plot([x for x in range(len(rolling_mean1))], rolling_mean1, 'crimson')\nax[1].set_title('Moving averages noise reduction')\nax[1].set(xlabel='days', ylabel='sales')\n\nax[2].plot([x for x in range(len(rolling_mean2))], rolling_mean2, 'tomato')\nax[2].set_title('Moving averages noise reduction')\nax[2].set(xlabel='days', ylabel='sales')\n\nfig.tight_layout()\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. Wave denoising <br>\n**from this awesome notebook -** https://www.kaggle.com/tarunpaparaju/m5-competition-eda-models"},{"metadata":{"trusted":true},"cell_type":"code","source":"def maddest(d, axis=None):\n    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n\ndef denoise_signal(x, wavelet='db4', level=1):\n    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n    sigma = (1/0.45) * maddest(coeff[-level])\n\n    uthresh = sigma * np.sqrt(2*np.log(len(x)))\n    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n\n    return pywt.waverec(coeff, wavelet, mode='per')\n\ny_w1 = denoise_signal(all_sales)\ny_w2 = denoise_signal(x1_sales)\ny_w3 = denoise_signal(x2_sales)\n\nprint('The graphs below are the first 3 graphs with Wave denoising')\n\nfig, ax = plt.subplots(3, figsize=(15,15))\nax[0].plot([x for x in range(len(y_w1))], y_w1, 'coral')\nax[0].set_title('Wave denoising noise reduction')\nax[0].set(xlabel='days', ylabel='sales')\n\nax[1].plot([x for x in range(len(y_w2))], y_w2, 'crimson')\nax[1].set_title('Wave denoising noise reduction')\nax[1].set(xlabel='days', ylabel='sales')\n\nax[2].plot([x for x in range(len(y_w3))], y_w3, 'tomato')\nax[2].set_title('Wave denoising noise reduction')\nax[2].set(xlabel='days', ylabel='sales')\n\nfig.tight_layout()\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"item_1 = df.iloc[1].values[6:]\nitem_1_pred = dt.iloc[1].values[1:]\nfig, ax = plt.subplots(1, figsize=(15,5))\nax.plot(([x for x in range(len(item_1))]+[x for x in range(len(item_1_pred))]), np.hstack((item_1,item_1_pred)), 'blue')\nax.axvspan(len(item_1), (len(item_1)+len(item_1_pred)), color='red', alpha=0.4)\nax.set(xlabel='days', ylabel='sales')\nax.set_title('We need to predict the sales in the red line')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<hr>\n# Forecasting Methods\n1. SARIMA\n<hr>"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pmdarima\nfrom pmdarima import auto_arima","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = auto_arima(item_1[-300:-14], seasonal=True, m=14)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **I only selected the last 300 time steps for the sarima model as it takes a pretty long time to fit the model on the entire data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, figsize=(15,5))\nax.plot([x for x in range(300)], item_1[-300:], 'blue', label='Item sales')\nax.plot([x for x in range(300+len(item_1_pred))], np.hstack((model.predict_in_sample(),model.predict(14), model.predict(14+len(item_1_pred))[14:])), 'orange', label='Sarima prediction')\nax.axvspan((300-14), 300, color='green', alpha=0.4, label='test set')\nax.axvspan(300, 300+len(item_1_pred), color='red', alpha=0.2, label='prediction')\nax.legend(loc=\"upper left\")\nax.set(xlabel='days', ylabel='sales')\nax.set_title('Iteam sales and sarima prediction')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\ndef measure_mse(actual, predicted):\n    return mean_squared_error(actual, predicted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('the score (mse)  of the model is: ', measure_mse(item_1[-14:],model.predict(14)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. Simple Neural Network Model ( CNN + LSTM + Dense )"},{"metadata":{"trusted":true},"cell_type":"code","source":"from math import sqrt\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Conv1D\nfrom keras.layers.convolutional import MaxPooling1D","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_test_split(data, n_test):\n    return data[:-n_test], data[-n_test:]\n\ndef series_to_supervised(data, n_in, n_out=1):\n    df = pd.DataFrame(data)\n    cols = list()\n\n    for i in range(n_in, 0, -1):\n        cols.append(df.shift(i))\n\n    for i in range(0, n_out):\n        cols.append(df.shift(-i))\n\n    agg = pd.concat(cols, axis=1)\n\n    agg.dropna(inplace=True)\n    return agg.values\n\ndef prepare_dataset(train, n_input):\n    data = series_to_supervised(train, n_input)\n    train_x, train_y = data[:, :-1], data[:, -1]\n    train_x = train_x.reshape((train_x.shape[0], train_x.shape[1], 1))\n    return train_x, train_y\n    \ndef model_fit(train, config):\n    n_input, n_filters, n_kernel, n_epochs, n_batch = config\n    train_x, train_y = prepare_dataset(train, n_input)\n    \ndef model_predict(model, history, config):\n    \n    n_input, _, _, _, _ = config\n    \n    x_input = np.array(history[-n_input:]).reshape((1, n_input, 1))\n    \n    yhat = model.predict(x_input, verbose=0)\n    return yhat[0]\n\ndef predict_next_n(model, history, config, n):\n    n_input, _, _, _, _ = config\n    pred = []\n    for i in range(n):\n        x_input = np.array(history[-n_input:]).reshape((1, n_input, 1))\n\n        yhat = model.predict(x_input, verbose=0)\n        pred.append(yhat[0][0])\n        history.append(yhat[0][0])\n    return pred\n\ndef walk_forward_validation(data, n_test, cfg):\n    predictions = list()\n\n    train, test = train_test_split(data, n_test)\n\n    model = model_fit(train, cfg)\n\n    history = [x for x in train]\n\n    for i in range(len(test)):\n        yhat = model_predict(model, history, cfg)\n        predictions.append(yhat)\n        history.append(test[i])\n    error = measure_mse(test, predictions)\n    print(' > %.3f' % error)\n    return [error, model]\n\ndef repeat_evaluate(data, config, n_test, n_repeats=1):\n    for _ in range(n_repeats):\n        return_list = walk_forward_validation(data, n_test, config)\n        scores = return_list[0]\n    return scores, return_list[1]\n\n\ndef prepare_dataset_no_y(train, n_input):\n    data_prep = series_to_supervised(train, n_input)\n    data_prep = data_prep.reshape((data_prep.shape[0], data_prep.shape[1], 1))\n    return data_prep\n\ndef model_fit(train, config):\n    n_input, n_filters, n_kernel, n_epochs, n_batch = config\n    train_x, train_y = prepare_dataset(train, n_input)\n    \n    model = Sequential()\n    model.add(Conv1D(filters=n_filters, kernel_size=n_kernel, activation='relu', input_shape=(n_input, 1), padding='same'))\n    model.add(LSTM(128, activation='relu'))\n    model.add(Dense(64, activation='relu'))\n#     model.add(Conv1D(filters=n_filters, kernel_size=n_kernel, activation='relu'))\n#     model.add(MaxPooling1D(pool_size=2))\n#     model.add(Flatten())\n    model.add(Dense(1))\n    model.compile(loss='mse', optimizer='adam')\n    model.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=0)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = item_1[-300:]\nn_input = 7\nn_test = 14\nconfig = [n_input, 256, 3, 400, 300]\nscores, model_cnn = repeat_evaluate(data, config, n_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('the score (mse)  of the model is: ',scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_x = series_to_supervised(data, n_in=(n_input-1), n_out=1)\ntest_x = test_x.reshape((test_x.shape[0], test_x.shape[1], 1))\n\nx = np.arange(n_input, dtype=int)\n\npred = predict_next_n(model_cnn, data.tolist(), config, len(item_1_pred))\n\nfig, ax = plt.subplots(1, figsize=(15,5))\nax.plot(data, color = 'blue')\nax.plot(np.vstack((np.zeros_like(x).reshape(-1,1),model_cnn.predict(test_x).reshape(-1,1), np.array(pred).reshape(-1,1))), color='orange')\nax.axvspan((len(data)-14), len(data), color='green', alpha=0.4, label='test set')\nax.axvspan((len(data)), len(data)+len(item_1_pred), color='red', alpha=0.2, label='prediction')\nax.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Even though SARIMA may have better mse, the CNN + LSTM model seems to make better predictions and fit better on the data"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}