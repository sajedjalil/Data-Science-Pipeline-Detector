{"cells":[{"metadata":{},"cell_type":"markdown","source":"# M5 CatBoost Demo"},{"metadata":{},"cell_type":"markdown","source":"This notebook is highly inspired by this work [M5 First Public Notebook Under 0.50](https://www.kaggle.com/kneroma/m5-first-public-notebook-under-0-50), but with [CatBoost](https://catboost.ai/)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport gc\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, timedelta\nfrom catboost import Pool, CatBoostRegressor\npd.set_option('display.max_columns', None)\nfrom catboost.utils import get_gpu_device_count\nfrom tqdm.notebook import tqdm\nprint('available GPU devices catboost:', get_gpu_device_count())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"DATA_DIR = '/kaggle/input/m5-forecasting-accuracy'\nMODEL_VER = 'v0'\nBACKWARD_LAGS = 60\nEND_D = 1913\nCUT_D = END_D - int(365 * 1.2)\nEND_DATE = '2016-04-24'\nprint(datetime.strptime(END_DATE, '%Y-%m-%d'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data load and process functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"CALENDAR_DTYPES = {\n    'date':             'str',\n    'wm_yr_wk':         'int16', \n    'weekday':          'object',\n    'wday':             'int16', \n    'month':            'int16', \n    'year':             'int16', \n    'd':                'object',\n    'event_name_1':     'object',\n    'event_type_1':     'object',\n    'event_name_2':     'object',\n    'event_type_2':     'object',\n    'snap_CA':          'int16', \n    'snap_TX':          'int16', \n    'snap_WI':          'int16'\n}\nPARSE_DATES = ['date']\nSPRICES_DTYPES = {\n    'store_id':    'object', \n    'item_id':     'object', \n    'wm_yr_wk':    'int16',  \n    'sell_price':  'float32'\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_df(is_train=True, backward_lags=None):\n    strain = pd.read_csv('{}/sales_train_validation.csv'.format(DATA_DIR))\n    print('read train:', strain.shape)\n    cat_cols = ['id', 'item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n    last_day = int(strain.columns[-1].replace('d_', ''))\n    print('first day is:', CUT_D)\n    print('last day is:', last_day)\n    if not is_train:\n        for day in range(last_day + 1, last_day + 28 + 28 + 1):\n            strain['d_{}'.format(day)] = np.nan\n        value_vars = [col for col in strain.columns \n                      if (col.startswith('d_') and (int(col.replace('d_', '')) >= END_D - backward_lags))]\n    else:\n        value_vars = [col for col in strain.columns \n                      if (col.startswith('d_') and (int(col.replace('d_', '')) >= CUT_D))]\n    strain = pd.melt(\n        strain,\n        id_vars = cat_cols,\n        value_vars = value_vars,\n        var_name = 'd',\n        value_name = 'sales'\n    )\n    print('melted train:', strain.shape)\n    calendar = pd.read_csv('{}/calendar.csv'.format(DATA_DIR), dtype=CALENDAR_DTYPES, parse_dates=PARSE_DATES)\n    print('read calendar:', calendar.shape)\n    strain = strain.merge(calendar, on='d', copy=False)\n    del calendar\n    gc.collect()\n    print('calendar merge done')\n    sprices = pd.read_csv('{}/sell_prices.csv'.format(DATA_DIR), dtype=SPRICES_DTYPES)\n    print('read prices:', sprices.shape)\n    strain = strain.merge(\n        sprices, \n        on=['store_id', 'item_id', 'wm_yr_wk'], \n        copy=False\n    )\n    del sprices\n    gc.collect()\n    print('prices merge done')\n    print('begin train date:', strain['date'].min())\n    print('end train date:', strain['date'].max())\n    if not is_train:\n        strain = strain.loc[\n            strain['date'] >= (datetime.strptime(END_DATE, '%Y-%m-%d') - timedelta(days=backward_lags))\n        ]\n    print('date cut train:', strain.shape)\n    print('cut train date:', strain['date'].min())\n    print('end train date:', strain['date'].max())\n    return strain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_features(strain):\n    print('in dataframe:', strain.shape)\n    lags = [7, 28]\n    windows= [7, 28]\n    wnd_feats = ['id', 'item_id']\n    lag_cols = ['lag_{}'.format(lag) for lag in lags ]\n    for lag, lag_col in zip(lags, lag_cols):\n        strain[lag_col] = strain[['id', 'sales']].groupby('id')['sales'].shift(lag)\n    print('lag sales done')\n    for wnd_feat in wnd_feats:\n        for wnd in windows:\n            for lag_col in lag_cols:\n                wnd_col = '{}_{}_rmean_{}'.format(lag_col, wnd_feat, wnd)\n                strain[wnd_col] = strain[[wnd_feat, lag_col]].groupby(wnd_feat)[lag_col].transform(\n                    lambda x: x.rolling(wnd).mean()\n                )\n        print('rolling mean sales for feature done:', wnd_feat)\n    date_features = {\n        'week_num': 'weekofyear',\n        'quarter': 'quarter',\n        'mday': 'day'\n    }\n    for date_feat_name, date_feat_func in date_features.items():\n        strain[date_feat_name] = getattr(strain['date'].dt, date_feat_func).astype('int16')\n    print('date features done')\n    strain['d'] = strain['d'].apply(lambda x: int(x.replace('d_', '')))  \n    print('out dataframe:', strain.shape)\n    return strain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nstrain = get_df(is_train=True, backward_lags=None)\nstrain = make_features(strain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_cols = ['id', 'sales', 'date', 'wm_yr_wk', 'weekday']\ntrain_cols = strain.columns[~strain.columns.isin(drop_cols)]\ncat_cols = [\n    'item_id', 'dept_id', 'store_id', 'cat_id', 'state_id', \n    'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2'\n]\nstrain[cat_cols] = strain[cat_cols].fillna(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CatBoost Pool and Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nval_size = int(strain.shape[0] * .15)\nval_idxs = np.random.choice(strain.index.values, val_size, replace=False)\ntrain_idxs = np.setdiff1d(strain.index.values, val_idxs)\ntrain_pool = Pool(\n    strain.loc[train_idxs][train_cols], \n    strain.loc[train_idxs]['sales'],\n    cat_features=cat_cols\n)\nval_pool = Pool(\n    strain.loc[val_idxs][train_cols], \n    strain.loc[val_idxs]['sales'],\n    cat_features=cat_cols\n)\ndel strain\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CatBoost is RAM expensive so I prefer to utilize GPU:"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CatBoostRegressor(\n    iterations=1000,\n    task_type='GPU',\n    verbose=0,\n    loss_function='RMSE',\n    boosting_type='Plain', #use to overcome the “Out of memory” error when training on GPU \n    depth=8,\n    #gpu_cat_features_storage='CpuPinnedMemory', #use to overcome the “Out of memory” error when training on GPU \n    #max_ctr_complexity=2 #use to overcome the “Out of memory” error when training on GPU \n)\nmodel.fit(\n    train_pool,\n    eval_set = val_pool,\n    plot=True   \n)\ndel train_pool, val_pool\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_model('model_{}.cbm'.format(MODEL_VER))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Importances"},{"metadata":{"trusted":true},"cell_type":"code","source":"feat_importances = sorted(\n    [(f, v) for f, v in zip(train_cols, model.get_feature_importance())],\n    key=lambda x: x[1],\n    reverse=True\n)\nthreshold = .25\nlabels = [x[0] for x in feat_importances if x[1] > threshold]\nvalues = [x[1] for x in feat_importances if x[1] > threshold]\nfig, ax = plt.subplots(figsize=(8, 8))\ny_pos = np.arange(len(labels))\nax.barh(y_pos, values)\nax.set_yticks(y_pos)\nax.set_yticklabels(labels)\nax.invert_yaxis()\nax.set_xlabel('Performance')\nax.set_title('feature importances')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction Loop"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nspred = get_df(is_train=False, backward_lags=BACKWARD_LAGS)\nfor pred_day in tqdm(range(1, 28 + 28 + 1)):\n    pred_date = datetime.strptime(END_DATE, '%Y-%m-%d') + timedelta(days=pred_day)\n    pred_date_back = pred_date - timedelta(days=BACKWARD_LAGS + 1)\n    print('-' * 70)\n    print('forecast day forward:', pred_day, '| forecast date:', pred_date) \n    spred_data = spred[(spred['date'] >= pred_date_back) & (spred['date'] <= pred_date)].copy()\n    spred_data = make_features(spred_data)\n    spred_data = spred_data.loc[spred['date'] == pred_date, train_cols]\n    spred_data[cat_cols] = spred_data[cat_cols].fillna(0)\n    spred.loc[spred['date'] == pred_date, 'sales'] = model.predict(spred_data)\ndel spred_data\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"spred_subm = spred.loc[spred['date'] > END_DATE, ['id', 'd', 'sales']].copy()\nlast_d = int(spred.loc[spred['date'] == END_DATE, 'd'].unique()[0].replace('d_', ''))\nprint('last d num:', last_d)\nspred_subm['d'] = spred_subm['d'].apply(lambda x: 'F{}'.format(int(x.replace('d_', '')) - last_d))\nspred_subm.loc[spred_subm['sales'] < 0, 'sales'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f_cols = ['F{}'.format(x) for x in range(1, 28 + 28 + 1)]\nspred_subm = spred_subm.set_index(['id', 'd']).unstack()['sales'][f_cols].reset_index()\nspred_subm.fillna(0, inplace=True)\nspred_subm.sort_values('id', inplace=True)\nspred_subm.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f_cols_val = ['F{}'.format(x) for x in range(1, 28 + 1)]\nf_cols_eval = ['F{}'.format(x) for x in range(28 + 1, 28 + 28 + 1)]\nspred_subm_eval = spred_subm.copy()\nspred_subm.drop(columns=f_cols_eval, inplace=True)\nspred_subm_eval.drop(columns=f_cols_val, inplace=True)\nspred_subm_eval.columns = spred_subm.columns\nspred_subm_eval['id'] = spred_subm_eval['id'].str.replace('validation', 'evaluation')\nspred_subm = pd.concat([spred_subm, spred_subm_eval], axis=0, sort=False)\nspred_subm.reset_index(drop=True, inplace=True)\nspred_subm.to_csv('submission.csv', index=False)\nprint('submission saved:', spred_subm.shape)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}