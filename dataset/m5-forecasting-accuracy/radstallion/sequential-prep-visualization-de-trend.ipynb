{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sample_submission.csv\")\nsample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data prep"},{"metadata":{},"cell_type":"markdown","source":"## n_sales"},{"metadata":{"trusted":true},"cell_type":"code","source":"dtype = {}\nfor i in range(2000):\n    dtype[f\"d_{i}\"] = np.uint16\nsales_train_validation = pd.read_csv(\n    \"/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv\",\n    dtype = dtype\n).set_index([\"cat_id\",\"id\",\"item_id\",\"dept_id\",\"store_id\",\"state_id\"])\nsales_train_validation.columns = [int(col.split(\"_\")[-1]) for col in sales_train_validation.columns]\nsales_train_validation.columns = pd.MultiIndex.from_tuples(\n    [ (\"n_sales\",i)for i in sales_train_validation.columns]\n)\nsales_train_validation.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## sell price and calendar"},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/calendar.csv\")\nsell_prices = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sell_prices.csv\",dtype={\"sell_price\":float})\n\nsell_calendar = calendar[[\"wm_yr_wk\",\"d\"]].join(sell_prices.set_index(\"wm_yr_wk\"),on=\"wm_yr_wk\")\ncalendar[\"d\"] = calendar[\"d\"].apply(lambda x : int(x.split(\"_\")[-1]))\nsell_calendar.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sell_price_calendar = pd.pivot_table(sell_calendar, values='sell_price', index=['store_id', 'item_id'],\n                    columns=['d'], aggfunc=\"last\", fill_value=0)\nsell_price_calendar.columns = [int(col.split(\"_\")[-1]) for col in sell_price_calendar.columns]\nsell_price_calendar = sell_price_calendar.sort_index(axis=1)\nsell_price_calendar.columns = pd.MultiIndex.from_tuples(\n    [ (\"sell_prices\",i)for i in sell_price_calendar.columns]\n)\n\nsell_price_calendar.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_dataset = sales_train_validation.join(sell_price_calendar,on=[\"store_id\",\"item_id\"])\nrevenue = sales_dataset[\"sell_prices\"]*sales_dataset[\"n_sales\"]\nrevenue.columns = pd.MultiIndex.from_tuples(\n    [ (\"revenue\",i)for i in revenue.columns]\n)\nsales_dataset = sales_dataset.join(revenue)\nsales_dataset.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cyclic Time data"},{"metadata":{"trusted":true},"cell_type":"code","source":"weekly = np.cos(np.array(range(2000))*2*np.pi/7)\nmonthly = np.cos(np.array(range(2000))*2*np.pi/(365.2425/12))\nyearly = np.cos(np.array(range(2000))*2*np.pi/365.2425)\nd = np.array(range(2000))\ncyclic_time = pd.DataFrame({\n    \"weekly\":weekly,\n    \"monthly\":monthly,\n    \"yearly\":yearly,\n    \"w_step\":np.array(range(2000))%7/7,\n    \"m_step\":np.array(range(2000))%(365.2425/12)/(365.2425/12),\n    \"y_step\":np.array(range(2000))%365.2425/365.2425,\n    \"d\":d\n}).set_index(\"d\")\n# cyclic_time = (cyclic_time+1)/2\ncyclic_time[\"mean\"] =cyclic_time.mean(axis=1)\ncyclic_time = cyclic_time.join(pd.get_dummies(calendar[[\"wday\",\"month\",\"d\"]].set_index(\"d\"),columns=[\"wday\",\"month\"])).fillna(0)\ncyclic_time.to_pickle(\"cyclic_time.zip.pkl\",compression=\"zip\")\ncyclic_time[[\"mean\",\"yearly\",\"monthly\"]].plot(figsize=(32/2, 9/2))\ncyclic_time.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualization\n## here we will visualize\n1. number of sales through time per catagory/state\n2. price through time per catagory/state\n3. revenue through time per catagory/state\n4. detrending"},{"metadata":{},"cell_type":"markdown","source":"## Number of Sales through time per catagory/state"},{"metadata":{"trusted":true},"cell_type":"code","source":"nsales_percata = sales_dataset[\"n_sales\"].groupby([\"cat_id\",\"state_id\"]).agg(np.mean).transpose()\n\nsales_dataset[\"n_sales\"].groupby([\"cat_id\"]).agg(np.mean).transpose().plot(figsize=(32/2, 9/2))\nplt.title(\"ALL mean n sales by cat_id\")\nfor cata in [\"FOODS\",\"HOBBIES\",\"HOUSEHOLD\"]:\n    nsales_percata[cata].plot(figsize=(32/2, 9/2))\n    plt.title(f\"{cata} mean n sales\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Find trends by fitting to linear regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfor cata in [\"FOODS\",\"HOBBIES\",\"HOUSEHOLD\"]:\n    \n    ser = nsales_percata[cata].transpose().mean()\n    reg = LinearRegression().fit(ser.index.values.reshape(-1, 1), ser.values)\n    trend = reg.predict(ser.index.values.reshape(-1, 1))\n    nsales_percata[(cata,\"trends\")] = trend\n    nsales_percata[cata].plot(figsize=(32/2, 9/2))\n    plt.title(f\"{cata} mean with trends\")\n\n    \nnsales_percata[[(\"FOODS\",\"trends\"),(\"HOBBIES\",\"trends\"),(\"HOUSEHOLD\",\"trends\")]].plot(figsize=(32/2, 9/2))\nplt.title(f\"trends for each catagoy\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm.auto import tqdm\ntqdm.pandas()\ndef apply_trend(x):\n    reg = LinearRegression().fit(x.index.values.reshape(-1, 1), x.values)\n    trend = reg.predict(x.index.values.reshape(-1, 1))\n    return trend\n\n\nn_sales_trends = sales_dataset[\"n_sales\"].copy()\nn_sales_trends[n_sales_trends.columns] = np.stack(n_sales_trends.progress_apply(apply_trend,axis=1))\n\nn_sales_detrends = sales_dataset[\"n_sales\"].copy()\nn_sales_detrends = n_sales_detrends - n_sales_trends\n\nn_sales_detrends.groupby([\"cat_id\",\"state_id\"]).agg(np.mean).transpose().plot(figsize=(32/2, 9/2))\nplt.title(f\"detrended data\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_sales_detrends.columns = pd.MultiIndex.from_tuples(\n    [ (\"n_sales_detrends\",i)for i in n_sales_detrends.columns]\n)\nn_sales_trends.columns = pd.MultiIndex.from_tuples(\n    [ (\"n_sales_trends\",i)for i in n_sales_trends.columns]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"by plotting with previously create cyclic time it is certain that sales are heavily corelated to day of week and day of month"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(32/2, 9/2))\nplt.plot(n_sales_detrends[\"n_sales_detrends\"].agg(np.mean).transpose()[-365:-1])\nplt.plot(cyclic_time[[\"weekly\",\"monthly\"]][1914-365:1914],alpha=0.5)\nplt.legend([\"average detrended nsales\",\"weekly sin t=7\",\"monthly sin t=30\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Join all preped data and save as pkl"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsales_dataset = sales_dataset.join(n_sales_detrends).join(n_sales_trends)\nsales_dataset.to_pickle(\"sales_dataset.zip.pkl\",compression=\"zip\")\nsales_dataset.columns.unique(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Models \n## Simple Regression using 1 model per item"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\n\nindex = 1\nY = sales_dataset[\"n_sales\"].iloc[index][-1000:-28]\nX = cyclic_time.loc[Y.index]\nreg = RandomForestRegressor(n_estimators=5).fit(X, Y)\n# reg = LinearRegression().fit(X, Y)\nprint(\"training\")\nprint(f\"R2 {reg.score(X, Y)}\")\nprint(f\"RMSE {np.sqrt(mean_squared_error(reg.predict(X),Y))}\")\nplt.scatter(reg.predict(X),Y.values)\n\nprint(\"validation\")\n\nY_val = sales_dataset[\"n_sales\"].iloc[index][-28:]\nX_val = cyclic_time.loc[Y_val.index]\nplt.scatter(reg.predict(X_val),Y_val.values)\nprint(f\"R2 {reg.score(X_val, Y_val)}\")\nprint(f\"RMSE {np.sqrt(mean_squared_error(reg.predict(X_val),Y_val))}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"index_list = sales_dataset[\"n_sales\"].index\n\ndef get_score_from_idx(idx):\n    Y = sales_dataset[\"n_sales\"].loc[idx][-600:-28]\n    X = cyclic_time.loc[Y.index]\n    reg = RandomForestRegressor(n_estimators=5).fit(X, Y)\n    reg = LinearRegression().fit(X, Y)\n    \n    Y_val = sales_dataset[\"n_sales\"].iloc[index][-28:]\n    X_val = cyclic_time.loc[Y_val.index]\n    return {\n        \"index\":idx,\n        \"rmse\":np.sqrt(mean_squared_error(reg.predict(X_val),Y_val))\n    }\n\nret = []\nfor idx in tqdm(index_list[:10]):\n    ret.append(get_score_from_idx(idx))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SCORE = pd.DataFrame(ret).set_index(\"index\")\nSCORE.index = pd.MultiIndex.from_tuples(\n    SCORE.index \n)\nSCORE.hist()\nSCORE.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}