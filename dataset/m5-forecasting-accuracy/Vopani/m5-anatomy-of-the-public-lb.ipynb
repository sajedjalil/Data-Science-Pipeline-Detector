{"cells":[{"metadata":{},"cell_type":"markdown","source":"## M5 Public LB\nThe true labels of the public LB have been released as announced [here](https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/155399).\n\nThis gives us a unique opportunity of deeply exploring the additional data and understanding what went right and what went wrong. This could also help in improving and optimizing the model predictions for the final private test data.\n\nThe weights used in this notebook are the weights for the public LB (validation data). Note that the private LB (evaluation data) uses a different set of weights. A summary of the weights comparison is shared here: https://www.kaggle.com/rohanrao/m5-the-weighing-scale\n\n**P.S.** Don't forget to hover over the graphs to get point-specific details.\n","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"## importing packages\nimport numpy as np\nimport pandas as pd\n\nfrom bokeh.layouts import column, row\nfrom bokeh.models import LinearAxis, Range1d, Span\nfrom bokeh.models.tools import HoverTool\nfrom bokeh.plotting import ColumnDataSource, figure, output_notebook, show\n\nfrom math import pi\nfrom typing import Union\nfrom tqdm.notebook import tqdm\n\noutput_notebook()\n\nLB_DATES = list(pd.date_range(start = \"2016-04-25\", end = \"2016-05-22\").strftime(\"%Y-%m-%d\"))\nLB_WEEKDAYS = pd.to_datetime(LB_DATES).to_series().dt.day_name()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission File\nFor the purpose of this notebook, I will use the submission from [kneroma](https://www.kaggle.com/kneroma)'s kernel: https://www.kaggle.com/kneroma/m5-first-public-notebook-under-0-50 but feel free to replace this submission with your own submission files. All you need to do is replace *df_submission* before running the notebook.\n","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_submission = pd.read_csv(\"../input/m5-first-public-notebook-under-0-50/submission.csv\")\ndf_submission.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluation\nThanks to [sakami](https://www.kaggle.com/sakami) for providing a neat class for the evaluation metric [here](https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/133834).\n\nYou can find details on how to calculate your true public LB score and rank: https://www.kaggle.com/rohanrao/m5-how-to-get-your-public-lb-score-rank.\n","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"## evaluation metric\n## edited from https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/133834\nclass WRMSSEEvaluator(object):\n\n    def __init__(self, train_df: pd.DataFrame, valid_df: pd.DataFrame, calendar: pd.DataFrame, prices: pd.DataFrame):\n        train_y = train_df.loc[:, train_df.columns.str.startswith('d_')]\n        train_target_columns = train_y.columns.tolist()\n        weight_columns = train_y.iloc[:, -28:].columns.tolist()\n\n        train_df['all_id'] = 0  # for lv1 aggregation\n\n        id_columns = train_df.loc[:, ~train_df.columns.str.startswith('d_')].columns.tolist()\n        valid_target_columns = valid_df.loc[:, valid_df.columns.str.startswith('d_')].columns.tolist()\n\n        if not all([c in valid_df.columns for c in id_columns]):\n            valid_df = pd.concat([train_df[id_columns], valid_df], axis=1, sort=False)\n\n        self.train_df = train_df\n        self.valid_df = valid_df\n        self.calendar = calendar\n        self.prices = prices\n\n        self.weight_columns = weight_columns\n        self.id_columns = id_columns\n        self.valid_target_columns = valid_target_columns\n\n        weight_df = self.get_weight_df()\n\n        self.group_ids = (\n            'all_id',\n            'cat_id',\n            'state_id',\n            'dept_id',\n            'store_id',\n            'item_id',\n            ['state_id', 'cat_id'],\n            ['state_id', 'dept_id'],\n            ['store_id', 'cat_id'],\n            ['store_id', 'dept_id'],\n            ['item_id', 'state_id'],\n            ['item_id', 'store_id']\n        )\n\n        for i, group_id in enumerate(tqdm(self.group_ids)):\n            train_y = train_df.groupby(group_id)[train_target_columns].sum()\n            scale = []\n            for _, row in train_y.iterrows():\n                series = row.values[np.argmax(row.values != 0):]\n                scale.append(((series[1:] - series[:-1]) ** 2).mean())\n            setattr(self, f'lv{i + 1}_scale', np.array(scale))\n            setattr(self, f'lv{i + 1}_train_df', train_y)\n            setattr(self, f'lv{i + 1}_valid_df', valid_df.groupby(group_id)[valid_target_columns].sum())\n\n            lv_weight = weight_df.groupby(group_id)[weight_columns].sum().sum(axis=1)\n            setattr(self, f'lv{i + 1}_weight', lv_weight / lv_weight.sum())\n\n    def get_weight_df(self) -> pd.DataFrame:\n        day_to_week = self.calendar.set_index('d')['wm_yr_wk'].to_dict()\n        weight_df = self.train_df[['item_id', 'store_id'] + self.weight_columns].set_index(['item_id', 'store_id'])\n        weight_df = weight_df.stack().reset_index().rename(columns={'level_2': 'd', 0: 'value'})\n        weight_df['wm_yr_wk'] = weight_df['d'].map(day_to_week)\n\n        weight_df = weight_df.merge(self.prices, how='left', on=['item_id', 'store_id', 'wm_yr_wk'])\n        weight_df['value'] = weight_df['value'] * weight_df['sell_price']\n        weight_df = weight_df.set_index(['item_id', 'store_id', 'd']).unstack(level=2)['value']\n        weight_df = weight_df.loc[zip(self.train_df.item_id, self.train_df.store_id), :].reset_index(drop=True)\n        weight_df = pd.concat([self.train_df[self.id_columns], weight_df], axis=1, sort=False)\n        return weight_df\n\n    def rmsse(self, valid_preds: pd.DataFrame, lv: int) -> pd.Series:\n        valid_y = getattr(self, f'lv{lv}_valid_df')\n        score = ((valid_y - valid_preds) ** 2).mean(axis=1)\n        scale = getattr(self, f'lv{lv}_scale')\n        return (score / scale).map(np.sqrt)\n\n    def score(self, valid_preds: Union[pd.DataFrame, np.ndarray]):\n        assert self.valid_df[self.valid_target_columns].shape == valid_preds.shape\n\n        if isinstance(valid_preds, np.ndarray):\n            valid_preds = pd.DataFrame(valid_preds, columns=self.valid_target_columns)\n\n        valid_preds = pd.concat([self.valid_df[self.id_columns], valid_preds], axis=1, sort=False)\n\n        group_ids = []\n        all_scores = []\n\n        for i, group_id in enumerate(self.group_ids):\n            lv_scores = self.rmsse(valid_preds.groupby(group_id)[self.valid_target_columns].sum(), i + 1)\n            weight = getattr(self, f'lv{i + 1}_weight')\n            lv_scores = pd.concat([weight, lv_scores], axis=1, sort=False).prod(axis=1)\n            group_ids.append(group_id)\n            all_scores.append(lv_scores.sum())\n\n        return group_ids, all_scores\n    \n    def get_scores(self, valid_preds: Union[pd.DataFrame, np.ndarray], lv: int):\n        assert self.valid_df[self.valid_target_columns].shape == valid_preds.shape\n\n        if isinstance(valid_preds, np.ndarray):\n            valid_preds = pd.DataFrame(valid_preds, columns=self.valid_target_columns)\n\n        valid_preds = pd.concat([self.valid_df[self.id_columns], valid_preds], axis=1, sort=False)\n        \n        for i, group_id in enumerate(self.group_ids):\n            if lv == i+1:\n                valid_df = valid_preds.groupby(group_id)[self.valid_target_columns].sum()\n                valid_y = getattr(self, f\"lv{lv}_valid_df\")\n                scale = getattr(self, f\"lv{lv}_scale\")\n                weight = getattr(self, f\"lv{lv}_weight\")\n                valid_df[\"score\"] = (((valid_y - valid_df) ** 2).mean(axis = 1) / scale).map(np.sqrt)\n                valid_df.columns = [\"pred_d_\" + str(x) for x in range(1914, 1942)] + [\"score\"]\n                valid_df = pd.concat([valid_df, valid_y], axis = 1)\n                valid_df[\"score_weighted\"] = valid_df.score * weight\n                valid_df[\"score_percentage\"] = valid_df.score_weighted / valid_df.score_weighted.sum()\n\n        return valid_df.reset_index()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preparing data\nReading the datasets and preparing the evaluator class.\n","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"## reading data\ndf_train_full =  pd.read_csv(\"../input/m5-forecasting-accuracy/sales_train_evaluation.csv\")\ndf_calendar = pd.read_csv(\"../input/m5-forecasting-accuracy/calendar.csv\")\ndf_prices = pd.read_csv(\"../input/m5-forecasting-accuracy/sell_prices.csv\")\ndf_sample_submission = pd.read_csv(\"../input/m5-forecasting-accuracy/sample_submission.csv\")\ndf_sample_submission[\"order\"] = range(df_sample_submission.shape[0])\n\ndf_train = df_train_full.iloc[:, :-28]\ndf_valid = df_train_full.iloc[:, -28:]\n\nevaluator = WRMSSEEvaluator(df_train, df_valid, df_calendar, df_prices)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Public LB Verification\nVerifying the public LB calculation. This submission scores 0.48874 on the public LB and we should get the same score offline.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## evaluating submission from public kernel M5 First Public Notebook Under 0.50\n## from https://www.kaggle.com/kneroma/m5-first-public-notebook-under-0-50\npreds_valid = df_submission[df_submission.id.str.contains(\"validation\")]\npreds_valid = preds_valid.merge(df_sample_submission[[\"id\", \"order\"]], on = \"id\").sort_values(\"order\").drop([\"id\", \"order\"], axis = 1).reset_index(drop = True)\npreds_valid.rename(columns = {\n    \"F1\": \"d_1914\", \"F2\": \"d_1915\", \"F3\": \"d_1916\", \"F4\": \"d_1917\", \"F5\": \"d_1918\", \"F6\": \"d_1919\", \"F7\": \"d_1920\",\n    \"F8\": \"d_1921\", \"F9\": \"d_1922\", \"F10\": \"d_1923\", \"F11\": \"d_1924\", \"F12\": \"d_1925\", \"F13\": \"d_1926\", \"F14\": \"d_1927\",\n    \"F15\": \"d_1928\", \"F16\": \"d_1929\", \"F17\": \"d_1930\", \"F18\": \"d_1931\", \"F19\": \"d_1932\", \"F20\": \"d_1933\", \"F21\": \"d_1934\",\n    \"F22\": \"d_1935\", \"F23\": \"d_1936\", \"F24\": \"d_1937\", \"F25\": \"d_1938\", \"F26\": \"d_1939\", \"F27\": \"d_1940\", \"F28\": \"d_1941\"\n}, inplace = True)\n\ngroups, scores = evaluator.score(preds_valid)\n\nscore_public_lb = np.mean(scores)\n\nfor i in range(len(groups)):\n    print(f\"Score for group {groups[i]}: {round(scores[i], 5)}\")\n\nprint(f\"\\nPublic LB Score: {round(score_public_lb, 5)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The weights used in this notebook are the weights for the public LB. Note that the private LB uses a different set of weights. A summary of the weights comparison is shared here: https://www.kaggle.com/rohanrao/m5-the-weighing-scale\n\n## 0. Global\nLets look at the overall metrics and errors.\n","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"levels = [\"all\", \"category\", \"state\", \"department\", \"store\", \"item\", \"state_category\", \"state_department\",\n          \"store_category\", \"store_department\", \"state_item\", \"store_item\"]\n\ndf_levels = pd.DataFrame({\n    \"level\": levels,\n    \"score\": scores\n})\n\nsource_1 = ColumnDataSource(data = dict(\n    level = df_levels.level.values,\n    score = df_levels.score.values\n))\n\ntooltips = [\n    (\"Level\", \"@level\"),\n    (\"Score\", \"@score\")\n]\n\nv1 = figure(plot_width = 650, plot_height = 400, y_range = df_levels.level.values, tooltips = tooltips, title = \"Scores by all aggregation levels\")\nv1.hbar(y = \"level\", right = \"score\", source = source_1, height = 0.75, alpha = 0.6, legend_label = \"Public LB Score\")\n\nmean = Span(location = np.mean(df_levels.score.values), dimension = \"height\", line_color = \"grey\", line_dash = \"dashed\", line_width = 1.5)\nv1.add_layout(mean)\n\nv1.xaxis.axis_label = \"WRMSSE Score\"\nv1.yaxis.axis_label = \"Aggregation Level\"\n\nv1.legend.location = \"bottom_right\"\n\n\ndf_levels.sort_values(\"score\", inplace = True)\n\nsource_2 = ColumnDataSource(data = dict(\n    level = df_levels.level.values,\n    score = df_levels.score.values\n))\n\nv2 = figure(plot_width = 650, plot_height = 400, y_range = df_levels.level.values, tooltips = tooltips, title = \"Scores by all aggregation levels (sorted)\")\nv2.hbar(y = \"level\", right = \"score\", source = source_2, height = 0.75, alpha = 0.6, legend_label = \"Public LB Score\")\n\nmean = Span(location = np.mean(df_levels.score.values), dimension = \"height\", line_color = \"grey\", line_dash = \"dashed\", line_width = 1.5)\nv2.add_layout(mean)\n\nv2.xaxis.axis_label = \"WRMSSE Score\"\nv2.yaxis.axis_label = \"Aggregation Level\"\n\nv2.legend.location = \"bottom_right\"\n\n\ndf_items = df_levels[df_levels.level.str.contains(\"item\")]\n\nsource_3 = ColumnDataSource(data = dict(\n    level = df_items.level.values,\n    score = df_items.score.values\n))\n\nv3 = figure(plot_width = 330, plot_height = 200, y_range = df_items.level.values, x_range = Range1d(0, 1), tooltips = tooltips, title = \"Scores by item levels\")\nv3.hbar(y = \"level\", right = \"score\", source = source_3, height = 0.75, color = \"mediumseagreen\", alpha = 0.6)\n\nmean = Span(location = np.mean(df_items.score.values), dimension = \"height\", line_color = \"grey\", line_dash = \"dashed\", line_width = 1.5)\nv3.add_layout(mean)\n\nv3.xaxis.axis_label = \"WRMSSE Score\"\nv3.yaxis.axis_label = \"Aggregation Level\"\n\n\ndf_stores = df_levels[df_levels.level.str.contains(\"store\")]\n\nsource_4 = ColumnDataSource(data = dict(\n    level = df_stores.level.values,\n    score = df_stores.score.values\n))\n\nv4 = figure(plot_width = 330, plot_height = 200, y_range = df_stores.level.values, x_range = Range1d(0, 1), tooltips = tooltips, title = \"Scores by store levels\")\nv4.hbar(y = \"level\", right = \"score\", source = source_4, height = 0.75, color = \"mediumseagreen\", alpha = 0.6)\n\nmean = Span(location = np.mean(df_stores.score.values), dimension = \"height\", line_color = \"grey\", line_dash = \"dashed\", line_width = 1.5)\nv4.add_layout(mean)\n\nv4.xaxis.axis_label = \"WRMSSE Score\"\nv4.yaxis.axis_label = \"Aggregation Level\"\n\n\ndf_departments = df_levels[df_levels.level.str.contains(\"dep\")]\n\nsource_5 = ColumnDataSource(data = dict(\n    level = df_departments.level.values,\n    score = df_departments.score.values\n))\n\nv5 = figure(plot_width = 330, plot_height = 200, y_range = df_departments.level.values, x_range = Range1d(0, 1), tooltips = tooltips, title = \"Scores by department levels\")\nv5.hbar(y = \"level\", right = \"score\", source = source_5, height = 0.75, color = \"mediumseagreen\", alpha = 0.6)\n\nmean = Span(location = np.mean(df_departments.score.values), dimension = \"height\", line_color = \"grey\", line_dash = \"dashed\", line_width = 1.5)\nv5.add_layout(mean)\n\nv5.xaxis.axis_label = \"WRMSSE Score\"\nv5.yaxis.axis_label = \"Aggregation Level\"\n\n\ndf_states = df_levels[df_levels.level.str.contains(\"state\")]\n\nsource_6 = ColumnDataSource(data = dict(\n    level = df_states.level.values,\n    score = df_states.score.values\n))\n\nv6 = figure(plot_width = 330, plot_height = 200, y_range = df_states.level.values, x_range = Range1d(0, 1), tooltips = tooltips, title = \"Scores by state levels\")\nv6.hbar(y = \"level\", right = \"score\", source = source_6, height = 0.75, color = \"mediumseagreen\", alpha = 0.6)\n\nmean = Span(location = np.mean(df_states.score.values), dimension = \"height\", line_color = \"grey\", line_dash = \"dashed\", line_width = 1.5)\nv6.add_layout(mean)\n\nv6.xaxis.axis_label = \"WRMSSE Score\"\nv6.yaxis.axis_label = \"Aggregation Level\"\n\n\ndf_categories = df_levels[df_levels.level.str.contains(\"cat\")]\n\nsource_7 = ColumnDataSource(data = dict(\n    level = df_categories.level.values,\n    score = df_categories.score.values\n))\n\nv7 = figure(plot_width = 330, plot_height = 200, y_range = df_categories.level.values, x_range = Range1d(0, 1), tooltips = tooltips, title = \"Scores by category levels\")\nv7.hbar(y = \"level\", right = \"score\", source = source_7, height = 0.75, color = \"mediumseagreen\", alpha = 0.6)\n\nmean = Span(location = np.mean(df_categories.score.values), dimension = \"height\", line_color = \"grey\", line_dash = \"dashed\", line_width = 1.5)\nv7.add_layout(mean)\n\nv7.xaxis.axis_label = \"WRMSSE Score\"\nv7.yaxis.axis_label = \"Aggregation Level\"\n\n\nshow(column(v1, v2, row(v3, v4), row(v5, v6), v7))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's clear that the item level aggregations are the hardest to predict. It is inituitive as well due to high volatility and changes in inventory, demand and consumption.\n\nThe more rolled up the aggregate levels are the lower the scores are. This is intuitive as well since rolling up tends to cancel out positive and negative errors at granular levels. That is why the singular levels have better scores than the coupled ones. And when all levels are rolled up into ***all*** it is the best.\n\n\n## 1. Store-Item\nLet's look at the most relevant store-item combinations of interest.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_store_item = evaluator.get_scores(preds_valid, 12)\ndf_store_item[\"store_item_id\"] = df_store_item.store_id + \"-\" + df_store_item.item_id\n\ndf_store_item_best = df_store_item.sort_values(\"score_weighted\").head(10).rename(columns = {\"score_weighted\": \"score_best\"})\ndf_store_item_worst = df_store_item.sort_values(\"score_weighted\", ascending = False).head(10).sort_values(\"score_weighted\").rename(columns = {\"score_weighted\": \"score_worst\"})\n\ndf_store_item_best_worst = pd.concat([df_store_item_best, df_store_item_worst])\n\nsource_1 = ColumnDataSource(data = dict(\n    store_item_id = df_store_item_best_worst.store_item_id.values,\n    score_best = df_store_item_best_worst.score_best.values,\n    score_worst = df_store_item_best_worst.score_worst.values\n))\n\ntooltips_1 = [\n    (\"Store-Item\", \"@store_item_id\"),\n    (\"Score\", \"@score_best{0.0000}\")\n]\n\ntooltips_2 = [\n    (\"Store-Item\", \"@store_item_id\"),\n    (\"Score\", \"@score_worst{0.0000}\")\n]\n\nv1 = figure(plot_width = 700, plot_height = 400, y_range = df_store_item_best_worst.store_item_id.values, title = \"Best and Worst Store-Item\")\nv11 = v1.hbar(\"store_item_id\", right = \"score_best\", source = source_1, height = 0.75, alpha = 0.6, color = \"green\")\nv12 = v1.hbar(\"store_item_id\", right = \"score_worst\", source = source_1, height = 0.75, alpha = 0.6, color = \"red\")\n\nv1.add_tools(HoverTool(renderers = [v11], tooltips = tooltips_1))\nv1.add_tools(HoverTool(renderers = [v12], tooltips = tooltips_2))\n\nv1.xaxis.axis_label = \"WRMSSE Score\"\nv1.yaxis.axis_label = \"Store-Item\"\n\n\ndef get_store_item_plot(df, store_item_id):\n    \"\"\"\n    Plots the actual and predicted values of store-item\n    \"\"\"\n    actual_dates = [\"d_\" + str(x) for x in range(1914, 1942)]\n    predicted_dates = [\"pred_d_\" + str(x) for x in range(1914, 1942)]\n    \n    source = ColumnDataSource(data = dict(\n        date_number = actual_dates,\n        date = LB_DATES,\n        weekday = LB_WEEKDAYS,\n        actual = df.loc[df.store_item_id == store_item_id, actual_dates].values[0],\n        predicted = df.loc[df.store_item_id == store_item_id, predicted_dates].values[0]\n    ))\n    \n    tooltips = [\n        (\"Date\", \"@date\"),\n        (\"Weekday\", \"@weekday\"),\n        (\"Actual\", \"@actual{0}\"),\n        (\"Predicted\", \"@predicted{0.0}\")\n    ]\n    \n    v = figure(plot_width = 700, plot_height = 400, x_range = actual_dates, tooltips = tooltips, title = f\"Store-Item: {store_item_id}\")\n    v.line(\"date_number\", \"actual\", source = source, color = \"steelblue\", alpha = 0.6, width = 3, legend_label = \"Actual\")\n    v.line(\"date_number\", \"predicted\", source = source, color = \"coral\", alpha = 0.6, width = 3, legend_label = \"Predicted\")\n    \n    v.xaxis.axis_label = \"Date\"\n    v.yaxis.axis_label = \"Sales\"\n\n    v.xaxis.major_label_orientation = pi / 4\n    \n    return v\n\nv2 = get_store_item_plot(df_store_item, df_store_item_worst.store_item_id.values[-1])\nv3 = get_store_item_plot(df_store_item, df_store_item_worst.store_item_id.values[-2])\nv4 = get_store_item_plot(df_store_item, df_store_item_worst.store_item_id.values[-3])\nv5 = get_store_item_plot(df_store_item, df_store_item_worst.store_item_id.values[-4])\nv6 = get_store_item_plot(df_store_item, df_store_item_worst.store_item_id.values[-5])\nv7 = get_store_item_plot(df_store_item, df_store_item_worst.store_item_id.values[-6])\nv8 = get_store_item_plot(df_store_item, df_store_item_worst.store_item_id.values[-7])\nv9 = get_store_item_plot(df_store_item, df_store_item_worst.store_item_id.values[-8])\nv10 = get_store_item_plot(df_store_item, df_store_item_worst.store_item_id.values[-9])\nv11 = get_store_item_plot(df_store_item, df_store_item_worst.store_item_id.values[-10])\n\n\nshow(column(v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, v11))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some of the best store-item combinations have a score of 0 since their weight is 0.\n\n## 2. State-Item\nLet's look at the most relevant state-item combinations of interest.\n","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_state_item = evaluator.get_scores(preds_valid, 11)\ndf_state_item[\"state_item_id\"] = df_state_item.state_id + \"-\" + df_state_item.item_id\n\ndf_state_item_best = df_state_item.sort_values(\"score_weighted\").head(10).rename(columns = {\"score_weighted\": \"score_best\"})\ndf_state_item_worst = df_state_item.sort_values(\"score_weighted\", ascending = False).head(10).sort_values(\"score_weighted\").rename(columns = {\"score_weighted\": \"score_worst\"})\n\ndf_state_item_best_worst = pd.concat([df_state_item_best, df_state_item_worst])\n\nsource_1 = ColumnDataSource(data = dict(\n    state_item_id = df_state_item_best_worst.state_item_id.values,\n    score_best = df_state_item_best_worst.score_best.values,\n    score_worst = df_state_item_best_worst.score_worst.values\n))\n\ntooltips_1 = [\n    (\"State-Item\", \"@state_item_id\"),\n    (\"Score\", \"@score_best{0.0000}\")\n]\n\ntooltips_2 = [\n    (\"State-Item\", \"@state_item_id\"),\n    (\"Score\", \"@score_worst{0.0000}\")\n]\n\nv1 = figure(plot_width = 700, plot_height = 400, y_range = df_state_item_best_worst.state_item_id.values, title = \"Best and Worst State-Item\")\nv11 = v1.hbar(\"state_item_id\", right = \"score_best\", source = source_1, height = 0.75, alpha = 0.6, color = \"green\")\nv12 = v1.hbar(\"state_item_id\", right = \"score_worst\", source = source_1, height = 0.75, alpha = 0.6, color = \"red\")\n\nv1.add_tools(HoverTool(renderers = [v11], tooltips = tooltips_1))\nv1.add_tools(HoverTool(renderers = [v12], tooltips = tooltips_2))\n\nv1.xaxis.axis_label = \"WRMSSE Score\"\nv1.yaxis.axis_label = \"State-Item\"\n\n\ndef get_state_item_plot(df, state_item_id):\n    \"\"\"\n    Plots the actual and predicted values of state-item\n    \"\"\"\n    actual_dates = [\"d_\" + str(x) for x in range(1914, 1942)]\n    predicted_dates = [\"pred_d_\" + str(x) for x in range(1914, 1942)]\n    \n    source = ColumnDataSource(data = dict(\n        date_number = actual_dates,\n        date = LB_DATES,\n        weekday = LB_WEEKDAYS,\n        actual = df.loc[df.state_item_id == state_item_id, actual_dates].values[0],\n        predicted = df.loc[df.state_item_id == state_item_id, predicted_dates].values[0]\n    ))\n    \n    tooltips = [\n        (\"Date\", \"@date\"),\n        (\"Weekday\", \"@weekday\"),\n        (\"Actual\", \"@actual{0}\"),\n        (\"Predicted\", \"@predicted{0.0}\")\n    ]\n    \n    v = figure(plot_width = 700, plot_height = 400, x_range = actual_dates, tooltips = tooltips, title = f\"State-Item: {state_item_id}\")\n    v.line(\"date_number\", \"actual\", source = source, color = \"steelblue\", alpha = 0.6, width = 3, legend_label = \"Actual\")\n    v.line(\"date_number\", \"predicted\", source = source, color = \"coral\", alpha = 0.6, width = 3, legend_label = \"Predicted\")\n\n    v.xaxis.axis_label = \"Date\"\n    v.yaxis.axis_label = \"Sales\"\n\n    v.xaxis.major_label_orientation = pi / 4\n\n    return v\n\nv2 = get_state_item_plot(df_state_item, df_state_item_worst.state_item_id.values[-1])\nv3 = get_state_item_plot(df_state_item, df_state_item_worst.state_item_id.values[-2])\nv4 = get_state_item_plot(df_state_item, df_state_item_worst.state_item_id.values[-3])\nv5 = get_state_item_plot(df_state_item, df_state_item_worst.state_item_id.values[-4])\nv6 = get_state_item_plot(df_state_item, df_state_item_worst.state_item_id.values[-5])\nv7 = get_state_item_plot(df_state_item, df_state_item_worst.state_item_id.values[-6])\nv8 = get_state_item_plot(df_state_item, df_state_item_worst.state_item_id.values[-7])\nv9 = get_state_item_plot(df_state_item, df_state_item_worst.state_item_id.values[-8])\nv10 = get_state_item_plot(df_state_item, df_state_item_worst.state_item_id.values[-9])\nv11 = get_state_item_plot(df_state_item, df_state_item_worst.state_item_id.values[-10])\n\n\nshow(column(v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, v11))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some of the best state-item combinations have a score of 0 since their weight is 0.\n\n## 3. Item\nLet's look at the most relevant items of interest.\n","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_item = evaluator.get_scores(preds_valid, 6)\n\ndf_item_best = df_item.sort_values(\"score_weighted\").head(10).rename(columns = {\"score_weighted\": \"score_best\"})\ndf_item_worst = df_item.sort_values(\"score_weighted\", ascending = False).head(10).sort_values(\"score_weighted\").rename(columns = {\"score_weighted\": \"score_worst\"})\n\ndf_item_best_worst = pd.concat([df_item_best, df_item_worst])\n\nsource_1 = ColumnDataSource(data = dict(\n    item_id = df_item_best_worst.item_id.values,\n    score_best = df_item_best_worst.score_best.values,\n    score_worst = df_item_best_worst.score_worst.values\n))\n\ntooltips_1 = [\n    (\"Item\", \"@item_id\"),\n    (\"Score\", \"@score_best{0.0000}\")\n]\n\ntooltips_2 = [\n    (\"Item\", \"@item_id\"),\n    (\"Score\", \"@score_worst{0.0000}\")\n]\n\nv1 = figure(plot_width = 700, plot_height = 400, y_range = df_item_best_worst.item_id.values, title = \"Best and Worst Item\")\nv11 = v1.hbar(\"item_id\", right = \"score_best\", source = source_1, height = 0.75, alpha = 0.6, color = \"green\")\nv12 = v1.hbar(\"item_id\", right = \"score_worst\", source = source_1, height = 0.75, alpha = 0.6, color = \"red\")\n\nv1.add_tools(HoverTool(renderers = [v11], tooltips = tooltips_1))\nv1.add_tools(HoverTool(renderers = [v12], tooltips = tooltips_2))\n\nv1.xaxis.axis_label = \"WRMSSE Score\"\nv1.yaxis.axis_label = \"Item\"\n\n\ndef get_item_plot(df, item_id):\n    \"\"\"\n    Plots the actual and predicted values of item_id\n    \"\"\"\n    actual_dates = [\"d_\" + str(x) for x in range(1914, 1942)]\n    predicted_dates = [\"pred_d_\" + str(x) for x in range(1914, 1942)]\n    \n    source = ColumnDataSource(data = dict(\n        date_number = actual_dates,\n        date = LB_DATES,\n        weekday = LB_WEEKDAYS,\n        actual = df.loc[df.item_id == item_id, actual_dates].values[0],\n        predicted = df.loc[df.item_id == item_id, predicted_dates].values[0]\n    ))\n    \n    tooltips = [\n        (\"Date\", \"@date\"),\n        (\"Weekday\", \"@weekday\"),\n        (\"Actual\", \"@actual{0}\"),\n        (\"Predicted\", \"@predicted{0.0}\")\n    ]\n    \n    v = figure(plot_width = 700, plot_height = 400, x_range = actual_dates, tooltips = tooltips, title = f\"Item: {item_id}\")\n    v.line(\"date_number\", \"actual\", source = source, color = \"steelblue\", alpha = 0.6, width = 3, legend_label = \"Actual\")\n    v.line(\"date_number\", \"predicted\", source = source, color = \"coral\", alpha = 0.6, width = 3, legend_label = \"Predicted\")\n\n    v.xaxis.axis_label = \"Date\"\n    v.yaxis.axis_label = \"Sales\"\n\n    v.xaxis.major_label_orientation = pi / 4\n\n    return v\n\nv2 = get_item_plot(df_item, df_item_worst.item_id.values[-1])\nv3 = get_item_plot(df_item, df_item_worst.item_id.values[-2])\nv4 = get_item_plot(df_item, df_item_worst.item_id.values[-3])\nv5 = get_item_plot(df_item, df_item_worst.item_id.values[-4])\nv6 = get_item_plot(df_item, df_item_worst.item_id.values[-5])\nv7 = get_item_plot(df_item, df_item_worst.item_id.values[-6])\nv8 = get_item_plot(df_item, df_item_worst.item_id.values[-7])\nv9 = get_item_plot(df_item, df_item_worst.item_id.values[-8])\nv10 = get_item_plot(df_item, df_item_worst.item_id.values[-9])\nv11 = get_item_plot(df_item, df_item_worst.item_id.values[-10])\n\n\nshow(column(v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, v11))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some of the items have a score of 0 since their weight is 0.\n\n## 4. Store-Department\nLet's look at the most relevant store-department combinations of interest.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_store_dept = evaluator.get_scores(preds_valid, 10)\ndf_store_dept[\"store_dept_id\"] = df_store_dept.store_id + \"-\" + df_store_dept.dept_id\n\ndf_store_dept_best = df_store_dept.sort_values(\"score_weighted\").head(10).rename(columns = {\"score_weighted\": \"score_best\"})\ndf_store_dept_worst = df_store_dept.sort_values(\"score_weighted\", ascending = False).head(10).sort_values(\"score_weighted\").rename(columns = {\"score_weighted\": \"score_worst\"})\n\ndf_store_dept_best_worst = pd.concat([df_store_dept_best, df_store_dept_worst])\n\nsource_1 = ColumnDataSource(data = dict(\n    store_dept_id = df_store_dept_best_worst.store_dept_id.values,\n    score_best = df_store_dept_best_worst.score_best.values,\n    score_worst = df_store_dept_best_worst.score_worst.values\n))\n\ntooltips_1 = [\n    (\"Store-Department\", \"@store_dept_id\"),\n    (\"Score\", \"@score_best{0.0000}\")\n]\n\ntooltips_2 = [\n    (\"Store-Department\", \"@store_dept_id\"),\n    (\"Score\", \"@score_worst{0.0000}\")\n]\n\nv1 = figure(plot_width = 700, plot_height = 400, y_range = df_store_dept_best_worst.store_dept_id.values, title = \"Best and Worst Store-Department\")\nv11 = v1.hbar(\"store_dept_id\", right = \"score_best\", source = source_1, height = 0.75, alpha = 0.6, color = \"green\")\nv12 = v1.hbar(\"store_dept_id\", right = \"score_worst\", source = source_1, height = 0.75, alpha = 0.6, color = \"red\")\n\nv1.add_tools(HoverTool(renderers = [v11], tooltips = tooltips_1))\nv1.add_tools(HoverTool(renderers = [v12], tooltips = tooltips_2))\n\nv1.xaxis.axis_label = \"WRMSSE Score\"\nv1.yaxis.axis_label = \"Store-Department\"\n\n\ndef get_store_dept_plot(df, store_dept_id):\n    \"\"\"\n    Plots the actual and predicted values of store-dept\n    \"\"\"\n    actual_dates = [\"d_\" + str(x) for x in range(1914, 1942)]\n    predicted_dates = [\"pred_d_\" + str(x) for x in range(1914, 1942)]\n    \n    source = ColumnDataSource(data = dict(\n        date_number = actual_dates,\n        date = LB_DATES,\n        weekday = LB_WEEKDAYS,\n        actual = df.loc[df.store_dept_id == store_dept_id, actual_dates].values[0],\n        predicted = df.loc[df.store_dept_id == store_dept_id, predicted_dates].values[0]\n    ))\n    \n    tooltips = [\n        (\"Date\", \"@date\"),\n        (\"Weekday\", \"@weekday\"),\n        (\"Actual\", \"@actual{0}\"),\n        (\"Predicted\", \"@predicted{0.0}\")\n    ]\n    \n    v = figure(plot_width = 700, plot_height = 400, x_range = actual_dates, tooltips = tooltips, title = f\"Store-Dept: {store_dept_id}\")\n    v.line(\"date_number\", \"actual\", source = source, color = \"steelblue\", alpha = 0.6, width = 3, legend_label = \"Actual\")\n    v.line(\"date_number\", \"predicted\", source = source, color = \"coral\", alpha = 0.6, width = 3, legend_label = \"Predicted\")\n\n    v.xaxis.axis_label = \"Date\"\n    v.yaxis.axis_label = \"Sales\"\n\n    v.xaxis.major_label_orientation = pi / 4\n\n    return v\n\nv2 = get_store_dept_plot(df_store_dept, df_store_dept_worst.store_dept_id.values[-1])\nv3 = get_store_dept_plot(df_store_dept, df_store_dept_worst.store_dept_id.values[-2])\nv4 = get_store_dept_plot(df_store_dept, df_store_dept_worst.store_dept_id.values[-3])\nv5 = get_store_dept_plot(df_store_dept, df_store_dept_worst.store_dept_id.values[-4])\nv6 = get_store_dept_plot(df_store_dept, df_store_dept_worst.store_dept_id.values[-5])\nv7 = get_store_dept_plot(df_store_dept, df_store_dept_worst.store_dept_id.values[-6])\nv8 = get_store_dept_plot(df_store_dept, df_store_dept_worst.store_dept_id.values[-7])\nv9 = get_store_dept_plot(df_store_dept, df_store_dept_worst.store_dept_id.values[-8])\nv10 = get_store_dept_plot(df_store_dept, df_store_dept_worst.store_dept_id.values[-9])\nv11 = get_store_dept_plot(df_store_dept, df_store_dept_worst.store_dept_id.values[-10])\n\n\nshow(column(v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, v11))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5. Store-Category\nLet's look at the most relevant store-category combinations of interest.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_store_cat = evaluator.get_scores(preds_valid, 9)\ndf_store_cat[\"store_cat_id\"] = df_store_cat.store_id + \"-\" + df_store_cat.cat_id\n\ndf_store_cat_best = df_store_cat.sort_values(\"score_weighted\").head(10).rename(columns = {\"score_weighted\": \"score_best\"})\ndf_store_cat_worst = df_store_cat.sort_values(\"score_weighted\", ascending = False).head(10).sort_values(\"score_weighted\").rename(columns = {\"score_weighted\": \"score_worst\"})\n\ndf_store_cat_best_worst = pd.concat([df_store_cat_best, df_store_cat_worst])\n\nsource_1 = ColumnDataSource(data = dict(\n    store_cat_id = df_store_cat_best_worst.store_cat_id.values,\n    score_best = df_store_cat_best_worst.score_best.values,\n    score_worst = df_store_cat_best_worst.score_worst.values\n))\n\ntooltips_1 = [\n    (\"Store-Category\", \"@store_cat_id\"),\n    (\"Score\", \"@score_best{0.0000}\")\n]\n\ntooltips_2 = [\n    (\"Store-Category\", \"@store_cat_id\"),\n    (\"Score\", \"@score_worst{0.0000}\")\n]\n\nv1 = figure(plot_width = 700, plot_height = 400, y_range = df_store_cat_best_worst.store_cat_id.values, title = \"Best and Worst Store-Category\")\nv11 = v1.hbar(\"store_cat_id\", right = \"score_best\", source = source_1, height = 0.75, alpha = 0.6, color = \"green\")\nv12 = v1.hbar(\"store_cat_id\", right = \"score_worst\", source = source_1, height = 0.75, alpha = 0.6, color = \"red\")\n\nv1.add_tools(HoverTool(renderers = [v11], tooltips = tooltips_1))\nv1.add_tools(HoverTool(renderers = [v12], tooltips = tooltips_2))\n\nv1.xaxis.axis_label = \"WRMSSE Score\"\nv1.yaxis.axis_label = \"Store-Category\"\n\n\ndef get_store_cat_plot(df, store_cat_id):\n    \"\"\"\n    Plots the actual and predicted values of store-cat\n    \"\"\"\n    actual_dates = [\"d_\" + str(x) for x in range(1914, 1942)]\n    predicted_dates = [\"pred_d_\" + str(x) for x in range(1914, 1942)]\n    \n    source = ColumnDataSource(data = dict(\n        date_number = actual_dates,\n        date = LB_DATES,\n        weekday = LB_WEEKDAYS,\n        actual = df.loc[df.store_cat_id == store_cat_id, actual_dates].values[0],\n        predicted = df.loc[df.store_cat_id == store_cat_id, predicted_dates].values[0]\n    ))\n    \n    tooltips = [\n        (\"Date\", \"@date\"),\n        (\"Weekday\", \"@weekday\"),\n        (\"Actual\", \"@actual{0}\"),\n        (\"Predicted\", \"@predicted{0.0}\")\n    ]\n    \n    v = figure(plot_width = 700, plot_height = 400, x_range = actual_dates, tooltips = tooltips, title = f\"Store-Category: {store_cat_id}\")\n    v.line(\"date_number\", \"actual\", source = source, color = \"steelblue\", alpha = 0.6, width = 3, legend_label = \"Actual\")\n    v.line(\"date_number\", \"predicted\", source = source, color = \"coral\", alpha = 0.6, width = 3, legend_label = \"Predicted\")\n\n    v.xaxis.axis_label = \"Date\"\n    v.yaxis.axis_label = \"Sales\"\n\n    v.xaxis.major_label_orientation = pi / 4\n\n    return v\n\nv2 = get_store_cat_plot(df_store_cat, df_store_cat_worst.store_cat_id.values[-1])\nv3 = get_store_cat_plot(df_store_cat, df_store_cat_worst.store_cat_id.values[-2])\nv4 = get_store_cat_plot(df_store_cat, df_store_cat_worst.store_cat_id.values[-3])\nv5 = get_store_cat_plot(df_store_cat, df_store_cat_worst.store_cat_id.values[-4])\nv6 = get_store_cat_plot(df_store_cat, df_store_cat_worst.store_cat_id.values[-5])\nv7 = get_store_cat_plot(df_store_cat, df_store_cat_worst.store_cat_id.values[-6])\nv8 = get_store_cat_plot(df_store_cat, df_store_cat_worst.store_cat_id.values[-7])\nv9 = get_store_cat_plot(df_store_cat, df_store_cat_worst.store_cat_id.values[-8])\nv10 = get_store_cat_plot(df_store_cat, df_store_cat_worst.store_cat_id.values[-9])\nv11 = get_store_cat_plot(df_store_cat, df_store_cat_worst.store_cat_id.values[-10])\n\n\nshow(column(v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, v11))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6. State-Department\nLet's look at the most relevant state-department combinations of interest.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_state_dept = evaluator.get_scores(preds_valid, 8)\ndf_state_dept[\"state_dept_id\"] = df_state_dept.state_id + \"-\" + df_state_dept.dept_id\n\ndf_state_dept_best = df_state_dept.sort_values(\"score_weighted\").head(10).rename(columns = {\"score_weighted\": \"score_best\"})\ndf_state_dept_worst = df_state_dept.sort_values(\"score_weighted\", ascending = False).head(10).sort_values(\"score_weighted\").rename(columns = {\"score_weighted\": \"score_worst\"})\n\ndf_state_dept_best_worst = pd.concat([df_state_dept_best, df_state_dept_worst])\n\nsource_1 = ColumnDataSource(data = dict(\n    state_dept_id = df_state_dept_best_worst.state_dept_id.values,\n    score_best = df_state_dept_best_worst.score_best.values,\n    score_worst = df_state_dept_best_worst.score_worst.values\n))\n\ntooltips_1 = [\n    (\"State-Department\", \"@state_dept_id\"),\n    (\"Score\", \"@score_best{0.0000}\")\n]\n\ntooltips_2 = [\n    (\"State-Department\", \"@state_dept_id\"),\n    (\"Score\", \"@score_worst{0.0000}\")\n]\n\nv1 = figure(plot_width = 700, plot_height = 400, y_range = df_state_dept_best_worst.state_dept_id.values, title = \"Best and Worst State-Department\")\nv11 = v1.hbar(\"state_dept_id\", right = \"score_best\", source = source_1, height = 0.75, alpha = 0.6, color = \"green\")\nv12 = v1.hbar(\"state_dept_id\", right = \"score_worst\", source = source_1, height = 0.75, alpha = 0.6, color = \"red\")\n\nv1.add_tools(HoverTool(renderers = [v11], tooltips = tooltips_1))\nv1.add_tools(HoverTool(renderers = [v12], tooltips = tooltips_2))\n\nv1.xaxis.axis_label = \"WRMSSE Score\"\nv1.yaxis.axis_label = \"State-Department\"\n\n\ndef get_state_dept_plot(df, state_dept_id):\n    \"\"\"\n    Plots the actual and predicted values of state-dept\n    \"\"\"\n    actual_dates = [\"d_\" + str(x) for x in range(1914, 1942)]\n    predicted_dates = [\"pred_d_\" + str(x) for x in range(1914, 1942)]\n    \n    source = ColumnDataSource(data = dict(\n        date_number = actual_dates,\n        date = LB_DATES,\n        weekday = LB_WEEKDAYS,\n        actual = df.loc[df.state_dept_id == state_dept_id, actual_dates].values[0],\n        predicted = df.loc[df.state_dept_id == state_dept_id, predicted_dates].values[0]\n    ))\n    \n    tooltips = [\n        (\"Date\", \"@date\"),\n        (\"Weekday\", \"@weekday\"),\n        (\"Actual\", \"@actual{0}\"),\n        (\"Predicted\", \"@predicted{0.0}\")\n    ]\n    \n    v = figure(plot_width = 700, plot_height = 400, x_range = actual_dates, tooltips = tooltips, title = f\"State-Department: {state_dept_id}\")\n    v.line(\"date_number\", \"actual\", source = source, color = \"steelblue\", alpha = 0.6, width = 3, legend_label = \"Actual\")\n    v.line(\"date_number\", \"predicted\", source = source, color = \"coral\", alpha = 0.6, width = 3, legend_label = \"Predicted\")\n\n    v.xaxis.axis_label = \"Date\"\n    v.yaxis.axis_label = \"Sales\"\n\n    v.xaxis.major_label_orientation = pi / 4\n\n    return v\n\nv2 = get_state_dept_plot(df_state_dept, df_state_dept_worst.state_dept_id.values[-1])\nv3 = get_state_dept_plot(df_state_dept, df_state_dept_worst.state_dept_id.values[-2])\nv4 = get_state_dept_plot(df_state_dept, df_state_dept_worst.state_dept_id.values[-3])\nv5 = get_state_dept_plot(df_state_dept, df_state_dept_worst.state_dept_id.values[-4])\nv6 = get_state_dept_plot(df_state_dept, df_state_dept_worst.state_dept_id.values[-5])\nv7 = get_state_dept_plot(df_state_dept, df_state_dept_worst.state_dept_id.values[-6])\nv8 = get_state_dept_plot(df_state_dept, df_state_dept_worst.state_dept_id.values[-7])\nv9 = get_state_dept_plot(df_state_dept, df_state_dept_worst.state_dept_id.values[-8])\nv10 = get_state_dept_plot(df_state_dept, df_state_dept_worst.state_dept_id.values[-9])\nv11 = get_state_dept_plot(df_state_dept, df_state_dept_worst.state_dept_id.values[-10])\n\n\nshow(column(v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, v11))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 7. Store\nLet's look at all the 10 stores.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_store = evaluator.get_scores(preds_valid, 5)\n\ndf_store_best = df_store.sort_values(\"score_weighted\").head(5).rename(columns = {\"score_weighted\": \"score_best\"})\ndf_store_worst = df_store.sort_values(\"score_weighted\", ascending = False).head(5).sort_values(\"score_weighted\").rename(columns = {\"score_weighted\": \"score_worst\"})\n\ndf_store_best_worst = pd.concat([df_store_best, df_store_worst])\n\nsource_1 = ColumnDataSource(data = dict(\n    store_id = df_store_best_worst.store_id.values,\n    score_best = df_store_best_worst.score_best.values,\n    score_worst = df_store_best_worst.score_worst.values\n))\n\ntooltips_1 = [\n    (\"Store\", \"@store_id\"),\n    (\"Score\", \"@score_best{0.0000}\")\n]\n\ntooltips_2 = [\n    (\"Store\", \"@store_id\"),\n    (\"Score\", \"@score_worst{0.0000}\")\n]\n\nv1 = figure(plot_width = 700, plot_height = 400, y_range = df_store_best_worst.store_id.values, title = \"Best and Worst Store\")\nv11 = v1.hbar(\"store_id\", right = \"score_best\", source = source_1, height = 0.75, alpha = 0.6, color = \"green\")\nv12 = v1.hbar(\"store_id\", right = \"score_worst\", source = source_1, height = 0.75, alpha = 0.6, color = \"red\")\n\nv1.add_tools(HoverTool(renderers = [v11], tooltips = tooltips_1))\nv1.add_tools(HoverTool(renderers = [v12], tooltips = tooltips_2))\n\nv1.xaxis.axis_label = \"WRMSSE Score\"\nv1.yaxis.axis_label = \"Store\"\n\n\ndef get_store_plot(df, store_id):\n    \"\"\"\n    Plots the actual and predicted values of store_id\n    \"\"\"\n    actual_dates = [\"d_\" + str(x) for x in range(1914, 1942)]\n    predicted_dates = [\"pred_d_\" + str(x) for x in range(1914, 1942)]\n    \n    source = ColumnDataSource(data = dict(\n        date_number = actual_dates,\n        date = LB_DATES,\n        weekday = LB_WEEKDAYS,\n        actual = df.loc[df.store_id == store_id, actual_dates].values[0],\n        predicted = df.loc[df.store_id == store_id, predicted_dates].values[0]\n    ))\n    \n    tooltips = [\n        (\"Date\", \"@date\"),\n        (\"Weekday\", \"@weekday\"),\n        (\"Actual\", \"@actual{0}\"),\n        (\"Predicted\", \"@predicted{0.0}\")\n    ]\n    \n    v = figure(plot_width = 700, plot_height = 400, x_range = actual_dates, tooltips = tooltips, title = f\"Store: {store_id}\")\n    v.line(\"date_number\", \"actual\", source = source, color = \"steelblue\", alpha = 0.6, width = 3, legend_label = \"Actual\")\n    v.line(\"date_number\", \"predicted\", source = source, color = \"coral\", alpha = 0.6, width = 3, legend_label = \"Predicted\")\n\n    v.xaxis.axis_label = \"Date\"\n    v.yaxis.axis_label = \"Sales\"\n\n    v.xaxis.major_label_orientation = pi / 4\n\n    return v\n\nv2 = get_store_plot(df_store, df_store_best_worst.store_id.values[-1])\nv3 = get_store_plot(df_store, df_store_best_worst.store_id.values[-2])\nv4 = get_store_plot(df_store, df_store_best_worst.store_id.values[-3])\nv5 = get_store_plot(df_store, df_store_best_worst.store_id.values[-4])\nv6 = get_store_plot(df_store, df_store_best_worst.store_id.values[-5])\nv7 = get_store_plot(df_store, df_store_best_worst.store_id.values[-6])\nv8 = get_store_plot(df_store, df_store_best_worst.store_id.values[-7])\nv9 = get_store_plot(df_store, df_store_best_worst.store_id.values[-8])\nv10 = get_store_plot(df_store, df_store_best_worst.store_id.values[-9])\nv11 = get_store_plot(df_store, df_store_best_worst.store_id.values[-10])\n\n\nshow(column(v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, v11))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 8. Department\nLet's look at all the 7 departments.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_dept = evaluator.get_scores(preds_valid, 4)\n\ndf_dept_best = df_dept.sort_values(\"score_weighted\").head(3).rename(columns = {\"score_weighted\": \"score_best\"})\ndf_dept_worst = df_dept.sort_values(\"score_weighted\", ascending = False).head(4).sort_values(\"score_weighted\").rename(columns = {\"score_weighted\": \"score_worst\"})\n\ndf_dept_best_worst = pd.concat([df_dept_best, df_dept_worst])\n\nsource_1 = ColumnDataSource(data = dict(\n    dept_id = df_dept_best_worst.dept_id.values,\n    score_best = df_dept_best_worst.score_best.values,\n    score_worst = df_dept_best_worst.score_worst.values\n))\n\ntooltips_1 = [\n    (\"Department\", \"@dept_id\"),\n    (\"Score\", \"@score_best{0.0000}\")\n]\n\ntooltips_2 = [\n    (\"Department\", \"@dept_id\"),\n    (\"Score\", \"@score_worst{0.0000}\")\n]\n\nv1 = figure(plot_width = 700, plot_height = 400, y_range = df_dept_best_worst.dept_id.values, title = \"Best and Worst Department\")\nv11 = v1.hbar(\"dept_id\", right = \"score_best\", source = source_1, height = 0.75, alpha = 0.6, color = \"green\")\nv12 = v1.hbar(\"dept_id\", right = \"score_worst\", source = source_1, height = 0.75, alpha = 0.6, color = \"red\")\n\nv1.add_tools(HoverTool(renderers = [v11], tooltips = tooltips_1))\nv1.add_tools(HoverTool(renderers = [v12], tooltips = tooltips_2))\n\nv1.xaxis.axis_label = \"WRMSSE Score\"\nv1.yaxis.axis_label = \"Department\"\n\n\ndef get_dept_plot(df, dept_id):\n    \"\"\"\n    Plots the actual and predicted values of dept_id\n    \"\"\"\n    actual_dates = [\"d_\" + str(x) for x in range(1914, 1942)]\n    predicted_dates = [\"pred_d_\" + str(x) for x in range(1914, 1942)]\n    \n    source = ColumnDataSource(data = dict(\n        date_number = actual_dates,\n        date = LB_DATES,\n        weekday = LB_WEEKDAYS,\n        actual = df.loc[df.dept_id == dept_id, actual_dates].values[0],\n        predicted = df.loc[df.dept_id == dept_id, predicted_dates].values[0]\n    ))\n\n    tooltips = [\n        (\"Date\", \"@date\"),\n        (\"Weekday\", \"@weekday\"),\n        (\"Actual\", \"@actual{0}\"),\n        (\"Predicted\", \"@predicted{0.0}\")\n    ]\n\n    v = figure(plot_width = 700, plot_height = 400, x_range = actual_dates, tooltips = tooltips, title = f\"Department: {dept_id}\")\n    v.line(\"date_number\", \"actual\", source = source, color = \"steelblue\", alpha = 0.6, width = 3, legend_label = \"Actual\")\n    v.line(\"date_number\", \"predicted\", source = source, color = \"coral\", alpha = 0.6, width = 3, legend_label = \"Predicted\")\n\n    v.xaxis.axis_label = \"Date\"\n    v.yaxis.axis_label = \"Sales\"\n\n    v.xaxis.major_label_orientation = pi / 4\n\n    return v\n\nv2 = get_dept_plot(df_dept, df_dept_best_worst.dept_id.values[-1])\nv3 = get_dept_plot(df_dept, df_dept_best_worst.dept_id.values[-2])\nv4 = get_dept_plot(df_dept, df_dept_best_worst.dept_id.values[-3])\nv5 = get_dept_plot(df_dept, df_dept_best_worst.dept_id.values[-4])\nv6 = get_dept_plot(df_dept, df_dept_best_worst.dept_id.values[-5])\nv7 = get_dept_plot(df_dept, df_dept_best_worst.dept_id.values[-6])\nv8 = get_dept_plot(df_dept, df_dept_best_worst.dept_id.values[-7])\n\n\nshow(column(v1, v2, v3, v4, v5, v6, v7, v8))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 9. State-Category\nLet's look at all the 9 state-category combinations.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_state_cat = evaluator.get_scores(preds_valid, 7)\ndf_state_cat[\"state_cat_id\"] = df_state_cat.state_id + \"-\" + df_state_cat.cat_id\n\ndf_state_cat_best = df_state_cat.sort_values(\"score_weighted\").head(4).rename(columns = {\"score_weighted\": \"score_best\"})\ndf_state_cat_worst = df_state_cat.sort_values(\"score_weighted\", ascending = False).head(5).sort_values(\"score_weighted\").rename(columns = {\"score_weighted\": \"score_worst\"})\n\ndf_state_cat_best_worst = pd.concat([df_state_cat_best, df_state_cat_worst])\n\nsource_1 = ColumnDataSource(data = dict(\n    state_cat_id = df_state_cat_best_worst.state_cat_id.values,\n    score_best = df_state_cat_best_worst.score_best.values,\n    score_worst = df_state_cat_best_worst.score_worst.values\n))\n\ntooltips_1 = [\n    (\"State-Category\", \"@state_cat_id\"),\n    (\"Score\", \"@score_best{0.0000}\")\n]\n\ntooltips_2 = [\n    (\"State-Category\", \"@state_cat_id\"),\n    (\"Score\", \"@score_worst{0.0000}\")\n]\n\nv1 = figure(plot_width = 700, plot_height = 400, y_range = df_state_cat_best_worst.state_cat_id.values, title = \"Best and Worst State-Category\")\nv11 = v1.hbar(\"state_cat_id\", right = \"score_best\", source = source_1, height = 0.75, alpha = 0.6, color = \"green\")\nv12 = v1.hbar(\"state_cat_id\", right = \"score_worst\", source = source_1, height = 0.75, alpha = 0.6, color = \"red\")\n\nv1.add_tools(HoverTool(renderers = [v11], tooltips = tooltips_1))\nv1.add_tools(HoverTool(renderers = [v12], tooltips = tooltips_2))\n\nv1.xaxis.axis_label = \"WRMSSE Score\"\nv1.yaxis.axis_label = \"State-Category\"\n\n\ndef get_state_cat_plot(df, state_cat_id):\n    \"\"\"\n    Plots the actual and predicted values of state-cat\n    \"\"\"\n    actual_dates = [\"d_\" + str(x) for x in range(1914, 1942)]\n    predicted_dates = [\"pred_d_\" + str(x) for x in range(1914, 1942)]\n    \n    source = ColumnDataSource(data = dict(\n        date_number = actual_dates,\n        date = LB_DATES,\n        weekday = LB_WEEKDAYS,\n        actual = df.loc[df.state_cat_id == state_cat_id, actual_dates].values[0],\n        predicted = df.loc[df.state_cat_id == state_cat_id, predicted_dates].values[0]\n    ))\n    \n    tooltips = [\n        (\"Date\", \"@date\"),\n        (\"Weekday\", \"@weekday\"),\n        (\"Actual\", \"@actual{0}\"),\n        (\"Predicted\", \"@predicted{0.0}\")\n    ]\n    \n    v = figure(plot_width = 700, plot_height = 400, x_range = actual_dates, tooltips = tooltips, title = f\"State-Category: {state_cat_id}\")\n    v.line(\"date_number\", \"actual\", source = source, color = \"steelblue\", alpha = 0.6, width = 3, legend_label = \"Actual\")\n    v.line(\"date_number\", \"predicted\", source = source, color = \"coral\", alpha = 0.6, width = 3, legend_label = \"Predicted\")\n\n    v.xaxis.axis_label = \"Date\"\n    v.yaxis.axis_label = \"Sales\"\n\n    v.xaxis.major_label_orientation = pi / 4\n\n    return v\n\nv2 = get_state_cat_plot(df_state_cat, df_state_cat_best_worst.state_cat_id.values[-1])\nv3 = get_state_cat_plot(df_state_cat, df_state_cat_best_worst.state_cat_id.values[-2])\nv4 = get_state_cat_plot(df_state_cat, df_state_cat_best_worst.state_cat_id.values[-3])\nv5 = get_state_cat_plot(df_state_cat, df_state_cat_best_worst.state_cat_id.values[-4])\nv6 = get_state_cat_plot(df_state_cat, df_state_cat_best_worst.state_cat_id.values[-5])\nv7 = get_state_cat_plot(df_state_cat, df_state_cat_best_worst.state_cat_id.values[-6])\nv8 = get_state_cat_plot(df_state_cat, df_state_cat_best_worst.state_cat_id.values[-7])\nv9 = get_state_cat_plot(df_state_cat, df_state_cat_best_worst.state_cat_id.values[-8])\nv10 = get_state_cat_plot(df_state_cat, df_state_cat_best_worst.state_cat_id.values[-9])\n\n\nshow(column(v1, v2, v3, v4, v5, v6, v7, v8, v9, v10))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 10. State\nLet's look at all the 3 states.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_state = evaluator.get_scores(preds_valid, 3)\n\ndf_state_best = df_state.sort_values(\"score_weighted\").head(1).rename(columns = {\"score_weighted\": \"score_best\"})\ndf_state_worst = df_state.sort_values(\"score_weighted\", ascending = False).head(2).sort_values(\"score_weighted\").rename(columns = {\"score_weighted\": \"score_worst\"})\n\ndf_state_best_worst = pd.concat([df_state_best, df_state_worst])\n\nsource_1 = ColumnDataSource(data = dict(\n    state_id = df_state_best_worst.state_id.values,\n    score_best = df_state_best_worst.score_best.values,\n    score_worst = df_state_best_worst.score_worst.values\n))\n\ntooltips_1 = [\n    (\"State\", \"@state_id\"),\n    (\"Score\", \"@score_best{0.0000}\")\n]\n\ntooltips_2 = [\n    (\"State\", \"@state_id\"),\n    (\"Score\", \"@score_worst{0.0000}\")\n]\n\nv1 = figure(plot_width = 700, plot_height = 400, y_range = df_state_best_worst.state_id.values, title = \"Best and Worst State\")\nv11 = v1.hbar(\"state_id\", right = \"score_best\", source = source_1, height = 0.75, alpha = 0.6, color = \"green\")\nv12 = v1.hbar(\"state_id\", right = \"score_worst\", source = source_1, height = 0.75, alpha = 0.6, color = \"red\")\n\nv1.add_tools(HoverTool(renderers = [v11], tooltips = tooltips_1))\nv1.add_tools(HoverTool(renderers = [v12], tooltips = tooltips_2))\n\nv1.xaxis.axis_label = \"WRMSSE Score\"\nv1.yaxis.axis_label = \"State\"\n\n\ndef get_state_plot(df, state_id):\n    \"\"\"\n    Plots the actual and predicted values of state_id\n    \"\"\"\n    actual_dates = [\"d_\" + str(x) for x in range(1914, 1942)]\n    predicted_dates = [\"pred_d_\" + str(x) for x in range(1914, 1942)]\n    \n    source = ColumnDataSource(data = dict(\n        date_number = actual_dates,\n        date = LB_DATES,\n        weekday = LB_WEEKDAYS,\n        actual = df.loc[df.state_id == state_id, actual_dates].values[0],\n        predicted = df.loc[df.state_id == state_id, predicted_dates].values[0]\n    ))\n\n    tooltips = [\n        (\"Date\", \"@date\"),\n        (\"Weekday\", \"@weekday\"),\n        (\"Actual\", \"@actual{0}\"),\n        (\"Predicted\", \"@predicted{0.0}\")\n    ]\n    \n    v = figure(plot_width = 700, plot_height = 400, x_range = actual_dates, tooltips = tooltips, title = f\"State: {state_id}\")\n    v.line(\"date_number\", \"actual\", source = source, color = \"steelblue\", alpha = 0.6, width = 3, legend_label = \"Actual\")\n    v.line(\"date_number\", \"predicted\", source = source, color = \"coral\", alpha = 0.6, width = 3, legend_label = \"Predicted\")\n\n    v.xaxis.axis_label = \"Date\"\n    v.yaxis.axis_label = \"Sales\"\n\n    v.xaxis.major_label_orientation = pi / 4\n\n    return v\n\nv2 = get_state_plot(df_state, df_state_best_worst.state_id.values[-1])\nv3 = get_state_plot(df_state, df_state_best_worst.state_id.values[-2])\nv4 = get_state_plot(df_state, df_state_best_worst.state_id.values[-3])\n\n\nshow(column(v1, v2, v3, v4))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 11. Category\nLet's look at all the 3 categories.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_cat = evaluator.get_scores(preds_valid, 2)\n\ndf_cat_best = df_cat.sort_values(\"score_weighted\").head(1).rename(columns = {\"score_weighted\": \"score_best\"})\ndf_cat_worst = df_cat.sort_values(\"score_weighted\", ascending = False).head(2).sort_values(\"score_weighted\").rename(columns = {\"score_weighted\": \"score_worst\"})\n\ndf_cat_best_worst = pd.concat([df_cat_best, df_cat_worst])\n\nsource_1 = ColumnDataSource(data = dict(\n    cat_id = df_cat_best_worst.cat_id.values,\n    score_best = df_cat_best_worst.score_best.values,\n    score_worst = df_cat_best_worst.score_worst.values\n))\n\ntooltips_1 = [\n    (\"Category\", \"@cat_id\"),\n    (\"Score\", \"@score_best{0.0000}\")\n]\n\ntooltips_2 = [\n    (\"Category\", \"@cat_id\"),\n    (\"Score\", \"@score_worst{0.0000}\")\n]\n\nv1 = figure(plot_width = 700, plot_height = 400, y_range = df_cat_best_worst.cat_id.values, title = \"Best and Worst Category\")\nv11 = v1.hbar(\"cat_id\", right = \"score_best\", source = source_1, height = 0.75, alpha = 0.6, color = \"green\")\nv12 = v1.hbar(\"cat_id\", right = \"score_worst\", source = source_1, height = 0.75, alpha = 0.6, color = \"red\")\n\nv1.add_tools(HoverTool(renderers = [v11], tooltips = tooltips_1))\nv1.add_tools(HoverTool(renderers = [v12], tooltips = tooltips_2))\n\nv1.xaxis.axis_label = \"WRMSSE Score\"\nv1.yaxis.axis_label = \"Category\"\n\n\ndef get_cat_plot(df, cat_id):\n    \"\"\"\n    Plots the actual and predicted values of cat_id\n    \"\"\"\n    actual_dates = [\"d_\" + str(x) for x in range(1914, 1942)]\n    predicted_dates = [\"pred_d_\" + str(x) for x in range(1914, 1942)]\n    \n    source = ColumnDataSource(data = dict(\n        date_number = actual_dates,\n        date = LB_DATES,\n        weekday = LB_WEEKDAYS,\n        actual = df.loc[df.cat_id == cat_id, actual_dates].values[0],\n        predicted = df.loc[df.cat_id == cat_id, predicted_dates].values[0]\n    ))\n    \n    tooltips = [\n        (\"Date\", \"@date\"),\n        (\"Weekday\", \"@weekday\"),\n        (\"Actual\", \"@actual{0}\"),\n        (\"Predicted\", \"@predicted{0.0}\")\n    ]\n\n    v = figure(plot_width = 700, plot_height = 400, x_range = actual_dates, tooltips = tooltips, title = f\"Category: {cat_id}\")\n    v.line(\"date_number\", \"actual\", source = source, color = \"steelblue\", alpha = 0.6, width = 3, legend_label = \"Actual\")\n    v.line(\"date_number\", \"predicted\", source = source, color = \"coral\", alpha = 0.6, width = 3, legend_label = \"Predicted\")\n\n    v.xaxis.axis_label = \"Date\"\n    v.yaxis.axis_label = \"Sales\"\n\n    v.xaxis.major_label_orientation = pi / 4\n\n    return v\n\nv2 = get_cat_plot(df_cat, df_cat_best_worst.cat_id.values[-1])\nv3 = get_cat_plot(df_cat, df_cat_best_worst.cat_id.values[-2])\nv4 = get_cat_plot(df_cat, df_cat_best_worst.cat_id.values[-3])\n\n\nshow(column(v1, v2, v3, v4))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 12. All\nLet's look at all levels aggregated together.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df = evaluator.get_scores(preds_valid, 1)\n\nsource_1 = ColumnDataSource(data = dict(\n    level = [\"All\"],\n    score = df.score_weighted.values\n))\n\ntooltips_1 = [\n    (\"Level\", \"all\"),\n    (\"Score\", \"@score{0.0000}\")\n]\n\nv1 = figure(plot_width = 700, plot_height = 200, y_range = [\"All\"], tooltips = tooltips_1, title = \"All levels\")\nv1.hbar(\"level\", right = \"score\", source = source_1, height = 0.5, alpha = 0.6, color = \"red\")\n\nv1.xaxis.axis_label = \"WRMSSE Score\"\n\nactual_dates = [\"d_\" + str(x) for x in range(1914, 1942)]\npredicted_dates = [\"pred_d_\" + str(x) for x in range(1914, 1942)]\n\nsource_2 = ColumnDataSource(data = dict(\n    date_number = actual_dates,\n    date = LB_DATES,\n    weekday = LB_WEEKDAYS,\n    actual = df[actual_dates].values[0],\n    predicted = df[predicted_dates].values[0]\n))\n    \ntooltips = [\n    (\"Date\", \"@date\"),\n    (\"Weekday\", \"@weekday\"),\n    (\"Actual\", \"@actual{0}\"),\n    (\"Predicted\", \"@predicted{0.0}\")\n]\n    \n    \nv2 = figure(plot_width = 700, plot_height = 400, x_range = actual_dates, tooltips = tooltips, title = \"All levels\")\nv2.line(\"date_number\", \"actual\", source = source_2, color = \"steelblue\", alpha = 0.6, width = 3, legend_label = \"Actual\")\nv2.line(\"date_number\", \"predicted\", source = source_2, color = \"coral\", alpha = 0.6, width = 3, legend_label = \"Predicted\")\n\nv2.xaxis.axis_label = \"Date\"\nv2.yaxis.axis_label = \"Sales\"\n\nv2.xaxis.major_label_orientation = pi / 4\n\nshow(column(v1, v2))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Anatomy to Action\nIt's not just about summarizing and plotting these graphs. It's about extracting insights from them and converting them into code/actions that can help in improving the model's performance on the private test data. Not just to overfit the public LB.\n\nApart from the validation and stability of the models there is also the factor of changing weights of the items since **the weights are different for public LB and private LB**. A summary of the same is shared here: https://www.kaggle.com/rohanrao/m5-the-weighing-scale\n\nGood Luck!\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}