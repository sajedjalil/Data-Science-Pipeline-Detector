{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Objective\n\nIn my baseline validation set consist on the last 28 days of the training data. \n\nThe problem in doing this is the following:\n\nAre we sure that this validation aligns with the test set?? (unknown demand and behaviour)\n\nWe really don't know, thats what we need to predict xD.\n\nFor this reason the best solution is to make a model that can generalize to unseen data (unknown demand and behaviour). Here we are going to validate the entire training data with GroupKFold strategy to avoid data leakage.\n\nThe main point on doing this is that the mean of different validations can generalize to a wide range of cases, we will not have the best model for our test but we reduce the chance of overfitting and have a horrible score.\n\nBest model is to get a validation that is really similar to the test set, but we don't know which one it is, this is unknown, we can make some guesses or found a statistical ground to choose the right validation set.\n\nAnother problem that we face is the loss function. Root mean squared error is not align with our competition metric (lower rmse does not guarantee a smaller wrmsse). For this we will use an asymmetric mean squared error loss function. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\nimport pandas as pd\nimport numpy as np\npd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)\nfrom typing import Union\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn import preprocessing\nimport gc\nimport lightgbm as lgb\nfrom datetime import datetime, timedelta\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn import metrics\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# helper functions to reduce memory\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df\n\n# function to read our data\ndef read_data():\n    # read data\n    data = pd.read_pickle('/kaggle/input/m5-reduce-data/data_small.pkl')\n    # fillna and label encode categorical features\n    data = transform(data)\n    # read submission\n    submission = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sample_submission.csv')\n    return data, submission\n\n# filla na and label encode categorical features\ndef transform(data):\n    \n    nan_features = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n    for feature in nan_features:\n        data[feature].fillna('unknown', inplace = True)\n        \n    cat = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', \n           'event_name_2', 'event_type_2']\n    for feature in cat:\n        encoder = preprocessing.LabelEncoder()\n        data[feature] = encoder.fit_transform(data[feature])\n        \n    # reduce memory usage\n    data = reduce_mem_usage(data)\n    \n    return data\n\n# simple feature ingineer function\ndef simple_fe(data):\n    \n    data_fe = data[['id', 'demand']]\n    \n    window = 28\n    periods = [7, 15, 30, 90]\n    group = data_fe.groupby('id')['demand']\n    \n    # most recent lag data\n    for period in periods:\n        data_fe['demand_rolling_mean_t' + str(period)] = group.transform(lambda x: x.shift(window).rolling(period).mean())\n        data_fe['demand_rolling_std_t' + str(period)] = group.transform(lambda x: x.shift(window).rolling(period).std())\n        \n    # reduce memory\n    data_fe = reduce_mem_usage(data_fe)\n    \n    # get time features\n    data['date'] = pd.to_datetime(data['date'])\n    time_features = ['year', 'month', 'quarter', 'week', 'day', 'dayofweek', 'dayofyear']\n    dtype = np.int16\n    for time_feature in time_features:\n        data[time_feature] = getattr(data['date'].dt, time_feature).astype(dtype)\n        \n    # concat lag and rolling features with main table\n    lag_rolling_features = [col for col in data_fe.columns if col not in ['id', 'demand']]\n    data = pd.concat([data, data_fe[lag_rolling_features]], axis = 1)\n    \n    del data_fe\n    gc.collect()\n\n    return data\n\n# define custom loss function\ndef custom_asymmetric_train(y_pred, y_true):\n    y_true = y_true.get_label()\n    residual = (y_true - y_pred).astype(\"float\")\n    grad = np.where(residual < 0, -2 * residual, -2 * residual * 1.15)\n    hess = np.where(residual < 0, 2, 2 * 1.15)\n    return grad, hess\n\n# define custom evaluation metric\ndef custom_asymmetric_valid(y_pred, y_true):\n    y_true = y_true.get_label()\n    residual = (y_true - y_pred).astype(\"float\")\n    loss = np.where(residual < 0, (residual ** 2) , (residual ** 2) * 1.15) \n    return \"custom_asymmetric_eval\", np.mean(loss), False\n\n# define lgbm simple model\ndef run_lgb(data, features, cat_features):\n    \n    # reset_index\n    data.reset_index(inplace = True, drop = True)\n    \n    # going to evaluate with the last 28 days\n    x_train = data[data['date'] <= '2016-04-24']\n    y_train = x_train['demand']\n    test = data[data['date'] >= '2016-04-25']\n\n    # define random hyperparammeters\n    params = {\n        'boosting_type': 'gbdt',\n        'n_jobs': -1,\n        'seed': 42,\n        'learning_rate': 0.1,\n        'bagging_fraction': 0.85,\n        'bagging_freq': 1, \n        'colsample_bytree': 0.85,\n        'colsample_bynode': 0.85,\n        'min_data_per_leaf': 25,\n        'num_leaves': 200,\n        'lambda_l1': 0.5,\n        'lambda_l2': 0.5}\n    \n    oof = np.zeros(len(x_train))\n    preds = np.zeros(len(test))\n    \n    # GroupKFold by week, month to avoid leakage and overfitting (not entirely sure xD)\n    kf = GroupKFold(5)\n    # get subgroups for each week, year pair\n    group = x_train['week'].astype(str) + '_' + x_train['year'].astype(str)\n    for fold, (trn_idx, val_idx) in enumerate(kf.split(x_train, y_train, group)):\n        print(f'Training fold {fold + 1}')\n        train_set = lgb.Dataset(x_train.iloc[trn_idx][features], y_train.iloc[trn_idx], \n                                categorical_feature = cat_features)\n        val_set = lgb.Dataset(x_train.iloc[val_idx][features], y_train.iloc[val_idx], \n                              categorical_feature = cat_features)\n        \n        # train with our custom loss function and evaluation metric\n        model = lgb.train(params, train_set, num_boost_round = 10000, early_stopping_rounds = 50, \n                          valid_sets = [train_set, val_set], verbose_eval = 50, fobj = custom_asymmetric_train, \n                          feval = custom_asymmetric_valid)\n    \n        # predict oof\n        oof[val_idx] = model.predict(x_train.iloc[val_idx][features])\n\n        # predict test\n        preds += model.predict(test[features]) / 5\n        \n        print('-'*50)\n        print('\\n')\n        \n    oof_rmse = np.sqrt(metrics.mean_squared_error(y_train, oof))\n    print(f'Our out of folds rmse is {oof_rmse}')\n        \n    test = test[['id', 'date', 'demand']]\n    test['demand'] = preds\n    return test\n\n# function to get the predictions in the correct format\ndef predict(test, submission):\n    predictions = pd.pivot(test, index = 'id', columns = 'date', values = 'demand').reset_index()\n    predictions.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]\n\n    evaluation_rows = [row for row in submission['id'] if 'evaluation' in row] \n    evaluation = submission[submission['id'].isin(evaluation_rows)]\n\n    validation = submission[['id']].merge(predictions, on = 'id')\n    final = pd.concat([validation, evaluation])\n    final.to_csv('submission_custom_loss.csv', index = False)\n    \n# this is the main function that will run our entire program\ndef train_and_evaluate():\n    \n    # read data\n    print('Reading our data...')\n    data, submission = read_data()\n    \n    data['date'] = pd.to_datetime(data['date'])\n    # get amount of unique days in our data\n    days = abs((data['date'].min() - data['date'].max()).days)\n    # how many training data do we need to train with at least 2 years and consider lags\n    need = 365 + 365 + 90 + 28\n    print(f'We have {(days - 28)} days of training history')\n    print(f'we have {(days - 28 - need)} days left')\n    if (days - 28 - need) > 0:\n        print('We have enought training data, lets continue')\n    else:\n        print('Get more training data, training can fail')\n    \n    # simple feature engineer\n    print('Running simple feature engineering...')\n    data = simple_fe(data)\n    print('Removing first 118 days')\n    # eliminate the first 118 days of our train data because of lags\n    min_date = data['date'].min() + timedelta(days = 118)\n    data = data[data['date'] > min_date]\n    \n    # define our numeric features and categorical features\n    features = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'year', \n                'month', 'quarter', 'week', 'day', 'dayofweek', 'dayofyear', 'demand_rolling_mean_t7', 'demand_rolling_mean_t15', 'demand_rolling_mean_t30', 'demand_rolling_mean_t90',\n                'demand_rolling_std_t7', 'demand_rolling_std_t15', 'demand_rolling_std_t30', 'demand_rolling_std_t90']\n    \n    cat_features = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', \n                    'event_name_2', 'event_type_2']\n    \n    print('-'*50)\n    print('\\n')\n    print(f'Training model with {len(features)} features...')\n    # run lgbm model with 5 GroupKFold (subgroups by year, month)\n    test = run_lgb(data, features, cat_features)\n    print('Save predictions...')\n    # predict\n    predict(test, submission)\n        \n# run our program\ntrain_and_evaluate()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}