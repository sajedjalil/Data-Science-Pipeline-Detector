{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\nIn this Notebook we are going to understand everything related to M5 Forecasting - Accuracy competition data. \nThe dataset involves the unit sales of 3,049 products, classified in 3 product categories (Hobbies, Foods, and Household) and 7 product departments, in which the above-mentioned categories are disaggregated.  The products are sold across ten stores, located in three States (CA, TX, and WI).","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# Data Analysis\nimport pandas as pd\nimport numpy as np\n\n# Data Visualization\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.io as pio\nimport plotly.offline as py\n\npy.init_notebook_mode(connected=True)\n\n# Data analysis custom settings\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"base_layout = dict(\n    colorway = ['#ff5200', '#6f0000', '#00263b'] +\n    [ '#ffa41b', '#000839', '#005082', '#00a8cc']+\n    ['#000839', '#00a8cc']\n    + ['#eb4559', '#f78259', '#522d5b'],\n)\nbase_fig = go.Figure(\n    layout = base_layout\n)\ntemplate_fig = pio.to_templated(base_fig)\npio.templates['m5'] = template_fig.layout.template\npio.templates.default = 'm5'\npio.renderers.default = 'kaggle'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.getcwd()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv')\ncalendar = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/calendar.csv')\nprices = pd.read_csv('/kaggle/input/m5-forecasting-accuracy/sell_prices.csv')\n\nfor d in np.arange(1914, 1970):\n    col = 'd_'+str(d)\n    sales[col] = 0\n    sales[col] = sales[col].astype(np.int16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Downcasting\n\nDowncasting is pretty importat for optimizing memory usage. I take an reference from https://www.kaggle.com/anshuls235/m5-forecasting-eda-feature-engineering. Please check that notebook for more details.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Downcasting\n\ndef downcast(df):\n    dtypes = df.dtypes\n    cols = dtypes.index.tolist()\n    types = dtypes.values.tolist()\n    \n    for col, typ in zip(cols, types):\n        \n        if 'int' in str(typ):\n            if df[col].min() > np.iinfo(np.int8).min and \\\n                df[col].max() < np.iinfo(np.int8).max:\n                df[col] = df[col].astype(np.int8)\n            \n            elif df[col].min() > np.iinfo(np.int16).min and \\\n                df[col].max() < np.iinfo(np.int16).max:\n                df[col] = df[col].astype(np.int16)\n                \n            elif df[col].min() > np.iinfo(np.int32).min and \\\n                df[col].max() < np.iinfo(np.int32).max:\n                df[col] = df[col].astype(np.int32)\n                \n            else:\n                df[col] = df[col].astype(np.int64)\n                \n        elif 'float' in str(typ):\n            if df[col].min() > np.finfo(np.float16).min and \\\n                df[col].max() < np.finfo(np.float16).max:\n                df[col] = df[col].astype(np.float16)\n                \n            elif df[col].min() > np.finfo(np.float32).min and \\\n                df[col].max() < np.finfo(np.float32).max:\n                df[col] = df[col].astype(np.float32)\n                \n            else:\n                df[col] = df[col].astype(np.float64)\n                \n        elif typ == np.object:\n            if col == 'date':\n                df[col] = pd.to_datetime(df[col], format='%Y-%m-%d')\n                \n            else:\n                df[col] = df[col].astype('category')\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales = downcast(sales)\ncalendar = downcast(calendar)\nprices = downcast(prices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.melt(\n    sales,\n    id_vars=[\n        'id',\n        'item_id',\n        'dept_id',\n        'cat_id',\n        'store_id',\n        'state_id'\n    ],\n    var_name='d',\n    value_name='sold'\n).dropna()\n\ndf = pd.merge(df, calendar, on='d', how='left')\n\ndf = pd.merge(\n    df,\n    prices,\n    on=['store_id','item_id','wm_yr_wk'],\n    how='left') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"day = [\n    'Monday',\n    'Tuesday',\n    'Thursday',\n    'Wednesday',\n    'Friday',\n    'Saturday',\n    'Sunday'\n]\n\ndf['weekday'] = pd.Categorical(\n    df['weekday'],\n    categories=day,\n    ordered=True\n)\ndf['revenue'] = df.sold*df.sell_price","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Setting colors coherently\nthis is important to keep track easily to each variable. \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"categories = pd.DataFrame(\n    df.cat_id.unique(),\n    columns=['cat_id']\n)\ncategories['color'] = ['#ff5200', '#6f0000', '#00263b']\ncategories.set_index('cat_id', inplace=True)\n\nevent_t1_df = pd.DataFrame(\n    calendar.event_type_1.dropna().unique(),\n    columns=['event_type_1']\n)\nevent_t1_df['color'] = [\n    '#ffa41b',\n    '#000839',\n    '#005082',\n    '#00a8cc'\n]\nevent_t1_df.set_index('event_type_1', inplace=True)\n\nevent_t2_df = pd.DataFrame(\n    calendar.event_type_2.dropna().unique(),\n    columns=['event_type_2']\n)\nevent_t2_df['color'] = ['#000839', '#00a8cc']\nevent_t2_df.set_index('event_type_2', inplace=True)\n\n\nstates = pd.DataFrame(\n    df.state_id.unique(),\n    columns=['state_id']\n)\nstates['color'] = ['#eb4559', '#f78259', '#522d5b']\nstates.set_index('state_id', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory data analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Categories and department behavior\n- FOODS category is the most sold.\n- Most of the items sold are in the FOODS_3 department, second place HOUSEHOLD_1 and third FOODS_2. \n- Each department has a product that sells a lot more than the rest. These are FOODS_3, HOUSEHOLD_1 and HOBBIES_1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bar_data = df.groupby(\n    ['cat_id', 'dept_id']\n)['sold'].sum().dropna()\n\nfig = go.Figure()\n\nfor cat in [ 'HOBBIES','HOUSEHOLD','FOODS']:\n    \n    bar_data_fil = bar_data.loc[(cat, )].sort_values()\n    trace = go.Bar(\n        y = bar_data_fil.index.get_level_values(0),\n        x = bar_data_fil.values,\n        marker_color=categories.loc[(cat), 'color'],\n        orientation='h',\n        name = cat,\n        texttemplate = '<b>%{x}</b>',\n        textposition='inside',\n    )\n    fig.add_trace(trace)\nfig.update_layout(\n    title = dict(text = 'UNITS SOLD BY DEPTARTMENT'),\n    legend = dict(x=0.85, y=0.1),\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# states and stores behavior\n- CA is the top item seller.\n- CA_3, TX_2, WI_2 are top item sellers of their respective states.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bar_data = df.groupby(\n    ['state_id', 'store_id']\n)['sold'].sum().dropna()\n\nfig = go.Figure()\n\nfor state in list(bar_data.index.levels[0])[::-1]:\n    \n    bar_data_fil = bar_data.loc[(state, )].sort_values()\n    trace = go.Bar(\n        y = bar_data_fil.index.get_level_values(0),\n        x = bar_data_fil.values,\n        marker_color=states.loc[(state), 'color'],\n        orientation='h',\n        name = state,\n        texttemplate = '<b>%{x}</b>',\n        textposition='inside',\n    )\n    fig.add_trace(trace)\nfig.update_layout(\n    title = dict(text = 'UNITS SOLD BY STORE'),\n    legend = dict(x=0.9, y=0.1),\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Stores and departments behavior\n- CA_3 is the best seller in FOODS_3 department, beating second place CA_1 by more than 1 million.\n- CA_3 is the best seller in HOUSEHOLD_1.\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df.groupby(\n    ['state_id', 'store_id', 'cat_id', 'dept_id']\n)['sold'].sum()\n\ndata = data.unstack(level=[-2,-1])\\\n        .dropna(axis=1, how='all')\\\n        .dropna(axis=0, how='all')\n\nfig = go.Figure()\ntrace = go.Heatmap(\n    y = [\n        data.index.get_level_values(0),\n        data.index.get_level_values(1)\n    ],\n    x = [\n        data.columns.get_level_values(0),\n        data.columns.get_level_values(1)\n    ],\n    z = data.values,\n    coloraxis = 'coloraxis'\n    \n)\nfig.add_trace(trace)\nfig.update_layout(\n    title = dict(\n        text = 'UNITS SOLD BY STORE AND DEPARTMENT'\n    ),\n    coloraxis = dict(colorscale = 'Cividis')\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- It seems that HOUSEHOLD_1 has a growing demand tendency.\n- FOODS_3 seems to have its peaks in the mid-year.\n- Demand on FOODS_2 is growing in the last periods.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df.groupby(['cat_id', 'dept_id', pd.Grouper(key='date', freq='M')])['sold'].sum()\ndata = data[data>0]\nfig = px.line(\n    data_frame=data.reset_index(),\n    x = 'date',\n    y = 'sold',\n    color = 'dept_id',\n    facet_col='cat_id'\n)\nfig.update_xaxes(nticks=7)\nfig.update_layout(\n    title = dict(text = 'UNITS SOLD BY MONTH-YEAR')\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- In all the departments the quantity of items sold is higher on the weekend, except in HOBBIES_2, which keeps the slope flat.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df.loc[df.sold>0].groupby(['cat_id', 'dept_id', 'weekday'])['sold'].mean().reset_index()\nfig = px.line(\n    data_frame=data,\n    x = 'weekday',\n    y = 'sold',\n    color = 'dept_id',\n    facet_col = 'cat_id',\n)\nfig.update_layout(\n    title = dict(text='AVERAGE UNITS SOLD BY DEPARTMENT')\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Over time, the average number of units sold in each department has gradually decreased.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df.loc[df.sold>0].groupby(\n    ['cat_id', 'dept_id', pd.Grouper(key='date', freq='M')]\n)['sold'].mean()\n\nfig = px.line(\n    data_frame=data.reset_index(),\n    x = 'date',\n    y = 'sold',\n    color = 'dept_id',\n    facet_col = 'cat_id',\n    render_mode='svg'\n)\n\nfig.update_xaxes(nticks=7)\nfig.update_layout(\n    title = dict(text = 'AVERAGE UNITS SOLD BY MONTH-YEAR')\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- The days that occur before a purchase have gradually decreased. Which means that the average quantity of consumption has decreased, but people come more often to make their purchases.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"selling_days = df.loc[df.sold>0].groupby(['cat_id', 'dept_id', pd.Grouper(key='date', freq='M')]).size()\nactive_days = df.groupby(['cat_id', 'dept_id', pd.Grouper(key='date', freq='M')]).size()\ndata = active_days.div(selling_days).reset_index()\ndata.rename(columns={0:'sold'}, inplace = True)\n\nfig = px.line(\n    data_frame=data,\n    x = 'date',\n    y = 'sold',\n    color = 'dept_id',\n    facet_col = 'cat_id',\n    render_mode='svg'\n)\nfig.update_xaxes(nticks=7)\nfig.update_layout(\n    title = dict(text = 'AVERAGE FREQUENCY ASSISTANCE BY YEAR-MONTH')\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- In the middle of the year between June and August the number of units sold is higher and at the end of the year until the beginning of the next, sales reach their lowest peak, in all departments.\n- The is more distance at the highest and lowest peaks of CA_3.\n- Since 2015 CA_2 has started to rise in terms of quantity sold.\n- TX_3 outnumbered units sold to TX_1 since 2014.\n- Since July 2013 WI_2 is the store that sells the most units in the state of WI.\n- WI_3 units sold have declined from 2012 through 2014, where they reached their lowest peak. After that sales gradually increased again.\n- While WI_2 sales decreased, W_1 and W_3 sales increased considerably in 2012.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df.groupby(['state_id', 'store_id', pd.Grouper(key='date', freq='M')])['sold'].sum()\ndata = data[data>0]\n\nmetadata = dict()\nmetadata['traces'] = []\nmetadata['rows'] = []\nmetadata['cols'] = []\nmetadata['titles'] = []\n\nnrows = 1\nncols = 3\n\nfor idx, cat in enumerate(data.index.levels[0]): \n    row = (idx//ncols)+ 1\n    col = (idx%ncols)+ 1\n    fil_stores = data.loc[(cat, )]\n    \n    for store in fil_stores.index.remove_unused_levels().levels[0]:\n        fil_data = fil_stores.loc[(store, )]\n        trace = go.Scatter(\n            x = fil_data.index,\n            y = fil_data.values,\n            name = store,\n            showlegend=False,\n            hovertemplate= f'<b>Store:</b> {store}<br>' +\n                            '<b>Units Sold:</b> %{y}<br>' +\n                            '<b>Date:</b> %{x}'\n        )\n        metadata['traces'].append(trace)\n        metadata['rows'].append(row)\n        metadata['cols'].append(col)\n    metadata['titles'].append(cat)\n        \nfig = make_subplots(rows = nrows, cols=ncols, subplot_titles=metadata['titles'], shared_yaxes=True)\nfig.add_traces(data = metadata['traces'], rows=metadata['rows'], cols = metadata['cols'])\nfig.update_layout(\n    title = dict(text = 'UNITS SOLD BY STORE')\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- More units are sold on the weekend, especially on weekends in August and September. Although in 2016 the weekends of February and March have exceeded the sales of past years during the same period.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data \ndata = df.groupby(\n    ['cat_id', 'date']\n)['sold'].sum().reset_index()\n\ndata['year'] = data.date.dt.year\ndata['month'] = pd.Categorical(\n    data.date.dt.month_name().str.slice(stop=3), \n                               categories = [\n                                   'Jan',\n                                   'Feb',\n                                   'Mar',\n                                   'Apr',\n                                   'May',\n                                   'Jun',\n                                   'Jul',\n                                   'Aug',\n                                   'Sep',\n                                   'Oct',\n                                   'Nov',\n                                   'Dec'\n                               ],\n                               ordered = True\n)\n\ndata['weekday'] = pd.Categorical(\n    data.date.dt.day_name(),\n    categories=day,\n    ordered=True\n)\n\n# subplots info\nmetadata = dict()\nmetadata['traces'] = []\nmetadata['rows'] = []\nmetadata['cols'] = []\nmetadata['titles'] = []\n\nnrows = 6\nncols = 1\n\nfor idx, year in enumerate(data.year.unique()):\n    \n    row_mask = data.year==year\n    col_mask = ['month', 'weekday', 'sold']\n    fil_data = data.loc[row_mask, col_mask]\\\n                        .pivot_table(columns='month', index='weekday')\\\n                        .sort_index(ascending=False)\n    trace = go.Heatmap(\n        x = fil_data.columns.get_level_values(1),\n        y = fil_data.index,\n        z = fil_data.values,\n        coloraxis = 'coloraxis',\n        name=''\n    )\n    fig.add_trace(trace)\n    \n    #updating subplots info\n    metadata['traces'].append(trace)\n    metadata['rows'].append(idx+1)\n    metadata['cols'].append(1)\n    metadata['titles'].append(str(year))\n    \nfig = make_subplots(\n    rows = nrows,\n    cols = ncols,\n    subplot_titles=metadata['titles'],\n    shared_xaxes=True,\n    shared_yaxes=True,\n)\n\nfig.add_traces(\n    data = metadata['traces'],\n    rows = metadata['rows'],\n    cols = metadata['cols'],\n)\n\nfig.update_layout(\n    title = 'UNITS SOLD BY DAY OF WEEK',\n    height=900,\n    coloraxis=dict(colorscale='Cividis'), showlegend=False\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's review the influence of different types of events on the quantity of items sold.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = df.groupby(['date', 'cat_id'])['sold'].sum().reset_index()\ndata1 = df.groupby(['date', 'cat_id'])['sold'].sum().rolling(14).mean().reset_index()\ndata = data.merge(data1, how='outer', on=['date', 'cat_id'])\ndata.columns = ['date', 'cat_id', 'sold', 'sold_ma']\nevent_cols = list(calendar.columns[calendar.columns.str.contains('event|snap')]) + ['date']\ndata = data.merge(calendar[event_cols], how='outer', on='date')\ndel(data1)\n\nmetadata = dict()\nmetadata['traces'] = []\nmetadata['rows'] = []\nmetadata['cols'] = []\nmetadata['titles'] = []\n\nnrows = 4\nncols = 1\nfor idx, event in enumerate(data.event_type_1.unique().dropna()):\n    for cat in data.cat_id.unique():\n        mask = (data.cat_id == cat)\n        mask1 = (data.event_type_1 == event)\n        fil_data = data.loc[mask]\n        fil_data2 = data.loc[mask&mask1]\n        if idx == 0:\n            showlegend = True\n        else:\n            showlegend = False\n        trace = go.Scatter(\n            x = fil_data.date,\n            y = fil_data.sold,\n            marker_color = categories.loc[(cat), 'color'],\n            legendgroup = f'Items sold MA - {cat}',\n            showlegend=showlegend,\n            name = f'Items sold - {cat}',\n            mode = 'lines',\n            hovertemplate = f'<b>Category: </b>{cat}<br>'+\n                            '<b>Sold Units: </b>%{y}<br>'+\n                            '<b>Date:</b>%{x}<br>'\n        )\n        metadata['traces'].append(trace)\n        metadata['rows'].append(idx+1)\n        metadata['cols'].append(1)\n        \n        trace2 = go.Scatter(\n            x = fil_data2.date,\n            y = fil_data2.sold,\n            marker_color = 'gold',\n            name = f'Items sold MA - {cat}',\n            legendgroup = f'Items sold MA - {cat}',\n            showlegend=False,\n            mode = 'markers',\n            text = fil_data2.event_name_1,\n            hovertemplate = '<b>Event Name:</b>%{text}',\n            texttemplate = '<b>%{text}'\n        )\n        metadata['traces'].append(trace2)\n        metadata['rows'].append(idx+1)\n        metadata['cols'].append(1)\n    metadata['titles'].append(f'Event type = {event}')\n    \nfig = make_subplots(\n    rows=nrows,\n    cols=ncols,\n    subplot_titles=metadata['titles'],\n    shared_xaxes=True,\n    shared_yaxes=True,\n)\nfig.add_traces(\n    data = metadata['traces'],\n    rows = metadata['rows'],\n    cols = metadata['cols'],\n)\nfig.update_layout(\n    height=900,\n    legend = dict(x=0.5, y=1.07, orientation='h'),\n    title = dict(text='IMPACT OF EVENT TYPES ON SOLD UNITS')\n)\nfig.show()        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def describe_moments(df):\n    my_aggs = dict(\n        sold = ['mean', 'median','std','skew', pd.DataFrame.kurt, 'sum', 'size'],\n        sell_price = ['mean', 'median','std','skew', pd.DataFrame.kurt],\n        revenue = ['mean', 'sum']\n    )\n    moments = df.groupby('item_id').agg(my_aggs)\n    moments.columns = moments.columns.get_level_values(0)+ '_' + moments.columns.get_level_values(1)\n    \n    moment_label = ['mean', 'median', 'std', 'skew', 'kurt']\n    for moment in moment_label:\n        col_min = moments[f'sold_{moment}'].min()\n        col_max = moments[f'sold_{moment}'].max()\n        print(f'{moment} {col_min}, {col_max}')\n    return moments","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"non_cero_moments = describe_moments(df[df.sold>0])\nnon_cero_moments['cat_id'] = np.array(non_cero_moments.index.str.extract('([A-Z]+)')[0])\nnon_cero_moments['dept_id'] = np.array(non_cero_moments.index.str.extract('([A-Z]+_\\d)')[0])\n\nselling_days = df[df.sold>0].groupby(['item_id'])['date'].size()\nactivity_horizon = df.groupby(['item_id'])['date'].size().div(selling_days)\nnon_cero_moments['avg_sold_days'] = non_cero_moments.index.map(activity_horizon)\n\nnon_cero_moments.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's analyze the global performance of each product:\n- We can notice that each department has a few items with higher performance than the rest.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=go.Figure()\nfor cat in non_cero_moments.cat_id.unique():\n    fil_data = non_cero_moments.loc[non_cero_moments.cat_id == cat]\n    trace = go.Box(\n        y = fil_data.dept_id,\n        x = fil_data.sold_mean,\n        marker_color = categories.loc[(cat), 'color'],\n        orientation = 'h',\n        name = cat,\n        hovertext = fil_data.index,\n        hovertemplate='<b>Item: </b>%{hovertext}<br>'+\n                        '<b>Department: </b>%{y}<br>'+\n                        '<b>Avg Sold Units: </b>%{x}<br>'\n    )\n    fig.add_trace(trace)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some quick observations:\n- 95% of the items are sold in batches of up to 10 units per assistance.\n- the FOODS category has more some more extreme products, even so they only represent 5% of the total items.\n- The mean and median of the quantities have a certain difference and this is due to the degree of asymmetry involved.\n- 95% of the items have a standard deviation of 8 units per transaction.\n- Most of the items have positive skewness, which justifies the superior performance of some products.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sold_cols = non_cero_moments.columns[non_cero_moments.columns.str.contains('sold')]\n\nmetadata = dict()\nmetadata['traces'] = []\nmetadata['rows'] = []\nmetadata['cols'] = []\nmetadata['titles'] = []\n\nnrows = 2\nncols = 4\n\nfor cat in non_cero_moments.cat_id.unique():\n    fil_cat_df = non_cero_moments.loc[non_cero_moments.cat_id == cat]\n\n    for idx, stat in enumerate(sold_cols):\n        row = (idx//ncols) + 1\n        col = (idx%ncols) + 1\n        color = categories.loc[cat, 'color'] \n        \n        if row ==1 and col==1:\n            showlegend = True\n        else:\n            showlegend = False\n            \n        trace = go.Histogram(\n            x = fil_cat_df[stat],\n            marker_color = color,\n            showlegend = showlegend,\n            legendgroup=cat,\n            opacity=0.4,\n            cumulative_enabled = True,\n            histnorm = 'probability',\n            name = cat\n        )\n        metadata['traces'].append(trace)\n        metadata['rows'].append(row)\n        metadata['cols'].append(col)\n        metadata['titles'].append(stat)\n    \nfig = make_subplots(rows=nrows, cols=ncols, subplot_titles = metadata['titles'])\nfig.add_traces(data=metadata['traces'], rows = metadata['rows'],\n               cols = metadata['cols'])\nfig.update_layout(\n    title = dict(text='DISTRIBUTIONS BY ITEM BEHAVIOR'),\n    xaxis_zeroline=False,\n    barmode='overlay'\n)\n# fig.update_yaxes(showticklabels=False)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the next graph we can observe a positive relationship between units sold mean and units sold standar deviation which involves that items with most sold items have bigger fluctuations.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.scatter(\n    data_frame = non_cero_moments.reset_index(),\n    x = 'sold_mean',\n    y = 'sold_std',\n    color = 'sold_kurt',\n    size = 'sold_skew',\n    facet_col='cat_id',\n    render_mode='svg'\n)\n\nfig.update_layout(\n#     title = 'UNITS SOLD BY DAY OF WEEK',\n    coloraxis=dict(colorscale='Cividis'), showlegend=False\n)\n\nfig.update_traces(\n    text = non_cero_moments.reset_index().item_id,\n    hovertemplate = '<b>Item: </b>%{text}<br>'+\n                    '<b>Sold Mean: </b>%{x:.2f}<br>'+\n                    '<b>Sold Std: </b>%{y:.2f}<br>'+\n                    '<b>Sold Skew: </b>%{marker.size:.2f}<br>'+\n                    '<b>Sold kurtosis: </b>%{marker.color:.2f}'\n)\n\nfig.update_layout(\n    title = dict(text='ITEMS BEHAVIOR BY CATEGORY')\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfig = px.scatter(\n    data_frame = non_cero_moments.reset_index(),\n    x = 'sold_mean',\n    y = 'sold_std',\n    size = 'revenue_sum',\n    color = 'sold_sum',\n    facet_col='cat_id',\n    render_mode='svg'\n)\nfig.update_layout(\n#     title = 'UNITS SOLD BY DAY OF WEEK',\n    coloraxis=dict(colorscale='Cividis'), showlegend=False\n)\nfig.update_traces(\n    text = non_cero_moments.reset_index().item_id,\n    hovertemplate = '<b>Item: </b>%{text}<br>'+\n                    '<b>Sold Mean: </b>%{x:.2f}<br>'+\n                    '<b>Sold Std: </b>%{y:.2f}<br>'+\n                    '<b>Total Revenue: </b>%{marker.size:,.0f}<br>'+\n                    '<b>Sold Units: </b>%{marker.color:,}'\n)\n\nfig.update_layout(\n    title = dict(text='ITEMS BEHAVIOR BY CATEGORY')\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top5_items = non_cero_moments.sold_sum.nlargest(5).index\n\ndef top5_plot(variable):\n    mycolors = ['#4d3e3e', '#bb3b0e', '#dd7631', '#708160', '#d8c593']\n    fig = make_subplots(rows = 2, cols = 1, subplot_titles=[f'Top 5 Items {variable} by Date', f'Top Items 5 {variable} Cumulative Distributions'])\n    for color, top in zip(mycolors, top5_items):\n        fil_df = df.loc[df.item_id == top].sort_values('date')\n\n        trace = go.Scatter(\n            x = fil_df.date,\n            y = fil_df[variable],\n            opacity=0.6,\n            marker_color = color,\n            legendgroup=top,\n            showlegend=False,\n            name = top,\n        )\n\n        fig.add_trace(trace, row=1, col=1)\n        trace1 = go.Histogram(\n            x = fil_df[variable],\n            opacity=0.6,\n            cumulative_enabled = True,\n            histnorm='probability',\n            marker_color = color,\n            legendgroup=top,\n            name = top,\n        )\n        fig.add_trace(trace1, row=2, col=1)\n    fig.update_layout(title = dict(text = f'Top 5 {variable}'), barmode='overlay')\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lest's obseve to top five items sold","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"top5_plot('sold')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"To do:\n- Price analysis.\n- Revenue analysis.\n- Seasonality and stacionarity analysis.\n\nIf you find it useful, please upvote. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}