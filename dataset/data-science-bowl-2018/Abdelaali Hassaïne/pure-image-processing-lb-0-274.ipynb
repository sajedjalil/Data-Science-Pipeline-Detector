{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"ac76a406-f2bd-4983-8aaa-9f35cc130bbf","_uuid":"98dd4df3bde2484278a6bc3e76f4e2f3738fa917"},"source":"**Overview**\n\nThis Kernel uses only the test data. However, some parameters have been tuned on the training data.\nIt reads the images, convert them into binary after some preprocessing steps, Then, it simply labels connected components and considers each obtained component as a nuclei."},{"cell_type":"markdown","metadata":{"_cell_guid":"4ae021eb-5807-47b6-9e7d-51735cdfb314","_uuid":"1b7f0851ca37aafdf1e3cb813f90d7f5eb417f11"},"source":"**Reading data**"},{"outputs":[],"cell_type":"code","metadata":{"_cell_guid":"963e73bf-7e69-4a68-845f-e4a4202cfff2","_uuid":"241c639d46630418b994f941241f75440a8f0f9e","collapsed":true},"execution_count":null,"source":"import os\nimport cv2\nimport numpy as np\n\ntest_dirs = os.listdir(\"../input/stage1_test\")\ntest_filenames=[\"../input/stage1_test/\"+file_id+\"/images/\"+file_id+\".png\" for file_id in test_dirs]\ntest_images=[cv2.imread(imagefile) for imagefile in test_filenames]\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"markdown","metadata":{"_cell_guid":"b9b352cb-aeb2-4c57-a997-3524007742e1","_uuid":"c73ceee4aa649ef416a620cce7de103818672145"},"source":"**List of operations to be performed on each image**"},{"outputs":[],"cell_type":"code","metadata":{"_cell_guid":"a1718431-6853-483f-8088-2eb17c3d3bc7","_uuid":"5e0c19f9bea88ae16e27fe93c8c6a4ca310e1fbb","collapsed":true},"execution_count":null,"source":"def process(img_rgb):\n    #green channel happends to produce slightly better results\n    #than the grayscale image and other channels\n    img_gray=img_rgb[:,:,1]#cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)\n    #morphological opening (size tuned on training data)\n    circle7=cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(7,7))\n    img_open=cv2.morphologyEx(img_gray, cv2.MORPH_OPEN, circle7)\n    #Otsu thresholding\n    img_th=cv2.threshold(img_open,0,255,cv2.THRESH_OTSU)[1]\n    #Invert the image in case the objects of interest are in the dark side\n    if(np.sum(img_th==255)>np.sum(img_th==0)):\n        img_th=cv2.bitwise_not(img_th)\n    #second morphological opening (on binary image this time)\n    bin_open=cv2.morphologyEx(img_th, cv2.MORPH_OPEN, circle7) \n    #connected components\n    cc=cv2.connectedComponents(bin_open)[1]\n    #cc=segment_on_dt(bin_open,20)\n    return cc"},{"cell_type":"markdown","metadata":{"_cell_guid":"595bd887-6c82-459e-931c-70046322dc16","_uuid":"6d1290b385b53607468cd465e503bcc84b8cadc5"},"source":"**Computing output for each image**"},{"outputs":[],"cell_type":"code","metadata":{"_cell_guid":"19d34dcb-4542-4032-bcd2-e7c47486a8b6","_uuid":"025dcf4c0217f908d44668864a6db5ecac2f0823","collapsed":true},"execution_count":null,"source":"test_connected_components=[process(img)  for img in test_images]"},{"cell_type":"markdown","metadata":{"_cell_guid":"ba78bd78-991f-4eba-8f0b-3970cc525e99","_uuid":"94125a7e7958d394a1a1e13fba2e476dd4fcf341"},"source":"**RLE encoding**\n\nTaken from this [kernel](https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277) but slghtly adapted to our case."},{"outputs":[],"cell_type":"code","metadata":{"_cell_guid":"815aa077-0598-4bf8-aeed-eb16f03d6b8e","_uuid":"d5b23bad42e75dae7cf1b0fe4acb5e4a5d585340","collapsed":true},"execution_count":null,"source":"def rle_encoding(cc):\n    values=list(np.unique(cc))\n    values.remove(0)\n    RLEs=[]\n    for v in values:\n        dots = np.where(cc.T.flatten() == v)[0]\n        run_lengths = []\n        prev = -2\n        for b in dots:\n            if (b>prev+1):\n                run_lengths.extend((b + 1, 0))\n            run_lengths[-1] += 1\n            prev = b\n        RLEs.append(run_lengths)\n    return RLEs\n\ntest_RLEs=[rle_encoding(cc) for cc in test_connected_components]"},{"cell_type":"markdown","metadata":{"_cell_guid":"12ad1cdc-f305-454f-b858-aa4aa4dc9039","_uuid":"2fe6b443d4449bf3d821da4e46eca82b78be86c5"},"source":"**Writing submission file**"},{"outputs":[],"cell_type":"code","metadata":{"_kg_hide-output":false,"_kg_hide-input":false,"_cell_guid":"0161f9e9-f87c-48ba-9eb5-cdc4848fb7de","_uuid":"12f09a801fe319627d8f1f9e5c307ad193ec7dcf","collapsed":true},"execution_count":null,"source":"with open(\"submission_image_processing.csv\", \"a\") as myfile:\n    myfile.write(\"ImageId,EncodedPixels\\n\")\n    for i,RLEs in enumerate(test_RLEs):\n        for RLE in RLEs:\n            myfile.write(test_dirs[i]+\",\"+\" \".join([str(i) for i in RLE])+\"\\n\")"}],"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"version":"3.6.4","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3"}},"nbformat_minor":1,"nbformat":4}