{"nbformat":4,"cells":[{"source":"This notebook provides additional information about stage1_train dataset that should help to balance into train/valid for cross-validation. \n\nIt starts from this interesting [thread](https://www.kaggle.com/c/data-science-bowl-2018/discussion/47640) about image types. Group A are histological slides, group B are fluorescent images, and group C are bright-field images. It can complete this other [kernel](https://www.kaggle.com/nhargan/defining-microscopy-type).\n\nIt looks we have the following breakdown:\n* fluorescent: 81.5%\n* histological: 16.1%\n* bright-field: 2.4%","cell_type":"markdown","metadata":{"_cell_guid":"3d54c5e7-943f-4f3a-8439-5adaec34c3ad","_uuid":"41e8768a852e7119e8f443b7e36da2d737f603dc"}},{"metadata":{"_cell_guid":"1a7d1b6f-caf0-4f08-91e1-1033a03faa37","collapsed":true,"_uuid":"e956727b1c0d4773f5d5b0d15c39e7504c55236a"},"outputs":[],"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport skimage.io\nimport os\nimport shutil\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom textwrap import wrap\nnp.random.seed(1234)\n%matplotlib inline","cell_type":"code","execution_count":11},{"source":"Initial variables.","cell_type":"markdown","metadata":{"_cell_guid":"be1dadef-d349-4f5f-a97e-5520ad71364f","_uuid":"14a44751e8f2e1dfd3bf5750155e8fe378b8303c"}},{"metadata":{"_cell_guid":"d60e3327-2d7f-4103-b6ba-1835a16e3aa7","collapsed":true,"_uuid":"ad6bb080218a350877fdcc9e02ed2128c6dd4e3b"},"outputs":[],"source":"STAGE1_TRAIN = \"../input/stage1_train\"\nSTAGE1_TRAIN_IMAGE_PATTERN = \"%s/{}/images/{}.png\" % STAGE1_TRAIN\nSTAGE1_TRAIN_MASK_PATTERN = \"%s/{}/masks/*.png\" % STAGE1_TRAIN\nIMAGE_ID = \"image_id\"\nIMAGE_WIDTH = \"width\"\nIMAGE_WEIGHT = \"height\"\nHSV_CLUSTER = \"hsv_cluster\"\nHSV_DOMINANT = \"hsv_dominant\"\nTOTAL_MASK = \"total_masks\"","cell_type":"code","execution_count":12},{"source":"Functions to load images. We keep only RGB channels as Alpha channel is always empty. ","cell_type":"markdown","metadata":{"_cell_guid":"5c7cb57e-2730-4c17-b221-e0b26019e113","_uuid":"2e5853f177298d5a9a2538f514c03848ae1a7556"}},{"metadata":{"_cell_guid":"ef7ac493-ac70-4f79-9c95-2111e91d0122","collapsed":true,"_uuid":"446f686631a0f3dfe7ff12724caf6dd888872767"},"outputs":[],"source":"def image_ids_in(root_dir, ignore=[]):\n    ids = []\n    for id in os.listdir(root_dir):\n        if id in ignore:\n            print('Skipping ID:', id)\n        else:\n            ids.append(id)\n    return ids","cell_type":"code","execution_count":13},{"metadata":{"_cell_guid":"f048dcb8-a660-4e48-9c4f-c571467cc77d","collapsed":true,"_uuid":"7a5b01078bdf9388692ab9b39403db613dc80f57"},"outputs":[],"source":"def read_image(image_id, space=\"rgb\"):\n    image_file = STAGE1_TRAIN_IMAGE_PATTERN.format(image_id, image_id)\n    image = skimage.io.imread(image_file)\n    # Drop alpha which is not used\n    image = image[:, :, :3]\n    if space == \"hsv\":\n        image = skimage.color.rgb2hsv(image)\n    return image","cell_type":"code","execution_count":14},{"metadata":{"_cell_guid":"e708a584-4148-47dc-a808-0c25c270a6fa","collapsed":true,"_uuid":"de172cc7bb74e907a4008dd96a6893564fa2ed83"},"outputs":[],"source":"# Get image width, height and count masks available.\ndef read_image_labels(image_id, space=\"rgb\"):\n    image = read_image(image_id, space = space)\n    mask_file = STAGE1_TRAIN_MASK_PATTERN.format(image_id)\n    masks = skimage.io.imread_collection(mask_file).concatenate()    \n    height, width, _ = image.shape\n    num_masks = masks.shape[0]\n    labels = np.zeros((height, width), np.uint16)\n    for index in range(0, num_masks):\n        labels[masks[index] > 0] = 255 #index + 1\n    return image, labels, num_masks","cell_type":"code","execution_count":15},{"metadata":{"_cell_guid":"3ad318a0-df14-453b-a3ea-98fd3e5a560c","collapsed":true,"_uuid":"5cafd4671fd072f2ed77be4b9b0cb6fe44b55d71"},"outputs":[],"source":"# Load stage 1 image identifiers.\ntrain_image_ids = image_ids_in(STAGE1_TRAIN)","cell_type":"code","execution_count":16},{"source":"Run KMeans on each image. Centroids provide dominant colors (based on provided colorspace). More details [here](https://www.pyimagesearch.com/2014/05/26/opencv-python-k-means-color-clustering/).","cell_type":"markdown","metadata":{"_cell_guid":"212f2e72-1319-4007-b94f-2f2099916c33","_uuid":"e9fe244236aa525307fe7cff156b5b03cd6608b4"}},{"metadata":{"_cell_guid":"c7e8881a-26de-40e9-baf3-dfbff94a2020","collapsed":true,"_uuid":"62ba0f22a5bfe4d858e038dcffe64e80434f88ac"},"outputs":[],"source":"def get_domimant_colors(img, top_colors=2):\n    img_l = img.reshape((img.shape[0] * img.shape[1], img.shape[2]))\n    clt = KMeans(n_clusters = top_colors)\n    clt.fit(img_l)\n    # grab the number of different clusters and create a histogram\n    # based on the number of pixels assigned to each cluster\n    numLabels = np.arange(0, len(np.unique(clt.labels_)) + 1)\n    (hist, _) = np.histogram(clt.labels_, bins = numLabels)\n    # normalize the histogram, such that it sums to one\n    hist = hist.astype(\"float\")\n    hist /= hist.sum()\n    return clt.cluster_centers_, hist","cell_type":"code","execution_count":17},{"metadata":{"_cell_guid":"2ab3394a-c48e-414e-bff4-4c64e5ba34ad","collapsed":true,"_uuid":"6ce9724fff3df5c79d8c96b7a2777a6c2f88b29c"},"outputs":[],"source":"def get_images_details(image_ids):\n    details = []\n    for image_id in image_ids:\n        image_hsv, labels, num_masks = read_image_labels(image_id, space=\"hsv\")\n        height, width, l = image_hsv.shape\n        dominant_colors_hsv, dominant_rates_hsv = get_domimant_colors(image_hsv, top_colors=1)\n        dominant_colors_hsv = dominant_colors_hsv.reshape(1, dominant_colors_hsv.shape[0] * dominant_colors_hsv.shape[1])\n        info = (image_id, width, height, num_masks, dominant_colors_hsv.squeeze())\n        details.append(info)\n    return details","cell_type":"code","execution_count":18},{"metadata":{"_cell_guid":"1bf93ca6-9290-4cd9-b83b-0fcb060b0aa1","collapsed":true,"_uuid":"fdd651473bc88a54e83461d43700f8b1ed4df4d2"},"outputs":[],"source":"META_COLS = [IMAGE_ID, IMAGE_WIDTH, IMAGE_WEIGHT, TOTAL_MASK]\nCOLS = META_COLS + [HSV_DOMINANT]","cell_type":"code","execution_count":19},{"metadata":{"_cell_guid":"2efae9d3-6982-4a90-bcc5-8d49459f55f0","_uuid":"9f9d246d5526956d52860a1473d38b235e8d20ea"},"outputs":[],"source":"details = get_images_details(train_image_ids)","cell_type":"code","execution_count":20},{"source":"KMeans to split images by 3 types (based on dominant HSV colors distributions)","cell_type":"markdown","metadata":{"_cell_guid":"67b2d543-4870-46a3-a730-a96160c0670e","_uuid":"df4259174bc35696907360463b447acd69e57b4d"}},{"metadata":{"_cell_guid":"c9d4521b-1465-498d-a8c8-28fead37bc83","collapsed":true,"_uuid":"5023956cc6f71995c026904edaab5e488235abbc"},"outputs":[],"source":"trainPD = pd.DataFrame(details, columns=COLS)\nX = (pd.DataFrame(trainPD[HSV_DOMINANT].values.tolist())).as_matrix()\nkmeans = KMeans(n_clusters=3).fit(X)\nclusters = kmeans.predict(X)\ntrainPD[HSV_CLUSTER] = clusters","cell_type":"code","execution_count":21},{"metadata":{"_cell_guid":"5a0c10c7-276f-45c1-9b85-6d19394eeebb","_uuid":"634a4a0e5b4d501125db53db2d038f581e227fc2"},"outputs":[],"source":"trainPD.head()","cell_type":"code","execution_count":22},{"source":"Plot some examples for each cluster.","cell_type":"markdown","metadata":{"_cell_guid":"417a250a-6335-4187-bcb5-0cbe9a86e7bf","_uuid":"78389296675293d4ca4e90a5322257e6d697c0c6"}},{"metadata":{"_cell_guid":"e36ed873-2fe3-4b10-a028-e0346e986a5a","collapsed":true,"_uuid":"f31915126cb946367a09dff4af610daddb28289f"},"outputs":[],"source":"def plot_images(images, images_rows, images_cols):\n    f, axarr = plt.subplots(images_rows,images_cols,figsize=(16,images_rows*2))\n    for row in range(images_rows):\n        for col in range(images_cols):\n            image_id = images[row*images_cols + col]\n            image = read_image(image_id)\n            height, width, l = image.shape\n            ax = axarr[row,col]\n            ax.axis('off')\n            ax.set_title(\"%dx%d\"%(width, height))\n            ax.imshow(image)","cell_type":"code","execution_count":23},{"source":"Some examples of cluster 0 (fluorescent images):","cell_type":"markdown","metadata":{"_cell_guid":"d6330c36-9405-4a03-8c3e-df4df3dc4b67","_uuid":"6d1e4caa3ce0b2e996fce782357bcbeadffe59c4"}},{"metadata":{"_cell_guid":"ba75d4ff-fad1-4d63-b69e-0f026dc6c2a4","_uuid":"a86a4784016e547a617772c1b16873a13a42201c"},"outputs":[],"source":"plot_images(trainPD[trainPD[HSV_CLUSTER] == 0][IMAGE_ID].values, 6, 8)","cell_type":"code","execution_count":24},{"source":"Some examples of cluster 1 (histological slides):","cell_type":"markdown","metadata":{"_cell_guid":"c32e0c25-59d6-410f-8a61-2d8f39a14e68","_uuid":"e8a545f4ec8e614e3db9933d40508d4cb5e6113e"}},{"metadata":{"_cell_guid":"cb25eec6-b06c-4d54-8d38-5407a5d80fcc","_uuid":"eae8b54e3581da38cc781aa5fb5e5e9baa6e565f"},"outputs":[],"source":"plot_images(trainPD[trainPD[HSV_CLUSTER] == 1][IMAGE_ID].values, 6, 8)","cell_type":"code","execution_count":25},{"source":"Some examples of cluster 2 (bright-field images):","cell_type":"markdown","metadata":{"_cell_guid":"f9068df6-cf2f-445e-a094-95992b39de94","_uuid":"abd7bcdf2d7007a8c6170f95384779354e06544e"}},{"metadata":{"_cell_guid":"4062d8ce-fbdb-40f0-b908-fc401f3d8d6a","_uuid":"18d550d159db567f6e2fc73779c0a243e1ab4b1b"},"outputs":[],"source":"plot_images(trainPD[trainPD[HSV_CLUSTER] == 2][IMAGE_ID].values, 2, 8)","cell_type":"code","execution_count":26},{"metadata":{"_cell_guid":"8739279e-5467-47da-b5e0-42c71bcb06db","_uuid":"d67a27a2c705a1d69b4fd451b7804e404843a5b1"},"outputs":[],"source":"P = trainPD.groupby(HSV_CLUSTER)[IMAGE_ID].count().reset_index()\nP['Percentage'] = 100*P[IMAGE_ID]/P[IMAGE_ID].sum()\nP","cell_type":"code","execution_count":27},{"metadata":{"_cell_guid":"171a168f-fc40-41fb-85f2-5f9b6df81fc6","_uuid":"d5d3859ffb0b8539c713bbcf4865dcf81ea7682d"},"outputs":[],"source":"f, ax = plt.subplots(1,1,figsize=(16,5))\nr = trainPD.plot(kind=\"hist\", bins=300, y = TOTAL_MASK, ax=ax, grid=True, title=\"Masks Histogram\")","cell_type":"code","execution_count":28},{"source":"Plot some images with masks:","cell_type":"markdown","metadata":{"_cell_guid":"5b834ecc-d66c-4b38-be9e-47810f5a1e60","_uuid":"9e8b0462235067ddfbaf9f11e6338591971e2f5d"}},{"metadata":{"_cell_guid":"80cc8170-5b37-4081-84a3-69b10a9f3833","collapsed":true,"_uuid":"72d8764ba687420a7915cc7cac3de347157351d4"},"outputs":[],"source":"def plot_image_masks(image, labels, num_masks, image_id):\n    f, ax = plt.subplots(1,3,figsize=(16,5))\n    d = ax[0].axis('off')\n    d = ax[0].imshow(image)\n    d = ax[0].set_title(\"\\n\".join(wrap(image_id, 32)))\n    d = ax[1].axis('off')\n    d = ax[1].imshow(labels)\n    d = ax[1].set_title(\"masks: %d\"%num_masks)\n    d = ax[2].axis('off')\n    d = ax[2].imshow(image)\n    d = ax[2].imshow(labels, alpha=0.5)\n    d = ax[2].set_title(\"both\")","cell_type":"code","execution_count":29},{"metadata":{"_cell_guid":"59b2bacb-bfc5-484f-ba4c-823695ec2fd8","collapsed":true,"_uuid":"dad6835537069f7c9475a937e90855ca7f4ff797"},"outputs":[],"source":"def display_image_masks(image_id):\n    image, labels, num_masks = read_image_labels(image_id)\n    plot_image_masks(image, labels, num_masks, image_id)","cell_type":"code","execution_count":30},{"metadata":{"_cell_guid":"83cadcda-df35-4c0c-a3d7-7a1da2215f69","_uuid":"d61c34dc38ee50f2c7749767afbdc7fd2e456789"},"outputs":[],"source":"display_image_masks(\"8f27ebc74164eddfe989a98a754dcf5a9c85ef599a1321de24bcf097df1814ca\")","cell_type":"code","execution_count":31},{"metadata":{"_cell_guid":"c2dd2866-e73a-40e6-a8a9-ed5b64b28ede","_uuid":"ce2d9a90cd6dbde1350932009d497a73b1b40222"},"outputs":[],"source":"display_image_masks(trainPD[trainPD[TOTAL_MASK] == trainPD[TOTAL_MASK].median()][IMAGE_ID].values[0])","cell_type":"code","execution_count":32},{"metadata":{"_cell_guid":"a014d789-7347-4156-a7cd-749db288de55","_uuid":"9c8738bbefa422fd2ce2acbb445dc7923948f953"},"outputs":[],"source":"display_image_masks(trainPD[trainPD[TOTAL_MASK] == trainPD[TOTAL_MASK].min()][IMAGE_ID].values[0])","cell_type":"code","execution_count":33},{"metadata":{},"outputs":[],"source":"display_image_masks(trainPD[trainPD[TOTAL_MASK] == trainPD[TOTAL_MASK].max()][IMAGE_ID].values[0])","cell_type":"code","execution_count":34}],"nbformat_minor":1,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"version":"3.6.4","name":"python","pygments_lexer":"ipython3","mimetype":"text/x-python","file_extension":".py","codemirror_mode":{"version":3,"name":"ipython"},"nbconvert_exporter":"python"}}}