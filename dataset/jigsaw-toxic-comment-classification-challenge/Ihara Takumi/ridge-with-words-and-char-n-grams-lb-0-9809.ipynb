{"cells":[{"metadata":{"_cell_guid":"1b5820b8-f1a3-4a02-8962-5b2334625d6b","_uuid":"920e65ec899210bbacf4581ae836592b286289b2","collapsed":true,"trusted":false},"cell_type":"code","source":"# I used the kernel and changed  LogisticRegression to Ridge.\n#https://www.kaggle.com/tunguz/logistic-regression-with-words-and-char-n-grams","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","collapsed":true,"trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import cross_val_score\nfrom scipy.sparse import hstack\n\nclass_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n\ntrain = pd.read_csv('../input/train.csv').fillna(' ')\ntest = pd.read_csv('../input/test.csv').fillna(' ')\n\ntrain_text = train['comment_text']\ntest_text = test['comment_text']\nall_text = pd.concat([train_text, test_text])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"trusted":false},"cell_type":"code","source":"word_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='word',\n    token_pattern=r'\\w{1,}',\n    stop_words='english',\n    ngram_range=(1, 1),\n    max_features=10000)\nword_vectorizer.fit(all_text)\ntrain_word_features = word_vectorizer.transform(train_text)\ntest_word_features = word_vectorizer.transform(test_text)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f74a9034-35e8-4027-a8f1-57c53d80a6b7","_uuid":"a0b114efc41ea4920c9082dc36107efa40ef831f","collapsed":true,"trusted":false},"cell_type":"code","source":"char_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='char',\n    stop_words='english',\n    ngram_range=(2, 6),\n    max_features=50000)\nchar_vectorizer.fit(all_text)\ntrain_char_features = char_vectorizer.transform(train_text)\ntest_char_features = char_vectorizer.transform(test_text)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c4530f45-fc1b-4616-9caf-8182c50d6edb","_uuid":"db71cab26ddb6c662ba1d5e1ff37457f1758cbfa","collapsed":true,"trusted":false},"cell_type":"code","source":"train_features = hstack([train_char_features, train_word_features])\ntest_features = hstack([test_char_features, test_word_features])\n\nscores = []\nsubmission = pd.DataFrame.from_dict({'id': test['id']})","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e637103a-4670-4928-a4cc-22e4851fb1e1","_uuid":"d49782dab6b339c6e47ae792dc2c2a39ca8c0e6e","collapsed":true,"trusted":false},"cell_type":"code","source":"for class_name in class_names:\n    train_target = train[class_name]\n    classifier = Ridge(alpha=20, copy_X=True, fit_intercept=True, solver='auto',\n                        max_iter=100,   normalize=False, random_state=0,  tol=0.0025)\n    classifier.fit(train_features, train_target)\n    submission[class_name] = classifier.predict(test_features)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"381c0359-2bc2-48df-a1be-d3711da93d48","_uuid":"391e24d75bc1656d00f4f7f4d894314dbb17f1fb","collapsed":true,"trusted":false},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}