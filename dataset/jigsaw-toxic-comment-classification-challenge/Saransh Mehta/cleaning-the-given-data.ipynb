{"nbformat":4,"nbformat_minor":1,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[],"metadata":{"_uuid":"3653f3dff3b656f0dc05eb27d1f9b929da36127f","_cell_guid":"fbb06c7b-4dd8-4ae0-b225-10fe6d7fa36e","collapsed":true}},{"cell_type":"code","source":"import re\nimport string\nimport os","execution_count":null,"outputs":[],"metadata":{"_uuid":"39e2f6e6b5b76e764f0f0cb4cb787617baf8436e","_cell_guid":"357f6d2e-51e6-405b-ac94-132ff249da86","collapsed":true}},{"cell_type":"code","source":"trainPath = \"../input/train.csv\"\ntestPath = \"../input/test.csv\"","execution_count":null,"outputs":[],"metadata":{"_uuid":"459ef28243c6d91fc03709f58b7df85ab3702c36","_cell_guid":"fcf19a0a-9dfe-493f-ba73-c31074ceff30","collapsed":true}},{"cell_type":"markdown","source":"Here I am just cleaning the text of both train and test datasets. Making it free from any kind of punctuations like !, ==, #, ? etc","metadata":{"_uuid":"2bf9c3e3618e71bbb993b4094563cf7d3c83ee5e","_cell_guid":"16e6c57e-5923-4f98-9fb3-b4233fd0e533"}},{"cell_type":"code","source":"df = pd.read_csv(trainPath)\ndf.head()","execution_count":null,"outputs":[],"metadata":{"_uuid":"bd63ef114294086393c9f524003a4dcec55984fe","_cell_guid":"342ec454-6f54-439f-a4a1-8cdef07f6ee0","collapsed":true}},{"cell_type":"markdown","source":"# we will make translation table (or dictionary) to remove punctions,\n# we ll map each punctuation to None, so translation will remove it whenever it finds it\n# specificaaly remove punctuations\n# we can also use the regex, re.sub(re.sub('[^a-zA-Z]+', '', sen))","metadata":{"_uuid":"0cc11d3b3175d3fb70a6df7b264406c42060c6cf","_cell_guid":"9291c18b-8e11-47a9-b8d6-3f16777d3249"}},{"cell_type":"code","source":"totalContentCleaned = []\npunctDict = {}\nfor punct in string.punctuation:\n    punctDict[punct] = None\ntransString = str.maketrans(punctDict)\n# since we intent to remove any punctuation with ''\nfor sen in df['comment_text']:\n    \n    #cleanedString = re.sub('[^a-zA-Z]+', '', sen)\n    \n    p = sen.translate(transString)\n    totalContentCleaned.append(p)","execution_count":null,"outputs":[],"metadata":{"_uuid":"0cd2a7cf3e51848bcad08bf038ec04df846150b6","_cell_guid":"89f021a2-c77a-43f1-a24f-0cce16c78860","collapsed":true}},{"cell_type":"code","source":"totalContentCleaned[:5]","execution_count":null,"outputs":[],"metadata":{"_uuid":"e6801f6725c07412e03ba1b6a989e7a267a600c9","_cell_guid":"68d94259-c31a-4bd7-b314-81db4afd0471","collapsed":true}},{"cell_type":"code","source":"df['comment_text'] = totalContentCleaned\n# we can save the file to csv if we want in local machine\n#df.to_csv(os.path.join(os.path.abspath('data'), 'train_cleaned.csv'), index = False)","execution_count":null,"outputs":[],"metadata":{"_uuid":"7bfbe284cfa5b0af3038e6cbee5b842dd57826a6","_cell_guid":"ebbb326b-7780-449e-906b-2682745461bd","collapsed":true}},{"cell_type":"code","source":"df2 = pd.read_csv(testPath)","execution_count":null,"outputs":[],"metadata":{"_uuid":"91ce4f55bca48e3a33cdef16dda8f9f7a0d9b999","_cell_guid":"4483ec47-c35f-4782-903c-2191916a5224","collapsed":true}},{"cell_type":"code","source":"df2.head()","execution_count":null,"outputs":[],"metadata":{"_uuid":"697d92f7370f8a4e2ee8c81f9f5202ef83ec530a","_cell_guid":"2030fd09-eeb5-4e63-97b8-efdbfa0dd067","collapsed":true}},{"cell_type":"code","source":"totalContentCleaned = []\nfor sen in df2['comment_text']:\n    \n    #cleanedString = re.sub('[^a-zA-Z]+', '', sen)\n    sen = str(sen)\n    p = sen.translate(transString)\n    totalContentCleaned.append(p)\ndf2['comment_text'] = totalContentCleaned","execution_count":null,"outputs":[],"metadata":{"_uuid":"e9b409d1d39a229373d0aa1964c4dbe7262430f7","_cell_guid":"15f53142-df7c-4628-bc91-c3c8afa852e1","collapsed":true}},{"cell_type":"code","source":"df2.head()\n#df2.to_csv(os.path.join(os.path.abspath('data'), 'test_cleaned.csv'), index = False)","execution_count":null,"outputs":[],"metadata":{"_uuid":"1d453de363f53c539eeda9429452c6940788d75d","_cell_guid":"decca1a1-0e49-4902-8940-020a6e279239","collapsed":true}},{"cell_type":"markdown","source":"# Thus we have done cleaning for both the files","metadata":{"_uuid":"173ef91c775484e09563581c7e14d4083208daad","_cell_guid":"86f103b4-079d-4bb2-b61f-7dcefbb9b56b"}},{"cell_type":"code","source":"","execution_count":null,"outputs":[],"metadata":{"_uuid":"811ea0d276089776cfacaf0bf80be40e0f537ea1","_cell_guid":"15e14a37-19e4-4dc4-893d-46477f113bdb","collapsed":true}}],"metadata":{"language_info":{"nbconvert_exporter":"python","codemirror_mode":{"version":3,"name":"ipython"},"version":"3.6.3","file_extension":".py","mimetype":"text/x-python","pygments_lexer":"ipython3","name":"python"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}}}