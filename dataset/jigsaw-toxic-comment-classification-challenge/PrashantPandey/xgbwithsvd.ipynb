{"nbformat":4,"nbformat_minor":1,"cells":[{"cell_type":"code","execution_count":null,"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport pandas as pd\nimport numpy as np\nimport re\nimport nltk\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import log_loss\nfrom sklearn.naive_bayes import MultinomialNB,GaussianNB\nfrom sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb\nfrom sklearn.decomposition import TruncatedSVD\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","outputs":[],"metadata":{"_cell_guid":"e5825421-3048-4e87-a859-a2248bb93a9a","_uuid":"fbc088d4976520309d25ad1cb12357202841373f"}},{"cell_type":"code","execution_count":null,"source":"train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\nsampleSubmission = pd.read_csv(\"../input/sample_submission.csv\")","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"6b3055c3-8a40-42fa-9666-462528bb5486","_uuid":"bd012f975667e886ba1d61eb483fda2e4e691d9d"}},{"cell_type":"code","execution_count":null,"source":"col = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\ntrainTxt = train['comment_text']\ntestTxt = test['comment_text']\ntrainTxt = trainTxt.fillna(\"unknown\")\ntestTxt = testTxt.fillna(\"unknown\")","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"179cc113-bfc6-4311-ac49-0dd1f61f6a04","_uuid":"9c2ca37258371081c246c45267a5c2e8d260f17f"}},{"cell_type":"code","execution_count":null,"source":"combinedTxt = pd.concat([trainTxt,testTxt],axis=0)","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"7e0d90bc-6d41-49cd-b7aa-ab8e0cbdf403","_uuid":"3cc5948454c3876cae9a22d10f7994d1e9add79b"}},{"cell_type":"code","execution_count":null,"source":"vect = TfidfVectorizer(decode_error='ignore',use_idf=True,smooth_idf=True,min_df=10,ngram_range=(1,3),lowercase=True,\n                      stop_words='english')","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"9ab12926-8938-47cb-8c70-710d86f04174","_uuid":"d075dccbc903590cb08439c4179849f2e2e595a0"}},{"cell_type":"code","execution_count":null,"source":"combinedDtm = vect.fit_transform(combinedTxt) #fit on combine\ntrainDtm = combinedDtm[:train.shape[0]]\ntestDtm = vect.transform(testTxt) #transform only test","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"21434a80-de63-44b1-8304-5ea9ff3a658c","_uuid":"0864159d1607202dbd4d04ab8b56d10191530fdb"}},{"cell_type":"code","execution_count":null,"source":"svd = TruncatedSVD(n_components=50, n_iter=10, random_state=42)\ntrainDtmSvd = svd.fit_transform(trainDtm)\ntestDtmSvd = svd.transform(testDtm)","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"11f147b6-f6b7-427b-884e-666e7a74802f","_uuid":"06dcaa0649eb1a8ba3cf12312ce92d60832b7cea"}},{"cell_type":"code","execution_count":null,"source":"#call fit on every single col value \n#normal lr\nloss = []\nlrpreds = np.zeros((test.shape[0],len(col)))\nfor i,j in enumerate(col):\n    lr = LogisticRegression(C=4)\n    lr.fit(trainDtm,train[j]) #train[j] is each type of comment\n    lrpreds[:,i] = lr.predict_proba(testDtm)[:,1]\n    train_preds = lr.predict_proba(trainDtm)[:,1]\n    loss.append(log_loss(train[j],train_preds))\nnp.mean(loss)","outputs":[],"metadata":{"_cell_guid":"53f0a61a-94a3-4b93-a893-aef2aa3f1a6a","_uuid":"50ec5df1aaf7ec596cfa0301f7e561d23f1ce821"}},{"cell_type":"code","execution_count":null,"source":"#lr with Svd\nloss = []\nlrpredssvd = np.zeros((test.shape[0],len(col)))\nfor i,j in enumerate(col):\n    lr = LogisticRegression(C=4)\n    lr.fit(trainDtmSvd,train[j]) #train[j] is each type of comment\n    lrpredssvd[:,i] = lr.predict_proba(testDtmSvd)[:,1]\n    train_preds = lr.predict_proba(trainDtmSvd)[:,1]\n    loss.append(log_loss(train[j],train_preds))\nnp.mean(loss)","outputs":[],"metadata":{"_cell_guid":"990ca1e0-6198-4de9-8ddb-033b2fc2b4e3","_uuid":"0655f6fe1c731835134b1be0c58cd0855cf1affe"}},{"cell_type":"code","execution_count":null,"source":"#call fit on every single col value \n#normal rf\nloss = []\nrfpreds = np.zeros((test.shape[0],len(col)))\nfor i,j in enumerate(col):\n    rf = RandomForestClassifier(max_depth=10, random_state=123)\n    rf.fit(trainDtm,train[j]) #train[j] is each type of comment\n    rfpreds[:,i] = rf.predict_proba(testDtm)[:,1]\n    train_preds = rf.predict_proba(trainDtm)[:,1]\n    loss.append(log_loss(train[j],train_preds))\nnp.mean(loss)","outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":"#rf with svd\nloss = []\nrfpredssvd = np.zeros((test.shape[0],len(col)))\nfor i,j in enumerate(col):\n    rf = RandomForestClassifier(max_depth=2, random_state=0)\n    rf.fit(trainDtmSvd,train[j]) #train[j] is each type of comment\n    rfpredssvd[:,i] = rf.predict_proba(testDtmSvd)[:,1]\n    train_preds = rf.predict_proba(trainDtmSvd)[:,1]\n    loss.append(log_loss(train[j],train_preds))\nnp.mean(loss)","outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":"#normal xgb\nloss = []\nxgbpreds = np.zeros((test.shape[0],len(col)))\nfor i,j in enumerate(col):\n    xg = xgb.XGBClassifier(max_depth=5, n_estimators=100, colsample_bytree=0.8, \n                        subsample=0.8, nthread=10, learning_rate=0.1)\n    xg.fit(trainDtm,train[j]) #train[j] is each type of comment\n    xgbpreds[:,i] = xg.predict_proba(testDtm)[:,1]\n    train_preds = xg.predict_proba(trainDtm)[:,1]\n    loss.append(log_loss(train[j],train_preds))\nnp.mean(loss)","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"991b3f0c-95fe-495b-a174-b6473df903db","_uuid":"fa682526efb6be6b587ac4d237e41d48adf18f3a"}},{"cell_type":"code","execution_count":null,"source":"#xgb with svd\nloss = []\nxgbpredssvd = np.zeros((test.shape[0],len(col)))\nfor i,j in enumerate(col):\n    xg = xgb.XGBClassifier(max_depth=7, n_estimators=200, colsample_bytree=0.8, \n                        subsample=0.8, nthread=10, learning_rate=0.1)\n    xg.fit(trainDtmSvd,train[j]) #train[j] is each type of comment\n    xgbpredssvd[:,i] = xg.predict_proba(testDtmSvd)[:,1]\n    train_preds = xg.predict_proba(trainDtmSvd)[:,1]\n    loss.append(log_loss(train[j],train_preds))\nnp.mean(loss)","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"6fbb7523-9d92-4e19-86af-f10247a06b5b","_uuid":"b274c44dd3e61b42684d91f36d38809668cd664e"}},{"cell_type":"code","execution_count":null,"source":"# predsMix = 0.6*lrpreds+0.3*xgbpreds+0.1*nbpreds\npredsMix = rfpredssvd\npredsDf = pd.DataFrame(predsMix,columns = col)\nsubid = pd.DataFrame({'id':sampleSubmission['id']})\nfinalPreds = pd.concat([subid,predsDf],axis=1)\nfinalPreds.to_csv(\"xgbSVDwithLR.csv\",index=False)","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"7223d4a0-2bfa-4316-85d6-8f3a6162901e","_uuid":"221cc9df76de73fa95f797dae07a5604c89ad6c9"}},{"cell_type":"code","execution_count":null,"source":"","outputs":[],"metadata":{"collapsed":true,"_cell_guid":"a78c0695-480c-475e-8bc8-daef670ff9c5","_uuid":"3cb33203358ac9723a1520030e6a3405d2458f47"}}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"pygments_lexer":"ipython3","version":"3.6.3","name":"python","file_extension":".py","nbconvert_exporter":"python","codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python"}}}