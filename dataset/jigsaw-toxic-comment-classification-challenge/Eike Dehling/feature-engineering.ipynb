{"nbformat_minor":1,"cells":[{"cell_type":"markdown","source":"# Feature engineering\n\nIn this notebook i want try hand-crafting some features that could help to create a model. I want to see what creative ideas i can come up with - and if they indeed seem to work.","metadata":{"_cell_guid":"91bc9f4c-9535-42bb-969d-80340840ef5f","_uuid":"1d9358b4afbf4c53c8d90b83198c00628e979020"}},{"cell_type":"code","outputs":[],"source":"import pandas as pd\n\ndf = pd.read_csv('../input/train.csv')","metadata":{"_cell_guid":"6f961a24-8ce0-4671-bd14-84077a802a53","_uuid":"b11eb49ad9b57030d1bbf8729f72ce45ac600c26","collapsed":true},"execution_count":16},{"cell_type":"code","outputs":[],"source":"df.head()","metadata":{"_cell_guid":"7f523ded-9393-4b60-abc2-c04891d729d2","_uuid":"785789b0e4e8fe941dfec90dc544225af5046ed7"},"execution_count":17},{"cell_type":"markdown","source":"Below i'm adding features to the dataset that are computed from the comment text. Some i've seen in discussions for this competition, others i came up with while looking at the data. Right now, they are:\n\n* Length of the comment - my initial assumption is that angry people write short messages\n* Number of capitals - observation was many toxic comments being ALL CAPS\n* Proportion of capitals - see previous\n* Number of exclamation marks - i observed several toxic comments with multiple exclamation marks\n* Number of question marks - assumption that angry people might not use question marks\n* Number of punctuation symbols - assumption that angry people might not use punctuation\n* Number of symbols - assumtion that words like f*ck or $#* or sh*t mean more symbols in foul language (Thx for tip!)\n* Number of words - angry people might write short messages?\n* Number of unique words - observation that angry comments are sometimes repeated many times\n* Proportion of unique words - see previous\n* Number of (happy) smilies - Angry people wouldn't use happy smilies, right?","metadata":{"_cell_guid":"aa509eed-dfdb-41a7-b41c-b5c08ca328d4","_uuid":"03003e1fb8a8ff49f0076dd78f1717c7d4f689eb"}},{"cell_type":"code","outputs":[],"source":"df['total_length'] = df['comment_text'].apply(len)\ndf['capitals'] = df['comment_text'].apply(lambda comment: sum(1 for c in comment if c.isupper()))\ndf['caps_vs_length'] = df.apply(lambda row: float(row['capitals'])/float(row['total_length']),\n                                axis=1)\ndf['num_exclamation_marks'] = df['comment_text'].apply(lambda comment: comment.count('!'))\ndf['num_question_marks'] = df['comment_text'].apply(lambda comment: comment.count('?'))\ndf['num_punctuation'] = df['comment_text'].apply(\n    lambda comment: sum(comment.count(w) for w in '.,;:'))\ndf['num_symbols'] = df['comment_text'].apply(\n    lambda comment: sum(comment.count(w) for w in '*&$%'))\ndf['num_words'] = df['comment_text'].apply(lambda comment: len(comment.split()))\ndf['num_unique_words'] = df['comment_text'].apply(\n    lambda comment: len(set(w for w in comment.split())))\ndf['words_vs_unique'] = df['num_unique_words'] / df['num_words']\ndf['num_smilies'] = df['comment_text'].apply(\n    lambda comment: sum(comment.count(w) for w in (':-)', ':)', ';-)', ';)')))","metadata":{"_cell_guid":"34610778-9d43-4369-a39a-98b0315af51e","_uuid":"71bafb31ff381838ebee97d4c43dc7a9b30abd2f","collapsed":true},"execution_count":18},{"cell_type":"markdown","source":"Let's inspect data - did this work?","metadata":{"_cell_guid":"e66ea469-91d7-4c9c-ae5d-dc17faca1c8f","_uuid":"3a7bbd42c35f0a6e2572927f472d34de08b4f93b"}},{"cell_type":"code","outputs":[],"source":"df.head()","metadata":{"_cell_guid":"5fa2b473-f6b9-4564-9889-78d14ba88d23","_uuid":"09d66504f7abeb475a833d58421e39008c486832"},"execution_count":19},{"cell_type":"markdown","source":"Now we'll calculation correlation between the added features and the to-be-predicted columns, this should be an indication of whether a model could use these features:","metadata":{"_cell_guid":"e3f10ae2-718c-4e78-a23f-6f092cb6d72b","_uuid":"74f817ad4c774172e44deae5212529b90f49cb94"}},{"cell_type":"code","outputs":[],"source":"features = ('total_length', 'capitals', 'caps_vs_length', 'num_exclamation_marks',\n            'num_question_marks', 'num_punctuation', 'num_words', 'num_unique_words',\n            'words_vs_unique', 'num_smilies', 'num_symbols')\ncolumns = ('toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate')\n\nrows = [{c:df[f].corr(df[c]) for c in columns} for f in features]\ndf_correlations = pd.DataFrame(rows, index=features)","metadata":{"_cell_guid":"6a576a79-62e7-430a-9d18-3b5ae53e3648","_uuid":"a1234d2a68c42835b390d767e6a590a9422371f5"},"execution_count":20},{"cell_type":"markdown","source":"Let's output the data:","metadata":{"_cell_guid":"8fc91ba1-111c-4107-8bc8-3c6c3ccedf22","_uuid":"544b6a0c71727a17adf833ec9c39ef4daa63fd5f"}},{"cell_type":"code","outputs":[],"source":"df_correlations","metadata":{"_cell_guid":"1b7e3f83-8953-4075-80cd-7be6be4f4c59","_uuid":"61cbee5d4d42de361ff0c4f703a9c4e2ae7e60f4"},"execution_count":21},{"cell_type":"markdown","source":"I'll also output the data as a heatmap - that's slightly easier to read.","metadata":{"_cell_guid":"2b84c0f9-9edd-49bf-92f1-76f2d6af23a6","_uuid":"2dd30cb117effd9fdd1bb8aa16d1a0f6e252e2bf"}},{"cell_type":"code","outputs":[],"source":"import seaborn as sns\n\nax = sns.heatmap(df_correlations, vmin=-0.2, vmax=0.2, center=0.0)","metadata":{"_cell_guid":"fcddde11-e833-4292-9874-eb0c675e9966","_uuid":"613ef976113f51c3e690431b54c6c508bc54961c"},"execution_count":22},{"cell_type":"markdown","source":"So, what have we learned? Some of the feature ideas i had make sense: They correlate with the to-be-predicted data, so a model should be able to use them. Other feature ideas don't correlate - so they look less promising.\n\nFor now these feature seem the best candidates:\n* Proportion of capitals \n* Number of unique words\n* Number of exclamation marks\n* Number of punctuations\n\nHope this could be usefull to someone! If you have more (feature) ideas or feedback - please comment, then i can add them here.","metadata":{"_cell_guid":"57a7e0a2-8865-4950-bd8c-12ccea7f2de8","_uuid":"e93dc934e0a4b247bc72471c8617dad17ff97136"}},{"cell_type":"markdown","source":"","metadata":{"_cell_guid":"4b24f890-7c66-469b-9542-9f1261997b6d","_uuid":"138db0cdfc6185f3a5b538dc05ff33deae57aa5b"}}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","mimetype":"text/x-python","version":"3.6.4","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","pygments_lexer":"ipython3","nbconvert_exporter":"python"}},"nbformat":4}