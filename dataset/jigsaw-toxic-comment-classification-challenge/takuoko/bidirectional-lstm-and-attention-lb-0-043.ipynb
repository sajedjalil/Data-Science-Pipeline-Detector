{"nbformat_minor":1,"nbformat":4,"cells":[{"source":"This code is inspirated by https://www.kaggle.com/qqgeogor/keras-lstm-attention-glove840b-lb-0-043","cell_type":"markdown","metadata":{"_cell_guid":"c8523520-a13c-4067-8aad-456d4a8797ea","_uuid":"6f1e3cb42fc60cca3e663c8796ca04b1a6f806e2"}},{"outputs":[],"source":"from keras import backend as K\nfrom keras.engine.topology import Layer\nfrom keras import initializers, regularizers, constraints\n\n\nclass Attention(Layer):\n    def __init__(self, step_dim,\n                 W_regularizer=None, b_regularizer=None,\n                 W_constraint=None, b_constraint=None,\n                 bias=True, **kwargs):\n        self.supports_masking = True\n        self.init = initializers.get('glorot_uniform')\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        self.step_dim = step_dim\n        self.features_dim = 0\n        super(Attention, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 3\n\n        self.W = self.add_weight((input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_W'.format(self.name),\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        self.features_dim = input_shape[-1]\n\n        if self.bias:\n            self.b = self.add_weight((input_shape[1],),\n                                     initializer='zero',\n                                     name='{}_b'.format(self.name),\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n        else:\n            self.b = None\n\n        self.built = True\n\n    def compute_mask(self, input, input_mask=None):\n        return None\n\n    def call(self, x, mask=None):\n        features_dim = self.features_dim\n        step_dim = self.step_dim\n\n        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n\n        if self.bias:\n            eij += self.b\n\n        eij = K.tanh(eij)\n\n        a = K.exp(eij)\n\n        if mask is not None:\n            a *= K.cast(mask, K.floatx())\n\n        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n\n        a = K.expand_dims(a)\n        weighted_input = x * a\n        return K.sum(weighted_input, axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0],  self.features_dim","cell_type":"code","metadata":{"_cell_guid":"c98be731-6349-4ba6-af09-775c066316e5","_uuid":"2010428cdc03cc10befe380967be2b2bf96ffc13","collapsed":true},"execution_count":null},{"outputs":[],"source":"from keras.models import Model\nfrom keras.layers import Dense, Embedding, Input\nfrom keras.layers import LSTM, Bidirectional, Dropout\n\n\ndef BidLstm(maxlen, max_features, embed_size, embedding_matrix):\n    inp = Input(shape=(maxlen, ))\n    x = Embedding(max_features, embed_size, weights=[embedding_matrix],\n                  trainable=False)(inp)\n    x = Bidirectional(LSTM(300, return_sequences=True, dropout=0.25,\n                           recurrent_dropout=0.25))(x)\n    x = Attention(maxlen)(x)\n    x = Dense(256, activation=\"relu\")(x)\n    x = Dropout(0.25)(x)\n    x = Dense(6, activation=\"sigmoid\")(x)\n    model = Model(inputs=inp, outputs=x)\n\n    return model","cell_type":"code","metadata":{"_cell_guid":"0673ed33-bdde-4430-b1fd-8bb492d55cd5","_uuid":"748d0616615fb1a09443480c9d7902b5543233bc","collapsed":true},"execution_count":null},{"outputs":[],"source":"import pandas as pd\nfrom keras.preprocessing import text, sequence\n\n\ndef make_df(train_path, test_path, max_features, maxlen, list_classes):\n    train = pd.read_csv(train_path)\n    test = pd.read_csv(test_path)\n    train = train.sample(frac=1)\n\n    list_sentences_train = train[\"comment_text\"].fillna(\"unknown\").values\n    y = train[list_classes].values\n    list_sentences_test = test[\"comment_text\"].fillna(\"unknown\").values\n\n    tokenizer = text.Tokenizer(num_words=max_features)\n    tokenizer.fit_on_texts(list(list_sentences_train))\n    list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n    list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n    X_t = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n    X_te = sequence.pad_sequences(list_tokenized_test, maxlen=maxlen)\n\n    word_index = tokenizer.word_index\n\n    return X_t, X_te, y, word_index","cell_type":"code","metadata":{"_cell_guid":"8cbf9b0c-d199-4c42-9597-29e93a2d0e24","_uuid":"5d0705ae2e556b8de1d42c5ed4e471318c88a467","collapsed":true},"execution_count":null},{"source":"https://github.com/stanfordnlp/GloVe <br>\ndownload \"glove.840B.300d.txt\" from here.","cell_type":"markdown","metadata":{"_cell_guid":"199467f8-4e9a-47d2-be2f-59c615cd7b69","_uuid":"b683f30bf77a43f73aef800a4abe9536bd785117"}},{"outputs":[],"source":"import numpy as np\n\n\ndef make_glovevec(glovepath, max_features, embed_size, word_index, veclen=300):\n    embeddings_index = {}\n    f = open(glovepath)\n    for line in f:\n        values = line.split()\n        word = ' '.join(values[:-300])\n        coefs = np.asarray(values[-300:], dtype='float32')\n        embeddings_index[word] = coefs.reshape(-1)\n    f.close()\n\n    nb_words = min(max_features, len(word_index))\n    embedding_matrix = np.zeros((nb_words, embed_size))\n    for word, i in word_index.items():\n        if i >= max_features:\n            continue\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n            embedding_matrix[i] = embedding_vector\n    return embedding_matrix","cell_type":"code","metadata":{"_cell_guid":"50ff598f-0e95-4757-937d-760b8c150da3","_uuid":"22d167e291614e2870b9ab6762341a9e25680c37","collapsed":true},"execution_count":null},{"source":"\"model.fit(xtr, y, batch_size=256, epochs=15, validation_split=0.1, callbacks=[ckpt, early])\" <br>\ncomment out it because of kernel run time.<br>\nif you use local machine, choose its fit code.","cell_type":"markdown","metadata":{"_cell_guid":"9f6ba85d-cbe1-4a70-9884-cd89e32d448a","_uuid":"683e4566b5f8c7979c5372500fd9c3ae8e9f1bcf"}},{"outputs":[],"source":"import numpy as np\nimport pandas as pd\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nnp.random.seed(7)\n\n\nif __name__ == \"__main__\":\n    max_features = 100000\n    maxlen = 150\n    embed_size = 300\n    list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\",\n                    \"identity_hate\"]\n\n    xtr, xte, y, word_index = make_df(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv\",\n                                      \"../input/jigsaw-toxic-comment-classification-challenge/test.csv\",\n                                      max_features, maxlen, list_classes)\n    embedding_vector = make_glovevec(\"../input/glove840b300dtxt/glove.840B.300d.txt\",\n                                     max_features, embed_size, word_index)\n\n    model = BidLstm(maxlen, max_features, embed_size, embedding_vector)\n    model.compile(loss='binary_crossentropy', optimizer='adam',\n                  metrics=['accuracy'])\n    file_path = \".model.hdf5\"\n    ckpt = ModelCheckpoint(file_path, monitor='val_loss', verbose=1,\n                           save_best_only=True, mode='min')\n    early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=1)\n    model.fit(xtr, y, batch_size=256, epochs=15, validation_split=0.1, callbacks=[ckpt, early])\n    #model.fit(xtr, y, batch_size=256, epochs=1, validation_split=0.1)\n\n    model.load_weights(file_path)\n    y_test = model.predict(xte)\n    sample_submission = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv\")\n    sample_submission[list_classes] = y_test\n    sample_submission.to_csv(\"sub.csv\", index=False)","cell_type":"code","metadata":{"_cell_guid":"7b2d8805-de5e-45ca-a9a4-2980a823a9a7","_uuid":"38a7f0c80aa40e62138798b3a6a169446a2ed0a3","collapsed":true},"execution_count":null}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"version":"3.6.3","file_extension":".py","codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","pygments_lexer":"ipython3","nbconvert_exporter":"python","name":"python"}}}