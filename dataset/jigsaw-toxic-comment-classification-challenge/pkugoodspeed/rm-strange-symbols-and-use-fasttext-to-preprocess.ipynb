{"cells":[{"source":"- Plan to train each column separately.\n- Here, use an rnn model to train the first column: `toxic`\n- It is pretty slow","cell_type":"markdown","metadata":{}},{"outputs":[],"source":"## system\nimport os\n\n## Math and dataFrame\nimport numpy as np\nimport pandas as pd\nimport scipy\nfrom scipy.sparse import csr_matrix, hstack\n\n## Visualization\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\nimport seaborn as sns","cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"333dc45a-ca46-4a2c-af24-00cd57e27883","_uuid":"b15824606aeebc19c0eafa981cbdaafcf80363f4"}},{"outputs":[],"source":"## Traditional Machine Learning\nfrom sklearn.linear_model import Ridge, LogisticRegression\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.preprocessing import LabelBinarizer","cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"6b1b883f-9fd8-4053-a309-5bca91008cbf","_uuid":"f9876766de8f6bcd302b6b1e9047d81d74c551fb"}},{"outputs":[],"source":"## Keras\nfrom keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, GRU, Embedding, Flatten\nfrom keras.models import Model, Sequential\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping#, TensorBoard\nfrom keras import backend as K\nfrom keras import optimizers\nfrom keras.optimizers import SGD\nfrom keras import initializers\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.utils import np_utils\nfrom keras.preprocessing.sequence import pad_sequences","cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"73660cd7-f560-4c5f-88a6-ccc76302c4dc","_uuid":"4d00479ca3112032f461505ea9cca53e449cb6c2"}},{"outputs":[],"source":"## Using Multi processing","cell_type":"code","execution_count":null,"metadata":{"collapsed":true}},{"outputs":[],"source":"from multiprocessing import Pool","cell_type":"code","execution_count":null,"metadata":{"collapsed":true}},{"outputs":[],"source":"## Load data\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7b4724d4-cf48-4caf-8682-0143652ab683","_uuid":"5702f8694094107547dfdb847e11de51cf6a6407"}},{"source":"##### Do some statistics","cell_type":"markdown","metadata":{}},{"outputs":[],"source":"display(train[:10])\nprint(train.shape)\nprint(\"toxic count = {0}\".format(train.toxic.sum()))\nprint(\"severe_toxic count = {0}\".format(train.severe_toxic.sum()))\nprint(\"obscene count = {0}\".format(train.obscene.sum()))\nprint(\"threat count = {0}\".format(train.threat.sum()))\nprint(\"insult count = {0}\".format(train.insult.sum()))\nprint(\"identity_hate count = {0}\".format(train.identity_hate.sum()))","cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2fd98650-b3de-4222-9662-6c0fad714ded","_uuid":"b23f8b789678c9446133308b212abfc0adea5830"}},{"source":"###### Show correlation matrix","cell_type":"markdown","metadata":{}},{"outputs":[],"source":"corr = train[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].corr()\nf, ax = plt.subplots(figsize=(10, 8))\nsns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n            square=True, ax=ax)","cell_type":"code","execution_count":null,"metadata":{}},{"source":"###### For Sentence processing","cell_type":"markdown","metadata":{"_cell_guid":"4eb487b4-2829-44a4-943d-f6ea0aa7c331","_uuid":"6418d9abb0412df2272688da7d31a3349722cf2e"}},{"outputs":[],"source":"from nltk import word_tokenize\nfrom nltk.corpus import stopwords\nimport string\nstop = set(stopwords.words('english'))\npunc = set(string.punctuation)","cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"f74c43dd-ea21-4d4f-a34f-23c612c0ace1","_uuid":"bb69470290d9b8fe5053efcef123fc87260e693f"}},{"source":"Here I am trying to remove all the stop words and punctuations. Not sure whether it will give a better result or not","cell_type":"markdown","metadata":{}},{"outputs":[],"source":"#### Preprocess sentences (removing punctuations and removing stop words)\ndef rmPunc(sent):\n    return ''.join([ch for ch in str(sent) if ch not in punc])\ndef rmStop(sent):\n    return ' '.join([word for word in sent.split() if word not in stop])","cell_type":"code","execution_count":null,"metadata":{"collapsed":true}},{"outputs":[],"source":"print(\"PREPROCESS TEXT...\")\npool = Pool()\n%time train.comment_text = pool.map(rmPunc, train.comment_text.str.lower())\n%time test.comment_text = pool.map(rmPunc, test.comment_text.str.lower())\n\n%time train.comment_text = pool.map(rmStop, train.comment_text.str.lower())\n%time test.comment_text = pool.map(rmStop, test.comment_text.str.lower())\npool.close()\npool.join()","cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4a60b951-2dcf-40e5-a247-6992765c7a21","_uuid":"4830e4afc41cc1b0cbbde2731e711a98302e75ad"}},{"source":"###### Tokenization","cell_type":"markdown","metadata":{"_cell_guid":"22933d1f-8125-4f87-bae4-3eb9e20da846","_uuid":"a6f25ccb7adf58b02cb3e3118524a1aec99f4ad8"}},{"outputs":[],"source":"#PROCESS TEXT: RAW\nprint(\"Text to seq process...\")\nprint(\"   Fitting tokenizer...\")\nfrom keras.preprocessing.text import Tokenizer\nraw_text = np.hstack([train.comment_text.str.lower(), \n                      test.comment_text.str.lower()])\ntok_raw = Tokenizer()\ntok_raw.fit_on_texts(raw_text)\nprint(\"   Transforming text to seq...\")\ntrain[\"input\"] = tok_raw.texts_to_sequences(train.comment_text.str.lower())\ntest[\"input\"] = tok_raw.texts_to_sequences(test.comment_text.str.lower())","cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1310a93f-2a26-4f3e-a1ef-f13d23d4df70","_uuid":"948fa452f8b833e79699e3620e39c4cdfe0d9f1a"}},{"source":"###### Some statistics on sentence lengths","cell_type":"markdown","metadata":{"_cell_guid":"80c9d372-7ce6-4362-9bd4-d651ae62bc2f","_uuid":"8180b10cde03390c7ef68e3692bbc88135c147ac"}},{"outputs":[],"source":"test.input.apply(lambda x: len(x)).hist()\ntrain.input.apply(lambda x: len(x)).hist()","cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9923b707-c79f-4b00-8a34-f393bbb8b02c","_uuid":"37d4430506598c63e71c84319e403f4e7db97ed9"}},{"outputs":[],"source":"MAX_LENGTH = 200\nMAX_TOKEN = np.max([np.max(train.input.max()),np.max(test.input.max())]) + 5\nprint(MAX_LENGTH, MAX_TOKEN)","cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"14f46bbc-761d-46f1-8fc9-1ee9530eb31d","_uuid":"1a114cf0a5fdec11c93bdc53760b6e5139ee6c55"}},{"outputs":[],"source":"train = train[['input', 'toxic']]\ndtrain, dvalid = train_test_split(train, random_state=17, train_size=0.7)\nprint(dtrain.shape)\nprint(dvalid.shape)","cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"99ad13ce-b85a-4b8f-b3ca-4be0b49be01c","_uuid":"44c7dda15d2f17bdddb8b0f4babdaa6f5f6b1b3d"}},{"source":"###### Artificially balance the classes","cell_type":"markdown","metadata":{"_cell_guid":"5e99953f-de71-4677-b235-b23868e1caac","_uuid":"34845acfb679150a21961be303995de1606d94dd"}},{"outputs":[],"source":"L = len(dtrain)\ndf_irr = dtrain[dtrain.toxic != 0]\nwhile len(dtrain) < 2*L:\n    dtrain = dtrain.append(df_irr, ignore_index=True)","cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"59514ed9-7210-44e9-b849-5ce97b3f8c5b","_uuid":"11a63d101990d39521447824ae565889aab6e39b"}},{"outputs":[],"source":"L = len(dvalid)\ndf_irr = dvalid[dvalid.toxic != 0]\nwhile len(dvalid) < 2*L:\n    dvalid = dvalid.append(df_irr, ignore_index=True)","cell_type":"code","execution_count":null,"metadata":{"collapsed":true}},{"source":"###### Creating RNN model","cell_type":"markdown","metadata":{}},{"outputs":[],"source":"A = Input(shape=[MAX_LENGTH], name=\"in\")\nB = Embedding(MAX_TOKEN, 128)(A)\nC = GRU(32) (B)\nD = Dropout(0.6) (Dense(128, activation='relu') (C))\nE = Dropout(0.4) (Dense(32, activation='relu') (D))\noutput = Dense(2, activation=\"softmax\") (E)","cell_type":"code","execution_count":null,"metadata":{"collapsed":true}},{"outputs":[],"source":"model = Model(A, output)\nN_epoch = 1\nlearning_rate = 0.05\noptimizer = SGD(learning_rate)\nloss = 'categorical_crossentropy'\nmetrics = ['accuracy']\nmodel.compile(optimizer=optimizer, loss=loss, metrics=metrics)\nmodel.summary()","cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"852083b4-3596-43af-8616-4eed1f0049a8","_uuid":"2efb5f0e4c0d78b190256a1bd5e1e3a0b2b0d525"}},{"outputs":[],"source":"train_x = pad_sequences(dtrain.input, maxlen=MAX_LENGTH)\nvalid_x = pad_sequences(dvalid.input, maxlen=MAX_LENGTH)\ntrain_y = np_utils.to_categorical(dtrain.toxic.values, 2)\nvalid_y = np_utils.to_categorical(dvalid.toxic.values, 2)","cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aec2217c-ccc8-41fa-93ca-eb08ca65e6bf","_uuid":"ad72e8f5cc6867e6653590d262e2abb91c0afc22"}},{"outputs":[],"source":"res = model.fit(train_x, train_y, batch_size = 128, epochs = N_epoch, \n                verbose = 1, validation_data = (valid_x, valid_y))","cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f6333e56-af22-4f25-9818-1d72780f7192","_uuid":"a73f1a3596dcada7221afbbd05d1678bb6210791"}},{"outputs":[],"source":"","cell_type":"code","execution_count":null,"metadata":{"collapsed":true}}],"nbformat":4,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","file_extension":".py","version":"3.6.4","mimetype":"text/x-python","pygments_lexer":"ipython3","nbconvert_exporter":"python"}},"nbformat_minor":1}