{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"dbe02867-4b18-37e7-d84d-df776939502a"},"outputs":[],"source":"from __future__ import division\nimport numpy as np\nimport pandas as pd\nfrom itertools import combinations_with_replacement\nfrom ast import literal_eval\nfrom scipy.optimize import linprog"},{"cell_type":"markdown","metadata":{"_cell_guid":"d95c43f2-e9b3-9e3e-2ec1-f926cb3706aa"},"source":"Ideas for efficiency improvements (in sampling from bag distributions) from [this Kaggle notebook][nb]. In particular, one can generate many samples from the weight distribution of each item to effectively have an array that models the PDF of that item. Then, any given bag's weight PDF is just the summation of the item distributions (which is quite quick when those are already in, e.g., a dictionary).\n\nThough this sped up my code significantly, the results I got (on the LB) were worse. I'm not sure if there was an error in my thinking with the new approach/implementation of it/if the sample of items used in the test set was better matched by chance by my previous approach.\n\n[nb]: https://www.kaggle.com/cpmpml/santas-uncertain-bags/optimal-expected-submission-value"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ee7c859c-d7c7-d610-b01f-60b34a36e869"},"outputs":[],"source":"gifts = pd.read_csv('../input/gifts.csv')\ngifts[\"gift_type\"] = gifts.GiftId.map(lambda x: x[:x.index(\"_\")])\ngift_types = np.sort(gifts.gift_type.unique())\ngift_type_to_int = {gift_types[i]: i for i in range(len(gift_types))}\nint_to_gift_type = {val: key for key, val in gift_type_to_int.items()}\ngifts['gift_type_int'] = gifts.gift_type.map(gift_type_to_int.get)\ngifts.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"594a3301-ce55-2622-e088-8c7efb167b52"},"outputs":[],"source":"gifts.gift_type.value_counts()"},{"cell_type":"markdown","metadata":{"_cell_guid":"cecf1337-65e8-9873-ed00-e6418c1f03f6"},"source":"Because each bag can only fit 50 weight into it, there are a finite number of bag types that we could realistically use (i.e. the infinite number of others are so improbable to have the proper weight that we ignore them). For each of these bag types, we want to know the expected score. The score of a bag $i$ ($s_i$) is its weight, $w_i$\n, unless $w_i>50$, in which case $s_i=0$. From the weight distribution of a bag, we can thus calculate the score distribution and determine the expected score. We will attempt to maximize the expected score of all bags, subject to the constraints on how many of each gift we have."},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ff2a3f3a-9a3f-5e42-8d41-eb6a5c9083a4"},"outputs":[],"source":"gift_types_int = range(len(gift_types))\ncombinations = []\nfor n_gifts in range(3, 9): # all bags must have >= 3 gifts; 8 is an arbitrary upper limit on the number of items in a bag\n    combinations.extend(list(combinations_with_replacement(gift_types_int, r=n_gifts)))\n\ngift_sets = pd.DataFrame([str(elem) for elem in combinations], columns=['set'])\ngift_sets.set = gift_sets.set.map(literal_eval) # back to tuples from strings; probably a better way to do this?\nprint(\"There are {:,} different gift sets.\".format(len(gift_sets)))\ngift_sets.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"82007f3e-9b91-1d03-92b7-74f23e6aa85b"},"outputs":[],"source":"n_samples=100000\ndistributions = {7: np.maximum(0, np.random.normal(5, 2, n_samples)),\n                0: np.maximum(0, np.random.normal(2, 0.3, n_samples)),\n                1: np.maximum(0, np.random.normal(20, 10, n_samples)),\n                8: np.maximum(0, np.random.normal(10, 5, n_samples)),\n                4: 47 * np.random.beta(0.5, 0.5 ,n_samples),\n                3: np.random.chisquare(2, n_samples),\n                5: np.random.gamma(5 ,1, n_samples),\n                2: np.random.triangular(5, 10, 20, n_samples)}\ngloves1 = 3.0 + np.random.rand(n_samples)\ngloves2 = np.random.rand(n_samples)\ngloves3 = np.random.rand(n_samples)\ndistributions[6] = np.where(gloves2 < 0.3, gloves1, gloves3)\n\ndef expected_score(gift_types):\n    \"\"\"\n    Computes the expected score of the bag with gifts specified in gift_types by taking n_samples samples from\n    the bag's score distribution and returning their average.\n    \n    :param gift_types: tuple[int] that specifies the types of gifts in this bag\n    :param n_samples: number of samples to take from the bag's score distribution\n    \"\"\"\n    \n    global n_samples\n    scores = np.zeros(n_samples)\n\n    for gift_type in gift_types:\n        scores += distributions[gift_type]\n    \n    scores[scores > 50] = 0\n    return scores.mean()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"df76876e-ec3b-2c1f-4cbb-b8420fa54745"},"outputs":[],"source":"%%time\n# ~30s now\nscores = gift_sets.set.apply(expected_score)\n\ngift_sets['score'] = scores\ngift_sets.sort_values('score', inplace=True, ascending=False)\nscores = gift_sets.score\ngift_sets.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b7742b2c-60f9-c110-e69f-f8e84fa06dd2"},"outputs":[],"source":"def count(array, val):\n    count = 0\n    for elem in array:\n        if elem == val:\n            count += 1\n    return count\n\n# constraint: # of any kind of gift can't exceed max number\nbounds = gifts.gift_type_int.value_counts()\ntype_counts = []\nfor i in bounds.index:\n    type_counts.append(gift_sets.set.apply(count, args=(i,)).values)\ntype_counts = np.array(type_counts)\n\n# constraint: max # bags is 1K; 1*bag_count <= 1K\nconstraint_matrix = np.row_stack((type_counts, np.ones(type_counts.shape[1])))\nconstraint_bounds = np.concatenate((bounds.values, np.array(1000).reshape(-1)))\n\nresult = linprog(-scores, constraint_matrix, constraint_bounds)\nbag_counts = result.x\nprint(\"Expected score: {:,}\".format(-result.fun))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ba67c6d2-c5a5-4c3f-d8d5-88ad24150d96"},"outputs":[],"source":"# now this part is a little tricky... the bag_counts are floats, but we need integer numbers of bags\n# approach: floor each element (so we never use too many of a bag), use that many of each kind of bag,\n# then greedy search to fill up the remaining bags\n\ndef lp_greedy_fill(gift_sets, bag_counts):\n    \"\"\"\n    :param gift_sets: dataframe with a column 'set' that contains types of gift bags (using integer ids for gifts) \n                      must be sorted s.t. best bags come first\n    :param bag_counts: numpy array containing the optimal (float) count of each type of bag;\n                       result of LP optimization\n    Other variables are taken from globals.\n    \"\"\"\n    \n    gift_counts = gifts.gift_type_int.value_counts()\n    counts_dict = {i: 0 for i in range(len(gift_counts))}\n    def get_gift_id_and_increment(gift_type):\n        \"\"\"\n        For making gift ids (e.g. bike_1) for the submission file.\n        \"\"\"\n        count = counts_dict[gift_type]\n        counts_dict[gift_type] += 1\n        return int_to_gift_type[gift_type] + \"_\" + str(count)\n\n    out_file_name = \"output.csv\"\n    with open(out_file_name, 'w') as outfile:\n        outfile.write(\"Gifts\\n\")\n        \n        bags_filled = 0\n        for gift_set_idx in range(len(bag_counts)):\n            count = int(bag_counts[gift_set_idx])\n            next_gift_set = gift_sets.set.iloc[gift_set_idx]\n            bag_gift_counts = pd.Series(next_gift_set).value_counts()\n            gift_counts.loc[bag_gift_counts.index] -= bag_gift_counts * count\n            for _ in range(count):\n                outfile.write(\" \".join(map(get_gift_id_and_increment, next_gift_set)) + \"\\n\")\n            bags_filled += count\n\n        # greedy search to fill the rest\n        gift_set_idx = 0\n        next_gift_set = gift_sets.set.iloc[gift_set_idx]\n        bag_gift_counts = pd.Series(next_gift_set).value_counts()\n        while bags_filled < 1000:\n            \n            if np.all(bag_gift_counts < gift_counts.loc[bag_gift_counts.index]):\n                gift_counts.loc[bag_gift_counts.index] -= bag_gift_counts\n                outfile.write(\" \".join(map(get_gift_id_and_increment, next_gift_set)) + \"\\n\")\n                bags_filled += 1\n            else: # can't do any more of this bag type; move to next best\n                gift_set_idx += 1\n                if gift_set_idx == len(gift_sets):\n                    print(\"Ran out of possible gift sets!\")\n                    break\n                else:\n                    next_gift_set = gift_sets.set.iloc[gift_set_idx]\n                    bag_gift_counts = pd.Series(next_gift_set).value_counts()\n\n        print(\"Output was written to {}\".format(out_file_name))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a5e533ba-fbab-ded0-04b0-ecff4ad530c7"},"outputs":[],"source":"%%time\nlp_greedy_fill(gift_sets, bag_counts)"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}