{"nbformat_minor":1,"nbformat":4,"cells":[{"metadata":{"collapsed":true,"_cell_guid":"4f7ca8e0-6af7-40a5-ae36-c5fdccd6ec5b","_uuid":"419948f1de60686ace56c21f07734edfab62d973"},"cell_type":"code","execution_count":null,"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom keras.utils import np_utils\nfrom tflearn.data_utils import to_categorical\nfrom sklearn.model_selection import train_test_split","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"cd799485-93e0-4d76-9624-0b628504bf88","_uuid":"7fc1b38e38da8ebee2d499b4cc627a723a07addf"},"cell_type":"code","execution_count":null,"source":"def getRawFeatures(picture):\n    red = []\n    green = []\n    blue = []\n    for row in range(picture.shape[0]):\n        for col in range(picture.shape[1]):\n            red.append(picture[row][col][0])\n            green.append(picture[row][col][1])\n            blue.append(picture[row][col][2])\n    feature = red\n    feature.extend(green)\n    feature.extend(blue)\n    return feature","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"f88cfc36-a17c-4eda-b5f2-fe567201441a","_uuid":"89d8ce2e6149ea1a8bf7db009e7db5f8b10adcec"},"cell_type":"code","execution_count":null,"source":"import io\nfrom tqdm import tqdm_notebook\nimport bson # this is installed with the pymongo package\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.data import imread   # or, whatever image library you prefer\nimport multiprocessing as mp      # will come in handy due to the size of the data\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"7a754b19-e70c-4f08-98cc-66b549a4a280","_uuid":"bdfffde30a8d59257d649a0379e3a33a44744d8b"},"cell_type":"code","execution_count":null,"source":"# # The images are being loaded :)\n# # It will take a while, as the total size is too large\n\n# # Simple data processing\n# count_images = 0\n# image_names_array = []\n# category_id_array = []\n# data = bson.decode_file_iter(open('../input/train.bson', 'rb'))\n# pictures = []\n# count = 0\n# prod_to_category = dict()\n\n# for c, d in enumerate(data):\n#     #for each product_id\n#     product_id = d['_id']\n#     category_id = d['category_id'] # This won't be in Test data\n#     prod_to_category[product_id] = category_id\n    \n#     for e, pic in enumerate(d['imgs']):\n#         #for each image\n#         picture = imread(io.BytesIO(pic['picture']))\n#         pictures.append(picture)\n#         count = count + 1\n#         # do something with the picture, etc\n# #         image_name = \"prod_id-\" + str(product_id) + \"-\" + \"image-\" + str(e)\n# #         print(\"PRODUCT ID:\", product_id, \"NUMBER\", e)\n# #         plt.imshow(picture)\n# #         fig1 = plt.gcf()\n# #         plt.show()\n# #         plt.draw()\n#         count_images = count_images + 1\n# #         image_names_array.append(image_name)\n#         category_id_array.append(str(category_id))\n#         #fig1.savefig(\"img/\" + str(image_name), dpi=100)\n#     print(count_images)\n# #     break\n\n# prod_to_category = pd.DataFrame.from_dict(prod_to_category, orient='index')\n# prod_to_category.index.name = '_id'\n# prod_to_category.rename(columns={0: 'category_id'}, inplace=True)","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"b112fc98-1e01-45ad-bdf4-aaf81233907a","_uuid":"5da033663ecf6e27e4a4c60d6a5b3eecde4b757e"},"cell_type":"code","execution_count":null,"source":"pictures = []\ncategory_id_array = []\nprod_id = []\nprod_category = []\nprod_num_imgs = []\n\nnum_dicts = 82 # according to data page\n\ncount = 0\n# This will take about 02m15s to complete\nwith open('../input/train_example.bson', 'rb') as f, tqdm_notebook(total=num_dicts) as bar:\n    \n    data = bson.decode_file_iter(f)\n\n    for c, d in enumerate(data):\n        bar.update()\n        count = count + 1\n#         if(count > 82):\n#             break\n        prod_id.append(d['_id'])\n        prod_category.append(str(d['category_id']))\n        prod_num_imgs.append(len(d['imgs']))\n        \n        for e, pic in enumerate(d['imgs']):\n            #for each image\n            picture = imread(io.BytesIO(pic['picture']))\n            pictures.append(picture)\n            category_id_array.append(str(d['category_id']))","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"5c9ff9fb-0aa2-4646-b270-cfb503e59088","_uuid":"dd9c5d9b3078672abc57612f7302cd40c207b2d4"},"cell_type":"code","execution_count":null,"source":"#loading a subset of data,  as it is tooo largeee\nfrom collections import Counter\nX = np.asarray(pictures)\ny = np.asarray(category_id_array)\ny.shape\nnumClasses = len(Counter(y))","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"edf1ee26-b25a-4ad0-8b47-8644ed2dc1ae","_uuid":"212c7bd7cc970c523f145c07f4b7f54371af9897"},"cell_type":"code","execution_count":null,"source":"#X has the RGB values of images, y has the category labels\nprint(X.shape)\nprint(y.shape)","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"4e70c847-e53e-464a-970e-204502ecf584","_uuid":"a598bc27fa63b16b02cf53df434c8c4f295e0f4d"},"cell_type":"code","execution_count":null,"source":"# X = X.reshape(X.shape[0], 3, 180, 180).astype('float32')\n# X = X - np.mean(X) / X.std()","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"c264809c-7c93-4710-adc6-20fd5e451218","_uuid":"d39d93483789299c7b0682b6fc6ad9304a791160"},"cell_type":"code","execution_count":null,"source":"# y_train","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"8bbe7c31-295f-437f-9736-b041afbf9179","_uuid":"6074f841a1e47c2799c0b86555d0aaea8ca186eb"},"cell_type":"code","execution_count":null,"source":"# b,c = np.unique(y_train, return_inverse=True)","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"03ff71db-9254-47c8-80a3-73ed1b00e34e","_uuid":"218cfbf405c95753628ee70780d513c87dabb1a7"},"cell_type":"code","execution_count":null,"source":"# from collections import Counter\n# # d = Counter(c)","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"37ed0c0f-e378-4e98-9906-331b5f1be3a3","_uuid":"c849c91309c0900788639c1af03b75e7a72a7a89"},"cell_type":"code","execution_count":null,"source":"# y_train = c","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"4fb8235c-c68d-48c0-8903-a09920738418","_uuid":"56077036cbc3da6fcd24e653370547de30054cf3"},"cell_type":"code","execution_count":null,"source":"# y_train = np_utils.to_categorical(y_train)","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"6011c80b-8df6-4522-bb65-5fb774ad6fa3","_uuid":"62edb20bcd5fba16188b40dd5147632641b511a1"},"cell_type":"code","execution_count":null,"source":"# X_train = X_train.reshape(X_train.shape[0], 180, 180, 3)\n# X_train = X_train.astype('float32')\n# X_train = X_train/255\nprint(X.shape, y.shape)","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"577df474-a1b8-4327-a153-70c73a57d423","_uuid":"b5b510932007dece737596c67918ae67b3b07ec8"},"cell_type":"code","execution_count":null,"source":"X = X.reshape(X.shape[0], 180, 180, 3)\nX = X.astype('float32')\nX/=255\nb, y = np.unique(y, return_inverse=True)\ny = np_utils.to_categorical(y)\nprint(y)\n\n#lets split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\nX_train = X\ny_train = y\n\nprint(X_train.shape, y_train.shape, X_test.shape, y_test.shape)","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"b6a608a3-fd30-4d7f-a0d7-31f7fd667835","_uuid":"c9861455245ff2a1fcf1c87d66f19ea3a6a0847b"},"cell_type":"code","execution_count":null,"source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.optimizers import Adam\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), input_shape=(180,180,3)))\nBatchNormalization(axis=-1)\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3)))\nBatchNormalization(axis=-1)\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(64,(3, 3)))\nBatchNormalization(axis=-1)\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3)))\nBatchNormalization(axis=-1)\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Flatten())\n\n# Fully connected layer\nmodel.add(Dense(512))\n\nBatchNormalization()\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(numClasses))\n\nmodel.add(Activation('softmax'))","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"1a4b4cec-cfd0-44d6-b5f1-75f895d6c4d7","_uuid":"cab0255b6ce12bdaaac303d6910f0dde086cb463"},"cell_type":"code","execution_count":null,"source":"model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"b37a11e0-c78f-492a-8772-6cf0085091ef","_uuid":"5b7851399f266112baade2c12d4bf0b3800369e3"},"cell_type":"code","execution_count":null,"source":"#this is the total number of classes in the chosen subset of the actual data\nnumClasses","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"f951046f-ca3f-4e26-b8b9-329a705d8271","_uuid":"1e9e468e4b2498cbb46e355a41ff71f05a254ce2"},"cell_type":"code","execution_count":null,"source":"from keras.preprocessing.image import ImageDataGenerator\ngen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n                         height_shift_range=0.08, zoom_range=0.08)\ntest_gen = ImageDataGenerator()","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"c5dda7c6-f4c5-405f-a654-bfefa97cf5d7","_uuid":"bd4b30c4a178e66ba3f4f8610545bd46d540eb09"},"cell_type":"code","execution_count":null,"source":"#the generator functions are created so as to, pass the train and test sets to the learner function\n#helps us keeping our hands clean\ntrain_generator = gen.flow(X_train, y_train, batch_size=10)\ntest_generator = test_gen.flow(X_test, y_test, batch_size=10)\n\nnumTrainExamples = len(X_train)\nnumTrainExamples\nnumTestExamples = len(X_test)\nbatchSize = 10#int((1/13)*numTrainExamples)\nnumEpochs = 10\n\n#Even for this dataset this is going to take a while\n#After doing on this, we did on a larger subset, but kaggle kernal didn't allow us to do so :/\n#The kernal died doing this enormous amount of processing on RGB images","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"28d5580d-ec37-4d1a-ad46-bccd2170afff","_uuid":"e54196eeef6a6ae9bcafa14c648bf011dff8e471"},"cell_type":"code","execution_count":null,"source":"model.fit_generator(train_generator, steps_per_epoch=numTrainExamples//batchSize, epochs=numEpochs, validation_data=test_generator, validation_steps=numTestExamples//batchSize)","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"fe765f16-a5b7-478d-8855-a03241fedc39","_uuid":"07f0cf2599944d3052be02e407db3a5d18373dd9"},"cell_type":"code","execution_count":null,"source":"y_predict = model.predict(X_test)","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"29830512-6e12-4fee-a33c-46188c4d565d","_uuid":"a1a7647aa147d4a0bc5ad5156f119ec25a322b9e"},"cell_type":"code","execution_count":null,"source":"len(y_predict)\n# # y_predict.index(max(y_predict[0]))\nindices_predict = np.argmax(y_predict, axis=1)\nc = Counter(indices_predict)\nprint(c)\n# indices_predict\nindices_test = np.argmax(y_test, axis=1)\n# print(indices_predict)\n# print(indices_test)\n\n","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"8d944b79-d412-4e3f-9570-b97e127c286b","_uuid":"380d676333f7d1dc590103dd18be10a0f88d50cb"},"cell_type":"code","execution_count":null,"source":"# print(arr[0].index(max(arr[0])))","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"bd6d84d0-f2c7-4682-8a21-470c94388230","_uuid":"eb95fc92cc4188b8e053699cde968954ae7e8a28"},"cell_type":"code","execution_count":null,"source":"# arr[0]","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"be233d3b-6997-45b4-99bf-865ec16f574d","_uuid":"e1965b621dcf0e19a404c5a5ee2ca42f1aa415c2"},"cell_type":"code","execution_count":null,"source":"# type(indices_test)","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"0f51f020-fb1f-422d-94b9-f2bb7a53a7d1","_uuid":"53f2a1ece29cfd2ebbabbc40c3c33ff2880cf2e9"},"cell_type":"code","execution_count":null,"source":"# from sklearn.metrics import roc_auc_score, roc_curve\n# from sklearn import metrics\n\n# # roc_auc_score(indices_test, indices_predict)\nindices_predict = np.array(indices_predict.tolist())\nindices_test = np.array(indices_test.tolist())\n# metrics.roc_curve(indices_test, indices_predict)\nprint(indices_predict, indices_test)","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"952a88fb-df10-4552-94ef-b0a28ffae708","_uuid":"c832b0ff08ff098eec4ed949ab47cc6108da1962"},"cell_type":"code","execution_count":null,"source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom itertools import cycle\n\nfrom sklearn import svm, datasets\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom scipy import interp\n\n# # Import some data to play with\n# iris = datasets.load_iris()\n# X = iris.data\n# y = iris.target\n\n# Binarize the output\n# y = label_binarize(y, classes=[0, 1, 2])\nn_classes = numClasses\n\n# # Add noisy features to make the problem harder\n# random_state = np.random.RandomState(0)\n# n_samples, n_features = X.shape\n# X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n\n# # shuffle and split training and test sets\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,\n#                                                     random_state=0)\n\n# # Learn to predict each class against the other\n# classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,\n#                                  random_state=random_state))\n# y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n\ny_score = y_predict\n# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"34f10409-3824-4492-9ccd-239f9bf55e52","_uuid":"c8f97b7950c6a41f3903cbb5f188a53ab7eb3142"},"cell_type":"code","execution_count":null,"source":"plt.figure()\nlw = 2\nplt.plot(fpr[2], tpr[2], color='darkorange',\n         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\nplt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"2f7bdff1-4b66-48b8-901e-105c1459752c","_uuid":"f02873e259093e3c09020a230cf3b118b633f3d3"},"cell_type":"code","execution_count":null,"source":"# Compute macro-average ROC curve and ROC area\n\n# First aggregate all false positive rates\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n\n# Then interpolate all ROC curves at this points\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(n_classes):\n    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\n# Finally average it and compute AUC\nmean_tpr /= n_classes\n\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n# Plot all ROC curves\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]),\n         color='deeppink', linestyle=':', linewidth=4)\n\nplt.plot(fpr[\"macro\"], tpr[\"macro\"],\n         label='macro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"macro\"]),\n         color='navy', linestyle=':', linewidth=4)\n\ncolors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\nfor i, color in zip(range(n_classes), colors):\n    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n             label='ROC curve of class {0} (area = {1:0.2f})'\n             ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--', lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\n#plt.legend(loc=\"lower right\")\nplt.show()","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"3395af9d-4faf-4521-b429-11bab16e6fe1","_uuid":"7b6af2eb96298c61760aa4f28c77737e32d14524"},"cell_type":"code","execution_count":null,"source":"y_score","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"0aa2c797-2125-4784-b05e-563c2e4dadfc","_uuid":"eb66b56021de857164d8ae10f7f40db1d5001f92"},"cell_type":"code","execution_count":null,"source":"y_test","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"4fe0de55-e8db-46a7-8e76-74797946a392","_uuid":"26deb20abc67b715108bacec0a888e2368902f4f"},"cell_type":"code","execution_count":null,"source":"","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"b1a9e070-5528-42a6-b3c0-98471b1e3e1c","_uuid":"ca8f527415362713f00f876406989ed96c144225"},"cell_type":"code","execution_count":null,"source":"","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"bf3334b4-63ee-4ad1-bf0b-4a55e2b6ab73","_uuid":"805c442c1bf11ad346661d0e18e7046de4d98587"},"cell_type":"code","execution_count":null,"source":"","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"eaa6988b-e608-4cf8-8172-b02f5854ea79","_uuid":"f6b692f9a147f3449f3a3d763e2f0d5cd367c10b"},"cell_type":"code","execution_count":null,"source":"","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"e2111fa3-3078-4c63-9143-86c485c9ec2a","_uuid":"a28a83340cacb7ef4465148d93472e613f8335e0"},"cell_type":"code","execution_count":null,"source":"","outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"version":"3.6.3","file_extension":".py","mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"},"pygments_lexer":"ipython3","name":"python","nbconvert_exporter":"python"}}}