{"metadata":{"language_info":{"name":"python","nbconvert_exporter":"python","file_extension":".py","pygments_lexer":"ipython3","mimetype":"text/x-python","version":"3.6.1","codemirror_mode":{"name":"ipython","version":3}},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"cells":[{"source":"This notebook is just a (very) small improvement over most common baseline.\n\nIt loads a few images from train and resize it to 8x8 pixels to generate a 64 (8 x 8) feature vector.\n\nThen, it uses KNN to find the most similar image on test set.\n\nUnfortunatelly, due to limitations on Kernel, only a few test images are classified.","metadata":{"_cell_guid":"077c0bd7-bc31-4528-a747-6b0c6e66ebe4","_uuid":"de87e4b1b18f48d3672221485a6577293ec10926"},"cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"7d7afe89-0c7e-43cb-9ba6-0e93db30b4bd","_uuid":"99b9a425db0c128d80fda1ecc9b42f952a77c93c"},"source":"import numpy as np\nimport pandas as pd\nimport io\nimport bson\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook\nimport concurrent.futures\nfrom multiprocessing import cpu_count","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"ea4565d0-2922-4d0d-b7c5-f970cbdf1cc1","_uuid":"25a8edf7b1bf5b9d0726b3ede0c796717ab720ab"},"source":"num_images = 200000\nim_size = 16\nnum_cpus = cpu_count()\nnum_cpus","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"82f5d889-b14d-4cb7-86b0-5bd726304d8b","_uuid":"4a5081a65e4d22316b7306cddd80332712b21b0d"},"source":"def imread(buf):\n    return cv2.imdecode(np.frombuffer(buf, np.uint8), cv2.IMREAD_ANYCOLOR)\n\ndef img2feat(im):\n    x = cv2.resize(im, (im_size, im_size), interpolation=cv2.INTER_AREA)\n    return np.float32(x) / 255\n\nX = np.empty((num_images, im_size, im_size, 3), dtype=np.float32)\ny = []\n\ndef load_image(pic, target, bar):\n    picture = imread(pic)\n    x = img2feat(picture)\n    bar.update()\n    \n    return x, target\n\nbar = tqdm_notebook(total=num_images)\nwith open('../input/train.bson', 'rb') as f, \\\n        concurrent.futures.ThreadPoolExecutor(num_cpus) as executor:\n\n    data = bson.decode_file_iter(f)\n    delayed_load = []\n\n    i = 0\n    try:\n        for c, d in enumerate(data):\n            target = d['category_id']\n            for e, pic in enumerate(d['imgs']):\n                delayed_load.append(executor.submit(load_image, pic['picture'], target, bar))\n                \n                i = i + 1\n\n                if i >= num_images:\n                    raise IndexError()\n\n    except IndexError:\n        pass;\n    \n    for i, future in enumerate(concurrent.futures.as_completed(delayed_load)):\n        x, target = future.result()\n        \n        X[i] = x\n        y.append(target)","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"5cfda60d-d8c8-481c-833b-85f170564cc6","_uuid":"39c439b021cfe966165d78d29486f97ea9b84c5b"},"source":"X.shape, len(y)","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_cell_guid":"b5166a88-3ab9-4c8e-b4ad-134362a17845","_uuid":"f5f630b612437a897f216c657530f18f8e9b4f96"},"source":"y1= pd.Series(y)","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_cell_guid":"7e266d56-303e-42a8-8279-e6a5dbc3115f","_uuid":"175f3b982eb641ff17fb790c872ef80db1d923d9"},"source":"y1","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_cell_guid":"3fd80f61-ca6d-48d3-909b-d605ff206686","_uuid":"fd00d573b02fcd88409cdf437bcc313e03208b64"},"source":"y1.value_counts()","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_cell_guid":"1529bff1-855b-4361-b49a-a162f73d143f","_uuid":"ce2ab3b93006f2944aca5e79504b0f59abdc5b04"},"source":"y1.value_counts().index[:499].tolist()","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_cell_guid":"39f4b991-794c-452b-acaa-6ad7b46a968c","_uuid":"f23014097dc697cbb369585290885d2a1757ebba"},"source":"len(y1.value_counts().index[:499].tolist())","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_cell_guid":"87058b8f-6f8c-44cd-b0f1-fdd60ba58d84","_uuid":"3e4320c510ef1928c19cd60e3b3ddd2219cdf010"},"source":"set(y1.value_counts().index[:499].tolist())","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_cell_guid":"a533d0d8-d20a-439a-b580-49384e290527","_uuid":"bfe944c0684733afc68b35fbbaad708cb9540789"},"source":"len(set(y1.value_counts().index[:499].tolist()))","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_cell_guid":"c3d22179-af06-45e8-9904-6b4353b051ad","_uuid":"0843cca57a70b00822cf04a007c8bdfe96f9145a"},"source":"y2 = set(y1.value_counts().index[:499].tolist())","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_cell_guid":"8a3e53eb-0eee-4c85-b648-63b837be6296","_uuid":"9c12475f57bbf4c5fc534271b725c0442e885406"},"source":"y1.isin(y2)","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_cell_guid":"8a1665d1-4ffb-4c91-8ad5-736b3cddb48b","_uuid":"e0d1699481d90793c0eee77f409a91427062a071"},"source":"y3 = y1.isin(y2)","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_cell_guid":"9dfb3bca-0768-4324-8f5e-31a482a57086","_uuid":"702208233c60a16844dd3b055152c2cffea91f82"},"source":"~y3","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_cell_guid":"1a58ef3d-2066-412b-857c-84bb76820b3e","_uuid":"8f72ecaf4deb9dfd9cb57c6fa60f24191743edd7"},"source":"y1[~y3] = -1","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_cell_guid":"33c1650b-6bcc-4b2f-a114-a2d2401ff471","_uuid":"93972c2056e2cb17f765e7728d84a7687fb99c65"},"source":"y1","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_cell_guid":"5dff47bc-7971-4c51-9a88-9638101cd07d","_uuid":"a2931f755fb0ba816bfeb413e72c5a7d13501b2f"},"source":"y3.mean()","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"34c9bf08-9f89-461f-b74f-1f24291a5829","_uuid":"56969c620e60a3e55f0684b412fe1f6b7590ba01"},"source":"y = pd.Series(y)\n\nnum_classes = 500  # This will reduce the max accuracy to about 0.75\n\n# Now we must find the most `num_classes-1` frequent classes\n# (there will be an aditional 'other' class)\nvalid_targets = set(y.value_counts().index[:num_classes-1].tolist())\nvalid_y = y.isin(valid_targets)\n\n# Set other classes to -1\ny[~valid_y] = -1\n\nmax_acc = valid_y.mean()\nprint(max_acc)","cell_type":"code"},{"source":"Note that the max accuracy reported above is greater than ~0.75 reported [here](http://https://www.kaggle.com/bguberfain/naive-statistics) due to smaller train set.","metadata":{"_cell_guid":"2951efcb-a616-48c8-ad20-6c2bf2317a19","_uuid":"f49981818f17dcfc127b0e4cb6b28f7bf3003c42"},"cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"7543f03c-1eb4-483c-bdb2-2b04a3758b97","_uuid":"bb34e3f26c81f39a2ed4f3f8cc4fa03301b85fcd"},"source":"y, rev_labels = pd.factorize(y)","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"b032166d-24ee-42ae-bbe3-444e8141ba53","_uuid":"c0adfc41acc8a560e92bd849ae2967422f622267"},"source":"y","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"d1557e85-32d2-42a7-90da-a75b0c0e4878","_uuid":"676e13013955cee9db034e38a9d759c703baa3f8"},"source":"rev_labels","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_cell_guid":"3c137f38-d10d-49e7-a9e5-b1628d2e0567","_uuid":"1975ac67714c59998a9c8e587c7fd5554fd7597b"},"source":"# Now we categorize the dataframe\ny, rev_labels = pd.factorize(y)","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_cell_guid":"8755a82d-ed9b-4587-8d90-1a17cd95e51b","_uuid":"2d3d34806c1f50b6ecaf5e63fbed89a4f5be3b4f"},"source":"num_classes=500","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"e6368858-f2ce-4426-85af-89219c651a06","_uuid":"96da9277c9c7fed8cb871a3c434be783c9eb10f1"},"source":"# Train a simple NN\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\n\nmodel = Sequential()\nmodel.add(Conv2D(16, 3, activation='relu', padding='same', input_shape=X.shape[1:]))\nmodel.add(Conv2D(16, 3, activation='relu', padding='same'))\nmodel.add(MaxPooling2D(2))\nmodel.add(Conv2D(32, 3, activation='relu', padding='same'))\nmodel.add(Conv2D(32, 3, activation='relu', padding='same'))\nmodel.add(MaxPooling2D(2))\nmodel.add(Flatten())\nmodel.add(Dense(num_classes, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n\nopt = Adam(lr=0.01)\n\nmodel.compile('adam', 'sparse_categorical_crossentropy', metrics=['accuracy'])\n\nmodel.summary()","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"scrolled":true,"_cell_guid":"663b6abe-c16e-445a-b55e-6895087dc321","_uuid":"7683eaaa3211bdf9a17ca675bf6af5b1dd1ccd24"},"source":"hist = model.fit(X, y, validation_split=0.1, epochs=2)","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_cell_guid":"e36e69f3-841d-4c73-986f-9570efc2d4e5","_uuid":"e5ddbdd8b3b6be3937992264306ac580b83230b5"},"source":"hist.history","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"da934b31-efeb-48b9-b9fc-2474aa2c4470","_uuid":"c8d10d15e06318953ceafc26ec03349c88a041c2"},"source":"# list all data in history\nprint(hist.history.keys())\n# summarize history for accuracy\nplt.plot(hist.history['acc'])\nplt.plot(hist.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'valid'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'valid'], loc='upper left')\nplt.show()","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"8980a025-38b1-4f1b-8860-ee413631c434","_uuid":"290914eec155b2c14ae06309436235063c844339","_kg_hide-input":true,"_kg_hide-output":true},"source":"model.save_weights('cdiscount_model.h5')  #You can download this model and run whole test localy","cell_type":"code"},{"source":"Now we evaluate the test set using the previous trained model.","metadata":{"_cell_guid":"4b990f20-cb25-4be0-92bc-df033ada90ad","_uuid":"3dcc4c6c6261ac47970b5d0e33eaa0b9066a3cb9"},"cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"4425bdc4-dd25-40c8-a26e-fe2eb11d3398","_uuid":"5811926ec436c8820ccaa468fc2ac6a09dfbd3bc"},"source":"submission = pd.read_csv('../input/sample_submission.csv', index_col='_id')\n\nmost_frequent_guess = 1000018296\nsubmission['category_id'] = most_frequent_guess # Most frequent guess","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"f7465e07-cc74-4371-9cc1-3639641f4110","_uuid":"bc6ce0ae1620a9ac5a481d0a7e4a0f0e25510fd1"},"source":"num_images_test = 800000  # We only have time for a few test images..\n\nbar = tqdm_notebook(total=num_images_test * 2)\nwith open('../input/test.bson', 'rb') as f, \\\n         concurrent.futures.ThreadPoolExecutor(num_cpus) as executor:\n\n    data = bson.decode_file_iter(f)\n\n    future_load = []\n    \n    for i,d in enumerate(data):\n        if i >= num_images_test:\n            break\n        future_load.append(executor.submit(load_image, d['imgs'][0]['picture'], d['_id'], bar))\n\n    print(\"Starting future processing\")\n    for future in concurrent.futures.as_completed(future_load):\n        x, _id = future.result()\n        \n        y_cat = rev_labels[np.argmax(model.predict(x[None])[0])]\n        if y_cat == -1:\n            y_cat = most_frequent_guess\n\n        bar.update()\n        submission.loc[_id, 'category_id'] = y_cat\nprint('Finished')","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true,"_cell_guid":"dd34386c-f28a-42d7-a3be-f09126fd61c7","_uuid":"f806114fc478e841392589d4f7e2f0b828b20311","_kg_hide-input":true,"_kg_hide-output":true},"source":"submission.to_csv('new_submission.csv.gz', compression='gzip')","cell_type":"code"}],"nbformat_minor":1,"nbformat":4}