{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python","name":"python","mimetype":"text/x-python","pygments_lexer":"ipython3","file_extension":".py","version":"3.6.1"}},"nbformat_minor":1,"nbformat":4,"cells":[{"metadata":{"_uuid":"2eb66bcba2ffcb381e161351769d8c96c8f7cfe9","_cell_guid":"ce15e7ac-99a8-4400-ac1c-b1d783c7feec"},"source":"tips:\n- https://github.com/rasbt/python-machine-learning-book/blob/master/code/optional-py-scripts/ch04.py\n- https://stackoverflow.com/questions/45932773/why-there-are-strips-in-the-predicted-image-in-keras\n- https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly.html\n- https://medium.com/@fromtheast/implement-fit-generator-in-keras-61aa2786ce98\n- https://www.kaggle.com/theblackcat/loading-bson-data-for-keras-fit-generator\n- https://github.com/abnera/image-classifier/blob/master/code/fine_tune.py#L124\n- https://www.kaggle.com/vfdev5/data-visualization-and-analysis/notebook\n- https://www.kaggle.com/saptak7/2-layer-cnn-adam-optimizer-and-5-epochs\n- https://www.kaggle.com/bguberfain/naive-keras-cdiscount/notebook\n\niterator\n- https://www.kaggle.com/humananalog/keras-generator-for-reading-directly-from-bson\n- https://spark-in.me/post/bird-voice-recognition-eight\n- https://www.kaggle.com/vfdev5/random-item-access\n- https://www.kaggle.com/ezietsman/keras-convnet-with-fit-generator\n- https://gist.github.com/faroit/92ba12373440d092e1096967b530a5b8\n- https://github.com/fchollet/keras/blob/master/tests/keras/utils/data_utils_test.py\n- https://stanford.edu/~shervine/blog/keras-generator-multiprocessing.html\n- https://keunwoochoi.wordpress.com/2017/08/24/tip-fit_generator-in-keras-how-to-parallelise-correctly/\n- http://anandology.com/blog/using-iterators-and-generators/\n\nmodels\n- https://gogul09.github.io/software/flower-recognition-deep-learning\n- https://shuaiw.github.io/2017/03/09/smaller-faster-deep-learning-models.html\n- https://www.kaggle.com/drn01z3/mxnet-xgboost-baseline-lb-0-57\n- https://www.kaggle.com/drn01z3/resnet50-features-xgboost\n- http://blog.kaggle.com/2016/04/28/yelp-restaurant-photo-classification-winners-interview-1st-place-dmitrii-tsybulevskii/\n- https://github.com/u1234x1234/kaggle-yelp-restaurant-photo-classification\n- http://blog.kaggle.com/2016/08/24/avito-duplicate-ads-detection-winners-interview-1st-place-team-devil-team-stanislav-dmitrii/\n- https://www.kaggle.com/zfturbo/python-xgboost-starter/code\n- https://github.com/petrosgk/Kaggle-Carvana-Image-Masking-Challenge\n- https://www.kaggle.com/algila/inception-v3-and-k-fold-in-python-0-98996\n- https://www.kaggle.com/abnera/transfer-learning-keras-xception-cnn\n\n\nensembles\n- https://mlwave.com/kaggle-ensembling-guide/\n\nlabel\n- http://sloth.readthedocs.io/en/latest/\n\nto order\n- https://github.com/LowikC/kaggle_cdiscount\n- https://github.com/rdoume/kaggle_cdiscount\n- https://github.com/fgmehlin/kaggle_cdiscount\n- https://github.com/Cuongvn08/kaggle_cdiscount_image_classify/blob/master/train.py\n- https://github.com/petrosgk/Kaggle-Cdiscount-Image-Classification-Challenge\n- https://github.com/lidalei/cdiscount\n- https://github.com/shawnxiaow1118/Kaggle_Cdiscounts_Image_Classification\n- https://github.com/xkumiyu/chainer-cdiscount-kernel\n- https://github.com/ilcauchy/cdiscount\n- https://github.com/DeepLearningSandbox/DeepLearningSandbox/blob/master/transfer_learning/fine-tune.py\n- https://github.com/abnera/image-classifier/blob/master/code/fine_tune.py\n\n- https://github.com/knjcode/mxnet-finetuner","cell_type":"markdown"},{"metadata":{"collapsed":true,"_uuid":"6edcc629573d3ef52b0a758f798e5aa923b50226","_cell_guid":"c57e30dc-fe6e-48b1-9e85-2487a7b2a84b"},"outputs":[],"execution_count":null,"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom skimage.data import imread \nimport json\nimport bson\nimport io"},{"metadata":{"collapsed":true,"_uuid":"886e141a8c369d166bdb34ea04a4dc20ddc3547a","_cell_guid":"dd577ce3-2fa8-48ea-83e8-6439bc7e3086"},"outputs":[],"execution_count":null,"cell_type":"code","source":"import os\nINPUT_PATH = os.path.join('..', 'input', 'cdiscount-image-classification-challenge')\n\ntrain_example_path = os.path.join(INPUT_PATH, 'train_example.bson')\ntrain_path = os.path.join(INPUT_PATH, 'train.bson')\n\n#train_example_path = \"../input/cdiscount-image-classification-challenge/train_example.bson\"\n#train_path = \"../input/cdiscount-image-classification-challenge/train.bson\""},{"metadata":{"collapsed":true,"_uuid":"d32b0ff24790d2787505abfe03d3ea160ece156d","_cell_guid":"3833568c-14cd-4108-b3d6-df0a44a82307"},"outputs":[],"execution_count":null,"cell_type":"code","source":"import os.path as path\n\ndef split():\n    ids = []\n    categories = []\n    for example in bson.decode_file_iter(open(train_path, 'rb')):\n        ids.append(example['_id'])\n        categories.append(example['category_id'])\n    return ids, categories\n        \nids, categories = split()"},{"metadata":{"collapsed":true,"_uuid":"9ee870aab83d1c93cbe5fec8f9d50227389d4ea0","_cell_guid":"e4d628c1-9846-4ac9-b96e-0903bd1083eb"},"outputs":[],"execution_count":null,"cell_type":"code","source":"import random\n\n_valid_percent=0.1\nsize = len(ids)\ntrain_size = int(size*(1-_valid_percent))\nvalid_size = (size-train_size)\nsplit = ['train']*train_size + ['valid']*valid_size\nrandom.shuffle(split)\nsplit_df = pd.DataFrame({'id': ids, 'split': split})\nsplit_df = split_df.set_index(['id'])\nsplit_df.head(11)"},{"metadata":{"collapsed":true,"_uuid":"0a20063af9d7de38615c2b4abf40debc79d8e8f0","_cell_guid":"b3012331-7e60-454b-aab8-ea6e3976b917"},"outputs":[],"execution_count":null,"cell_type":"code","source":"#if self._split.loc[example['_id']]['split'] == name:\n#for row in \n#split_df.loc[11]['split'] == 'valid'"},{"metadata":{"collapsed":true,"_uuid":"964a05457d98d2ef8c5923d0242b374ecf633d3a","_cell_guid":"892f6ed8-c0bd-4e5a-8a4b-9e60d4e785bd"},"outputs":[],"execution_count":null,"cell_type":"code","source":"from sklearn.cross_validation import train_test_split\nids_train,ids_test = train_test_split(ids,test_size=0.1)\nprint(len(ids_train),len(ids_test))\nprint(ids_train[0], ids_test[0])\n\n#X_train,X_test,Y_train,Y_test = train_test_split(X,dummy_y,test_size=0.3)\n#print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)"},{"metadata":{"collapsed":true,"_uuid":"d1c23a0ca7c2b9fff4ebf0f3c00667cd460a5cbf","_cell_guid":"db6cc795-df9e-412d-abba-90a542796798"},"outputs":[],"execution_count":null,"cell_type":"code","source":"#10 in ids, 10 in ids_train, 10 in ids_test"},{"metadata":{"collapsed":true,"_uuid":"adc1f7fa17989bb62379d4583394714a64f08b2b","_cell_guid":"79593b15-f6a0-458f-9fe7-69d02851a4d5"},"outputs":[],"execution_count":null,"cell_type":"code","source":"#data.category_id.values\n#path = \"../input/cdiscount-image-classification-challenge/train_example.bson\"\ncategory_names = pd.read_csv(os.path.join(INPUT_PATH, 'category_names.csv'))\nprint(len(category_names['category_id'].unique()))\ncategory_names.head()"},{"metadata":{"collapsed":true,"_uuid":"eca91cee760bf55604d5386e71072456340be5f3","_cell_guid":"3d71eaff-c1da-4cab-9d43-dfb47707557e"},"outputs":[],"execution_count":null,"cell_type":"code","source":"num_classes = 5270"},{"metadata":{"collapsed":true,"_uuid":"114745f85f772313e00c78f8e089cc94b4f766c8","_cell_guid":"88cd9522-0606-4c68-bb61-d66f1192905a"},"outputs":[],"execution_count":null,"cell_type":"code","source":"from keras.utils import np_utils\nfrom sklearn.preprocessing import LabelEncoder\n\nencoder = LabelEncoder()\nencoder.fit(category_names['category_id'])\n#encoded_y = encoder.transform(y)\n#dummy_y = np_utils.to_categorical(encoded_y, num_classes=num_classes)\n#dummy_y.shape"},{"metadata":{"collapsed":true,"_uuid":"7096111619a709d772dfc15c296838b40d5f3f16","_cell_guid":"52850a1a-7fe6-4868-89d0-f0f05436cf07"},"outputs":[],"execution_count":null,"cell_type":"code","source":"#encoder.fit([1000010653])\nnp_utils.to_categorical(encoder.transform([1000010653]), num_classes=num_classes).shape"},{"metadata":{"collapsed":true,"_uuid":"76f5991f9479031218f8b7e468c65435894f95a8","_cell_guid":"796e9027-b4a6-4c76-8720-74cfce1e9e8d"},"outputs":[],"execution_count":null,"cell_type":"code","source":"im_size = 180\n\nbatch_size = 32\nbatch_size_validation = 64\n\nepochs_top = 10\nepochs = 20\n\nsteps_per_epoch_top = 5\nsteps_per_epoch = 10\n\nvalidation_steps_top=2\nvalidation_steps=2\n\n#minibatch_size = batch_size\n#words_per_epoch = 6362906+706990\n#6362906 \n\n#val_words = 706990\n\n#steps = 7069896/32\n#steps = 220,934.25\n\n#validation_steps = val_words // minibatch_size\n#validation_steps = 706990//32\n#validation_steps = 22,093.4375\n\n#steps_per_epoch = (words_per_epoch - val_words) // minibatch_size\n#steps_per_epoch = (7069896 - 706990) // 32\n#steps_per_epoch = 198,840.8125\n\n# https://github.com/fchollet/keras/blob/master/examples/image_ocr.py\n#val_words = int(words_per_epoch * (val_split))\n#val_split = 0.2\n#val_split=words_per_epoch - val_words"},{"metadata":{"collapsed":true,"_uuid":"dc14990b06c8ae5ee5207cf3b379d20afef77f20","_cell_guid":"d60beafa-a891-47b1-86bb-32cffd344830"},"outputs":[],"execution_count":null,"cell_type":"code","source":"import cv2\n\ndef _imread(buf):\n    return cv2.imdecode(np.frombuffer(buf, np.uint8), cv2.IMREAD_ANYCOLOR)\n\ndef img2feat(im):\n    x = cv2.resize(im, (im_size, im_size), interpolation=cv2.INTER_AREA)\n    return np.float32(x) / 255.\n\n#X = np.empty((num_images, im_size, im_size, 3), dtype=np.float32)\n#y = []\n\ndef load_image(pic, target):\n    x = _imread(pic['picture'])\n    x = img2feat(x)\n#    bar.update()\n    \n    return x, target\n\ndef generate_arrays_from_file(path, batch_size):\n    batch_features = np.zeros((batch_size, im_size, im_size, 3))\n    batch_labels = np.zeros((batch_size,1))\n    while 1:\n        f = open(path,'rb')\n        data_iter = bson.decode_file_iter(f)\n        for i, d in enumerate(data_iter):\n            target = d['category_id']\n            for e, pic in enumerate(d['imgs']):\n                x, target = load_image(pic, target)\n#                yield x, np_utils.to_categorical(encoder.transform([target]), num_classes=num_classes)[0]\n\n\n                encoded_y = encoder.transform([target])\n                dummy_y = np_utils.to_categorical(encoded_y, num_classes=num_classes)\n                yield np.array([x]), dummy_y\n#                yield ({'input_2': np.array([x])}, {'dense_2': dummy_y})\n#                yield batch_features, batch_labels\n        f.close()"},{"metadata":{"collapsed":true,"_uuid":"df88a396fe1c4415d90447dcff0c32b764c59a05","_cell_guid":"7f8f8907-61c6-49b0-a612-dfaae8b3345b"},"outputs":[],"execution_count":null,"cell_type":"code","source":"def convert2onehot(category_id):\n    encoded_y = encoder.transform([category_id])\n    dummy_y = np_utils.to_categorical(encoded_y, num_classes=num_classes)\n    return True, dummy_y[0]\n#convert2onehot(1000010653)"},{"metadata":{"collapsed":true,"_uuid":"38202456e421ee1826b73e5b4ff969050c712e83","_cell_guid":"24888474-1b1f-4476-8602-d1bad2334fd8"},"outputs":[],"execution_count":null,"cell_type":"code","source":"# https://www.kaggle.com/theblackcat/loading-bson-data-for-keras-fit-generator\n\nfrom random import randint\n    \ndef data_generator(path, ids, batch_size=128, start_image=0, name=''):\n    count_product = 0\n    images = []\n    y_label = []\n    while True:\n        f = open(path,'rb')\n        data_iter = bson.decode_file_iter(f)\n        count = 0\n        for c, d in enumerate(data_iter):\n#            if d['_id'] not in ids:\n            if split_df.loc[d['_id']]['split'] == name:\n#                print(name, 'not in', d['_id'])\n                continue\n#            print(name, 'in', d['_id'])\n            category_id = d['category_id']\n            if count_product < start_image:\n                count_product += 1\n                continue\n            success, one_hot = convert2onehot(category_id)\n            if not success:\n                print(\"id conversion failed\")\n                continue\n            for e, pic in enumerate(d['imgs']):\n#                picture = imread(io.BytesIO(pic['picture']))\n                picture, _ = load_image(pic, category_id)\n                images.append(picture)\n                y_label.append(one_hot)\n                count += 1\n            if count >= batch_size:\n                count = 0\n                y_label = np.asarray(y_label)\n                images = np.asarray(images)\n                '''\n                    since shuffle in fit function will not work here, \n                    a batch shuffle mechnism is added \n                '''\n                for i,image in enumerate(images[:int(batch_size/2)]):\n                    j = randint(0,batch_size-1)\n                    y_temp = y_label[i]\n                    img_temp = image\n                    images[i] = images[j]\n                    y_label[i] = y_label[j]\n                    images[j] = img_temp\n                    y_label[j] = y_temp\n                yield images, y_label\n                # just to be sure past batch are removed from the memory\n                del images\n                del y_label\n                images = []\n                y_label = []\n#                return\n#list(data_generator(batch_size=2))"},{"metadata":{"collapsed":true,"_uuid":"2b42db011bffccad4e9566314fca4e2cde62f98b","_cell_guid":"bcd56319-7c8c-4b57-aab9-c88df74620af"},"outputs":[],"execution_count":null,"cell_type":"code","source":"#from sklearn.cross_validation import train_test_split\n#X_train,X_test,Y_train,Y_test = train_test_split(X,dummy_y,test_size=0.3)\n#print(X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)"},{"metadata":{"collapsed":true,"_uuid":"01e70489b42fdfadc2e7e6220eab23f3946b7498","_cell_guid":"1a0220fd-cf25-4761-8810-940a8321d437"},"outputs":[],"execution_count":null,"cell_type":"code","source":"import keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Dropout, Flatten,Input\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K\n\nK.set_image_dim_ordering('tf')"},{"metadata":{"collapsed":true,"_uuid":"a494a284c2d601199b9aa747a59bc2688ad72895","_cell_guid":"b40970d6-6d80-4978-9f46-8986f0a3880e"},"outputs":[],"execution_count":null,"cell_type":"code","source":"from keras.applications.inception_v3 import InceptionV3\nfrom keras.preprocessing import image\nfrom keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.layers import Input\nfrom keras import backend as K\n\ninput_tensor = Input(shape=(im_size, im_size, 3))\n\n# create the base pre-trained model\n#base_model = InceptionV3(weights=None, include_top=False, input_tensor=input_tensor)\nbase_model = InceptionV3(weights=None, include_top=False, input_shape=(im_size, im_size, 3))\n\nkeras_models_dir = \"../input/keras inception v3 notop v0.5\"\nbase_model.load_weights('%s/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5' % keras_models_dir)"},{"metadata":{"collapsed":true,"_uuid":"8ab925a28655f20676cea7c6e5e6e425deae24a0","_cell_guid":"530af1d6-698d-4178-b58f-f6052406a066"},"outputs":[],"execution_count":null,"cell_type":"code","source":"# add a global spatial average pooling layer\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\n# let's add a fully-connected layer\nx = Dense(1024, activation='relu')(x)\n# and a logistic layer -- let's say we have 200 classes\npredictions = Dense(num_classes, activation='softmax')(x)\n\n# add a new top layer\n#x = base_model.output\n#x = Flatten()(x)\n#predictions = Dense(17, activation='sigmoid')(x)\n\n#x = AveragePooling2D((8, 8), strides=(8, 8), name='avg_pool')(x)\n#x = Flatten(name='flatten')(x)\n#predictions = Dense(36, activation='softmax', name='predictions')(x)\n\n# this is the model we will train\nmodel = Model(inputs=base_model.input, outputs=predictions)"},{"metadata":{"collapsed":true,"_uuid":"d8ae37ef3309e9fdac2bee14f3daaba5e4fea65b","_cell_guid":"1be90bc9-50dd-47c9-b807-1a9e1c3867f5"},"outputs":[],"execution_count":null,"cell_type":"code","source":"# first: train only the top layers (which were randomly initialized)\n# i.e. freeze all convolutional InceptionV3 layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# compile the model (should be done *after* setting layers to non-trainable)\nmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"},{"metadata":{"collapsed":true,"_uuid":"42ef2858c833baa93c329cb324d8e06cc16da282","_cell_guid":"437ac1c1-a7b4-4aa2-a5ee-26044694e083"},"outputs":[],"execution_count":null,"cell_type":"code","source":"# train the model on the new data for a few epochs\nif True:\n    #model.fit_generator(...)\n#    batch_size = 32\n#    epochs = 10\n#    generator=generate_arrays_from_file(path)\n    generator = data_generator(train_path, ids_train, batch_size=batch_size, name='train')\n    generator_validation = data_generator(train_path, ids_test, batch_size=batch_size_validation, name='valid')\n    hist = model.fit_generator(\n                  generator=generator,\n                  steps_per_epoch=steps_per_epoch_top,\n                  epochs=epochs_top,\n                  verbose=1,\n                  callbacks = None,\n                  validation_data=generator_validation,\n                  validation_steps=validation_steps_top,\n#                  validation_data=(X_test, Y_test)\n                  )\nelse:\n#    batch_size = 32\n#    epochs = 10\n    hist = model.fit(X_train, Y_train,\n                  batch_size=batch_size,\n                  epochs=epochs_top,\n                  verbose=1,\n                  callbacks = None,\n                  validation_data=(X_test, Y_test))"},{"metadata":{"collapsed":true,"_uuid":"bc1141a484e188ca2352ed54478c64f83e4e9f58","_cell_guid":"c404af9a-6aef-418c-b06f-63b291b064a4"},"outputs":[],"execution_count":null,"cell_type":"code","source":"# at this point, the top layers are well trained and we can start fine-tuning\n# convolutional layers from inception V3. We will freeze the bottom N layers\n# and train the remaining top layers.\n\n# let's visualize layer names and layer indices to see how many layers\n# we should freeze:\nfor i, layer in enumerate(base_model.layers):\n   print(i, layer.name)\n\n# we chose to train the top 2 inception blocks, i.e. we will freeze\n# the first 249 layers and unfreeze the rest:\nfor layer in model.layers[:249]:\n   layer.trainable = False\nfor layer in model.layers[249:]:\n   layer.trainable = True\n\n# we need to recompile the model for these modifications to take effect\n# we use SGD with a low learning rate\nfrom keras.optimizers import SGD\nmodel.compile(optimizer=SGD(lr=0.0001, momentum=0.9), \n              loss='categorical_crossentropy', \n              metrics=['accuracy'])"},{"metadata":{"collapsed":true,"_uuid":"ab2f29e32b6a005e7452b2039f7e11678af3130d","_cell_guid":"2d7ccd1c-a080-4aef-a470-94eeaab5d910"},"outputs":[],"execution_count":null,"cell_type":"code","source":"# we train our model again (this time fine-tuning the top 2 inception blocks\n# alongside the top Dense layers\n#model.fit_generator(...)\nif True:\n    #model.fit_generator(...)\n#    batch_size = 32\n#    epochs = 10\n#    generator=generate_arrays_from_file(path)\n    generator = data_generator(train_path, ids_train, batch_size=batch_size, name='train')\n    generator_validation = data_generator(train_path, ids_test, batch_size=batch_size_validation, name='valid')\n    hist = model.fit_generator(\n                  generator=generator,\n                  steps_per_epoch=steps_per_epoch,\n                  epochs=epochs,\n                  verbose=1,\n                  callbacks = None,\n                  validation_data=generator_validation,\n                  validation_steps=validation_steps,\n#                  validation_data=(X_test, Y_test)\n                  )\nelse:\n#    batch_size = 32\n#    epochs = 10\n    hist = model.fit(X_train, Y_train,\n                  batch_size=batch_size,\n                  epochs=epochs,\n                  verbose=1,\n                  callbacks = None,\n                  validation_data=(X_test, Y_test))"},{"metadata":{"collapsed":true,"_uuid":"68c4e047bae1596eb5cb80f57f311ebefcff8617","_cell_guid":"1a7a6a56-2cb6-45db-bcc2-e56ad6470318"},"outputs":[],"execution_count":null,"cell_type":"code","source":"def plot_train(hist):\n    h = hist.history\n    if 'acc' in h:\n        meas='acc'\n        loc='lower right'\n    else:\n        meas='loss'\n        loc='upper right'\n    plt.plot(hist.history[meas])\n    plt.plot(hist.history['val_'+meas])\n    plt.title('model '+meas)\n    plt.ylabel(meas)\n    plt.xlabel('epoch')\n    plt.legend(['train', 'validation'], loc=loc)\nplot_train(hist)"},{"metadata":{"collapsed":true,"_uuid":"5b4bde5d7b8f7bfddf4883c2318a5b7a2e42b6bd","_cell_guid":"8e7ee910-3ad3-46af-b691-3f2187333e94"},"outputs":[],"execution_count":null,"cell_type":"code","source":"#hist.history"},{"metadata":{"collapsed":true,"_uuid":"5dc7f2f744492b20b78f5cdf0fa761a9829746f5","_cell_guid":"e49e36e4-86cb-46de-a834-ecf6a2644681"},"outputs":[],"execution_count":null,"cell_type":"code","source":"# https://www.kaggle.com/saptak7/2-layer-cnn-adam-optimizer-and-5-epochs\n# https://www.kaggle.com/bguberfain/naive-keras-cdiscount/notebook\n\nfrom tqdm import tqdm_notebook\nimport concurrent.futures\nfrom multiprocessing import cpu_count\nnum_cpus = cpu_count()\n\nsubmission = pd.read_csv(\n    '../input/cdiscount-image-classification-challenge/sample_submission.csv', \n    index_col='_id')\n\n#most_frequent_guess = 1000018296\n#submission['category_id'] = most_frequent_guess \n\nnum_images_test = 100\nbar = tqdm_notebook(total=num_images_test * 1)\n\nwith open('../input/cdiscount-image-classification-challenge/test.bson', 'rb') as f, \\\n         concurrent.futures.ThreadPoolExecutor(num_cpus) as executor:\n\n    data = bson.decode_file_iter(f)\n\n    future_load = []\n\n    for i,d in enumerate(data):\n        if i >= num_images_test:\n              break\n#        future_load.append(executor.submit(load_image, d['imgs'][0]['picture'], d['_id'], bar))\n        future_load.append(executor.submit(load_image, d['imgs'][0], d['_id']))\n        \n#        print(\"Starting future processing\")\n    for future in concurrent.futures.as_completed(future_load):\n        x, _id = future.result()\n        y_cat = encoder.inverse_transform(np.argmax(model.predict(x[None])[0]))\n#        print(y_cat)\n#        y_cat = rev_labels[np.argmax(model.predict(x[None])[0])]\n#        if y_cat == -1:\n#            y_cat = most_frequent_guess\n\n        bar.update()\n        submission.loc[_id, 'category_id'] = y_cat\nprint('Finished')"},{"metadata":{"collapsed":true,"_uuid":"98c0613cdf15938e1d3fb18c290a58f3ea2156a0","_cell_guid":"ef117828-603b-43fe-b75e-0a1616eb690d"},"outputs":[],"execution_count":null,"cell_type":"code","source":"submission.to_csv('new_submission.csv.gz', compression='gzip')"},{"metadata":{"collapsed":true,"_uuid":"f7f56b63a548e1a2ef77f594da4fd8cc596ac8cd","_cell_guid":"17e925af-aa4b-44a3-ada9-6d6ae40812e0"},"outputs":[],"execution_count":null,"cell_type":"code","source":"#encoder.inverse_transform(model.predict(x[None]))\n#encoder.inverse_transform(np.argmax(model.predict(x[None])[0]))"},{"metadata":{"_uuid":"98f0b4eba7db251eeaf6978b7c74afbeb30036f1","_cell_guid":"16c83905-c7de-4882-88d5-1d05c8c4ba49"},"source":"First kernel try in keras \nLot more to come!!\nStay Advance :)","cell_type":"markdown"}]}