{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Data and Library Loading"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\nimport sklearn.model_selection\nimport sklearn.metrics\nfrom catboost import CatBoostClassifier\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport warnings\nimport gc\nimport time\n\nfrom keras.layers import * # Keras is the most friendly Neural Network library, this Kernel use a lot of layers classes\nfrom keras.models import *\nfrom tqdm import tqdm # Processing time measurement\nfrom sklearn.model_selection import train_test_split \nfrom keras import backend as K # The backend give us access to tensorflow operations and allow us to create the Attention class\nfrom keras import optimizers # Allow us to access the Adam class to modify some parameters\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold # Used to use Kfold to train our model\nfrom keras.callbacks import * # This object helps the model to train in a smarter way, avoiding overfitting\nfrom keras import activations\nfrom keras import regularizers\nfrom keras import initializers\nfrom keras import constraints\nfrom sklearn.preprocessing import MinMaxScaler\nfrom numba import jit\nfrom math import log, floor\nfrom sklearn.neighbors import KDTree\nfrom scipy.signal import periodogram, welch\nfrom keras.engine import Layer\nfrom keras.engine import InputSpec\nfrom keras.objectives import categorical_crossentropy\nfrom keras.objectives import sparse_categorical_crossentropy\nimport tensorflow as tf\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nplt.style.use('seaborn')\nsns.set(font_scale=1)","execution_count":2,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/vsb-power-line-fault-detection/metadata_train.csv')\ndf_train = df_train.set_index(['id_measurement', 'phase'])\n\nX = np.load(\"../input/folk-base-neural-network-using-lstm/X.npy\")\ny = np.load(\"../input/folk-base-neural-network-using-lstm/y.npy\")\nfeatures = np.load(\"../input/folk-base-neural-network-using-lstm/features.npy\")","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def augment(x,y,t=2):\n    xs,xn = [],[]\n    for i in range(t):\n        mask = y>0\n        x1 = x[mask].copy()\n        ids = np.arange(x1.shape[0])\n        for c in range(x1.shape[1]):\n            np.random.shuffle(ids)\n            x1[:,c] = x1[ids][:,c]\n        xs.append(x1)\n\n    for i in range(t//2):\n        mask = y==0\n        x1 = x[mask].copy()\n        ids = np.arange(x1.shape[0])\n        for c in range(x1.shape[1]):\n            np.random.shuffle(ids)\n            x1[:,c] = x1[ids][:,c]\n        xn.append(x1)\n\n    xs = np.vstack(xs)\n    xn = np.vstack(xn)\n    ys = np.ones(xs.shape[0])\n    yn = np.zeros(xn.shape[0])\n    x = np.vstack([x,xs,xn])\n    y = np.concatenate([y,ys,yn])\n    return x,y","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape, y.shape","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"((2904, 160, 57), (2904,))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nX, y = augment(X,y)\nprint(X.shape, y.shape)","execution_count":6,"outputs":[{"output_type":"stream","text":"(5986, 160, 57) (5986,)\nCPU times: user 5.63 s, sys: 16.3 s, total: 21.9 s\nWall time: 22 s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = np.load('../input/vsb-aug-features/aug_features.npy')\nfeatures.shape","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"(5986, 7)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Building a RNN Model Architecture"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Attention(Layer):\n    def __init__(self, step_dim,\n                 W_regularizer=None, b_regularizer=None,\n                 W_constraint=None, b_constraint=None,\n                 bias=True, **kwargs):\n        self.supports_masking = True\n        self.init = initializers.get('glorot_uniform')\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        self.step_dim = step_dim\n        self.features_dim = 0\n        super(Attention, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 3\n\n        self.W = self.add_weight((input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_W'.format(self.name),\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        self.features_dim = input_shape[-1]\n\n        if self.bias:\n            self.b = self.add_weight((input_shape[1],),\n                                     initializer='zero',\n                                     name='{}_b'.format(self.name),\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n        else:\n            self.b = None\n\n        self.built = True\n\n    def compute_mask(self, input, input_mask=None):\n        return None\n\n    def call(self, x, mask=None):\n        features_dim = self.features_dim\n        step_dim = self.step_dim\n\n        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n\n        if self.bias:\n            eij += self.b\n\n        eij = K.tanh(eij)\n\n        a = K.exp(eij)\n\n        if mask is not None:\n            a *= K.cast(mask, K.floatx())\n\n        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n\n        a = K.expand_dims(a)\n        weighted_input = x * a\n        return K.sum(weighted_input, axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0],  self.features_dim","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def matthews_correlation(y_true, y_pred):\n    '''Calculates the Matthews correlation coefficient measure for quality\n    of binary classification problems.\n    '''\n    \n    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n    y_pred_neg = 1 - y_pred_pos\n\n    y_pos = K.round(K.clip(y_true, 0, 1))\n    y_neg = 1 - y_pos\n\n    tp = K.sum(y_pos * y_pred_pos)\n    tn = K.sum(y_neg * y_pred_neg)\n\n    fp = K.sum(y_neg * y_pred_pos)\n    fn = K.sum(y_pos * y_pred_neg)\n\n    numerator = (tp * tn - fp * fn)\n    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n\n    return numerator / (denominator + K.epsilon())","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def threshold_search(y_true, y_proba):\n    best_threshold = 0\n    best_score = 0\n    for threshold in tqdm([i * 0.01 for i in range(100)]):\n        score = K.eval(matthews_correlation(y_true.astype(np.float64), (y_proba > threshold).astype(np.float64)))\n        if score > best_score:\n            best_threshold = threshold\n            best_score = score\n    search_result = {'threshold': best_threshold, 'matthews_correlation': best_score}\n    return search_result","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This is NN LSTM Model creation\ndef model_lstm(input_shape, feat_shape):\n    inp = Input(shape=(input_shape[1], input_shape[2],))\n    feat = Input(shape=(feat_shape[1],))\n\n    bi_lstm_1 = Bidirectional(CuDNNLSTM(128, return_sequences=True), merge_mode='concat')(inp)\n    bi_lstm_2 = Bidirectional(CuDNNGRU(64, return_sequences=True), merge_mode='concat')(bi_lstm_1)\n    \n    attention = Attention(input_shape[1])(bi_lstm_2)\n    \n    x = concatenate([attention, feat], axis=1)\n    x = Dense(64, activation=\"relu\")(x)\n    x = Dense(1, activation=\"sigmoid\")(x)\n    \n    model = Model(inputs=[inp, feat], outputs=x)\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[matthews_correlation])\n    \n    return model\n","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here is where the training happens\n# First, create a set of indexes of the 5 folds\nN_SPLITS = 5\nsplits = list(StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=2019).split(X, y))\npreds_val = []\ny_val = []\n# Then, iteract with each fold\n# If you dont know, enumerate(['a', 'b', 'c']) returns [(0, 'a'), (1, 'b'), (2, 'c')]\nfor idx, (train_idx, val_idx) in enumerate(splits):\n    K.clear_session() # I dont know what it do, but I imagine that it \"clear session\" :)\n    print(\"Beginning fold {}\".format(idx+1))\n    # use the indexes to extract the folds in the train and validation data\n    train_X, train_feat, train_y, val_X, val_feat, val_y = X[train_idx], features[train_idx], y[train_idx], X[val_idx], features[val_idx], y[val_idx]\n    # instantiate the model for this fold\n    model = model_lstm(train_X.shape, features.shape)\n    # This checkpoint helps to avoid overfitting. It just save the weights of the model if it delivered an\n    # validation matthews_correlation greater than the last one.\n    ckpt = ModelCheckpoint('weights_{}.h5'.format(idx), save_best_only=True, save_weights_only=True, verbose=1, monitor='val_matthews_correlation', mode='max')\n    # Train, train, train\n    model.fit([train_X, train_feat], train_y, batch_size=128, epochs=50, validation_data=([val_X, val_feat], val_y), callbacks=[ckpt])\n    # loads the best weights saved by the checkpoint\n    model.load_weights('weights_{}.h5'.format(idx))\n    # Add the predictions of the validation to the list preds_val\n    preds_val.append(model.predict([val_X, val_feat], batch_size=512))\n    # and the val true y\n    y_val.append(val_y)\n\n# concatenates all and prints the shape    \npreds_val = np.concatenate(preds_val)[...,0]\ny_val = np.concatenate(y_val)\npreds_val.shape, y_val.shape\n","execution_count":12,"outputs":[{"output_type":"stream","text":"Beginning fold 1\nTrain on 4788 samples, validate on 1198 samples\nEpoch 1/50\n4788/4788 [==============================] - 5s 989us/step - loss: 0.3383 - matthews_correlation: 0.0345 - val_loss: 0.1725 - val_matthews_correlation: 0.2639\n\nEpoch 00001: val_matthews_correlation improved from -inf to 0.26387, saving model to weights_0.h5\nEpoch 2/50\n4788/4788 [==============================] - 2s 457us/step - loss: 0.1467 - matthews_correlation: 0.7269 - val_loss: 0.1195 - val_matthews_correlation: 0.2872\n\nEpoch 00002: val_matthews_correlation improved from 0.26387 to 0.28719, saving model to weights_0.h5\nEpoch 3/50\n4788/4788 [==============================] - 2s 458us/step - loss: 0.1139 - matthews_correlation: 0.7744 - val_loss: 0.0954 - val_matthews_correlation: 0.3596\n\nEpoch 00003: val_matthews_correlation improved from 0.28719 to 0.35955, saving model to weights_0.h5\nEpoch 4/50\n4788/4788 [==============================] - 2s 461us/step - loss: 0.0847 - matthews_correlation: 0.8052 - val_loss: 0.1534 - val_matthews_correlation: 0.3016\n\nEpoch 00004: val_matthews_correlation did not improve from 0.35955\nEpoch 5/50\n4788/4788 [==============================] - 2s 460us/step - loss: 0.1010 - matthews_correlation: 0.7976 - val_loss: 0.0898 - val_matthews_correlation: 0.3466\n\nEpoch 00005: val_matthews_correlation did not improve from 0.35955\nEpoch 6/50\n4788/4788 [==============================] - 2s 448us/step - loss: 0.0780 - matthews_correlation: 0.8105 - val_loss: 0.0757 - val_matthews_correlation: 0.4707\n\nEpoch 00006: val_matthews_correlation improved from 0.35955 to 0.47067, saving model to weights_0.h5\nEpoch 7/50\n4788/4788 [==============================] - 2s 443us/step - loss: 0.0675 - matthews_correlation: 0.8288 - val_loss: 0.0572 - val_matthews_correlation: 0.4082\n\nEpoch 00007: val_matthews_correlation did not improve from 0.47067\nEpoch 8/50\n4788/4788 [==============================] - 2s 446us/step - loss: 0.0593 - matthews_correlation: 0.8438 - val_loss: 0.0449 - val_matthews_correlation: 0.4658\n\nEpoch 00008: val_matthews_correlation did not improve from 0.47067\nEpoch 9/50\n4788/4788 [==============================] - 2s 449us/step - loss: 0.0713 - matthews_correlation: 0.8482 - val_loss: 0.0578 - val_matthews_correlation: 0.5226\n\nEpoch 00009: val_matthews_correlation improved from 0.47067 to 0.52261, saving model to weights_0.h5\nEpoch 10/50\n4788/4788 [==============================] - 2s 454us/step - loss: 0.0573 - matthews_correlation: 0.8616 - val_loss: 0.0499 - val_matthews_correlation: 0.4258\n\nEpoch 00010: val_matthews_correlation did not improve from 0.52261\nEpoch 11/50\n4788/4788 [==============================] - 2s 458us/step - loss: 0.0556 - matthews_correlation: 0.8827 - val_loss: 0.0448 - val_matthews_correlation: 0.4738\n\nEpoch 00011: val_matthews_correlation did not improve from 0.52261\nEpoch 12/50\n4788/4788 [==============================] - 2s 458us/step - loss: 0.0529 - matthews_correlation: 0.8889 - val_loss: 0.0452 - val_matthews_correlation: 0.4382\n\nEpoch 00012: val_matthews_correlation did not improve from 0.52261\nEpoch 13/50\n4788/4788 [==============================] - 2s 458us/step - loss: 0.0520 - matthews_correlation: 0.8787 - val_loss: 0.0425 - val_matthews_correlation: 0.5438\n\nEpoch 00013: val_matthews_correlation improved from 0.52261 to 0.54379, saving model to weights_0.h5\nEpoch 14/50\n4788/4788 [==============================] - 2s 461us/step - loss: 0.0501 - matthews_correlation: 0.8872 - val_loss: 0.0430 - val_matthews_correlation: 0.5125\n\nEpoch 00014: val_matthews_correlation did not improve from 0.54379\nEpoch 15/50\n4788/4788 [==============================] - 2s 457us/step - loss: 0.0496 - matthews_correlation: 0.8894 - val_loss: 0.0467 - val_matthews_correlation: 0.4956\n\nEpoch 00015: val_matthews_correlation did not improve from 0.54379\nEpoch 16/50\n4788/4788 [==============================] - 2s 458us/step - loss: 0.0500 - matthews_correlation: 0.8854 - val_loss: 0.0383 - val_matthews_correlation: 0.4955\n\nEpoch 00016: val_matthews_correlation did not improve from 0.54379\nEpoch 17/50\n4788/4788 [==============================] - 2s 458us/step - loss: 0.0507 - matthews_correlation: 0.8870 - val_loss: 0.0398 - val_matthews_correlation: 0.4890\n\nEpoch 00017: val_matthews_correlation did not improve from 0.54379\nEpoch 18/50\n4788/4788 [==============================] - 2s 459us/step - loss: 0.0486 - matthews_correlation: 0.8838 - val_loss: 0.0447 - val_matthews_correlation: 0.4636\n\nEpoch 00018: val_matthews_correlation did not improve from 0.54379\nEpoch 19/50\n4788/4788 [==============================] - 2s 457us/step - loss: 0.0495 - matthews_correlation: 0.8747 - val_loss: 0.0409 - val_matthews_correlation: 0.4972\n\nEpoch 00019: val_matthews_correlation did not improve from 0.54379\nEpoch 20/50\n4788/4788 [==============================] - 2s 458us/step - loss: 0.0481 - matthews_correlation: 0.8774 - val_loss: 0.0460 - val_matthews_correlation: 0.5039\n\nEpoch 00020: val_matthews_correlation did not improve from 0.54379\nEpoch 21/50\n4788/4788 [==============================] - 2s 459us/step - loss: 0.0482 - matthews_correlation: 0.8950 - val_loss: 0.0389 - val_matthews_correlation: 0.5088\n\nEpoch 00021: val_matthews_correlation did not improve from 0.54379\nEpoch 22/50\n4788/4788 [==============================] - 2s 462us/step - loss: 0.0487 - matthews_correlation: 0.8847 - val_loss: 0.0432 - val_matthews_correlation: 0.5062\n\nEpoch 00022: val_matthews_correlation did not improve from 0.54379\nEpoch 23/50\n4788/4788 [==============================] - 2s 457us/step - loss: 0.0469 - matthews_correlation: 0.8810 - val_loss: 0.0404 - val_matthews_correlation: 0.5076\n\nEpoch 00023: val_matthews_correlation did not improve from 0.54379\nEpoch 24/50\n4788/4788 [==============================] - 2s 458us/step - loss: 0.0490 - matthews_correlation: 0.8880 - val_loss: 0.0438 - val_matthews_correlation: 0.4890\n\nEpoch 00024: val_matthews_correlation did not improve from 0.54379\nEpoch 25/50\n4788/4788 [==============================] - 2s 459us/step - loss: 0.0469 - matthews_correlation: 0.8830 - val_loss: 0.0416 - val_matthews_correlation: 0.5125\n\nEpoch 00025: val_matthews_correlation did not improve from 0.54379\nEpoch 26/50\n4788/4788 [==============================] - 2s 459us/step - loss: 0.0464 - matthews_correlation: 0.8861 - val_loss: 0.0416 - val_matthews_correlation: 0.4915\n\nEpoch 00026: val_matthews_correlation did not improve from 0.54379\nEpoch 27/50\n4788/4788 [==============================] - 2s 462us/step - loss: 0.0458 - matthews_correlation: 0.8758 - val_loss: 0.0385 - val_matthews_correlation: 0.5238\n\nEpoch 00027: val_matthews_correlation did not improve from 0.54379\nEpoch 28/50\n4788/4788 [==============================] - 2s 451us/step - loss: 0.0446 - matthews_correlation: 0.8930 - val_loss: 0.0385 - val_matthews_correlation: 0.5033\n\nEpoch 00028: val_matthews_correlation did not improve from 0.54379\nEpoch 29/50\n4788/4788 [==============================] - 2s 448us/step - loss: 0.0445 - matthews_correlation: 0.8973 - val_loss: 0.0412 - val_matthews_correlation: 0.4703\n\nEpoch 00029: val_matthews_correlation did not improve from 0.54379\nEpoch 30/50\n4788/4788 [==============================] - 2s 452us/step - loss: 0.0448 - matthews_correlation: 0.8807 - val_loss: 0.0397 - val_matthews_correlation: 0.5105\n\nEpoch 00030: val_matthews_correlation did not improve from 0.54379\nEpoch 31/50\n4788/4788 [==============================] - 2s 458us/step - loss: 0.0468 - matthews_correlation: 0.8969 - val_loss: 0.0502 - val_matthews_correlation: 0.4737\n\nEpoch 00031: val_matthews_correlation did not improve from 0.54379\nEpoch 32/50\n4788/4788 [==============================] - 2s 458us/step - loss: 0.0556 - matthews_correlation: 0.8767 - val_loss: 0.0441 - val_matthews_correlation: 0.4824\n\nEpoch 00032: val_matthews_correlation did not improve from 0.54379\nEpoch 33/50\n4788/4788 [==============================] - 2s 461us/step - loss: 0.0500 - matthews_correlation: 0.8850 - val_loss: 0.0413 - val_matthews_correlation: 0.5025\n\nEpoch 00033: val_matthews_correlation did not improve from 0.54379\nEpoch 34/50\n","name":"stdout"},{"output_type":"stream","text":"4788/4788 [==============================] - 2s 459us/step - loss: 0.0489 - matthews_correlation: 0.8894 - val_loss: 0.0423 - val_matthews_correlation: 0.5238\n\nEpoch 00034: val_matthews_correlation did not improve from 0.54379\nEpoch 35/50\n4788/4788 [==============================] - 2s 460us/step - loss: 0.0442 - matthews_correlation: 0.8975 - val_loss: 0.0483 - val_matthews_correlation: 0.4779\n\nEpoch 00035: val_matthews_correlation did not improve from 0.54379\nEpoch 36/50\n4788/4788 [==============================] - 2s 461us/step - loss: 0.0481 - matthews_correlation: 0.8807 - val_loss: 0.0460 - val_matthews_correlation: 0.5199\n\nEpoch 00036: val_matthews_correlation did not improve from 0.54379\nEpoch 37/50\n4788/4788 [==============================] - 2s 460us/step - loss: 0.0458 - matthews_correlation: 0.8815 - val_loss: 0.0383 - val_matthews_correlation: 0.5120\n\nEpoch 00037: val_matthews_correlation did not improve from 0.54379\nEpoch 38/50\n4788/4788 [==============================] - 2s 461us/step - loss: 0.0442 - matthews_correlation: 0.8996 - val_loss: 0.0431 - val_matthews_correlation: 0.4891\n\nEpoch 00038: val_matthews_correlation did not improve from 0.54379\nEpoch 39/50\n4788/4788 [==============================] - 2s 460us/step - loss: 0.0444 - matthews_correlation: 0.9022 - val_loss: 0.0451 - val_matthews_correlation: 0.5302\n\nEpoch 00039: val_matthews_correlation did not improve from 0.54379\nEpoch 40/50\n4788/4788 [==============================] - 2s 457us/step - loss: 0.0483 - matthews_correlation: 0.8711 - val_loss: 0.0524 - val_matthews_correlation: 0.4957\n\nEpoch 00040: val_matthews_correlation did not improve from 0.54379\nEpoch 41/50\n4788/4788 [==============================] - 2s 457us/step - loss: 0.0436 - matthews_correlation: 0.9038 - val_loss: 0.0412 - val_matthews_correlation: 0.4964\n\nEpoch 00041: val_matthews_correlation did not improve from 0.54379\nEpoch 42/50\n4788/4788 [==============================] - 2s 451us/step - loss: 0.0430 - matthews_correlation: 0.8957 - val_loss: 0.0401 - val_matthews_correlation: 0.4913\n\nEpoch 00042: val_matthews_correlation did not improve from 0.54379\nEpoch 43/50\n4788/4788 [==============================] - 2s 448us/step - loss: 0.0411 - matthews_correlation: 0.9025 - val_loss: 0.0408 - val_matthews_correlation: 0.5240\n\nEpoch 00043: val_matthews_correlation did not improve from 0.54379\nEpoch 44/50\n4788/4788 [==============================] - 2s 448us/step - loss: 0.0413 - matthews_correlation: 0.8847 - val_loss: 0.0444 - val_matthews_correlation: 0.4878\n\nEpoch 00044: val_matthews_correlation did not improve from 0.54379\nEpoch 45/50\n4788/4788 [==============================] - 2s 446us/step - loss: 0.0408 - matthews_correlation: 0.9032 - val_loss: 0.0440 - val_matthews_correlation: 0.5413\n\nEpoch 00045: val_matthews_correlation did not improve from 0.54379\nEpoch 46/50\n4788/4788 [==============================] - 2s 443us/step - loss: 0.0426 - matthews_correlation: 0.8966 - val_loss: 0.0406 - val_matthews_correlation: 0.5252\n\nEpoch 00046: val_matthews_correlation did not improve from 0.54379\nEpoch 47/50\n4788/4788 [==============================] - 2s 455us/step - loss: 0.0449 - matthews_correlation: 0.8729 - val_loss: 0.0400 - val_matthews_correlation: 0.5071\n\nEpoch 00047: val_matthews_correlation did not improve from 0.54379\nEpoch 48/50\n4788/4788 [==============================] - 2s 459us/step - loss: 0.0445 - matthews_correlation: 0.8863 - val_loss: 0.0409 - val_matthews_correlation: 0.5125\n\nEpoch 00048: val_matthews_correlation did not improve from 0.54379\nEpoch 49/50\n4788/4788 [==============================] - 2s 460us/step - loss: 0.0402 - matthews_correlation: 0.9069 - val_loss: 0.0401 - val_matthews_correlation: 0.5210\n\nEpoch 00049: val_matthews_correlation did not improve from 0.54379\nEpoch 50/50\n4788/4788 [==============================] - 2s 460us/step - loss: 0.0399 - matthews_correlation: 0.9027 - val_loss: 0.0494 - val_matthews_correlation: 0.5074\n\nEpoch 00050: val_matthews_correlation did not improve from 0.54379\nBeginning fold 2\nTrain on 4788 samples, validate on 1198 samples\nEpoch 1/50\n4788/4788 [==============================] - 3s 670us/step - loss: 0.2712 - matthews_correlation: 0.3182 - val_loss: 0.1643 - val_matthews_correlation: 0.3159\n\nEpoch 00001: val_matthews_correlation improved from -inf to 0.31585, saving model to weights_1.h5\nEpoch 2/50\n4788/4788 [==============================] - 2s 459us/step - loss: 0.1452 - matthews_correlation: 0.7608 - val_loss: 0.1563 - val_matthews_correlation: 0.3257\n\nEpoch 00002: val_matthews_correlation improved from 0.31585 to 0.32575, saving model to weights_1.h5\nEpoch 3/50\n4788/4788 [==============================] - 2s 461us/step - loss: 0.1247 - matthews_correlation: 0.7988 - val_loss: 0.1104 - val_matthews_correlation: 0.3514\n\nEpoch 00003: val_matthews_correlation improved from 0.32575 to 0.35142, saving model to weights_1.h5\nEpoch 4/50\n4788/4788 [==============================] - 2s 459us/step - loss: 0.1067 - matthews_correlation: 0.8001 - val_loss: 0.0921 - val_matthews_correlation: 0.3577\n\nEpoch 00004: val_matthews_correlation improved from 0.35142 to 0.35771, saving model to weights_1.h5\nEpoch 5/50\n4788/4788 [==============================] - 2s 460us/step - loss: 0.0776 - matthews_correlation: 0.8115 - val_loss: 0.0686 - val_matthews_correlation: 0.2705\n\nEpoch 00005: val_matthews_correlation did not improve from 0.35771\nEpoch 6/50\n4788/4788 [==============================] - 2s 460us/step - loss: 0.2462 - matthews_correlation: 0.5216 - val_loss: 0.1393 - val_matthews_correlation: 0.3844\n\nEpoch 00006: val_matthews_correlation improved from 0.35771 to 0.38442, saving model to weights_1.h5\nEpoch 7/50\n4788/4788 [==============================] - 2s 458us/step - loss: 0.1075 - matthews_correlation: 0.8053 - val_loss: 0.0810 - val_matthews_correlation: 0.4408\n\nEpoch 00007: val_matthews_correlation improved from 0.38442 to 0.44082, saving model to weights_1.h5\nEpoch 8/50\n4788/4788 [==============================] - 2s 461us/step - loss: 0.0818 - matthews_correlation: 0.8319 - val_loss: 0.0609 - val_matthews_correlation: 0.4419\n\nEpoch 00008: val_matthews_correlation improved from 0.44082 to 0.44189, saving model to weights_1.h5\nEpoch 9/50\n4788/4788 [==============================] - 2s 463us/step - loss: 0.0717 - matthews_correlation: 0.8535 - val_loss: 0.0548 - val_matthews_correlation: 0.4693\n\nEpoch 00009: val_matthews_correlation improved from 0.44189 to 0.46934, saving model to weights_1.h5\nEpoch 10/50\n4788/4788 [==============================] - 2s 461us/step - loss: 0.0654 - matthews_correlation: 0.8712 - val_loss: 0.0486 - val_matthews_correlation: 0.4985\n\nEpoch 00010: val_matthews_correlation improved from 0.46934 to 0.49854, saving model to weights_1.h5\nEpoch 11/50\n4788/4788 [==============================] - 2s 460us/step - loss: 0.0580 - matthews_correlation: 0.8633 - val_loss: 0.0547 - val_matthews_correlation: 0.5239\n\nEpoch 00011: val_matthews_correlation improved from 0.49854 to 0.52387, saving model to weights_1.h5\nEpoch 12/50\n4788/4788 [==============================] - 2s 461us/step - loss: 0.0618 - matthews_correlation: 0.8595 - val_loss: 0.0469 - val_matthews_correlation: 0.5050\n\nEpoch 00012: val_matthews_correlation did not improve from 0.52387\nEpoch 13/50\n4788/4788 [==============================] - 2s 461us/step - loss: 0.0603 - matthews_correlation: 0.8669 - val_loss: 0.0446 - val_matthews_correlation: 0.5163\n\nEpoch 00013: val_matthews_correlation did not improve from 0.52387\nEpoch 14/50\n4788/4788 [==============================] - 2s 462us/step - loss: 0.0546 - matthews_correlation: 0.8736 - val_loss: 0.0443 - val_matthews_correlation: 0.5432\n\nEpoch 00014: val_matthews_correlation improved from 0.52387 to 0.54315, saving model to weights_1.h5\nEpoch 15/50\n4788/4788 [==============================] - 2s 460us/step - loss: 0.0537 - matthews_correlation: 0.8797 - val_loss: 0.0474 - val_matthews_correlation: 0.4813\n\nEpoch 00015: val_matthews_correlation did not improve from 0.54315\nEpoch 16/50\n4788/4788 [==============================] - 2s 459us/step - loss: 0.0528 - matthews_correlation: 0.8871 - val_loss: 0.0467 - val_matthews_correlation: 0.5337\n","name":"stdout"},{"output_type":"stream","text":"\nEpoch 00016: val_matthews_correlation did not improve from 0.54315\nEpoch 17/50\n4788/4788 [==============================] - 2s 462us/step - loss: 0.0513 - matthews_correlation: 0.8822 - val_loss: 0.0456 - val_matthews_correlation: 0.4916\n\nEpoch 00017: val_matthews_correlation did not improve from 0.54315\nEpoch 18/50\n4788/4788 [==============================] - 2s 463us/step - loss: 0.0496 - matthews_correlation: 0.8744 - val_loss: 0.0450 - val_matthews_correlation: 0.5197\n\nEpoch 00018: val_matthews_correlation did not improve from 0.54315\nEpoch 19/50\n4788/4788 [==============================] - 2s 463us/step - loss: 0.0520 - matthews_correlation: 0.8737 - val_loss: 0.0466 - val_matthews_correlation: 0.4889\n\nEpoch 00019: val_matthews_correlation did not improve from 0.54315\nEpoch 20/50\n4788/4788 [==============================] - 2s 463us/step - loss: 0.0477 - matthews_correlation: 0.8906 - val_loss: 0.0467 - val_matthews_correlation: 0.5176\n\nEpoch 00020: val_matthews_correlation did not improve from 0.54315\nEpoch 21/50\n4788/4788 [==============================] - 2s 462us/step - loss: 0.0499 - matthews_correlation: 0.8863 - val_loss: 0.0459 - val_matthews_correlation: 0.5295\n\nEpoch 00021: val_matthews_correlation did not improve from 0.54315\nEpoch 22/50\n4788/4788 [==============================] - 2s 458us/step - loss: 0.0478 - matthews_correlation: 0.8874 - val_loss: 0.0446 - val_matthews_correlation: 0.5137\n\nEpoch 00022: val_matthews_correlation did not improve from 0.54315\nEpoch 23/50\n4788/4788 [==============================] - 2s 461us/step - loss: 0.0477 - matthews_correlation: 0.8943 - val_loss: 0.0464 - val_matthews_correlation: 0.4693\n\nEpoch 00023: val_matthews_correlation did not improve from 0.54315\nEpoch 24/50\n4788/4788 [==============================] - 2s 460us/step - loss: 0.0514 - matthews_correlation: 0.8820 - val_loss: 0.0454 - val_matthews_correlation: 0.4987\n\nEpoch 00024: val_matthews_correlation did not improve from 0.54315\nEpoch 25/50\n4788/4788 [==============================] - 2s 457us/step - loss: 0.0494 - matthews_correlation: 0.8782 - val_loss: 0.0483 - val_matthews_correlation: 0.4965\n\nEpoch 00025: val_matthews_correlation did not improve from 0.54315\nEpoch 26/50\n4788/4788 [==============================] - 2s 459us/step - loss: 0.0464 - matthews_correlation: 0.8963 - val_loss: 0.0571 - val_matthews_correlation: 0.5174\n\nEpoch 00026: val_matthews_correlation did not improve from 0.54315\nEpoch 27/50\n4788/4788 [==============================] - 2s 453us/step - loss: 0.0510 - matthews_correlation: 0.8746 - val_loss: 0.0508 - val_matthews_correlation: 0.5360\n\nEpoch 00027: val_matthews_correlation did not improve from 0.54315\nEpoch 28/50\n4788/4788 [==============================] - 2s 448us/step - loss: 0.0462 - matthews_correlation: 0.9067 - val_loss: 0.0469 - val_matthews_correlation: 0.4751\n\nEpoch 00028: val_matthews_correlation did not improve from 0.54315\nEpoch 29/50\n4788/4788 [==============================] - 2s 447us/step - loss: 0.0507 - matthews_correlation: 0.8780 - val_loss: 0.0470 - val_matthews_correlation: 0.5206\n\nEpoch 00029: val_matthews_correlation did not improve from 0.54315\nEpoch 30/50\n4788/4788 [==============================] - 2s 452us/step - loss: 0.0446 - matthews_correlation: 0.8950 - val_loss: 0.0455 - val_matthews_correlation: 0.5146\n\nEpoch 00030: val_matthews_correlation did not improve from 0.54315\nEpoch 31/50\n4788/4788 [==============================] - 2s 449us/step - loss: 0.0429 - matthews_correlation: 0.8921 - val_loss: 0.0461 - val_matthews_correlation: 0.5081\n\nEpoch 00031: val_matthews_correlation did not improve from 0.54315\nEpoch 32/50\n4788/4788 [==============================] - 2s 461us/step - loss: 0.0488 - matthews_correlation: 0.8843 - val_loss: 0.0473 - val_matthews_correlation: 0.4937\n\nEpoch 00032: val_matthews_correlation did not improve from 0.54315\nEpoch 33/50\n4788/4788 [==============================] - 2s 461us/step - loss: 0.0462 - matthews_correlation: 0.8934 - val_loss: 0.0477 - val_matthews_correlation: 0.5491\n\nEpoch 00033: val_matthews_correlation improved from 0.54315 to 0.54910, saving model to weights_1.h5\nEpoch 34/50\n4788/4788 [==============================] - 2s 461us/step - loss: 0.0456 - matthews_correlation: 0.8931 - val_loss: 0.0460 - val_matthews_correlation: 0.5227\n\nEpoch 00034: val_matthews_correlation did not improve from 0.54910\nEpoch 35/50\n4788/4788 [==============================] - 2s 461us/step - loss: 0.0422 - matthews_correlation: 0.9061 - val_loss: 0.0485 - val_matthews_correlation: 0.5247\n\nEpoch 00035: val_matthews_correlation did not improve from 0.54910\nEpoch 36/50\n4788/4788 [==============================] - 2s 458us/step - loss: 0.0453 - matthews_correlation: 0.8890 - val_loss: 0.0463 - val_matthews_correlation: 0.5127\n\nEpoch 00036: val_matthews_correlation did not improve from 0.54910\nEpoch 37/50\n4788/4788 [==============================] - 2s 459us/step - loss: 0.0451 - matthews_correlation: 0.8944 - val_loss: 0.0549 - val_matthews_correlation: 0.4953\n\nEpoch 00037: val_matthews_correlation did not improve from 0.54910\nEpoch 38/50\n4788/4788 [==============================] - 2s 461us/step - loss: 0.0459 - matthews_correlation: 0.8924 - val_loss: 0.0450 - val_matthews_correlation: 0.5432\n\nEpoch 00038: val_matthews_correlation did not improve from 0.54910\nEpoch 39/50\n4788/4788 [==============================] - 2s 458us/step - loss: 0.0457 - matthews_correlation: 0.8878 - val_loss: 0.0552 - val_matthews_correlation: 0.5088\n\nEpoch 00039: val_matthews_correlation did not improve from 0.54910\nEpoch 40/50\n4788/4788 [==============================] - 2s 458us/step - loss: 0.0438 - matthews_correlation: 0.8958 - val_loss: 0.0469 - val_matthews_correlation: 0.4872\n\nEpoch 00040: val_matthews_correlation did not improve from 0.54910\nEpoch 41/50\n4788/4788 [==============================] - 2s 461us/step - loss: 0.0422 - matthews_correlation: 0.8980 - val_loss: 0.0476 - val_matthews_correlation: 0.5005\n\nEpoch 00041: val_matthews_correlation did not improve from 0.54910\nEpoch 42/50\n4788/4788 [==============================] - 2s 462us/step - loss: 0.0439 - matthews_correlation: 0.8845 - val_loss: 0.0502 - val_matthews_correlation: 0.5332\n\nEpoch 00042: val_matthews_correlation did not improve from 0.54910\nEpoch 43/50\n4788/4788 [==============================] - 2s 460us/step - loss: 0.0446 - matthews_correlation: 0.9107 - val_loss: 0.0502 - val_matthews_correlation: 0.5255\n\nEpoch 00043: val_matthews_correlation did not improve from 0.54910\nEpoch 44/50\n4788/4788 [==============================] - 2s 462us/step - loss: 0.0421 - matthews_correlation: 0.9031 - val_loss: 0.0549 - val_matthews_correlation: 0.5026\n\nEpoch 00044: val_matthews_correlation did not improve from 0.54910\nEpoch 45/50\n4788/4788 [==============================] - 2s 462us/step - loss: 0.0473 - matthews_correlation: 0.8848 - val_loss: 0.0491 - val_matthews_correlation: 0.5247\n\nEpoch 00045: val_matthews_correlation did not improve from 0.54910\nEpoch 46/50\n4788/4788 [==============================] - 2s 464us/step - loss: 0.0453 - matthews_correlation: 0.9062 - val_loss: 0.0464 - val_matthews_correlation: 0.5086\n\nEpoch 00046: val_matthews_correlation did not improve from 0.54910\nEpoch 47/50\n4788/4788 [==============================] - 2s 465us/step - loss: 0.0449 - matthews_correlation: 0.8759 - val_loss: 0.0514 - val_matthews_correlation: 0.4690\n\nEpoch 00047: val_matthews_correlation did not improve from 0.54910\nEpoch 48/50\n4788/4788 [==============================] - 2s 461us/step - loss: 0.0463 - matthews_correlation: 0.8810 - val_loss: 0.0461 - val_matthews_correlation: 0.5402\n\nEpoch 00048: val_matthews_correlation did not improve from 0.54910\nEpoch 49/50\n4788/4788 [==============================] - 2s 462us/step - loss: 0.0405 - matthews_correlation: 0.9026 - val_loss: 0.0482 - val_matthews_correlation: 0.5290\n\nEpoch 00049: val_matthews_correlation did not improve from 0.54910\nEpoch 50/50\n4788/4788 [==============================] - 2s 462us/step - loss: 0.0395 - matthews_correlation: 0.9035 - val_loss: 0.0470 - val_matthews_correlation: 0.5370\n\nEpoch 00050: val_matthews_correlation did not improve from 0.54910\n","name":"stdout"},{"output_type":"stream","text":"Beginning fold 3\nTrain on 4789 samples, validate on 1197 samples\nEpoch 1/50\n4789/4789 [==============================] - 3s 668us/step - loss: 0.3391 - matthews_correlation: 0.0850 - val_loss: 0.2183 - val_matthews_correlation: 0.2348\n\nEpoch 00001: val_matthews_correlation improved from -inf to 0.23477, saving model to weights_2.h5\nEpoch 2/50\n4789/4789 [==============================] - 2s 462us/step - loss: 0.1776 - matthews_correlation: 0.6545 - val_loss: 0.1639 - val_matthews_correlation: 0.2553\n\nEpoch 00002: val_matthews_correlation improved from 0.23477 to 0.25530, saving model to weights_2.h5\nEpoch 3/50\n4789/4789 [==============================] - 2s 460us/step - loss: 0.1244 - matthews_correlation: 0.7909 - val_loss: 0.1176 - val_matthews_correlation: 0.2851\n\nEpoch 00003: val_matthews_correlation improved from 0.25530 to 0.28505, saving model to weights_2.h5\nEpoch 4/50\n4789/4789 [==============================] - 2s 462us/step - loss: 0.0858 - matthews_correlation: 0.8117 - val_loss: 0.0811 - val_matthews_correlation: 0.2778\n\nEpoch 00004: val_matthews_correlation did not improve from 0.28505\nEpoch 5/50\n4789/4789 [==============================] - 2s 459us/step - loss: 0.0906 - matthews_correlation: 0.8162 - val_loss: 0.0881 - val_matthews_correlation: 0.2741\n\nEpoch 00005: val_matthews_correlation did not improve from 0.28505\nEpoch 6/50\n4789/4789 [==============================] - 2s 461us/step - loss: 0.0809 - matthews_correlation: 0.8376 - val_loss: 0.0876 - val_matthews_correlation: 0.3112\n\nEpoch 00006: val_matthews_correlation improved from 0.28505 to 0.31118, saving model to weights_2.h5\nEpoch 7/50\n4789/4789 [==============================] - 2s 460us/step - loss: 0.0881 - matthews_correlation: 0.8046 - val_loss: 0.0838 - val_matthews_correlation: 0.3136\n\nEpoch 00007: val_matthews_correlation improved from 0.31118 to 0.31362, saving model to weights_2.h5\nEpoch 8/50\n4789/4789 [==============================] - 2s 461us/step - loss: 0.0719 - matthews_correlation: 0.8375 - val_loss: 0.0611 - val_matthews_correlation: 0.4358\n\nEpoch 00008: val_matthews_correlation improved from 0.31362 to 0.43581, saving model to weights_2.h5\nEpoch 9/50\n4789/4789 [==============================] - 2s 464us/step - loss: 0.0619 - matthews_correlation: 0.8535 - val_loss: 0.0589 - val_matthews_correlation: 0.4209\n\nEpoch 00009: val_matthews_correlation did not improve from 0.43581\nEpoch 10/50\n4789/4789 [==============================] - 2s 461us/step - loss: 0.0573 - matthews_correlation: 0.8615 - val_loss: 0.0602 - val_matthews_correlation: 0.5062\n\nEpoch 00010: val_matthews_correlation improved from 0.43581 to 0.50625, saving model to weights_2.h5\nEpoch 11/50\n4789/4789 [==============================] - 2s 463us/step - loss: 0.0581 - matthews_correlation: 0.8612 - val_loss: 0.0563 - val_matthews_correlation: 0.4506\n\nEpoch 00011: val_matthews_correlation did not improve from 0.50625\nEpoch 12/50\n4789/4789 [==============================] - 2s 455us/step - loss: 0.0538 - matthews_correlation: 0.8611 - val_loss: 0.0553 - val_matthews_correlation: 0.4772\n\nEpoch 00012: val_matthews_correlation did not improve from 0.50625\nEpoch 13/50\n4789/4789 [==============================] - 2s 451us/step - loss: 0.0501 - matthews_correlation: 0.8779 - val_loss: 0.0565 - val_matthews_correlation: 0.4445\n\nEpoch 00013: val_matthews_correlation did not improve from 0.50625\nEpoch 14/50\n4789/4789 [==============================] - 2s 452us/step - loss: 0.0522 - matthews_correlation: 0.8711 - val_loss: 0.0546 - val_matthews_correlation: 0.5157\n\nEpoch 00014: val_matthews_correlation improved from 0.50625 to 0.51571, saving model to weights_2.h5\nEpoch 15/50\n4789/4789 [==============================] - 2s 452us/step - loss: 0.0548 - matthews_correlation: 0.8574 - val_loss: 0.0527 - val_matthews_correlation: 0.5300\n\nEpoch 00015: val_matthews_correlation improved from 0.51571 to 0.53004, saving model to weights_2.h5\nEpoch 16/50\n4789/4789 [==============================] - 2s 451us/step - loss: 0.0508 - matthews_correlation: 0.8740 - val_loss: 0.0629 - val_matthews_correlation: 0.5029\n\nEpoch 00016: val_matthews_correlation did not improve from 0.53004\nEpoch 17/50\n4789/4789 [==============================] - 2s 458us/step - loss: 0.0504 - matthews_correlation: 0.8797 - val_loss: 0.0556 - val_matthews_correlation: 0.4899\n\nEpoch 00017: val_matthews_correlation did not improve from 0.53004\nEpoch 18/50\n4789/4789 [==============================] - 2s 459us/step - loss: 0.0493 - matthews_correlation: 0.8858 - val_loss: 0.0591 - val_matthews_correlation: 0.4461\n\nEpoch 00018: val_matthews_correlation did not improve from 0.53004\nEpoch 19/50\n4789/4789 [==============================] - 2s 462us/step - loss: 0.0488 - matthews_correlation: 0.8905 - val_loss: 0.0547 - val_matthews_correlation: 0.5325\n\nEpoch 00019: val_matthews_correlation improved from 0.53004 to 0.53246, saving model to weights_2.h5\nEpoch 20/50\n4789/4789 [==============================] - 2s 461us/step - loss: 0.0472 - matthews_correlation: 0.8842 - val_loss: 0.0516 - val_matthews_correlation: 0.5075\n\nEpoch 00020: val_matthews_correlation did not improve from 0.53246\nEpoch 21/50\n4789/4789 [==============================] - 2s 461us/step - loss: 0.0466 - matthews_correlation: 0.8866 - val_loss: 0.0528 - val_matthews_correlation: 0.4995\n\nEpoch 00021: val_matthews_correlation did not improve from 0.53246\nEpoch 22/50\n4789/4789 [==============================] - 2s 465us/step - loss: 0.0447 - matthews_correlation: 0.8902 - val_loss: 0.0540 - val_matthews_correlation: 0.5011\n\nEpoch 00022: val_matthews_correlation did not improve from 0.53246\nEpoch 23/50\n4789/4789 [==============================] - 2s 462us/step - loss: 0.0457 - matthews_correlation: 0.9016 - val_loss: 0.0550 - val_matthews_correlation: 0.5027\n\nEpoch 00023: val_matthews_correlation did not improve from 0.53246\nEpoch 24/50\n4789/4789 [==============================] - 2s 463us/step - loss: 0.0458 - matthews_correlation: 0.8838 - val_loss: 0.0522 - val_matthews_correlation: 0.5065\n\nEpoch 00024: val_matthews_correlation did not improve from 0.53246\nEpoch 25/50\n4789/4789 [==============================] - 2s 464us/step - loss: 0.0747 - matthews_correlation: 0.7775 - val_loss: 0.0973 - val_matthews_correlation: 0.4902\n\nEpoch 00025: val_matthews_correlation did not improve from 0.53246\nEpoch 26/50\n4789/4789 [==============================] - 2s 465us/step - loss: 0.0603 - matthews_correlation: 0.8597 - val_loss: 0.0584 - val_matthews_correlation: 0.4831\n\nEpoch 00026: val_matthews_correlation did not improve from 0.53246\nEpoch 27/50\n4789/4789 [==============================] - 2s 464us/step - loss: 0.0496 - matthews_correlation: 0.8738 - val_loss: 0.0558 - val_matthews_correlation: 0.5050\n\nEpoch 00027: val_matthews_correlation did not improve from 0.53246\nEpoch 28/50\n4789/4789 [==============================] - 2s 464us/step - loss: 0.0485 - matthews_correlation: 0.8840 - val_loss: 0.0529 - val_matthews_correlation: 0.5023\n\nEpoch 00028: val_matthews_correlation did not improve from 0.53246\nEpoch 29/50\n4789/4789 [==============================] - 2s 461us/step - loss: 0.0441 - matthews_correlation: 0.8930 - val_loss: 0.0555 - val_matthews_correlation: 0.5130\n\nEpoch 00029: val_matthews_correlation did not improve from 0.53246\nEpoch 30/50\n4789/4789 [==============================] - 2s 461us/step - loss: 0.0459 - matthews_correlation: 0.8852 - val_loss: 0.0537 - val_matthews_correlation: 0.4895\n\nEpoch 00030: val_matthews_correlation did not improve from 0.53246\nEpoch 31/50\n4789/4789 [==============================] - 2s 464us/step - loss: 0.0432 - matthews_correlation: 0.8920 - val_loss: 0.0538 - val_matthews_correlation: 0.4888\n\nEpoch 00031: val_matthews_correlation did not improve from 0.53246\nEpoch 32/50\n4789/4789 [==============================] - 2s 462us/step - loss: 0.0421 - matthews_correlation: 0.9040 - val_loss: 0.0517 - val_matthews_correlation: 0.5433\n\nEpoch 00032: val_matthews_correlation improved from 0.53246 to 0.54325, saving model to weights_2.h5\nEpoch 33/50\n4789/4789 [==============================] - 2s 459us/step - loss: 0.0430 - matthews_correlation: 0.8934 - val_loss: 0.0564 - val_matthews_correlation: 0.5023\n","name":"stdout"},{"output_type":"stream","text":"\nEpoch 00033: val_matthews_correlation did not improve from 0.54325\nEpoch 34/50\n4789/4789 [==============================] - 2s 463us/step - loss: 0.0402 - matthews_correlation: 0.8902 - val_loss: 0.0539 - val_matthews_correlation: 0.5006\n\nEpoch 00034: val_matthews_correlation did not improve from 0.54325\nEpoch 35/50\n4789/4789 [==============================] - 2s 462us/step - loss: 0.0408 - matthews_correlation: 0.9083 - val_loss: 0.0614 - val_matthews_correlation: 0.5149\n\nEpoch 00035: val_matthews_correlation did not improve from 0.54325\nEpoch 36/50\n4789/4789 [==============================] - 2s 463us/step - loss: 0.0432 - matthews_correlation: 0.8910 - val_loss: 0.0681 - val_matthews_correlation: 0.5056\n\nEpoch 00036: val_matthews_correlation did not improve from 0.54325\nEpoch 37/50\n4789/4789 [==============================] - 2s 459us/step - loss: 0.0430 - matthews_correlation: 0.8871 - val_loss: 0.0663 - val_matthews_correlation: 0.5212\n\nEpoch 00037: val_matthews_correlation did not improve from 0.54325\nEpoch 38/50\n4789/4789 [==============================] - 2s 462us/step - loss: 0.0457 - matthews_correlation: 0.8916 - val_loss: 0.0539 - val_matthews_correlation: 0.5417\n\nEpoch 00038: val_matthews_correlation did not improve from 0.54325\nEpoch 39/50\n4789/4789 [==============================] - 2s 461us/step - loss: 0.0404 - matthews_correlation: 0.9057 - val_loss: 0.0559 - val_matthews_correlation: 0.5325\n\nEpoch 00039: val_matthews_correlation did not improve from 0.54325\nEpoch 40/50\n4789/4789 [==============================] - 2s 464us/step - loss: 0.0387 - matthews_correlation: 0.9013 - val_loss: 0.0637 - val_matthews_correlation: 0.5255\n\nEpoch 00040: val_matthews_correlation did not improve from 0.54325\nEpoch 41/50\n4789/4789 [==============================] - 2s 464us/step - loss: 0.0404 - matthews_correlation: 0.9006 - val_loss: 0.0745 - val_matthews_correlation: 0.4228\n\nEpoch 00041: val_matthews_correlation did not improve from 0.54325\nEpoch 42/50\n4789/4789 [==============================] - 2s 463us/step - loss: 0.0409 - matthews_correlation: 0.9023 - val_loss: 0.0534 - val_matthews_correlation: 0.5384\n\nEpoch 00042: val_matthews_correlation did not improve from 0.54325\nEpoch 43/50\n4789/4789 [==============================] - 2s 463us/step - loss: 0.0384 - matthews_correlation: 0.9018 - val_loss: 0.0556 - val_matthews_correlation: 0.5015\n\nEpoch 00043: val_matthews_correlation did not improve from 0.54325\nEpoch 44/50\n4789/4789 [==============================] - 2s 465us/step - loss: 0.0383 - matthews_correlation: 0.9011 - val_loss: 0.0737 - val_matthews_correlation: 0.5089\n\nEpoch 00044: val_matthews_correlation did not improve from 0.54325\nEpoch 45/50\n4789/4789 [==============================] - 2s 462us/step - loss: 0.0390 - matthews_correlation: 0.9003 - val_loss: 0.0533 - val_matthews_correlation: 0.5104\n\nEpoch 00045: val_matthews_correlation did not improve from 0.54325\nEpoch 46/50\n4789/4789 [==============================] - 2s 460us/step - loss: 0.0372 - matthews_correlation: 0.8968 - val_loss: 0.0549 - val_matthews_correlation: 0.5056\n\nEpoch 00046: val_matthews_correlation did not improve from 0.54325\nEpoch 47/50\n4789/4789 [==============================] - 2s 460us/step - loss: 0.0372 - matthews_correlation: 0.9140 - val_loss: 0.0584 - val_matthews_correlation: 0.5405\n\nEpoch 00047: val_matthews_correlation did not improve from 0.54325\nEpoch 48/50\n4789/4789 [==============================] - 2s 458us/step - loss: 0.0363 - matthews_correlation: 0.9096 - val_loss: 0.0582 - val_matthews_correlation: 0.5104\n\nEpoch 00048: val_matthews_correlation did not improve from 0.54325\nEpoch 49/50\n4789/4789 [==============================] - 2s 450us/step - loss: 0.0362 - matthews_correlation: 0.9139 - val_loss: 0.0548 - val_matthews_correlation: 0.5121\n\nEpoch 00049: val_matthews_correlation did not improve from 0.54325\nEpoch 50/50\n4789/4789 [==============================] - 2s 449us/step - loss: 0.0365 - matthews_correlation: 0.9181 - val_loss: 0.0570 - val_matthews_correlation: 0.5210\n\nEpoch 00050: val_matthews_correlation did not improve from 0.54325\nBeginning fold 4\nTrain on 4789 samples, validate on 1197 samples\nEpoch 1/50\n4789/4789 [==============================] - 3s 686us/step - loss: 0.3749 - matthews_correlation: 7.3249e-04 - val_loss: 0.2328 - val_matthews_correlation: -0.0025\n\nEpoch 00001: val_matthews_correlation improved from -inf to -0.00245, saving model to weights_3.h5\nEpoch 2/50\n4789/4789 [==============================] - 2s 460us/step - loss: 0.1607 - matthews_correlation: 0.6744 - val_loss: 0.1429 - val_matthews_correlation: 0.2680\n\nEpoch 00002: val_matthews_correlation improved from -0.00245 to 0.26802, saving model to weights_3.h5\nEpoch 3/50\n4789/4789 [==============================] - 2s 458us/step - loss: 0.1372 - matthews_correlation: 0.7468 - val_loss: 0.1017 - val_matthews_correlation: 0.3050\n\nEpoch 00003: val_matthews_correlation improved from 0.26802 to 0.30502, saving model to weights_3.h5\nEpoch 4/50\n4789/4789 [==============================] - 2s 459us/step - loss: 0.0998 - matthews_correlation: 0.8189 - val_loss: 0.0838 - val_matthews_correlation: 0.3391\n\nEpoch 00004: val_matthews_correlation improved from 0.30502 to 0.33912, saving model to weights_3.h5\nEpoch 5/50\n4789/4789 [==============================] - 2s 459us/step - loss: 0.0815 - matthews_correlation: 0.8177 - val_loss: 0.0708 - val_matthews_correlation: 0.3619\n\nEpoch 00005: val_matthews_correlation improved from 0.33912 to 0.36186, saving model to weights_3.h5\nEpoch 6/50\n4789/4789 [==============================] - 2s 456us/step - loss: 0.0840 - matthews_correlation: 0.8220 - val_loss: 0.0617 - val_matthews_correlation: 0.3686\n\nEpoch 00006: val_matthews_correlation improved from 0.36186 to 0.36861, saving model to weights_3.h5\nEpoch 7/50\n4789/4789 [==============================] - 2s 460us/step - loss: 0.0585 - matthews_correlation: 0.8531 - val_loss: 0.0613 - val_matthews_correlation: 0.3877\n\nEpoch 00007: val_matthews_correlation improved from 0.36861 to 0.38773, saving model to weights_3.h5\nEpoch 8/50\n4789/4789 [==============================] - 2s 463us/step - loss: 0.0542 - matthews_correlation: 0.8678 - val_loss: 0.0569 - val_matthews_correlation: 0.4345\n\nEpoch 00008: val_matthews_correlation improved from 0.38773 to 0.43447, saving model to weights_3.h5\nEpoch 9/50\n4789/4789 [==============================] - 2s 461us/step - loss: 0.0512 - matthews_correlation: 0.8743 - val_loss: 0.0609 - val_matthews_correlation: 0.4315\n\nEpoch 00009: val_matthews_correlation did not improve from 0.43447\nEpoch 10/50\n4789/4789 [==============================] - 2s 463us/step - loss: 0.0524 - matthews_correlation: 0.8801 - val_loss: 0.0559 - val_matthews_correlation: 0.4336\n\nEpoch 00010: val_matthews_correlation did not improve from 0.43447\nEpoch 11/50\n4789/4789 [==============================] - 2s 462us/step - loss: 0.0496 - matthews_correlation: 0.8921 - val_loss: 0.0550 - val_matthews_correlation: 0.4287\n\nEpoch 00011: val_matthews_correlation did not improve from 0.43447\nEpoch 12/50\n4789/4789 [==============================] - 2s 461us/step - loss: 0.0471 - matthews_correlation: 0.8815 - val_loss: 0.0633 - val_matthews_correlation: 0.4508\n\nEpoch 00012: val_matthews_correlation improved from 0.43447 to 0.45080, saving model to weights_3.h5\nEpoch 13/50\n4789/4789 [==============================] - 2s 448us/step - loss: 0.0484 - matthews_correlation: 0.9006 - val_loss: 0.0585 - val_matthews_correlation: 0.4204\n\nEpoch 00013: val_matthews_correlation did not improve from 0.45080\nEpoch 14/50\n4789/4789 [==============================] - 2s 455us/step - loss: 0.0481 - matthews_correlation: 0.8851 - val_loss: 0.0563 - val_matthews_correlation: 0.4469\n\nEpoch 00014: val_matthews_correlation did not improve from 0.45080\nEpoch 15/50\n4789/4789 [==============================] - 2s 461us/step - loss: 0.0473 - matthews_correlation: 0.8976 - val_loss: 0.0598 - val_matthews_correlation: 0.4531\n\nEpoch 00015: val_matthews_correlation improved from 0.45080 to 0.45306, saving model to weights_3.h5\nEpoch 16/50\n","name":"stdout"},{"output_type":"stream","text":"4789/4789 [==============================] - 2s 460us/step - loss: 0.0505 - matthews_correlation: 0.8757 - val_loss: 0.0556 - val_matthews_correlation: 0.4213\n\nEpoch 00016: val_matthews_correlation did not improve from 0.45306\nEpoch 17/50\n4789/4789 [==============================] - 2s 459us/step - loss: 0.0436 - matthews_correlation: 0.9024 - val_loss: 0.0561 - val_matthews_correlation: 0.4505\n\nEpoch 00017: val_matthews_correlation did not improve from 0.45306\nEpoch 18/50\n4789/4789 [==============================] - 2s 462us/step - loss: 0.0435 - matthews_correlation: 0.9010 - val_loss: 0.0598 - val_matthews_correlation: 0.4109\n\nEpoch 00018: val_matthews_correlation did not improve from 0.45306\nEpoch 19/50\n4789/4789 [==============================] - 2s 459us/step - loss: 0.0422 - matthews_correlation: 0.8997 - val_loss: 0.0552 - val_matthews_correlation: 0.4187\n\nEpoch 00019: val_matthews_correlation did not improve from 0.45306\nEpoch 20/50\n4789/4789 [==============================] - 2s 461us/step - loss: 0.0463 - matthews_correlation: 0.8842 - val_loss: 0.0563 - val_matthews_correlation: 0.4586\n\nEpoch 00020: val_matthews_correlation improved from 0.45306 to 0.45864, saving model to weights_3.h5\nEpoch 21/50\n4789/4789 [==============================] - 2s 461us/step - loss: 0.0426 - matthews_correlation: 0.8819 - val_loss: 0.0575 - val_matthews_correlation: 0.4244\n\nEpoch 00021: val_matthews_correlation did not improve from 0.45864\nEpoch 22/50\n4789/4789 [==============================] - 2s 460us/step - loss: 0.0431 - matthews_correlation: 0.9015 - val_loss: 0.0586 - val_matthews_correlation: 0.4486\n\nEpoch 00022: val_matthews_correlation did not improve from 0.45864\nEpoch 23/50\n4789/4789 [==============================] - 2s 460us/step - loss: 0.0423 - matthews_correlation: 0.9078 - val_loss: 0.0531 - val_matthews_correlation: 0.4447\n\nEpoch 00023: val_matthews_correlation did not improve from 0.45864\nEpoch 24/50\n4789/4789 [==============================] - 2s 460us/step - loss: 0.0436 - matthews_correlation: 0.8924 - val_loss: 0.0587 - val_matthews_correlation: 0.4292\n\nEpoch 00024: val_matthews_correlation did not improve from 0.45864\nEpoch 25/50\n4789/4789 [==============================] - 2s 463us/step - loss: 0.0439 - matthews_correlation: 0.8990 - val_loss: 0.0538 - val_matthews_correlation: 0.4468\n\nEpoch 00025: val_matthews_correlation did not improve from 0.45864\nEpoch 26/50\n4789/4789 [==============================] - 2s 461us/step - loss: 0.0400 - matthews_correlation: 0.8946 - val_loss: 0.0559 - val_matthews_correlation: 0.4406\n\nEpoch 00026: val_matthews_correlation did not improve from 0.45864\nEpoch 27/50\n4789/4789 [==============================] - 2s 460us/step - loss: 0.0393 - matthews_correlation: 0.9000 - val_loss: 0.0561 - val_matthews_correlation: 0.4370\n\nEpoch 00027: val_matthews_correlation did not improve from 0.45864\nEpoch 28/50\n4789/4789 [==============================] - 2s 463us/step - loss: 0.0468 - matthews_correlation: 0.8908 - val_loss: 0.0640 - val_matthews_correlation: 0.3732\n\nEpoch 00028: val_matthews_correlation did not improve from 0.45864\nEpoch 29/50\n4789/4789 [==============================] - 2s 462us/step - loss: 0.0456 - matthews_correlation: 0.8901 - val_loss: 0.0620 - val_matthews_correlation: 0.4348\n\nEpoch 00029: val_matthews_correlation did not improve from 0.45864\nEpoch 30/50\n4789/4789 [==============================] - 2s 462us/step - loss: 0.0499 - matthews_correlation: 0.8814 - val_loss: 0.0541 - val_matthews_correlation: 0.3985\n\nEpoch 00030: val_matthews_correlation did not improve from 0.45864\nEpoch 31/50\n4789/4789 [==============================] - 2s 459us/step - loss: 0.0399 - matthews_correlation: 0.9109 - val_loss: 0.0571 - val_matthews_correlation: 0.4487\n\nEpoch 00031: val_matthews_correlation did not improve from 0.45864\nEpoch 32/50\n4789/4789 [==============================] - 2s 461us/step - loss: 0.0389 - matthews_correlation: 0.9104 - val_loss: 0.0539 - val_matthews_correlation: 0.4379\n\nEpoch 00032: val_matthews_correlation did not improve from 0.45864\nEpoch 33/50\n4789/4789 [==============================] - 2s 455us/step - loss: 0.0379 - matthews_correlation: 0.9105 - val_loss: 0.0561 - val_matthews_correlation: 0.4515\n\nEpoch 00033: val_matthews_correlation did not improve from 0.45864\nEpoch 34/50\n4789/4789 [==============================] - 2s 447us/step - loss: 0.0366 - matthews_correlation: 0.9150 - val_loss: 0.0606 - val_matthews_correlation: 0.4637\n\nEpoch 00034: val_matthews_correlation improved from 0.45864 to 0.46368, saving model to weights_3.h5\nEpoch 35/50\n4789/4789 [==============================] - 2s 451us/step - loss: 0.0399 - matthews_correlation: 0.9070 - val_loss: 0.0530 - val_matthews_correlation: 0.4428\n\nEpoch 00035: val_matthews_correlation did not improve from 0.46368\nEpoch 36/50\n4789/4789 [==============================] - 2s 451us/step - loss: 0.0392 - matthews_correlation: 0.9080 - val_loss: 0.0554 - val_matthews_correlation: 0.4542\n\nEpoch 00036: val_matthews_correlation did not improve from 0.46368\nEpoch 37/50\n4789/4789 [==============================] - 2s 449us/step - loss: 0.0368 - matthews_correlation: 0.9113 - val_loss: 0.0599 - val_matthews_correlation: 0.4812\n\nEpoch 00037: val_matthews_correlation improved from 0.46368 to 0.48117, saving model to weights_3.h5\nEpoch 38/50\n4789/4789 [==============================] - 2s 460us/step - loss: 0.0369 - matthews_correlation: 0.9153 - val_loss: 0.0625 - val_matthews_correlation: 0.4610\n\nEpoch 00038: val_matthews_correlation did not improve from 0.48117\nEpoch 39/50\n4789/4789 [==============================] - 2s 464us/step - loss: 0.0364 - matthews_correlation: 0.9120 - val_loss: 0.0570 - val_matthews_correlation: 0.4553\n\nEpoch 00039: val_matthews_correlation did not improve from 0.48117\nEpoch 40/50\n4789/4789 [==============================] - 2s 461us/step - loss: 0.0376 - matthews_correlation: 0.9209 - val_loss: 0.0550 - val_matthews_correlation: 0.4508\n\nEpoch 00040: val_matthews_correlation did not improve from 0.48117\nEpoch 41/50\n4789/4789 [==============================] - 2s 460us/step - loss: 0.0373 - matthews_correlation: 0.9197 - val_loss: 0.0573 - val_matthews_correlation: 0.4367\n\nEpoch 00041: val_matthews_correlation did not improve from 0.48117\nEpoch 42/50\n4789/4789 [==============================] - 2s 467us/step - loss: 0.0373 - matthews_correlation: 0.9148 - val_loss: 0.0546 - val_matthews_correlation: 0.4385\n\nEpoch 00042: val_matthews_correlation did not improve from 0.48117\nEpoch 43/50\n4789/4789 [==============================] - 2s 462us/step - loss: 0.0349 - matthews_correlation: 0.9146 - val_loss: 0.0573 - val_matthews_correlation: 0.4326\n\nEpoch 00043: val_matthews_correlation did not improve from 0.48117\nEpoch 44/50\n4789/4789 [==============================] - 2s 463us/step - loss: 0.0321 - matthews_correlation: 0.9272 - val_loss: 0.0571 - val_matthews_correlation: 0.4441\n\nEpoch 00044: val_matthews_correlation did not improve from 0.48117\nEpoch 45/50\n4789/4789 [==============================] - 2s 461us/step - loss: 0.0369 - matthews_correlation: 0.9215 - val_loss: 0.0627 - val_matthews_correlation: 0.4756\n\nEpoch 00045: val_matthews_correlation did not improve from 0.48117\nEpoch 46/50\n4789/4789 [==============================] - 2s 459us/step - loss: 0.0362 - matthews_correlation: 0.9235 - val_loss: 0.0600 - val_matthews_correlation: 0.4601\n\nEpoch 00046: val_matthews_correlation did not improve from 0.48117\nEpoch 47/50\n4789/4789 [==============================] - 2s 459us/step - loss: 0.0347 - matthews_correlation: 0.9215 - val_loss: 0.0661 - val_matthews_correlation: 0.4273\n\nEpoch 00047: val_matthews_correlation did not improve from 0.48117\nEpoch 48/50\n4789/4789 [==============================] - 2s 459us/step - loss: 0.0341 - matthews_correlation: 0.9136 - val_loss: 0.0649 - val_matthews_correlation: 0.4037\n\nEpoch 00048: val_matthews_correlation did not improve from 0.48117\nEpoch 49/50\n4789/4789 [==============================] - 2s 459us/step - loss: 0.0378 - matthews_correlation: 0.9068 - val_loss: 0.0576 - val_matthews_correlation: 0.4441\n\nEpoch 00049: val_matthews_correlation did not improve from 0.48117\nEpoch 50/50\n","name":"stdout"},{"output_type":"stream","text":"4789/4789 [==============================] - 2s 460us/step - loss: 0.0332 - matthews_correlation: 0.9247 - val_loss: 0.0606 - val_matthews_correlation: 0.4280\n\nEpoch 00050: val_matthews_correlation did not improve from 0.48117\nBeginning fold 5\nTrain on 4790 samples, validate on 1196 samples\nEpoch 1/50\n4790/4790 [==============================] - 3s 709us/step - loss: 0.3232 - matthews_correlation: 0.1001 - val_loss: 0.2105 - val_matthews_correlation: 0.2005\n\nEpoch 00001: val_matthews_correlation improved from -inf to 0.20053, saving model to weights_4.h5\nEpoch 2/50\n4790/4790 [==============================] - 2s 459us/step - loss: 0.1775 - matthews_correlation: 0.5392 - val_loss: 0.1163 - val_matthews_correlation: 0.3114\n\nEpoch 00002: val_matthews_correlation improved from 0.20053 to 0.31145, saving model to weights_4.h5\nEpoch 3/50\n4790/4790 [==============================] - 2s 457us/step - loss: 0.1200 - matthews_correlation: 0.7875 - val_loss: 0.1053 - val_matthews_correlation: 0.2768\n\nEpoch 00003: val_matthews_correlation did not improve from 0.31145\nEpoch 4/50\n4790/4790 [==============================] - 2s 458us/step - loss: 0.0900 - matthews_correlation: 0.8078 - val_loss: 0.0761 - val_matthews_correlation: 0.3265\n\nEpoch 00004: val_matthews_correlation improved from 0.31145 to 0.32654, saving model to weights_4.h5\nEpoch 5/50\n4790/4790 [==============================] - 2s 460us/step - loss: 0.0643 - matthews_correlation: 0.8456 - val_loss: 0.0985 - val_matthews_correlation: 0.2902\n\nEpoch 00005: val_matthews_correlation did not improve from 0.32654\nEpoch 6/50\n4790/4790 [==============================] - 2s 457us/step - loss: 0.0603 - matthews_correlation: 0.8568 - val_loss: 0.0690 - val_matthews_correlation: 0.3484\n\nEpoch 00006: val_matthews_correlation improved from 0.32654 to 0.34840, saving model to weights_4.h5\nEpoch 7/50\n4790/4790 [==============================] - 2s 457us/step - loss: 0.0625 - matthews_correlation: 0.8590 - val_loss: 0.0655 - val_matthews_correlation: 0.3193\n\nEpoch 00007: val_matthews_correlation did not improve from 0.34840\nEpoch 8/50\n4790/4790 [==============================] - 2s 454us/step - loss: 0.0663 - matthews_correlation: 0.8587 - val_loss: 0.0628 - val_matthews_correlation: 0.3293\n\nEpoch 00008: val_matthews_correlation did not improve from 0.34840\nEpoch 9/50\n4790/4790 [==============================] - 2s 454us/step - loss: 0.0526 - matthews_correlation: 0.8874 - val_loss: 0.0664 - val_matthews_correlation: 0.3433\n\nEpoch 00009: val_matthews_correlation did not improve from 0.34840\nEpoch 10/50\n4790/4790 [==============================] - 2s 456us/step - loss: 0.0516 - matthews_correlation: 0.8736 - val_loss: 0.0711 - val_matthews_correlation: 0.3873\n\nEpoch 00010: val_matthews_correlation improved from 0.34840 to 0.38733, saving model to weights_4.h5\nEpoch 11/50\n4790/4790 [==============================] - 2s 456us/step - loss: 0.0503 - matthews_correlation: 0.8860 - val_loss: 0.0628 - val_matthews_correlation: 0.3861\n\nEpoch 00011: val_matthews_correlation did not improve from 0.38733\nEpoch 12/50\n4790/4790 [==============================] - 2s 457us/step - loss: 0.0481 - matthews_correlation: 0.8775 - val_loss: 0.0618 - val_matthews_correlation: 0.3355\n\nEpoch 00012: val_matthews_correlation did not improve from 0.38733\nEpoch 13/50\n4790/4790 [==============================] - 2s 459us/step - loss: 0.0473 - matthews_correlation: 0.8839 - val_loss: 0.0590 - val_matthews_correlation: 0.3267\n\nEpoch 00013: val_matthews_correlation did not improve from 0.38733\nEpoch 14/50\n4790/4790 [==============================] - 2s 455us/step - loss: 0.0457 - matthews_correlation: 0.8906 - val_loss: 0.0577 - val_matthews_correlation: 0.3542\n\nEpoch 00014: val_matthews_correlation did not improve from 0.38733\nEpoch 15/50\n4790/4790 [==============================] - 2s 456us/step - loss: 0.0453 - matthews_correlation: 0.8894 - val_loss: 0.0619 - val_matthews_correlation: 0.3633\n\nEpoch 00015: val_matthews_correlation did not improve from 0.38733\nEpoch 16/50\n4790/4790 [==============================] - 2s 457us/step - loss: 0.0468 - matthews_correlation: 0.8867 - val_loss: 0.0592 - val_matthews_correlation: 0.3324\n\nEpoch 00016: val_matthews_correlation did not improve from 0.38733\nEpoch 17/50\n4790/4790 [==============================] - 2s 459us/step - loss: 0.0456 - matthews_correlation: 0.8879 - val_loss: 0.0673 - val_matthews_correlation: 0.3356\n\nEpoch 00017: val_matthews_correlation did not improve from 0.38733\nEpoch 18/50\n4790/4790 [==============================] - 2s 450us/step - loss: 0.0462 - matthews_correlation: 0.8839 - val_loss: 0.0579 - val_matthews_correlation: 0.3865\n\nEpoch 00018: val_matthews_correlation did not improve from 0.38733\nEpoch 19/50\n4790/4790 [==============================] - 2s 445us/step - loss: 0.0489 - matthews_correlation: 0.8881 - val_loss: 0.0586 - val_matthews_correlation: 0.3516\n\nEpoch 00019: val_matthews_correlation did not improve from 0.38733\nEpoch 20/50\n4790/4790 [==============================] - 2s 444us/step - loss: 0.0506 - matthews_correlation: 0.8842 - val_loss: 0.0589 - val_matthews_correlation: 0.3290\n\nEpoch 00020: val_matthews_correlation did not improve from 0.38733\nEpoch 21/50\n4790/4790 [==============================] - 2s 445us/step - loss: 0.0442 - matthews_correlation: 0.9027 - val_loss: 0.0563 - val_matthews_correlation: 0.3584\n\nEpoch 00021: val_matthews_correlation did not improve from 0.38733\nEpoch 22/50\n4790/4790 [==============================] - 2s 443us/step - loss: 0.0436 - matthews_correlation: 0.8923 - val_loss: 0.0624 - val_matthews_correlation: 0.2910\n\nEpoch 00022: val_matthews_correlation did not improve from 0.38733\nEpoch 23/50\n4790/4790 [==============================] - 2s 457us/step - loss: 0.0442 - matthews_correlation: 0.9053 - val_loss: 0.0551 - val_matthews_correlation: 0.3767\n\nEpoch 00023: val_matthews_correlation did not improve from 0.38733\nEpoch 24/50\n4790/4790 [==============================] - 2s 458us/step - loss: 0.0451 - matthews_correlation: 0.8884 - val_loss: 0.0571 - val_matthews_correlation: 0.3065\n\nEpoch 00024: val_matthews_correlation did not improve from 0.38733\nEpoch 25/50\n4790/4790 [==============================] - 2s 459us/step - loss: 0.0425 - matthews_correlation: 0.8993 - val_loss: 0.0641 - val_matthews_correlation: 0.3429\n\nEpoch 00025: val_matthews_correlation did not improve from 0.38733\nEpoch 26/50\n4790/4790 [==============================] - 2s 459us/step - loss: 0.0418 - matthews_correlation: 0.9076 - val_loss: 0.0561 - val_matthews_correlation: 0.3403\n\nEpoch 00026: val_matthews_correlation did not improve from 0.38733\nEpoch 27/50\n4790/4790 [==============================] - 2s 460us/step - loss: 0.0442 - matthews_correlation: 0.9043 - val_loss: 0.0749 - val_matthews_correlation: 0.3079\n\nEpoch 00027: val_matthews_correlation did not improve from 0.38733\nEpoch 28/50\n4790/4790 [==============================] - 2s 459us/step - loss: 0.0437 - matthews_correlation: 0.9009 - val_loss: 0.0591 - val_matthews_correlation: 0.3009\n\nEpoch 00028: val_matthews_correlation did not improve from 0.38733\nEpoch 29/50\n4790/4790 [==============================] - 2s 460us/step - loss: 0.0418 - matthews_correlation: 0.9095 - val_loss: 0.0564 - val_matthews_correlation: 0.3534\n\nEpoch 00029: val_matthews_correlation did not improve from 0.38733\nEpoch 30/50\n4790/4790 [==============================] - 2s 458us/step - loss: 0.0433 - matthews_correlation: 0.9049 - val_loss: 0.0555 - val_matthews_correlation: 0.3475\n\nEpoch 00030: val_matthews_correlation did not improve from 0.38733\nEpoch 31/50\n4790/4790 [==============================] - 2s 457us/step - loss: 0.0431 - matthews_correlation: 0.9028 - val_loss: 0.0600 - val_matthews_correlation: 0.3560\n\nEpoch 00031: val_matthews_correlation did not improve from 0.38733\nEpoch 32/50\n4790/4790 [==============================] - 2s 458us/step - loss: 0.0433 - matthews_correlation: 0.9045 - val_loss: 0.0641 - val_matthews_correlation: 0.2963\n\nEpoch 00032: val_matthews_correlation did not improve from 0.38733\nEpoch 33/50\n","name":"stdout"},{"output_type":"stream","text":"4790/4790 [==============================] - 2s 460us/step - loss: 0.0481 - matthews_correlation: 0.9053 - val_loss: 0.0714 - val_matthews_correlation: 0.2947\n\nEpoch 00033: val_matthews_correlation did not improve from 0.38733\nEpoch 34/50\n4790/4790 [==============================] - 2s 455us/step - loss: 0.0499 - matthews_correlation: 0.8925 - val_loss: 0.0591 - val_matthews_correlation: 0.3656\n\nEpoch 00034: val_matthews_correlation did not improve from 0.38733\nEpoch 35/50\n4790/4790 [==============================] - 2s 457us/step - loss: 0.0430 - matthews_correlation: 0.9052 - val_loss: 0.0542 - val_matthews_correlation: 0.3635\n\nEpoch 00035: val_matthews_correlation did not improve from 0.38733\nEpoch 36/50\n4790/4790 [==============================] - 2s 459us/step - loss: 0.0417 - matthews_correlation: 0.8965 - val_loss: 0.0559 - val_matthews_correlation: 0.3840\n\nEpoch 00036: val_matthews_correlation did not improve from 0.38733\nEpoch 37/50\n4790/4790 [==============================] - 2s 457us/step - loss: 0.0423 - matthews_correlation: 0.9069 - val_loss: 0.0521 - val_matthews_correlation: 0.3475\n\nEpoch 00037: val_matthews_correlation did not improve from 0.38733\nEpoch 38/50\n4790/4790 [==============================] - 2s 458us/step - loss: 0.0405 - matthews_correlation: 0.8968 - val_loss: 0.0572 - val_matthews_correlation: 0.3673\n\nEpoch 00038: val_matthews_correlation did not improve from 0.38733\nEpoch 39/50\n4790/4790 [==============================] - 2s 462us/step - loss: 0.0424 - matthews_correlation: 0.8939 - val_loss: 0.0571 - val_matthews_correlation: 0.3548\n\nEpoch 00039: val_matthews_correlation did not improve from 0.38733\nEpoch 40/50\n4790/4790 [==============================] - 2s 459us/step - loss: 0.0396 - matthews_correlation: 0.9137 - val_loss: 0.0559 - val_matthews_correlation: 0.3759\n\nEpoch 00040: val_matthews_correlation did not improve from 0.38733\nEpoch 41/50\n4790/4790 [==============================] - 2s 457us/step - loss: 0.0389 - matthews_correlation: 0.8994 - val_loss: 0.0552 - val_matthews_correlation: 0.3804\n\nEpoch 00041: val_matthews_correlation did not improve from 0.38733\nEpoch 42/50\n4790/4790 [==============================] - 2s 459us/step - loss: 0.0388 - matthews_correlation: 0.9088 - val_loss: 0.0564 - val_matthews_correlation: 0.3805\n\nEpoch 00042: val_matthews_correlation did not improve from 0.38733\nEpoch 43/50\n4790/4790 [==============================] - 2s 457us/step - loss: 0.0389 - matthews_correlation: 0.9025 - val_loss: 0.0583 - val_matthews_correlation: 0.3672\n\nEpoch 00043: val_matthews_correlation did not improve from 0.38733\nEpoch 44/50\n4790/4790 [==============================] - 2s 460us/step - loss: 0.0399 - matthews_correlation: 0.9097 - val_loss: 0.0545 - val_matthews_correlation: 0.3821\n\nEpoch 00044: val_matthews_correlation did not improve from 0.38733\nEpoch 45/50\n4790/4790 [==============================] - 2s 458us/step - loss: 0.0392 - matthews_correlation: 0.9127 - val_loss: 0.0572 - val_matthews_correlation: 0.3719\n\nEpoch 00045: val_matthews_correlation did not improve from 0.38733\nEpoch 46/50\n4790/4790 [==============================] - 2s 460us/step - loss: 0.0364 - matthews_correlation: 0.9193 - val_loss: 0.0554 - val_matthews_correlation: 0.3613\n\nEpoch 00046: val_matthews_correlation did not improve from 0.38733\nEpoch 47/50\n4790/4790 [==============================] - 2s 459us/step - loss: 0.0401 - matthews_correlation: 0.8902 - val_loss: 0.1262 - val_matthews_correlation: 0.2830\n\nEpoch 00047: val_matthews_correlation did not improve from 0.38733\nEpoch 48/50\n4790/4790 [==============================] - 2s 460us/step - loss: 0.0453 - matthews_correlation: 0.9003 - val_loss: 0.0507 - val_matthews_correlation: 0.3853\n\nEpoch 00048: val_matthews_correlation did not improve from 0.38733\nEpoch 49/50\n4790/4790 [==============================] - 2s 460us/step - loss: 0.0405 - matthews_correlation: 0.9027 - val_loss: 0.0534 - val_matthews_correlation: 0.3821\n\nEpoch 00049: val_matthews_correlation did not improve from 0.38733\nEpoch 50/50\n4790/4790 [==============================] - 2s 452us/step - loss: 0.0374 - matthews_correlation: 0.9172 - val_loss: 0.0532 - val_matthews_correlation: 0.3889\n\nEpoch 00050: val_matthews_correlation improved from 0.38733 to 0.38891, saving model to weights_4.h5\n","name":"stdout"},{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"((5986,), (5986,))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def matthews_correlation(y_true, y_pred):\n    '''Calculates the Matthews correlation coefficient measure for quality\n    of binary classification problems.\n    '''\n    \n    y_pred = tf.convert_to_tensor(y_pred, np.float64)\n    y_true = tf.convert_to_tensor(y_true, np.float64)\n    \n    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n    y_pred_neg = 1 - y_pred_pos\n\n    y_pos = K.round(K.clip(y_true, 0, 1))\n    y_neg = 1 - y_pos\n\n    tp = K.sum(y_pos * y_pred_pos)\n    tn = K.sum(y_neg * y_pred_neg)\n\n    fp = K.sum(y_neg * y_pred_pos)\n    fn = K.sum(y_pos * y_pred_neg)\n\n    numerator = (tp * tn - fp * fn)\n    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n\n    return numerator / (denominator + K.epsilon())","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimal_values = threshold_search(y_val, preds_val)\nbest_threshold = optimal_values['threshold']\nbest_score = optimal_values['matthews_correlation']","execution_count":16,"outputs":[{"output_type":"stream","text":"100%|| 100/100 [00:16<00:00,  4.04it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"\"\"------------------------------\nFinished training a LSTM model.\nCV scores: %.3f\n------------------------------\"\"\" % (best_score))","execution_count":17,"outputs":[{"output_type":"stream","text":"------------------------------\nFinished training a LSTM model.\nCV scores: 0.909\n------------------------------\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Calculate proba of test dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"meta_test = pd.read_csv('../input/vsb-power-line-fault-detection/metadata_test.csv')\nX_test_input = np.load(\"../input/folk-base-neural-network-using-lstm/X_test.npy\")\nfeatures_test = np.load(\"../input/folk-base-neural-network-using-lstm/features_test.npy\")\nsubmission = pd.read_csv('../input/vsb-power-line-fault-detection/sample_submission.csv')","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_test = []\nfor i in range(N_SPLITS):\n    model.load_weights('weights_{}.h5'.format(i))\n    pred = model.predict([X_test_input, features_test], batch_size=300, verbose=1)\n    pred_3 = []\n    for pred_scalar in pred:\n        for i in range(3):\n            pred_3.append(pred_scalar)\n    preds_test.append(pred_3)\n","execution_count":19,"outputs":[{"output_type":"stream","text":"6779/6779 [==============================] - 1s 131us/step\n6779/6779 [==============================] - 1s 131us/step\n6779/6779 [==============================] - 1s 123us/step\n6779/6779 [==============================] - 1s 118us/step\n6779/6779 [==============================] - 1s 117us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimal_values = threshold_search(y_val, preds_val)\nbest_threshold = optimal_values['threshold']\nbest_score = optimal_values['matthews_correlation']\n","execution_count":20,"outputs":[{"output_type":"stream","text":"100%|| 100/100 [00:38<00:00,  2.04it/s]\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_test = (np.squeeze(np.mean(preds_test, axis=0)) > best_threshold).astype(np.int)\npreds_test.shape","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"(20337,)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['target'] = preds_test\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"   signal_id  target\n0       8712       0\n1       8713       0\n2       8714       0\n3       8715       0\n4       8716       0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>signal_id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8712</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8713</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8714</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8715</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8716</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission[submission.target == 1].info()","execution_count":23,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 738 entries, 57 to 20324\nData columns (total 2 columns):\nsignal_id    738 non-null int64\ntarget       738 non-null int64\ndtypes: int64(2)\nmemory usage: 17.3 KB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}