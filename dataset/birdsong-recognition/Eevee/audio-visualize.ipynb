{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport math\nimport gc\nimport warnings\nimport os\nfrom glob import glob\nfrom PIL import Image\nimport cv2\nimport pydicom\nfrom IPython.display import display, Audio\nimport folium\n\nfrom sklearn.preprocessing import minmax_scale\n\nimport librosa\nfrom librosa.display import waveplot, specshow\nfrom librosa.feature import melspectrogram, chroma_cqt, mfcc, delta, spectral_bandwidth, spectral_centroid\nfrom librosa.beat import beat_track\n\nwarnings.filterwarnings('ignore')\npd.set_option('display.max_columns', 100)\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Config","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"MAIN_PATH = '../input/birdsong-recognition/'\n\nTRAIN_PATH = os.path.join(MAIN_PATH, 'train.csv')\nTEST_PATH = os.path.join(MAIN_PATH, 'test.csv')\nSUB_PATH = os.path.join(MAIN_PATH, 'sample_submission.csv')\n\nEXAM_TEST = os.path.join(MAIN_PATH, 'example_test_audio')\nTRAIN_AUDIO_PATH = os.path.join(MAIN_PATH, 'train_audio')\n\nSR = 32000","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize(x, axis=0):\n    return minmax_scale(x, axis=axis)\n\n\n\ndef display_feature(df, feature, top=10):\n    \n    plt.figure(figsize=(15,8))\n    sns.set_style('darkgrid')\n    ax = sns.countplot(y=feature, data=df, order=df[feature].value_counts().index[:top])\n\n    for p in ax.patches:\n        ax.annotate('{:.2f}%'.format(100*p.get_width()/df.shape[0]), (p.get_x() + p.get_width() + 0.02, p.get_y() + p.get_height()/2))\n\n    plt.title(f'Distribution of {feature}', size=25, color='b')\n    plt.show()\n    \n    \n    \ndef audio_map(df, audio_list, num_bird=5):\n    for i in range(num_bird):\n        rand_bird = random.choice(df['ebird_code'])\n        rand_df = df[df['ebird_code']==rand_bird].sample().reset_index(drop=True)\n        latitude = rand_df.loc[0, 'latitude']\n        longitude = rand_df.loc[0, 'longitude']\n        location = rand_df.loc[0, 'location']\n        \n        map_hooray = folium.Map(location=[latitude, longitude], zoom_start=10)\n        folium.Marker([latitude, longitude], popup=location).add_to(map_hooray)\n        \n        file = random.choice(rand_df['filename'])\n        print(f'{file}: {rand_bird} in{location}')\n        file_path = [i for i in audio_list if file in i][0]\n        display(Audio(data=file_path, autoplay=True))\n        display(map_hooray)\n        \n        \n        \ndef spectrum_wave(df, audio_list, num_bird=3):\n    num_ax = 8\n    for i in range(num_bird):\n        rand_bird = random.choice(df['ebird_code'])\n        rand_df = df[df['ebird_code']==rand_bird].sample().reset_index(drop=True)\n        file = random.choice(rand_df['filename'])\n        file_path = [i for i in audio_list if file in i][0]\n        y, sr = librosa.load(file_path, sr=SR, offset=0, duration=10)\n        \n        S = melspectrogram(y, sr=sr, n_mels=128)\n        log_s = librosa.power_to_db(S, ref=np.max)\n        \n        fig, ax = plt.subplots(num_ax, 1, figsize=(20, 7*num_ax))\n        \n        ax0 = ax[0].twinx()\n        waveplot(y, sr, color='yellowgreen', alpha=0.4, ax=ax0)\n        s0 = specshow(log_s, sr=sr, x_axis='time', y_axis='log', ax=ax[0])\n        ax[0].set_title('Mel', color='r', fontsize=15)\n        \n        \n        y_harmonic, y_percussive = librosa.effects.hpss(y)\n        s_harmonic   = melspectrogram(y_harmonic, sr=sr)\n        s_percussive = melspectrogram(y_percussive, sr=sr)\n        \n        log_sh = librosa.power_to_db(s_harmonic, ref=np.max)\n        log_sp = librosa.power_to_db(s_percussive, ref=np.max)\n        \n        ax1 = ax[1].twinx()\n        waveplot(y, sr, color='yellowgreen', alpha=0.4, ax=ax1)\n        specshow(log_sh, sr=sr, x_axis='time', y_axis='log', ax=ax[1])\n        ax[1].set_title('Harmonic', color='r', fontsize=15)\n        \n        ax2 = ax[2].twinx()\n        waveplot(y, sr, color='yellowgreen', alpha=0.4, ax=ax2)\n        specshow(log_sp, sr=sr, x_axis='time', y_axis='log', ax=ax[2])\n        ax[2].set_title('Percussive', color='r', fontsize=15)\n        \n        c = chroma_cqt(y_harmonic, sr=sr, bins_per_octave=36)\n        \n        specshow(c, sr=sr, x_axis='time', y_axis='log', ax=ax[3])\n        ax[3].set_title('Chromagram', color='r', fontsize=15)\n        \n        tempo, beats = beat_track(y_percussive, sr=sr)\n        \n        specshow(log_s, sr=sr, x_axis='time', y_axis='log', ax=ax[4])\n        ax[4].set_title('Beat track', color='r', fontsize=15)\n        ax[4].vlines(librosa.frames_to_time(beats), 1, 0.5 * sr,\n                     colors='w', linestyles='-', linewidth=2, alpha=0.5)\n        \n        mfcc_ = mfcc(S=log_s, n_mfcc=13)\n        delta_mffc = delta(mfcc_)\n        delta_mffc2 = delta(mfcc_, order=2)\n        \n        specshow(mfcc_, x_axis='time', y_axis='log', ax=ax[5])\n        ax[5].set_title('MFFC', color='r', fontsize=15)\n        \n        specshow(delta_mffc, x_axis='time', y_axis='log', ax=ax[6])\n        ax[6].set_title('Delta MFFC', color='r', fontsize=15)\n        \n        specshow(delta_mffc2, x_axis='time', y_axis='log', ax=ax[7])\n        ax[7].set_title('Delta MFFC2', color='r', fontsize=15)\n        \n        plt.suptitle(f'{file}: {rand_bird}', fontsize=20, color='b')\n        fig.tight_layout(rect=[0, 0.03, 1, 0.95])        \n        \n        \n        \ndef bandwidth(df, audio_list, num_bird=5, num_each_bird=3):\n    for i in range(num_bird):\n        rand_bird = random.choice(df['ebird_code'])\n        rand_df = df[df['ebird_code']==rand_bird].sample(num_each_bird).reset_index(drop=True)\n        fig, ax = plt.subplots(num_each_bird, 1, figsize=(20, 10*num_each_bird))\n        for row in range(len(rand_df)):\n            file = rand_df.loc[row, 'filename']\n            file_path = [i for i in audio_list if file in i][0]\n            y, sr = librosa.load(file_path, sr=SR, offset=0, duration=10)\n            spec_center = spectral_centroid(y, sr=sr)[0]\n            band2 = spectral_bandwidth(y, sr=sr, p=2)[0]\n            band3 = spectral_bandwidth(y, sr=sr, p=3)[0]\n            band4 = spectral_bandwidth(y, sr=sr, p=4)[0]\n#             spec_center = specshow(spec_center, sr=sr, x_axis='time', y_axis='log')\n\n            waveplot(y, sr, color='b', alpha=0.4, ax=ax[row])\n            ax0 = ax[row].plot(librosa.frames_to_time(range(len(spec_center))), normalize(spec_center), color='r')[0]\n            ax1 = ax[row].plot(librosa.frames_to_time(range(len(band2))), normalize(band2), color='g')[0]\n            ax2 = ax[row].plot(librosa.frames_to_time(range(len(band3))), normalize(band3), color='black')[0]\n            ax3 = ax[row].plot(librosa.frames_to_time(range(len(band4))), normalize(band4), color='y')[0]\n            fig.legend([ax0, ax1, ax2, ax3], ['center', 'band2', 'band3', 'band4'], fontsize=16)\n            ax[row].set_title(f'{rand_df.loc[row, \"filename\"]}', color='r', fontsize=15)\n            \n            ax[row].legend()\n                     \n        plt.suptitle(f'{rand_bird}', fontsize=20, color='b')\n        fig.tight_layout(rect=[0, 0.03, 1, 0.95])           \n        plt.show()        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read File","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(TRAIN_PATH, usecols=['ebird_code', 'recordist', 'location', 'file_type',\n                                            'date', 'filename', 'url', 'longitude', 'latitude'])\ntrain_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(TEST_PATH)\ntest_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.read_csv(SUB_PATH)\nsub_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_mp3 = glob(f'{TRAIN_AUDIO_PATH}/*/*.*')\nprint(f'Number of file: {len(train_mp3)}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Some Analysis","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"display_feature(train_df, 'recordist', top=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Display Audio","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"audio_map(train_df, train_mp3, num_bird=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Way + Mel + Harmonic + Percussive + Chromagram + Beat track + MFFC\nReference: https://medium.com/@jonathan_hui/speech-recognition-feature-extraction-mfcc-plp-5455f5a69dd9","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nspectrum_wave(train_df, train_mp3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Spectral Bandwidth","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bandwidth(train_df, train_mp3)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}