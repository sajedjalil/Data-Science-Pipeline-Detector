{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns # data visualization library\nimport matplotlib.pyplot as plt # data visualization library\nimport scipy.stats as stats # library of statistical functions\nimport warnings\nwarnings.filterwarnings(\"ignore\") # warnings filter to never print matching warnings\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Reading Data","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/liberty-mutual-group-property-inspection-prediction/train.csv.zip\")\ndf_test = pd.read_csv(\"/kaggle/input/liberty-mutual-group-property-inspection-prediction/test.csv.zip\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Understanding the Data","metadata":{}},{"cell_type":"code","source":"df_train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Getting Unique values of each column","metadata":{}},{"cell_type":"code","source":"for col in df_train.columns: \n    print('{} :{} ' . format(col.upper(),df_train[col].unique()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Reducing data size","metadata":{}},{"cell_type":"markdown","source":"Converting Object data type to Category","metadata":{}},{"cell_type":"code","source":"objectCol = list(df_train.select_dtypes(include=['object']).columns)\n\nfor col in objectCol:\n    df_train[col] = df_train[col].astype(\"category\")\n    df_test[col] = df_test[col].astype(\"category\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Changing the numerical data types to reduce size further","metadata":{}},{"cell_type":"code","source":"# Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    #start_mem = df.memory_usage().sum() / 1024**2\n    #print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n\n    for col in df.columns:\n        col_type = df[col].dtype\n        if col_type != object and str(col_type) != 'category':\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            elif str(col_type)[:5] == 'float':\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    #end_mem = df.memory_usage().sum() / 1024**2\n    #print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    #print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n\n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = reduce_mem_usage(df_train)\ndf_test = reduce_mem_usage(df_test)\ndf_train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Splitting Column names based on Data Types","metadata":{}},{"cell_type":"code","source":"df_train=df_train.drop(['Id'],axis=1)\ndf_test_Id=df_test['Id']\ndf_test=df_test.drop(['Id'],axis=1)\ndf_numerical_cols = df_train.select_dtypes(exclude='object').select_dtypes(exclude='category').columns.tolist()\n# df_categorical_cols = df.select_dtypes(include='object').columns.tolist()\ndf_categorical_cols = [i for i in df_train.columns if i not in df_numerical_cols]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_numerical_cols","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_categorical_cols","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Histogram","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(len(df_numerical_cols),2)\nfig.set_figwidth(10)\nfig.set_figheight(120)\ni=0\nfor col in df_numerical_cols:\n    sns.histplot(x=df_train[col], ax=axs[i,0],kde=True)\n    stats.probplot(df_train[col], dist=\"norm\", plot=axs[i,1])\n    i=i+1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Correlation matrix","metadata":{}},{"cell_type":"code","source":"corrmat = df_train.corr()\nf, ax = plt.subplots(figsize=(15, 15))\nmatrix = np.triu(df_train.corr())\nsns.heatmap(corrmat, square=True, annot=True, fmt='.1g',  cbar=False, mask=matrix);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No feature is highly correlated","metadata":{}},{"cell_type":"markdown","source":"Skewness along the index axis","metadata":{}},{"cell_type":"code","source":"df_train.skew(axis = 0, skipna = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"Removing the skewness with |skewness| > 1","metadata":{}},{"cell_type":"markdown","source":"**T2_V2, T2_V6, T2_V8, T2_V14, T2_V15** \nnot able to remove skewness of T2_V8","metadata":{}},{"cell_type":"code","source":"col = 'T2_V2'\nfig, axs = plt.subplots(3)\nfig.set_figwidth(8)\nfig.set_figheight(15)\nsns.kdeplot(df_train[col],color='Purple',fill=True, ax=axs[0])\nprint(\"Old skew of %s: %.2f\" % (col,df_train[col].skew(axis = 0, skipna = True)))\n# Removing the skewness using a log function and checking the distribution again\ndf_train[col] = df_train[col].map(lambda i : np.log(i) if i > 0 else 0)\nsns.kdeplot(df_train[col],color='Orange',fill=True, ax=axs[1])\nstats.probplot(df_train[col], dist=\"norm\", plot=axs[2])\nprint(\"New skew of %s: %.2f\" % (col,df_train[col].skew(axis = 0, skipna = True)))\ndf_test[col] = df_test[col].map(lambda i : np.log(i) if i > 0 else 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col = 'T2_V6'\nfig, axs = plt.subplots(3)\nfig.set_figwidth(8)\nfig.set_figheight(15)\nsns.kdeplot(df_train[col],color='Purple',fill=True, ax=axs[0])\nprint(\"Old skew of %s: %.2f\" % (col,df_train[col].skew(axis = 0, skipna = True)))\n# Removing the skewness using a log function and checking the distribution again\ndf_train[col] = df_train[col].map(lambda i : np.log(i) if i > 0 else 0)\nsns.kdeplot(df_train[col],color='Orange',fill=True, ax=axs[1])\nstats.probplot(df_train[col], dist=\"norm\", plot=axs[2])\nprint(\"New skew of %s: %.2f\" % (col,df_train[col].skew(axis = 0, skipna = True)))\ndf_test[col] = df_test[col].map(lambda i : np.log(i) if i > 0 else 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col = 'T2_V14'\nfig, axs = plt.subplots(3)\nfig.set_figwidth(8)\nfig.set_figheight(15)\nsns.kdeplot(df_train[col],color='Purple',fill=True, ax=axs[0])\nprint(\"Old skew of %s: %.2f\" % (col,df_train[col].skew(axis = 0, skipna = True)))\n# Removing the skewness using a log function and checking the distribution again\ndf_train[col] = df_train[col].map(lambda i : np.log(i) if i > 0 else 0)\nsns.kdeplot(df_train[col],color='Orange',fill=True, ax=axs[1])\nstats.probplot(df_train[col], dist=\"norm\", plot=axs[2])\nprint(\"New skew of %s: %.2f\" % (col,df_train[col].skew(axis = 0, skipna = True)))\ndf_test[col] = df_test[col].map(lambda i : np.log(i) if i > 0 else 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"col = 'T2_V15'\nfig, axs = plt.subplots(3)\nfig.set_figwidth(8)\nfig.set_figheight(15)\nsns.kdeplot(df_train[col],color='Purple',fill=True, ax=axs[0])\nprint(\"Old skew of %s: %.2f\" % (col,df_train[col].skew(axis = 0, skipna = True)))\n# Removing the skewness using a log function and checking the distribution again\ndf_train[col] = df_train[col].map(lambda i : np.log(i) if i > 0 else 0)\nsns.kdeplot(df_train[col],color='Orange',fill=True, ax=axs[1])\nstats.probplot(df_train[col], dist=\"norm\", plot=axs[2])\nprint(\"New skew of %s: %.2f\" % (col,df_train[col].skew(axis = 0, skipna = True)))\ndf_test[col] = df_test[col].map(lambda i : np.log(i) if i > 0 else 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Splitting columns into features and dependent columns","metadata":{}},{"cell_type":"code","source":"# creating a copy of dataframe\ndf1 = df_train\n\n# separating the features and target \nX = df1.drop(['Hazard'],axis=1)\ny = df1[['Hazard']]\nX_df_test = df_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_numerical_cols.remove('Hazard')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Deleting unused variables and collecting memory","metadata":{}},{"cell_type":"code","source":"import gc\ndel df1\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Encoding categorical data","metadata":{}},{"cell_type":"code","source":"# In case when few categorical values are not common in Train set and Test set \n# then training the model using Train set and transforming Test set will result in \n# different number of columns\n# Combining training set and test set so make the number of encoded columns same\nX['train']=1\nX_df_test['train']=0\ncombined = pd.concat([X,X_df_test])\ndf = pd.get_dummies(combined[df_categorical_cols])\ndf_dummies=pd.concat([combined[df_numerical_cols],df,combined['train']],axis=1)\n# Splitting training set and test set\nX = df_dummies[df_dummies['train']==1]\nX_df_test = df_dummies[df_dummies['train']==0]\n# Deleting Train column\nX.drop(['train'],axis=1,inplace=True)\nX_df_test.drop(['train'],axis=1,inplace=True)\nX.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"markdown","source":"Checking the accuracy of models on Train data first and then we will use that model to predict the Test outcome.","metadata":{}},{"cell_type":"markdown","source":"Splitting the dataset into the Training set and Test set","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Feature Scaling","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler \nsc = StandardScaler()\n\nfor col in df_numerical_cols:\n    X_train[col] =  sc.fit_transform(X_train[col].values.reshape(-1,1))\n    X_test[col] =  sc.transform(X_test[col].values.reshape(-1,1))\ny_train['Hazard'] =  sc.fit_transform(y_train['Hazard'].values.reshape(-1,1))\ny_test['Hazard'] =  sc.transform(y_test['Hazard'].values.reshape(-1,1))\n# last object is fitted on y, this will be used to inverse transform y_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Packages","metadata":{}},{"cell_type":"code","source":"# Base Models\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.svm import SVR\nfrom sklearn.tree import DecisionTreeRegressor\n\n# Ensembling and Boosting\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"the Python implementation from the [Gini coefficient discussion with code samples](https://www.kaggle.com/c/ClaimPredictionChallenge/discussion/703):","metadata":{}},{"cell_type":"code","source":"def gini(actual, pred):\n    assert (len(actual) == len(pred))\n    all = np.asarray(np.c_[actual, pred, np.arange(len(actual))], dtype=np.float)\n    all = all[np.lexsort((all[:, 2], -1 * all[:, 1]))]\n    totalLosses = all[:, 0].sum()\n    giniSum = all[:, 0].cumsum().sum() / totalLosses\n\n    giniSum -= (len(actual) + 1) / 2.\n    return giniSum / len(actual)\n\n# The higher the better\ndef gini_normalized(actual, pred):\n    return gini(actual, pred) / gini(actual, actual)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Base Modeling","metadata":{}},{"cell_type":"code","source":"models = [\n    ('LinearRegression', LinearRegression()),\n    ('GradientBoostingRegressor', GradientBoostingRegressor()),\n    ('DecisionTreeRegressor',DecisionTreeRegressor(random_state = 0)),\n    ('RandomForestRegressor',RandomForestRegressor(n_estimators = 10, random_state = 0))\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Gini score","metadata":{}},{"cell_type":"code","source":"print(\"The accuracy scores of the models are :\")\nfor model_name, model in models:\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    y_test['Hazard'] =  sc.inverse_transform(y_test['Hazard'].values)\n    y_pred =  sc.inverse_transform(y_pred)\n    print(model_name, \" after rescale Test score: \", gini_normalized(y_test, y_pred))\n    y_pred = model.predict(X_train)\n    y_train['Hazard'] =  sc.inverse_transform(y_train['Hazard'].values)\n    y_pred =  sc.inverse_transform(y_pred)\n    print(model_name, \" after rescale Train score: \", gini_normalized(y_train, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"GradientBoostingRegressor and LinearRegression performed the best, We will use these 2 models. Now we will use whole train data to train and test data to predict.","metadata":{}},{"cell_type":"markdown","source":"Feature Scaling","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler \nsc = StandardScaler()\n\nfor col in df_numerical_cols:\n    X[col] =  sc.fit_transform(X[col].values.reshape(-1,1))\n    X_df_test[col] =  sc.transform(X_df_test[col].values.reshape(-1,1))\ny['Hazard'] =  sc.fit_transform(y['Hazard'].values.reshape(-1,1))\n# last object is fitted on y, this will be used to inverse transform y_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = GradientBoostingRegressor()\nmodel.fit(X, y)\ny_pred = model.predict(X_df_test)\ny_pred = sc.inverse_transform(y_pred)\noutput = pd.DataFrame({'Id': df_test_Id, 'Hazard': y_pred})\noutput.to_csv('GradientBoostingRegressor10May.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}