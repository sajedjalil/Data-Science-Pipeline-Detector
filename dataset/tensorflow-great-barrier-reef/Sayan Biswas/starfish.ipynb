{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-14T02:52:55.89995Z","iopub.execute_input":"2022-02-14T02:52:55.90092Z","iopub.status.idle":"2022-02-14T02:52:55.922071Z","shell.execute_reply.started":"2022-02-14T02:52:55.900805Z","shell.execute_reply":"2022-02-14T02:52:55.921322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install wandb","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:52:55.923601Z","iopub.execute_input":"2022-02-14T02:52:55.923873Z","iopub.status.idle":"2022-02-14T02:53:04.496348Z","shell.execute_reply.started":"2022-02-14T02:52:55.92384Z","shell.execute_reply":"2022-02-14T02:53:04.495488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ðŸ Secrets\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandb\")\n\n! wandb login $secret_value_0","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:53:04.499763Z","iopub.execute_input":"2022-02-14T02:53:04.500037Z","iopub.status.idle":"2022-02-14T02:53:07.419941Z","shell.execute_reply.started":"2022-02-14T02:53:04.500007Z","shell.execute_reply":"2022-02-14T02:53:07.419132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\n\nimport os\nimport cv2\nimport tqdm\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\nimport shutil\nimport random\nimport yaml\nimport torch\n","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:53:07.422399Z","iopub.execute_input":"2022-02-14T02:53:07.422686Z","iopub.status.idle":"2022-02-14T02:53:08.97368Z","shell.execute_reply.started":"2022-02-14T02:53:07.422649Z","shell.execute_reply":"2022-02-14T02:53:08.972941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Preliminary folder analysis","metadata":{}},{"cell_type":"code","source":"# image_path='/kaggle/input/tensorflow-great-barrier-reef/train_images/video_'\n# for i in range(3):\n#     filetypes=set()\n#     print(\"for folder video\",i,\"available file types are: \")\n#     for dirname, _, filenames in os.walk(image_path+str(i)):\n#         for filename in filenames:\n#             ext = os.path.splitext(filename)[-1].lower()\n#             filetypes.add(ext)\n#     print(filetypes)\n\n\n# for dirpath, dirname, filenames in os.walk('/kaggle/input/tensorflow-great-barrier-reef'):\n#     for file in filenames: \n#         if not file.endswith('.jpg'):\n#                               print(file)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:53:08.975193Z","iopub.execute_input":"2022-02-14T02:53:08.975424Z","iopub.status.idle":"2022-02-14T02:53:08.981213Z","shell.execute_reply.started":"2022-02-14T02:53:08.975392Z","shell.execute_reply":"2022-02-14T02:53:08.98049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_WIDTH=1280\nIMG_HEIGHT=720","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:53:08.982491Z","iopub.execute_input":"2022-02-14T02:53:08.983228Z","iopub.status.idle":"2022-02-14T02:53:08.988135Z","shell.execute_reply.started":"2022-02-14T02:53:08.983169Z","shell.execute_reply":"2022-02-14T02:53:08.987264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT_DIR  = '/kaggle/input/tensorflow-great-barrier-reef/'\nIMAGE_DIR = '/kaggle/images' # directory to save images\nLABEL_DIR = '/kaggle/labels' # directory to save labels\n\n#creating image and labels directories\nif not os.path.exists(IMAGE_DIR):\n    !mkdir -p {IMAGE_DIR}\nif not os.path.exists(LABEL_DIR):\n    !mkdir -p {LABEL_DIR}","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:53:08.989291Z","iopub.execute_input":"2022-02-14T02:53:08.989725Z","iopub.status.idle":"2022-02-14T02:53:10.52869Z","shell.execute_reply.started":"2022-02-14T02:53:08.989688Z","shell.execute_reply":"2022-02-14T02:53:10.527748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(f'{ROOT_DIR}/train.csv')\n# Adding image path and label paths to each image\ndf['original_path']=f'{ROOT_DIR}/train_images/video_'+df.video_id.astype(str)+'/'+df.video_frame.astype(str)+'.jpg'\n#'/kaggle/input/tensorflow-great-barrier-reef/train_images/video_0/0.jpg' =>for first data point\n\n# New images and labels path\ndf['image_path']  = f'{IMAGE_DIR}/'+df.image_id+'.jpg'\ndf['label_path']  = f'{LABEL_DIR}/'+df.image_id+'.txt'\ndf['annotations'] = df['annotations'].progress_apply(eval)\n\ndisplay(df.head(20))\nprint(df.shape[0])","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:53:10.532149Z","iopub.execute_input":"2022-02-14T02:53:10.532368Z","iopub.status.idle":"2022-02-14T02:53:10.993202Z","shell.execute_reply.started":"2022-02-14T02:53:10.532341Z","shell.execute_reply":"2022-02-14T02:53:10.992444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# COunts number of objectless images\ndf['num_bbox'] = df['annotations'].progress_apply(lambda x:len(x))\ndata = (df.num_bbox>0).value_counts(normalize=True)*100\nprint(f\"No BBox: {data[0]:0.2f}% | With BBox: {data[1]:0.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:53:10.99456Z","iopub.execute_input":"2022-02-14T02:53:10.99497Z","iopub.status.idle":"2022-02-14T02:53:11.09251Z","shell.execute_reply.started":"2022-02-14T02:53:10.994933Z","shell.execute_reply":"2022-02-14T02:53:11.091847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Removing some objectless images\ndf2=df.query('num_bbox==0')\ndf2=df2.sample(n=800)\ndf=df.query('num_bbox>0')\ndf=pd.concat([df,df2],ignore_index=True)\n\ndf = df.sample(frac=1).reset_index(drop=True)\nprint(df.shape[0])","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:53:11.095557Z","iopub.execute_input":"2022-02-14T02:53:11.096222Z","iopub.status.idle":"2022-02-14T02:53:11.128641Z","shell.execute_reply.started":"2022-02-14T02:53:11.096184Z","shell.execute_reply":"2022-02-14T02:53:11.127929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:53:11.130058Z","iopub.execute_input":"2022-02-14T02:53:11.130537Z","iopub.status.idle":"2022-02-14T02:53:11.144986Z","shell.execute_reply.started":"2022-02-14T02:53:11.1305Z","shell.execute_reply":"2022-02-14T02:53:11.14411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Storing Images","metadata":{}},{"cell_type":"code","source":"# Populating the images folder\nfor i in tqdm(range(df.shape[0])):\n    src_path=df.iloc[i]['original_path']\n    dst_path=df.iloc[i]['image_path']\n    \n    if not os.path.exists(dst_path):\n        shutil.copy(src=src_path,dst=dst_path)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:53:11.146388Z","iopub.execute_input":"2022-02-14T02:53:11.146671Z","iopub.status.idle":"2022-02-14T02:54:35.273412Z","shell.execute_reply.started":"2022-02-14T02:53:11.146635Z","shell.execute_reply":"2022-02-14T02:54:35.272723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sanity check random image\nind=random.randint(0,df.shape[0])\nimid=df.iloc[ind]['image_id']\nplt.figure(figsize=(10, 10))\nimg_sample = cv2.imread(\"../images/\"+f'{imid}'+'.jpg')\nimg_sample = cv2.cvtColor(img_sample, cv2.COLOR_BGR2RGB)\nprint(\"Image id is {}\".format(imid))\nplt.imshow(img_sample)\nplt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:54:35.274852Z","iopub.execute_input":"2022-02-14T02:54:35.275166Z","iopub.status.idle":"2022-02-14T02:54:35.900213Z","shell.execute_reply.started":"2022-02-14T02:54:35.275127Z","shell.execute_reply":"2022-02-14T02:54:35.899538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creating Labels","metadata":{}},{"cell_type":"code","source":"def get_bbox(annots):\n    bboxes = [list(annot.values()) for annot in annots]\n    if len(bboxes)==0:\n        return []\n    bboxes=coco2yolo(bboxes)\n    return bboxes\ndef coco2yolo(bboxes):\n    ##yolo format [xmid, ymid, w, h]\n    bboxes = np.array(bboxes).astype(float)\n    # Normalize xmin, w\n    bboxes[:, [0, 2]]= bboxes[:, [0, 2]]/ IMG_WIDTH\n    # Normalize ymin, h\n    bboxes[:, [1, 3]]= bboxes[:, [1, 3]]/ IMG_HEIGHT\n\n    # Converstion (xmin, ymin) => (xmid, ymid)\n    bboxes[:, [0, 1]] = bboxes[:, [0, 1]] + bboxes[:, [2, 3]]/2\n    # Clip values (between 0 and 1)\n    bboxes = np.clip(bboxes, a_min=0, a_max=1)\n    return bboxes\n\n\ndf['bboxes_YOLO'] = df.annotations.progress_apply(get_bbox)\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:54:35.901213Z","iopub.execute_input":"2022-02-14T02:54:35.90151Z","iopub.status.idle":"2022-02-14T02:54:36.521272Z","shell.execute_reply.started":"2022-02-14T02:54:35.901466Z","shell.execute_reply":"2022-02-14T02:54:36.52061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.iloc[0]['bboxes_YOLO']","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:54:36.522643Z","iopub.execute_input":"2022-02-14T02:54:36.5229Z","iopub.status.idle":"2022-02-14T02:54:36.529223Z","shell.execute_reply.started":"2022-02-14T02:54:36.522866Z","shell.execute_reply":"2022-02-14T02:54:36.52852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Writing down the labels","metadata":{}},{"cell_type":"code","source":"# Populate the ../labels folder\nyolo_bboxes=[]\nfor i in tqdm(range(df.shape[0])):\n    row_data=df.iloc[i,:]\n    yolo_bbox=row_data['bboxes_YOLO']\n    \n    with open(row_data['label_path'],'w') as file:\n        yolo_bboxes.append(yolo_bbox)\n        \n        num_box=row_data['num_bbox']\n        for j in range(num_box):\n            annot = [\"0\"] + \\\n                    yolo_bbox[j].astype(str).tolist() + \\\n                    ([\"\"] if j+1 == num_box else [\"\\n\"])\n            annot = \" \".join(annot).strip()\n            file.write(annot)\n            ","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:54:36.530766Z","iopub.execute_input":"2022-02-14T02:54:36.531247Z","iopub.status.idle":"2022-02-14T02:54:38.571451Z","shell.execute_reply.started":"2022-02-14T02:54:36.531208Z","shell.execute_reply":"2022-02-14T02:54:38.570615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sanity check of labels folder \nind=random.randint(0,df.shape[0])\nimid=df.iloc[ind]['image_id']\nf = open(\"../labels/\"+f'{imid}'+'.txt', 'r')\nprint(\"Image ID: {}\".format(imid))\nprint(\"Number of boxes are: {}\".format(df.iloc[ind]['num_bbox']))\nprint(f.read())","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:54:38.572809Z","iopub.execute_input":"2022-02-14T02:54:38.57316Z","iopub.status.idle":"2022-02-14T02:54:38.589548Z","shell.execute_reply.started":"2022-02-14T02:54:38.573121Z","shell.execute_reply":"2022-02-14T02:54:38.588439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## see some images with labels\n\n# ind=random.randint(0,df.shape[0]-10)\nimage_list=list(df[\"image_id\"])# videoid-sequence.jpg\n\nids=[]\nfor i in range(6):\n    ids.append(image_list[random.randint(0,len(image_list))])\n# video_id=[im.split(\"-\")[0] for im in image_list]\n# seq_id=[im.split(\"-\")[1] for im in image_list]\n# print(seq_id)\n\n# Plot\npaths=[]\nboxnums=[]\nfig, axs = plt.subplots(2, 3, figsize=(23, 10))\naxs = axs.flatten()\nfig.suptitle(f\"Images with yolo bounding boxes\", fontsize = 20)\nfor k in range(6):\n    im=cv2.imread(f\"/kaggle/images/{ids[k]}.jpg\")\n    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n    dh, dw, _ = im.shape\n    path=\"/kaggle/labels/\"+f\"{ids[k]}\"+\".txt\"\n    txt=open(path,\"r\").read().split(\" \")[1:]\n    no_boxes = int(len(txt)/4)\n    \n    paths.append(path)\n    boxnums.append(no_boxes)\n#     print(\"###########################\")\n#     print(path)\n#     print(txt)\n#     print(no_boxes)\n    \n    # Draw boxes\n    i = 0\n    while i+4 <= 4*no_boxes:\n        box = txt[i:i+4]\n        i = i+4\n#         print(box)\n        x, y, w, h = box\n        x, y, w, h = float(x), float(y), float(w), float(h)\n        \n        l = int((x - w / 2) * dw)\n        r = int((x + w / 2) * dw)\n        t = int((y - h / 2) * dh)\n        b = int((y + h / 2) * dh)\n\n        if l < 0: l = 0\n        if r > dw - 1: r = dw - 1\n        if t < 0: t = 0\n        if b > dh - 1: b = dh - 1\n\n        cv2.rectangle(im, (l, t), (r, b), (255,0,0), 3)\n        \n    axs[k].set_title(f\"Sample {k}\", fontsize = 14)\n    axs[k].imshow(im)\n    axs[k].set_axis_off()\n    \nplt.tight_layout()\nplt.show()\n\nprint(paths)\nprint(boxnums)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:54:38.590953Z","iopub.execute_input":"2022-02-14T02:54:38.591349Z","iopub.status.idle":"2022-02-14T02:54:40.460862Z","shell.execute_reply.started":"2022-02-14T02:54:38.591312Z","shell.execute_reply":"2022-02-14T02:54:40.460105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use Video 0 and 2 for training and 1 for validation\ntrain_data = df[df[\"video_id\"].isin([0, 2])]\ntest_data = df[df[\"video_id\"].isin([1])]\n\n# Get path to images & labels\ntrain_images = list(df[\"image_path\"])\ntrain_labels = list(df[\"label_path\"])\n\ntest_images = list(df[\"image_path\"])\ntest_labels = list(df[\"label_path\"])\n\nprint(\"Train Length:\"+str(len(train_data)), \"\\n\" +\"Test Length:\"+ str(len(test_data)))","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:54:40.462466Z","iopub.execute_input":"2022-02-14T02:54:40.462919Z","iopub.status.idle":"2022-02-14T02:54:40.486992Z","shell.execute_reply.started":"2022-02-14T02:54:40.462884Z","shell.execute_reply":"2022-02-14T02:54:40.486355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# shutil.rmtree(\"/kaggle/working\")","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:54:40.488914Z","iopub.execute_input":"2022-02-14T02:54:40.489375Z","iopub.status.idle":"2022-02-14T02:54:41.940323Z","shell.execute_reply.started":"2022-02-14T02:54:40.489333Z","shell.execute_reply":"2022-02-14T02:54:41.939273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"/kaggle/working BEFORE:\"+ str(os.listdir(\"/kaggle/working\")))\n\n# Create train and test path data\nwith open(\"/kaggle/working/train_images.txt\", \"w\") as file:\n    for path in train_images:\n        file.write(path + \"\\n\")\n        \nwith open(\"/kaggle/working/test_images.txt\", \"w\") as file:\n    for path in test_images:\n        file.write(path + \"\\n\")\n\n\n# Create configuration\ndata = dict(path= '/kaggle/working',\n          train= '/kaggle/working/train_images.txt',\n          val='/kaggle/working/test_images.txt',\n          nc=1,\n          names= ['cots'])\n\nwith open(\"/kaggle/working/gbr.yaml\", \"w\") as file:\n    yaml.dump(data, file, default_flow_style=False)\n\n        \nprint(\"/kaggle/working AFTER:\"+str(os.listdir(\"/kaggle/working\")))\nf = open(\"/kaggle/working/gbr.yaml\", 'r')\nprint('\\nyaml:')\nprint(f.read())","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:54:41.941905Z","iopub.execute_input":"2022-02-14T02:54:41.942272Z","iopub.status.idle":"2022-02-14T02:54:41.961505Z","shell.execute_reply.started":"2022-02-14T02:54:41.942232Z","shell.execute_reply":"2022-02-14T02:54:41.960821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ---> YOLOv5 install <---\n%cd /kaggle/working     \n!cp -r /kaggle/input/yolov5-lib-ds /kaggle/working/yolov5     \n%cd yolov5     \n%pip install -qr requirements.txt   \n\nfrom yolov5 import utils\ndisplay = utils.notebook_init()","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:54:41.962885Z","iopub.execute_input":"2022-02-14T02:54:41.963163Z","iopub.status.idle":"2022-02-14T02:54:52.554551Z","shell.execute_reply.started":"2022-02-14T02:54:41.96313Z","shell.execute_reply":"2022-02-14T02:54:52.553725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# --- PARAMETERS ---\nSIZE = 2000\nBATCH_SIZE = 4\nEPOCHS = 20\nMODEL = \"yolov5m\"\nWORKERS = 1\nPROJECT = \"GreatBarrierReef\"\nRUN_NAME = f\"{MODEL}_size{SIZE}_epochs{EPOCHS}_batch{BATCH_SIZE}_simple\"","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:59:48.469126Z","iopub.execute_input":"2022-02-14T02:59:48.469442Z","iopub.status.idle":"2022-02-14T02:59:48.475193Z","shell.execute_reply.started":"2022-02-14T02:59:48.469406Z","shell.execute_reply":"2022-02-14T02:59:48.474474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Hypermeters","metadata":{}},{"cell_type":"code","source":"%%writefile /kaggle/working/hyp.yaml\nlr0: 0.01  # initial learning rate (SGD=1E-2, Adam=1E-3)\nlrf: 0.1  # final OneCycleLR learning rate (lr0 * lrf)\nmomentum: 0.937  # SGD momentum/Adam beta1\nweight_decay: 0.0005  # optimizer weight decay 5e-4\nwarmup_epochs: 3.0  # warmup epochs (fractions ok)\nwarmup_momentum: 0.8  # warmup initial momentum\nwarmup_bias_lr: 0.1  # warmup initial bias lr\nbox: 0.05  # box loss gain\ncls: 0.5  # cls loss gain\ncls_pw: 1.0  # cls BCELoss positive_weight\nobj: 1.0  # obj loss gain (scale with pixels)\nobj_pw: 1.0  # obj BCELoss positive_weight\niou_t: 0.40  # IoU training threshold\nanchor_t: 4.0  # anchor-multiple threshold\n# anchors: 3  # anchors per output layer (0 to ignore)\nfl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)\nhsv_h: 0.015  # image HSV-Hue augmentation (fraction)\nhsv_s: 0.7  # image HSV-Saturation augmentation (fraction)\nhsv_v: 0.4  # image HSV-Value augmentation (fraction)\ndegrees: 0.0  # image rotation (+/- deg)\ntranslate: 0.10  # image translation (+/- fraction)\nscale: 0.5  # image scale (+/- gain)\nshear: 0.0  # image shear (+/- deg)\nperspective: 0.0  # image perspective (+/- fraction), range 0-0.001\nflipud: 0.5  # image flip up-down (probability)\nfliplr: 0.5  # image flip left-right (probability)\nmosaic: 0.5  # image mosaic (probability)\nmixup: 0.5 # image mixup (probability)\ncopy_paste: 0.0  # segment copy-paste (probability)","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:56:20.49096Z","iopub.execute_input":"2022-02-14T02:56:20.491657Z","iopub.status.idle":"2022-02-14T02:56:20.500848Z","shell.execute_reply.started":"2022-02-14T02:56:20.49162Z","shell.execute_reply":"2022-02-14T02:56:20.499574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training\n!python train.py --img {SIZE}\\\n                --batch {BATCH_SIZE}\\\n                --epochs {EPOCHS}\\\n                --data /kaggle/working/gbr.yaml\\\n                --hyp /kaggle/working/hyp.yaml\\\n                --weights {MODEL}.pt\\\n                --workers {WORKERS}\\\n                --project {PROJECT}\\\n                --name {RUN_NAME}\\\n                --exist-ok\n","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:59:51.919582Z","iopub.execute_input":"2022-02-14T02:59:51.920152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"OUTPUT_DIR = '{}/{}'.format(PROJECT, RUN_NAME)\n!ls {OUTPUT_DIR}","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:55:51.601097Z","iopub.execute_input":"2022-02-14T02:55:51.60132Z","iopub.status.idle":"2022-02-14T02:55:52.292675Z","shell.execute_reply.started":"2022-02-14T02:55:51.601291Z","shell.execute_reply":"2022-02-14T02:55:52.291741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Change our position within the dirctory back\n# %cd /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:55:52.296251Z","iopub.execute_input":"2022-02-14T02:55:52.296494Z","iopub.status.idle":"2022-02-14T02:55:52.299648Z","shell.execute_reply.started":"2022-02-14T02:55:52.296466Z","shell.execute_reply":"2022-02-14T02:55:52.298842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # # --- Trained Model ---\n# MODEL_PATH = \"../input/reef-baseline-fold12/l6_3600_uflip_vm5_f12_up/f1/best.pt\"\n\n# # Load the model\n# model = torch.hub.load(\"../input/yolov5-lib-ds\", \"custom\",\n#                        path=MODEL_PATH,\n#                        source='local', force_reload=True)\n\n# # BoundingBox Confidence\n# model.conf = 0.01\n# # Intersection Over Union\n# model.iou = 0.5","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:55:52.305549Z","iopub.execute_input":"2022-02-14T02:55:52.305904Z","iopub.status.idle":"2022-02-14T02:55:52.31127Z","shell.execute_reply.started":"2022-02-14T02:55:52.305874Z","shell.execute_reply":"2022-02-14T02:55:52.310449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import greatbarrierreef\n\n# # Initialize the environment\n# env = greatbarrierreef.make_env()\n# # Iterator that loops through the submission dataset\n# # !!! you can run this cell only once\n# iter_test = env.iter_test()","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:55:52.313041Z","iopub.execute_input":"2022-02-14T02:55:52.313776Z","iopub.status.idle":"2022-02-14T02:55:52.322038Z","shell.execute_reply.started":"2022-02-14T02:55:52.313733Z","shell.execute_reply":"2022-02-14T02:55:52.321163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def load_model(ckpt_path, conf=0.25, iou=0.50):\n#     model = torch.hub.load('/kaggle/input/yolov5-lib-ds',\n#                            'custom',\n#                            path=ckpt_path,\n#                            source='local',\n#                            force_reload=True)  # local repo\n#     model.conf = conf  # NMS confidence threshold\n#     model.iou  = iou  # NMS IoU threshold\n#     model.classes = None   # (optional list) filter by class, i.e. = [0, 15, 16] for persons, cats and dogs\n#     model.multi_label = False  # NMS multiple labels per box\n#     model.max_det = 1000  # maximum number of detections per image\n#     return model","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:55:52.323174Z","iopub.execute_input":"2022-02-14T02:55:52.323741Z","iopub.status.idle":"2022-02-14T02:55:52.33129Z","shell.execute_reply.started":"2022-02-14T02:55:52.323703Z","shell.execute_reply":"2022-02-14T02:55:52.330518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ROOT_DIR  = '/kaggle/input/tensorflow-great-barrier-reef/'\n# # CKPT_DIR  = '/kaggle/input/greatbarrierreef-yolov5-train-ds'\n# CKPT_PATH = '/kaggle/input/reef-baseline-fold12/l6_3600_uflip_vm5_f12_up/f1/best.pt' # by @steamedsheep\n# IMG_SIZE  = 9000\n# CONF      = 0.25\n# IOU       = 0.40\n# AUGMENT   = True","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:55:52.332425Z","iopub.execute_input":"2022-02-14T02:55:52.333257Z","iopub.status.idle":"2022-02-14T02:55:52.339698Z","shell.execute_reply.started":"2022-02-14T02:55:52.333219Z","shell.execute_reply":"2022-02-14T02:55:52.338841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def predict(model, img, size=768, augment=False):\n#     height, width = img.shape[:2]\n#     results = model(img, size=size, augment=augment)  # custom inference size\n#     preds   = results.pandas().xyxy[0]\n#     bboxes  = preds[['xmin','ymin','xmax','ymax']].values\n#     if len(bboxes):\n#         bboxes  = voc2coco(bboxes,height,width).astype(int)\n#         confs   = preds.confidence.values\n#         return bboxes, confs\n#     else:\n#         return [],[]\n    \n# def format_prediction(bboxes, confs):\n#     annot = ''\n#     if len(bboxes)>0:\n#         for idx in range(len(bboxes)):\n#             xmin, ymin, w, h = bboxes[idx]\n#             conf             = confs[idx]\n#             annot += f'{conf} {xmin} {ymin} {w} {h}'\n#             annot +=' '\n#         annot = annot.strip(' ')\n#     return annot\n\n# def show_img(img, bboxes, bbox_format='yolo'):\n#     names  = ['starfish']*len(bboxes)\n#     labels = [0]*len(bboxes)\n#     img    = draw_bboxes(img = img,\n#                            bboxes = bboxes, \n#                            classes = names,\n#                            class_ids = labels,\n#                            class_name = True, \n#                            colors = colors, \n#                            bbox_format = bbox_format,\n#                            line_thickness = 2)\n#     return Image.fromarray(img).resize((800, 400))","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:55:52.342217Z","iopub.execute_input":"2022-02-14T02:55:52.343922Z","iopub.status.idle":"2022-02-14T02:55:52.349246Z","shell.execute_reply.started":"2022-02-14T02:55:52.343883Z","shell.execute_reply":"2022-02-14T02:55:52.348252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = load_model(CKPT_PATH, conf=CONF, iou=IOU)\n# for idx, (img, pred_df) in enumerate(tqdm(iter_test)):\n#     bboxes, confs  = predict(model, img, size=IMG_SIZE, augment=AUGMENT)\n#     annot          = format_prediction(bboxes, confs)\n#     pred_df['annotations'] = annot\n#     env.predict(pred_df)\n#     if idx<3:\n#         display(show_img(img, bboxes, bbox_format='coco'))","metadata":{"execution":{"iopub.status.busy":"2022-02-14T02:55:52.350732Z","iopub.execute_input":"2022-02-14T02:55:52.351029Z","iopub.status.idle":"2022-02-14T02:55:52.359469Z","shell.execute_reply.started":"2022-02-14T02:55:52.350993Z","shell.execute_reply":"2022-02-14T02:55:52.358625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}