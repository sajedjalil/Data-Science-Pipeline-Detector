{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\nSince the competition is now over, I want to share my (hopefully **silver**, or bronze) solution. My agent is an ensemble of 3 IL agents, I borrowed that idea from the [lux-ai-with-il-ensemble-of-models](https://www.kaggle.com/realneuralnetwork/lux-ai-with-il-ensemble-of-models) notebook but instead of choosing the most common action, I take the softmax function and choose the action with highest probability. 3 IL models are:\n- [lux-ai-with-il-decreasing-learning-rate](https://www.kaggle.com/realneuralnetwork/lux-ai-with-il-decreasing-learning-rate) \n- [toad model from the orginal ensemble notebook](https://www.kaggle.com/realneuralnetwork/lux-ai-with-il-ensemble-of-models) I tried to use many different models but somehow this one gave the best performance\n- [unet immitation learning](https://www.kaggle.com/bachngoh/luxai-unet-immitationlearning-lb-1100) I was inspired by [this](https://www.kaggle.com/c/lux-ai-2021/discussion/289540) amazing post by nosound.\n\nI also use unet to train the city tile actions:\n- [unet for ctiles](https://www.kaggle.com/bachngoh/luxai-unet-for-ctiles)","metadata":{}},{"cell_type":"code","source":"!pip install kaggle-environments -U > /dev/null 2>&1\n!cp -r ../input/lux-ai-2021/* .","metadata":{"execution":{"iopub.status.busy":"2021-12-07T13:21:36.337846Z","iopub.execute_input":"2021-12-07T13:21:36.338164Z","iopub.status.idle":"2021-12-07T13:21:44.128457Z","shell.execute_reply.started":"2021-12-07T13:21:36.338133Z","shell.execute_reply":"2021-12-07T13:21:44.127366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport json\nfrom pathlib import Path\nimport os\nimport random\nfrom tqdm.notebook import tqdm\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-07T13:21:44.132196Z","iopub.execute_input":"2021-12-07T13:21:44.132478Z","iopub.status.idle":"2021-12-07T13:21:44.140279Z","shell.execute_reply.started":"2021-12-07T13:21:44.132435Z","shell.execute_reply":"2021-12-07T13:21:44.139183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[lux-ai-with-il-decreasing-learning-rate](https://www.kaggle.com/realneuralnetwork/lux-ai-with-il-decreasing-learning-rate) amazing notebook!","metadata":{}},{"cell_type":"code","source":"model = torch.jit.load(\"../input/lux-ai-with-il-decreasing-learning-rate/model.pth\")\nmodel.eval()\ntraced = torch.jit.trace(model.cpu(), torch.rand(1, 20, 32, 32))\ntraced.save('model_il.pth')","metadata":{"execution":{"iopub.status.busy":"2021-12-07T13:06:04.863949Z","iopub.execute_input":"2021-12-07T13:06:04.864737Z","iopub.status.idle":"2021-12-07T13:06:04.927806Z","shell.execute_reply.started":"2021-12-07T13:06:04.864694Z","shell.execute_reply":"2021-12-07T13:06:04.925964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torch.jit.load(\"../input/models-lux/model_toad.pth\")\nmodel.eval()\ntraced = torch.jit.trace(model.cpu(), torch.rand(1, 20, 32, 32))\ntraced.save('model_toad.pth')","metadata":{"execution":{"iopub.status.busy":"2021-12-07T13:06:05.512802Z","iopub.execute_input":"2021-12-07T13:06:05.513228Z","iopub.status.idle":"2021-12-07T13:06:05.564706Z","shell.execute_reply.started":"2021-12-07T13:06:05.513199Z","shell.execute_reply":"2021-12-07T13:06:05.563796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"model = torch.jit.load(\"../input/d/bachngoh/luxai-models/submission_unet_v6_updated_ctile/model.pth\")\nmodel.eval()\ntraced = torch.jit.trace(model.cpu(), (torch.rand(1, 14, 32, 32), torch.rand(1,14,4,4)))\ntraced.save('model_unet.pth')","metadata":{"execution":{"iopub.status.busy":"2021-12-07T13:01:49.349431Z","iopub.execute_input":"2021-12-07T13:01:49.349711Z","iopub.status.idle":"2021-12-07T13:01:50.274563Z","shell.execute_reply.started":"2021-12-07T13:01:49.349684Z","shell.execute_reply":"2021-12-07T13:01:50.273894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torch.jit.load(\"../input/d/bachngoh/luxai-models/submission_unet_v6_updated_ctile/model_ct.pth\")\nmodel.eval()\ntraced = torch.jit.trace(model.cpu(), (torch.rand(1, 14, 32, 32), torch.rand(1,14,4,4)))\ntraced.save('model_unet_ct.pth')","metadata":{"execution":{"iopub.status.busy":"2021-12-07T13:01:50.277143Z","iopub.execute_input":"2021-12-07T13:01:50.277887Z","iopub.status.idle":"2021-12-07T13:01:51.121301Z","shell.execute_reply.started":"2021-12-07T13:01:50.277848Z","shell.execute_reply":"2021-12-07T13:01:51.120525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"%%writefile agent.py\nimport os\nimport numpy as np\nimport torch\nfrom lux.game import Game\nfrom collections import Counter\nfrom torch import nn\n\n\npath = '/kaggle_simulations/agent' if os.path.exists('/kaggle_simulations') else '.'\n\nmodel = torch.jit.load(f\"{path}/model_il.pth\")\nmodel.eval()\n\nmodel2 = torch.jit.load(f\"{path}/model_unet.pth\")\nmodel2.eval()\n\nmodel4 = torch.jit.load(f\"{path}/model_toad.pth\")\nmodel4.eval()\n\nmodel_ct = torch.jit.load(f\"{path}/model_unet_ct.pth\")\nmodel_ct.eval()\n\n\ndef make_input(obs, unit_id):\n    width, height = obs['width'], obs['height']\n    x_shift = (32 - width) // 2\n    y_shift = (32 - height) // 2\n    cities = {}\n    \n    b = np.zeros((20, 32, 32), dtype=np.float32)\n    \n    for update in obs['updates']:\n        strs = update.split(' ')\n        input_identifier = strs[0]\n        \n        if input_identifier == 'u':\n            x = int(strs[4]) + x_shift\n            y = int(strs[5]) + y_shift\n            wood = int(strs[7])\n            coal = int(strs[8])\n            uranium = int(strs[9])\n            if unit_id == strs[3]:\n                # Position and Cargo\n                b[:2, x, y] = (\n                    1,\n                    (wood + coal + uranium) / 100\n                )\n            else:\n                # Units\n                team = int(strs[2])\n                cooldown = float(strs[6])\n                idx = 2 + (team - obs['player']) % 2 * 3\n                b[idx:idx + 3, x, y] = (\n                    1,\n                    cooldown / 6,\n                    (wood + coal + uranium) / 100\n                )\n        elif input_identifier == 'ct':\n            # CityTiles\n            team = int(strs[1])\n            city_id = strs[2]   \n            x = int(strs[3]) + x_shift\n            y = int(strs[4]) + y_shift\n            idx = 8 + (team - obs['player']) % 2 * 2\n            b[idx:idx + 2, x, y] = (\n                1,\n                cities[city_id]\n            )\n        elif input_identifier == 'r':\n            # Resources\n            r_type = strs[1]\n            x = int(strs[2]) + x_shift\n            y = int(strs[3]) + y_shift\n            amt = int(float(strs[4]))\n            b[{'wood': 12, 'coal': 13, 'uranium': 14}[r_type], x, y] = amt / 800\n        elif input_identifier == 'rp':\n            # Research Points\n            team = int(strs[1])\n            rp = int(strs[2])\n            b[15 + (team - obs['player']) % 2, :] = min(rp, 200) / 200\n        elif input_identifier == 'c':\n            # Cities\n            city_id = strs[2]\n            fuel = float(strs[3])\n            lightupkeep = float(strs[4])\n            cities[city_id] = min(fuel / lightupkeep, 10) / 10\n    \n    # Day/Night Cycle\n    b[17, :] = obs['step'] % 40 / 40\n    # Turns\n    b[18, :] = obs['step'] / 360\n    # Map Size\n    b[19, x_shift:32 - x_shift, y_shift:32 - y_shift] = 1\n\n    return b\n\ndef make_input_unet(obs):\n    width, height = obs['width'], obs['height']\n    x_shift = (32 - width) // 2\n    y_shift = (32 - height) // 2\n    cities = {}\n    global_features = np.zeros((14,4,4))\n    \n    b = np.zeros((14, 32, 32), dtype=np.float32)\n    \n    friendly_unit_cnt = 0\n    opponent_unit_cnt = 0\n    friendly_ctile_cnt = 0\n    opponent_ctile_cnt = 0\n    total_wood = 0\n    total_coal = 0\n    total_uranium = 0\n    \n    can_mine_coal = 0\n    can_mine_uranium = 0\n    \n    for update in obs['updates']:\n        strs = update.split(' ')\n        input_identifier = strs[0]\n        \n        if input_identifier == 'u':\n            \n            x = int(strs[4]) + x_shift\n            y = int(strs[5]) + y_shift\n            wood = int(strs[7])\n            coal = int(strs[8])\n            uranium = int(strs[9])\n            \n            # Units\n            team = int(strs[2])\n            \n            if (team - obs['player']) % 2 == 0:\n                friendly_unit_cnt += 1\n            else:\n                opponent_unit_cnt += 1\n            \n            cooldown = float(strs[6])\n            idx = (team - obs['player']) % 2 * 3\n            b[idx:idx + 3, x, y] = (\n                1,\n                cooldown / 6,\n                (wood + coal + uranium) / 100\n            )\n        elif input_identifier == 'ct':\n            # CityTiles\n            \n            team = int(strs[1])\n            \n            if (team - obs['player']) % 2 == 0:\n                friendly_ctile_cnt += 1\n            else:\n                opponent_ctile_cnt += 1\n            \n            city_id = strs[2]\n            x = int(strs[3]) + x_shift\n            y = int(strs[4]) + y_shift\n            idx = 6 + (team - obs['player']) % 2 * 2\n            b[idx:idx + 2, x, y] = (\n                1,\n                cities[city_id]\n            )\n        elif input_identifier == 'r':\n            # Resources\n            r_type = strs[1]\n            x = int(strs[2]) + x_shift\n            y = int(strs[3]) + y_shift\n            amt = int(float(strs[4]))\n            b[{'wood': 10, 'coal': 11, 'uranium': 12}[r_type], x, y] = amt / 800\n            if r_type == 'wood': total_wood += amt\n            elif r_type == 'coal': total_coal += amt\n            elif r_type == 'uranium': total_uranium += amt\n            \n        elif input_identifier == 'rp':\n            # Research Points\n            team = int(strs[1])\n            rp = int(strs[2])\n            if team - obs['player'] % 2 == 0:\n                if rp >= 50:\n                    can_mine_coal = 1\n                if rp >= 200:\n                    can_mine_uranium = 1\n            \n            global_features[(team - obs['player']) % 2, :] = min(rp, 200) / 200\n        elif input_identifier == 'c':\n            # Cities\n            city_id = strs[2]\n            fuel = float(strs[3])\n            lightupkeep = float(strs[4])\n            cities[city_id] = min(fuel / lightupkeep, 10) / 10\n    \n    # Day/Night Cycle\n    global_features[2, :] = obs['step'] % 40 / 40\n    # Turns\n    global_features[3, :] = obs['step'] / 360\n    # Number of friendly unit \n    global_features[4, :] = friendly_unit_cnt / 50\n    # Number of opponent unit\n    global_features[5, :] = opponent_unit_cnt / 50\n    # Number of friendly ctiles\n    global_features[6, :] = friendly_ctile_cnt / 50\n    # Number of opponent unit\n    global_features[7, :] = opponent_ctile_cnt / 50\n    # Total Wood\n    global_features[8, :] = total_wood / 24000\n    # Total Coal\n    global_features[9, :] = total_coal / 24000\n    # Total Uranium\n    global_features[10, :] = total_uranium / 12000\n    global_features[11, :] = can_mine_coal\n    global_features[12, :] = can_mine_uranium\n    # Map Size\n    global_features[13, :] = width \n    \n    # Map Size\n    b[13, x_shift:32 - x_shift, y_shift:32 - y_shift] = 1\n\n    return b, global_features\n\n\ngame_state = None\ndef get_game_state(observation):\n    global game_state\n    \n    if observation[\"step\"] == 0:\n        game_state = Game()\n        game_state._initialize(observation[\"updates\"])\n        game_state._update(observation[\"updates\"][2:])\n        game_state.id = observation[\"player\"]\n    else:\n        game_state._update(observation[\"updates\"])\n    return game_state\n\n\ndef in_city(pos):    \n    try:\n        city = game_state.map.get_cell_by_pos(pos).citytile\n        return city is not None and city.team == game_state.id\n    except:\n        return False\n\n\ndef call_func(obj, method, args=[]):\n    return getattr(obj, method)(*args)\n\n\nunit_actions = [('move', 'n'), ('move', 's'), ('move', 'w'), ('move', 'e'), ('build_city',)]\ndef get_action(policy, unit, dest):\n\n    for label in np.argsort(policy)[::-1]:\n        act = unit_actions[label]\n        pos = unit.pos.translate(act[-1], 1) or unit.pos\n        if pos not in dest or in_city(pos):\n            return call_func(unit, *act), pos \n            \n    return unit.move('c'), unit.pos\n\ndef get_action_unet(policy, unit, dest, shift):\n    logits = nn.Softmax(policy[:, unit.pos.x + shift, unit.pos.y + shift] )\n    action = unet_unit_actions[ np.argmax( policy[:, unit.pos.x + shift, unit.pos.y + shift] )]\n    pos = unit.pos.translate(action[-1], 1) or unit.pos\n    if pos not in dest or in_city(pos):\n        return call_func(unit, *action), pos\n    \n    return unit.move('c'), unit.pos \n\ndef get_shift(observation):\n    width, height = observation['width'], observation['height']\n    shift = (32 - width) // 2\n    return shift\n\n\ndef agent(observation, configuration):\n    global game_state\n    \n    game_state = get_game_state(observation)    \n    player = game_state.players[observation.player]\n    actions = []\n    \n    shift = get_shift(observation)\n    #print(shift)\n    state_1, state_2 = make_input_unet(observation)\n    with torch.no_grad():\n        p_ct = model_ct(torch.from_numpy(state_1).unsqueeze(0).float(), torch.from_numpy(state_2).unsqueeze(0).float())\n        policy_ct = p_ct.squeeze(0).numpy()\n        \n    # City Actions\n    unit_count = len(player.units)\n    for city in player.cities.values():\n        for city_tile in city.citytiles:\n            if city_tile.can_act():\n                action = np.argmax( policy_ct[:, city_tile.pos.x + shift, city_tile.pos.y + shift] )\n                if action == 0:\n                    actions.append(city_tile.research())\n                    player.research_points += 1\n                elif action == 1:\n                    actions.append(city_tile.build_worker())\n                    unit_count += 1\n    \n    # Worker Actions\n    dest = []\n\n    with torch.no_grad():\n        p1 = model2(torch.from_numpy(state_1).unsqueeze(0).float(), torch.from_numpy(state_2).unsqueeze(0).float())\n        policy_unet = p1.squeeze(0).numpy()\n\n    \n    for unit in player.units:\n        if unit.can_act() and (game_state.turn % 40 < 30 or not in_city(unit.pos)):\n            state = make_input(observation, unit.id)\n            with torch.no_grad():\n                p = model(torch.from_numpy(state).unsqueeze(0))\n            \n                p2 = model4(torch.from_numpy(state).unsqueeze(0))\n\n            policy = p.squeeze(0).numpy()\n            policy2 = policy_unet[:, unit.pos.x + shift, unit.pos.y + shift] \n            policy4 = p2.squeeze(0).numpy()\n\n            softmax = nn.Softmax(dim=0)\n            logits1 = softmax(torch.from_numpy(policy))\n            logits2 = softmax(torch.from_numpy(policy2))\n            logits4 = softmax(torch.from_numpy(policy4))\n\n            ensemble_logits = np.array( logits1 * 0.4 + logits2 * 0.4 + logits4 * 0.2)\n\n            action, pos = get_action(policy, unit, dest)\n\n            actions.append(action)\n            dest.append(pos)\n\n    return actions","metadata":{"execution":{"iopub.status.busy":"2021-12-07T13:08:24.544861Z","iopub.execute_input":"2021-12-07T13:08:24.545184Z","iopub.status.idle":"2021-12-07T13:08:24.556781Z","shell.execute_reply.started":"2021-12-07T13:08:24.545152Z","shell.execute_reply":"2021-12-07T13:08:24.555933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_environments import make\n\nenv = make(\"lux_ai_2021\", configuration={\"width\": 24, \"height\": 24, \"loglevel\": 0, \"annotations\": True}, debug=True)\nsteps = env.run(['agent.py', 'agent.py'])\nenv.render(mode=\"ipython\", width=1200, height=800)","metadata":{"execution":{"iopub.status.busy":"2021-12-07T13:08:25.26334Z","iopub.execute_input":"2021-12-07T13:08:25.264146Z","iopub.status.idle":"2021-12-07T13:11:13.98315Z","shell.execute_reply.started":"2021-12-07T13:08:25.264102Z","shell.execute_reply":"2021-12-07T13:11:13.982518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!tar -czf submission.tar.gz *","metadata":{"execution":{"iopub.status.busy":"2021-12-07T13:11:13.984295Z","iopub.execute_input":"2021-12-07T13:11:13.984921Z","iopub.status.idle":"2021-12-07T13:11:18.886542Z","shell.execute_reply.started":"2021-12-07T13:11:13.984864Z","shell.execute_reply":"2021-12-07T13:11:18.885503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}