{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Solved (EDIT) \n\nit was never an issue with timing out, I was unaware I could get errorlogs from failed submissions (new to this). Should note that running locally the `lux-ai-2021` command doesn't give the 60s for the first submission I don't think. so use `--maxtime` to set the buffer higher if necessary. \n\nThis Notebook is prepared to attempt to debug the Issue raised in the discussion, https://www.kaggle.com/c/lux-ai-2021/discussion/277324, it's a notebook based of Imitation learning notebook, https://www.kaggle.com/shoheiazuma/lux-ai-with-imitation-learning. \n\nThe Issue at hand is that importing `Tensorflow` or `tf.keras.models.load_model` takes over 3s, which appears to cause a timeout on the first turn, implying that the 60s allowed for imports on the first call isn't being invoked\n","metadata":{}},{"cell_type":"markdown","source":"If Anyone had experienced something similar. would appreciate any comments on how to fix this issue","metadata":{}},{"cell_type":"code","source":"!pip install tensorflow==2.3\n#!git clone https://github.com/Lux-AI-Challenge/Lux-Design-2021","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# create simple model and prepare data","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Activation, Dropout\nfrom tensorflow.keras.optimizers import Adam\nimport numpy as np\nfrom collections import deque\nimport json \nfrom pathlib import Path\nimport os\nimport random\nfrom tqdm.notebook import tqdm\nimport sys\n\n\n#preprocessing SAZUMA Kaggle notebook\ndef to_label(action):\n    strs = action.split(' ')\n    unit_id = strs[1]\n    if strs[0] == 'm':\n        label = {'c': None, 'n': 0, 's': 1, 'w': 2, 'e': 3}[strs[2]]\n    elif strs[0] == 'bcity':\n        label = 4\n    else:\n        label = None\n    return unit_id, label\n\n\ndef depleted_resources(obs):\n    for u in obs['updates']:\n        if u.split(' ')[0] == 'r':\n            return False\n    return True\n\n\"\"\"\ncreate dataset from the episodes, \nsamples = list of tuples [(observation_id, unit_id (e.g worker id), label/action (e.g move West)), ...]\n\"\"\"\n\n\ndef create_dataset_from_json(episode_dir, team_name='Toad Brigade'):\n    obses = {}\n    samples = []\n    append = samples.append\n    #prepend with 5.json to select only certain epsisodes for memory purpose\n    #full version should use tf.Dataset and *.json to take all the episodes\n    episodes = [path for path in Path(episode_dir).glob('*5.json') if 'replay' not in path.name]\n    print(episodes[1])\n    for filepath in tqdm(episodes):\n        with open(filepath) as f:\n            json_load = json.load(f)\n        ep_id = json_load['info']['EpisodeId']\n        index = np.argmax([r or 0 for r in json_load['rewards']])\n        if json_load['info']['TeamNames'][index] != team_name:\n            continue\n\n        for i in range(len(json_load['steps'])-1):\n            if json_load['steps'][i][index]['status'] == 'ACTIVE':\n                actions = json_load['steps'][i+1][index]['action']\n                obs = json_load['steps'][i][0]['observation']\n\n                if depleted_resources(obs):\n                    break\n\n                obs['player'] = index\n                obs = dict([\n                    (k,v) for k,v in obs.items()\n                    if k in ['step', 'updates', 'player', 'width', 'height']\n                ])\n                obs_id = f'{ep_id}_{i}'\n                obses[obs_id] = obs\n\n                for action in actions:\n                    unit_id, label = to_label(action)\n                    if label is not None:\n                        append((obs_id, unit_id, label))\n\n    return obses, samples\n\n##Test above funcs\nobses, samples = create_dataset_from_json('../input/lux-ai-episodes/')\nprint(type(samples[0]))\nprint(samples[0])\ncount = 0\nfor _,value in obses.items():\n\t\tprint(value['updates'])\n\t\tif count > 0:\n\t\t\t\tbreak\n\t\tcount +=1 \n\n\nlabels = [sample[-1] for sample in samples]\nactions = ['North', 'South', 'West', 'East', 'Build_City']\nfor value, count in zip(*np.unique(labels, return_counts=True)):\n\t\tprint(f'{actions[value]:^5}: {count:>3}')\n\nprint(set(labels))\n\n# Input for Neural Network\ndef make_input(obs, unit_id):\n    width, height = obs['width'], obs['height']\n    x_shift = (32 - width) // 2\n    y_shift = (32 - height) // 2\n    cities = {}\n    \n    b = np.zeros((20, 32, 32), dtype=np.float32)\n    \n    for update in obs['updates']:\n        strs = update.split(' ')\n        input_identifier = strs[0]\n        \n        if input_identifier == 'u':\n            x = int(strs[4]) + x_shift\n            y = int(strs[5]) + y_shift\n            wood = int(strs[7])\n            coal = int(strs[8])\n            uranium = int(strs[9])\n            if unit_id == strs[3]:\n                # Position and Cargo\n                b[:2, x, y] = (\n                    1,\n                    (wood + coal + uranium) / 100\n                )\n            else:\n                # Units\n                team = int(strs[2])\n                cooldown = float(strs[6])\n                idx = 2 + (team - obs['player']) % 2 * 3\n                b[idx:idx + 3, x, y] = (\n                    1,\n                    cooldown / 6,\n                    (wood + coal + uranium) / 100\n                )\n        elif input_identifier == 'ct':\n            # CityTiles\n            team = int(strs[1])\n            city_id = strs[2]\n            x = int(strs[3]) + x_shift\n            y = int(strs[4]) + y_shift\n            idx = 8 + (team - obs['player']) % 2 * 2\n            b[idx:idx + 2, x, y] = (\n                1,\n                cities[city_id]\n            )\n        elif input_identifier == 'r':\n            # Resources\n            r_type = strs[1]\n            x = int(strs[2]) + x_shift\n            y = int(strs[3]) + y_shift\n            amt = int(float(strs[4]))\n            b[{'wood': 12, 'coal': 13, 'uranium': 14}[r_type], x, y] = amt / 800\n        elif input_identifier == 'rp':\n            # Research Points\n            team = int(strs[1])\n            rp = int(strs[2])\n            b[15 + (team - obs['player']) % 2, :] = min(rp, 200) / 200\n        elif input_identifier == 'c':\n            # Cities\n            city_id = strs[2]\n            fuel = float(strs[3])\n            lightupkeep = float(strs[4])\n            cities[city_id] = min(fuel / lightupkeep, 10) / 10\n    \n    # Day/Night Cycle\n    b[17, :] = obs['step'] % 40 / 40\n    # Turns\n    b[18, :] = obs['step'] / 360\n    # Map Size\n    b[19, x_shift:32 - x_shift, y_shift:32 - y_shift] = 1\n\n    return b\n\n\ndef create_model(n_features, n_actions):\n\tmodel = Sequential()\n\tmodel.add(Conv2D(32, (3, 3), input_shape = (20,32,32)))\n\tmodel.add(Activation('relu'))\n\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\tmodel.add(Dropout(0.2))\n\tmodel.add(tf.keras.layers.Flatten())\n\tmodel.add(tf.keras.layers.Dense(20, activation = 'linear'))\n\tmodel.add(tf.keras.layers.Dense(n_actions, activation = 'softmax'))\n\tmodel.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = Adam(learning_rate = .001))\n\treturn model\nfrom matplotlib import pyplot\n\ndef train_model(model, inputs, output, batch_size, epochs, val_in, val_out):\n\t\tmc = tf.keras.callbacks.ModelCheckpoint('best_model', monitor = 'val_loss', save_best_only = True, save_weights_only = True)\n\t\thistory = model.fit(inputs, output, batch_size = batch_size, epochs = epochs, validation_data = (val_in, val_out), verbose = 1)\n\t\ttf.keras.models.save_model(model, \"model\")\n\t\tpyplot.subplot(211)\n\t\tpyplot.title('Loss ')\n\t\tpyplot.plot(history.history['loss'],label='train')\n\t\tpyplot.plot(history.history['val_loss'],label='test')\n\t\tpyplot.legend()\n\n\t\tpyplot.subplot(212)\n\t\tpyplot.title('Accuracy ')\n\t\tpyplot.plot(history.history['accuracy'],label='train')\n\t\tpyplot.plot(history.history['val_accuracy'],label='test')\n\t\tpyplot.legend()\n\t\tpyplot.show()\n\nfrom sklearn.model_selection import train_test_split\n\ntrain_samples, val_samples = train_test_split(samples, test_size=.15, random_state = 8, stratify = labels)\n\ndef prep(samples):\n\n\tinput_matrix = []\n\toutput = []\n\tfor (obs_id, unit_id, action) in samples:\n\t\t\tobs = obses[obs_id]\n\t\t\tinput_matrix.append(make_input(obs, unit_id))\n\t\t\tout = []\n\t\t\tfor i in range(0,5):\n\t\t\t\t\tif i == action:\n\t\t\t\t\t\t\tout.append(1)\n\t\t\t\t\telse:\n\t\t\t\t\t\t\tout.append(0)\n\t\t\toutput.append(np.array(out))\n\treturn input_matrix, output\t\n\ntrain_x, train_y = prep(train_samples)\nval_x, val_y = prep(val_samples)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-14T11:20:09.388349Z","iopub.execute_input":"2021-10-14T11:20:09.388604Z","iopub.status.idle":"2021-10-14T11:20:34.11217Z","shell.execute_reply.started":"2021-10-14T11:20:09.38857Z","shell.execute_reply":"2021-10-14T11:20:34.111186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Model","metadata":{}},{"cell_type":"code","source":"\nmodel = create_model(20, 5)\nhistory = train_model(model, np.array(train_x), np.array(train_y), 64, 8, np.array(val_x), np.array(val_y))\n","metadata":{"execution":{"iopub.status.busy":"2021-10-14T11:20:34.115031Z","iopub.execute_input":"2021-10-14T11:20:34.115358Z","iopub.status.idle":"2021-10-14T11:22:05.204619Z","shell.execute_reply.started":"2021-10-14T11:20:34.115317Z","shell.execute_reply":"2021-10-14T11:22:05.204019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# install kaggle-environments to run the games","metadata":{}},{"cell_type":"code","source":"!pip install kaggle-environments -U > /dev/null 2>&1\n!cp -r ../input/lux-ai-2021/* .\n","metadata":{"execution":{"iopub.status.busy":"2021-10-14T11:22:05.205803Z","iopub.execute_input":"2021-10-14T11:22:05.206179Z","iopub.status.idle":"2021-10-14T11:22:14.227171Z","shell.execute_reply.started":"2021-10-14T11:22:05.206151Z","shell.execute_reply":"2021-10-14T11:22:14.22608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Overwrite agent.py and main.py","metadata":{}},{"cell_type":"code","source":"%%writefile agent.py\n\nimport time\nt1 = time.time()\nimport math, sys\nfrom lux.game import Game\nimport numpy as np\nfrom tensorflow.keras.models import load_model\nimport os\n\n\ngame_state = None\n#print(time.time() - t1, file=sys.stderr)\n\n\n# Input for Neural Network\ndef make_input(obs, unit_id):\n    width, height = obs['width'], obs['height']\n    x_shift = (32 - width) // 2\n    y_shift = (32 - height) // 2\n    cities = {}\n    \n    b = np.zeros((20, 32, 32), dtype=np.float32)\n    \n    for update in obs['updates']:\n        strs = update.split(' ')\n        input_identifier = strs[0]\n        \n        if input_identifier == 'u':\n            x = int(strs[4]) + x_shift\n            y = int(strs[5]) + y_shift\n            wood = int(strs[7])\n            coal = int(strs[8])\n            uranium = int(strs[9])\n            if unit_id == strs[3]:\n                # Position and Cargo\n                b[:2, x, y] = (\n                    1,\n                    (wood + coal + uranium) / 100\n                )\n            else:\n                # Units\n                team = int(strs[2])\n                cooldown = float(strs[6])\n                idx = 2 + (team - obs['player']) % 2 * 3\n                b[idx:idx + 3, x, y] = (\n                    1,\n                    cooldown / 6,\n                    (wood + coal + uranium) / 100\n                )\n        elif input_identifier == 'ct':\n            # CityTiles\n            team = int(strs[1])\n            city_id = strs[2]\n            x = int(strs[3]) + x_shift\n            y = int(strs[4]) + y_shift\n            idx = 8 + (team - obs['player']) % 2 * 2\n            b[idx:idx + 2, x, y] = (\n                1,\n                cities[city_id]\n            )\n        elif input_identifier == 'r':\n            # Resources\n            r_type = strs[1]\n            x = int(strs[2]) + x_shift\n            y = int(strs[3]) + y_shift\n            amt = int(float(strs[4]))\n            b[{'wood': 12, 'coal': 13, 'uranium': 14}[r_type], x, y] = amt / 800\n        elif input_identifier == 'rp':\n            # Research Points\n            team = int(strs[1])\n            rp = int(strs[2])\n            b[15 + (team - obs['player']) % 2, :] = min(rp, 200) / 200\n        elif input_identifier == 'c':\n            # Cities\n            city_id = strs[2]\n            fuel = float(strs[3])\n            lightupkeep = float(strs[4])\n            cities[city_id] = min(fuel / lightupkeep, 10) / 10\n    \n    # Day/Night Cycle\n    b[17, :] = obs['step'] % 40 / 40\n    # Turns\n    b[18, :] = obs['step'] / 360\n    # Map Size\n    b[19, x_shift:32 - x_shift, y_shift:32 - y_shift] = 1\n\n    return b\n\ndef in_city(pos):    \n    try:\n        city = game_state.map.get_cell_by_pos(pos).citytile\n        return city is not None and city.team == game_state.id\n    except:\n        return False\n\n\ndef call_func(obj, method, args=[]):\n    return getattr(obj, method)(*args)\n\n\nunit_actions = [('move', 'n'), ('move', 's'), ('move', 'w'), ('move', 'e'), ('build_city',)]\n\ndef get_action(policy, unit, dest):\n    for label in np.argsort(policy)[::-1]:\n        act = unit_actions[label]\n        pos = unit.pos.translate(act[-1], 1) or unit.pos\n        if pos not in dest or in_city(pos):\n            return call_func(unit, *act), pos \n            \n    return unit.move('c'), unit.pos\n#print(f\"{time.time() - t1} test\")\nprint(time.time() - t1, file=sys.stderr)\npath = '/kaggle_simulations/agent' if os.path.exists('/kaggle_simulations') else '.'\nprint(f\"path is {path}\", file=sys.stderr)\nmodel = load_model(f\"{path}/model\")\ndef agent(observation, configuration):\n\tglobal game_state\n\tprint(\"agent Called\", file=sys.stderr)\n\n\t\n\t### Do not edit ###\n\tif observation[\"step\"] == 0:\n\t\tgame_state = Game()\n\t\tgame_state._initialize(observation[\"updates\"])\n\t\tgame_state._update(observation[\"updates\"][2:])\n\t\tgame_state.id = observation.player\n\telse:\n\t\tgame_state._update(observation[\"updates\"])\n    \n\tactions = []\n\n    ### AI Code goes down here! ### \n\tplayer = game_state.players[observation.player]\n\topponent = game_state.players[(observation.player + 1) % 2]\n\twidth, height = game_state.map.width, game_state.map.height\n\n\t\n\t\"\"\"when we get here we should have trained the DQN on games so when we actually play \n\twe loop through the available units (player, citytiles, Carts) and call model(cart/worker/citytile)\n\tto get which action each tile should take ????\"\"\"\n#\tt1 = time.time()\n\tunit_count = len(player.units)\n\tfor city in player.cities.values():\n\t\t\tfor citytile in city.citytiles:\n\t\t\t\t\tif citytile.can_act():\n\t\t\t\t\t\t\tif unit_count < player.city_tile_count:\n\t\t\t\t\t\t\t\t\tactions.append(citytile.build_worker())\n\t\t\t\t\t\t\t\t\tunit_count += 1\n\t\t\t\t\t\t\telif not player.researched_uranium():\n\t\t\t\t\t\t\t\t\tactions.append(citytile.research())\n\t\t\t\t\t\t\t\t\tplayer.research_points += 1\n\n\t\n\tdest = []\n\tfor unit in player.units:\n\t\tif unit.can_act() and (game_state.turn % 40 < 30 or not in_city(unit.pos)):\n\t\t\t\tstate = make_input(observation, unit.id)\n\t\t\t\tstate1 = np.reshape(state, (1,20,32,32))\n\t\t\t\tpolicy = model.predict(state1)\n\t\t\t\ttm2 = time.time()\n\t\t\t\taction, pos = get_action(policy[0], unit, dest)\n\t\t\t\tactions.append(action)\n\t\t\t\tdest.append(pos)\n\n\treturn actions\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-14T11:22:14.229895Z","iopub.execute_input":"2021-10-14T11:22:14.230319Z","iopub.status.idle":"2021-10-14T11:22:14.242943Z","shell.execute_reply.started":"2021-10-14T11:22:14.230265Z","shell.execute_reply":"2021-10-14T11:22:14.242358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Run the game using `make`, this runs perfectly fine with no timeouts.","metadata":{}},{"cell_type":"code","source":"%%writefile main.py\n\nimport time\nt1 = time.time()\nfrom typing import Dict\nimport sys\nfrom agent import agent\nprint(f\"{time.time() - t1} time to load in main\", file=sys.stderr)\nif __name__ == \"__main__\":\n    \n  def read_input():\n    \"\"\"\n    Reads input from stdin\n    \"\"\"\n    try:\n      return input()\n    except EOFError as eof:\n      raise SystemExit(eof)\n  step = 0\n  class Observation(Dict[str, any]):\n    def __init__(self, player=0) -> None:\n      self.player = player\n      # self.updates = []\n      # self.step = 0\n  observation = Observation()\n  observation[\"updates\"] = []\n  observation[\"step\"] = 0\n  player_id = 0\n  count = 0\n  while True:\n    t2 = time.time()\n    inputs = read_input()\n    observation[\"updates\"].append(inputs)\n    if inputs == \"D_DONE\":\n      if step == 0:  # the codefix\n        player_id = int(observation[\"updates\"][0])\n        observation.player = player_id\n        observation[\"player\"] = player_id\n        observation[\"width\"], observation[\"height\"] = map(int, observation[\"updates\"][1].split())\n      print(f\"{time.time() - t2} time from start of loop til agent\", file=sys.stderr)\n      t3 = time.time()\n      if count < 2:\n        print(f\"{time.time() - t1}: time to {count} agent call\", file=sys.stderr)\n        count += 1\n      actions = agent(observation, None)\n      print(f\"{time.time() - t3}: Time to get agents actions\", file=sys.stderr)\n      observation[\"updates\"] = []\n      step += 1\n      observation[\"step\"] = step\n      print(\",\".join(actions))\n      print(\"D_FINISH\")\n      t1 = time.time()\n","metadata":{"execution":{"iopub.status.busy":"2021-10-14T11:22:14.244067Z","iopub.execute_input":"2021-10-14T11:22:14.244782Z","iopub.status.idle":"2021-10-14T11:22:14.262228Z","shell.execute_reply.started":"2021-10-14T11:22:14.244747Z","shell.execute_reply":"2021-10-14T11:22:14.261335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_environments import make\n\nenv = make(\"lux_ai_2021\", configuration={\"width\": 24, \"height\": 24, \"loglevel\": 2, \"annotations\": True}, debug=True)\nsteps = env.run(['agent.py', 'agent.py'])\nenv.render(mode=\"ipython\", width=800, height=600)","metadata":{"execution":{"iopub.status.busy":"2021-10-14T11:22:14.263646Z","iopub.execute_input":"2021-10-14T11:22:14.264548Z","iopub.status.idle":"2021-10-14T11:22:22.13781Z","shell.execute_reply.started":"2021-10-14T11:22:14.2645Z","shell.execute_reply":"2021-10-14T11:22:22.136572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Uncomment and run below code to see time it takes to import files in `main.py` on the first call. *will run indefinitely so must interrupt manually to stop it*","metadata":{}},{"cell_type":"code","source":"#!python3 main.py","metadata":{"execution":{"iopub.status.busy":"2021-10-14T11:22:22.139512Z","iopub.execute_input":"2021-10-14T11:22:22.140413Z","iopub.status.idle":"2021-10-14T11:22:22.143396Z","shell.execute_reply.started":"2021-10-14T11:22:22.140366Z","shell.execute_reply":"2021-10-14T11:22:22.142841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"create submission file","metadata":{}},{"cell_type":"code","source":"!tar -czvf submission.tar.gz *","metadata":{"execution":{"iopub.status.busy":"2021-10-14T12:47:30.296386Z","iopub.execute_input":"2021-10-14T12:47:30.296759Z","iopub.status.idle":"2021-10-14T12:47:35.348754Z","shell.execute_reply.started":"2021-10-14T12:47:30.296717Z","shell.execute_reply":"2021-10-14T12:47:35.347512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Trying to use `lux-ai-2021` command to help debugging, unsure how to use in Kaggle Notebook","metadata":{}},{"cell_type":"code","source":"#!lux-ai-2021 ./Lux-Design-2021/kits/python/simple/main.py ./Lux-Design-2021/kits/python/simple/main.py ","metadata":{"execution":{"iopub.status.busy":"2021-10-14T11:37:21.518395Z","iopub.execute_input":"2021-10-14T11:37:21.519414Z","iopub.status.idle":"2021-10-14T11:37:22.332024Z","shell.execute_reply.started":"2021-10-14T11:37:21.519362Z","shell.execute_reply":"2021-10-14T11:37:22.330909Z"},"trusted":true},"execution_count":null,"outputs":[]}]}