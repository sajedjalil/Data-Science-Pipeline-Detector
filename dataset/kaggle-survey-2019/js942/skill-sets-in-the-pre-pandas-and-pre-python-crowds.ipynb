{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Skills Assessment among Pre-Pandas and Pre-Python Data Science Enthusiasts\n\nKeeping skills up to date is key to staying relevant in today's fast moving tech sector.\n\nAlthough that has always been the case, the ways in which we learn and master new skills have changed. \nYesterday, we went to college and subscribed to trade journals. Today's options include a wide array of digitally delivered content, including both content to read and content to interact with. \n\nFor those still in college or recently graduated, this is not news. These groups have another advantage -- many or \nperhaps most of the *foundation technologies used in Data Science were probably introduced during their college \n(or university) \nyears*. After all, python has been around since 1989, pandas since 2008, and Kaggle itself since 2010."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\n\n#plt.rcParams[\"figure.figsize\"]=24,20\n\n# Basic chart\n# initialize list of lists \n\n# Some guesses had to be made (exact dates are not critical)\n# University - 1800?\n# Trade Journals - 1800?\n# Since I'm going to plot them at 1982, this error will not matter for now. \n# I will fix this later.\n\n\ntech_timeline = [['learn','University Courses', 1800, 40], \\\n                 ['media','Trade Journals', 1800, 10], \\\n                 ['tool','SAS (1960)', 1960, 110], \\\n                 ['tool','SPSS (1968)', 1968, 120], \\\n                 \n                 ['tool','vim(vi)/emacs', 1980, 130], \\\n                 ['tool','MATLAB', 1980, 140], \\\n                 \n                 ['tool','python', 1985, 150], \\\n                 ['tool','MS Excel', 1985, 160], \\\n                 \n                 ['tool','R', 1993, 100],\\\n\n                 ['tool','Spotfire', 1996, 80], \\\n                 ['tool','Salesforce', 1999, 100], \\\n\n                 ['tool','IPython', 2001, 110], \\\n                 \n                 ['tool','matplotlib', 2002, 120], \\\n                 \n\n                 ['tool','notepad++', 2003, 130], \\\n                 ['tool','Tableau', 2003, 90], \\\n                 \n                 ['media','podcasts', 2004, 10], \\\n                 \n                 ['media','Reddit', 2005, 20], \\\n                 ['media','YouTube', 2005, 30], \\\n                 ['tool','ggplot', 2005, 80], \\\n                 \n                 ['tool','Twitter', 2006, 100], \\\n                 ['tool','Google Sheets', 2006, 120], \\\n                 ['tool','AWS', 2006, 140], \\\n                 ['tool','numpy', 2006, 160],\\\n                 \n                 ['media','Hacker News', 2007, 10], \\\n                 \n                 ['tool','pandas', 2008, 100], \\\n                 ['tool','Sublime text', 2008, 110], \\\n                 ['tool','Spyder', 2009, 140], \\\n                 \n                 ['term','\\\"Data Science\\\"\"', 2010, 200],\\\n                 ['tool','Azure', 2010, 160], \\\n                 ['tool','PyCharm', 2010, 180], \\\n                 ['tool','scikit-learn',2010,150],\\\n                 ['tool','Kaggle', 2010, 130],\\\n\n                 ['learn','Udacity', 2011, 30], \\\n                 ['learn','Coursera', 2011, 50], \\\n                 ['tool','GCP', 2011, 190], \\\n                 \n                 ['learn','edX', 2012, 40], \\\n                 ['tool','seaborn', 2012, 160], \\\n                 \n                 ['tool','bokeh', 2013, 180], \\\n                 ['media','Slack', 2013, 10], \\\n\n                 ['learn','DataCamp', 2014, 30], \\\n                 ['tool','xgboost',2014,80],\\\n                 \n                 ['learn','fast.ai', 2015, 20], \\\n                 ['learn','DataQuest', 2015, 40], \\\n                 ['tool','RStudio', 2015, 100], \\\n                 ['tool','JupyterLab', 2015, 120], \\\n                 ['tool','Visual Studio Code', 2015, 140], \\\n                 ['tool', 'TensorFlow', 2015, 160],\\\n                 ['tool', 'Keras', 2015, 180],\\\n                 \n                 ['media','Towards Data Science', 2016, 10], \\\n                 ['tool','geoplotlib', 2016, 150], \\\n                 ['tool','FloydHub', 2016, 170], \\\n\n                 ['tool','Atom', 2017, 70], \\\n                 ['tool','lightgbm', 2017, 90],\\\n                 ['tool','Google Colab', 2017, 110], \\\n                 \n                 ['tool','BERT', 2018, 185],\\\n\n                 ['term','2019 Survey', 2019, 215],\\\n                 ['none','',2023, 0] ]\n\n# Create the pandas DataFrame \ntech_df = pd.DataFrame(tech_timeline, columns = ['TechType','TechName', 'Year', 'y-coord']) \n\n# pYear is \"plot Year\" -- anything before 1982 is going to be plotted at 1982\ntech_df['pYear'] = tech_df.apply(lambda row: row['Year'] if (row['Year'] > 1982) else 1982, axis=1)\n\n# tech_df.dtypes  # for error checking","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\n\nplt.xlim = (1980, 2025)\nplt.ylim = (0, 100)\nplt.yticks([])\n\n#plt.plot('Year', data=tech_df, linestyle='none', marker='o')\nplt.plot('pYear','y-coord',data=tech_df[tech_df['TechType']=='tool'][['pYear','y-coord']], linestyle='none', marker='o', color='b')\nplt.plot('pYear','y-coord',data=tech_df[tech_df['TechType']=='term'][['pYear','y-coord']], linestyle='none', marker='x',color='r')\nplt.plot('pYear','y-coord',data=tech_df[tech_df['TechType']=='learn'][['pYear','y-coord']], linestyle='none', marker='+',color='g')\nplt.plot('pYear','y-coord',data=tech_df[tech_df['TechType']=='media'][['pYear','y-coord']], linestyle='none', marker='*',color='black')\nplt.plot('pYear','y-coord',data=tech_df[tech_df['TechType']=='none'][['pYear','y-coord']], linestyle='none', marker='.',color='black')\n\nplt.plot([1984.8,1984.8],[0,200],linestyle=\"--\",linewidth=1,color='y')\nplt.plot([2007.8,2007.8],[0,200],linestyle=\"--\",linewidth=1,color='y')  \n\n\ntitle_font = {'size':'16', 'color':'black'} # Bottom vertical alignment for more space\nplt.title(\"Data Science Technology Timeline**\", **title_font)\n# add tech labels\nfor i, row in tech_df.iterrows():\n    year = row['pYear']\n    plt.annotate(row['TechName'], xy=(year, row['y-coord']), xytext=(year, row['y-coord']+3))        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Footnotes for the technology timeline: \n(1) The exact date of introduction can be difficult to identify; all dates should be considered approximate. \n(2) Technology, terms, and learning resources introduced before 1982 have been plotted at 1982 to improve readability.\n\nLooking back over a rough timeline of Data Science technology (see above), the first wave started around or before the 1980's. There was a slow progression starting with python and R and then numpy and pandas around 2010. After 2010, popular tools, media and learning platforms seem to have exploded. \n\nAccording to a traditional education model, anyone graduating from college or Uni before a technology has been out for a few years is likely to miss out on formal education in that area. Data Science enthusiasts who are in college now (2019) are most certainly being exposed to the latest technologies, and those who graduated recently are part of the modern paradigm where a quick internet search and a few videos can fill the gap quickly.\n\n**What about Data Science enthusiasts whose \npost high-school education would likely pre-date all or most of these technologies?** Are they being left behind? Are they motivated by staying relevant in their current careers, changing careers, or getting better at a DS hobby? \n\nGetting left behind in the tech age is a significant concern for everyone, but is particularly hard on older workers. Age-based discrimination has not been eliminated, and studies have documented \nlayoffs, declining salaries, and challenges in finding new employment. Articles and blogs advocate putting effort into \nlearning fresh skills and keeping up with new technologies as this may be a critical factor in remaining employed and employable. Outside of work, older generations are often portrayed as being behind the times and unable to catch up, as in the \"So easy your Grandma can do it\" phrase we now see from both bloggers and mainstream tech industry giants.\n\nSo when it comes time to talk about who is or is not keeping up with technology, it may be interesting to set the grandma quips aside and look for some data. \n\nDid the pre-pandas cohort learn pandas, and how did they do it?\n\nWhat about the pre-python, pre-web, pre-personal-computer crowd -- are they using online learning platforms?\n\n**In short, are the older groups keeping up?**\n\nLet's dig into some recent data and see if we can get a glimpse of how it's going for the pre-python and pre-pandas crowd.\n\n*Author's Notes: The terms \"college\", \"university\", and \"uni\" will be used informally and interchangeably in this essay. This notebook is a work in progress.*"},{"metadata":{},"cell_type":"markdown","source":"# Contents\n\n1. [Data Exploration Plan](#background)\n2. [Exploring](#exploring)\n3. [Conclusions](#conclusion)\n4. [References](#references)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"background\"></a>\n## Data Exploration Plan\n\nThe 2019 Kaggle Survey of DS & ML contains reponses from 19,717 individuals from 18 to 70+ years of age. The survey also\nincluded the location (country), job title, job tasks, technologies used and how the respondents freshen their skills. Since the goal here is to look at skills, we'll leave out job titles and job tasks as we want to keep all enthusiasts (including hobbyists) in the mix.\n\nUsing the U.S. education system as a baseline, I've grouped survey respondents\nbased on the following criteria:\n - 1 \"Uni\"       \n        [18-21]\n        Likely still in college or university\n - 2 \"New grad\"   \n        [22-24, 25-29]\n        Likely completed college or university recently \n - 3 \"Pre-pandas\" \n        [30-34, 35-39, 40-44]\n        Likely completed college or university before\n                     pandas (2008)\n                     \"Data Science\" was coined (2010)\n                     Kaggle (2010)\n                     Udemy (2009), Coursera (2011), Udacity (2011)\n                     coding bootcamps (2011)\n - 4 \"Pre-python\" \n        [45-49, 50-54, 55-59, 60-69, 70+]\n        Likely completed college or university before key computer tech\n                     first web browser (1990)\n                     college students had their own computers (~ 1990s)\n                     python (1989)       \n                     \n                     \nAfter breaking down the respondents into these 4 groups, we'll see how they are doing with respect to the newer graduates for several skills.\n * Skill #1: Can they write code?\n * Skill #2: Do they know python?\n * Skill #3: Do they know pandas?\n * Skill #4: Are they leveraging online learning platforms?\n \n"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"## Cleaning and Organizing the Data -- hidden\n\n# don't print the file names any more\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\n# A note about coding style in this notebook. My coding habits are to slip in sanity checks frequently\n# in order to catch problems before they get complicated. I've left them in just in case my next notebook\n# update needs a little debugging.\n\n# Using skiprows to take out the lengthy questions will prevent the warning about dtypes and low memory\n\ndf_raw = pd.read_csv(\"/kaggle/input/kaggle-survey-2019/multiple_choice_responses.csv\",skiprows=[1])\n# df_other = pd.read_csv(\"/kaggle/input/kaggle-survey-2019/other_text_responses.csv\",skiprows=[1])\n# df_longq = pd.read_csv(\"/kaggle/input/kaggle-survey-2019/questions_only.csv\",skiprows=[1])\n    \n# df_raw.shape    # initial shape was 19717, 246\n\n# df_raw.columns   # ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Drop unused columns.\n# 1. All of the \"*_OTHER_TEXT\" data is in the file other_text_responses.csv. Since this data cannot\n#     be aligned with the main data, the columns that indicate that other text was entered cannot be easily included. \n#     Drop those columns.\ndf_raw.drop(columns=['Q2_OTHER_TEXT','Q5_OTHER_TEXT','Q9_OTHER_TEXT',\\\n                     'Q12_OTHER_TEXT','Q13_OTHER_TEXT','Q14_Part_1_TEXT','Q14_Part_2_TEXT','Q14_Part_3_TEXT',\\\n                     'Q14_Part_4_TEXT','Q14_Part_5_TEXT','Q14_OTHER_TEXT',\\\n                     'Q16_OTHER_TEXT',\\\n                     'Q32_OTHER_TEXT','Q33_OTHER_TEXT','Q34_OTHER_TEXT'],inplace=True)\n# df_raw.shape\n# df_raw.head(3)\n# Rename columns\ndf_raw.rename(columns = {'Time from Start to Finish (seconds)':'SurveyTime'}, inplace = True) \ndf_raw.rename(columns = {'Q3':'Country'}, inplace = True) \ndf_raw.rename(columns = {'Q15':'Coding Experience'}, inplace = True) \n# df_longq.rename(columns = {'Time from Start to Finish (seconds)':'SurveyTime'}, inplace = True) \n# Replace lengthy values\n#  Some of these made for unwieldy labels on plots\n\n# df_raw.loc[10,'Q4']\ndf_raw = df_raw.replace(to_replace=r\"Some college/university study without earning a bachelorâ€™s degree\",\\\n                        value=\"Some college or uni\",regex=True)\n# df_raw.loc[10,'Q4']\ndf_raw = df_raw.replace(to_replace=r\"No formal education past high school\",\\\n                        value=\"High School\",regex=True)\ndf_raw = df_raw.replace(to_replace=r\"United Kingdom of Great Britain and Northern Ireland\",\\\n                        value=\"UK\",regex=True)\ndf_raw = df_raw.replace(to_replace=r\"Iran, Islamic Republic of...\",\\\n                        value=\"Iran\",regex=True)\ndf_raw = df_raw.replace(to_replace=r\"United States of America\",\\\n                        value=\"USA\",regex=True)\n\n# df_raw.head(3)\n# df_raw.dtypes\ndf_raw['TimeInMinutes']=df_raw['SurveyTime'].apply(lambda row: pd.to_numeric(row, errors='coerce')/60)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"exploring\"></a>\n## Exploring"},{"metadata":{},"cell_type":"markdown","source":"Survey respondents covered the full adult age range from 18 to 70+, with heavy emphasis at the younger age brackets. For this study, our interest is in comparing the older brackets -- pre-pandas and pre-python -- to the younger groups who are either still in Uni or are recent graduates. Let's start by looking at the age distributions."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig,ax = plt.subplots(1,1,figsize=(10,4))\nax = sns.countplot(x='Q1',data=df_raw,order=['18-21','22-24','25-29','30-34','35-39',\\\n                                               '40-44','45-49','50-54','55-59','60-69','70+'])\nax.set_title(\"Ages of the survey respondents\")\n\nax.set_xlabel(\"Survey age groups\")\nage_list = df_raw['Q1'].value_counts().sort_index()\ntype(age_list)\n\ni = 0\nfor p, label in zip(ax.patches, df_raw['Q1'].value_counts().index):\n    a_count = age_list[i]\n    ax.annotate(a_count, (p.get_x()+0.2, p.get_height()+0.15))\n    i = i+1\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Divide into 4 groups, relative to major developments in tools as described in the EDA Plan\n\ndef agroup(x):\n    group = 0\n    \n    if (x=='18-21'):\n        group = 1\n    elif (x=='22-24' or x=='25-29'):\n        group = 2\n    elif (x=='30-34' or x=='35-39' or x=='40-44'):\n        group = 3\n    else:\n        group = 4\n         # '45-49', 50-54','55-59','60-69','70+'\n\n    #print('x was {} and group is {}'.format(x,group))\n    return group\n\ndf_raw['AgeGroup'] = df_raw.apply(lambda x: agroup(x['Q1']), axis=1  )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dividing the groups as described above, the groups of most interest are #3 \"pre-pandas\" and #4 \"pre-python\". These groups contain 6646 and 2501 respondents respectively."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig,ax = plt.subplots(1,1,figsize=(8,4))\nax = sns.countplot(x='AgeGroup',data=df_raw)\nax.set_xticklabels(labels=[\"1 - Uni\",\"2 - Recent grads\",\"3 - Pre-Pandas\",\"4 - Pre-Python\" ])\nax.set_title(\"Comparison of respondents grouped by age relative to introduction of new tools\")\n\n# sanity check -- should not be any values other than 1,2,3,4\ndf_raw['AgeGroup'].value_counts().sort_index()\n\n# make some easy views based on these groupings\ndf_age1 = df_raw[df_raw['AgeGroup'] == 1]\ndf_age2 = df_raw[df_raw['AgeGroup'] == 2]\ndf_age3 = df_raw[df_raw['AgeGroup'] == 3]\ndf_age4 = df_raw[df_raw['AgeGroup'] == 4]\n\ndf_age12 = df_age1 + df_age2\n\n# Uncomment to double check and watch for errors\n# df_age1.shape   # 2502, 233\n\n# df_age2.shape   # 8068, 233\n# df_age3.shape     # 6646, 233\n# df_age3['Q1'].value_counts()\n# df_age4.shape     # 2501, 233\n# df_age12.shape    # 10570, 233","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Where do groups 3 and 4 reside? We'll look at the top 30 countries for all respondents, \nthen see how they break down for the 4 groups.\n\nFrom the stacked bar chart, we can see that the United States has the most respondents in both groups 3 and 4, and India has the most in groups 1 and 2. The survey data doesn't include enough information to help us understand whether this is due to economic factors, cultural factors, or something else."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"topN = df_raw['Country'].value_counts().iloc[:30]\ntop_countries = list(topN.index)\n# top15_countries\n\ndf_plot = df_raw[df_raw['Country'].isin(top_countries)].groupby(['AgeGroup', \\\n                        'Country']).size().reset_index().pivot(columns='AgeGroup',\\\n                        index='Country', values=0)\nrefignore = df_plot.plot(kind='barh', stacked=True,figsize=(12,8),\\\n                         title=\"Comparison of age groups in each country\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a href=#coding></a>\n### Coding\nNow that we have a sense of the size and location of these groups, let's see where their skills \nare and how they're keeping them polished.\n\n**Skill #1**: Can they write code? \n\n**Answer**: Yes, they can. One point to be careful about in this graph is that groups 1 and 2 are under 30 years of age, so very few would be expected to have 10 or more years of coding experience."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Group by years of coding experience, which was Q15\nexp_list = ['I have never written code', '< 1 years', '1-2 years', '3-5 years',\\\n           '5-10 years','10-20 years', '20+ years']\ndf_plot = df_raw.groupby(['AgeGroup', \\\n                           'Coding Experience']).size().reset_index().pivot(columns='AgeGroup',\\\n                            index='Coding Experience', values=0)\nrefignore = df_plot.reindex(exp_list).plot(kind='barh', stacked=True,\\\n                               figsize=(12,8),\\\n                               title=\"Comparison of age groups and coding experience\")","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true},"cell_type":"markdown","source":"### Python\n\n**Skill #2**: Do they know python? \n\n    \n**Answer**: Yes, they are using python, and at about the same rate as other groups.\n    \nCaveat: This answer is not straightforward. The survey question is actually \n    \"What programming languages do you use on a regular basis?\" In theory,\n    the respondent could know python but not use it on a regular basis. For now, we'll gloss over this subtlety \n    and assume an entry of Yes means they know python and No means that they don't."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Group by use of python, which was Q18_Part_1\ndf_raw['usesPython'] = df_raw.apply(lambda x: True if x['Q18_Part_1']=='Python' else False, axis=1)\n# df_raw[['Q18_Part_1','usesPython','AgeGroup']].head(10)  # error check","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_plot = df_raw.groupby(['AgeGroup', \\\n                           'usesPython']).size().reset_index().pivot(columns='AgeGroup',\\\n                                                                      index='usesPython', values=0)\nrefignore = df_plot.plot(kind='barh', stacked=True, figsize=(12,4),title=\"Comparison of age groups and use of python\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pandas\n\n**Skill #3**: Do they know pandas?\n\n**Answer**: The data we have doesn't allow us to answer this one, actually, since pandas was not asked or reported. \n\n**Skill #3 alternate**: Let's look at scikit-learn, TensorFlow, Keras, and Xgboost instead, as these are also common technologies introduced at roughly the same time period.\n    \n**Answer**: In all 4 cases, groups 3 and 4 don't stand out as favoring any of these tools more than groups 1 and 2. We'll take that to mean that they are aware of and using them to the same extent as the younger groups."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_raw['usesSciKitLearn'] = df_raw.apply(lambda x: True if x['Q28_Part_1']=='  Scikit-learn ' else False, axis=1)\ndf_raw['usesTensorFlow']  = df_raw.apply(lambda x: True if x['Q28_Part_2']=='  TensorFlow ' else False, axis=1)\ndf_raw['usesKeras']       = df_raw.apply(lambda x: True if x['Q28_Part_3']==' Keras ' else False, axis=1)\ndf_raw['usesXgboost']     = df_raw.apply(lambda x: True if x['Q28_Part_5']==' Xgboost ' else False, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_plot = df_raw.groupby(['AgeGroup', \\\n                           'usesSciKitLearn']).size().reset_index().pivot(columns='AgeGroup',\\\n                                                                      index='usesSciKitLearn', values=0)\ndf_plot.plot(kind='barh', stacked=True, figsize=(12,4),title=\"Comparison of age groups and use of scikit-learn\")\n\n\ndf_plot = df_raw.groupby(['AgeGroup', \\\n                           'usesTensorFlow']).size().reset_index().pivot(columns='AgeGroup',\\\n                                                                      index='usesTensorFlow', values=0)\ndf_plot.plot(kind='barh', stacked=True, figsize=(12,4),title=\"Comparison of age groups and use of TensorFlow\")\n\ndf_plot = df_raw.groupby(['AgeGroup', \\\n                           'usesKeras']).size().reset_index().pivot(columns='AgeGroup',\\\n                                                                      index='usesKeras', values=0)\ndf_plot.plot(kind='barh', stacked=True, figsize=(12,4),title=\"Comparison of age groups and use of Keras\")\n\ndf_plot = df_raw.groupby(['AgeGroup', \\\n                           'usesXgboost']).size().reset_index().pivot(columns='AgeGroup',\\\n                                                                      index='usesXgboost', values=0)\n\nrefignore = df_plot.plot(kind='barh', stacked=True, figsize=(12,4),title=\"Comparison of age groups and use of Xgboost\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Online Learning\n\nFinally, let's look at how the groups are choosing to learn. \n\n**Skill #4**: Continuing education, is everyone learning?\n\n**Answer A**: Everyone is learning, and the proportion of each age group that is or isn't using a particular platform is similar.\n\n**Answer B**: When comparing the total number of platforms being used, again, \n    the groups are similar with 74% of respondents using 2 or fewer platforms. "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_raw['onUdacity'] = df_raw.apply(lambda x: 1 if x['Q13_Part_1']=='Udacity' else 0, axis=1)\n# df_raw[['AgeGroup','onUdacity','Q13_Part_1']].head(5)  # check for operation\ndf_raw['onCoursera']  = df_raw.apply(lambda x: 1 if x['Q13_Part_2']=='Coursera' else 0, axis=1)\ndf_raw['onedX']       = df_raw.apply(lambda x: 1 if x['Q13_Part_3']=='edX' else 0, axis=1)\ndf_raw['onDataCamp']     = df_raw.apply(lambda x: 1 if x['Q13_Part_4']=='DataCamp' else 0, axis=1)\ndf_raw['onDataQuest']       = df_raw.apply(lambda x: 1 if x['Q13_Part_5']=='DataQuest' else 0, axis=1)\ndf_raw['onKaggle']     = df_raw.apply(lambda x: 1 if x['Q13_Part_6']=='Kaggle Courses (i.e. Kaggle Learn)' else 0, axis=1)\ndf_raw['onFastAI']       = df_raw.apply(lambda x: 1 if x['Q13_Part_7']=='Fast.ai' else 0, axis=1)\ndf_raw['onUdemy']       = df_raw.apply(lambda x: 1 if x['Q13_Part_8']=='Udemy' else 0, axis=1)\ndf_raw['onLinkedIn']     = df_raw.apply(lambda x: 1 if x['Q13_Part_9']=='LinkedIn Learning' else 0, axis=1)\n\ndf_raw['numLearning'] = df_raw.apply(lambda x: x['onUdacity']+x['onCoursera']\\\n                                     +x['onedX']+x['onDataCamp']\\\n                                     +x['onDataQuest']+x['onKaggle']\\\n                                     +x['onFastAI']+x['onUdemy']\\\n                                     +x['onLinkedIn'],axis=1)\n                                                        \n# df_raw[['AgeGroup','onUdacity','Q13_Part_1','onCoursera','onedX','onDataCamp',\\\n#        'onDataQuest','onFastAI','onKaggle','onUdemy','onLinkedIn','numLearning']].head(5)  \n# check for operation  \n\n\n\n\n## plots start here\n\ndf_plot = df_raw.groupby(['AgeGroup', \\\n                           'numLearning']).size().reset_index().pivot(columns='AgeGroup', index='numLearning', values=0)\n\ndf_plot.plot(kind='barh', stacked=True, figsize=(12,4),\\\n             title=\"Comparison of age groups and number of learning platforms used\")\n\n\n\ndf_raw[['AgeGroup','onUdacity','Q13_Part_1','onCoursera','onedX','onDataCamp',\\\n        'onDataQuest','onFastAI','onKaggle','onUdemy','onLinkedIn']].head(5)  # check for operation\n\n# type(df_raw.loc[1,'onUdacity'])\n\n     \n\n#\ndf_plot = df_raw.groupby(['AgeGroup', \\\n                           'onUdacity']).size().reset_index().pivot(columns='AgeGroup', index='onUdacity', values=0)\ndf_plot.plot(kind='barh', stacked=True, figsize=(12,3),title=\"Comparison of age groups and use of Udacity\")\n\n\ndf_plot = df_raw.groupby(['AgeGroup', \\\n                           'onCoursera']).size().reset_index().pivot(columns='AgeGroup', index='onCoursera', values=0)\ndf_plot.plot(kind='barh', stacked=True, figsize=(12,3),title=\"Comparison of age groups and use of Coursera\")\n\ndf_plot = df_raw.groupby(['AgeGroup', \\\n                           'onedX']).size().reset_index().pivot(columns='AgeGroup', index='onedX', values=0)\ndf_plot.plot(kind='barh', stacked=True, figsize=(12,3),title=\"Comparison of age groups and use of edX\")\n\ndf_plot = df_raw.groupby(['AgeGroup', \\\n                           'onDataCamp']).size().reset_index().pivot(columns='AgeGroup', index='onDataCamp', values=0)\ndf_plot.plot(kind='barh', stacked=True, figsize=(12,3),title=\"Comparison of age groups and use of DataCamp\")\n\ndf_plot = df_raw.groupby(['AgeGroup', \\\n                           'onFastAI']).size().reset_index().pivot(columns='AgeGroup', index='onFastAI', values=0)\ndf_plot.plot(kind='barh', stacked=True, figsize=(12,3),title=\"Comparison of age groups and use of FastAI\")\n\ndf_plot = df_raw.groupby(['AgeGroup', \\\n                           'onKaggle']).size().reset_index().pivot(columns='AgeGroup', index='onKaggle', values=0)\ndf_plot.plot(kind='barh', stacked=True, figsize=(12,3),title=\"Comparison of age groups and use of Kaggle\")\n\ndf_plot = df_raw.groupby(['AgeGroup', \\\n                           'onUdemy']).size().reset_index().pivot(columns='AgeGroup', index='onUdemy', values=0)\ndf_plot.plot(kind='barh', stacked=True, figsize=(12,3),title=\"Comparison of age groups and use of Udemy\")\n\ndf_plot = df_raw.groupby(['AgeGroup', \\\n                           'onLinkedIn']).size().reset_index().pivot(columns='AgeGroup', index='onLinkedIn', values=0)\ndf_plot.plot(kind='barh', stacked=True, figsize=(12,3),title=\"Comparison of age groups and use of LinkedIn\")\n\n\n\ntotal = df_raw['numLearning'].value_counts().sum()  # check that it adds up\n# Sanity checks (looking for errors and suspicious results)\nnumlearnlist = df_raw['numLearning'].value_counts()\n#print(\"The number of learning platforms used by the {} survey resondents break down as follows: \\n{}\".format(total,numlearnlist))\n#numlearnlist\n\nusing0 = numlearnlist[0]/total # percent using 2 or fewer\nusing1or2 = df_raw['numLearning'].value_counts()[1:3].sum()/total # percent using 2 or fewer\nusing3ormore = df_raw['numLearning'].value_counts()[3:].sum()/total # percent using 2 or fewer\n\nprint(\"The breakdown of the {} respondents utilizing non-University learning platforms is:\".format(total))\nprint(\"    Using 0 online learning platforms: {0:.0f}%\".format(100*using0))\nprint(\"    Using 1 or 2 learning platforms: {0:.0f}%\".format(100*using1or2))\nprint(\"    Using 3 or more learning platforms: {0:.0f}%\".format(100*using3ormore))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before coming to a conclusion, let's take one more look at the correlation \nbetween age groups -- Uni, Recent Grad, pre-pandas and pre-python -- and these skills using a correlation matrix. If our \nearlier visual\ninspection of the data is correct, we should find that there is little or no correlation between age group and any of these\ncategories we've studied. (Correlation values should be close to zero.)\n\nAs seen in the correlation heatmap below, this is indeed the case."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# The columns of interest were:\n# Years of coding experience - Q15\n# Python -- usesPython\n# Other tools used -- usesTensorFlow, usesKeras, usesXgboost, usesSciKitLearn\n# Learning -- Q13_Part_1 through Q13_Part_9, a.k.a. onCoursera, onUdacity, etc.\n\n# One more look...gather the columns of interest\nuseCols = ['AgeGroup','usesPython',\\\n           'usesTensorFlow','usesKeras','usesXgboost','usesSciKitLearn',\\\n           'onUdacity','onCoursera','onedX','onDataCamp',\\\n           'onDataQuest','onFastAI','onKaggle','onUdemy','onLinkedIn','numLearning']\nagecorr = df_raw[useCols].corr()\nf, ax = plt.subplots(figsize=(12,12))\nrefignore = sns.heatmap(agecorr,annot=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"conclusion\"></a>\n## Conclusion\n\nBased on the 2019 data analyzed here, it appears that any concerns that our older data science enthusiasts are \nlagging behind are unfounded. The pre-pandas and pre-python crowds are using the foundational tools at roughly the same\nrates as the fresh-from-college crowd, and they are aware of and on-top of the online learning opportunities.\n\nIn the introduction, a couple of other questions were also posed -- what is motivating this crowd to keep \nup on new technologies? Is it to keep an existing career? Are some of them looking to join the Data Science fun and switch\ncareers? Or does this group contain the most hobbyists? Unfortunately, the data collected so far doesn't yet provide us enough \nclues to let us dig into that. \n\nHowever, Kaggle revises the DS & ML Survey each year, so perhaps they'll add those questions for the 2020 survey. Let's hope so!\n"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"references\"></a>\n## References\n\n[1] https://www.wikipedia.org/ -- Numerous wikipedia pages and linked pages were used to research the dates of introduction for the various technologies.\n\n[2] https://insights.dice.com/2019/01/09/older-workers-tech-fight-against-ageism-impact/\n\n[3] https://blog.eero.com/so-easy-grandma-can-do-it/\n\n[4] https://www.youtube.com/watch?v=_GR5_X1CfUA\n\n[5] https://infed.org/mobi/self-directed-learning/\n    \n[6] Knowles, M. (1975) Self-directed learning: A guide for learners and teachers, New York: Cambridge Books.\n\n[7] Knowles, M. (1991) The adult learner: A neglected species. (4th. edn.), Houston: Gulf Publishing."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}