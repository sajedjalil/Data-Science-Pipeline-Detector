{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 2019 Kaggle ML & DS Survey"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom locale import atof\n%matplotlib inline\n\n#set ggplot style\n#plt.style.use('ggplot')\n\n# Load dataset\n\nmultiple_choice_responses = pd.read_csv('/kaggle/input/kaggle-survey-2019/multiple_choice_responses.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Contents\n### 1. Introduction\n### 2. What is Data Science?\n        2.1. Definition\n        2.2. Basic and goal of data science\n        2.3. Growth of data science\n### 3. Who is a Data Scientist?\n        3.1. Data scientist role at work \n        3.2. The highest level of formal education for data scientist\n        3.3. Data scientist yearly compensation\n        3.4. How to become a data scientist?\n### 4. What is Machine Learning?\n        4.1. Machine Learning Algorithms\n### 6. Data science and Machine Learning tools\n        6.1. IDE's, programming language and data visualization libraries for data science and machine learning\n        6.2. Hardware for data science and machine learning\n        6.3. Machine Learning framework \n        6.4. Machine Learning tools\n        6.5. Automated Machine Learning tools\n        6.6. Machine Learning products\n### 7.  Cloud Computing platforms\n### 8. Conclusion"},{"metadata":{},"cell_type":"markdown","source":"           "},{"metadata":{},"cell_type":"markdown","source":"### 1. Introduction"},{"metadata":{},"cell_type":"markdown","source":"Modern technology has enabled the creation and storage of increasing amounts of information, which has increased the volume of data. For example, Facebook users import 10 million photos every hour. [The number of connected devices in the world, called the Internet of Things (IoT), is expected to reach more than 75 billion by 2025](http://www.statista.com/statistics/471264/iot-number-of-connected-devices-worldwide/).\nThe wealth of data collected and stored by these technologies can bring benefits that will transform organizations and societies around the world, but only if we can interpret them. That's where Data Science comes in. Our job is to make a story about data science and machine learning. This goal will be achieved by following the steps above and especially by relying on Data Science survey 2019. "},{"metadata":{},"cell_type":"markdown","source":"Indeed, this survey comes from information collected from some Kaggle users. These respondents are 19,717. The graphic representation below shows the title of the various respondents and the number of respondents corresponding to each title."},{"metadata":{"trusted":true},"cell_type":"code","source":"len(multiple_choice_responses) - 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"multiple_choice_responses = multiple_choice_responses.drop(0, axis=0)\nmultiple_choice_responses = multiple_choice_responses.reset_index(drop=True)\nmultiple_choice_responses[\"Q5\"].value_counts().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"However our story will be more focused on the respondents (without forgetting the others) who perform at least one machine learning task (among those listed in survey) because we are talking about data science and machine learning, so it will be essential for us to rely on them. Here we have 9,226 respondents."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get a dataframe with responding who make at least one ML activities\ndf = multiple_choice_responses.copy()\nonly_ml_activities = multiple_choice_responses.copy()\nfor rows in range(len(multiple_choice_responses)):\n    if(pd.isna(df.iloc[rows]['Q9_Part_1']) & pd.isna(df.iloc[rows]['Q9_Part_2']) \n       & pd.isna(df.iloc[rows]['Q9_Part_3']) & pd.isna(df.iloc[rows]['Q9_Part_4']) \n       & pd.isna(df.iloc[rows]['Q9_Part_5']) & pd.isna(df.iloc[rows]['Q9_Part_6'])\n       & pd.isna(df.iloc[rows]['Q9_Part_7']) & pd.isna(df.iloc[rows]['Q9_Part_8'])):\n        only_ml_activities.drop(rows, axis=0, inplace=True)\nonly_ml_activities = only_ml_activities.reset_index(drop=True)\nlen(only_ml_activities)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. What is Data Science?"},{"metadata":{},"cell_type":"markdown","source":"  #### 2.1. Definition"},{"metadata":{},"cell_type":"markdown","source":"Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to exploit data."},{"metadata":{},"cell_type":"markdown","source":"#### 2.2. Basic and goal of data science"},{"metadata":{},"cell_type":"markdown","source":"It comes from the fields of statistical analysis and data extraction. \n\nData science reveals trends and provides information that companies can use to make better decisions and create more innovative products and services. Data is the foundation of innovation, but its value comes from the information that data scientists can draw and then exploit."},{"metadata":{},"cell_type":"markdown","source":"#### 2.3. Growth of data science"},{"metadata":{},"cell_type":"markdown","source":"This area has become very popular thanks to the wealth of data we create. To give you an idea, [it is created around 2 billion bytes of data in the world every minute](http://https://theconversation.com/management-et-data-science-une-discipline-emergente-en-sciences-de-gestion-85264).\nThe Data Science Journal appeared in 2002, published by the International Council for Science: Committee on Data for Science and Technology. [In 2008, the title of data scientist had emerged and the field had grown rapidly](http://https://www.dataversity.net/brief-history-data-science/). The emergence of this area is reflected by the increase in the demand for data scientist on the job market."},{"metadata":{},"cell_type":"markdown","source":"### 3. Who is a Data Scientist?"},{"metadata":{},"cell_type":"markdown","source":"A data scientist is a specialist whose mission is to develop data analysis strategies, prepare data for analysis, explore, analyze and visualize data, create models with data to the data using programming languages such as Python and R, and deploying these models in applications.\nThe process of data analysis and exploitation is iterative rather than linear, but here is the standard workflow of a data modeling project:\n- Plan: Define a project and its potential results\n- Prepare: build the work environment by ensuring that data scientists have the right tools, as well as access to appropriate data and other resources such as computing power\n- Ingest: load data into the work environmentExplore: analyze, explore and visualize data\n- Model: Design, Train, and Validate Models to Work as Expected\n- Deploy: deploy models in production"},{"metadata":{},"cell_type":"markdown","source":"Data scientist is not a specific gender. It can be male, female or order."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,10))\nax = sns.countplot(x=\"Q2\", hue=\"Q5\", data=only_ml_activities, palette=\"muted\", order=only_ml_activities[\"Q2\"].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3.1. Data scientist role at work"},{"metadata":{},"cell_type":"markdown","source":"According to data survey, the mainly role (in ascending order of the most practiced) of data scientist are:\n- Analyze and understand data to influence product or business decisions \n- Build prototypes to explore applying machine learning to new areas\n- Experimentation and iteration to improve existing ML models\n- Build and/or run a machine learning service that operationally improves my product or workflows\n- Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data\n- Do research that advances the state of the art of machine learning"},{"metadata":{"trusted":true},"cell_type":"code","source":"def question_column(column, df):\n    count = 0\n    for col in range(len(df.columns)):\n        if column in df.columns[col]:\n            new=df[[df.columns[col]]]\n            if count==0:\n                new_df = pd.DataFrame(new)\n                count=+1\n            else:\n                new_df = new_df.join(new)\n    return new_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def change_column_name(df):\n    name = []\n    dfs = df.copy()\n    for column in df.columns:\n        for row in range(len(df)):\n            if pd.isna(df.iloc[row][column]):\n                continue\n            else:\n                dfs=df.rename(columns = {column : df.iloc[row][column]}, inplace=True)\n                break\n    return df ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def change_value(df):\n    for column in df.columns:\n        for row in range(len(df)):\n            if pd.isna(df.iloc[row][column]):\n                df.iloc[row][column] = 0\n            else:\n                df.iloc[row][column] = 1\n    return df ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get activity columns from DataFrame only_ml_activitiabses\ncolumns = question_column(\"Q9\", only_ml_activities)\n# Change columns name\nchange_name = change_column_name(columns)\n# Change cell value 0 or 1\nQ9 = change_value(change_name)\n# Drop the last column\nQ9_drop = Q9.drop(Q9.columns[-1], axis=1)\n# Concatenate activity columns with respondent role columns\nQ5_Q9 = pd.concat([only_ml_activities[\"Q5\"], Q9_drop], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Group by role\ngroupe_role = Q5_Q9.groupby(\"Q5\").sum().transpose()\n# Plotting for data scientist role\ngroupe_role[\"Data Scientist\"].plot.barh()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"However, not only are data scientists practicing at least one of the activities (as shown below). We also find that no student performs any of these activities, perhaps because they are still students. On the other hand, others (Software Engineer, Data Analyst, Research Scientist, ...) do it. Do they also have to be considered data scientists ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting all role whose make least a machine learning activities\nonly_ml_activities[\"Q5\"].value_counts().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For Computer Engineers the order of the activities is the following one (from the most practiced to the least practiced):\n- Build prototypes to explore applying machine learning to new areas\n- Analyze and understand data to influence product or business decisions \n- Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data\n- Build and/or run a machine learning service that operationally improves my product or workflows\n- Experimentation and iteration to improve existing ML models\n- Do research that advances the state of the art of machine learning"},{"metadata":{},"cell_type":"markdown","source":"For Research Scientist the order of the activities is the following one (from the most practiced to the least practiced):\nactivities is the following one (from the most practiced to the least practiced):\n- Build prototypes to explore applying machine learning to new areas\n- Do research that advances the state of the art of machine learning\n- Experimentation and iteration to improve existing ML models\n- Analyze and understand data to influence product or business decisions \n- Build and/or run a machine learning service that operationally improves my product or workflows\n- Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data"},{"metadata":{},"cell_type":"markdown","source":"We can thus deduce that the activities performed by each depend on their role."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting activities and total of role for each activity\nfig, ax = plt.subplots(figsize=(15,10))\nQ5_Q9.groupby(\"Q5\").sum().plot(ax=ax)\nax.set_xlabel(\"ROLE\")\nax.set_ylabel(\"TOTAL\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data scientist doesn't work alone. In reality, data science is more efficient when a team is working on it. In addition to a data expert, this team can include a business analyst who defines the problem, a data engineer who prepares the data and their availability, an IT architect who oversees the underlying processes and infrastructure, and a software developer that deploys the models or results of the analysis into applications and products."},{"metadata":{},"cell_type":"markdown","source":"The graph below shows that the majority of data scientists work in a team, about **98.28**%."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Concatenate role and responsible for data science workloads columns\nconcat_Q5_Q7 = pd.concat([only_ml_activities[\"Q5\"], only_ml_activities[\"Q7\"]], axis=1)\ngroup_Q5_Q7 = concat_Q5_Q7.groupby([\"Q5\", \"Q7\"]).size()\n# Get DataFrame for data scientist only \ndata_scientist = concat_Q5_Q7[concat_Q5_Q7[\"Q5\"]==\"Data Scientist\"]\n# Get DataFrame for all who work in a team\nin_team = concat_Q5_Q7[concat_Q5_Q7[\"Q7\"]!=\"0\"]\n# Get for data scientist only who work in a team\ndata_scientist_in_team = in_team[in_team[\"Q5\"]==\"Data Scientist\"]\n# Compute the percent of data scientist who work in a team\npercent_data_scientist =(len(data_scientist_in_team) / len(data_scientist)) * 100\nprint(percent_data_scientist)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group_Q5_Q7[\"Data Scientist\"].plot.barh()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is also the case for the other roles (see the figure below)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting for all role\nfig, ax = plt.subplots(figsize=(15,5))\nconcat_Q5_Q7.groupby([\"Q7\",\"Q5\"])[\"Q7\"].count().unstack().plot(ax=ax)\nax.set_xlabel(\"ROLE\")\nax.set_ylabel(\"TOTAL\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3.2. The highest level of formal education for data scientist"},{"metadata":{},"cell_type":"markdown","source":"We find that the highest level of formal education that data scientist have attained or plan to attain within the next 2 year is mostly Master's Degree, followed by Bachelor's Degree and Doctoral Degree. However, we also have data scientist who don't got formal education past high school. So, is it possible to become a data scientist without get formal education past high school? How did they do to get data scientist role? "},{"metadata":{"trusted":true},"cell_type":"code","source":"group_level = pd.concat([only_ml_activities[\"Q5\"], only_ml_activities[\"Q4\"]], axis=1)\ngroup = group_level.groupby([\"Q5\", \"Q4\"]).size()\n\ngroup[\"Data Scientist\"].plot.barh()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3.3. Data scientist yearly compensation"},{"metadata":{},"cell_type":"markdown","source":"According to Glassdoor, the average data scientist salary is **$113,436**.\n\nAccording to [O’Reilly’s 2016](http://www.oreilly.com/data/free/files/2016-data-science-salary-survey.pdf) Data Science Salary Survey, experience is one of the most important factors in a data scientist’s salary. For every year of experience, data science professionals make an average of $2,000 to $2,500 more. "},{"metadata":{},"cell_type":"markdown","source":"A 2018 [Burtch Works study of data science salaries](http://www.burtchworks.com/wp-content/uploads/2018/05/Burtch-Works-Study_DS-2018.pdf) reported the latest salary trends based on experience : \n\n- Entry-level data scientist salary. Despite a recent influx of early-career professionals, the median starting salary for a     data scientist remains high at $95,000.\n\n- Mid-level data scientist salary. The median salary for a mid-level data scientist is $128,750. If this data scientist is also   in a managerial role, the median salary rises to $185,000. \n\n- Experienced data scientist salary. The median salary for experienced data science professionals is $165,000—while the median   salary for experienced manager-level professionals is considerably higher at $250,000."},{"metadata":{},"cell_type":"markdown","source":"According to data science survey 2019, median data scientist yearly compensation \n- with experience < 1 year is : $**19,520.75-24,582.02**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def compensation_remove_carac(df):\n    for x in range(len(df)):\n        compensation = df.get_value(x,'Q10')\n        if(type(compensation)!=float):\n            value = compensation.replace(\"$\", \"\")\n            df.at[x, \"Q10\"] = value.replace(\"> \", \"\")\n        else:\n            continue\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_min_max_compensation(df):\n    df2 = pd.DataFrame(columns=[\"Min_compensation\",\"Max_compensation\"])\n    group_compensation = pd.concat([df, df2], axis=1)\n    for x in range(len(df)):\n        compensation2 = df.get_value(x,'Q10')\n        if(pd.isna(compensation2)):\n            group_compensation.at[x, \"Min_compensation\"] = float(0)\n            group_compensation.at[x, \"Max_compensation\"] = float(0)\n        else:\n            if(compensation2==\"500,000\"):\n                group_compensation.at[x, \"Min_compensation\"] = float(500000)\n                group_compensation.at[x, \"Max_compensation\"] = float(500000)\n            else:\n                group_compensation.at[x, \"Min_compensation\"] = float(compensation2.split('-', 1)[0].replace(',', ''))\n                group_compensation.at[x, \"Max_compensation\"] = float(compensation2.split('-', 1)[1].replace(',', ''))\n    group_compensation=group_compensation.drop(group_compensation.columns[0], axis=1)\n    return group_compensation.astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get compensation column\ncompensation = pd.DataFrame(only_ml_activities[\"Q10\"])\ndf = compensation_remove_carac(compensation)\ncompensation_min_max = get_min_max_compensation(df)\n# Concatenate role, yearly compensation, professional experiences columns \nrole_compensation_experience = pd.concat([only_ml_activities[\"Q5\"], only_ml_activities[\"Q23\"], compensation_min_max], axis = 1)\n# Plotting data scientist yearly compensation with experience < 1 year\ngroup_role_compensation_experience = role_compensation_experience[role_compensation_experience[\"Q23\"]==\"< 1 years\"]\ngroup_role_compensation_experience = group_role_compensation_experience[group_role_compensation_experience[\"Q5\"]==\"Data Scientist\"]\n\nmean_min = group_role_compensation_experience[\"Min_compensation\"].mean()  \nmean_max = group_role_compensation_experience[\"Max_compensation\"].mean()\n\nprint(\"$\" + str(\"{:.2f}\".format(mean_min)) + \"-\" + str(\"{:.2f}\".format(mean_max)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- with experience between 5-10 years is : **$97,383.41 - 120,008.64**"},{"metadata":{"trusted":true},"cell_type":"code","source":"group_role_compensation_experience = role_compensation_experience[role_compensation_experience[\"Q23\"]==\"5-10 years\"]\ngroup_role_compensation_experience = group_role_compensation_experience[group_role_compensation_experience[\"Q5\"]==\"Data Scientist\"]\n\nmean_min = group_role_compensation_experience[\"Min_compensation\"].mean()  \nmean_max = group_role_compensation_experience[\"Max_compensation\"].mean()  \n\nprint(\"$\" + str(\"{:.2f}\".format(mean_min)) + \"-\" + str(\"{:.2f}\".format(mean_max)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- with experience between 10-15 years is : **$110,128.91-140,127.98**"},{"metadata":{"trusted":true},"cell_type":"code","source":"group_role_compensation_experience = role_compensation_experience[role_compensation_experience[\"Q23\"]==\"10-15 years\"]#.groupby([\"Q5\", \"Min_compensation\"]).size()\ngroup_role_compensation_experience = group_role_compensation_experience[group_role_compensation_experience[\"Q5\"]==\"Data Scientist\"]\n\nmean_min = group_role_compensation_experience[\"Min_compensation\"].mean()  \nmean_max = group_role_compensation_experience[\"Max_compensation\"].mean()  \n\nprint(\"$\" + str(\"{:.2f}\".format(mean_min)) + \"-\" + str(\"{:.2f}\".format(mean_max)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- with experience between 20+ years years is :**$ 134, 379.03-170, 789.40**"},{"metadata":{"trusted":true},"cell_type":"code","source":"group_role_compensation_experience = role_compensation_experience[role_compensation_experience[\"Q23\"]==\"20+ years\"]\ngroup_role_compensation_experience = group_role_compensation_experience[group_role_compensation_experience[\"Q5\"]==\"Data Scientist\"]\n\nmean_min = group_role_compensation_experience[\"Min_compensation\"].mean()  \nmean_max = group_role_compensation_experience[\"Max_compensation\"].mean()  \n\nprint(\"$\" + str(\"{:.2f}\".format(mean_min)) + \"-\" + str(\"{:.2f}\".format(mean_max)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According to [Kdnuggets](http://www.kdnuggets.com/2019/05/data-scientist-best-job-careercast.html), Data Scientist is the top job in USA, with very good work environment, low stress, high growth, and median salary of $114,520. This statement encourages all those who wish to be data scientist to achieve their objective."},{"metadata":{},"cell_type":"markdown","source":"#### 3.4. How to become a data scientist?"},{"metadata":{},"cell_type":"markdown","source":"As it is often said \"*Everything has a beginning*\". It is also the case to be data scientist. \nTo become data scientist:"},{"metadata":{},"cell_type":"markdown","source":"- You must attend platforms data science courses. We note that the majority of data scientists have acquired their knowledge in data science on training platforms. Here the most popular platform is **Coursera**."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get activity columns from DataFrame only_ml_activitiabses\ncolumns = question_column(\"Q13\", only_ml_activities)\n# Change columns name\nchange_name = change_column_name(columns)\n# Change cell value 0 or 1\nQ13 = change_value(change_name)\n# Drop the last column\nQ13_drop = Q13.drop(Q13.columns[-1], axis=1)\n# Concatenate activity columns with respondent role columns\nQ5_Q13 = pd.concat([only_ml_activities[\"Q5\"], Q13_drop], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,7))\ngroup_platform = Q5_Q13.groupby(\"Q5\").sum().transpose()\ngroup_platform.plot.barh(ax= ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- You must attend media souces that report on data science topic. The most followed by dat scientist is **Blog**."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get activity columns from DataFrame only_ml_activitiabses\ncolumns = question_column(\"Q12\", only_ml_activities)\n# Change columns name\nchange_name = change_column_name(columns)\n# Change cell value 0 or 1\nQ12 = change_value(change_name)\n# Drop the last column\nQ12_drop = Q12.drop(Q12.columns[-1], axis=1)\n# Concatenate activity columns with respondent role columns\nQ5_Q12 = pd.concat([only_ml_activities[\"Q5\"], Q12_drop], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,5))\nQ5_Q12 = Q5_Q12.groupby(\"Q5\").sum()\nQ5_Q12.plot(ax=ax)\nax.set_xlabel(\"ROLE\")\nax.set_ylabel(\"TOTAL\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- You must familiarize yourself with data analyze tools. The primary tool use at work or school to analyse data by data scientist is **Local development environments**."},{"metadata":{"trusted":true},"cell_type":"code","source":"Q14 = pd.get_dummies(only_ml_activities[\"Q14\"])\nQ14 = Q14.reset_index(drop=True)\nQ14_concat = pd.concat([only_ml_activities[\"Q5\"], Q14], axis=1)\nQ14_concat_group = Q14_concat.groupby(\"Q5\").sum()\nfig, ax = plt.subplots(figsize=(15,5))\nQ14_concat_group.plot(ax=ax)\nax.set_xlabel(\"ROLE\")\nax.set_ylabel(\"TOTAL\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- You must learn least a programming language for data science. The most recommended by data scientist is **python**."},{"metadata":{"trusted":true},"cell_type":"code","source":"only_ml_activities[\"Q19\"].value_counts().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- You must be ready to spent money on machine learning and cloud computing products. The graph below shows the expenditures made by the data scientist is last 5 years."},{"metadata":{"trusted":true},"cell_type":"code","source":"expense = pd.concat([only_ml_activities[\"Q5\"], only_ml_activities[\"Q11\"]], axis=1)\ngroup_expense = expense.groupby([\"Q5\",\"Q11\"])[\"Q11\"].count()\ngroup_expense[\"Data Scientist\"].plot.barh()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- You don't need to get highest level of formal education (see 3.2)\n"},{"metadata":{},"cell_type":"markdown","source":"- The gender is not a disadvantage (see 3.)."},{"metadata":{},"cell_type":"markdown","source":"- Speaking of age, note that the youngest data scientist is between **18-21 years** old and the oldest is at least **70 years** old. "},{"metadata":{"trusted":true},"cell_type":"code","source":"age = pd.concat([only_ml_activities[\"Q5\"], only_ml_activities[\"Q1\"]], axis=1)\ngroup_age_interval = age.groupby([\"Q5\",\"Q1\"])[\"Q1\"].count()\ngroup_age_interval[\"Data Scientist\"].plot.barh()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4. What is Machine Learning?"},{"metadata":{},"cell_type":"markdown","source":"Machine Learning is a data analysis method for automating analytic model development. Through algorithms that learn iteratively, Machine Learning allows computers to discover hidden insights without being programmed to know where to look for them."},{"metadata":{},"cell_type":"markdown","source":"At the beginning, Machine Learning was born thanks to pattern recognition technologies and the theory that computers can learn without being programmed to perform specific tasks. Researchers interested in artificial intelligence wanted to see if computers could learn from data. The iterative aspect of Machine Learning is essential because it allows models to adapt independently when exposed to new data. They learn from previous calculations to create reliable and repeatable decisions and results."},{"metadata":{},"cell_type":"markdown","source":"#### 4.1. Machine Learning Algorithms"},{"metadata":{},"cell_type":"markdown","source":"Machine Learning algorithms are not new, but it is only recently that it is possible to apply complex mathematical calculations faster and faster to Big Data. Machine Learning is now used in many areas, such as autonomous vehicle development, online recommendation systems such as Netflix and Amazon, customer sentiment analysis, and fraud detection."},{"metadata":{},"cell_type":"markdown","source":"According to data survey 2019, Machine Learning algorithms most used whatever the role are : Linear or Logistic Regression and Decision Trees or Random Forest."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get activity columns from DataFrame only_ml_activitiabses\ncolumns = question_column(\"Q24\", only_ml_activities)\n# Change columns name\nchange_name = change_column_name(columns)\n# Change cell value 0 or 1\nQ24 = change_value(change_name)\n# Drop the last column\nQ24_drop = Q24.drop(Q24.columns[-1], axis=1)\n# Concatenate activity columns with respondent role columns\nQ5_Q24 = pd.concat([only_ml_activities[\"Q5\"], Q24_drop], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,5))\ngroup_Q5_Q24 = Q5_Q24.groupby(\"Q5\").sum()\ngroup_Q5_Q24.plot(ax=ax)\nax.set_xlabel(\"ROLE\")\nax.set_ylabel(\"TOTAL\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The graph above shows us that the priorities of the algorithms vary according to the roles. This is due to everyone's activities. So the choice of an algorithm depends on the task we want to perform. This graph also shows us that the Recurrent Neural Networks and Dense Neural Networks (MLPs, etc) algorithms have almost the same number of users. These Machine Learning Algorithms can be applied using machine learning tools."},{"metadata":{},"cell_type":"markdown","source":"### 6. Data science and Machine Learning tools"},{"metadata":{},"cell_type":"markdown","source":"Data scientists use many types of tools, but most commonly open source notebooks, which are web-based applications for writing and executing code, visualizing data, and displaying results, all in the same environment. Jupyter and RStudio are some of the most popular softwares."},{"metadata":{},"cell_type":"markdown","source":"#### 6.1. IDE's, programming language and data visualization libraries for data science and machine learning"},{"metadata":{},"cell_type":"markdown","source":"Each step of the Data Scientist's work has associated specific tools. We found that the mostly popular IDE's is Jupiter (JupyterLab, Jupyter Notebook, etc) used by all roles followed by Rsudio (As show in following graph)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get activity columns from DataFrame only_ml_activitiabses\ncolumns = question_column(\"Q16\", only_ml_activities)\n# Change columns name\nchange_name = change_column_name(columns)\n# Change cell value 0 or 1\nQ16 = change_value(change_name)\n# Drop the last column\nQ16_drop = Q16.drop(Q16.columns[-1], axis=1)\n# Concatenate activity columns with respondent role columns\nQ5_Q16 = pd.concat([only_ml_activities[\"Q5\"], Q16_drop], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,5))\nQ5_Q16.groupby(\"Q5\").sum().plot(ax=ax)\nax.set_xlabel(\"ROLE\")\nax.set_ylabel(\"TOTAL\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notepad software is very useful for performing analysis, but it has limitations when data scientists have to work as a team. Data science hosted notebook have been developed to solve this problem.\n\nThe graph below shows us that the hosted notebook products mainly used are :\n- Kaggle Notebooks (Kernels) : 2496 users\n- Google Colab : 2438 users\n- Microsoft Azure Notebooks : 565 users\n- Google Cloud Notebook Products (AI Platform, Datalab, etc) : 693 users\n- Paperspace / Gradient : 104 users\n- FloydHub : 66 users\n- Binder / JupyterHub : 960 users\n- IBM Watson Studio : 371 users\n- Code Ocean : 48 users\nWe notice that there is a very big difference (number of users) between the first two and the others. Is this due to ignorance of their existence by the users? Or a question of efficiency? For the second case we can then deduce that Kaggle Notebook (Kernel) and Google Colab are the most effective for each step of the Data Scientist's work. "},{"metadata":{"trusted":true},"cell_type":"code","source":"def small_multiples_for_line_chart(df, title):\n    # create a color palette\n    palette = plt.get_cmap('Set1')\n    \n    plt.figure(figsize=(10,15))\n    # multiple line plot\n    num=0\n    for column in df[df.columns[1:]]:\n        num+=1\n        # Find the right spot on the plot\n        \n        plt.subplot(6,2, num)\n         # plot every groups, but discreet\n        for v in df[df.columns[1:]]:\n            plt.plot(df.index, df[v], marker='', color='grey', linewidth=1.6, alpha=0.2)\n \n        # Plot the lineplot\n        plt.plot(df.index, df[column], marker='', color=palette(num), linewidth=2.4, alpha=1, label=column)\n\n        # Same limits for everybody!\n        plt.xlim(0,10)\n        plt.ylim(-2,2500)\n\n        # Not ticks everywhere\n        if num in range(11) :\n            plt.tick_params(labelbottom='off')\n        if num not in [1,3,5,7,9,11] :\n            plt.tick_params(labelleft='off')\n\n        # Add title\n        plt.title(column, loc='left', fontsize=12, fontweight=0, color=palette(num) )\n\n    # general title\n    plt.suptitle(title, fontsize=13, fontweight=0, color='black', style='italic', y=1.02)\n\n    # Axis title\n    plt.text(0.5, 0.02, 'Time', ha='center', va='center')\n    plt.text(0.06, 0.5, 'Note', ha='center', va='center', rotation='vertical')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get activity columns from DataFrame only_ml_activitiabses\ncolumns = question_column(\"Q17\", only_ml_activities)\n# Change columns name\nchange_name = change_column_name(columns)\n# Change cell value 0 or 1\nQ17 = change_value(change_name)\n# Drop the last column\nQ17_drop = Q17.drop(Q17.columns[-1], axis=1)\n# Concatenate activity columns with respondent role columns\nQ5_Q17 = pd.concat([only_ml_activities[\"Q5\"], Q17_drop], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"group_concat_Q5_Q17 = Q5_Q17.groupby(\"Q5\").sum()\ndf = pd.DataFrame(group_concat_Q5_Q17.index)\n#df2= group_concat_Q5_Q17[group_concat_Q5_Q17.columns]\n#small_multiples_for_line_chart(df)\ndf2 = group_concat_Q5_Q17.reset_index(drop=True)\nconcat = pd.concat([df, df2], axis=1)\n#concat[concat.columns[1:]]\ntitle = \"Hosted notebook products from survey\"\nsmall_multiples_for_line_chart(concat, title)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Graphic representations are more meaningful than long texts.\nIn data science, graphical representations are very important for seeing trends in order to make decisions. This is how several visualization libraries have been developed. The ascending order according to the most used is:\n- Matplotlib\n- Seaborn\n- Ggplot/ggplot2\n- PLotly/Plotly Express\n- Shiny\n- D3.js\n- Bokeh\n- Leaflet/Folium\n- Geoplotlib"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get activity columns from DataFrame only_ml_activitiabses\ncolumns = question_column(\"Q20\", only_ml_activities)\n# Change columns name\nchange_name = change_column_name(columns)\n# Change cell value 0 or 1\nQ20 = change_value(change_name)\n# Drop the last column\nQ20_drop = Q20.drop(Q20.columns[-1], axis=1)\n# Concatenate activity columns with respondent role columns\nQ5_Q20 = pd.concat([only_ml_activities[\"Q5\"], Q20_drop], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,5))\nQ5_Q20.groupby(\"Q5\").sum().plot(ax=ax)\nax.set_xlabel(\"ROLE\")\nax.set_ylabel(\"TOTAL\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In addition to IDE's, it is also very important to consider hardware resources when applying the machine learning algorithms."},{"metadata":{},"cell_type":"markdown","source":"#### 6.2. Hardware for data science en machine learning"},{"metadata":{},"cell_type":"markdown","source":"Given the amount of data to be processed, the use of powerful hardware resources will solve of data science or machine learning problems quickly."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get activity columns from DataFrame only_ml_activitiabses\ncolumns = question_column(\"Q21\", only_ml_activities)\n# Change columns name\nchange_name = change_column_name(columns)\n# Change cell value 0 or 1\nQ21 = change_value(change_name)\n# Drop the last column\nQ21_drop = Q21.drop(Q21.columns[-1], axis=1)\n# Concatenate activity columns with respondent role columns\nQ5_Q21 = pd.concat([only_ml_activities[\"Q5\"], Q21_drop], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,5))\nQ5_Q21.groupby(\"Q5\").sum().plot(ax=ax)\nax.set_xlabel(\"ROLE\")\nax.set_ylabel(\"TOTAL\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Indeed, the CPU is responsible for performing all kinds of calculations. He is able to carry out many different tasks. Conversely, the GPU only manages graphical calculations. It handles the display of pixels, textures and shapes on the screen, as well as the processing of the video. And the Tensor Processing Unit (TPU) is an application-specific integrated circuit ([ASIC](http://fr.m.wikipedia.org/wiki/Application-specific_integrated_circuit)) developed by Google specifically to accelerate artificial intelligence systems using neural networks. \n\nAccording to the above graph, the most using hardware resources is CPUs. On the other hand, the TPU which was designed for artificial intelligence tasks is unfortunately the least used. The maximum number of TPU usage is 5 times (see the graph below). This is very insignificant because we will need more interest in this resource given the amount of data that increases each day."},{"metadata":{"trusted":true},"cell_type":"code","source":"tpu = pd.get_dummies(only_ml_activities[\"Q22\"])\ntpu = tpu.reset_index(drop=True)\ntpu_concat = pd.concat([only_ml_activities[\"Q5\"], tpu], axis=1)\ntpu_concat_group = tpu_concat.groupby(\"Q5\").sum()\nfig, ax = plt.subplots(figsize=(15,5))\ntpu_concat_group.plot(ax=ax)\nax.set_xlabel(\"ROLE\")\nax.set_ylabel(\"TOTAL\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 6.3. Machine Learning framework "},{"metadata":{},"cell_type":"markdown","source":"There are several machine Learning framework . Of those listed in the sample, the most popular is Scikit-learn (graph below). So it is practicable for all Machine learning tasks. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get activity columns from DataFrame only_ml_activitiabses\ncolumns = question_column(\"Q28\", only_ml_activities)\n# Change columns name\nchange_name = change_column_name(columns)\n# Change cell value 0 or 1\nQ28 = change_value(change_name)\n# Drop the last column\nQ28_drop = Q28.drop(Q28.columns[-1], axis=1)\n# Concatenate activity columns with respondent role columns\nQ5_Q28 = pd.concat([only_ml_activities[\"Q5\"], Q28_drop], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,5))\nQ5_Q28.groupby(\"Q5\").sum().plot(ax=ax)\nax.set_xlabel(\"ROLE\")\nax.set_ylabel(\"TOTAL\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We also notice that these frameworks have almost the same order of priority for all roles."},{"metadata":{"trusted":true},"cell_type":"code","source":"group_Q5 = Q5_Q28.groupby(\"Q5\").sum().transpose()\ngroup_Q5[\"Data Scientist\"].plot.barh()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 6.4. Machine Learning tools "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get activity columns from DataFrame only_ml_activitiabses\ncolumns = question_column(\"Q25\", only_ml_activities)\n# Change columns name\nchange_name = change_column_name(columns)\n# Change cell value 0 or 1\nQ25 = change_value(change_name)\n# Drop the last column\nQ25_drop = Q25.drop(Q25.columns[-1], axis=1)\n# Concatenate activity columns with respondent role columns\nQ5_Q25 = pd.concat([only_ml_activities[\"Q5\"], Q25_drop], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,5))\nQ5_Q25.groupby(\"Q5\").sum().plot(ax=ax)\nax.set_xlabel(\"ROLE\")\nax.set_ylabel(\"TOTAL\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The graph above shows us that the majority of respondents do not use any of these tools. We also note that, as for the framework, there are practically no priorities for using these tools according to roles. We deduce that the choice of tools does not depend on the role."},{"metadata":{},"cell_type":"markdown","source":"#### 6.5. Automated Machine Learning tools"},{"metadata":{},"cell_type":"markdown","source":"According to [DataRobot](http://www.datarobot.com/wiki/automated-machine-learning/), Machine Learning (AutoML) fundamentally change the way organizations Machine Learning and Data Science. The application of real-world business problems traditional methods of machine learning is a big challenge, requires a lot of time and resources. Hence the need of Automated Machine Learning tools.\n"},{"metadata":{},"cell_type":"markdown","source":"Unfortunately, the graph below shows us that MLs are almost not used. This may be due to ignorance of the existence of these tools."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get activity columns from DataFrame only_ml_activitiabses\ncolumns = question_column(\"Q33\", only_ml_activities)\n# Change columns name\nchange_name = change_column_name(columns)\n# Change cell value 0 or 1\nQ33 = change_value(change_name)\n# Drop the last column\nQ33_drop = Q33.drop(Q33.columns[-1], axis=1)\n# Concatenate activity columns with respondent role columns\nQ5_Q33 = pd.concat([only_ml_activities[\"Q5\"], Q33_drop], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,5))\nQ5_Q33.groupby(\"Q5\").sum().plot(ax=ax)\nax.set_xlabel(\"ROLE\")\nax.set_ylabel(\"TOTAL\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 6.6. Machine Learning products"},{"metadata":{},"cell_type":"markdown","source":"Machine Learning products gives developers and scientists data the means to create, train and deploy Machine Learning models faster."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get activity columns from DataFrame only_ml_activitiabses\ncolumns = question_column(\"Q32\", only_ml_activities)\n# Change columns name\nchange_name = change_column_name(columns)\n# Change cell value 0 or 1\nQ32 = change_value(change_name)\n# Drop the last column\nQ32_drop = Q32.drop(Q32.columns[-1], axis=1)\n# Concatenate activity columns with respondent role columns\nQ5_Q32 = pd.concat([only_ml_activities[\"Q5\"], Q32_drop], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,5))\nQ5_Q32.groupby(\"Q5\").sum().plot(ax=ax)\nax.set_xlabel(\"ROLE\")\nax.set_ylabel(\"TOTAL\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user = 0\nfor col in Q5_Q32.columns[1:]:\n    s = Q5_Q32[col].sum()\n    if((col !=\"None\") & (col != \"Other\")):\n        user = user + s\n    print(col + \" : \" + str(s) + \"\\n\")\nprint(\"Total users\" + \" : \" + str(user))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We note that the Machine Learning products are practically not used. However these product are based on cloud computing."},{"metadata":{},"cell_type":"markdown","source":"### 7. Cloud Computing platforms"},{"metadata":{},"cell_type":"markdown","source":"Cloud computing is to use remote computer servers via a network, usually the Internet, to store or exploit data.The main services offered in cloud computing are SaaS (Software as a Service), PaaS (Platform as a Service) and IaaS (Infrastructure as a Service). Depending on the service, operating systems, infrastructure software and application software will be the responsibility of either the supplier or the customer."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get activity columns from DataFrame only_ml_activitiabses\ncolumns = question_column(\"Q29\", only_ml_activities)\n# Change columns name\nchange_name = change_column_name(columns)\n# Change cell value 0 or 1\nQ29 = change_value(change_name)\n# Drop the last column\nQ29_drop = Q29.drop(Q29.columns[-1], axis=1)\n# Concatenate activity columns with respondent role columns\nQ5_Q29 = pd.concat([only_ml_activities[\"Q5\"], Q29_drop], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,5))\nQ5_Q29.groupby(\"Q5\").sum().plot(ax=ax)\nax.set_xlabel(\"ROLE\")\nax.set_ylabel(\"TOTAL\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The most Cloud Computing platforms used is Amazon Web Service Especially by data scientist. On the other hand, the majority of the answerers do not use cloud computing products and big data/analytics products (view below graphs)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get activity columns from DataFrame only_ml_activitiabses\ncolumns = question_column(\"Q30\", only_ml_activities)\n# Change columns name\nchange_name = change_column_name(columns)\n# Change cell value 0 or 1\nQ30 = change_value(change_name)\n# Drop the last column\nQ30_drop = Q30.drop(Q30.columns[-1], axis=1)\n# Concatenate activity columns with respondent role columns\nQ5_Q30 = pd.concat([only_ml_activities[\"Q5\"], Q30_drop], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,5))\nQ5_Q30.groupby(\"Q5\").sum().plot(ax=ax)\nax.set_xlabel(\"ROLE\")\nax.set_ylabel(\"TOTAL\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get activity columns from DataFrame only_ml_activitiabses\ncolumns = question_column(\"Q31\", only_ml_activities)\n# Change columns name\nchange_name = change_column_name(columns)\n# Change cell value 0 or 1\nQ31 = change_value(change_name)\n# Drop the last column\nQ31_drop = Q31.drop(Q31.columns[-1], axis=1)\n# Concatenate activity columns with respondent role columns\nQ5_Q31 = pd.concat([only_ml_activities[\"Q5\"], Q31_drop], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,5))\nQ5_Q31.groupby(\"Q5\").sum().plot(ax=ax)\nax.set_xlabel(\"ROLE\")\nax.set_ylabel(\"TOTAL\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### More information"},{"metadata":{},"cell_type":"markdown","source":"The graph below show us that the main hosted notebook product used for \"**Build prototypes to explore applying machine learning to new areas**\" tasks is Google Colab. And Kaggle Notebook(kernels) for other tasks."},{"metadata":{"trusted":true},"cell_type":"code","source":"for x in range(len(Q9_drop.columns)-1):\n    column = pd.DataFrame(Q9_drop[Q9_drop.columns[x]])\n    df=pd.concat([column, Q17_drop], axis=1)\n    df.groupby(Q9_drop.columns[x]).sum().transpose().plot.barh()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 8. Conclusion"},{"metadata":{},"cell_type":"markdown","source":"We conclude by saying that there is not really a big difference between scientist data and other roles. Because they perform the same tasks, use the same tools. However tools like **Automated Machine Learning Tools, Machine Learning products** are not used enough. Data science communities should further educate others about the benefits of these tools."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}