{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Content\n\nHey, thanks for viewing my Kernel!\n\nIf you like my work, please, leave an upvote: it will be really appreciated and it will motivate me in offering more content to the Kaggle community ! :)\n\nThis is a survey dataset that is about data science and machine learning in 2019. The survey was live for three weeks in October and is finished with 19,717 responses. The objective here is to find the difference between data scientists with high and low salaries. This work has 3 parts. You can see these parts below.\n\n**Part 1:** Data Cleaning\n\n**Part 2:** Data Analysis\n\n**Part 3:** Results","metadata":{}},{"cell_type":"markdown","source":"# Data Cleaning\n\nThe objective here is to find the different data scientists with high and low salaries. Therefore, we dropped rows that are equal to 'Student' or 'Not employed'. After that, we will look at data distribution for visual information.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport warnings\n\n\nwarnings.simplefilter(\"ignore\")\nsns.set(font_scale=1)\n\ndf = pd.read_csv(\"../input/kaggle-survey-2019/multiple_choice_responses.csv\", low_memory = False)\ndf = df[~df['Q5'].isin([\"Student\", \"Not employed\"])]","metadata":{"execution":{"iopub.status.busy":"2021-12-27T07:08:39.246277Z","iopub.execute_input":"2021-12-27T07:08:39.247225Z","iopub.status.idle":"2021-12-27T07:08:42.823161Z","shell.execute_reply.started":"2021-12-27T07:08:39.247115Z","shell.execute_reply":"2021-12-27T07:08:42.822115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-27T07:08:42.824959Z","iopub.execute_input":"2021-12-27T07:08:42.82523Z","iopub.status.idle":"2021-12-27T07:08:42.861086Z","shell.execute_reply.started":"2021-12-27T07:08:42.8252Z","shell.execute_reply":"2021-12-27T07:08:42.860112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_distirubution(df, cols, normalize=True):\n    df_survey_result = df.loc[1:, :]\n    labels = df.loc[0, cols].values\n    \n    n_cols = 2\n    nrows = round(len(cols) / n_cols)\n    fig, axes = plt.subplots(nrows, n_cols, figsize=(24, 12))\n    plt.subplots_adjust(hspace=0.4)\n    \n    index = 0\n    for row in range(nrows):\n        for col in range(n_cols):\n            df_count = df_survey_result[cols[index]].value_counts(normalize=True)\n            df_count = df_count.mul(100)\n            df_count = df_count.rename('percent').reset_index()\n            \n            df_count = df_count[df_count['percent'] > 1]\n\n            g = sns.barplot(y='index', x='percent', data=df_count, ax=axes[row][col])\n            axes[row][col].set_xlim(0,100)\n            axes[row][col].set_title(labels[index])\n\n            for p in axes[row][col].patches:\n                txt = str(p.get_width().round(2)) + '%'\n                #txt_x = p.get_x() \n                #txt_y = p.get_height()\n                txt_x = p.get_width() \n                txt_y = p.get_y() + p.get_height() / 2\n                axes[row][col].text(txt_x,txt_y,txt)\n            \n            index += 1","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-27T07:08:42.866081Z","iopub.execute_input":"2021-12-27T07:08:42.866302Z","iopub.status.idle":"2021-12-27T07:08:42.879376Z","shell.execute_reply.started":"2021-12-27T07:08:42.866275Z","shell.execute_reply":"2021-12-27T07:08:42.878306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Q1 age, Q2 gender, Q3 country, Q4 education, Q5 job title, Q10 income\ncols = ['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q10']\nplot_distirubution(df, cols)","metadata":{"execution":{"iopub.status.busy":"2021-12-27T07:08:42.881278Z","iopub.execute_input":"2021-12-27T07:08:42.881607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Analysis\n\nThe type of compensation_num is a string. Therefore, firstly we clean and convert string data to integer data. Then we divided compensation data into 3 groups and gave the 'compensation_num_group' name to this column. This column represents 3 different incomes that are low, medium, high.\n\nAfter that, we calculated high and low-income differences by categorical_distribution_diff function and we plotted graphs according to categorical distribution score. The first graph plots the most important column and the last graph plots the least important column.","metadata":{}},{"cell_type":"code","source":"df['compensation_num'] = df['Q10'].str.replace('$', '')\ndf['compensation_num'] = df['compensation_num'].str.replace(',', '')\ndf['compensation_num'] = df['compensation_num'].str.replace('> 500000', '600000')\n\nquenstion_dict = {}\nfor index, value in enumerate(df.loc[0, :]):\n    quenstion_dict[df.columns[index]] = value\n\ndf['low_compensation_num'] = df.loc[1:, 'compensation_num'].str.split('-').str[0]\ndf['high_compensation_num'] = df.loc[1:, 'compensation_num'].str.split('-').str[1]\n\ndf['low_compensation_num'] = df['low_compensation_num'].fillna(-1)\ndf['high_compensation_num'] = df['high_compensation_num'].fillna(-1)\n\ndf['low_compensation_num'] = df['low_compensation_num'].astype(int)\ndf['high_compensation_num'] = df['high_compensation_num'].astype(int)\n\ndf['compensation_num'] = (df['low_compensation_num'] + df['high_compensation_num']) / 2 \ndf = df[df['compensation_num'] != -1]\n\ndf = df.drop(['low_compensation_num', 'high_compensation_num'], 1)\ndf['compensation_num_group'] = pd.qcut(df['compensation_num'], 3, labels=[\"low\", \"medium\", \"high\"])\n\nprint(df['compensation_num_group'].value_counts())","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def group_cols(df):\n    cols = df.columns\n    \n    col_part = []\n    for col in cols:\n        if '_' in col:\n            col_part.append(col)\n    \n    cols_1 = list(set(cols) - set(col_part))\n    \n    temp_df = pd.DataFrame(col_part)\n    temp_df['question'] = temp_df[0].str.split('_').str[0]\n    temp_group = temp_df.groupby('question')[0]\n    \n    cols_2 = []\n    for name, group in temp_group:\n        if len(group) > 1:\n            cols_2.append(list(group.values))\n    \n    return list(cols_1 + cols_2)\n\n\ndef categorical_distribution_diff(x, y):\n    x_counts = x.value_counts()\n    y_counts = y.value_counts()\n    \n    total_diff = 0\n    for index in x_counts.index:\n        try:\n            diff = abs(x_counts[index] - y_counts[index])\n            total_diff += diff\n        except:\n            total_diff += x_counts[index]\n    \n    for index in y_counts.index:\n        try:\n            diff = abs(x_counts[index] - y_counts[index])\n            total_diff += diff\n        except:\n            total_diff += y_counts[index]\n    \n    return total_diff / 2","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_distribution_diff(df, questions, target_col):\n    df_survey_result = df.loc[1:, :]\n    \n    low_df = df_survey_result[df_survey_result[target_col] == 'low']\n    high_df = df_survey_result[df_survey_result[target_col] == 'high']\n    \n    score_list = []\n    for col in questions:\n        if type(col) is str:\n            dist_diff = categorical_distribution_diff(low_df[col], high_df[col])\n            score_list.append(dist_diff)\n        else:\n            total_diff = 0\n            for q in col:\n                if 'TEXT' in q:\n                    continue\n                dist_diff = categorical_distribution_diff(low_df[q], high_df[q])\n                total_diff += dist_diff\n            total_diff = total_diff\n            score_list.append(dist_diff)\n    \n    score_np = np.array(score_list)\n    sort_index = np.argsort(score_np)[::-1]\n    \n    score_cols = {}\n    for order in sort_index:\n        if type(questions[order]) is str:\n            score_cols[questions[order]] = questions[order], score_np[order]\n        else:\n            question_list = []\n            for q in questions[order]:\n                if 'TEXT' in q:\n                    continue\n                question_list.append(q)\n            if len(question_list) <= 1:\n                continue\n            score_cols[questions[order][0].split('_')[0]] = question_list, score_np[order]\n    \n    return score_cols\n\n\ndef long_sentences_seperate(sentence, step=10):\n    try:\n        splittext = sentence.split(\" \")\n        for x in range(step, len(splittext), step):\n            splittext[x] = \"\\n\"+splittext[x].lstrip()\n        text = \" \".join(splittext)\n        return text\n    except:\n        return sentence","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_point_salary(df, target='', country='all'):\n    if country != 'all':\n        temp_df = df[df['Q3'] == country]\n        if len(temp_df) <= 0:\n            print('There is no such a country in dataset like ' + str(country) + ' !!!')\n            print('Here is the countries list: ', df['Q3'].unique())\n            return 0\n    else:\n        temp_df = df.copy()\n        \n    x_list = ['Q4', 'Q15', 'Q15', 'Q15', 'Q15']\n    y_list = ['Q2', 'Q1', 'Q4', 'Q5', 'Q19']\n    \n    fig, ax = plt.subplots(len(x_list))\n    plt.close(fig)\n    ax_index = 0\n    for x, y in zip(x_list, y_list):\n        x_values = temp_df[x].unique()\n        counts_list = []\n        for target_value in ['low', 'medium', 'high']:\n            ttemp_df = temp_df[temp_df[target] == target_value]\n            for value_name_x in x_values:\n                tttemp_df = ttemp_df[ttemp_df[x] == value_name_x]\n                counts_y = tttemp_df[y].value_counts()\n                for value_name_y in counts_y.index:\n                    condition_1 = np.logical_and(temp_df[y]==value_name_y, temp_df[x]==value_name_x)\n                    condition_2 = np.logical_and(condition_1, temp_df[target]==target_value)\n                    temp_df.loc[condition_2, 'size'] = counts_y.loc[value_name_y]\n                    counts_list.append(counts_y.loc[value_name_y])\n        \n        temp_df[y] = temp_df[y].apply(lambda x: long_sentences_seperate(x, step=4))\n        temp_df[x] = temp_df[x].apply(lambda x: long_sentences_seperate(x, step=4))\n        \n        minsize = min(counts_list)\n        maxsize = max(counts_list)\n        \n        chart = sns.relplot(data=temp_df, y=y, x=x, col=target, hue='size', hue_norm=(minsize,maxsize), \n                            size='size', size_norm=(1, 1000), sizes=(minsize,maxsize), kind='scatter', \n                            legend='brief', ax=ax[ax_index])\n        ax_index += 1\n        for axes in chart.axes.flat:\n            _ = axes.set_xticklabels(axes.get_xticklabels(), rotation=90)\n    plt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_treemap_salary(df, target='', country='all'):\n    if country != 'all':\n        temp_df = df[df['Q3'] == country]\n        if len(temp_df) <= 0:\n            print('There is no such a country in dataset like ' + str(country) + ' !!!')\n            print('Here is the countries list: ', df['Q3'].unique())\n            return 0\n    else:\n        temp_df = df.copy()\n    \n    temp_df['Q15'] = temp_df['Q15'].fillna('None')\n    temp_df['Q11'] = temp_df['Q11'].fillna('None')\n    \n    x_list = ['Q2', 'Q3', 'Q5']\n    y_list = ['Q4', 'Q1', 'Q15']\n    z_list = ['Q5', 'Q6', 'Q11']\n    title_list = ['Genders', 'Countries', 'Job Titles', 'Courses']\n    for title, x, y, z in zip(title_list, x_list, y_list, z_list):\n        x_values = temp_df[x].unique()\n        z_values = temp_df[z].unique()\n        counts_list = []\n        for target_value in ['low', 'medium', 'high']:\n            ttemp_df = temp_df[temp_df[target] == target_value]\n            for value_name_z in z_values:\n                tttemp_df = ttemp_df[ttemp_df[z] == value_name_z]\n                for value_name_x in x_values:\n                    ttttemp_df = tttemp_df[tttemp_df[x] == value_name_x]\n                    counts_y = ttttemp_df[y].value_counts()\n                    for value_name_y in counts_y.index:\n                        condition_1 = np.logical_and(temp_df[y]==value_name_y, temp_df[x]==value_name_x)\n                        condition_2 = np.logical_and(condition_1, temp_df[target]==target_value)\n                        condition_3 = np.logical_and(condition_2, temp_df[z]==value_name_z)\n                        temp_df.loc[condition_2, 'size'] = counts_y.loc[value_name_y]\n                        counts_list.append(counts_y.loc[value_name_y])\n        \n        fig = px.treemap(temp_df, path=[px.Constant(title), x, y, z], values='size',\n                      color='compensation_num', color_continuous_scale='RdBu')\n        #fig.update_layout(margin = dict(t=50, l=25, r=25, b=25))\n        fig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_parallel_categories_salary(df, country='all'):\n    if country != 'all':\n        temp_df = df[df['Q3'] == country]\n        if len(temp_df) <= 0:\n            print('There is no such a country in dataset like ' + str(country) + ' !!!')\n            print('Here is the countries list: ', df['Q3'].unique())\n            return 0\n    else:\n        temp_df = df.copy()\n    \n    temp_df['compensation_num_factorized'] = pd.qcut(temp_df['compensation_num'], 3, labels=[1, 2, 3])\n    \n    #################################################################\n    \n    fig = px.parallel_categories(temp_df, dimensions=['Q4', 'Q2', 'Q15'], \n                                 color=\"compensation_num_factorized\", color_continuous_scale='RdBu',\n                                labels={'Q4':'Educations', 'Q2':'Genders', 'Q15':'Experiences'})\n    fig.show()\n    \n    #################################################################\n    \n    ttemp_df = temp_df[temp_df['Q3'].isin(['France', 'India', 'United States of America', 'Germany', 'Russia', 'Japan',\n                                        'Other', 'Brazil', 'Canada', 'Spain', 'United Kingdom of Great Britain and Northern Ireland'])]\n    \n    fig = px.parallel_categories(ttemp_df, dimensions=['Q11', 'Q3', 'Q5'], \n                                 color=\"compensation_num_factorized\", color_continuous_scale='RdBu',\n                                labels={'Q11':'Spending Money For ML', 'Q3':'Countries', 'Q5':'Job Titles'})\n    fig.show()\n    \n    #################################################################\n    \n    def data_preparation(df_indef, col_names, targets):\n        df_list = []\n        y_label = col_names[0].split('_')[0]\n        df_cols = targets.copy()\n        df_cols.append(y_label)\n        for col_n in col_names:\n            df_part = pd.DataFrame(columns=df_cols)\n            df_part[targets] = df_indef[targets]\n            df_part[y_label] = df_indef[col_n]\n            df_list.append(df_part)\n        df_all = pd.concat(df_list)\n        return df_all\n    courses = ['Q13_Part_1', 'Q13_Part_2', 'Q13_Part_3', 'Q13_Part_4', 'Q13_Part_5', 'Q13_Part_6', 'Q13_Part_7', 'Q13_Part_8', \n               'Q13_Part_9', 'Q13_Part_10', 'Q13_Part_11', 'Q13_Part_12']\n    target_list = ['Q14', 'Q1', 'compensation_num_factorized']\n    ttemp_df = data_preparation(temp_df, courses, target_list)\n    \n    ttemp_df = ttemp_df.dropna()\n    fig = px.parallel_categories(ttemp_df, dimensions=['Q13', 'Q14', 'Q1'], \n                                 color=\"compensation_num_factorized\", color_continuous_scale='RdBu',\n                                labels={'Q13':'Courses', 'Q14':'ML Tools', 'Q1':'Ages'})\n    fig.show()\n    \n    #################################################################\n    \n    ml_models = ['Q28_Part_1', 'Q28_Part_2', 'Q28_Part_3', 'Q28_Part_4', 'Q28_Part_5', 'Q28_Part_6', 'Q28_Part_7', 'Q28_Part_8', \n                 'Q28_Part_9', 'Q28_Part_10', 'Q28_Part_11', 'Q28_Part_12']\n    target_list = ['Q14', 'Q1', 'compensation_num_factorized']\n    ttemp_df = data_preparation(temp_df, ml_models, target_list)\n    \n    ttemp_df = ttemp_df.dropna()\n    fig = px.parallel_categories(ttemp_df, dimensions=['Q28', 'Q14', 'Q1'], \n                                 color=\"compensation_num_factorized\", color_continuous_scale='RdBu',\n                                labels={'Q28':'ML Models', 'Q14':'ML Tools', 'Q1':'Ages'})\n    fig.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_parallel_categories_salary(df, country='all')\n\nplot_treemap_salary(df, target='compensation_num_group', country='all')\n\nplot_point_salary(df, target='compensation_num_group', country='all')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_salary(df, score_cols, quenstion_dict, target='', country='all'):\n    n_cols = 2\n    keys = list(score_cols.keys())\n    keys.remove('Time from Start to Finish (seconds)')\n    keys.remove('compensation')\n    keys.remove('Q10')\n    nrows = round(len(keys) / n_cols)\n    fig, axes = plt.subplots(nrows, n_cols, figsize=(16, 288))\n    plt.subplots_adjust(hspace=0.15, wspace=0.5)    \n    \n    index = 0\n    for row in range(nrows):\n        for col in range(n_cols):\n            col_name, score = score_cols[keys[index]]\n            \n            if country != 'all':\n                temp_df = df[df['Q3'] == country]\n                if len(temp_df) <= 0:\n                    print('There is no such a country in dataset like ' + str(country) + ' !!!')\n                    print('Here is the countries list: ', df['Q3'].unique())\n                    return 0\n            else:\n                temp_df = df.copy()\n                    \n            if type(col_name) is str:\n                df_count = temp_df[col_name].value_counts(normalize=True)\n                df_count = df_count.mul(100)\n                df_count.index.rename(col_name, inplace=True)\n                df_count = df_count.rename('percent').reset_index()\n                if col_name != 'Q3':\n                    df_count = df_count[df_count['percent'] > 1]\n                else:\n                    df_count = df_count[df_count['percent'] > 2]\n                temp_df = temp_df[temp_df[col_name].isin(df_count[col_name])]\n                \n                temp_df[col_name] = temp_df[col_name].apply(lambda x: long_sentences_seperate(x, step=3))\n                plot_order = temp_df[col_name].value_counts(normalize=True).index\n                sns.countplot(data=temp_df, y=col_name, hue=target, order=plot_order, ax=axes[row][col])\n                #title_name = title_name + ' - Score: ' + str(score)\n                title_name_new = long_sentences_seperate(quenstion_dict[col_name])\n                axes[row][col].set_title(title_name_new)\n                \n                percentages = []\n                for plot_index in plot_order:\n                    df_percentages = temp_df[temp_df[col_name] == plot_index][target].value_counts(normalize=True)\n                    percentages.extend(df_percentages.loc[['low', 'medium', 'high']].values)\n                \n                percentages_y = []\n                for p in axes[row][col].patches:\n                    txt_y = p.get_y()\n                    percentages_y.append(txt_y)\n                percentages_y = np.array(percentages_y)\n                percentages_order = percentages_y.argsort()\n                \n                for p_index in range(0, len(axes[row][col].patches)):\n                    p = axes[row][col].patches[percentages_order[p_index]]\n                    txt = str(round(percentages[p_index], 2)) + '%'\n                    txt_x = p.get_width() \n                    txt_y = p.get_y() + p.get_height() / 2\n                    axes[row][col].text(txt_x,txt_y,txt)\n            else:\n                df_list = []\n                y_label = col_name[0].split('_')[0]\n                for col_n in col_name:\n                    df_part = pd.DataFrame(columns=[target, y_label])\n                    df_part[target] = temp_df[target]\n                    df_part[y_label] = temp_df[col_n]\n                    df_list.append(df_part)\n                df_all = pd.concat(df_list)\n                \n                df_all[y_label] = df_all[y_label].apply(lambda x: long_sentences_seperate(x, step=3))\n                plot_order = df_all[y_label].value_counts(normalize=True).index\n                sns.countplot(data=df_all, y=y_label, hue=target, order=plot_order, ax=axes[row][col])\n                title_name = quenstion_dict[col_name[0]]\n                #title_name = title_name + ' - Score: ' + str(score)\n                title_name_new = long_sentences_seperate(title_name)\n                axes[row][col].set_title(title_name_new)\n                \n                percentages = []\n                for plot_index in plot_order:\n                    df_percentages = df_all[df_all[y_label] == plot_index][target].value_counts(normalize=True)\n                    percentages.extend(df_percentages.loc[['low', 'medium', 'high']].values)\n                \n                percentages_y = []\n                for p in axes[row][col].patches:\n                    txt_y = p.get_y()\n                    percentages_y.append(txt_y)\n                percentages_y = np.array(percentages_y)\n                percentages_order = percentages_y.argsort()\n                \n                for p_index in range(0, len(axes[row][col].patches)):\n                    p = axes[row][col].patches[percentages_order[p_index]]\n                    txt = str(round(percentages[p_index], 2)) + '%'\n                    txt_x = p.get_width() \n                    txt_y = p.get_y() + p.get_height() / 2\n                    axes[row][col].text(txt_x,txt_y,txt)\n            index += 1","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"questions = group_cols(df)\n\nscore_cols = find_distribution_diff(df, questions, 'compensation_num_group')\n\nsns.set(font_scale=1.2)\n\nplot_salary(df, score_cols, quenstion_dict, target='compensation_num_group', country='all')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Results\n\nAccording to the order of count plots, the country is the most important feature for a high salary. **USA, Germany**, and **Canada** are the most common high-paying countries for data scientists. \n\nThe second important feature is the experience. A data scientist that been working for **5 years in Data Analysis** and for **3–4 years in Machine Learning**, is experienced. Age and experience are the same features and both of them represent the experience.\n\nSpending money on machine learning is the third important feature. If someone spent over 1000 dollars on machine learning, it can earn more salary than other data scientists. But the most significant thing in this plot is a lot of data scientists have high salaries without spending money on machine learning. This situation shows us the importance of **free sources**.\n\nThe fourth important feature is the properties of the company that data scientists work for. If the company has a machine learning model for more than **2 years in product**, **20 people** that are responsible for data science, and more than 1**0 000 employees**, that company give a high salary for a data scientist.\n\nJob title and education of the data scientist are other important features. The data scientist that has a **Product/Project Manager** job title and a** Doctoral degree or Master's degree** earns a high salary. These features are tied with features of experience because becoming a Product/Project Manager and having a Doctoral degree or Master's degree needs time.\n\nPrograming language and databases are also important features for data science. The most common programming language is python but **SQL** is more significant for a high salary and all databases are serious features for high compensation in general. According to this result, we can say \"All good data scientists have to know databases\".\n\nThere are a lot of online courses for data science. The most common online platform for data science courses is **Coursera** and **Fast.ai** has the highest rate for high salaries.\n\nMachine learning models are used for making decisions. The most important machine learning model is Xgboost. This model is also the most common ml model in **Kaggle**.\n\nCloud computing and data analysis tools are also important features. **AWS** is the most important tool for data science.\n\n                                                         ...\n\nThis analysis was done for all countries but the analysis can change according to the country. If you are interested in the relationship between high compensation and data science talent in your own country, you can copy & edit this [notebook](https://www.kaggle.com/hasanbasriakcay/difference-between-500-225-000-income-in-ds). Just you should change the country variable in the plot_salary function.\n\nIf you like my work, please, leave an upvote: it will be really appreciated and it will motivate me in offering more content to the Kaggle community ! :)","metadata":{}}]}