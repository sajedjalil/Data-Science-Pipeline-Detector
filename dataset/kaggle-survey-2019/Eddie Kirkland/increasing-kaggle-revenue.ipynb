{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Increasing Kaggle Revenue: Analyzing user data to recommend the best new product\n\nIn this project, we will create recommendations for increasing revenue at Kaggle, an online community for data science professionals. We will analyze a Kaggle customer survey, attempting to learn if there are any indicators of potential revenue growth for the company. To make our recommendations, we will try to learn:\n\n* Is there market potential for a \"freemium\" kernel product?\n* Is there market potential for a consulting marketplace?\n* Based on current user data, which is more likely to be more profitable?\n\n## Summary of Observations\n\n* Over 60% of Kaggle's users earn less than $50k per year, and are unlikely to spend discretionary income on a higher-tier subscription. In addition, over 58% of users work in companies of less than 1,000 employees. Companies willing to invest in a costly enterprise solution seem to be a small segment of Kaggle's current user base.\n* Although subscription services can drive long-term revenue through creating the \"strategic value\" of an increased user base, Kaggle seems unlikely to gain a significant amount of new users through offering the freemium product.\n* Users of Kaggle's current products are highly educated, largely based outside the US, and tend toward the lower tiers of salary compensation. All of these factors could make Kaggle users very promising candidates for high-quality remote contract work on Data Science projects.\n\n## Summary of Recommendations\n\nThe results of Kaggle's user survey show that **Kaggle is more likely to drive significant future revenue from a monetized consultant marketplace, rather than a freemium kernel product.** It would be difficult to recoup a significant investment in developing a freemium kernel product, and Kaggle's current userbase makes it unlikely to draw significant market share away from GitHub and other existing products. In contrast, given their competent and geographically diverse user base, a robust Data Science contractor marketplace should result in a more significant increase of revenue.\n\nFor more details and a thorough description of the methodology of this report, please see below."},{"metadata":{},"cell_type":"markdown","source":"# Methodology #\n\n## Data Source ##\nThe data for this project is taken from a publicly-released [Kaggle competition](https://www.kaggle.com/c/kaggle-survey-2019). The survey was deployed from October 8-28, 2019, and responses were taken largely from Kaggle-related channels (email list, social media, and discussion forums). The survey received 19,717 useable responses, and filtered out any responses that were flagged automatically as \"Spam.\"\n\n## Area of interest ##\nAn outline of some of Kaggle's future potential revenue streams can be found in [an article posted by Kaggle's founder, Anthony Goldbloom](https://www.quora.com/How-does-Kaggle-make-money), on Quora.com. In this post, Anthony Goldbloom lays out several current revenue streams for Kaggle:\n\n* Featured competitions\n* Recruiting competitions\n* Research competitions\n\nIn addition, Goldbloom lays out several services Kaggle was planning on adding to generate revenue:\n\n* Making [Kaggle kernels](http://www.kaggle.com/kernels_) a freemium service, to which companies will subscribe as a team collaboration space.\n* A \"data science marketplace for consulting help.\"\n\nAs of the writing of this report (November 25, 2019), neither of these options are visibly listed on the Kaggle website, and are thus both potential revenue sources.\n\n## Hypothesis ##\n\nThe \"team collaboration\" space is currently dominated by [GitHub](https://github.com/), which also uses a freemium service to make money via Enterprise subscriptions. GitHub was recently aquired by Microsoft for 7.5 billion, and the purchase price was driven largely by the opportunity provided in GitHub's collaborative network. According to [Harvard Business Review](https://hbr.org/2018/06/why-microsoft-is-willing-to-pay-so-much-for-github):\n\n> In other words, Microsoft is not paying 7.5 billion for GitHub for its ability to make money (its financial value). It’s paying for the access it gets to the legions of developers who use GitHub’s code repository products on a daily basis (the company’s strategic value) — so they can be guided into the Microsoft developer environment, where the real money is made.\n\nWith this in mind, potential revenue for Kaggle is not simply based on potential subscription dollars, but on what, if any, marketshare Kaggle can take from GitHub in this domain. As a result, it is a resonable hypothesis that **given Kaggle's current customer base, a Kernels freemium service would provide greater potential for future revenue than a data science consulting marketplace.**\n\n## Required Data needed ##\n\nTo test this hypothesis, we need to explore:\n\n* Information on demographics and expertise of current customers\n* Information on size of customers' data science teams (most likely to utilize a kernel-based system)\n* Information on % of users employed in large-budget companies (most likely to purchase enterprise system)\n* Information on % of users with significant education and Data Science experience (most likely to generate high-dollar revenue in consulting marketplace)\n\nIn addition, we will explore other demographics provided in the dataset to see if any other potential hypotheses emerge.\n\n## Assumptions ##\n\nIt is important to note several key assumptions that are informing this analysis.\n\n**1. The survey data is representative of Kaggle's overall customer base.**\nWith the available data, it is impossible to know if this survey is representative of the overall population of Kaggle customers. Selection bias is likely present in some form. However, given the large number of responses in the survey, it is likely a reliable source for the purpose of this analysis.\n\n**2. A new freemium kernel product would be structured much like others in the domain, with a paid subscription tier and larger-team enterprise level tier.**\nThis is the strategy used by [GitHub](https://github.com/enterprise), the leader in this space, as well as most other freemium services.\n\n**3. In order for Kaggle to make significant revenue from a freemium kernel product, they will need a base of current customers with the financial means to subscribe.**\nThis requires a large group of either users with discretionary income to spend on subscriptions, or employees of large companies with the budget and need for enterprise subscriptions."},{"metadata":{},"cell_type":"markdown","source":"# Data Cleaning #\n\nTo begin, we import and clean the dataset provided from Kaggle. Four datasets are provided, which we will read in as separate files. The `'survey_schema'` file shows that not all questions were given to all participants, which is helpful in understanding null values in the larger dataset.\n\nOnly the `'mc_responses.csv'` file, which contains the answers to all multiple choice questions, will be relevant for this analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib as plt\n%matplotlib inline\n\n# reading in csv file\nmc = pd.read_csv('/kaggle/input/kaggle-survey-2019/multiple_choice_responses.csv')\n\n# exploring overall data\nmc.info()\nmc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# exploring overall data\nmc.info()\nmc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reassigning header to first row and removing first row\nmc.columns = mc.iloc[0,:]\nmc = mc[1:]\nmc.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove duplicates\nmc = mc.drop_duplicates()\nprint(len(mc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Removing \"text\" columns\ntext_columns = mc.filter(regex=(\".*\\ Text$\"))\nmc.drop(text_columns.columns, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Listing column names\nmc.columns.values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Note:** The dataset contains several multiple-choice categories which are broken over several columns, each with a single response. For ease of use, we can aggregate these columns into a single category for each question, and remove the individual response columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"## Creating 'activities' column\n# Assigning Multiple Choice columns into a single column with nan values\ntest_list = mc.loc[:,'Select any activities that make up an important part of your role at work: (Select all that apply) - Selected Choice - Analyze and understand data to influence product or business decisions':\n                   'Select any activities that make up an important part of your role at work: (Select all that apply) - Selected Choice - Other'].apply(\n    lambda x: \",\".join(x.dropna()), axis=1)\ntest_list = test_list.replace({'nannannan':np.nan})\nmc['activities'] = test_list\n# Dropping Multiple Choice columns from range\ndrop_list = mc.loc[:,'Select any activities that make up an important part of your role at work: (Select all that apply) - Selected Choice - Analyze and understand data to influence product or business decisions':\n                   'Select any activities that make up an important part of your role at work: (Select all that apply) - Selected Choice - Other']\ndrop_list_cols = list(drop_list.columns.values)\nmc.drop(drop_list_cols, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Creating 'fav_media' column\n# Assigning Multiple Choice columns into a single column with nan values\ntest_list = mc.loc[:,'Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - Twitter (data science influencers)':\n                   'Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - Other'].apply(\n    lambda x: \",\".join(x.dropna()), axis=1)\ntest_list = test_list.replace({'nannannan':np.nan})\nmc['fav_media'] = test_list\n# Dropping Multiple Choice columns from range\ndrop_list = mc.loc[:,'Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - Twitter (data science influencers)':\n                   'Who/what are your favorite media sources that report on data science topics? (Select all that apply) - Selected Choice - Other']\ndrop_list_cols = list(drop_list.columns.values)\nmc.drop(drop_list_cols, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Creating 'dscourse_platforms' column\n# Assigning Multiple Choice columns into a single column with nan values\ntest_list = mc.loc[:,'On which platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - Udacity':\n                   'On which platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - Other'].apply(\n    lambda x: \",\".join(x.dropna()), axis=1)\ntest_list = test_list.replace({'nannannan':np.nan})\nmc['dscourse_platforms'] = test_list\n# Dropping Multiple Choice columns from range\ndrop_list = mc.loc[:,'On which platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - Udacity':\n                   'On which platforms have you begun or completed data science courses? (Select all that apply) - Selected Choice - Other']\ndrop_list_cols = list(drop_list.columns.values)\nmc.drop(drop_list_cols, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Creating 'ides_used' column\n# Assigning Multiple Choice columns into a single column with nan values\ntest_list = mc.loc[:,\"Which of the following integrated development environments (IDE's) do you use on a regular basis?  (Select all that apply) - Selected Choice - Jupyter (JupyterLab, Jupyter Notebooks, etc) \":\n                   \"Which of the following integrated development environments (IDE's) do you use on a regular basis?  (Select all that apply) - Selected Choice - Other\"].apply(\n    lambda x: \",\".join(x.dropna()), axis=1)\ntest_list = test_list.replace({'nannannan':np.nan})\nmc['ides_used'] = test_list\n# Dropping Multiple Choice columns from range\ndrop_list = mc.loc[:,\"Which of the following integrated development environments (IDE's) do you use on a regular basis?  (Select all that apply) - Selected Choice - Jupyter (JupyterLab, Jupyter Notebooks, etc) \":\n                   \"Which of the following integrated development environments (IDE's) do you use on a regular basis?  (Select all that apply) - Selected Choice - Other\"]\ndrop_list_cols = list(drop_list.columns.values)\nmc.drop(drop_list_cols, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Creating 'notebooks_used' column\n# Assigning Multiple Choice columns into a single column with nan values\ntest_list = mc.loc[:,'Which of the following hosted notebook products do you use on a regular basis?  (Select all that apply) - Selected Choice -  Kaggle Notebooks (Kernels) ':\n                   'Which of the following hosted notebook products do you use on a regular basis?  (Select all that apply) - Selected Choice - Other'].apply(\n    lambda x: \",\".join(x.dropna()), axis=1)\ntest_list = test_list.replace({'nannannan':np.nan})\nmc['notebooks_used'] = test_list\n# Dropping Multiple Choice columns from range\ndrop_list = mc.loc[:,'Which of the following hosted notebook products do you use on a regular basis?  (Select all that apply) - Selected Choice -  Kaggle Notebooks (Kernels) ':\n                   'Which of the following hosted notebook products do you use on a regular basis?  (Select all that apply) - Selected Choice - Other']\ndrop_list_cols = list(drop_list.columns.values)\nmc.drop(drop_list_cols, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Creating 'langs_used' column\n# Assigning Multiple Choice columns into a single column with nan values\ntest_list = mc.loc[:,'What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - Python':\n                   'What programming language would you recommend an aspiring data scientist to learn first? - Selected Choice'].apply(\n    lambda x: \",\".join(x.dropna()), axis=1)\ntest_list = test_list.replace({'nannannan':np.nan})\nmc['langs_used'] = test_list\n# Dropping Multiple Choice columns from range\ndrop_list = mc.loc[:,'What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - Python':\n                   'What programming language would you recommend an aspiring data scientist to learn first? - Selected Choice']\ndrop_list_cols = list(drop_list.columns.values)\nmc.drop(drop_list_cols, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Creating 'dataviz_used' column\n# Assigning Multiple Choice columns into a single column with nan values\ntest_list = mc.loc[:,'What data visualization libraries or tools do you use on a regular basis?  (Select all that apply) - Selected Choice -  Ggplot / ggplot2 ':\n                   'What data visualization libraries or tools do you use on a regular basis?  (Select all that apply) - Selected Choice - Other'].apply(\n    lambda x: \",\".join(x.dropna()), axis=1)\ntest_list = test_list.replace({'nannannan':np.nan})\nmc['dataviz_used'] = test_list\n# Dropping Multiple Choice columns from range\ndrop_list = mc.loc[:,'What data visualization libraries or tools do you use on a regular basis?  (Select all that apply) - Selected Choice -  Ggplot / ggplot2 ':\n                   'What data visualization libraries or tools do you use on a regular basis?  (Select all that apply) - Selected Choice - Other']\ndrop_list_cols = list(drop_list.columns.values)\nmc.drop(drop_list_cols, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Creating 'hardware_used' column\n# Assigning Multiple Choice columns into a single column with nan values\ntest_list = mc.loc[:,'Which types of specialized hardware do you use on a regular basis?  (Select all that apply) - Selected Choice - CPUs':\n                   'Which types of specialized hardware do you use on a regular basis?  (Select all that apply) - Selected Choice - Other'].apply(\n    lambda x: \",\".join(x.dropna()), axis=1)\ntest_list = test_list.replace({'nannannan':np.nan})\nmc['hardware_used'] = test_list\n# Dropping Multiple Choice columns from range\ndrop_list = mc.loc[:,'Which types of specialized hardware do you use on a regular basis?  (Select all that apply) - Selected Choice - CPUs':\n                   'Which types of specialized hardware do you use on a regular basis?  (Select all that apply) - Selected Choice - Other']\ndrop_list_cols = list(drop_list.columns.values)\nmc.drop(drop_list_cols, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Creating 'ml_alg_used' column\n# Assigning Multiple Choice columns into a single column with nan values\ntest_list = mc.loc[:,'Which of the following ML algorithms do you use on a regular basis? (Select all that apply): - Selected Choice - Linear or Logistic Regression':\n                   'Which of the following ML algorithms do you use on a regular basis? (Select all that apply): - Selected Choice - Other'].apply(\n    lambda x: \",\".join(x.dropna()), axis=1)\ntest_list = test_list.replace({'nannannan':np.nan})\nmc['ml_alg_used'] = test_list\n# Dropping Multiple Choice columns from range\ndrop_list = mc.loc[:,'Which of the following ML algorithms do you use on a regular basis? (Select all that apply): - Selected Choice - Linear or Logistic Regression':\n                   'Which of the following ML algorithms do you use on a regular basis? (Select all that apply): - Selected Choice - Other']\ndrop_list_cols = list(drop_list.columns.values)\nmc.drop(drop_list_cols, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Creating 'ml_tools_used' column\n# Assigning Multiple Choice columns into a single column with nan values\ntest_list = mc.loc[:,'Which categories of ML tools do you use on a regular basis?  (Select all that apply) - Selected Choice - Automated data augmentation (e.g. imgaug, albumentations)':\n                   'Which categories of ML tools do you use on a regular basis?  (Select all that apply) - Selected Choice - Other'].apply(\n    lambda x: \",\".join(x.dropna()), axis=1)\ntest_list = test_list.replace({'nannannan':np.nan})\nmc['ml_tools_used'] = test_list\n# Dropping Multiple Choice columns from range\ndrop_list = mc.loc[:,'Which categories of ML tools do you use on a regular basis?  (Select all that apply) - Selected Choice - Automated data augmentation (e.g. imgaug, albumentations)':\n                   'Which categories of ML tools do you use on a regular basis?  (Select all that apply) - Selected Choice - Other']\ndrop_list_cols = list(drop_list.columns.values)\nmc.drop(drop_list_cols, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Creating 'cvision_used' column\n# Assigning Multiple Choice columns into a single column with nan values\ntest_list = mc.loc[:,'Which categories of computer vision methods do you use on a regular basis?  (Select all that apply) - Selected Choice - General purpose image/video tools (PIL, cv2, skimage, etc)':\n                   'Which categories of computer vision methods do you use on a regular basis?  (Select all that apply) - Selected Choice - Other'].apply(\n    lambda x: \",\".join(x.dropna()), axis=1)\ntest_list = test_list.replace({'nannannan':np.nan})\nmc['cvision_used'] = test_list\n# Dropping Multiple Choice columns from range\ndrop_list = mc.loc[:,'Which categories of computer vision methods do you use on a regular basis?  (Select all that apply) - Selected Choice - General purpose image/video tools (PIL, cv2, skimage, etc)':\n                   'Which categories of computer vision methods do you use on a regular basis?  (Select all that apply) - Selected Choice - Other']\ndrop_list_cols = list(drop_list.columns.values)\nmc.drop(drop_list_cols, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Creating 'nlp_methods_used' column\n# Assigning Multiple Choice columns into a single column with nan values\ntest_list = mc.loc[:,'Which of the following natural language processing (NLP) methods do you use on a regular basis?  (Select all that apply) - Selected Choice - Word embeddings/vectors (GLoVe, fastText, word2vec)':\n                   'Which of the following natural language processing (NLP) methods do you use on a regular basis?  (Select all that apply) - Selected Choice - Other'].apply(\n    lambda x: \",\".join(x.dropna()), axis=1)\ntest_list = test_list.replace({'nannannan':np.nan})\nmc['nlp_methods_used'] = test_list\n# Dropping Multiple Choice columns from range\ndrop_list = mc.loc[:,'Which of the following natural language processing (NLP) methods do you use on a regular basis?  (Select all that apply) - Selected Choice - Word embeddings/vectors (GLoVe, fastText, word2vec)':\n                   'Which of the following natural language processing (NLP) methods do you use on a regular basis?  (Select all that apply) - Selected Choice - Other']\ndrop_list_cols = list(drop_list.columns.values)\nmc.drop(drop_list_cols, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Creating 'ml_frameworks_used' column\n# Assigning Multiple Choice columns into a single column with nan values\ntest_list = mc.loc[:,'Which of the following machine learning frameworks do you use on a regular basis? (Select all that apply) - Selected Choice -   Scikit-learn ':\n                   'Which of the following machine learning frameworks do you use on a regular basis? (Select all that apply) - Selected Choice - Other'].apply(\n    lambda x: \",\".join(x.dropna()), axis=1)\ntest_list = test_list.replace({'nannannan':np.nan})\nmc['ml_frameworks_used'] = test_list\n# Dropping Multiple Choice columns from range\ndrop_list = mc.loc[:,'Which of the following machine learning frameworks do you use on a regular basis? (Select all that apply) - Selected Choice -   Scikit-learn ':\n                   'Which of the following machine learning frameworks do you use on a regular basis? (Select all that apply) - Selected Choice - Other']\ndrop_list_cols = list(drop_list.columns.values)\nmc.drop(drop_list_cols, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Creating 'cloud_platform_used' column\n# Assigning Multiple Choice columns into a single column with nan values\ntest_list = mc.loc[:,'Which of the following cloud computing platforms do you use on a regular basis? (Select all that apply) - Selected Choice -  Google Cloud Platform (GCP) ':\n                   'Which of the following cloud computing platforms do you use on a regular basis? (Select all that apply) - Selected Choice - Other'].apply(\n    lambda x: \",\".join(x.dropna()), axis=1)\ntest_list = test_list.replace({'nannannan':np.nan})\nmc['cloud_platform_used'] = test_list\n# Dropping Multiple Choice columns from range\ndrop_list = mc.loc[:,'Which of the following cloud computing platforms do you use on a regular basis? (Select all that apply) - Selected Choice -  Google Cloud Platform (GCP) ':\n                   'Which of the following cloud computing platforms do you use on a regular basis? (Select all that apply) - Selected Choice - Other']\ndrop_list_cols = list(drop_list.columns.values)\nmc.drop(drop_list_cols, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Creating 'cloud_products_used' column\n# Assigning Multiple Choice columns into a single column with nan values\ntest_list = mc.loc[:,'Which specific cloud computing products do you use on a regular basis? (Select all that apply) - Selected Choice - AWS Elastic Compute Cloud (EC2)':\n                   'Which specific cloud computing products do you use on a regular basis? (Select all that apply) - Selected Choice - Other'].apply(\n    lambda x: \",\".join(x.dropna()), axis=1)\ntest_list = test_list.replace({'nannannan':np.nan})\nmc['cloud_products_used'] = test_list\n# Dropping Multiple Choice columns from range\ndrop_list = mc.loc[:,'Which specific cloud computing products do you use on a regular basis? (Select all that apply) - Selected Choice - AWS Elastic Compute Cloud (EC2)':\n                   'Which specific cloud computing products do you use on a regular basis? (Select all that apply) - Selected Choice - Other']\ndrop_list_cols = list(drop_list.columns.values)\nmc.drop(drop_list_cols, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Creating 'bigdataanalytics_used' column\n# Assigning Multiple Choice columns into a single column with nan values\ntest_list = mc.loc[:,'Which specific big data / analytics products do you use on a regular basis? (Select all that apply) - Selected Choice - Google BigQuery':\n                   'Which specific big data / analytics products do you use on a regular basis? (Select all that apply) - Selected Choice - Other'].apply(\n    lambda x: \",\".join(x.dropna()), axis=1)\ntest_list = test_list.replace({'nannannan':np.nan})\nmc['bigdataanalytics_used_used'] = test_list\n# Dropping Multiple Choice columns from range\ndrop_list = mc.loc[:,'Which specific big data / analytics products do you use on a regular basis? (Select all that apply) - Selected Choice - Google BigQuery':\n                   'Which specific big data / analytics products do you use on a regular basis? (Select all that apply) - Selected Choice - Other']\ndrop_list_cols = list(drop_list.columns.values)\nmc.drop(drop_list_cols, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Creating 'ml_products_used' column\n# Assigning Multiple Choice columns into a single column with nan values\ntest_list = mc.loc[:,'Which of the following machine learning products do you use on a regular basis? (Select all that apply) - Selected Choice - SAS':\n                   'Which of the following machine learning products do you use on a regular basis? (Select all that apply) - Selected Choice - Other'].apply(\n    lambda x: \",\".join(x.dropna()), axis=1)\ntest_list = test_list.replace({'nannannan':np.nan})\nmc['ml_products_used'] = test_list\n# Dropping Multiple Choice columns from range\ndrop_list = mc.loc[:,'Which of the following machine learning products do you use on a regular basis? (Select all that apply) - Selected Choice - SAS':\n                   'Which of the following machine learning products do you use on a regular basis? (Select all that apply) - Selected Choice - Other']\ndrop_list_cols = list(drop_list.columns.values)\nmc.drop(drop_list_cols, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Creating 'automl_tools_used' column\n# Assigning Multiple Choice columns into a single column with nan values\ntest_list = mc.loc[:,'Which automated machine learning tools (or partial AutoML tools) do you use on a regular basis?  (Select all that apply) - Selected Choice -  Google AutoML ':\n                   'Which automated machine learning tools (or partial AutoML tools) do you use on a regular basis?  (Select all that apply) - Selected Choice - Other'].apply(\n    lambda x: \",\".join(x.dropna()), axis=1)\ntest_list = test_list.replace({'nannannan':np.nan})\nmc['automl_tools_used'] = test_list\n# Dropping Multiple Choice columns from range\ndrop_list = mc.loc[:,'Which automated machine learning tools (or partial AutoML tools) do you use on a regular basis?  (Select all that apply) - Selected Choice -  Google AutoML ':\n                   'Which automated machine learning tools (or partial AutoML tools) do you use on a regular basis?  (Select all that apply) - Selected Choice - Other']\ndrop_list_cols = list(drop_list.columns.values)\nmc.drop(drop_list_cols, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Creating 'reldb_products_used' column\n# Assigning Multiple Choice columns into a single column with nan values\ntest_list = mc.loc[:,'Which of the following relational database products do you use on a regular basis? (Select all that apply) - Selected Choice - MySQL':\n                   'Which of the following relational database products do you use on a regular basis? (Select all that apply) - Selected Choice - Other'].apply(\n    lambda x: \",\".join(x.dropna()), axis=1)\ntest_list = test_list.replace({'nannannan':np.nan})\nmc['reldb_products_used'] = test_list\n# Dropping Multiple Choice columns from range\ndrop_list = mc.loc[:,'Which of the following relational database products do you use on a regular basis? (Select all that apply) - Selected Choice - MySQL':\n                   'Which of the following relational database products do you use on a regular basis? (Select all that apply) - Selected Choice - Other']\ndrop_list_cols = list(drop_list.columns.values)\nmc.drop(drop_list_cols, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making column names readable\ncolumn_clean = {'Duration (in seconds)':'duration',\n                'What is your age (# years)?':'age',\n                'What is your gender? - Selected Choice':'gender',\n                'In which country do you currently reside?':'country',\n                'What is the highest level of formal education that you have attained or plan to attain within the next 2 years?':'education',\n                'Select the title most similar to your current role (or most recent title if retired): - Selected Choice':'title',\n                'What is the size of the company where you are employed?':'comp_size',\n                'Approximately how many individuals are responsible for data science workloads at your place of business?':'ds_teamsize',\n                'Does your current employer incorporate machine learning methods into their business?':'use_ml',\n                'What is your current yearly compensation (approximate $USD)?':'compensation',\n                'Approximately how much money have you spent on machine learning and/or cloud computing products at your work in the past 5 years?':'dollars_mlorcloud',\n                'What is the primary tool that you use at work or school to analyze data? (Include text response) - Selected Choice':'prim_analaysistool',\n                'How long have you been writing code to analyze data (at work or at school)?':'coding_years',\n                'Have you ever used a TPU (tensor processing unit)?':'used_tpu',\n                'For how many years have you used machine learning methods?':'ml_years'}\nmc = mc.rename(columns=column_clean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#replacing null str with NaN\nmc = mc.replace('None', np.nan)\nmc = mc.replace('', np.nan)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mc.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for remaining null values\nmc.apply(lambda x: sum(x.notnull()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cleaning Observations ###\nAfter inital exploration, cleaning and consolidation, it seems the data is comprised entirely of `str` objects, rather than numerical values. Several categories are already broken down into broad category bins, which will be helpful for a quick analysis. The number of null values in later categories is to be expected, given the schema of the survey. However, most of these categories are probably not of significant interest for this analysis.\n\nThere are still a large number of null values for some categories which are of interest: `'comp_size'`, `'ds_teamsize'`, `'use_ml'`, `'compensation'`, and `'dollars_mlorcloud`'. However, even after subtracting the null values, there are over 12,000 data points in each of these categories, which should be more than enough for meaningful analysis."},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis (EDA)\n\nWe begin by analyzing categorical variables that are most relevant to our analysis. First, we create a frequency table and bar-graph visualization for each variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Filter categorical variables\ncategorical_columns = [x for x in mc.dtypes.index if mc.dtypes[x]=='object']\n#Exclude ID cols and source:\ncategorical_columns = [x for x in mc if x not in ['duration', 'activities', 'fav_media', 'dscourse_platforms', 'ides_used',\n                      'notebooks_used', 'langs_used', 'dataviz_used', 'hardware_used', 'ml_alg_used',\n                      'ml_tools_used', 'cvision_used', 'nlp_methods_used', 'ml_frameworks_used',\n                      'cloud_platform_used', 'cloud_products_used', 'bigdataanalytics_used_used',\n                      'ml_products_used', 'automl_tools_used', 'reldb_products_used']]\n#Print frequency of all relevant categories\nfor col in categorical_columns:\n    print('\\nFrequency of Categories for %s'%col)\n    print(mc[col].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating Age Frequency Table\nage_freq = mc['age'].value_counts(normalize=True)\nage_freq = age_freq.sort_index(axis=0)\nage_freq = age_freq.reset_index()\nage_freq = pd.DataFrame(age_freq)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Setting style for bar graphs\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# set font\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.sans-serif'] = 'Helvetica'\n\n# set the style of the axes and the text color\nplt.rcParams['axes.edgecolor']='#333F4B'\nplt.rcParams['axes.linewidth']=0.8\nplt.rcParams['xtick.color']='#333F4B'\nplt.rcParams['ytick.color']='#333F4B'\nplt.rcParams['text.color']='#333F4B'\n\n# numeric placeholder for the y axis\nmy_range=list(range(1,len(age_freq.index)+1))\n\nfig, ax = plt.subplots(figsize=(8,5))\n\n# create for each bin a vertical line that starts at y = 0 with the length \n# represented by the specific percentage.\nplt.vlines(x=my_range, ymin=0, ymax=age_freq['age'], color='#007ACC', alpha=0.5, linewidth=30)\n\n# create for each bin a dot at the level of the expense percentage value\n# plt.plot(my_range, age_freq['age'], \"o\", markersize=10, color='#007ACC', alpha=0.6)\n\n# set labels\nax.set_xlabel('Age', fontsize=15, fontweight='black', color = '#333F4B')\nax.set_ylabel('% of Respondents', fontsize=15, fontweight='black', color = '#333F4B')\n\n# set axis\nax.tick_params(axis='both', which='major', labelsize=12)\nplt.xticks(my_range, age_freq['index'])\n\n# add an horizonal label for the y axis \n# fig.text(-0.15, 0.5, '% of Respondants', fontsize=15, fontweight='black', color = '#333F4B')\n\n# change the style of the axis spines\nax.spines['top'].set_color('none')\nax.spines['right'].set_color('none')\nax.spines['left'].set_smart_bounds(True)\nax.spines['bottom'].set_smart_bounds(True)\n\n# set the spines position\nax.spines['bottom'].set_position(('axes', -0.04))\nax.spines['left'].set_position(('axes', 0.015))\n\n# set background color\nax.set_facecolor('white')\n\n# add margin to y-axis\nax.margins(0.1, 0)\n\n# add title\nfig.suptitle('Age of Survey Respondents', fontsize=18, fontweight='black')\n\nplt.savefig('age_freq.png', dpi=300, bbox_inches='tight')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating Gender Frequency Table\ngender_freq = mc['gender'].value_counts(normalize=True)\ngender_freq = gender_freq.reset_index()\ngender_freq = gender_freq.sort_index(axis=0)\ngender_freq = pd.DataFrame(gender_freq)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Creating Gender Frequency Graph\n# Setting style for bar graphs\n%matplotlib inline\n\n# set font\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.sans-serif'] = 'Helvetica'\n\n# set the style of the axes and the text color\nplt.rcParams['axes.edgecolor']='#333F4B'\nplt.rcParams['axes.linewidth']=0.8\nplt.rcParams['xtick.color']='#333F4B'\nplt.rcParams['ytick.color']='#333F4B'\nplt.rcParams['text.color']='#333F4B'\n\n# numeric placeholder for the y axis\nmy_range=list(range(1,len(gender_freq.index)+1))\n\nfig, ax = plt.subplots(figsize=(8,5))\n\n# create for each bin a vertical line that starts at y = 0 with the length \n# represented by the specific percentage.\nplt.vlines(x=my_range, ymin=0, ymax=gender_freq['gender'], color='#007ACC', alpha=0.5, linewidth=50)\n\n# create for each bin a dot at the level of the expense percentage value\n# plt.plot(my_range, age_freq['age'], \"o\", markersize=10, color='#007ACC', alpha=0.6)\n\n# set labels\nax.set_xlabel('Gender', fontsize=15, fontweight='black', color = '#333F4B')\nax.set_ylabel('% of Respondents', fontsize=15, fontweight='black', color = '#333F4B')\n\n# set axis\nax.tick_params(axis='both', which='major', labelsize=12)\nplt.xticks(my_range, gender_freq['index'])\n\n# add an horizonal label for the y axis \n# fig.text(-0.15, 0.5, '% of Respondants', fontsize=15, fontweight='black', color = '#333F4B')\n\n# change the style of the axis spines\nax.spines['top'].set_color('none')\nax.spines['right'].set_color('none')\nax.spines['left'].set_smart_bounds(True)\nax.spines['bottom'].set_smart_bounds(True)\n\n# set the spines position\nax.spines['bottom'].set_position(('axes', -0.04))\nax.spines['left'].set_position(('axes', 0.015))\n\n# set background color\nax.set_facecolor('white')\n\n# add margin to y-axis\nax.margins(0.2, 0)\n\n# add title\nfig.suptitle('Gender of Survey Respondents', fontsize=18, fontweight='black')\n\nplt.savefig('gender_freq.png', dpi=300, bbox_inches='tight')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Renaming long value name\nmc['country'] = mc['country'].replace('United Kingdom of Great Britain and Northern Ireland', 'UK')\nmc['country'] = mc['country'].replace('United States of America', 'USA')\n# Creating Country Frequency Table\ncountry_freq = mc['country'].value_counts(normalize=True, ascending=False)\n#country_freq = country_freq.sort_index(axis=0)\ncountry_freq = country_freq.reset_index()\ncountry_freq = pd.DataFrame(country_freq)\ncountry_freq = country_freq.loc[country_freq['country'] >= .01]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Creating Country Frequency Graph\n# Setting style for bar graphs\n%matplotlib inline\n\n# set font\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.sans-serif'] = 'Helvetica'\n\n# set the style of the axes and the text color\nplt.rcParams['axes.edgecolor']='#333F4B'\nplt.rcParams['axes.linewidth']=0.8\nplt.rcParams['xtick.color']='#333F4B'\nplt.rcParams['ytick.color']='#333F4B'\nplt.rcParams['text.color']='#333F4B'\n\n# numeric placeholder for the y axis\nmy_range=list(range(1,len(country_freq.index)+1))\n\nfig, ax = plt.subplots(figsize=(20,6))\n\n# create for each bin a vertical line that starts at y = 0 with the length \n# represented by the specific percentage.\nplt.vlines(x=my_range, ymin=0, ymax=country_freq['country'], color='#007ACC', alpha=0.5, linewidth=15)\n\n# create for each bin a dot at the level of the expense percentage value\nplt.plot(my_range, country_freq['country'], \"o\", markersize=15, color='#007ACC', alpha=0.9)\n\n# set labels\nax.set_xlabel('Country', fontsize=15, fontweight='black', color = '#333F4B')\nax.set_ylabel('% of Respondents', fontsize=15, fontweight='black', color = '#333F4B')\n\n# set axis\nax.tick_params(axis='both', which='major', labelsize=12)\nplt.xticks(my_range, country_freq['index'], rotation=45)\n\n# add an horizonal label for the y axis \n# fig.text(-0.15, 0.5, '% of Respondants', fontsize=15, fontweight='black', color = '#333F4B')\n\n# change the style of the axis spines\nax.spines['top'].set_color('none')\nax.spines['right'].set_color('none')\nax.spines['left'].set_smart_bounds(True)\nax.spines['bottom'].set_smart_bounds(True)\n\n# set the spines position\nax.spines['bottom'].set_position(('axes', -0.04))\nax.spines['left'].set_position(('axes', 0.015))\n\n# set background color\nax.set_facecolor('white')\n\n# add margin to y-axis\nax.margins(0.05, 0.03)\nax.set_xticklabels(country_freq['index'], rotation=90)\n\n# add title\nfig.suptitle('Country of Survey Respondents (> 1%)', fontsize=18, fontweight='black')\n\nplt.savefig('country_freq.png', dpi=300, bbox_inches='tight')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Renaming long descriptors\nmc['education'] = mc['education'].replace(\"Some college/university study without earning a bachelor’s degree\", 'Some college')\nmc['education'] = mc['education'].replace('No formal education past high school', 'High School')\n\n# Creating Education Frequency Table\neducation_freq = mc['education'].value_counts(normalize=True)\neducation_freq = education_freq.reset_index()\ngender_freq = education_freq.sort_index(axis=0)\neducation_freq = pd.DataFrame(education_freq)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Creating Education Frequency Graph\n# Setting style for bar graphs\n%matplotlib inline\n\n# set font\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.sans-serif'] = 'Helvetica'\n\n# set the style of the axes and the text color\nplt.rcParams['axes.edgecolor']='#333F4B'\nplt.rcParams['axes.linewidth']=0.8\nplt.rcParams['xtick.color']='#333F4B'\nplt.rcParams['ytick.color']='#333F4B'\nplt.rcParams['text.color']='#333F4B'\n\n# numeric placeholder for the y axis\nmy_range=list(range(1,len(education_freq.index)+1))\n\nfig, ax = plt.subplots(figsize=(8,5))\n\n# create for each bin a vertical line that starts at y = 0 with the length \n# represented by the specific percentage.\nplt.vlines(x=my_range, ymin=0, ymax=education_freq['education'], color='#007ACC', alpha=0.5, linewidth=50)\n\n# create for each bin a dot at the level of the expense percentage value\n# plt.plot(my_range, age_freq['age'], \"o\", markersize=10, color='#007ACC', alpha=0.6)\n\n# set labels\nax.set_xlabel('Education Level', fontsize=15, fontweight='black', color = '#333F4B')\nax.set_ylabel('% of Respondents', fontsize=15, fontweight='black', color = '#333F4B')\n\n# set axis\nax.tick_params(axis='both', which='major', labelsize=12)\nplt.xticks(my_range, education_freq['index'])\n\n# add an horizonal label for the y axis \n# fig.text(-0.15, 0.5, '% of Respondants', fontsize=15, fontweight='black', color = '#333F4B')\n\n# change the style of the axis spines\nax.spines['top'].set_color('none')\nax.spines['right'].set_color('none')\nax.spines['left'].set_smart_bounds(True)\nax.spines['bottom'].set_smart_bounds(True)\n\n# set the spines position\nax.spines['bottom'].set_position(('axes', -0.04))\nax.spines['left'].set_position(('axes', 0.015))\n\n# set background color\nax.set_facecolor('white')\n\n# add margin to y-axis\nax.margins(0.2, 0)\nax.set_xticklabels(education_freq['index'], rotation=90)\n\n# add title\nfig.suptitle('Highest Education Level of Survey Respondents', fontsize=18, fontweight='black')\n\nplt.savefig('education_freq.png', dpi=300, bbox_inches='tight')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating Title Frequency Table\ntitle_freq = mc['title'].value_counts(normalize=True)\ntitle_freq = title_freq.reset_index()\ntitle_freq = title_freq.sort_index(axis=0)\ntitle_freq = pd.DataFrame(title_freq)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Creating Title Frequency Graph\n# Setting style for bar graphs\n%matplotlib inline\n\n# set font\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.sans-serif'] = 'Helvetica'\n\n# set the style of the axes and the text color\nplt.rcParams['axes.edgecolor']='#333F4B'\nplt.rcParams['axes.linewidth']=0.8\nplt.rcParams['xtick.color']='#333F4B'\nplt.rcParams['ytick.color']='#333F4B'\nplt.rcParams['text.color']='#333F4B'\n\n# numeric placeholder for the y axis\nmy_range=list(range(1,len(title_freq.index)+1))\n\nfig, ax = plt.subplots(figsize=(10,6))\n\n# create for each bin a vertical line that starts at y = 0 with the length \n# represented by the specific percentage.\nplt.vlines(x=my_range, ymin=0, ymax=title_freq['title'], color='#007ACC', alpha=0.5, linewidth=15)\n\n# create for each bin a dot at the level of the expense percentage value\nplt.plot(my_range, title_freq['title'], \"o\", markersize=15, color='#007ACC', alpha=0.9)\n\n# set labels\nax.set_xlabel('Job Title', fontsize=15, fontweight='black', color = '#333F4B')\nax.set_ylabel('% of Respondents', fontsize=15, fontweight='black', color = '#333F4B')\n\n# set axis\nax.tick_params(axis='both', which='major', labelsize=12)\nplt.xticks(my_range, title_freq['index'], rotation=45)\n\n# add an horizonal label for the y axis \n# fig.text(-0.15, 0.5, '% of Respondants', fontsize=15, fontweight='black', color = '#333F4B')\n\n# change the style of the axis spines\nax.spines['top'].set_color('none')\nax.spines['right'].set_color('none')\nax.spines['left'].set_smart_bounds(True)\nax.spines['bottom'].set_smart_bounds(True)\n\n# set the spines position\nax.spines['bottom'].set_position(('axes', -0.04))\nax.spines['left'].set_position(('axes', 0.015))\n\n# set background color\nax.set_facecolor('white')\n\n# add margin to y-axis\nax.margins(0.05, 0.03)\nax.set_xticklabels(title_freq['index'], rotation=90)\n\n# add title\nfig.suptitle('Job Title of Survey Respondents', fontsize=18, fontweight='black')\n\nplt.savefig('title_freq.png', dpi=300, bbox_inches='tight')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating Data Science Team Size Frequency Table\nds_teamsize_freq = mc['ds_teamsize'].value_counts(normalize=True)\nds_teamsize_freq = ds_teamsize_freq.reset_index()\nds_teamsize_freq = ds_teamsize_freq.sort_index(axis=0)\nds_teamsize_freq = pd.DataFrame(ds_teamsize_freq)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Creating Data Science Team Size Frequency Graph\n# Setting style for bar graphs\n%matplotlib inline\n\n# set font\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.sans-serif'] = 'Helvetica'\n\n# set the style of the axes and the text color\nplt.rcParams['axes.edgecolor']='#333F4B'\nplt.rcParams['axes.linewidth']=0.8\nplt.rcParams['xtick.color']='#333F4B'\nplt.rcParams['ytick.color']='#333F4B'\nplt.rcParams['text.color']='#333F4B'\n\n# numeric placeholder for the y axis\nmy_range=list(range(1,len(ds_teamsize_freq.index)+1))\n\nfig, ax = plt.subplots(figsize=(10,6))\n\n# create for each bin a vertical line that starts at y = 0 with the length \n# represented by the specific percentage.\nplt.vlines(x=my_range, ymin=0, ymax=ds_teamsize_freq['ds_teamsize'], color='#007ACC', alpha=0.5, linewidth=15)\n\n# create for each bin a dot at the level of the expense percentage value\nplt.plot(my_range, ds_teamsize_freq['ds_teamsize'], \"o\", markersize=15, color='#007ACC', alpha=0.9)\n\n# set labels\nax.set_xlabel('# of People', fontsize=15, fontweight='black', color = '#333F4B')\nax.set_ylabel('% of Respondents', fontsize=15, fontweight='black', color = '#333F4B')\n\n# set axis\nax.tick_params(axis='both', which='major', labelsize=12)\nplt.xticks(my_range, ds_teamsize_freq['index'], rotation=45)\n\n# add an horizonal label for the y axis \n# fig.text(-0.15, 0.5, '% of Respondants', fontsize=15, fontweight='black', color = '#333F4B')\n\n# change the style of the axis spines\nax.spines['top'].set_color('none')\nax.spines['right'].set_color('none')\nax.spines['left'].set_smart_bounds(True)\nax.spines['bottom'].set_smart_bounds(True)\n\n# set the spines position\nax.spines['bottom'].set_position(('axes', -0.04))\nax.spines['left'].set_position(('axes', 0.015))\n\n# set background color\nax.set_facecolor('white')\n\n# add margin to y-axis\nax.margins(0.05, 0.03)\nax.set_xticklabels(ds_teamsize_freq['index'], rotation=90)\n\n# add ds_teamsize\nfig.suptitle('Data Science Team Size of Survey Respondents', fontsize=18, fontweight='black')\n\nplt.savefig('teamsize_freq.png', dpi=300, bbox_inches='tight')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating larger bins for compensation\nmc['compensationhi'] = mc['compensation'].str.extract(r'(?<=-|\\$)(.*$)')\nmc['compensationhi'] = mc['compensationhi'].str.replace(',','')\nmc['compensationhi'] = mc['compensationhi'].str.replace('-','')\nmc['compensationhi'] = mc['compensationhi'].str.replace('<','')\nmc['compensationhi'] = mc['compensationhi'].astype(float)\nmc['compensationbins'] = pd.cut(mc['compensationhi'], [0, 50000, 100000, 200000, 300000, 500000, 1000000], \n                                labels=['$0-50K', '$50-100K', '$100-200K', '$200-300K', '$300-500K', '$500K+'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating Compensation Frequency Table\ncompensationbins_freq = mc['compensationbins'].value_counts(normalize=True)\ncompensationbins_freq = compensationbins_freq.reset_index()\ncompensationbins_freq = compensationbins_freq.sort_index(axis=0)\ncompensationbins_freq = pd.DataFrame(compensationbins_freq)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Creating Compensation Frequency Graph\n# Setting style for bar graphs\n%matplotlib inline\n\n# set font\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.sans-serif'] = 'Helvetica'\n\n# set the style of the axes and the text color\nplt.rcParams['axes.edgecolor']='#333F4B'\nplt.rcParams['axes.linewidth']=0.8\nplt.rcParams['xtick.color']='#333F4B'\nplt.rcParams['ytick.color']='#333F4B'\nplt.rcParams['text.color']='#333F4B'\n\n# numeric placeholder for the y axis\nmy_range=list(range(1,len(compensationbins_freq.index)+1))\n\nfig, ax = plt.subplots(figsize=(8,5))\n\n# create for each bin a vertical line that starts at y = 0 with the length \n# represented by the specific percentage.\nplt.vlines(x=my_range, ymin=0, ymax=compensationbins_freq['compensationbins'], color='#007ACC', alpha=0.5, linewidth=50)\n\n# create for each bin a dot at the level of the expense percentage value\n# plt.plot(my_range, age_freq['age'], \"o\", markersize=10, color='#007ACC', alpha=0.6)\n\n# set labels\nax.set_xlabel('', fontsize=15, fontweight='black', color = '#333F4B')\nax.set_ylabel('% of Respondents', fontsize=15, fontweight='black', color = '#333F4B')\n\n# set axis\nax.tick_params(axis='both', which='major', labelsize=12)\nplt.xticks(my_range, compensationbins_freq['index'])\n\n# add an horizonal label for the y axis \n# fig.text(-0.15, 0.5, '% of Respondants', fontsize=15, fontweight='black', color = '#333F4B')\n\n# change the style of the axis spines\nax.spines['top'].set_color('none')\nax.spines['right'].set_color('none')\nax.spines['left'].set_smart_bounds(True)\nax.spines['bottom'].set_smart_bounds(True)\n\n# set the spines position\nax.spines['bottom'].set_position(('axes', -0.04))\nax.spines['left'].set_position(('axes', 0.015))\n\n# set background color\nax.set_facecolor('white')\n\n# add margin to y-axis\nax.margins(0.2, 0)\n\n# add title\nfig.suptitle('Annual Compensation of Survey Respondents', fontsize=18, fontweight='black')\n\nplt.savefig('compensationbins_freq.png', dpi=300, bbox_inches='tight')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Renaming bins for dollars spent\nrename = {'$0 (USD)':'$0','$100-$999':'$100-$1k',\n          '$1000-$9,999':'$1K-$10K','$1-$99':'$1-$100',\n          '$10,000-$99,999':'$10K-$100K','> $100,000 ($USD)':'$100K+'}\nmc['dollars_mlorcloud'] = mc['dollars_mlorcloud'].replace(rename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating dollars spent Frequency Table\ndollars_mlorcloud = mc['dollars_mlorcloud'].value_counts(normalize=True)\ndollars_mlorcloud = dollars_mlorcloud.reset_index()\ndollars_mlorcloud = dollars_mlorcloud.sort_index(axis=0)\ndollars_mlorcloud = pd.DataFrame(dollars_mlorcloud)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Creating Dollars Spent Frequency Graph\n# Setting style for bar graphs\n%matplotlib inline\n\n# set font\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.sans-serif'] = 'Helvetica'\n\n# set the style of the axes and the text color\nplt.rcParams['axes.edgecolor']='#333F4B'\nplt.rcParams['axes.linewidth']=0.8\nplt.rcParams['xtick.color']='#333F4B'\nplt.rcParams['ytick.color']='#333F4B'\nplt.rcParams['text.color']='#333F4B'\n\n# numeric placeholder for the y axis\nmy_range=list(range(1,len(dollars_mlorcloud.index)+1))\n\nfig, ax = plt.subplots(figsize=(11,5))\n\n# create for each bin a vertical line that starts at y = 0 with the length \n# represented by the specific percentage.\nplt.vlines(x=my_range, ymin=0, ymax=dollars_mlorcloud['dollars_mlorcloud'], color='#007ACC', alpha=0.5, linewidth=50)\n\n# create for each bin a dot at the level of the expense percentage value\n# plt.plot(my_range, age_freq['age'], \"o\", markersize=10, color='#007ACC', alpha=0.6)\n\n# set labels\nax.set_xlabel('', fontsize=15, fontweight='black', color = '#333F4B')\nax.set_ylabel('% of Respondents', fontsize=15, fontweight='black', color = '#333F4B')\n\n# set axis\nax.tick_params(axis='both', which='major', labelsize=12)\nplt.xticks(my_range, dollars_mlorcloud['index'])\n\n# add an horizonal label for the y axis \n# fig.text(-0.15, 0.5, '% of Respondants', fontsize=15, fontweight='black', color = '#333F4B')\n\n# change the style of the axis spines\nax.spines['top'].set_color('none')\nax.spines['right'].set_color('none')\nax.spines['left'].set_smart_bounds(True)\nax.spines['bottom'].set_smart_bounds(True)\n\n# set the spines position\nax.spines['bottom'].set_position(('axes', -0.04))\nax.spines['left'].set_position(('axes', 0.015))\n\n# set background color\nax.set_facecolor('white')\n\n# add margin to y-axis\nax.margins(0.2, 0)\n\n# add title\nfig.suptitle('$ Spent on Machine Learning or Cloud Computing (Per Year)', fontsize=18, fontweight='black')\n\nplt.savefig('dollars_mlorcloud.png', dpi=300, bbox_inches='tight')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Renaming bins for machine learning years\nmc['ml_years'] = mc['ml_years'].str.replace(' years', '')\n\n# Creating machine learning years spent Frequency Table\nml_years = mc['ml_years'].value_counts(normalize=True)\nml_years = ml_years.reset_index()\nml_years = ml_years.sort_index(axis=0)\nml_years = pd.DataFrame(ml_years)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Creating machine learning years Frequency Graph\n# Setting style for bar graphs\n%matplotlib inline\n\n# set font\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.sans-serif'] = 'Helvetica'\n\n# set the style of the axes and the text color\nplt.rcParams['axes.edgecolor']='#333F4B'\nplt.rcParams['axes.linewidth']=0.8\nplt.rcParams['xtick.color']='#333F4B'\nplt.rcParams['ytick.color']='#333F4B'\nplt.rcParams['text.color']='#333F4B'\n\n# numeric placeholder for the y axis\nmy_range=list(range(1,len(ml_years.index)+1))\n\nfig, ax = plt.subplots(figsize=(11,5))\n\n# create for each bin a vertical line that starts at y = 0 with the length \n# represented by the specific percentage.\nplt.vlines(x=my_range, ymin=0, ymax=ml_years['ml_years'], color='#007ACC', alpha=0.5, linewidth=50)\n\n# create for each bin a dot at the level of the expense percentage value\n# plt.plot(my_range, age_freq['age'], \"o\", markersize=10, color='#007ACC', alpha=0.6)\n\n# set labels\nax.set_xlabel('', fontsize=15, fontweight='black', color = '#333F4B')\nax.set_ylabel('% of Respondents', fontsize=15, fontweight='black', color = '#333F4B')\n\n# set axis\nax.tick_params(axis='both', which='major', labelsize=12)\nplt.xticks(my_range, ml_years['index'])\n\n# add an horizonal label for the y axis \n# fig.text(-0.15, 0.5, '% of Respondants', fontsize=15, fontweight='black', color = '#333F4B')\n\n# change the style of the axis spines\nax.spines['top'].set_color('none')\nax.spines['right'].set_color('none')\nax.spines['left'].set_smart_bounds(True)\nax.spines['bottom'].set_smart_bounds(True)\n\n# set the spines position\nax.spines['bottom'].set_position(('axes', -0.04))\nax.spines['left'].set_position(('axes', 0.015))\n\n# set background color\nax.set_facecolor('white')\n\n# add margin to y-axis\nax.margins(0.2, 0)\n\n# add title\nfig.suptitle('# of Years Experience with Machine Learning', fontsize=18, fontweight='black')\n\nplt.savefig('ml_years.png', dpi=300, bbox_inches='tight')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA Visualizations and Analysis\n<img src=\"age_freq.png\" width=\"80%\">\nSurvey responses seem to be distributed somewhat normally, with a high percentage in the range of 22-34 years old."},{"metadata":{},"cell_type":"markdown","source":"<img src=\"title_freq.png\" width=\"60%\">\nA large percentage of the survey sample are either Data Scientists or Students. This likely explains the younger age distribution of respondents. As students will not be likely to attract a high degree of value in any consulting-based marketplace, this will be an interesting field to use as a filter in our analysis."},{"metadata":{},"cell_type":"markdown","source":"<img src=\"country_freq.png\" width=\"80%\">\nRespondents were most likely to live in India or the United States, with no other country accounting for more than 5% of the overall population."},{"metadata":{},"cell_type":"markdown","source":"<img src=\"gender_freq.png\" width=\"60%\">\nThe survey sample is very male-dominant, with less than 20% of female respondents."},{"metadata":{},"cell_type":"markdown","source":"<img src=\"education_freq.png\" width=\"60%\">\nThe survey sample is highly educated, with the vast majority having obtained at least a Bachelor's degree."},{"metadata":{},"cell_type":"markdown","source":"<img src=\"teamsize_freq.png\" width=\"60%\">\n\n15% of survey respondents responded that they worked on a Data Science of less than 3 people. All other respondents are a part of a larger Data Science team. The most popular response was the largest option given, teams of 20 or more members. This is very relevant for our question about a freemium enterprise-based kernel service."},{"metadata":{},"cell_type":"markdown","source":"<img src=\"compensationbins_freq.png\" width=\"60%\">\n\nThe annual compensation of Kaggle users is heavily dominated by employees making less than 50k per year. This is a relevant fact in our \"freemium\" service proposal, as many will be unlikely to personally have considerable margin for a paid service."},{"metadata":{},"cell_type":"markdown","source":"<img src=\"dollars_mlorcloud.png\" width=\"60%\">\nOver 60% of survey respondents work for companies who spent nothing on Machine Learning or Cloud Computing in the previous year. As such, they are unlikely to have significant expertise working with these technologies."},{"metadata":{},"cell_type":"markdown","source":"<img src=\"ml_years.png\" width=\"60%\">\n\nSimilar to the above diagram, over 60% of the respondents have more than 2 years of experience using Machine learning. Accordingly, they will have limited expertise in this field."},{"metadata":{},"cell_type":"markdown","source":"## EDA Results\n\nAfter reviewing the categorical variables, several important insights stand out:\n\n* Over 20% of the survey respondents are students, and as such are not likely to help drive revenue in either a freemium kernel product or a consulting marketplace. Their information should be removed to further evaluate Kaggle's target market for these products.\n* Nearly 25% of respondents currently reside in India, and a significant majority live outside the United States, which could make users more likely to engage in a remote consulting marketplace product.\n* Over 65% of respondents currently work on a Data Science team of 3 or more people, and over 20% work on a team of 1-2 people. As a result, the vast majority of Kaggle customers are already working collaboratively on data-science related products.\n* Over 60% of respondents make less than 50K per year. As a result, they are not likely to have a large amount of discretionary income for paid Data Science collaboration services.\n* Over 60% of respondents work for companies who have spent nothing on Machine Learning or Cloud Computing, and have personally spent less than 2 years working with Machine Learning products."},{"metadata":{},"cell_type":"markdown","source":"# Further Analysis\n\nTo continue our analysis, we will focus our dataset on only those respondents who are currently working in the data science/analysis field. These respondents are most likely to use any Kaggle products and contribute to increased revenue. To do this, we will remove `'student'` values from the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get names of indexes for which title is student.\nindexNames = mc[mc['title'] == 'Student' ].index\n \n# Delete these row indexes from dataFrame\nmcclean = mc.drop(indexNames)\nprint(len(mc)-len(mcclean))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have now removed over 4000 responses that are irrelevant for our analysis. With this new dataset, we can focus on exploring our hypothesis, that a kernel freemium service will provide more potential revenue than a consulting marketplace.\n\n## Potential for Freemium Service\n\nFirst, we will explore the adjusted compensation percentages, having removed students (more likely to be unemployed or underemployed) from the sample."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating Compensation Frequency Table\ncompensationbins_clean = mcclean['compensationbins'].value_counts(normalize=True)\ncompensationbins_clean = compensationbins_clean.reset_index()\ncompensationbins_clean = compensationbins_clean.sort_index(axis=0)\ncompensationbins_clean = pd.DataFrame(compensationbins_clean)\nprint(compensationbins_clean)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating Compensation Frequency Graph\n# Setting style for bar graphs\n%matplotlib inline\n\n# set font\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.sans-serif'] = 'Helvetica'\n\n# set the style of the axes and the text color\nplt.rcParams['axes.edgecolor']='#333F4B'\nplt.rcParams['axes.linewidth']=0.8\nplt.rcParams['xtick.color']='#333F4B'\nplt.rcParams['ytick.color']='#333F4B'\nplt.rcParams['text.color']='#333F4B'\n\n# numeric placeholder for the y axis\nmy_range=list(range(1,len(compensationbins_freq.index)+1))\n\nfig, ax = plt.subplots(figsize=(8,5))\n\n# create for each bin a vertical line that starts at y = 0 with the length \n# represented by the specific percentage.\nplt.vlines(x=my_range, ymin=0, ymax=compensationbins_clean['compensationbins'], color='#007ACC', alpha=0.5, linewidth=50)\n\n# create for each bin a dot at the level of the expense percentage value\n# plt.plot(my_range, age_freq['age'], \"o\", markersize=10, color='#007ACC', alpha=0.6)\n\n# set labels\nax.set_xlabel('', fontsize=15, fontweight='black', color = '#333F4B')\nax.set_ylabel('% of Respondents', fontsize=15, fontweight='black', color = '#333F4B')\n\n# set axis\nax.tick_params(axis='both', which='major', labelsize=12)\nplt.xticks(my_range, compensationbins_clean['index'])\n\n# add an horizonal label for the y axis \n# fig.text(-0.15, 0.5, '% of Respondants', fontsize=15, fontweight='black', color = '#333F4B')\n\n# change the style of the axis spines\nax.spines['top'].set_color('none')\nax.spines['right'].set_color('none')\nax.spines['left'].set_smart_bounds(True)\nax.spines['bottom'].set_smart_bounds(True)\n\n# set the spines position\nax.spines['bottom'].set_position(('axes', -0.04))\nax.spines['left'].set_position(('axes', 0.015))\n\n# set background color\nax.set_facecolor('white')\n\n# add margin to y-axis\nax.margins(0.2, 0)\n\n# add title\nfig.suptitle('Annual Compensation of Survey Respondents', fontsize=18, fontweight='black')\n\nplt.savefig('compensationbins_clean.png', dpi=300, bbox_inches='tight')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Working with this smaller sample, the compensation numbers are still skewed largely to the lower-end. Over 60% of non-student Kaggle users make less than 50k per year. This means they are probably less likely to have discretionary income for a paid-subscription service.\n\nNext, we will use this reduced sample size to see how many respondents are a part of a large data science team, which would require collaboration on data science projects."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating Data Science Team Size Frequency Table\nds_teamsize_clean = mcclean['ds_teamsize'].value_counts(normalize=True)\nds_teamsize_clean = ds_teamsize_clean.reset_index()\nds_teamsize_clean = ds_teamsize_clean.sort_index(axis=0)\nds_teamsize_clean = pd.DataFrame(ds_teamsize_clean)\nprint(ds_teamsize_clean.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating Data Science Team Size Frequency Graph\n# Setting style for bar graphs\n%matplotlib inline\n\n# set font\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.sans-serif'] = 'Helvetica'\n\n# set the style of the axes and the text color\nplt.rcParams['axes.edgecolor']='#333F4B'\nplt.rcParams['axes.linewidth']=0.8\nplt.rcParams['xtick.color']='#333F4B'\nplt.rcParams['ytick.color']='#333F4B'\nplt.rcParams['text.color']='#333F4B'\n\n# numeric placeholder for the y axis\nmy_range=list(range(1,len(ds_teamsize_freq.index)+1))\n\nfig, ax = plt.subplots(figsize=(10,6))\n\n# create for each bin a vertical line that starts at y = 0 with the length \n# represented by the specific percentage.\nplt.vlines(x=my_range, ymin=0, ymax=ds_teamsize_clean['ds_teamsize'], color='#007ACC', alpha=0.5, linewidth=15)\n\n# create for each bin a dot at the level of the expense percentage value\nplt.plot(my_range, ds_teamsize_clean['ds_teamsize'], \"o\", markersize=15, color='#007ACC', alpha=0.9)\n\n# set labels\nax.set_xlabel('# of People', fontsize=15, fontweight='black', color = '#333F4B')\nax.set_ylabel('% of Respondents', fontsize=15, fontweight='black', color = '#333F4B')\n\n# set axis\nax.tick_params(axis='both', which='major', labelsize=12)\nplt.xticks(my_range, ds_teamsize_clean['index'], rotation=45)\n\n# add an horizonal label for the y axis \n# fig.text(-0.15, 0.5, '% of Respondants', fontsize=15, fontweight='black', color = '#333F4B')\n\n# change the style of the axis spines\nax.spines['top'].set_color('none')\nax.spines['right'].set_color('none')\nax.spines['left'].set_smart_bounds(True)\nax.spines['bottom'].set_smart_bounds(True)\n\n# set the spines position\nax.spines['bottom'].set_position(('axes', -0.04))\nax.spines['left'].set_position(('axes', 0.015))\n\n# set background color\nax.set_facecolor('white')\n\n# add margin to y-axis\nax.margins(0.05, 0.03)\nax.set_xticklabels(ds_teamsize_freq['index'], rotation=90)\n\n# add ds_teamsize\nfig.suptitle('Data Science Team Size of Survey Respondents', fontsize=18, fontweight='black')\n\nplt.savefig('teamsize_freq_clean.png', dpi=300, bbox_inches='tight')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After removing students from the survey data, over 53% of respondents are on a data science team of 3 or more, with over 23% on a team of 20+ people. In addition, 22% are on a team of 1-2, which could mean additional opportunity for collaboration in this space.\n\nGiven this number, it seems as though the overall number of people who might be interested in a collaborative freemium service is notable.\n\nHowever, from the exploratory analysis above, it seems as though most respondents come from companies that spend little to no money on products like Machine Learning and Cloud Computing. To explore further, we will analyze the size of companies represented by survey respondents."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(mcclean['comp_size'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Renaming bins for company size\nrename = {'1000-9,999 employees':'1k - 10k','> 10,000 employees':'10k+',\n          '0-49 employees':'0 - 50','50-249 employees':'50 - 250',\n          '250-999':'250 - 1k'}\nmcclean['comp_size'] = mc['comp_size'].replace(rename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating company size Frequency Table\ncomp_size = mcclean['comp_size'].value_counts(normalize=True)\ncomp_size = comp_size.reset_index()\ncomp_size = comp_size.sort_index(axis=0)\ncomp_size = pd.DataFrame(comp_size)\nprint(comp_size.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating Company Size  Frequency Graph\n# Setting style for bar graphs\n%matplotlib inline\n\n# set font\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.sans-serif'] = 'Helvetica'\n\n# set the style of the axes and the text color\nplt.rcParams['axes.edgecolor']='#333F4B'\nplt.rcParams['axes.linewidth']=0.8\nplt.rcParams['xtick.color']='#333F4B'\nplt.rcParams['ytick.color']='#333F4B'\nplt.rcParams['text.color']='#333F4B'\n\n# numeric placeholder for the y axis\nmy_range=list(range(1,len(comp_size.index)+1))\n\nfig, ax = plt.subplots(figsize=(11,5))\n\n# create for each bin a vertical line that starts at y = 0 with the length \n# represented by the specific percentage.\nplt.vlines(x=my_range, ymin=0, ymax=comp_size['comp_size'], color='#007ACC', alpha=0.5, linewidth=50)\n\n# create for each bin a dot at the level of the expense percentage value\n# plt.plot(my_range, age_freq['age'], \"o\", markersize=10, color='#007ACC', alpha=0.6)\n\n# set labels\nax.set_xlabel('', fontsize=15, fontweight='black', color = '#333F4B')\nax.set_ylabel('% of Respondents', fontsize=15, fontweight='black', color = '#333F4B')\n\n# set axis\nax.tick_params(axis='both', which='major', labelsize=12)\nplt.xticks(my_range, comp_size['index'])\n\n# add an horizonal label for the y axis \n# fig.text(-0.15, 0.5, '% of Respondants', fontsize=15, fontweight='black', color = '#333F4B')\n\n# change the style of the axis spines\nax.spines['top'].set_color('none')\nax.spines['right'].set_color('none')\nax.spines['left'].set_smart_bounds(True)\nax.spines['bottom'].set_smart_bounds(True)\n\n# set the spines position\nax.spines['bottom'].set_position(('axes', -0.04))\nax.spines['left'].set_position(('axes', 0.015))\n\n# set background color\nax.set_facecolor('white')\n\n# add margin to y-axis\nax.margins(0.2, 0)\n\n# add title\nfig.suptitle('Size of Company Where Employed', fontsize=18, fontweight='black')\n\nplt.savefig('comp_size_clean.png', dpi=300, bbox_inches='tight')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According to this information, over 58% of survey respondents work in companies with less than 1,000 employees. These companies will likely be unable to pay for an Enterprise-level freemium subscription for their employees. As noted above, most individuals in the sample are also unlikely to purchase a subscription due to relatively low annual compensation.\n\nThis means that Kaggle would be reliant upon \"mid-tier\" priced subscriptions, for users whose companies are large enough to support a data science team but not large enough to justify an enterprise solution.\n\n## Result of Analysis\n\nGiven the relatively low compensation rates of Kaggle users, it is unlikely that individual customers will sign up for a paid model in large numbers. And since the majority of Kaggle users come from companies of less than 1,000 employees, it is unlikely that large-scale enterprise subscriptions will be a significant revenue driver.\n\nEven when considering the potential value increase that a freemium kernel product could provide [through increasing overall exposure and access](https://hbr.org/2018/06/why-microsoft-is-willing-to-pay-so-much-for-github), adding a freemium product is not likely to increase the overall Kaggle user base. GitHub seems to be the dominant player in this market segment, and the cost of creating and marketing a unique freemium service would likely be cost-prohibitive.\n\nAccording to this analysis of the current Kaggle customer base, it is unlikely that a kernel subscription service will be able to generate substantial new revenue for the company.\n\n## Potential for Consulting Marketplace\n\nWhen considering the potential value of providing a consulting marketplace, there are several factors to consider:\n\n* The brand awareness to attract companies with a need for outside talent.\n* The availability of talented users to provide meaningful solutions.\n\n### Attracting Contract Employers\n\nThe provided dataset includes some interesting information related to these two factors.\n\nWhereas small company size is a negative factor in driving enterprise subscriptions, smaller companies are more likely to need outside help for data science needs. 58% of Kaggle users work in companies under 1,000, and 52% of users work on a data science team of less than five people. For companies such as these, a reputable contract-based marketplace could be incredibly helpful.\n\nIn addition, Kaggle's current revenue sources come largely from company-driven competitions, a segment of which are focused specifically on finding creative crowd-sourced solutions for company problems. The potential for attracting companies with a need for outside, consultant-based talent is readily available.\n\n### Attracting Talented Contractors\n\nIn addition, the survey data shows that Kaggle is already connected with a valuable pool of potential contract-based employees. As noted above, over 60% of respondents make less than 50k per year, which could be a helpful indicator of users looking to profit from contract-based data science work. The popularity of Kaggle competitions, prize winners receiving cash prizes, is an obvious indicator that Kaggle is readily connected with potential data science contractors.\n\nAlso, there is a highly-qualified subset of Kaggle Users which could demand high-dollar contracts, thus increasing revenue potential for the company."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating Education Frequency Table\neducation_freq_clean = mcclean['education'].value_counts(normalize=True)\neducation_freq_clean = education_freq_clean.reset_index()\ngender_freq_clean = education_freq_clean.sort_index(axis=0)\neducation_freq_clean = pd.DataFrame(education_freq_clean)\neducation_freq_clean.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating Education Frequency Graph\n# Setting style for bar graphs\n%matplotlib inline\n\n# set font\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.sans-serif'] = 'Helvetica'\n\n# set the style of the axes and the text color\nplt.rcParams['axes.edgecolor']='#333F4B'\nplt.rcParams['axes.linewidth']=0.8\nplt.rcParams['xtick.color']='#333F4B'\nplt.rcParams['ytick.color']='#333F4B'\nplt.rcParams['text.color']='#333F4B'\n\n# numeric placeholder for the y axis\nmy_range=list(range(1,len(education_freq_clean.index)+1))\n\nfig, ax = plt.subplots(figsize=(8,5))\n\n# create for each bin a vertical line that starts at y = 0 with the length \n# represented by the specific percentage.\nplt.vlines(x=my_range, ymin=0, ymax=education_freq_clean['education'], color='#007ACC', alpha=0.5, linewidth=50)\n\n# create for each bin a dot at the level of the expense percentage value\n# plt.plot(my_range, age_freq['age'], \"o\", markersize=10, color='#007ACC', alpha=0.6)\n\n# set labels\nax.set_xlabel('Education Level', fontsize=15, fontweight='black', color = '#333F4B')\nax.set_ylabel('% of Respondents', fontsize=15, fontweight='black', color = '#333F4B')\n\n# set axis\nax.tick_params(axis='both', which='major', labelsize=12)\nplt.xticks(my_range, education_freq_clean['index'])\n\n# add an horizonal label for the y axis \n# fig.text(-0.15, 0.5, '% of Respondants', fontsize=15, fontweight='black', color = '#333F4B')\n\n# change the style of the axis spines\nax.spines['top'].set_color('none')\nax.spines['right'].set_color('none')\nax.spines['left'].set_smart_bounds(True)\nax.spines['bottom'].set_smart_bounds(True)\n\n# set the spines position\nax.spines['bottom'].set_position(('axes', -0.04))\nax.spines['left'].set_position(('axes', 0.015))\n\n# set background color\nax.set_facecolor('white')\n\n# add margin to y-axis\nax.margins(0.2, 0)\nax.set_xticklabels(education_freq['index'], rotation=90)\n\n# add title\nfig.suptitle('Highest Education Level of Survey Respondents', fontsize=18, fontweight='black')\n\nplt.savefig('education_freq_clean.png', dpi=300, bbox_inches='tight')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"When \"student\" respondents are removed, over 62% of Kaggle users hold at least a Master's degree, with 16% holding a doctoral degree.\n\nAdd to this the factor that nearly 25% of Kaggle respondents are from India, and over 80% live outside the United States, and there is a vast majority of users that could potentially be interested in a remote, consulting-based opportunity.\n\n# Final Conclusions #\n\nAfter exploring the results of a Kaggle user survey, our initial hypothesis is disproven. Because of the proliferation of free collaborative environments like GitHub, and the unlikely customer base for personal or enterprise subscriptions, a freemium service seems likely to increase revenue only marginally. In contrast, because of Kaggle's readily available connections with motivated employers in need of outside help, and a large user base of high-skilled potential contractors, a contractor marketplace could drive much more revenue for the cost of implementation.\n\nAs a result of this analysis, we can determine that **Kaggle is more likely to drive significant future revenue from a monetized consultant marketplace, rather than a freemium kernel product.**"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}