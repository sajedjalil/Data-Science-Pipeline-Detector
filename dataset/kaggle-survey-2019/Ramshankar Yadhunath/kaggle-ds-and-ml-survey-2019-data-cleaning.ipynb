{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Cleaning Up the Kaggle DS and ML Survey 2019\n##### A step-by-step approach to dealing with messy data and structuring it to your needs"},{"metadata":{},"cell_type":"markdown","source":"## What is Data Cleaning?\n- According to **Wikipedia**, *\"Data cleansing or data cleaning is the process of detecting and correcting (or removing) corrupt or inaccurate records from a record set, table, or database and refers to identifying incomplete, incorrect, inaccurate or irrelevant parts of the data and then replacing, modifying, or deleting the dirty or coarse data.\"*\n- Basically put, **\"Data Cleaning can be thought of as a fundamental step in data science that helps convert available data into a form more suitable for the analysis task at hand.\"**\n\nTaking that *easier-to-comprehend* definition to heart, I have tried cleaning up the [2019 Kaggle ML and DS Survey](https://www.kaggle.com/c/kaggle-survey-2019) data for a pet-project I am trying to work on. "},{"metadata":{},"cell_type":"markdown","source":"## The Aim of this Notebook\n\n- Outline a \"Step-by-Step\" procedure to **Data Cleaning** on the [2019 Kaggle ML and DS Survey](https://www.kaggle.com/c/kaggle-survey-2019) data\n- Generate a **clean version** of \"multiple_choice_responses.csv\" (Can be found in the **Output** section)\n- This clean version has only 35 columns (34 question-responses and 1 for the timestamp; contrary to the 246 columns in the original *multiple_choice_responses.csv* (There is **no loss** of important data during this conversion)\n- Provide **re-usable code samples** so that anybody could use similar functions for their own projects (or maybe just improve my functions and help me learn in the process)"},{"metadata":{},"cell_type":"markdown","source":"## Key Considerations while dealing with \"Messy Data\"\n\n### The \"Aim\" of your Analysis\n- The kind of data cleaning performed and the extent of data cleaning performed is dependent on the kind of analysis you want to perform\n- Data Cleaning is always going to be **\"specific\"** to the questions you want to answer\n\n### Understanding \"Important\" Data\n- While data cleaning involves removing messy values and modifying them, it is important to identify which of these values are \"un-important\" and can be removed\n- Just because a particular feature has about 30% missing values, it is not possible to make a mechanical call as to whether the feature must be kept or removed; we will need to identify the importance of that feature to the data we have\n- Many a time, we can convert **messy-looking** values to better formats by writing a bit of code. Eg : \"500 Dollars\" might seem like a bad value if we want to perform a calculation with it. So, it's better to convert it to \"500\" for correct computation. (Make sure it's integer)\n\n### Identifying the \"Causes\" of Messy Data\n- Identifying the cause will help shape a better solution to data cleaning\n- At times, human error or bias can be a cause of bad data and other times, faulty apparatus can engender poor data entry\n- If we know the cause, we can definitely figure out the cure!"},{"metadata":{},"cell_type":"markdown","source":"**NOTE:**\n- I shall be using the terms \"column\" and \"feature\" interchangeably in the course of this notebook"},{"metadata":{},"cell_type":"markdown","source":"Withour further ado, I shall step right into the data cleaning process!"},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning Begins here!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading necessary libraries\n\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Load the relevant datasets\n\nmcr = pd.read_csv(\"../input/kaggle-survey-2019/multiple_choice_responses.csv\") # responses\nques = pd.read_csv(\"../input/kaggle-survey-2019/questions_only.csv\") # questions\ntxtr = pd.read_csv(\"../input/kaggle-survey-2019/other_text_responses.csv\") # text responses\nss = pd.read_csv(\"../input/kaggle-survey-2019/survey_schema.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inspect mcr using head()\n\nmcr.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The \"*print_all*\" function\n\n- **Motivation :** Since each question in the survey is very long, printing them would cause the truncation of these long values and the truncated portion would be replaced with **...**. This is will not help us observe all the values clearly.\n- **Aim :** To print out the contents of all cells in a given row without truncation\n- **Modules needed :** pandas\n- **Application :** Here, we use it to print all the questions (in row 0 of mcr) in their full length"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to print the contents of all cells in a given row of a dataframe in their entire length\n\ndef print_all(df, r_num):\n    \"\"\"\n    Task:\n    To print all the content of the cells in a given row without truncation\n    \n    Input :\n    df <- Dataframe\n    r_num <- Row number (starts at 0)\n    \n    Output :\n    Prints out all values for the input row across all attributes with corresponding headers\n    \"\"\"\n    row = df.iloc[r_num]\n    pd.set_option('display.max_rows', len(row))\n    pd.set_option('display.max_colwidth', -1)\n    print(row)\n    pd.reset_option('display.max_rows')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Inspecting Multiple Choice Responses (We need Questions, so that's why we are passing 0 as the row number)\nprint_all(mcr,0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There were only 34 questions in the survey in total. But, the responses dataframe (mcr) has a whopping 246 columns. Why did this happen?\n<br>\n> It's because several questions have their answers split over multiple columns. Example : \"Select all that apply\" and \"Other Text\" questions. We can notice two important patterns from mcr.head():\n* **Select all that apply** questions are in columns encoded as Qi_Part_k (i = question number, k = choice number)\n* **Other Text** responses are under the columns titled Qi_OTHER_TEXT (i = question number)"},{"metadata":{},"cell_type":"markdown","source":"**NOTE :** Text Responses have been encoded to maintain anonymity of respondents (as on the survey data description). So, removing the OTHER_TEXT columns from mcr makes better sense."},{"metadata":{},"cell_type":"markdown","source":"### The \"*col_rem_by_exp*\" function\n\n- **Motivation :** Certain columns in a dataset are of a similar type and this type might not be be useful for analysis. And often, columns of the similar type share a common \"string expression\" in their titles. So, we can remove them all together based on this expression.\n- **Aim :** To remove all the columns in a dataframe based on a shared expression\n- **Modules needed :** pandas\n- **Application :** Here, we use it to remove all the \"OTHER_TEXT\" columns from mcr"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to remove columns from a dataset based on an expression in the column name\n\ndef col_rem_by_exp(df, exp):\n    \"\"\"\n    Task:\n    To remove columns from a dataset based on an expression in the column name\n    \n    Input :\n    df <- Dataframe\n    exp <- The string expression that is common to all columns that need to be removed\n    \n    Output :\n    Returns a dataframe with the removed columns\n    \"\"\"\n    removable_cols = []\n    for i in df.columns:\n        if (exp in i):\n            removable_cols.append(i)\n    return (df.drop(removable_cols, axis=1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Removing \"OTHER_TEXT\" columns\n\nmcr = col_rem_by_exp(mcr, \"_OTHER_TEXT\")\nprint_all(mcr,0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All columns with \"OTHER_TEXT\" responses have been removed now, as seen from the output generated."},{"metadata":{},"cell_type":"markdown","source":"### Which are the \"Select all that apply\" questions ?\n\nHere, we shall segregate all the questions that have a \"Select all that apply\" option and store them for later"},{"metadata":{},"cell_type":"markdown","source":"### The \"*select_features*\" function\n\n- **Motivation :** Certain columns in a dataset might share a common \"string expression\" in their titles. So, we can group them all together based on this expression.\n- **Aim :** To make a list of all the columns in a dataframe based on a shared expression\n- **Modules needed :** pandas\n- **Application :** Here, we use it to make a list of all columns with \"_Part_\" in their column titles (Because that's the pattern of questions with a \"Select all that apply\" option"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to segregate all the questions that have the \"Select all that apply\" option\ndef select_features(df, exp):\n    \"\"\"\n    Task:\n    To group columns from a dataset based on an expression in the column name\n    \n    Input :\n    df <- Dataframe\n    exp <- The string expression that is common to all columns that need to be aggregated\n    \n    Output :\n    Returns the list of all features with the common expression\n    \"\"\"\n    feature_list = []\n    for i in mcr.columns:\n        if (\"_Part_\" in i):\n            q = i\n            pos_ = q.index('_')\n            q_no = int(q[:pos_][1:])\n            if(q_no not in feature_list):\n                feature_list.append(q_no)\n    return feature_list\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"select_all_ques = select_features(mcr, \"_Part_\")\nprint('\"Select all that apply\" questions :')\nprint(select_all_ques)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The \"*response_combine*\" function\n\n- **Motivation :** The \"Select all that apply\" type questions allows for each respondent to choose more than one option for a given question. In the survey data, each of these options are encoded as separate features. (*That explains the huge 240+ features in the dataframe*)\n- **Aim :** To combine responses of \"Select all that apply\" questions\n- **Modules needed :** pandas\n- **Application :** Here, we use it to combine all the options chosen by a respondent for a given question into a single feature\n\n> **CAVEAT :** This function when applied to the dataframe takes a long time to run (over 10 minutes). That's a drawback of this function and I will try to see if I can improve it in the future."},{"metadata":{"trusted":true},"cell_type":"code","source":"def response_combine(df, q_num):\n    \"\"\"\n    Task:\n    To combine responses of \"Select all that apply\" questions\n    \n    Input :\n    df <- Multiple choice response survey\n    q_num <- Question number whose responses need to be combined\n    \n    Output :\n    > List of lists...each list corresponds to a row and all the options selected by that respondent are grouped together in it\n    > Leave out the first list (it just groups the headers) once you get the output\n    \"\"\"\n    # Identify the PARTS of the given question number\n    resp_cols = []\n    for i in df.columns:\n        if (('Q'+str(q_num)) in i):\n            resp_cols.append(i)\n            \n    # Aggregate all the responses of a given respondent\n    responses = []\n    for i in range(df.shape[0]):\n        l = list(df[resp_cols].iloc[i])\n        cleaned_responses = [choice for choice in l if str(choice) != 'nan']\n        responses.append(cleaned_responses)\n    \n    # Create a dataframe of these aggregated responses, merge them with the original dataframe and delete the PARTS\n    header = (\"Q\"+str(q_num))\n    temp_df = pd.DataFrame(dict({header:responses}))\n    df = df.drop(resp_cols, axis=1)\n    final_df = pd.concat([df, temp_df], axis=1, sort=False)\n    \n    return (final_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cleaning the complete dataframe\nclean_mcr = response_combine(mcr,select_all_ques[0])\nfor q in select_all_ques[1:]:\n    clean_mcr = response_combine(clean_mcr,q)\n    \nprint(\"The shape of the cleaned dataframe is :\",clean_mcr.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The new dataset only has 35 columns (1 for the time taken and 34 for questions). This is much cleaner and compact."},{"metadata":{},"cell_type":"markdown","source":"### It's not over! Yet...\nOkay, so with the **clean_mcr** generated, it looks as though we have cleaned our data well. But, there is an issue that we have introduced in the course of our analysis.\n\n- The response_combine() function removes the questions with \"Select all that apply\" from their original positions in the dataframe, combines all the responses for a given question and appends these new clean features at the end of the new dataframe.\n- This means that we need to make sure that the \"Questions\" that we provide to each of these new features are also ordered correctly. Else, there will be a mixup of column headers and values. And, **THAT IS GOING TO BE BAD!**\n\nTo avoid such a problem, I have written a few lines of code in the cell beneath that takes care of this issue."},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"\"\"\"Fixing the Column Headers\"\"\"\n\n# list of all questions whose positions have changed after response_combine()\npos_changed_ques = [(\"Q\"+str(x)) for x in select_all_ques]\n\n# dropping the position-changed-questions from the main dataframe\nquestions = list(ques.loc[0,pos_changed_ques])\nnew_ques = ques.drop(pos_changed_ques, axis=1)\n\n# using the concept of dataframes concatenation to create \"new_ques\" from \"ques\"\n## new_ques is a modified version of ques that orders questions like how they have been modified in clean_mcr\ntemp_dict = {}\nfor i in range(len(pos_changed_ques)):\n    temp_dict[pos_changed_ques[i]] = questions[i]\ntemp_ques = pd.DataFrame(temp_dict, index=[0])\nnew_ques = pd.concat([new_ques,temp_ques], axis=1)\n\n# new_ques\nnew_ques","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\" Final Clean Up \"\"\"\n\n# Rename columns\nclean_mcr.columns = list(new_ques.iloc[0,:])\n\n# Drop the first row\nclean_mcr = clean_mcr.drop([0])\n\n# Drop the first column (it's not needed)\n# clean_mcr = clean_mcr.drop(clean_mcr.columns[[0]], axis=1)\n\n# Save clean_mcr as an output dataset\nclean_mcr.to_csv(\"clean_multiple_choice_responses.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### RESULT\n**clean_mcr** is our final, cleaned survey dataframe.<br>\nYou can download it from the \"Output\" feature."},{"metadata":{},"cell_type":"markdown","source":"### FUTURE WORK\n- Use this cleaned dataset for my project\n- Try and automate the data cleaning process above and apply it to the previous year's Kaggle DS and ML surveys\n\n### CONCLUSION\n\nAnd that's it! My data cleaning for the task I needed is done (as of now). Hopefully, I was able to perform my task correctly, but if there is anything that I have not done well enough, I would love to know about it so that I can improve this notebook :)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}