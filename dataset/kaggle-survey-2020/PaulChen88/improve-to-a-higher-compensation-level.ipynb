{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Improve to a higher salary level. A global scale perspective :\nAbility dependence, Experience dependence, both or none of these?**\n\nIn ML generation,  companies and industries looking for more expertise to help analyze and predict how their products fit the need of customers and markets through out the world. Instead, ML has been applied to multiple fields of industries. As a consequence, the more precise prediction a worker can provide, the higher salary the worker can earn. However, behind an accurate prediction and a higher salary level, there were lots of effort needs to be contributed. Namely, what skills, experience, and learning attitude a worker should prepare determined the salary level. Therefore, inorder to found out what determined the compensation level and difference between districts, in this notebook, I will provide the following steps to analysed and visualised the datasets based on this survey:\n\n1. Feature cleaning\n2. Feature engineering\n3. Selecting feature\n4. Visualised these features\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#dataframe import\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n#for statas\nfrom scipy import stats\n\n#visualsing\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom matplotlib import rc\n\n\n#Data featuring\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.base import BaseEstimator, TransformerMixin\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"#Useful function to extract columns and count ability\n\ndef Extract_columns(data, Select_condition, act):\n    columnname = list(data.iloc[1].index)\n    \n    Qstep1 = []\n    for word in columnname:\n        re = Select_condition in word\n        Qstep1.append(re)\n        \n    Q = []\n    for var in list(np.where(Qstep1)[0]):\n        re = columnname[var]\n        Q.append(re)\n    \n    if act == \"remove\":\n        re = data.drop(Q, axis = 1)\n    elif act == \"Convert\":\n        data[Q] = data[Q].notnull().astype('int')\n    else:\n        re = data[Q]\n\n    return(re)\n\n\ndef CountNumberAbility(data, dropvalue, select_condition,act):\n    \n    x_testQQ = data.drop([dropvalue], axis = 1)\n    QQ = Extract_columns(data = x_testQQ , Select_condition = select_condition, act = act)\n    \n    QQ = QQ.notnull().astype('int')\n    \n    number_of_ability = QQ.sum(axis=1)\n    return(number_of_ability)\n\n\n#Outlier detection by IQR\ndef OutlierRemove(data, listoftarget):\n    \n    tg = data[listoftarget]\n    \n    Q1 = tg.quantile(0.25)\n    Q3 = tg.quantile(0.75)\n    IQR = Q3 - Q1\n    \n    data_out = data[~((tg < (Q1 - 1.5 * IQR)) |(tg > (Q3 + 1.5 * IQR))).any(axis=1)]\n    \n    return(data_out)\n\n#for modeling \ndef rmse(model):\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    \n    return mean_squared_error(y_test, y_pred, squared= False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Process of hadling the survey data**\n1. Countries were group as differernt district based on their geolocation. \n2. The nomial variables were transform to dummie format to prepared for feature selection. \n3. Those ordinal variables were transform to numeric number. \n3. Adding features based on the counts of prgramming language, database, environment, method of machine learning, method of visulising, and modeling approach that a worker is familiar with as ability.  \n4. Remove the outlier from those numeric variable if they present.\n5. Dropped those questions that is not correlated with ability or attitude (e.g. questions relates to the company scale of a worker belongs to and gender of a human)."},{"metadata":{"trusted":true},"cell_type":"code","source":"class FeatureEngineering(BaseEstimator, TransformerMixin):\n    def fit(self, X, y= None):\n        self.drop_ls = ['Q8',\n                        'Q1',\n                        'Q2',\n                        'Q5',\n                        'Q20',\n                        'Q21',\n                        'Q25',\n                        'Q37_Part_1',\n                        'Q37_Part_2',\n                        'Q37_Part_3',\n                        'Q37_Part_4',\n                        'Q37_Part_5',\n                        'Q37_Part_6',\n                        'Q37_Part_7',\n                        'Q37_Part_8',\n                        'Q37_Part_9',\n                        'Q37_Part_10',\n                        'Q37_Part_11',\n                        'Q39_Part_1',\n                        'Q39_Part_2',\n                        'Q39_Part_3',\n                        'Q39_Part_4',\n                        'Q39_Part_5',\n                        'Q39_Part_6',\n                        'Q39_Part_7',\n                        'Q39_Part_8',\n                        'Q39_Part_9',\n                        'Q39_Part_10',\n                        'Q39_Part_11',\n                        'Time from Start to Finish (seconds)'\n                      ]\n    \n    def transform(self, X, y= None): \n        \n        #Removed the column include \"OTHER\" to ensure the suffecient information that gain from this survey\n        X = Extract_columns(X, \"OTHER\", \"remove\")\n        \n        #Reclassifying featureing\n        X[\"Q24\"].replace({\"$0-999\": 1, \n                       \"1,000-1,999\": 2,\n                       \"2,000-2,999\": 2, \n                       \"3,000-3,999\": 2, \n                       \"4,000-4,999\": 2, \n                       \"5,000-7,499\": 3, \n                       \"7,500-9,999\": 3,\n                       \"10,000-14,999\":4, \n                       \"15,000-19,999\":4, \n                       \"20,000-24,999\":5,\n                       \"25,000-29,999\":5, \n                       \"30,000-39,999\":6,\n                       \"40,000-49,999\":7,\n                       \"50,000-59,999\":8,\n                       \"60,000-69,999\":9,\n                       \"70,000-79,999\":10,\n                       \"80,000-89,999\":11,\n                       \"90,000-99,999\":12,\n                       \"100,000-124,999\":13,\n                       \"125,000-149,999\":14,\n                       \"150,000-199,999\":15,\n                       \"200,000-249,999\":16,\n                       \"250,000-299,999\":17,\n                       \"300,000-500,000\":18,\n                       \"> $500,000\":19,}, inplace=True)\n        \n        X[\"Q3\"].replace({\"India\": \"South_Asia\", \n                       \"United States of America\": \"North_America\",\n                       \"Other\": \"Other\", \n                       \"Brazil\": \"South_America\", \n                       \"Japan\": \"East_Asia\", \n                       \"Russia\": \"North_Asia\", \n                       \"United Kingdom of Great Britain and Northern Ireland\": \"West_Europe\",\n                       \"Germany\":\"Central_Europe\", \n                       \"Nigeria\":\"Africa\", \n                       \"Spain\":\"South_Europe\",\n                       \"Canada\":\"North_America\", \n                       \"France\":\"West_Europe\",\n                       \"Italy\":\"South_Europe\",\n                       \"China\":\"East_Asia\",\n                       \"Turkey\":\"West_Asia\",\n                       \"Australia\":\"Australia\",\n                       \"Mexico\":\"South_America\",\n                       \"Indonesia\":\"Southeast_Asia\",\n                       \"Taiwan\":\"East_Asia\",\n                       \"Pakistan\":\"South_Asia\",\n                       \"Colombia\":\"South_America\",\n                       \"Ukraine\":\"East_Europe\",\n                       \"Netherlands\":\"West_Europe\",\n                       \"Poland\":\"Central_Europe\",\n                       \"Egypt\":\"Africa\",\n                       \"Singapore\":\"Southeast_Asia\",\n                       \"Portugal\":\"South_America\",\n                       \"South Korea\":\"East_Asia\",\n                       \"Argentina\":\"South_America\",\n                       \"Viet Nam\":\"Southeast_Asia\",\n                       \"South Africa\":\"Africa\",\n                       \"Iran, Islamic Republic of...\":\"West_Asia\",\n                       \"Kenya\":\"Africa\",\n                       \"Thailand\":\"Southeast_Asia\",\n                       \"Greece\":\"South_Europe\",\n                       \"Israel\":\"West_Asia\",\n                       \"Peru\":\"South_America\",\n                       \"Chile\":\"South_America\",\n                       \"Morocco\":\"Africa\",\n                       \"Sweden\":\"North_Europe\",\n                       \"Malaysia\":\"Southeast_Asia\",\n                       \"Philippines\":\"Southeast_Asia\",\n                       \"Tunisia\":\"Africa\",\n                       \"Switzerland\":\"Central_Europe\",\n                       \"Saudi Arabia\":\"West_Asia\",\n                       \"Bangladesh\":\"South_Asia\",\n                       \"United Arab Emirates\":\"West_Asia\",\n                       \"Republic of Korea\":\"East_Asia\",\n                       \"Sri Lanka\":\"South_Asia\",\n                       \"Romania\":\"South_Europe\",\n                       \"Ghana\":\"Africa\",\n                       \"Belarus\":\"East_Europe\", \n                       \"Belgium\":\"West_Europe\", \n                       \"Ireland\":\"West_Europe\", \n                       \"Nepal\":\"South_Asia\"}, inplace=True)\n        \n       \n        \n       \n        #Adding new feature: These feature were created based on the number of skill or abililty that a person had learn or famamilar with.\n        #I dopped the column \"None\" to ensure it is not one of the ability they learnt.\n        \n        number_of_code= CountNumberAbility(data = X, dropvalue = \"Q7_Part_11\", select_condition = \"Q7\", act = \"non\")\n        number_of_env= CountNumberAbility(data = X, dropvalue = \"Q9_Part_10\", select_condition = \"Q9\", act = \"non\") \n        number_of_notebook= CountNumberAbility(data = X, dropvalue = \"Q10_Part_13\", select_condition = \"Q10\", act = \"non\")   \n        number_of_hardware = CountNumberAbility(data = X, dropvalue = \"Q12_Part_2\", select_condition = \"Q12\", act = \"non\")   \n        number_of_visualised = CountNumberAbility(data = X, dropvalue = \"Q14_Part_11\", select_condition = \"Q14\", act = \"non\")   \n        number_of_ML = CountNumberAbility(data = X, dropvalue = \"Q16_Part_15\", select_condition = \"Q16\", act = \"non\")   \n        number_of_AL = CountNumberAbility(data = X, dropvalue = \"Q17_Part_11\", select_condition = \"Q17\", act = \"non\")   \n        number_of_vision = CountNumberAbility(data = X, dropvalue = \"Q18_Part_6\", select_condition = \"Q18\", act = \"non\")   \n        number_of_nlp = CountNumberAbility(data = X, dropvalue = \"Q19_Part_5\", select_condition = \"Q19\", act = \"non\")   \n        number_of_useage = CountNumberAbility(data = X, dropvalue = \"Q23_Part_7\", select_condition = \"Q23\", act = \"non\")\n        number_of_cloud = CountNumberAbility(data = X, dropvalue = \"Q26_A_Part_10\", select_condition = \"Q26_A\", act = \"non\")\n        number_of_service = CountNumberAbility(data = X, dropvalue = \"Q27_A_Part_10\", select_condition = \"Q27_A\", act = \"non\")\n        number_of_platform = CountNumberAbility(data = X, dropvalue = \"Q28_A_Part_10\", select_condition = \"Q28_A\", act = \"non\")\n        number_of_database = CountNumberAbility(data = X, dropvalue = \"Q29_A_Part_16\", select_condition = \"Q29_A\", act = \"non\")\n        number_of_BI = CountNumberAbility(data = X, dropvalue = \"Q31_A_Part_14\", select_condition = \"Q31_A\", act = \"non\")\n        number_of_AutoML = CountNumberAbility(data = X, dropvalue = \"Q33_A_Part_7\", select_condition = \"Q33_A\", act = \"non\")\n        number_of_AutoMLskill = CountNumberAbility(data = X, dropvalue = \"Q34_A_Part_11\", select_condition = \"Q34_A\", act = \"non\")\n        number_of_MLtool = CountNumberAbility(data = X, dropvalue = \"Q35_A_Part_10\", select_condition = \"Q35_A\", act = \"non\")\n        number_of_shareing = CountNumberAbility(data = X, dropvalue = \"Q36_Part_9\", select_condition = \"Q36\", act = \"non\")\n        \n        \n        X['Environment_ability'] = number_of_env\n        X['Code_ability'] = number_of_code\n        X['Notebook_ability'] = number_of_notebook\n        X['Hardware_ability'] = number_of_hardware\n        X['Visualised_ability'] = number_of_visualised\n        X['ML_ability'] = number_of_ML\n        X['AL_ability'] = number_of_AL\n        X['Vision_ability'] = number_of_vision\n        X['nlp_ability'] = number_of_nlp\n        X['Numberof_applyfield'] = number_of_useage\n        X['Cloud_ability'] = number_of_cloud\n        X['Service_ability'] = number_of_service\n        X['platform_ability'] = number_of_platform\n        X['database_ability'] = number_of_database\n        X['BI_ability'] = number_of_BI             \n        X['AutoML_ability'] = number_of_AutoML\n        X['AutoMLskill_ability'] = number_of_AutoMLskill\n        X['MLtool_ability'] = number_of_MLtool\n        X['Sharing_of_heart'] = number_of_shareing\n\n        \n        \n        #Replace the threshold variable to numeric value\n        X['Q4'].replace(list(X['Q4'].value_counts().index),[4,3,5,6,2,0,1], inplace = True)\n        X['Q6'].replace(list(X['Q6'].value_counts().index),[3,2,4,5,1,6,0], inplace = True)\n        X['Q11'].replace(list(X['Q11'].value_counts().index),[1,2,3,4,0], inplace = True)\n        X['Q13'].replace(list(X['Q13'].value_counts().index), [2,3,4,0,1], inplace = True)\n        X['Q15'].replace(list(X['Q15'].value_counts().index), [1,2,3,0,4,6,5,7,8], inplace = True)\n        X['Q22'].replace(list(X['Q22'].value_counts().index), [3,0,5,4,1,2], inplace = True)\n        \n        \n        \n        #Replace the skill ability to 1 and 0\n        Extract_columns(data = X, Select_condition = \"Q7\" , act = \"Convert\")\n        Extract_columns(data = X, Select_condition = \"Q9\" , act = \"Convert\")\n        Extract_columns(data = X, Select_condition = \"Q10\" , act = \"Convert\")\n        Extract_columns(data = X, Select_condition = \"Q12\" , act = \"Convert\")\n        Extract_columns(data = X, Select_condition = \"Q14\" , act = \"Convert\")\n        Extract_columns(data = X, Select_condition = \"Q19\" , act = \"Convert\")\n        Extract_columns(data = X, Select_condition = \"Q16\" , act = \"Convert\")  \n        Extract_columns(data = X, Select_condition = \"Q17\" , act = \"Convert\")\n        Extract_columns(data = X, Select_condition = \"Q18\" , act = \"Convert\")\n        Extract_columns(data = X, Select_condition = \"Q23\" , act = \"Convert\")\n        Extract_columns(data = X, Select_condition = \"Q26\" , act = \"Convert\")\n        Extract_columns(data = X, Select_condition = \"Q27\" , act = \"Convert\")\n        Extract_columns(data = X, Select_condition = \"Q28\" , act = \"Convert\")\n        Extract_columns(data = X, Select_condition = \"Q29\" , act = \"Convert\")\n        Extract_columns(data = X, Select_condition = \"Q31\" , act = \"Convert\")\n        Extract_columns(data = X, Select_condition = \"Q33\" , act = \"Convert\")\n        Extract_columns(data = X, Select_condition = \"Q35\" , act = \"Convert\")\n        Extract_columns(data = X, Select_condition = \"Q34\" , act = \"Convert\")\n        Extract_columns(data = X, Select_condition = \"Q36\" , act = \"Convert\")\n      \n        #Outlier removing which is based on the scatter plot between compensation level and the below feature\n        X = X.loc[X['Sharing_of_heart'] < 6]\n        X = X.loc[X['MLtool_ability'] < 6]\n        X = X.loc[X['platform_ability'] < 8]\n        X = X.loc[X['AutoMLskill_ability'] < 7]\n        X = X.loc[X['AutoML_ability'] < 7]\n        X = X.loc[X['BI_ability'] < 7]\n        X = X.loc[X['database_ability'] < 11]\n        X = X.loc[X['Service_ability'] < 9]\n        X = X.loc[X['Cloud_ability'] < 8]\n        X = X.loc[X['ML_ability'] < 13]\n        X = X.loc[X['Visualised_ability'] < 10]\n        X = X.loc[X['Code_ability'] < 10]\n        X = X.loc[X['Environment_ability'] < 9]   \n        \n        #Drop the NA rows of Q11, Q13, Q15, Q17 but not filling it is because they are indepandant variable.\n        #Therfore it is not feasible insert it with the most ovserved feature or average feature\n        \n        X = X[X['Q11'].notna()]\n        X = X[X['Q25'].notna()]\n        \n        \n        for feature in self.drop_ls:\n            X.drop([feature], axis=1, inplace=True)\n        return X\n    \n    def fit_transform(self, X, y=None):\n        \n        self.fit(X, y)\n        return self.transform(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Transform these variable to dummy variable\ndef getrans(X):\n    X = pd.get_dummies(X,columns=[\"Q30\"])\n    X = pd.get_dummies(X,columns=[\"Q32\"])\n    X = pd.get_dummies(X,columns=[\"Q38\"])\n    X = Extract_columns(X, \"Other\", \"remove\")\n    return(X)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"#Data import\ndf_test = pd.read_csv('../input/kaggle-survey-2020/kaggle_survey_2020_responses.csv')\ndf_test= df_test.drop([0], axis = 0)\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#To begin with this project, I remove the nan row based on \"Q24 What is your current yearly compensation (approximate $USD)\"\n\nx_test = df_test.copy()\nx_test = Extract_columns(data = x_test,Select_condition = \"B\", act = \"remove\")\nx_test = x_test[x_test['Q24'].notna()]\nx_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"#Dealing with features by the feature engineering above\nft = FeatureEngineering()\nft.fit(x_test)\nx_test = ft.transform(x_test)\n\nx_test = getrans(x_test)\nx_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"#To check whether two variable in the datasets correlating with each other         \nNumeric_variable = ['Environment_ability','Code_ability','Notebook_ability','Hardware_ability',\n                    'Visualised_ability','ML_ability','AL_ability','Vision_ability','nlp_ability',\n                    'Numberof_applyfield','Cloud_ability','Service_ability','platform_ability','database_ability',\n                    'BI_ability','AutoML_ability','AutoMLskill_ability','MLtool_ability','Sharing_of_heart','Q4','Q6','Q11','Q22','Q24'\n                   ]\n\n\nNumeric = x_test[Numeric_variable]\ncorr = Numeric.corr()\n\n#The true here stands for keeping the variable and no auto correlation appear between features.\nm = ~(corr.mask(np.eye(len(corr), dtype=bool)).abs() > 0.85).any()\nm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"#Plot the correlation heat map\nplt.subplots(figsize=(15,12))\nsns.heatmap(data = corr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"#Checking outlier of compensation level by IQR\nx_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"#Checking outlier of compensation level by IQR\n\nlistoftarget = ['Q24']\nout = OutlierRemove(data = x_test,listoftarget = listoftarget)\nout.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Countrygroup = (x_test.groupby(['Q3'])['Q24']\n          .value_counts(normalize=True)\n          .rename('percentage')\n          .mul(100)\n          .reset_index())\nCountrygroup = Countrygroup.loc[Countrygroup['Q3'] != \"Other\"]\ng = sns.FacetGrid(Countrygroup, col=\"Q3\", col_wrap= 3)\ng.map(sns.barplot,\"Q24\", \"percentage\")\ng.set(xlabel=\"Compensation Levels\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Unblance compensation level among districts** \n* The histogram shows differernt salary structure between districts. In Africa and South Asia, those people who earn less than 999 dolars per year is more than 50%. The structure is more even in Europe and North America."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Modeling\nX = x_test.drop(['Q24','Q3'],axis = 1)\ny = x_test['Q24']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model selection to found out which criteria determined the compensation level**\n* By applying SelectKBest based on F-test and ExtraTreesClassifier, I found that the most three influencial factors are the expreience of ML you learnt and apply and the experience of coding. (i.g. Q6, Q15, Q22) This result infered that instead of chosing what type of program language to learn or how many types of programing language to learn, people who is looking for a higher compensation level should focus on more projects relate to ML to gain experience.  "},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\nfrom numpy import set_printoptions\n\ntest = SelectKBest(score_func=f_classif, k=4)\nfit = test.fit(X, y)\n# summarize scores\nset_printoptions(precision=3)\n\n\nimpo = list(fit.scores_)\ncol = list(X.columns) \nd = {'column':col,'Importance':impo}\n\nImportanceresult = pd.DataFrame(d).sort_values(['Importance'], ascending=False)\nImportanceresult = Importanceresult.head(3)\nImportanceresult['Full Question name'] = ['For how many years have you been writing code and/or programming?','For how many years have you used machine learning methods?','Does your current employer incorporate machine learning methods into their business?']\n\nImportanceresult","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\n\n\nmodel = ExtraTreesClassifier(n_estimators=10)\nmodel.fit(X, y)\n\nimpo = list(model.feature_importances_)\ncol = list(X.columns) \nd = {'column':col,'Importance':impo}\nImportanceresult = pd.DataFrame(d).sort_values(['Importance'],ascending=False)\n\n#Setup a threshold\nthres = Importanceresult['Importance'].mean()*3\n\n#Extract the column\nSelectimpo = Importanceresult.loc[Importanceresult['Importance'] > thres]\n\n\n\nSelectimpo = Selectimpo.head(3)\nSelectimpo['Full Question name'] = ['For how many years have you been writing code and/or programming?','For how many years have you used machine learning methods?','Does your current employer incorporate machine learning methods into their business?']\n\nSelectimpo\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Visualised Q6 with compensation level\n#sns.barplot(data = x_test, x = 'Q6' , y  = 'Q24')\ncolor_palette = ['#620800','#ff1500','#ff5500','#ff9500', '#ffd500','#e9ff00']\ndc = {'Q6':list(x_test.groupby(['Q6'])['Q24'].mean().index),\n      'Value':list(x_test.groupby(['Q6'])['Q24'].mean().values),\n      'Std':list(x_test.groupby(['Q6'])['Q24'].std().values)}\nQ6 = pd.DataFrame(dc)\n\n#list(x_test.groupby(['Q6'])['Q24'].mean().index)\npositions = (1, 2, 3, 4, 5 ,6)\nlabels = (\"< 1 years\", \"1-2 years\", \"3-5 years\", \"5-10 years\", \"10-20 years\", \"20+ years\")\nplt.rcParams[\"figure.figsize\"] = (10, 6)\nbarWidth = 0.85\nplt.bar(Q6['Q6'], Q6['Value'], yerr=Q6['Std'],color= color_palette[1], edgecolor='white', width=barWidth, align='center', alpha=0.5, ecolor='black', capsize=10)\nplt.xticks(positions, labels)\nplt.xlabel(\"Question 6\", fontsize = 16)\nplt.ylabel(\"Average_Compensaionlevel\", fontsize = 16)\nplt.title(\"For how many years have you been writing code and/or programming?\", fontsize = 16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From bar plot result of question 6, we can tell that the more coding experience, the higher compensation level a person will earn. Namely, concentrate on few particular programming language is enough to solve differernt problem on projects. This result is disagree with what I expected which is the more programming language a person known the more salary he/she will earn. The reason might due to it is more important how you solve the problem by your familiar language instead of knowing lots of programming languages and keep the problem unsolved."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Visualised Q6 with compensation level\ndc = {'Q15':list(x_test.groupby(['Q15'])['Q24'].mean().index),\n      'Value':list(x_test.groupby(['Q15'])['Q24'].mean().values),\n      'Std':list(x_test.groupby(['Q15'])['Q24'].std().values)}\nQ15 = pd.DataFrame(dc)\nplt.rcParams[\"figure.figsize\"] = (10, 6)\nplt.bar(Q15['Q15'], Q15['Value'], yerr=Q15['Std'],color= color_palette[1], edgecolor='white', width=barWidth, align='center', alpha=0.5, ecolor='black', capsize=10)\nplt.rcParams[\"figure.figsize\"] = (10, 6)\npositions = (0, 1, 2, 3, 4, 5 ,6 ,7 ,8 )\nlabels = (\"I do not use\",\"< 1 years\", \"1-2 years\", \"2-3 years\", \"3-4 years\",\"4-5 years\",\"5-10 years\", \"10-20 years\", \"20+ years\")\n\nplt.xticks(positions, labels, rotation=45)\nplt.xlabel(\"Question 15\", fontsize = 16)\nplt.ylabel(\"Average_Compensaionlevel\", fontsize = 16)\nplt.title(\"For how many years have you used machine learning methods?\",  fontsize = 16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From bar plot result of question 15, it goes similar as the result of question 6. Here, the result showed that the more time spending on machine learning the more money you earn. On the other words, the salary level is depended on how fast you get familiar with the job. Besides, those people who work on machine learning for only 1 - 3 year might not learn enough experience from their job. This result could give us a hint that if you want to imporve yourself to a better compensation level it might not be immediate."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Visualised Q6 with compensation level\n#sns.barplot(data = x_test, x = 'Q22' , y  = 'Q24')\n\ndc = {'Q22':list(x_test.groupby(['Q22'])['Q24'].mean().index),\n      'Value':list(x_test.groupby(['Q22'])['Q24'].mean().values),\n      'Std':list(x_test.groupby(['Q22'])['Q24'].std().values)}\nQ22 = pd.DataFrame(dc)\n\nplt.rcParams[\"figure.figsize\"] = (10, 6)\nplt.bar(Q22['Q22'], Q22['Value'], yerr=Q22['Std'],color= color_palette[1], edgecolor='white', width=barWidth, align='center', alpha=0.5, ecolor='black', capsize=10)\npositions = (0,1, 2, 3, 4, 5 )\nlabels = (\"do not know\", \"not use\", \"generating insights\", \"exploring\", \"recently started\", \"well established\")\n\nplt.xticks(positions, labels, rotation=45)\nplt.xlabel(\"Question 22\", fontsize = 16)\nplt.ylabel(\"Average_Compensaionlevel\", fontsize = 16)\nplt.title(\"Does your current employer incorporate machine learning methods into their business?\",  fontsize = 16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From bar plot result of question 22, the highest average compensation level is fall into the \"employer have well established ML methods\" group. Although this result is not directly link to what ability or what atitude that need to be prepared, it still tells us, again, establishing ML methods is a trend for company. Therfore, link to the result showed in question 15, the people who are more familiar with Machine Learning, the higher compensation level they earn.  "},{"metadata":{},"cell_type":"markdown","source":"**Comparison the three most important factors by differernt district**\n* From the bar plots below, it is easily to fonud that most of the developing district is still lacking of the experience of coding. Not to mention a well developing maching learning skills. Most of the number of the people who had less written code and used machine learning approach is dominant by Africa. This also reflect the compensation level of their district. While the case is totaly oppsite in those well developing district such as North America and North Europe. These result not only reflect the compensation level but also the education structure, since the ability of coding and machine learning is based on well developed education system. However, this system could not be found since people in those district might confronting problem of survive. Besides, from these results we might able to discover the gap of technology between those developing districts and well developed districts."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x_test = x_test.loc[x_test['Q3'] != 'Other']\nCountrygroup = (x_test.groupby(['Q3'])['Q6']\n          .value_counts(normalize=True)\n          .rename('percentage')\n          .mul(100)\n          .reset_index())\nCountrygroup = Countrygroup.sort_values(['Q3'], ascending=False)\n\nplt.rcParams[\"figure.figsize\"] = (10, 6)\n\n#district = list(Countrygroup['Q3'].value_counts().index)\nQuestion_level = list(Countrygroup['Q6'].value_counts().index)\n\n#Question_level\n\n\n\nlegend = ['< 1 years', '1 - 2 years']\n\n\n\nfirst = Countrygroup.loc[Countrygroup['Q6'] == Question_level[5]].sort_values(['Q3'], ascending=False)\nsecond = Countrygroup.loc[Countrygroup['Q6'] == Question_level[4]].sort_values(['Q3'], ascending=False)\n\nfirst['sum'] = first['percentage'].values + second['percentage'].values\nsecond['sum'] = first['percentage'].values + second['percentage'].values\n\nfirst = first.sort_values(['sum'], ascending=False)#['percentage']\nsecond = second.sort_values(['sum'], ascending=False)['percentage']\n\n\nplt.bar(first['Q3'], first['percentage'],color= color_palette[1], edgecolor='white', width=barWidth, alpha = 0.6)\nplt.bar(first['Q3'], second, bottom = first['percentage'],color= color_palette[3], edgecolor='white', width=barWidth, alpha = 0.6)\n\n\nplt.xlabel(\"District\", fontsize = 16)\nplt.ylabel(\"Percentage\", fontsize = 16)\n\nplt.legend(labels = legend, bbox_to_anchor=(1.02, 1), loc='upper left', fontsize = 14)\nplt.xticks(rotation=90,  fontsize = 14)\nplt.yticks(fontsize = 14)\n\nplt.title('For how many years have you been writing code and/or programming?', fontsize = 16)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"\nfirst = Countrygroup.loc[Countrygroup['Q6'] == Question_level[0]].sort_values(['Q3'], ascending=False)\nsecond = Countrygroup.loc[Countrygroup['Q6'] == Question_level[1]].sort_values(['Q3'], ascending=False)\n\nfirst['sum'] = first['percentage'].values + second['percentage'].values\nsecond['sum'] = first['percentage'].values + second['percentage'].values\n\nfirst = first.sort_values(['sum'], ascending=True)#['percentage']\nsecond = second.sort_values(['sum'], ascending=True)['percentage']\n\nlegend = ['20+ years','10-20 years']\n\n\nplt.bar(first['Q3'], first['percentage'],color= color_palette[1], edgecolor='white', width=barWidth, alpha = 0.6)\nplt.bar(first['Q3'], second, bottom = first['percentage'],color= color_palette[3], edgecolor='white', width=barWidth, alpha = 0.6)\n\n\nplt.xlabel(\"District\", fontsize = 16)\nplt.ylabel(\"Percentage\", fontsize = 16)\n\nplt.legend(labels = legend, bbox_to_anchor=(1.02, 1), loc='upper left', fontsize = 14)\nplt.xticks(rotation=90,  fontsize = 14)\nplt.yticks(fontsize = 14)\nplt.title('For how many years have you been writing code and/or programming?', fontsize = 16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x_test = x_test.loc[x_test['Q3'] != 'Other']\nCountrygroup = (x_test.groupby(['Q3'])['Q15']\n          .value_counts(normalize=True)\n          .rename('percentage')\n          .mul(100)\n          .reset_index())\nCountrygroup = Countrygroup.sort_values(['Q3'], ascending=False)\n\nplt.rcParams[\"figure.figsize\"] = (10, 6)\n\n#district = list(Countrygroup['Q3'].value_counts().index)\nQuestion_level = list(Countrygroup['Q15'].value_counts().index)\n# color_palette = ['#620800','#ff1500','#ff5500','#ff9500', '#ffd500','#e9ff00']\nQuestion_level = sorted(Question_level)\nQuestion_level\n\n# barWidth = 0.85\nlegend = ['I do not use machine learning methods','Under 1 year', '1-2 years']\n\n\n\nfirst = Countrygroup.loc[Countrygroup['Q15'] == Question_level[0]].sort_values(['Q3'], ascending=False)\nsecond = Countrygroup.loc[Countrygroup['Q15'] == Question_level[1]].sort_values(['Q3'], ascending=False)\nthird = Countrygroup.loc[Countrygroup['Q15'] == Question_level[2]].sort_values(['Q3'], ascending=False)\n\nfirst['sum'] = first['percentage'].values + second['percentage'].values\nsecond['sum'] = first['percentage'].values + second['percentage'].values\nthird['sum'] = second['percentage'].values + third['percentage'].values\n\n\nfirst = first.sort_values(['sum'], ascending=True)\nsecond = second.sort_values(['sum'], ascending=True)['percentage']\nthird = third.sort_values(['sum'], ascending=True)['percentage']\n\n\nplt.bar(first['Q3'], first['percentage'],color= color_palette[1], edgecolor='white', width=barWidth, alpha = 0.6)\nplt.bar(first['Q3'], second, bottom = first['percentage'],color= color_palette[2], edgecolor='white', width=barWidth, alpha = 0.6)\nplt.bar(first['Q3'], third, bottom=[i+j for i,j in zip(first['percentage'], second)],color= color_palette[3], edgecolor='white', width=barWidth, alpha = 0.6)\n\n\nplt.xlabel(\"District\", fontsize = 16)\nplt.ylabel(\"Percentage\", fontsize = 16)\n\nplt.legend(labels = legend, bbox_to_anchor=(1.02, 1), loc='upper left', fontsize = 14)\nplt.xticks(rotation=90,  fontsize = 14)\nplt.yticks(fontsize = 14)\nplt.title('For how many years have you used machine learning methods', fontsize = 16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"first = Countrygroup.loc[Countrygroup['Q15'] == Question_level[7]].sort_values(['Q3'], ascending=False)\nsecond = Countrygroup.loc[Countrygroup['Q15'] == Question_level[6]].sort_values(['Q3'], ascending=False)\n\nfirst['sum'] = first['percentage'].values + second['percentage'].values\nsecond['sum'] = first['percentage'].values + second['percentage'].values\n\nfirst = first.sort_values(['sum'], ascending=True)#['percentage']\nsecond = second.sort_values(['sum'], ascending=True)['percentage']\n\nlegend = ['20+ years','10-20 years']\n\n\nplt.bar(first['Q3'], first['percentage'],color= color_palette[1], edgecolor='white', width=barWidth, alpha = 0.6)\nplt.bar(first['Q3'], second, bottom = first['percentage'],color= color_palette[3], edgecolor='white', width=barWidth, alpha = 0.6)\n\n\nplt.xlabel(\"District\", fontsize = 16)\nplt.ylabel(\"Percentage\", fontsize = 16)\n\nplt.legend(labels = legend, bbox_to_anchor=(1.02, 1), loc='upper left', fontsize = 14)\nplt.xticks(rotation=90,  fontsize = 14)\nplt.yticks(fontsize = 14)\nplt.title('For how many years have you used machine learning methods', fontsize = 16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"Countrygroup = (x_test.groupby(['Q3'])['Q22']\n          .value_counts(normalize=True)\n          .rename('percentage')\n          .mul(100)\n          .reset_index())\nCountrygroup = Countrygroup.sort_values(['Q3'], ascending=False)\n\nplt.rcParams[\"figure.figsize\"] = (10, 6)\n\n#district = list(Countrygroup['Q3'].value_counts().index)\nQuestion_level = list(Countrygroup['Q22'].value_counts().index)\ncolor_palette = ['#620800','#ff1500','#ff5500','#ff9500', '#ffd500','#e9ff00']\nQuestion_level = sorted(Question_level)\nQuestion_level\n\nbarWidth = 0.85\nlegend = [' I do not know','No (we do not use ML methods)']\n\n\n\nfirst = Countrygroup.loc[Countrygroup['Q22'] == Question_level[0]].sort_values(['Q3'], ascending=False)\nsecond = Countrygroup.loc[Countrygroup['Q22'] == Question_level[1]].sort_values(['Q3'], ascending=False)\n\nfirst['sum'] = first['percentage'].values + second['percentage'].values\nsecond['sum'] = first['percentage'].values + second['percentage'].values\n\n\nfirst = first.sort_values(['sum'], ascending=False)\nsecond = second.sort_values(['sum'], ascending=False)['percentage']\n\n\nplt.bar(first['Q3'], first['percentage'],color= color_palette[1], edgecolor='white', width=barWidth, alpha = 0.6)\nplt.bar(first['Q3'], second, bottom = first['percentage'],color= color_palette[3], edgecolor='white', width=barWidth, alpha = 0.6)\n\n\nplt.xlabel(\"District\", fontsize = 16)\nplt.ylabel(\"Percentage\", fontsize = 16)\n\nplt.legend(labels = legend, bbox_to_anchor=(1.02, 1), loc='upper left', fontsize = 14)\nplt.xticks(rotation=90,  fontsize = 14)\nplt.yticks(fontsize = 14)\nplt.title('Does your current employer incorporate machine learning methods into their business?', fontsize = 16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"Countrygroup = (x_test.groupby(['Q3'])['Q22']\n          .value_counts(normalize=True)\n          .rename('percentage')\n          .mul(100)\n          .reset_index())\nCountrygroup = Countrygroup.sort_values(['Q3'], ascending=False)\n\nplt.rcParams[\"figure.figsize\"] = (10, 6)\n\n#district = list(Countrygroup['Q3'].value_counts().index)\nQuestion_level = list(Countrygroup['Q22'].value_counts().index)\ncolor_palette = ['#620800','#ff1500','#ff5500','#ff9500', '#ffd500','#e9ff00']\nQuestion_level = sorted(Question_level)\nQuestion_level\n\nbarWidth = 0.85\nlegend = [' We have well established ML methods']\n\nfirst = Countrygroup.loc[Countrygroup['Q22'] == Question_level[5]].sort_values(['Q3'], ascending=False)\nfirst['sum'] = first['percentage'].values\nfirst = first.sort_values(['sum'], ascending=True)\n\nplt.bar(first['Q3'], first['percentage'],color= color_palette[3], edgecolor='white', width=barWidth, alpha = 0.6)\n\n\nplt.xlabel(\"District\", fontsize = 16)\nplt.ylabel(\"Percentage\", fontsize = 16)\n\nplt.legend(labels = legend, bbox_to_anchor=(1.02, 1), loc='upper left', fontsize = 14)\nplt.xticks(rotation=90,  fontsize = 14)\nplt.yticks(fontsize = 14)\nplt.title('Does your current employer incorporate machine learning methods into their business?', fontsize = 16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Conclusion**\n* In summary, this assay provides a clear answer of what brings a higher compensation level and why some of the districts include a lower compensation level structure. In shorts, earning more money by enhacing our expreience on coding and machine learning is necessary. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}