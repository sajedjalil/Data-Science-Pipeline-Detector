{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.utils import shuffle\nfrom IPython.core.display import display, HTML, Javascript\nfrom string import Template\nimport json, random\nimport IPython.display\nfrom plotly.offline import init_notebook_mode, iplot\nfrom plotly import subplots\nimport plotly.figure_factory as ff\nimport plotly as py\nimport plotly.graph_objects as go\ninit_notebook_mode(connected=True)\n\ndf = pd.read_csv('/kaggle/input/kaggle-survey-2020/kaggle_survey_2020_responses.csv')\ndf = df.drop(df.index[0])\nquestions = df.columns\n\n# Defining all our palette colours.\nprimary_blue = \"#496595\"\nprimary_blue2 = \"#85a1c1\"\nprimary_blue3 = \"#3f4d63\"\nprimary_grey = \"#c6ccd8\"\nprimary_black = \"#202022\"\nprimary_bgcolor = \"#f4f0ea\"\n\n# \"coffee\" pallette turqoise-gold.\nf1 = \"#a2885e\"\nf2 = \"#e9cf87\"\nf3 = \"#f1efd9\"\nf4 = \"#8eb3aa\"\nf5 = \"#235f83\"\nf6 = \"#b4cde3\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"html_contents =\"\"\"\n<!DOCTYPE html>\n<html lang=\"en\">\n    <head>\n    <style>\n    .toc h2{\n        color: white;\n        background: #3f4d63;\n        font-weight: 600;\n        font-family: Helvetica;\n        font-size: 23px;\n        padding: 6px 12px;\n        margin-bottom: 2px;\n    }\n    \n    .toc ol li{\n        list-style:none;\n        line-height:normal;\n        }\n     \n    .toc li{\n        background: #235f83;\n        color: white;\n        font-weight: 600;\n        font-family: Helvetica;\n        font-size: 18px;\n        margin-bottom: 2px;\n        padding: 6px 12px;\n    }\n\n    .toc ol ol li{\n        background: #fff;\n        color: #4d4d4d;\n        font-weight: 400;\n        font-size: 15px;\n        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n        margin-top: 0px;\n        margin-bottom: 0px;\n        padding: 3px 12px;\n    } \n    \n    .section_title{\n        background-color: #3f4d63;\n        color: white;\n        font-family: Helvetica;\n        font-size: 25px;\n        padding: 6px 12px;\n        margin-bottom: 5px;\n    }\n    .subsection_title{\n        background: #235f83;\n        color: white;\n        font-family: Helvetica;\n        font-size: 21px;\n        padding: 6px 12px;\n        margin-bottom: 0px;\n    }\n    .sidenote{\n        font-size: 13px;\n        border: 1px solid #d7d7d7;\n        padding: 1px 10px 2px;\n        box-shadow: 1px 1px 2px 1px rgba(0,0,0,0.3);\n        margin-bottom: 3px;\n    }\n    </style>\n    </head>\n    <body>\n        <div class=\"toc\">\n        \n        <ol> \n        <h2> Table of Contents </h2>\n        <li>1. Introduction </li> \n        <li>2. Meet the professionals</li>\n        <ol> \n            <li>2.1 Data related work across fields </li>\n            <li>2.2 The data science life cycle </li> \n            <li>2.3 Workflow of data professionals </li>\n            <li>2.4 Data roles in different fields </li>            \n            <li>2.5 Ages of data professionals </li> \n            <li>2.6 Education required </li> \n            <li>2.7 Company size and earnings </li> \n            <li>2.8 Machine learning practices </li>\n        </ol>\n        <li>3. What should I focus on? </li>\n        <ol> \n            <li>3.1 The skills gap </li> \n            <li>3.2 Development environments: IDEs and Hosted Notebooks </li>\n            <li>3.3 How much coding experience do I need? </li> \n            <li>3.4 Programming languages </li> \n            <li>3.5 Visualisation tools </li> \n            <li>3.6 How much machine learning experience do I need? </li> \n            <li>3.7 Machine learning frameworks </li> \n            <li>3.8 Learning platforms </li>\n            <li>3.9 Media and learning </li>\n            <li>3.10 Obstacles to working with data </li>\n        </ol>\n        <li>4. So you want to work in...? </li>\n        <ol> \n            <li>4.1 Computer Vision </li> \n            <li>4.2 Natural Language Processing </li> \n            <li>4.3 Machine learning in general </li>\n        </ol>\n        <li>5. Conclusion </li>\n        <li>6. References </li>\n        </ol>\n        </div>\n    </body>\n</html>\n\"\"\"\n\nHTML(html_contents)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <div class=\"section_title\">Enthusiast to Data Professional - What changes?</div>\n<img src=\"https://images.unsplash.com/photo-1459180129673-eefb56f79b45?ixid=MXwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHw%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=1052&q=80\" style=\"height: 370px; width: 100%; object-fit: cover; object-position: 0px -128px;\"/>\n<div class=\"sidenote\" style=\"margin:auto; text-align: center\"> \"At the bustling Times Square\" - Photo by <a href=\"https://unsplash.com/@saulomohana\">Saulo Mohana </a>| Unsplash  </div> \n\n## <div class=\"section_title\">1. Introduction</div>\n\nI'm sure many of you have read articles about all the buzz words in our community - \"Machine Learning\", \"Data Scientist\", \"AI\" and so on. Some have even branded data science as the \"**sexiest job of the 21st century**\"! While these articles go on about the high earnings and the supposed demand for them, very rarely do they go in to **what it takes to work with data**. They even tend to throw around a lot of terms like \"data analyst\", \"business analyst\", \"machine learning engineer\" without ever explaining what each one specifically deals with, while often **using them interchangably**.\n\nIn this notebook I aim to provide to all the enthusiasts in our community a better understanding of the field, the different jobs that work with data and what do they actually do in their day-to-day work. It also gives students a better insight into what technologies are used and hopefully will empower them with the information to help them break into some of these fields.\n\nI will also keep this notebook rather short, while I do enjoy designing graphs I am strong believer of quality over quantity so I will avoid bombarding you'll with any more information than is necessary, just for the sake of displaying data."},{"metadata":{},"cell_type":"markdown","source":"## <div class=\"subsection_title\">Criteria to be considered as a data professional</div>\n\nIn this analysis I will consider data professionals as those who have described their work to include at least one of the following tasks(responses to \"*Q23. Select any activities that make up an important part of your role at work*\"):\n- Analyze and understand data to influence product or business decisions\n- Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data\n- Build prototypes to explore applying machine learning to new areas\n- Build and/or run a machine learning service that operationally improves my product or workflows\n- Experimentation and iteration to improve existing ML models\n- Do research that advances the state of the art of machine learning\n\nThere was a small number of people who seemed to be employed but didn't respond to any of the fields in Q23, so I have omitted those entries for our analysis purpose.\n\nI also avoided any age restrictions that would exclude those that just joined into the field from being considered as data professionals because not only would it be subjective to decide how much experience one needs to be considered an expert, but also it's these individuals that are of most interest to enthusiasts as they too would like to understand what set them apart to land that job. "},{"metadata":{},"cell_type":"markdown","source":"# <div class=\"section_title\">2. Meet the Professionals</div>\n\nThis section will cover the different fields that make up our data professionals and how their roles differ from one another. We gain a better understanding of the companies in which they work and what are the salaries like in their line of work.\n"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Get list of all columns for question 23\nq23_all = [question for question in questions if 'Q23' in question]\n\n# Remove \"none column\"\nq23 = q23_all[0:6]\n\n# Those that have answered Q23\nq23_df = df[df[q23_all].isnull().sum(axis=1) != len(q23_all)]\n\n# Those who selected atleast one non-\"None\" option. This will be the set of all the data professionals going forwards\ndataprofs = q23_df[q23_df[q23].isnull().sum(axis=1) != len(q23)]\n\nprint(\"Total number of respondents: \", df.shape[0])\nprint(\"The number of data professionals in the respondents: \",dataprofs.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <div class=\"subsection_title\">2.1 Data related work across fields</div>\nSurely not all professions are made equally, so I wondered **which fields tend to have more professionals involved in data analysis activities?** The below graph shows the percentage of individuals within each field that work in data-related roles on a daily basis. **Additional details are included in the hover text.**\n<div class=\"sidenote\">\n    Source: Kaggle 2020 DS and ML Survey - <span style=\"font-style: italic;\">Q23. Select any activities that make up an important part of your role at work.</span>\n</div>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Field distribution of professionals\n\n# List of fields\nfields = dataprofs[\"Q5\"].unique()\n\n# DataFrame with required values for plotting and tooltips\nfields_df = pd.DataFrame()\nfields_df[\"all\"] = q23_df[\"Q5\"].value_counts()\nfields_df[\"profs\"] = dataprofs[\"Q5\"].value_counts()\nfields_df[\"non_profs\"] = fields_df[\"all\"] - fields_df[\"profs\"]\nfields_df[\"ratio\"] = fields_df[\"profs\"]/ fields_df[\"all\"]\nfields_df[\"proportion\"] = fields_df['profs'] * 100/ fields_df[\"profs\"].sum()\n\nfields_df.index = [index+\"  \" for index in fields_df.index]\n\ntrace1 = go.Bar(\n    y = fields_df.index,\n    x = fields_df[\"ratio\"],\n    orientation = \"h\",\n    marker = dict(color=[primary_blue] + [primary_grey]*10),\n    name = \"\",\n    width= 0.85,    \n    customdata = fields_df[[\"profs\",\"non_profs\",\"proportion\"]],\n    hoverinfo = \"none\",\n    hovertemplate = ' Work in data related roles: %{customdata[0]}<br> Do not work in data related roles: %{customdata[1]}<br> Contribution to  total number of data professionals: %{customdata[2]:.2f}%'\n)\n\nlayout = dict(\n    margin = dict(t=220),\n    legend=dict(orientation='h',yanchor='top',xanchor='center',y=-0.05,x=0.5,font=dict(size= 18),traceorder='normal'),\n    xaxis = dict(domain=[0,0.73],\n            tickformat=\"%\"),\n    yaxis= dict(\n            categoryorder = 'array',\n            categoryarray = fields_df[\"ratio\"].sort_values(ascending=True).keys()),\n    width = 780,\n    height = 600,\n    plot_bgcolor= \"#fff\",\n    hoverlabel=dict(\n        bgcolor=\"white\",\n        font_size=12\n    )\n)\n\ndata = [trace1]\n\nfig = go.Figure(data = data, layout = layout)\n\n# percentage annotations\nfor index in range(len(fields_df.index)):\n    fig.add_annotation(dict(\n                            x=(fields_df.iloc[index])[\"ratio\"]/2,\n                            y=fields_df.index[index],\n                            showarrow=False,\n                            text=\"<b style='color:#fff'> %d%%</b>\" % np.round((fields_df.iloc[index])[\"ratio\"]*100),\n                            textangle=0,\n                            xref=\"x\",\n                            yref=\"y\"\n                           ))\n\n# helper text annotation\nfig.add_annotation(dict(\n                            x=0.783,\n                            y=1.067,\n                            showarrow=False,\n                            text=\"<b style='font-family:Helvetica; font-size: 13px'>The bars depict the percentage of individuals in each field that work in data-related roles</b>\",\n                            textangle=0,\n                            xref=\"paper\",\n                            yref=\"paper\"\n                           ))\n\n# title annotation\nlarge_title_format = \"<span style='font-size:28px; font-family:Times New Roman'>How common is data related work across fields?</span>\"\nsmall_title_format = \"<span style='font-size:13px; font-family:Helvetica'><b style='color:#496595'>Data scientists</b> have the highest percentage of individuals that work with data. With 2,291 <br>respondents they form 26% of our data professionals, significantly ahead of data analysts in<br>second place with 13%.                                                                                                            <br></span>\"\n\nfig.add_annotation(dict(\n                            x=0.783,\n                            y=1.41,\n                            showarrow=False,\n                            text= large_title_format + \"<br><br>\" + small_title_format,\n                            textangle=0,\n                            xref=\"paper\",\n                            yref=\"paper\"\n                           ))\n\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Unsurprisingly fields like **Data Scientists**, with higher percentages of individuals working with data and contributing towards the bulk of the data professionals. **Data Analystst, Business Analysts, ML Engineers and Data Engineers are a close second** with high percentages of data professionals, however due to the fewer number of respondents in these categories they tend to contribute less towards our sum total."},{"metadata":{},"cell_type":"markdown","source":"## <div class=\"subsection_title\">2.2 The data science life cycle</div>\n\nWe will talk about a lot of tools and processes throughout the course of this notebook. This section will go over the basic steps and terminology in the data life cycle and will help enthusiasts understand how each of the discussed tools fit into the actual workflow.\n\nThis process is rarely linear and often occurs over multiple iterations. While the order of stages or terminology might be different, a basic overview of the stages in handling and working with data are as follows:\n1. Problem Identification\n2. Business Understanding\n3. Data Acquisition\n4. Data Cleaning\n5. Data Visualisation\n6. Feature Engineering\n7. Model Training\n8. Deployment\n\n**1. Problem Identification**\n\n   Often when starting out, the objective of a data science project might be rather ambiguous or we might lack an understanding of what exactly is the problem and how it affects all the parties involved. We remedy this by asking questions - *a lot of them* . We try get a better understanding of the domain and the root cause of the problem by speaking to the stakeholders and industry experts. Literature reviews and surveys will also help us decide what data we might want to collect and use.\n   \n**2. Business Understanding**\n\n   At this stage we try to define the business objective behind our data science problem. For example, we might be analysing prospective market segments with the **business objective of increasing the company's market share and the resulting profits**. Identifying such a business objective helps us define our success criteria for the project. We also define the metrics that will help us track our progress towards our objective:\n   - **KPI(Key Performance Indicator)**: Measure your performance against key business objectives. Businesses use this to measure their performance against objectives and the overall health of their business.\n   - **SLA(Service Level Agreement)**: These describe the level of service that will be provided to the client. It defines the metrics by which the performance will measured and also the penalties incurred if these standards aren't met. \n   \n   Poorly designed metrics will affect how the product is priced, customer experience and the overall company reputation, so its important to get this right.\n   \n**3. Data Acquisition**\n\n   In most data science industry projects, you will be using data that already exists and is being collected. Occasionally, you’ll be leading efforts to collect new data, but that can be a lot of engineering work and it can take a while to bear fruit. This is an iterative process often using an ETL/ELT pipeline consisting of the main stages:\n   - **Extract:** Extraction refers to pulling the source data from the original database or data source. With ETL, the data goes into a temporary staging area. With ELT, it goes immediately into a data lake storage system.\n   - **Transform:** Transformation refers to the process of changing the structure of the information, so it integrates with the target data system and the rest of the data in that system.\n   - **Load:** Loading refers to the process of depositing the information into a data storage system.\n   \n**4. Data Cleaning** \n\n   Just because the data is loaded into storage doesn't mean that its ready to be used in your analysis. Collected data may be full of issues like corrupted data, incorrectly formatted or invalid entries, duplicate data, etc. Remedying this is a time consuming process, because each field having missing or incorrect data begs another question as to why something went wrong that caused this to happen and also how do we fix this incorrect data. Such a task takes a great deal of manual effort and expertise to perform which soaks up a large chunk of data professionals' time.\n   \n**5. Data Visualisation** \n   \n   We now explore the data, looking for patterns and insights that might be worth investigating through the use of graphs and charts. Data visualisation is important not only in data exploration, but also when understanding our tracked metrics and communicating our results to answer our clients' most important questions.\n   \n**6. Feature Engineering** \n   \n   We utilise domain knowledge to craft features that will improve the performance of our machine learning model. This often involves applying data transforms like log transformation, binning, category encoding, etc. In this step we may also attempt to mitigate any bias in the data, remove outliers, etc.\n   \n**7. Model Training** \n\n   We start out by developing a baseline model that we will use as a reference against which we will test later models. This is an iterative process as one experiments with different algorithms, network architectures as well as the choice for loss metrics and hyperparameters used.\n   \n**8. Model Deployment** \n   Now we need to deploy our model so that it may be used by either the business or the client. Before you deploy a model, there are a couple of criteria that your machine learning model needs to achieve before it’s ready for deployment:\n - **Portability**: this refers to the ability of your software to be transferred from one machine or system to another. A portable model is one with a relatively low response time and one that can be rewritten with minimal effort.\n - **Scalability**: this refers to how large your model can scale. A scalable model is one that doesn’t need to be redesigned to maintain its performance. \n\n\nIf you wish to read further on these topics I'd recommend the following articles:\n- [The Data Science Process: What a data scientist actually does day-to-day](https://medium.springboard.com/the-data-science-process-the-complete-laymans-guide-to-what-a-data-scientist-actually-does-ca3e166b7c67)\n- [The “Generic” Data Science Life-Cycle](https://towardsdatascience.com/stoend-to-end-data-science-life-cycle-6387523b5afc)"},{"metadata":{},"cell_type":"markdown","source":"## <div class=\"subsection_title\">2.3 Workflow of Data Professionals</div>\n<a id='workflows'></a>\nWhile we do gain a basic idea of the roles our data professionals perform our survey question, I would still like to shed some light on the actual workflow of a data professional and how the previous activities factor into their daily work. For this we turn to [Anaconda's State of Data Science Report 2020](https://www.anaconda.com/state-of-data-science-2020) where they asked data scientists to assign a percentage of time spent to each stage of their data work. This helps us understand how much time is spent in each area of the workflow from start to end(top to bottom, in the diagram).\n\n<div class=\"sidenote\">\n    Source: Anaconda State of DS Report 2020 - <span style=\"font-style: italic;\"> Thinking about your current job, how much of your time is spent in each of the following tasks? </span>\n</div>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# With d3 We will first create the CSV file and write to the Kaggle working dir and then read the same from the js section of d3.\n# Creating the csv file for the stacked bar chart\n\nstages_df = pd.DataFrame([[\"stages\",11, 12, 11, 21, 26, 19]])\nstages_df.columns = [\"group\",'dm', 'mt', 'ms', 'dv', 'dc', 'dl']\n\nstages_df.to_csv(\"stages.csv\", index=False)\n\nhtmlt1 = '''\n<head>\n    <style>\n        .stages_title{\n            position: absolute;\n            font-size: 17.5px;\n            font-family: Tahoma;\n            margin-left: 10px;\n        }\n        .dv_stages{\n            border: 1px solid #d7d7d7;\n            width: 440px;\n            height: 600px\n            padding-left: 10px;\n            padding-top: 5px;\n            box-shadow: 2px 2px 2px 1px rgba(0,0,0,0.3); \n            margin: auto;\n        }\n    </style>\n</head>\n<body>\n    <div class=\"dv_stages\">\n    <div class=\"stages_title\">What percentage of time is spent in these activities?</div>\n    <div id=\"stages_viz\"></div>\n    </div>\n</body>\n'''\n\njs_t1 = '''\n         require.config({\n            paths: {\n                d3: \"https://d3js.org/d3.v4.min\"\n             }\n             });\n        require([\"d3\"], function(d3) {\n        \n         // set the dimensions and margins of the graph\n        var margin_stages = {top: 15, right: 30, bottom: 30, left:0},\n            width_stages = 460 - margin_stages.left - margin_stages.right,\n            height_stages = 400 - margin_stages.top - margin_stages.bottom;\n        \n        // append the svg object to the body of the page\n        var svg = d3.select(\"#stages_viz\")\n          .append(\"svg\")\n            .attr(\"width\", width_stages + margin_stages.left + margin_stages.right)\n            .attr(\"height\", height_stages + margin_stages.top + margin_stages.bottom)\n          .append(\"g\")\n            .attr(\"transform\",\n                  \"translate(\" + margin_stages.left + \",\" + margin_stages.top + \")\");\n        \n        // Create a map for titles\n        var title_data_stages = {\n            \"dl\" : \"Data loading\",\n            \"dc\" : \"Data cleansing\",\n            \"dv\" : \"Data visualisation\",\n            \"ms\" : \"Model selection\",\n            \"mt\" : \"Model training and scoring\",\n            \"dm\" : \"Deploying models\"\n        }\n        \n        // Create a map for desc\n        var desc_data_stages = {\n            \"dl\" : \"Retrieve and combine data from different sources.\",\n            \"dc\" : \"Remove or fix incorrect, duplicate or missing data.\",\n            \"dv\" : \"Graphical representation of data, to spot patterns.\",\n            \"ms\" : \"The task of selecting the best candidate model.\",\n            \"mt\" : \"Applying algorithms to the data and scoring them.\",\n            \"dm\" : \"Deployment of models into production.\"\n        }\n\n        // Parse the Data\n        d3.csv(\"stages.csv\", function(data) {\n        \n          var subgroups = data.columns.slice(1)\n        \n          var groups = d3.map(data, function(d){return(d.group)}).keys()\n        \n          // Add X axis, and hide it\n          var x = d3.scaleBand()\n              .domain(groups)\n              .range([0, width_stages])\n              .padding([0.2])\n          svg.append(\"g\")\n            .style(\"display\",\"none\")\n            .attr(\"transform\", \"translate(0,\" + height_stages + \")\")\n            .call(d3.axisBottom(x).tickSizeOuter(0));\n        \n          // Add Y axis, and hide it\n          var y = d3.scaleLinear()\n            .domain([0, 105])\n            .range([ height_stages, 0 ])\n          svg.append(\"g\")\n            .style(\"display\",\"none\")\n            .call(d3.axisLeft(y));\n        \n          var color = d3.scaleLinear()\n            .domain([0,2,5])\n            .range(['#202022','#3f4d63','#c6ccd8'])\n        \n          var stackedData = d3.stack()\n            .keys(subgroups)\n            (data)\n        \n          // Show the bars\n        var chart =  svg.append(\"g\")\n            .selectAll(\"g\")\n            .data(stackedData)\n            .enter().append(\"g\")\n              .attr(\"fill\", function(d) { return color(d.index); })\n              .selectAll(\"rect\")\n              .data(function(d) { return d; })\n              .enter().append(\"rect\")\n                .attr(\"x\", function(d) { return x(d.data.group); })\n                .attr(\"y\", function(d) { return y(d[1]); })\n                .attr(\"height\", function(d) { return y(d[0]) - y(d[1]); })\n                .attr(\"width\",100)\n        \n        // Creates the text elements for percentage on the stacked bar chart\n        svg\n            .selectAll(\"text.perc\")\n            .data(stackedData)\n                .enter()\n                .append(\"text\")\n                .attr(\"class\",\"perc\")\n                .attr(\"text-anchor\",\"middle\")\n                .text((d)=> d[0].data[d.key]+\"%\")\n                .attr(\"x\", function(d) { return x(d[0].data.group) + 52 })\n                .attr(\"y\", function(d) { return y((d[0][1] + d[0][0])/2) + 5})\n                .style(\"fill\", \"white\")\n        \n        // Creates the text elements for titles on the right\n        svg\n            .selectAll(\"text.title\")\n            .data(stackedData)\n                .enter()\n                .append(\"text\")\n                .attr(\"class\",\"title\")\n                .attr(\"text-anchor\",\"start\")\n                .text((d) => title_data_stages[d.key])\n                .attr(\"x\", function(d) {return x(d[0].data.group) + 109 })\n                .attr(\"y\", function(d) { return y(d[0][1]) + 16 })\n                .style(\"fill\", \"black\")\n                .style(\"font-weight\",600)\n                .style(\"font-family\",\"Tahoma\")\n                .style(\"font-size\",\"12px\")\n        \n        // Creates the text elements for descriptions on the right\n        svg.selectAll(\"text.desc\")\n            .data(stackedData)\n                .enter()\n                .append(\"text\")\n                .attr(\"class\",\"desc\")\n                .attr(\"text-anchor\",\"start\")\n                .text((d) => desc_data_stages[d.key])\n                .attr(\"x\", function(d) { return (x(d[0].data.group) + 110)})\n                .attr(\"y\", function(d)  { return ( y(d[0][1]) + 30)})\n                .style(\"color\", \"#4d4d4d\")\n                .style(\"line-height\", 1)\n                .style(\"font-family\", \"Tahoma\")\n                .style(\"font-size\", \"11px\")\n        })\n});\n'''\n\nh = display(HTML(htmlt1))\n\nj = IPython.display.Javascript(js_t1)\nIPython.display.display_javascript(j)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A surprising observation is that a **significant amount of time goes into loading and cleaning data**(45% of total time). This is a real eye opener because a lot of students will neglect this integral part of data handling and instead focus solely on the more trending machine learning side of things which only comprises 23% of the work.\n\nPerhaps **automated tools** might also help to reduce the massive chunk of data professionals' time that is sunk into the manual task of loading and cleaning the data, allowing them to focus on the more challenging data science work."},{"metadata":{},"cell_type":"markdown","source":"## <div class=\"subsection_title\">2.4 Data roles in different fields</div>\n<a id='roles'></a>\nOne thing I always wondered with all these different roles, what exactly do they work on, on a day-to-day basis - It can't all be the same regardless of the job title right?\n\nAnother question that has always bothered me(and I'm sure many of you too) - \"**What's the difference between the roles data scientist, data engineer, data analyst and business analyst?**\" Lets see if we can answer this in the following graph of data roles.\n\n<div class=\"sidenote\">\n    Source: Kaggle 2020 DS and ML Survey - <span style=\"font-style: italic;\">Q23. Select any activities that make up an important part of your role at work.</span>\n</div>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Create a dataframe that will store value_counts for each field's roles\nfield_df = pd.DataFrame()\navg_roles = dict()\n\nfield_data = df[df[q23_all[0:7]].isnull().sum(axis=1)!=len(q23_all[0:7])]\ndf_q23 = df[df[q23].isnull().sum(axis=1) != len(q23)]\n\nfor field in fields:\n    temp_df = field_data[field_data[\"Q5\"]==field]\n    field_df[field] = temp_df[q23_all[:7]].count()/temp_df[q23_all[:7]].shape[0]\n    avg_roles[field]= (temp_df[q23_all[:7]].count(axis=1).mean())\n    \nfield_df.drop(\"Other\", axis=1, inplace=True)\n\n# shortened version of labels\nlabels = [\n    'Analyze data for business decisions',\n    'Build the data infrastructure',\n    'Build ML prototypes in new areas',\n    'Build ML services for products/workflows',\n    'Improving existing ML models',\n    'Research to advance ML',\n    'None']\n\ntraces = dict()\n\ncommon_trace = go.Bar(\n    # Since we want to show even \"None\" we use df_q23 instead of dataprofs\n    x = df_q23[q23[:-1]].notnull().sum() / df_q23.shape[0],\n    y = labels,\n    marker = dict(color=\"#d7d7d7\", opacity=0.3),\n    orientation = \"h\"\n    )\n\nfor field in field_df.columns:\n    # Used to create the colours list to highlight max 2 columns\n    colors_list = [primary_grey]* field_df.shape[0]\n    max_indexes = np.argsort(-field_df[field])\n    colors_list[max_indexes[0]] = primary_blue\n    colors_list[max_indexes[1]] = primary_blue2\n    \n    trace = go.Bar(\n    x = field_df[field],\n    y = labels,\n    marker = dict(color= colors_list), #highlights max column\n    text = np.round(field_df[field]*100),\n    texttemplate = [\"<b style='color: #fff'>%{text}%</b>\"]*6 + [\"<b style='color: #444444'>%{text}%</b>\"],\n    textposition = [\"inside\"]*6 + [\"outside\"],\n    name = field,\n    orientation = \"h\",\n    hoverinfo = \"none\"\n    )\n    traces[field] = trace\n\nfig = subplots.make_subplots(\n    rows=5, \n    cols=2, \n    shared_yaxes=True, \n    shared_xaxes=True, \n    horizontal_spacing = 0.02, \n    vertical_spacing = 0.05 )\n\nfig.append_trace(traces[\"Data Scientist\"],1,1);            fig.append_trace(traces[\"Data Analyst\"],1,2); \nfig.append_trace(traces[\"Data Engineer\"],2,1);             fig.append_trace(traces[\"Business Analyst\"],2,2);\nfig.append_trace(traces[\"Statistician\"],3,1);              fig.append_trace(traces[\"Research Scientist\"],3,2);\nfig.append_trace(traces[\"Machine Learning Engineer\"],4,1); fig.append_trace(traces[\"Product/Project Manager\"],4,2);\nfig.append_trace(traces[\"DBA/Database Engineer\"],5,1);     fig.append_trace(traces[\"Software Engineer\"],5,2);\n\nlarge_title_format = \"<span style='font-size:36px; font-family:Times New Roman'>Data Roles in Different Fields</span>\"\nsmall_title_format = \"<span style='font-size:14px; font-family:Helvetica'>  The length of the bars denotes the <b>percentage of professionals in the field that perform the specified activity</b>.</span>\"\n\nlayout = dict(\n    title = large_title_format + \"<br>\" + small_title_format,\n    showlegend = False,\n    margin = dict(t=150,pad=6),\n    plot_bgcolor='#fff',\n    xaxis9 ={'showticklabels':False},\n    xaxis10={'showticklabels':False},\n    yaxis={'categoryorder':'array',\n           'categoryarray': labels[::-1], 'zeroline':True, 'zerolinecolor':'#4d4d4d'},\n    yaxis3={'categoryorder':'array',\n           'categoryarray': labels[::-1]},\n    yaxis5={'categoryorder':'array',\n           'categoryarray': labels[::-1]},\n    yaxis7={'categoryorder':'array',\n           'categoryarray': labels[::-1]},\n    yaxis9={'categoryorder':'array',\n           'categoryarray': labels[::-1]},\n    bargap = 0.05,\n    height = 1300,\n    width = 850\n)\n# Y positions for the annotations\nannot_y = [1.033, 0.823, 0.597, 0.388, 0.162]\n\n#Adding subplot titles and average roles annotations\nfor index in range(len(field_df.columns)):\n    field = fig[\"data\"][index][\"name\"]\n    \n    fig.add_annotation(dict(\n                            x=0.4,\n                            y=annot_y[index//2],\n                            showarrow=False,\n                            text='<span style=\"font-size:13px; font-family:Helvetica\"><b>%s:</b><br>avg. roles: %s</span>' % (field,np.round(avg_roles[field],2)),\n                            textangle=0,\n                            xref=\"x\"+str((index % 2)+1),\n                            yref=\"paper\"\n                           ))\n\nfig['layout'].update(layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As for the answer to our previous question:\n- For all the four titles(first 4 bar charts), the **main focus remains analysing data for business decisions**.\n- **Data analysts and Business Analysts seem to be almost identical** with respect to the role distribution and average number of roles per individual.\n- Data engineers seem to be similar to the others, except for their significant **focus on building infrastructure for the data management and analysis**.\n- Finally data scientists also have a higher focus on building ML prototypes in a new areas as well as have a relatively higher number of roles on average. Both these traits make it **very similar to Machine Learning Engineers**(except for the focus on impacting business decisions). \n\nAnother interesting detail is machine learning engineers, true to their name, show higher numbers across the board for all the ML related roles. Even their work in research on state of the art ML methods, is only second to research scientists themselves."},{"metadata":{},"cell_type":"markdown","source":"## <div class=\"subsection_title\">2.5 Ages of data professionals</div>\n\nLets see if the age data will produce any interesting findings. \n\n<div class=\"sidenote\">\n    Source: Kaggle 2020 DS and ML Survey - <span style=\"font-style: italic;\">Q1. What is your age (# years)?</span>\n</div>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Creating df for students\nstudents = df[df[\"Q5\"]==\"Student\"]\n\nstudent_ages = students[\"Q1\"].value_counts()\ndataprof_ages = dataprofs[\"Q1\"].value_counts()\n\ntrace1 = go.Bar(\n    x = student_ages.keys(),\n    y = student_ages.values,\n    name = \"Students\",\n    marker_color = primary_blue,\n    text = student_ages[student_ages.keys()],\n    textposition = \"outside\",\n#     width = 0.6\n)\n\ntrace2 = go.Bar(\n    x = student_ages.keys(),\n    y = - dataprof_ages[student_ages.keys()],\n    name = \"Data Professionals\",\n    marker_color = primary_grey,\n    text = dataprof_ages[student_ages.keys()],\n    textposition = \"outside\",\n)\n\n\nlayout = dict(\n    title = \"<span style='font-size:36px; font-family:Times New Roman'>Study of age groups</span>\",\n    plot_bgcolor='#fff',\n    margin = dict(t=50, l=0, r=0),\n    legend=dict(title=\"  Color Key:\", yanchor='top',xanchor='right', x=0.86, y=0.7, font=dict(family=\"Tahoma\", size= 14),traceorder='normal', bordercolor=\"#4d4d4d\", borderwidth=0.5),\n    xaxis = dict(domain=[0,1]),\n    yaxis = dict(showticklabels = False, zeroline=True, zerolinecolor=\"#4d4d4d\", zerolinewidth=0.5, showgrid=False),\n    barmode=\"overlay\",\n    bargap = 0.1,\n    width = 765\n)\n\ndata = [trace1, trace2]\nfig = go.Figure(data = data, layout = layout)\n\nfig['layout'].update(layout)\n\n# Adding anotations\n\nfig.add_annotation(dict(\n        x=0.3,\n        y=student_ages.values[0] - 200,\n        text=\"<b>students in the early phases of<br>education</b>: 70%  of  respondents<br>in this age group  have bachelor's <br> degrees.\",\n        ax=\"38\",\n        ay=\"-50\",\n        showarrow = True,\n        arrowhead = 7,\n        arrowwidth = 0.7\n    \n))\nfig.add_annotation(dict(\n        x=0.75,\n        y=-dataprof_ages[student_ages.keys()][1] + 180,\n        text=\"Most students <b>pursue their masters <br> in this age group</b>, evidenced by the <br> fact that 45% here have one\",\n        ax=\"0\",\n        ay=\"100\",\n        showarrow = True,\n        arrowhead = 7,\n        arrowwidth = 0.7\n))\nfig.add_annotation(dict(\n        x=4.3,\n        y=-dataprof_ages[student_ages.keys()][4]+ 40,\n        text=\"Unlike the other fields that peak in the 25-29<br>age group, <b>Product Managers  have their <br>highest  numbers  in  later  age  groups.</b>\",\n        ax=\"225\",\n        ay=\"50\",\n        showarrow = True,\n        arrowhead = 7,\n        arrowwidth = 0.7\n))\n\n# Rectangle to highlight range\nfig.add_vrect(x0=2.53, x1=5.52,\n              fillcolor=\"#e9cf87\",\n              layer=\"below\", \n              opacity=0.25, \n              line_width=0\n)\n\nfig.add_annotation(dict(\n        x=4.03,\n        y=student_ages[student_ages.keys()][1],\n        text=\"The age group 30-45 accounts<br>for <b>almost  60%  of all        <br>doctoral degree holders.    </b>\",\n        showarrow = False\n))\n\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some interesting points to note:\n- 70% of students in the age group 18-21 are **pursuing a Bachelor's degree**.\n- In the **22-24 age group, the focus shifts towards Masters**, having a marked jump from 11% to 45% in this age group. Meanwhile the percentage of Bachelors degree holders drops to below 40% for the first time.\n- In later age, groups the proportion Masters still remains around the 40-60% mark, with Doctoral degrees as a close second, while the numbers for bachelors slowly decreases.\n- On the data professional side of things, we see that most fields have a **majority of their respondents in the 25-29 age group**. \n- The **sole exception to this is Project Managers, which peaks at 35-39**. Most likely because these are positions you would only enter after a fair deal of experience. This also helps explain their relatively higher pays that we noted in the previous section."},{"metadata":{},"cell_type":"markdown","source":"## <div class=\"subsection_title\">2.6 Education required</div>\n\nWith all the disciplines that go into data analysis and machine learning, I always wondered what education qualifications were the norm in these professions and possibly what education I should pursue to thrive in these areas. Let's see how the fields stack up in terms of their educational make-up.\n\n<div class=\"sidenote\">\n    Source: Kaggle 2020 DS and ML Survey - <span style=\"font-style: italic;\">Q4. What is the highest level of formal education that you have attained or plan to attain within the next 2 years?</span>\n</div>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Education levels of professionals by field\n\n# df containing percentage distribution of education levels by field\neducation_df = pd.DataFrame()\n\nfor field in fields:\n    education_df[field] = dataprofs[dataprofs[\"Q5\"]==field][\"Q4\"].value_counts()\n     \neducation_df.dropna(inplace = True)\neducation_df = education_df/education_df.sum()\n\n# Adding spacing and formatting directly to the column names.\neducation_df.columns = [(\"<span style='font-size:14px; font-family:Helvetica'>\"+label + \"</span>  \") for label in education_df.columns]\n\n# plotting stacked bar charts\ntrace1 = go.Bar(\n    y = education_df.columns,\n    x = education_df.loc[\"Doctoral degree\"],\n    name = \"Doctoral Degree\",\n    marker = dict(color= f1),#\"#a2885e\"\n    orientation = \"h\"\n)\n\ntrace2 = go.Bar(\n    y = education_df.columns,\n    x = education_df.loc[\"Master’s degree\"],\n    orientation = \"h\",\n    marker = dict(color= f2), #\"#e9cf87\"\n    name = \"Master's degree\"\n)\n\ntrace3 = go.Bar(\n    y = education_df.columns,\n    x = education_df.loc[\"Professional degree\"],\n    marker = dict(color= f3), #\"#f1efd9\"\n    name = \"Professional degree\",\n    orientation = \"h\"    \n)\n\ntrace4 = go.Bar(\n    y = education_df.columns,\n    x = education_df.loc[\"Bachelor’s degree\"],\n    name = \"Bachelor's degree\",\n    marker = dict(color= f4), #\"#8eb3aa\"\n    orientation = \"h\"\n)\n\ntrace5 = go.Bar(\n    y = education_df.columns,\n    x = education_df.loc[\"Some college/university study without earning a bachelor’s degree\"],\n    name = \"Education without a degree\",\n    marker = dict(color= f5), #\"#235f83\"\n    orientation = \"h\"\n)\n\ntrace6 = go.Bar(\n    y = education_df.columns,\n    x = education_df.loc[\"No formal education past high school\"],\n    name = \"No formal education past high school\",\n    orientation = \"h\",\n    marker = dict(color= primary_blue3), #\"#b4cde3\"\n)\n\nlarge_title_format = \"<span style='font-size:30px; font-family:Times New Roman'>What educational qualifications do I need?</span>\"\nsmall_title_format = \"<span style='font-size:13px; font-family:Tahoma'><b>Master's and Bachelor's degrees form the majority of all fields</b>. The case of Research Scientists<br>however, is an exception  where a <b>doctoral degree</b> is a common pursuit, with 525 doctoral degrees<br>out of 1044 candidates - the most in any field.</span>\"\n\nlayout = dict(\n    title = dict(text = large_title_format + \"<br><br>\" + small_title_format,x=0.5, y=0.963),\n    margin = dict(t=150, l=0,b=0),\n    xaxis = dict(title=\"<span style='font-size:13px; font-family:Helvetica'><b>Color Key: </b>Educational qualifications of professionals</span>\", side=\"top\",title_standoff=0, domain=[0,0.95], showticklabels = False),\n    xaxis2 = dict(domain=[0,1], tickformat = '%'),\n    yaxis = dict(domain=[0.85,1], showticklabels = False),\n    yaxis2={'categoryorder':'array',\n           'categoryarray': education_df.loc[\"Doctoral degree\"].sort_values(ascending=True).keys(),\n            'domain':[0,0.83]\n           },\n    barmode = \"stack\",\n    bargap = 0.05,\n    showlegend = False,\n    width = 700,\n    height = 600,\n    plot_bgcolor = \"#fff\"\n)\n\n# Adding a separate subplot that will act as a color key\ncolorscale = ff.create_annotated_heatmap(\n    z=[[1,2,3,4,5,6]],\n        annotation_text =[[\"<span style='font-size:12px; font-family: Tahoma'>\"+text+\"</span>\" for text in [\"Doctoral<br>degree\",\"Master's<br>degree\",\"Professional<br>degree\",\"Bachelor's<br>degree\",\"Education<br>without<br>degree\",\"High school<br>education\"]]],\n    colorscale= [\n        [0.000,\"#a2885e\"],[0.166,\"#a2885e\"],\n        [0.166,\"#e9cf87\"],[0.333,\"#e9cf87\"],\n        [0.333,\"#f1efd9\"],[0.500,\"#f1efd9\"],\n        [0.500,\"#8eb3aa\"],[0.666,\"#8eb3aa\"],\n        [0.666,\"#235f83\"],[0.833,\"#235f83\"],\n        [0.833,primary_blue3],[1.000,primary_blue3],\n    ],\n    font_colors = [\"white\", \"white\", \"black\", \"white\", \"white\", \"white\"],\n    xgap = 1.5,\n    showscale = False\n)\n\n\ndata = [trace1, trace2, trace3, trace4, trace5, trace6]\n\nfig = subplots.make_subplots(\n    rows=2, \n    cols=1, \n    shared_yaxes=True, \n    shared_xaxes=False, \n    horizontal_spacing = 0.02, \n    vertical_spacing = 0.01\n)\n\nfig.append_trace(colorscale.data[0],1,1); \n\nfig.append_trace(trace1,2,1); \nfig.append_trace(trace2,2,1); \nfig.append_trace(trace3,2,1); \nfig.append_trace(trace4,2,1); \nfig.append_trace(trace5,2,1); \nfig.append_trace(trace6,2,1);\n\n# Workaround to show annotations with ff.create_annotated_heatmap() subplots.\nannot1 = list(colorscale.layout.annotations)\nfor k in range(len(annot1)):\n    annot1[k]['xref'] = 'x'\n    annot1[k]['yref'] = 'y'\nfig.update_layout(annotations=annot1) \n\n\nfig.update_layout(layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The general trend seems to be that more than half of the individuals in each field seem to have either a **Master's or Bachelor's degree** in almost all fields. A notable exception being Research Scientists where more than half the respondents have doctoral degrees and when you include Masters and Professional degree holders this number comprises of 93% of the total professionals in their field.\n\nSome additional points of interest:\n- In most fields **Masters degree seems to be the way to go** with 30-55% of respondents having one.\n- A **bachelors degree** seems to be a close second with numbers around the 20-30% mark.\n- **Professional degrees** seem to be a less common choice with around 4-5% having one. Hovewer they do help to get jobs because professional degree holders have the **second lowest fraction of unemployed individuals**, after Doctoral degree holders."},{"metadata":{},"cell_type":"markdown","source":"## <div class=\"subsection_title\">2.7.1 Handling Regional bias in pays</div>\n\nSalaries aren't really comparable by simply converting to USD and then drawing conclusions from this data. A major factor in this is the **cost of living** in different countries - Companies situated in places where costs of living are higher pay their employees more to compensate for this. A simple example would be how 100$ would have **different purchasing power in different places**.\n\nI'll handle this disparity by dividing each respondents salary by their **country's cost of living index** and then converting this value to an equivalent amount in USD. A simple demonstration of how this affects reported salaries is shown below\n\n<div class=\"sidenote\">\n    Source: Countries Dataset 2020 - <span style=\"font-style: italic;\">Numbeo: Cost of living index</span>\n</div>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Map to convert bins to mid point amount.\nearnings_map ={\n '$0-999': 500,\n '100,000-124,999': 112500,\n '10,000-14,999': 12500,\n '1,000-1,999': 1500,\n '40,000-49,999': 45000,\n '30,000-39,999': 35000,\n '50,000-59,999': 55000,\n '5,000-7,499': 6250,\n '15,000-19,999': 17500,\n '70,000-79,999': 75000,\n '60,000-69,999': 65000,\n '20,000-24,999': 22500,\n '150,000-199,999': 175000,\n '7,500-9,999': 8650,\n '125,000-149,999': 137500,\n '2,000-2,999': 2500,\n '25,000-29,999': 27500,\n '90,000-99,999': 95000,\n '80,000-89,999': 85000,\n '4,000-4,999': 4500,\n '3,000-3,999': 3500,\n '200,000-249,999': 225000,\n '300,000-500,000': 400000,\n '250,000-299,999': 275000,\n '> $500,000': 600000\n}\n\n# Loading cost of living index data\ncol_path = \"/kaggle/input/countries-dataset-2020/Cost of living index by country 2020.csv\"\ncol = pd.read_csv(col_path)\n\ncol_index = col[[\"Country\",\"Cost of Living Index\"]] \n\n# We'll need this later to convert everything back to its USD equivalent\nUSA_coli = col_index[col_index[\"Country\"]== \"United States\"][\"Cost of Living Index\"].values[0]\n\n# Replacing the names which don't match across the two datasets\ndataprofs_with_salary = dataprofs.replace(\"United States of America\",\"United States\")\ndataprofs_with_salary = dataprofs_with_salary.replace(\"Viet Nam\",\"Vietnam\")\ndataprofs_with_salary = dataprofs_with_salary.replace(\"Republic of Korea\",\"South Korea\")\ndataprofs_with_salary = dataprofs_with_salary.replace(\"United Kingdom of Great Britain and Northern Ireland\",\"United Kingdom\")\ndataprofs_with_salary = dataprofs_with_salary.replace(\"Iran, Islamic Republic of...\",\"Iran\")\n\n# Merge on countries and drop all professionals that haven't reported any salary\ndataprofs_with_salary = pd.merge(dataprofs_with_salary,col_index, left_on=\"Q3\", right_on=\"Country\")\ndataprofs_with_salary = dataprofs_with_salary.dropna(axis=0, subset=[\"Q24\"])\n\n# amount - bins converted to a dollar amount, norm - amount / cost of living index, norm_US equivalent amount in USD\ndataprofs_with_salary[\"Q24_amount\"] = [earnings_map[row] for row in dataprofs_with_salary[\"Q24\"].values]\ndataprofs_with_salary[\"Q24_norm\"] = dataprofs_with_salary[\"Q24_amount\"]/dataprofs_with_salary[\"Cost of Living Index\"]\ndataprofs_with_salary[\"Q24_norm_US\"] = dataprofs_with_salary[\"Q24_norm\"] * USA_coli\n\n# Creating dfs for the example\nsalary_eg_india = dataprofs_with_salary[dataprofs_with_salary[\"Q3\"]==\"India\"]\nsalary_eg_us = dataprofs_with_salary[dataprofs_with_salary[\"Q3\"]==\"United States\"]\n\nfield_avg_pays_ind = pd.DataFrame()\n\nfor field in fields:\n    field_avg_pays_ind[field] = [dataprofs_with_salary[(dataprofs_with_salary[\"Q3\"]==\"India\") & (dataprofs_with_salary[\"Q5\"]==field)][\"Q24_amount\"].mean(),\n                                 dataprofs_with_salary[(dataprofs_with_salary[\"Q3\"]==\"India\") & (dataprofs_with_salary[\"Q5\"]==field)][\"Q24_norm_US\"].mean()\n                            ]\n\nfield_avg_pays_ind.index = [\"original\",\"normalised\"]\nfield_avg_pays_ind = field_avg_pays_ind.T\n\nfield_avg_pays_us = pd.DataFrame()\n\nfor field in fields:\n    field_avg_pays_us[field] = [dataprofs_with_salary[(dataprofs_with_salary[\"Q3\"]==\"United States\") & (dataprofs_with_salary[\"Q5\"]==field)][\"Q24_amount\"].mean(),\n                                 dataprofs_with_salary[(dataprofs_with_salary[\"Q3\"]==\"United States\") & (dataprofs_with_salary[\"Q5\"]==field)][\"Q24_norm_US\"].mean()\n                            ]\n\nfield_avg_pays_us.index = [\"original\",\"normalised\"]\nfield_avg_pays_us = field_avg_pays_us.T\n\n# Binning amounts\nbins = [0,2500,10000,25000,50000,100000,250000,500000, 1000000]\n\nsalary_eg_india[\"amount_bins\"] = pd.cut(salary_eg_india[\"Q24_amount\"], bins)\nsalary_eg_india[\"norm_US_bins\"] = pd.cut(salary_eg_india[\"Q24_norm_US\"], bins)\nsalary_eg_us[\"amount_bins\"] = pd.cut(salary_eg_us[\"Q24_amount\"], bins)\n\norder = [str(interval.left)+\"-<br>\"+str(interval.right) for interval in np.sort(salary_eg_india[\"amount_bins\"].unique())]\n\n# Creating graph\ntrace1 = go.Bar(\n    y = salary_eg_india[\"amount_bins\"].value_counts(),\n    x = [str(interval.left)+\"-<br>\"+str(interval.right) for interval in salary_eg_india[\"amount_bins\"].value_counts().index],\n    name = \"India - before\",\n    marker = dict(color = primary_grey),\n)\n\ntrace2 = go.Bar(\n    y = salary_eg_india[\"norm_US_bins\"].value_counts(),\n    x = [str(interval.left)+\"-<br>\"+str(interval.right) for interval in salary_eg_india[\"norm_US_bins\"].value_counts().index],\n    name = \"India - after\",\n    marker = dict(color = primary_blue2),\n)\n\ntrace3 = go.Bar(\n    y = salary_eg_us[\"amount_bins\"].value_counts(),\n    x = [str(interval.left)+\"-<br>\"+str(interval.right) for interval in salary_eg_us[\"amount_bins\"].value_counts().index],\n    name = \"USA\",\n    marker = dict(color = primary_blue),\n)\n\nlayout = dict(\n#     title = \n    margin = dict(l=0),\n    xaxis= dict(\n            categoryorder = 'array',\n            categoryarray = order,\n    ),\n    yaxis= dict(\n            domain=[0.55,1],\n            showgrid = False,\n            zeroline = True,\n            zerolinewidth = 1,\n            zerolinecolor = \"#4d4d4d\"\n    ),\n    xaxis2={'categoryorder':'array',\n           'categoryarray': order},\n    yaxis2= dict(\n            domain=[0,0.45],\n            showgrid = False,\n            zeroline = True,\n            zerolinewidth = 1,\n            zerolinecolor = \"#4d4d4d\"\n    ),\n    barmode = \"group\",\n    legend=dict(yanchor='top',xanchor='center',y=0.99,x=0.587,font=dict(family=\"Tahoma\",size= 12),traceorder='normal'),\n    plot_bgcolor = \"#fff\",\n    width = 800,\n    height=700,\n)\n\ntitle_format = \"<span style='font-size:20px; font-family:Times New Roman'>%s</span>\"\n\nfig = subplots.make_subplots(rows=2, cols=1, subplot_titles=[title_format % \"Before considering cost of living ($)\" + \" \"*70,title_format % \"After considering cost of living ($)\" + \" \"*70])\nfig.append_trace(trace1,1,1)\nfig.append_trace(trace3,1,1)\nfig.append_trace(trace2,2,1)\nfig.append_trace(trace3,2,1)\n\nfig.add_vrect(x0=3.5, x1=7.6,\n              xref = \"paper\",\n              yref = \"y2\",\n              fillcolor= \"#e9cf87\",\n              layer=\"below\", \n              opacity=0.25, \n              line_width=0\n)\n\n# Annotations section\n\nmain_annot_format = \"<span style='font-size:11px; font-family:Tahoma;'><b> %s </b><br> %s</span>\"\n\nfig.add_annotation(dict(\n        x=0.865,\n        y=0.75,\n        xref = \"paper\",\n        yref = \"paper\",\n        text= main_annot_format % (\"50,000 USD and upwards\",\n                                   \"\"\"Before taking  into  account  the cost<br>of living only  <b>10%</b>  of Indians make<br>more   than   50,000$,   much  lower<br>than the 59% shown by respondents<br>working in USA.\"\"\"),\n        ax=0, ay=0\n))\n\nfig.add_annotation(dict(\n        x=0.865,\n        y=0.22,\n        xref = \"paper\",\n        yref = \"paper\",\n        text= main_annot_format % (\"50,000 USD and upwards - <br>after normalising\",\n                                   \"\"\"The adjusted  salaries  in  India  bring <br>our  observations  more  in  line  with<br>those seen in the US, with <b>30%</b> now<br>making more than 50,000$.\"\"\"),\n        ax=0, ay=0\n))\n\nfig.add_annotation(dict(\n        x=0.180,\n        y=0.24,\n        xref = \"paper\",\n        yref = \"paper\",\n        text= main_annot_format % (\"Shift to higher pay ranges\",\n                                   \"\"\"There is  a  noticeable reduction<br>in the number of Indians in the<br>lower pay  ranges as compared<br>to the above graph.\"\"\"),\n        ax=0, ay=0\n))\n\nfig['layout'].update(layout)\n\n# Prevent USA from showing up twice in legend\nfig[\"data\"][3][\"showlegend\"] = False\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see how a country like India, where the cost of living is much lower than that of the US, has the majority of its individuals towards the lower end of the graph. However on normalising with the cost of living data, we see how a much larger portion of Indians enter the higher pay brackets. In fact the salaries in India are **almost tripled to get their corrected values**.\n\nWhile this won't be a 100% accurate it gives us a much **better basis on which we may compare salaries**. And in this case we would probably be safe to assume that  in general, companies in the US just do pay their data experts more."},{"metadata":{},"cell_type":"markdown","source":"## <div class=\"subsection_title\">2.7.2 Company size and Earnings</div>\n\nMaybe there might be a difference in these closely related fields based on where the sizes of the organisations. Perhaps certain roles might be more common than in certain organisation structures? Perhaps there is a marked pay difference between them?\n\nLet's see if we can answer these questions with the following illustration.\nNote that we will use the normalised US equivalents of each respondents pay here.\n<a id='company_size_earnings'></a>\n\n<div class=\"sidenote\">\n    Sources: Kaggle 2020 DS and ML Survey - \n    <span style=\"font-style: italic;\">\n      <ul>\n        <li> Q20. What is the size of the company where you are employed?</li>\n        <li> Q5. Select the title most similar to your current role (or most recent title if retired)</li>\n        <li> Q24. What is your current yearly compensation (approximate USD)? </li>\n      </ul>\n    </span>\n</div>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"companysize_labels_original = ['0-49 employees', '50-249 employees', '250-999 employees', '1000-9,999 employees', '10,000 or more employees']\n\n# dfs for count and salary data.\ncompany_count_data = dataprofs_with_salary.groupby([\"Q5\"])[\"Q20\"].value_counts()\ncompany_sal_data = np.round(dataprofs_with_salary.groupby([\"Q5\",\"Q20\"])[\"Q24_norm_US\"].mean())\n\ncount_sal_data_list = [] \nfor field in fields:\n    for cosize in companysize_labels_original:\n        count_sal_data_list.append([\n            cosize.split(\" emp\")[0],\n            field,\n            company_count_data[field][cosize],\n            np.int32(company_sal_data[field][cosize]),\n            company_count_data[field][cosize] * np.round(company_sal_data[field][cosize])\n        ])\n\ncount_sal_data_df = pd.DataFrame(count_sal_data_list, columns = [\"size\",\"field\",\"count\",\"sal\",\"prop\"])\n\n# Shortening some of the labels in the CSV \ncount_sal_data_df = count_sal_data_df.replace(\"Machine Learning Engineer\",\"ML Engineer\")\ncount_sal_data_df = count_sal_data_df.replace(\"Product/Project Manager\",\"Project Manager\")\n\n# Write out for use in D3\ncount_sal_data_df.to_csv(\"count_sal_data.csv\", index=False)\n\nhtmlt1 = '''\n<html lang=\"en\">\n\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Document</title>\n    <style>\n        .dv_count_sal{\n            border: 1px solid #d7d7d7;\n            width: 640px;\n            padding: 10px 15px;\n            box-shadow: 2px 2px 2px 1px rgba(0,0,0,0.3); \n            margin: auto;\n        }\n        button.count_sal_button{\n            height: unset;\n            width: unset;\n            position: static;\n            border-radius: 0;\n            font-size: 14px;\n            padding: 5px 10px;\n            color: #000;\n            background-color: #fff;\n            border: 1px solid #d7d7d7;\n        }\n        button.count_sal_button:hover{\n            border-radius: 0;\n            background-color: #d7d7d7;\n        }\n        button.count_sal_button:focus{\n            outline: none;\n            border-radius: 0;\n            background-color: #4d4d4d;\n            color: #fff;\n        }\n    </style>\n</head>\n\n<body>\n    <!-- Create a div where the graph will take place -->\n    <div class = \"dv_count_sal\">\n    <button class=\"count_sal_button\" value=\"count\">Count</button>    \n    <button class=\"count_sal_button\" value=\"salary\">Salary</button>\n    <button class=\"count_sal_button\" value=\"money\">Overall compensation</button>\n    <div class=\"count_sal_title\"> Title goes here </div>\n    <div class=\"count_sal_desc\"> Desc goes here </div>\n\n    <div id=\"dataviz_count_sal\"></div>\n    </div>\n</body>\n\n</html>\n'''\n\njs_t1 = '''\n         require.config({\n            paths: {\n                d3: \"https://d3js.org/d3.v4.min\"\n             }\n             });\n        require([\"d3\"], function(d3) {\n        \n        // Map for title data\n         var titleData = {\n            \"count\" : \"Counts of Professionals across company sizes\",\n            \"salary\": \"Compensation of Professionals across company sizes\",\n            \"money\" : \"Spending on Data Professionals\"\n        }\n        \n        // Map for description data\n        var descData = {\n            \"count\" : \"Data scientists form the bulk of our respondents. Working in more tight-knit companies with less than 50 employees is also common among data professionals.\",\n            \"salary\": \"In general larger companies tend to pay their data professionals more, with minor exceptions. In professions like Project Manager and DBA experience is greatly valued, resulting in higher pays (all amounts in USD).\",\n            \"money\" : \"A product of the previous two graphs, this graph gives us a sense of all the money these companies spend on data professionals, where is it concentrated? Well, of the 513B USD spent on data-related work, almost a third of it (137B USD) goes towards Data Scientists.\"\n        }\n\n        // set the dimensions and margins of the graph\n        var margin_count_sal = { top: 20, right: 0, bottom: 30, left: 95 },\n            width_count_sal = 610 - margin_count_sal.left - margin_count_sal.right,\n            height_count_sal = 500 - margin_count_sal.top - margin_count_sal.bottom;\n\n        // append the svg object to the body of the page\n        var svg = d3.select(\"#dataviz_count_sal\")\n            .append(\"svg\")\n            .attr(\"width\", width_count_sal + margin_count_sal.left + margin_count_sal.right)\n            .attr(\"height\", height_count_sal + margin_count_sal.top + margin_count_sal.bottom)\n            .append(\"g\")\n            .attr(\"transform\",\n                \"translate(\" + margin_count_sal.left + \",\" + margin_count_sal.top + \")\");\n\n        // Labels of row and columns\n        var xlabels = ['0-49 employees', '50-249 employees', '250-999 employees', '1000-9,999 employees', '10,000 or more employees']\n        var ylabels = ['Data Engineer', 'Data Scientist', 'Research Scientist', 'Statistician', 'Project Manager', 'Data Analyst', 'Software Engineer', 'ML Engineer', 'Other', 'Business Analyst', 'DBA/Database Engineer']\n\n        // Build X scales and axis:\n        var x = d3.scaleBand()\n            .range([0, width_count_sal])\n            .domain(xlabels)\n            .padding(0.01);\n\n        svg.append(\"g\")\n            .attr(\"transform\", \"translate(0,\" + height_count_sal + \")\")\n            .call(d3.axisBottom(x))\n            .style(\"font-size\",\"8px\")\n                \n\n        // Build X scales and axis:\n        var y = d3.scaleBand()\n            .range([height_count_sal, 0])\n            .domain(ylabels)\n            .padding(0.03);\n\n        svg.append(\"g\")\n            .call(d3.axisLeft(y))\n\n        // Build color scale\n        var myColor = d3.scaleLinear()\n            .range([\"#f5f5f5\", \"#29658c\"])\n            .domain([1, 216])\n\n        showData();\n        let buttons = d3.selectAll(\".dv_count_sal button\")\n\n        buttons\n            .on(\"click\", function(){\n                showData(this.value)\n            })\n\n        function showData(mode=\"count\"){\n                    d3.csv(\"count_sal_data.csv\", function (data) {\n                    \n                    function getValue(d){\n                        if(mode == \"count\") return +d.count\n                        else if(mode == \"salary\") return +d.sal\n                        else return +d.prop\n                    }\n\n                    d3.select(\".count_sal_title\")\n                        .text(titleData[mode])\n                        .style(\"position\",\"relative\")\n                        .style(\"left\",\"30px\")\n                        .style(\"font-family\",\"Times New Roman\")\n                        .style(\"font-size\", \"26px\")\n\n                    d3.select(\".count_sal_desc\")\n                        .text(descData[mode])\n                        .style(\"width\",\"560px\")\n                        .style(\"position\",\"relative\")\n                        .style(\"left\",\"30px\")\n                        .style(\"font-family\",\"Tahoma\")\n                        .style(\"font-size\", \"14px\")\n                        .style(\"color\",\"#4d4d4d\")\n                        .style(\"line-height\",\"normal\")\n                    \n                    var maxColor = d3.max(data, (d)=>{return getValue(d)})\n                    var minColor = d3.min(data, (d)=>{return getValue(d)})\n                    var myColor = d3.scaleLinear()\n                    .range([\"#f5f5f5\", \"#29658c\"])\n                    .domain([minColor, maxColor])\n                    \n                    // Draw rectangles for cells\n                    var u = svg.selectAll(\"rect\")\n                    .data(data)\n                    \n                    u\n                    .enter()\n                    .append(\"rect\")\n                    .merge(u)\n                    .transition()\n                    .duration(1000)\n                    .attr(\"x\", function (d) { return x(d.size + \" employees\")})\n                    .attr(\"y\", function (d) { return y(d.field) })\n                    .attr(\"width\", x.bandwidth())\n                    .attr(\"height\", y.bandwidth())\n                    .style(\"fill\", function (d) { if(d.count !==\"nan\"){return myColor(getValue(d));} return myColor(0);  })\n                    \n                    // Text labels for the cells\n                    var v = svg.selectAll(\"svg > g > text\")\n                    .data(data)\n\n                    v\n                    .enter()\n                    .append(\"text\")\n                    .merge(v)\n                    .transition()\n                    .duration(1000)\n                    .text( function (d) { if(getValue(d) !==\"nan\" && getValue(d) != 0){ return getValue(d).toString().replace(/\\B(?=(\\d{3})+(?!\\d))/g, \",\")} return \" \"; })\n                    .attr(\"x\", function (d) { return x(d.size + \" employees\")})\n                    .attr(\"y\", function (d) { return y(d.field) })\n                    .attr(\"text-anchor\",\"middle\")\n                    .attr(\"transform\",\"translate(55,26)\")\n                    .style(\"font-family\",\"Didot\")\n                    .style(\"font-size\",\"16px\")\n                    .style(\"fill\", function (d){if(getValue(d) > maxColor/2) { return \"#f5f5f5\"}; return \"black\";})\n        })\n    }\n\n});\n'''\n\nh = display(HTML(htmlt1))\n\nj = IPython.display.Javascript(js_t1)\nIPython.display.display_javascript(j)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**NOTE:** With earnings data split into bins in the dataset, I have considered the individual's earnings to be the midpoint of each bin for the purpose of averaging. Since this makes the data inaccurate, it is only meant to give a basic idea of how the pays differ across different fields and company sizes.\n\nWhile there is a lot to look at in the graph, some common themes seem to be:\n- The general distribution of experts across company sizes seems to **remain roughly the same for all fields**.\n- A **majority of them work in companies with 0-50 employees**, although their pay remains on the lower end of the scale.\n- **Larger companies tend to pay more** in general.\n- Companies seem to be **investing massive amounts in their data scientist** as compared to the other fields(as shown in the \"Overall compensation\" tab)."},{"metadata":{},"cell_type":"markdown","source":"## <div class=\"subsection_title\">2.8 Machine Learning practices</div>\n\nSo.. you want to work in machine learning? Well, lets give you a better idea of the type of ML-related work you might encounter in certain fields. \n\n<div class=\"sidenote\">\n    Sources: Kaggle 2020 DS and ML Survey - \n    <span style=\"font-style: italic;\"> Q22. Does your current employer incorporate machine learning methods into their business?\n    </span>\n</div>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Dataframe for Q22 by fields\ninc_labels = list(dataprofs[\"Q22\"].value_counts().index)\n\ninc_fields = pd.DataFrame()\n\nfor inc in inc_labels:\n    inc_fields[inc] = dataprofs[dataprofs[\"Q22\"]== inc][\"Q5\"].value_counts()\n    \ninc_fields.drop([\"I do not know\"],axis=1, inplace=True)\n    \ninc_fields = inc_fields.div(inc_fields.sum(axis=1),axis=0)\n\ninc_fields[\"total_prod\"] = inc_fields[inc_labels[1]] + inc_fields[inc_labels[2]]\n\ninc_fields = inc_fields.sort_values(\"total_prod\", ascending=False)\n\n# Draw graphs\n\ntrace3 = go.Bar(\n    y = inc_fields.index,\n    x = - inc_fields[inc_labels[3]],\n    name = \"Don't use ML methods\",\n    marker = dict( color = f1),\n    text = np.round(inc_fields[inc_labels[3]]*100),\n    texttemplate = [\"<b style='color: #4d4d4d'>%{text}%</b>\"]*3 +[\"<b style='color: #fff'> %{text}% </b>\"]*11,\n    textposition = [\"outside\"]*3 + [\"inside\"]*11,\n    orientation = \"h\",\n)\n\ntrace2 = go.Bar(\n    y = inc_fields.index,\n    x = inc_fields[inc_labels[4]],\n    name = \"Use ML for generating insights\",\n    marker = dict( color = f2),\n    orientation = \"h\",\n)\n\ntrace1 = go.Bar(\n    y = inc_fields.index,\n    x = inc_fields[inc_labels[0]] + inc_fields[inc_labels[4]],\n    name = \"Exploring ML methods\",\n    marker = dict( color = f3),\n    orientation = \"h\",\n)\n\ntrace5 = go.Bar(\n    y = inc_fields.index,\n    x = inc_fields[inc_labels[2]],\n    name = \"Models in production for < 2 years\",\n    marker = dict( color = primary_blue2),\n    orientation = \"h\",\n)\n\ntrace4 = go.Bar(\n    y = inc_fields.index,\n    x = inc_fields[\"total_prod\"],\n    name = \"Models in production for > 2 years\",\n    marker = dict( color = primary_grey),\n    text = np.round((inc_fields[\"total_prod\"])*100),\n    texttemplate = \"<b style='color: #4d4d4d;'> %{text}% </b>\",\n    textposition = \"inside\",\n    orientation = \"h\",\n)\n\nlayout = dict(\n    margin = dict(t=250),\n#     showlegend = False,\n    legend=dict(\n                yanchor='top',xanchor='center',\n                y= 1.45,\n                x=0.775,\n                font=dict(size= 12),\n                traceorder='normal',\n               ),\n    yaxis={'categoryorder':'array',\n            'categoryarray': inc_fields[\"total_prod\"].sort_values(ascending=True).keys(),\n            'linecolor':\"#777777\",\n            'linewidth' : 2\n           },\n    yaxis2={'categoryorder':'array',\n            'categoryarray': inc_fields[\"total_prod\"].sort_values(ascending=True).keys(),\n            'linecolor':\"#777777\",\n            'linewidth' : 2\n           },\n    xaxis=dict(side=\"top\",\n                domain = [0,0.41],\n                gridcolor = \"#d7d7d7\",\n                zeroline = True,\n                zerolinecolor = \"#d7d7d7\",\n                zerolinewidth = 3,\n                tickformat = \"%\",\n              ),           \n    xaxis2=dict(side=\"top\", \n                domain = [0.5,1],\n                gridcolor = \"#d7d7d7\",\n                tickformat = \"%\",\n               ),\n    width = 850,\n    height= 850,\n    plot_bgcolor = \"#fff\", # \"#f6f2e8\"\n    barmode = \"overlay\"\n)\n\nfig = subplots.make_subplots(rows=1, cols=2, shared_yaxes=True)\nfig.append_trace(trace3,1,1)\nfig.append_trace(trace1,1,1)\nfig.append_trace(trace2,1,1)\nfig.append_trace(trace4,1,2)\nfig.append_trace(trace5,1,2)\n\nfig['layout'].update(layout)\n\nmain_annot_format = \"<span style='font-size:11px; font-family:Tahoma;'><b> %s </b><br> %s</span>\"\n\n# Arrow -> production models\nfig.add_annotation(dict(\n        x=0.41,\n        y=1.045,\n        text=\"\",\n        ax=\"-130\",\n        ay=\"0\",\n        xref = \"paper\",\n        yref = \"paper\",        \n        showarrow = True,\n        arrowhead = 2,\n        arrowwidth = 0.9\n))\n\n# Annot - production models\nfig.add_annotation(dict(\n        x=0.95,\n        y=1.225,\n        text= main_annot_format % (\"Models in production\",\"These  companies  are  able  to  bring  their  machine<br>learning models to production. Once deployed, these<br>models will be actively  used  by consumers and will <br>have to scale to meet business requirements.           \"),\n        xref = \"paper\",\n        yref = \"paper\",\n        showarrow = False        \n))\n\n# Arrow -> not in prod\nfig.add_annotation(dict(\n        x=0.95,\n        y=1.045,\n        text=\"\",\n        ax=\"-270\",\n        ay=\"0\",\n        xref = \"paper\",\n        yref = \"paper\",        \n        showarrow = True,\n        arrowhead = 2,\n        arrowwidth = 0.9\n))\n\n# Annot - not in prod\nfig.add_annotation(dict(\n        x=0.140,\n        y=1.225,\n        text= main_annot_format % (\"Not in production\",\"Companies  in   the   early  stages  of<br>exploring the use of ML or those that<br>build models  for  their  own analysis<br>instead of deploying.                       \"),\n        xref = \"paper\",\n        yref = \"paper\",\n        showarrow = False\n        \n))\n\n# Arrow <- no ml\nfig.add_annotation(dict(\n        x=-0.025,\n        y=1.045,\n        text=\"\",\n        ax=\"70\",\n        ay=\"0\",\n        xref = \"paper\",\n        yref = \"paper\",        \n        showarrow = True,\n        arrowhead = 2,\n        arrowwidth = 0.9\n))\n\n# Annot - no ml\nfig.add_annotation(dict(\n        x=-0.12,\n        y=1.225,\n        text= main_annot_format % (\"No ML usage\",\"These companies  do not<br>uitilise machine learning<br>in their daily  operations\"),\n        xref = \"paper\",\n        yref = \"paper\",\n        showarrow = False\n        \n))\n\n# Title Annotation\nlarge_title_format = \"<span style='font-size:50px; font-family:Times New Roman'> Machine Learning<br><br><br>Practices of Companies</span>\"\n\nfig.add_annotation(dict(\n        x=-0.27,\n        y=1.45,\n        text= large_title_format,\n        xref = \"paper\",\n        yref = \"paper\",\n        showarrow = False\n        \n))\n\niplot(fig)\n\n# Notes: ~ 4.5-5hrs on this one\n# Had to find a workaround for requiring both stacked and overlay barmodes in the same graph\n# Blank annotation texts for the arrows also worked out well","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In case you are unclear on what exactly \"production\" means I'll give you a little background here - Traditionally, when a data scientist would create an ML model they would often do so in a sandbox or development environment. This is **great for experimenting and reiterating quickly**, however in order for the consumers to use it, the model must be deployed so that it **scales well with increased usage volumes and is always available** for use by others. This deployment however, requires a skill-set different than what most data scientists possess and often this **burden falls on the Software Engineers**. \n\nIn order for a ML product to be put into production both teams must work closely and this cooperation is what a lot of companies dealing in ML products strive for. This back-and-forth forms the basis by which they manage to build and maintain well established ML models. (You can read more about this [here](https://stackoverflow.blog/2020/10/12/how-to-put-machine-learning-models-into-production/).)\n\nNow back to the graph - an interesting observation is how **Machine Learning Engineers** ranked second here in terms of well-established ML production practices, this is the exact situation where ML Engineers shine - they are a **mix of both Software Engineers and Data Scientists** whose main role is **to take machine learning models and make them scalable in production**.\n\nThe left-most bar also shows us what proportion of the companies don't utilise ML methods in their daily activities."},{"metadata":{},"cell_type":"markdown","source":"# <div class=\"section_title\">3. What should I focus on?</div>\n\nNow that we have a good idea of the different fields that work with data, lets take a deeper dive to understand what tools are commonly used and about trends in the industry. We will use the data professionals' responses to find out where we should focus our learning efforts."},{"metadata":{},"cell_type":"markdown","source":"## <div class=\"subsection_title\">3.1 The Skills Gap</div>\n<a id='skillsgap'></a>\nA lot of enterprises express that their recruits fresh out of their degree courses often lack certain fundamentals to seamlessly fit into the workplace. This may be attributed to their universities not prioritising certain key skills or perhaps due to the lack of initiative taken by the students in learning by themselves. In [Anaconda's State of Data Science Report 2020](https://www.anaconda.com/state-of-data-science-2020), respondents working in industry backgrounds were asked what were some of the essential skills that their newer recruits lacked. On the other side of things, students were even asked what they chose to study in preparation for their work.\n<div class=\"sidenote\">\n    Source: Anaconda's State of DS Report 2020 - \n    <span style=\"font-style: italic;\"> The Skills Gap\n    </span>\n</div>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Creating plotly tables with Anaconda data.\ntrace1 = go.Table(\n            columnwidth = [3,1],\n            header = dict(values=['What students learn'],                        \n                        line_color= primary_blue3,\n                        fill_color= primary_blue3,\n                        font_color= \"white\",\n                        font_size = 16,\n                        height = 30,\n                        align='left'),\n            cells = dict(values=[[\"Python\", \"Machine Learning\", \"Data visualisation\", \"Probability and statistics\",\"Deep learning\"], # 1st column\n                               [\"85%\", \"55%\", \"49%\", \"43%\", \"42%\"]], # 2nd column\n                        line_color='darkslategray',\n                        line_width=0.5,\n                        fill_color='white',\n                        font_size = 15,\n                        height = 28,\n                       align=['left','center'])\n        )\n\ntrace2 = go.Table(\n            columnwidth = [3,1],\n            header = dict(values=['Enterprises say they lack'],                        \n                        line_color= f1,\n                        line_width=0.5,\n                        fill_color= f1,\n                        font_color= \"white\",\n                        font_size = 16,\n                        height = 30,\n                        align='left'),\n            cells = dict(values=[[\"Big data management\", \"Advanced Mathematics\", \"Deep learning\", \"Engineering skills\",\"Machine learning\"], # 1st column\n                               [\"39%\", \"36%\", \"31%\", \"26%\", \"25%\"]], # 2nd column\n                        line_color='darkslategray',\n                        line_width=0.5,\n                        fill_color='white',\n                        font_size = 15,\n                        height = 28,\n                       align=['left','center'])\n        )\n\nlayout = dict(\n            margin = dict(t=0,b=0,l=0,r=10),\n            width = 750,\n            height= 180\n        )\n\nfig = subplots.make_subplots(\n                            rows=1, cols=2, shared_yaxes=True,\n                            specs=[[{\"type\": \"table\"},{\"type\": \"table\"}]],\n                            horizontal_spacing = 0.02\n                            )\nfig.add_trace(trace1,row=1,col=1)\nfig.add_trace(trace2,row=1,col=2)\n\nfig['layout'].update(layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"While these numbers are specifically for the field of data science, it does still give us an idea of where there is a disconnect between what the students learn and what is actually expected of them in the workplace. Some of the areas where students seem to be lacking are:\n* **Big data management:** When people talk about big data, one of the first things that come to a lot of peoples' mind is deep learning and how it leverages massive volumes of data to generate powerful models. Rarely does one think of big data management which actually encompasses the entire range of **policies, procedures and technologies that are utilised in the organization and administration of large repositories of data**. Often students will glaze over this part of data management because its one of the more mundane parts of the job.\n* **Deep Learning and Machine Learning:** Based on the specifics of the role, companies also place a lot of importance on the recruit having a good foundation in the **working of machine learning and deep learning algorithms** as well as a hands-on experience of **when to apply** these to specfic problems.\n* **Advanced Mathematics:** While admittedly there are slight variations on the exact content of \"advanced mathematics\", it is a safe bet that if one wants to work with data they should be **well-versed with the basics of algebra, statistics, calculus and trigonometry**, and must be comfortable to delve deeper into these topics should their work require it"},{"metadata":{},"cell_type":"markdown","source":"## <div class=\"subsection_title\">3.2 Development environments: IDEs and Hosted notebooks</div>\nLet us see if there are any note-worthy trends in terms of what tools data professionals use during their development work."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# List of questions\nq9 = [question for question in questions if 'Q9' in question]\n\n# Creating labels for plot\nides = []\nfor qn in q9:\n    for val in dataprofs[qn].unique():\n        ides.append(val)\n\nides = [str.strip(ide)+\"  \" for ide in ides if str(ide)!='nan']\n\n# Percentage data for plot\nide_percentages = ((dataprofs.shape[0] - dataprofs[q9].isnull().sum()))/dataprofs.shape[0]\nide_percentages.index = ides\n\n# Creating the bar chart\ntrace = go.Bar(\n    y = ides,\n    x = ide_percentages,\n    name = \"IDE usage\",\n    orientation = \"h\",\n    marker = dict(color = [primary_blue] + [primary_grey]*11),\n    text = np.round(ide_percentages*100),\n    texttemplate =  \"<b style='color: #fff'>%{text}% </b>\",\n    textposition = [\"inside\"]*10 + [\"outside\"] + [\"inside\"]\n)\n\n# title format\nlarge_title_format = \"<span style='font-size:36px; font-family:Times New Roman'> What IDEs are used?</span>\"\nsmall_title_format = \"<span style='font-size:14px; font-family:Helvetica'>       <b>Jupyter products</b>, like JupyterLab and Jupyter Notebooks seem to be the development environment of <br>       choice for data professionals. With most options having sizable audiences, it seems like the choice<br>       <b>comes down to personal preference.</b></span>\"\n\nlayout = dict(\n   title = large_title_format + \"<br><br>\" + small_title_format,\n    margin = dict(t=230),\n    yaxis={'categoryorder':'array',\n           'categoryarray': ide_percentages.sort_values(ascending=True).keys()\n          ,\n          },\n    xaxis=dict(side=\"top\", zerolinecolor = \"#4d4d4d\", zerolinewidth = 0.5, gridcolor=\"#e7e7e7\", tickformat=\"%\"),\n    width = 800,\n    height= 700,\n    plot_bgcolor = \"#fff\" # \"#f6f2e8\"\n)\n\nfig = go.Figure(data = trace, layout = layout)\n\nmain_annot_format = \"<span style='font-size:12px; font-family:Tahoma;'><b> %s </b><br> %s</span>\"\n\nfig.add_annotation(dict(\n        x=0.62,\n        y=0.4,\n        xref = \"paper\",\n        yref = \"paper\",\n        text= main_annot_format % (\"MORE THAN ONE IDE?\",\n                                   \"\"\"Individuals were not restricted to picking only <br>a single IDE in  this  survey  question. In fact, <br>from the responses, we learn that on average, <br>data professionals  are  comfortable  using <b>2+<br>IDEs</b> for  their development needs  on a daily<br>basis.\"\"\"),\n        ax=0, ay=0\n))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"sidenote\">\n    Source: Kaggle 2020 DS and ML Survey - \n    <span style=\"font-style: italic;\"> Q9. Which of the following integrated development environments (IDE's) do you use on a regular basis?\n    </span>\n</div>\n<br>\nWhile Jupyter products hold the top spot in this graph, most of the **other IDEs do share a sizable chunk of the audience**. One might even be tempted to experiment with language specific IDEs like PyCharm, RStudio, Spyder, MATLAB, etc, because of the greater amount of customisation and **language specific features** that might aid the development process."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# quicker one, ~45 mins on this graph \n\nq10 = [question for question in questions if 'Q10' in question]\n\nnbs = []\nfor qn in q10:\n    for val in dataprofs[qn].unique():\n        nbs.append(val)\n    \nnbs = [str.strip(nb) for nb in nbs if str(nb)!='nan']\n\nnbs_percentages = ((dataprofs.shape[0] - dataprofs[q10].isnull().sum())) / dataprofs.shape[0]\nnbs_percentages.index = nbs\n\nexcluded_nbs  = nbs_percentages.sort_values(ascending=False)[6:]\nnbs_percentages = nbs_percentages.sort_values(ascending=False)[:6]\nnbs_percentages[\"Other\"] = excluded_nbs.sum()\n\ntrace = go.Bar(\n    y = nbs_percentages.index,\n    x = nbs_percentages,\n    name = \"Hosted nb usage\",\n    orientation = \"h\",\n    marker = dict(color = [primary_blue]+ [primary_blue2] + [primary_grey]*6),\n    hoverinfo = \"none\",\n    text = np.round(nbs_percentages*100),\n    texttemplate =  \"<b style='color: #fff'>%{text}% </b>\",\n    textposition = \"inside\"\n)\n\nlarge_title_format = \"<span style='font-size:36px; font-family:Times New Roman'> Which hosted notebooks should I use?</span>\"\nsmall_title_format = \"<span style='font-size:14px; font-family:Helvetica'>        <b>Colab</b> followed by <b>Kaggle notebooks</b> seem to be the main choice for our professionals. With<br>        respondents being able to select multiple notebooks, the graph represents <b>the percentage of<br>        respondents that  are  experienced  with  that  notebook</b>  and  not the market share of that<br>        product, which is why these values dont sum to 100. </span>\"\n\nlayout = dict(\n   title = large_title_format + \"<br><br>\" + small_title_format,\n    margin = dict(t=290, pad=5),\n    yaxis={'categoryorder':'array',\n           'categoryarray': nbs_percentages.sort_values(ascending=True).keys()\n          ,\n          },\n    xaxis=dict(side=\"top\", zerolinecolor = \"#4d4d4d\", zerolinewidth = 1, gridcolor=\"#e7e7e7\",tickformat=\"%\"),\n    width = 800,\n    height= 700,\n    plot_bgcolor = \"#fff\" # \"#f6f2e8\"\n)\n\nfig = go.Figure(data = trace, layout = layout)\n\nmain_annot_format = \"<span style='font-size:12px; font-family:Tahoma;'><b> %s </b><br> %s</span>\"\n\nfig.add_annotation(dict(\n        x=0.65,\n        y=0.22,\n        xref = \"paper\",\n        yref = \"paper\",\n        text= main_annot_format % (\"Included in others:                                      \",\n                                   \"\"\"1. Azure Notebooks - 6.4%                           <br>2. IBM Watson Studio - 4.7%                       <br>3. Amazon Sagemaker Studio - 4.1%            <br>4. Databricks Collaborative Notebooks - 3.6%<br>5. Amazon EMR Notebooks - 1.8%               <br>6. Paperspace / Gradient - 1.1%                  <br>7. Code Ocean - 0.6%                                \"\"\"),\n        ax=0, ay=0\n))\n\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"sidenote\">\n    Source: Kaggle 2020 DS and ML Survey - \n    <span style=\"font-style: italic;\"> Q10. Which of the following hosted notebook products do you use on a regular basis?\n    </span>\n</div>\n<br>\nHosted notebooks provide us access to a hassle free environment in which we may collaborate and share our results with others. For example, even though I dont have R installed on my system, Kaggle will happily let me open up an R notebook and start coding immediately without any setup on my side. \n\nAmong those that do use hosted notebooks **Colab and Kaggle notebooks are the top two choices**. With 28% of individuals responding that they dont any hosted notebooks, we understand that **not all roles require their use**."},{"metadata":{},"cell_type":"markdown","source":"## <div class=\"subsection_title\">3.3 How much coding experience do I need?</div>\n<a id='coding_experience'></a>\nAnother interesting question to ask is **how much coding experience do I need to start out** in these fields?\nNow, I could just plot the fields vs the average coding experience of its professionals, but this doesn't account for the experience they gained during the course of their career.\nSo it might be more fitting to plot a heatmap of their coding experience against their age, so we know how experienced individuals are at particular age groups in the field.\n\nAlso I'm sure many of you have specfic fields that you may be interested in, so feel free to **use the buttons to view how the numbers differ across fields**. \n\n<div class=\"sidenote\">\n    Source: Kaggle 2020 DS and ML Survey - \n    <span style=\"font-style: italic;\"> Q6. For how many years have you been writing code and/or programming?\n    </span>\n</div>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# NOTE: This cell at times, needs to be run multiple times before the output shows \n# EDIT: works fine now that I removed the script tag that included the d3.js dependency\n\n# Creating the df for d3\nexperience_labels = ['I have never written code', '< 1 years', '1-2 years', '3-5 years','5-10 years', '10-20 years', '20+ years']\n\nexpdata_list = []\nmax = 0\n\nexperience_age_heatmap = pd.DataFrame()\n\nfor agegroup in student_ages.keys():\n    experience_age_heatmap[agegroup] = dataprofs[dataprofs[\"Q1\"]==agegroup][\"Q6\"].value_counts().reindex(experience_labels)\n\nexpdata = experience_age_heatmap.values\n\nfor row in range(expdata.shape[0]):\n    for col in range(expdata.shape[1]):\n        expdata_list.append([experience_labels[row],student_ages.keys()[col],expdata[row][col],\"all\"])\n        \nfor field in fields:\n    for agegroup in student_ages.keys():\n        experience_age_heatmap[agegroup] = dataprofs[(dataprofs[\"Q1\"]==agegroup) & (dataprofs[\"Q5\"]==field)][\"Q6\"].value_counts().reindex(experience_labels)\n\n    expdata = experience_age_heatmap.values\n\n    for row in range(expdata.shape[0]):\n        for col in range(expdata.shape[1]):\n            expdata_list.append([experience_labels[row],student_ages.keys()[col],expdata[row][col],field])\n            \nexpdata_df = pd.DataFrame(expdata_list,columns=['group', 'variable', 'value', 'field'])\nexpdata_df[\"group\"] = [\"'\"+data+\"'\" for data in expdata_df[\"group\"]]\nexpdata_df[\"variable\"] = [\"'\"+data+\"'\" for data in expdata_df[\"variable\"]]\nexpdata_df[\"field\"] = [\"'\"+data+\"'\" for data in expdata_df[\"field\"]]\n\nexpdata_df.to_csv(\"experience_heatmap.csv\", index=False)\n\n# Creating the graph\nhtmlt1 = '''\n<!DOCTYPE html>\n<html lang=\"en\">\n\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Document</title>\n    <style>\n        .dv1{\n            border: 1px solid #d7d7d7;\n            width: 700px;\n            height: 1000px\n            padding: 10px 15px;\n            box-shadow: 2px 2px 2px 1px rgba(0,0,0,0.3); \n        }\n        .btns{\n            margin-left: 10px;\n            margin-top: 10px;\n        }\n        .btns button{\n            width: 167px;\n            position: static;\n            border-radius: 0;\n            font-size: 12px;\n            padding: 3px 6px;\n            color: #000;\n            background-color: #fff;\n            border: 1px solid #d7d7d7;\n            margin-bottom:5px;\n        }\n        .btns button:hover{\n            border-radius: 0;\n            background-color: #d7d7d7;\n        }\n        .btns button:focus{\n            outline: none;\n            border-radius: 0;\n            background-color: #4d4d4d;\n            color: #fff;\n        }\n        \n    </style>\n</head>\n\n<body>\n    <div class=\"dv1\">\n    <div class=\"btns\">\n    <button id = \"all\" onclick=\"change('all')\">All</button>\n    <button id = \"ds\">Data Scientist</button>    \n    <button id = \"de\">Data Engineer</button>\n    <button id = \"da\">Data Analyst</button>\n    <br>\n    <button id = \"ba\">Business Analyst</button>\n    <button id = \"ml\">ML Engineer</button>\n    <button id = \"rs\">Research Scientist</button>\n    <button id = \"st\">Statistician</button>\n    <br>\n    <button id = \"pm\">Project Manager</button>\n    <button id = \"db\">DBA/Database Engineer</button>\n    <button id = \"se\">Software Engineer</button>\n    <button id = \"ot\">Other</button>\n    </div>\n    <div id=\"my_dataviz\"></div>\n    </div>\n\n    <script>\n        require.config({\n            paths: {\n                d3: \"https://d3js.org/d3.v4.min\"\n             }\n             });\n        require([\"d3\"], function(d3) {\n        \n        \n\n        // Labels of row and columns\n        var myGroups = [\"'18-21'\", \"'22-24'\", \"'25-29'\", \"'30-34'\", \"'35-39'\", \"'40-44'\", \"'45-49'\", \"'50-54'\", \"'55-59'\", \"'60-69'\", \"'70+'\"];\n        var myVars = [\"'I have never written code'\", \"'< 1 years'\", \"'1-2 years'\", \"'3-5 years'\", \"'< 1 years'\",\"'5-10 years'\", \"'10-20 years'\", \"'20+ years'\"];\n\n        \n\n        function change(field){\n            this.field = field\n            showData(field);\n        }\n\n        function showData(field=\"all\"){\n\n        \n    }\n    });\n    </script>\n</body>\n\n</html>'''\n\njs_t1 = '''\n         require.config({\n            paths: {\n                d3: \"https://d3js.org/d3.v4.min\"\n             }\n             });\n        require([\"d3\"], function(d3) {\n        var data;\n        // set the dimensions and margins of the graph\n        var margin = { top: 5, right: 65, bottom: 60, left: 70 },\n            width = 750 - margin.left - margin.right,\n            height = 600 - margin.top - margin.bottom;\n\n        // append the svg object to the body of the page\n        var svg = d3.select(\"#my_dataviz\")\n            .append(\"svg\")\n            .attr(\"width\", width + margin.left + margin.right)\n            .attr(\"height\", height + margin.top + margin.bottom)\n            .append(\"g\")\n            .attr(\"transform\",\n                \"translate(\" + margin.left + \",\" + margin.top + \")\");\n\n        // Labels of row and columns\n        var myGroups = [\"'18-21'\", \"'22-24'\", \"'25-29'\", \"'30-34'\", \"'35-39'\", \"'40-44'\", \"'45-49'\", \"'50-54'\", \"'55-59'\", \"'60-69'\", \"'70+'\"];\n        var myVars = [\"'I have never written code'\", \"'< 1 years'\", \"'1-2 years'\", \"'3-5 years'\", \"'< 1 years'\",\"'5-10 years'\", \"'10-20 years'\", \"'20+ years'\"];\n\n        // Build X scales and axis:\n        var x = d3.scaleBand()\n            .range([0, width])\n            .domain(myGroups)\n            .padding(0.03);\n\n        svg.append(\"g\")\n            .attr(\"transform\", \"translate(0,\" + height + \")\")\n            .call(d3.axisBottom(x))\n\n        // Build X scales and axis:\n        var y = d3.scaleBand()\n            .range([height, 0])\n            .domain(myVars)\n            .padding(0.03);\n\n        svg.append(\"g\")\n            .call(d3.axisLeft(y));\n\n        // Build color scale\n        var myColor = d3.scaleLinear()\n            .range([\"#f5f5f5\", \"#496595\"])\n            .domain([1, 216])\n\n        showData()\n        \n        document.getElementById(\"ds\").addEventListener(\"click\", function(evt) {showData(evt.target.innerHTML)});\n        document.getElementById(\"da\").addEventListener(\"click\", function(evt) {showData(evt.target.innerHTML)});\n        document.getElementById(\"de\").addEventListener(\"click\", function(evt) {showData(evt.target.innerHTML)});\n        document.getElementById(\"ba\").addEventListener(\"click\", function(evt) {showData(evt.target.innerHTML)});\n        document.getElementById(\"ml\").addEventListener(\"click\", function(evt) {showData('Machine Learning Engineer')});\n        document.getElementById(\"rs\").addEventListener(\"click\", function(evt) {showData(evt.target.innerHTML)});\n        document.getElementById(\"st\").addEventListener(\"click\", function(evt) {showData(evt.target.innerHTML)});\n        document.getElementById(\"ot\").addEventListener(\"click\", function(evt) {showData(evt.target.innerHTML)});\n        document.getElementById(\"db\").addEventListener(\"click\", function(evt) {showData(evt.target.innerHTML)});\n        document.getElementById(\"se\").addEventListener(\"click\", function(evt) {showData(evt.target.innerHTML)});\n        document.getElementById(\"pm\").addEventListener(\"click\", function(evt) {showData('Product/Project Manager')});\n        document.getElementById(\"all\").addEventListener(\"click\", function(evt) {showData(\"all\")});\n        \n        function changeContent(evt){ showData(evt.target.innerHTML)}\n        \n        function change(field){\n            this.field = field\n            showData(field);\n        }\n\n        function showData(field=\"all\"){\n                    d3.csv(\"experience_heatmap.csv\", function (data) {\n               \n                    data = data.filter(function(d){\n                        return d.field == \"'\"+field+\"'\";\n                    })\n                    \n                    var maxColor = d3.max(data, (d)=>{return parseInt(d.value)})\n                    var myColor = d3.scaleLinear()\n                    .range([\"#f5f5f5\", \"#29658c\"])\n                    .domain([1, maxColor])\n\n                    var u = svg.selectAll(\"rect\")\n                    .data(data)\n\n                    u\n                    .enter()\n                    .append(\"rect\")\n                    .merge(u)\n                    .transition()\n                    .duration(1000)\n                    .attr(\"x\", function (d) {return x(d.variable) })\n                    .attr(\"y\", function (d) {return y(d.group) })\n                    .attr(\"width\", x.bandwidth())\n                    .attr(\"height\", y.bandwidth())\n                    .style(\"fill\", function (d) { if(d.value !==\"nan\"){return myColor(d.value);} return myColor(0);  })\n                    \n                    var v = svg.selectAll(\"svg > g > text\")\n                    .data(data)\n\n                    v\n                    .enter()\n                    .append(\"text\")\n                    .merge(v)\n                    .transition()\n                    .duration(1000)\n                    .text( function (d) { if(d.value !==\"nan\"){ return d.value.split(\".\")[0];} return 0;  })\n                    .attr(\"x\", function (d) { return x(d.variable) })\n                    .attr(\"y\", function (d) { return y(d.group) })\n                    .attr(\"transform\",\"translate(10,50)\")\n                    .style(\"font-family\",\"Didot\")\n                    .style(\"font-size\",\"24px\")\n                    .style(\"fill\", function (d){if(d.value > maxColor/2) { return \"#f5f5f5\"}; return \"black\";})\n        })\n    }\n});\n'''\n\n\nh = display(HTML(htmlt1))\n\nj = IPython.display.Javascript(js_t1)\nIPython.display.display_javascript(j)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### How to read the graph?\nAs you go through the tabs you will notice that most display higher numbers along a diagonal path, this is normal because as the expert's age increases he becomes more experienced with his coding skills. If the diagonal as a whole is lower, or there is a large concentration of people below the diagonal in the graph we learn that a lot more individuals are managing with **lower coding experience than what is the norm**. Conversely, if the whole diagonal is higher or if there is a lot of people above this diagonal, then **the field might require more coding experience** than what is the norm in other fields\n\nFor the most part, we see the same tendencies with **data professionals in the age group 22 - 29 having around 1-5 years of coding experience**. Such experience is well within the range of the average student. Once again we see Product Managers(and \"Others\") deviating quite a bit from the normal trend, with their coding experience falling short of the normal \"diagonal\" trend we see otherwise. \n\nA couple other interesting points to note when looking at the different views of the graph:\n- **Database Engineers seem to be the most experienced** of the bunch with 44% of respondents having 10+ years of experience(and 65% with 5+ years). This is followed by Research Scientists and Software Engineers.\n- Product Managers still defy norms with the **highest percentage of individuals that haven't written code**(11%), while at the same time having the 4th highest percentage of respondents with 20+ years experience.\n"},{"metadata":{},"cell_type":"markdown","source":"## <div class=\"subsection_title\">3.4 What languages should I learn?</div>\n\nContinuing on the topic of experience a very relevant question is what languages do I need to know in order to work as a data professional? Lets try to understand what languages students tend to learn versus whats actually utilised in the industry.\n<div class=\"sidenote\">\n    Source: Kaggle 2020 DS and ML Survey - \n    <span style=\"font-style: italic;\"> Q7. What programming languages do you use on a regular basis?\n    </span>\n</div>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"primary_blue = \"#496595\"\nprimary_blue2 = \"#85a1c1\"\nprimary_blue3 = \"#3f4d63\"\nprimary_grey = \"#c6ccd8\"\nprimary_black = \"#202022\"\n\nq7 = [question for question in questions if 'Q7' in question]\n\nlanguages = []\nfor qn in q7:\n    for val in dataprofs[qn].unique():\n        languages.append(val)\n        \nlanguages = [lang for lang in languages if str(lang)!='nan']\n\nprof_langs = (dataprofs.shape[0] - dataprofs[q7].isnull().sum()) / dataprofs.shape[0]\nstudent_langs = (students.shape[0] - students[q7].isnull().sum()) / students.shape[0]\n\nprof_langs.index = languages\nstudent_langs.index = languages\n\ntexttemplate_white = \"<b style='color: #fff'>%{text}% </b>\"\ntexttemplate_black = \"<b style='color: #000'> %{text}% </b>\"\n\ntrace2 = go.Bar(\n    y = languages,\n    x = prof_langs,\n    orientation = \"h\",\n    name = \"Professionals\",\n    marker = dict(color = primary_blue),\n    text = np.round(prof_langs*100),\n    texttemplate = [texttemplate_white]*7 +[texttemplate_black]*2 + [texttemplate_white]*2 +[texttemplate_black] + [texttemplate_white],\n    textposition = [\"inside\"]*7 +[\"outside\"]*2 + [\"inside\"]*2 +[\"outside\"] + [\"inside\"],\n)\n\n\ntexttemplate_white = \"<b style='color: #fff'>%{text}% </b>\"\ntexttemplate_black = \"<b style='color: #000'> %{text}% </b>\"\n\ntrace2 = go.Bar(\n    y = languages,\n    x = prof_langs,\n    orientation = \"h\",\n    name = \"Professionals\",\n    marker = dict(color = primary_blue),\n    text = np.round(prof_langs*100),\n    texttemplate = [texttemplate_white]*7 +[texttemplate_black]*2 + [texttemplate_white]*2 +[texttemplate_black] + [texttemplate_white],\n    textposition = [\"inside\"]*7 +[\"outside\"]*2 + [\"inside\"]*2 +[\"outside\"] + [\"inside\"],\n)\n\n\ntrace1 = go.Bar(\n    y = languages,\n    x = student_langs,\n    name = \"Students\",\n    orientation = \"h\",\n    marker = dict(color = primary_grey),\n    text = np.round(student_langs*100),\n    texttemplate = [texttemplate_white]*7 +[texttemplate_black]*2 + [texttemplate_white]*2 +[texttemplate_black] + [texttemplate_white],\n    textposition = [\"inside\"]*7 +[\"outside\"]*2 + [\"inside\"]*2 +[\"outside\"] + [\"inside\"],    \n)\n\nlarge_title_format = \"<span style='font-size:32px; font-family:Times New Roman'> Which languages should I learn?</span>\"\nsmall_title_format = \"<span style='font-size:16px; font-family:Tahoma'>    Python is the most popular language followed by SQL and R.</span>\"\n\nlayout = dict(\n   title = large_title_format + \"<br>\" + small_title_format,\n    margin = dict(t=150),\n    legend=dict(#title = \"<span style='font-size:16px'>  Legend</span>\",\n                orientation=\"h\",\n                yanchor='top',xanchor='center',\n                y= 1.06,x=0.5,\n                font=dict(size= 16),\n                traceorder='reversed',\n#                 bordercolor=primary_grey,\n#                 borderwidth=1, \n#                 bgcolor = \"#f4f0ea\"\n               ),\n    yaxis={'categoryorder':'array',\n           'categoryarray': prof_langs.sort_values(ascending=True).keys()},\n    xaxis=dict(side=\"top\",showgrid=False, tickformat=\"%\"),\n    barmode = \"group\",\n    bargap = 0.05,\n    bargroupgap =0.1,\n    width = 800,\n    height= 1000,\n    plot_bgcolor = \"#f4f0ea\" # \"#f6f2e8\"\n)\n\ndata = [trace1, trace2]\n\nfig = go.Figure(data = data, layout = layout)\n\nmain_annot_format = \"<span style='font-size:12px; font-family:Tahoma;'><b> %s </b><br> %s</span>\"\n\nfig.add_annotation(dict(\n        x=0.780,\n        y=0.87,\n        xref = \"paper\",\n        yref = \"paper\",\n        text= main_annot_format % (\"All  percentages  denote  the  fraction of <br>individuals that work with the language <br>on a daily basis.\",\n                                   \"\"),\n    #         showarrow = True,\n        ax=0, ay=0\n))\n\nfig.add_annotation(dict(\n        x=0.68,\n        y=0.68,\n        xref = \"paper\",\n        yref = \"paper\",\n        text= main_annot_format % (\"Python\",\n                                   \"\"\"Python seems like a clear favourite with more than 83% of <br>respondents  using it.  However in the <i>\\\"2020 Hacker Earth<br>Developer Survey\\\"</i> we saw numbers of 55% and 40% for <br>students and professionals respectively - much lower than <br>what we see here.  Clearly,  where the  survey was taken<br>seems to bias the results.\"\"\"),\n        \n))\n\nfig.add_annotation(dict(\n        x=0.68,\n        y=0.51,\n        xref = \"paper\",\n        yref = \"paper\",\n        text= main_annot_format % (\"SQL - an unlikely second?\",\n                                   \"\"\"Working with databases seems to be a common part of most <br>of our professionals work. Naturally, Database Engineers enjoy <br>the  top  spot  here  with  83%  working  with  SQL. They  are <br>however,  closely followed by  Data  Engineers (73%) and Data<br>Analysts(59%).\"\"\"),\n        \n))\n\nfig.add_annotation(dict(\n        x=0.68,\n        y=0.38,\n        xref = \"paper\",\n        yref = \"paper\",\n        text= main_annot_format % (\"R reigns supreme in Statistics\",\n                                   \"\"\"While most fields go the Python route, with Statisticians R is the<br> preferred choice  with  83%  of them working with the language.<br>Data  Scientists  come  second  with  38%  using  the  language.\"\"\"),\n        \n))\n\nfig.add_annotation(dict(\n        x=0.68,\n        y=0.26,\n        xref = \"paper\",\n        yref = \"paper\",\n        text= main_annot_format % (\"C, C++ and Java\",\n                                   \"\"\"These languages form the building blocks of students as they start<br>coding,  however  they  don't  see  as  much  use  with  most data <br>professionals other than Software Engineers.\"\"\"),\n        \n))\n\nfig.add_annotation(dict(\n        x=0.68,\n        y=0.13,\n        xref = \"paper\",\n        yref = \"paper\",\n        text= main_annot_format % (\"Champions of the less common languages\",\n                                   \"\"\"<span style='text-decoration:none'>1. Javascript - Software Engineers (46%)<br>2. MATLAB  -  Research Scientists (24%)<br>3. Bash  -  Database  Engineers   (24%) <br>4. Swift    -   Software  Engineers  (3%) </span>\"\"\"),\n        \n))\n\nfig[\"data\"][0][\"text\"][0] = 83.98\nfig[\"data\"][1][\"text\"][0] = 83.64\n\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some of the key takeaways are:\n- The students seem to be on a strong start here - learning **Python** is not only a safe bet because of its widespread use in the industry, but its also by far the language **most recommended** to beginners. \n- Having at least a **basic understanding of SQL** and database management would go a long way in your career.\n- While languages like C, C++ and Java are what many of us start out with, students should **learn to quickly adapt** and transfer their knowledge to more commonly used languages."},{"metadata":{},"cell_type":"markdown","source":"## <div class=\"subsection_title\">3.5 Visualization Tools</div>\nLet's see if there are any favorites among data professionals when it comes to visualising their data. Also **be sure to check the hover info for additional stats and information** about each of the tools.\n\n<div class=\"sidenote\">\n    Source: Kaggle 2020 DS and ML Survey - \n    <span style=\"font-style: italic;\"> Q14. What data visualization libraries or tools do you use on a regular basis? \n    </span>\n</div>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# This was a fun project to do soon after completing my short course on d3\n# The graph in total took around ~4 hrs to finish in VScode + live server, getting it to work in the notebook was another ~3-4 hrs - I'm getting better at this... I swear\n# Apparently if each svg in the entire notebook wasn't given a unique selector to be used, then the graphs with identical selectors would all display in the same output cell\n# Revisited to switch data source from github to data from the working directory\n\nq14 = [question for question in questions if 'Q14' in question]\n\nviztools = []\nfor qn in q14:\n    for val in dataprofs[qn].unique():\n        viztools.append(val)\n        \nviztools = [str.strip(viztool) for viztool in viztools if str(viztool)!='nan']\n\nviztool_counts = dataprofs[q14].notnull().sum()\nviztool_counts.index = viztools\n\nviz_data= []\nviz_data.append([\"name\",\"parent\",\"value\"])\nviz_data.append([\"Origin\",\"\",\"\"])\n\nfor i in range(len(viztools)):\n    viz_data.append([viztools[i].split(\" \")[0], \"Origin\", viztool_counts[i]])\n    \nviz_df = pd.DataFrame(viz_data)\n\nviz_df.to_csv(\"viztools.csv\", index=False, header=False)\n\nhtmlt2 = '''\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <title>Document</title>\n    <style>\n        .tooltip{\n            background-color:white;\n            width: 306px;\n            height: 235px;\n            position: absolute;\n            top: 166px;\n            left: 94px;\n            display: none;\n            box-shadow: 6px 8px 4px 4px rgba(0,0,0,0.3);\n            pointer-events: none;\n            opacity: 100;\n        }\n\n        .tt-container{\n            font-size:14px;\n            font-family: Arial, Helvetica, sans-serif;\n            padding: 20px;\n        }\n\n        .tt-container b{\n            font-size: 30px;\n        }\n\n        .tt-bar{\n            height: 40px;\n            margin: 10px 10px -10px 10px;\n        }\n\n    </style>\n</head>\n\n<style>\n</style>\n<body>\n<span style='font-size:36px; padding-left:20px; font-family:Times New Roman'> What should I use to visualize my data?</span>\n<br>\n<br>\n<span style='font-size:14px; position:relative; left:20px; font-family:Helvetica'> While the majority of our data professionals have experience with Matplotlib and Seaborn,<br>a lot of the libraries do see a fair amount of use in vizualisation.</span>\n<br>\n<div id=\"my_dataviz2\"></div>\n<div class=\"tooltip\"></div>\n\n<script>\nrequire.config({\n            paths: {\n                d3: \"https://d3js.org/d3.v4.min\"\n             }\n             });\n        require([\"d3\"], function(d3) {\n        \n    // set the dimensions and margins of the graph\n    var margin = {top: 10, right: 10, bottom: 10, left: 10},\n      width = 600 - margin.left - margin.right,\n      height = 600 - margin.top - margin.bottom;\n      \n    var colorScale = d3.scaleLinear()\n        .range([\"#a2885e\",\"#f1efd9\",\"#235f83\"])\n        .domain([150, 800, 6256])\n\n   \n\n    var tooltip_text = {\n        \"Matplotlib\": \"<div class='tt-bar' style='background-color:%s'></div><div class='tt-container'><b> Matplotlib</b><br><br>Matplotlib is almost every user's first step into data visualisation. This is evidenced by the fact that 71% of respondents have experience with the library.<br><br>   The areas where the library lacks is in interactive visualisations and the difficulty in customisation due to the level interface.</div>\",\n        \"Seaborn\": \"<div class='tt-bar' style='background-color:%s'></div><div class='tt-container'><b> Seaborn</b><br><br>Used by 53% of respondents, Seaborn is a Python data visualization library based on Matplotlib. It provides a higher-level wrapper on the library which makes it easier to use.<br><br>  The only drawback is that it doesnt have the same range of graphs that were available in Matplotlib.</div>\",\n        \"Plotly\": \"<div class='tt-bar' style='background-color:%s'></div><div class='tt-container'><b> Plotly</b><br><br>Plotly (and Plotly Express) is a visualisation library that provides interactive and publication-quality graphics.<br><br>    It even provides functionalities for 3-D plots and has a powerful out-of-the-box customisation feature-set.<br><br>   It does however require decent knowledge of data pre-processing to get the required data for certain kinds of graphs.</div>\",\n        \"Ggplot\": \"<div class='tt-bar' style='background-color:%s'></div><div class='tt-container'><b> Ggplot</b><br><br>ggplot2 is a data visualization package for the language R. Its an implementation of the Grammar of Graphics — a general scheme for data visualization which breaks up graphs into semantic components such as scales and layers.<br><br> Of all our respondents 29% have experience of working with ggplot.</div>\",\n        \"Shiny\": \"<div class='tt-bar' style='background-color:%s'></div><div class='tt-container'><b> Shiny</b><br><br>Shiny is an open R package that provides the tools for us to create interactive web pages. Without requiring knowledge of HTML, CSS and JS one can use Shiny to create powerful visualisations.<br><br> 10% of our respondents use Shiny.</div>\",\n        \"D3\": \"<div class='tt-bar' style='background-color:%s'></div><div class='tt-container'><b> D3.js</b><br><br>D3.js is a JavaScript library for producing dynamic, interactive data visualizations in web browsers( like this one!).<br><br> While it does provide an immense capability for customisation, it does require prior knowledge of HTML, CSS  and JS, probably why it is utilised by only 7% of data professionals.</div>\",\n        \"Altair\": \"<div class='tt-bar' style='background-color:%s'></div><div class='tt-container'><b> Altair</b><br><br>Altair is a declarative statistical visualization library for Python based on vega-lite, which makes it ideal for plots that require a lot of statistical transformation.<br><br> Altair is used by 2% of respondents. </div>\",\n        \"Bokeh\": \"<div class='tt-bar' style='background-color:%s'></div><div class='tt-container'><b> Bokeh</b><br><br>Bokeh is a flexible interactive visualization library that targets web browsers for representation. Its interface ranges from low to high, which makes it easy to produce both versatile and elegant graphics.<br><br> Bokeh is utilised by 7% of respondents.</div>\",\n        \"Geoplotlib\": \"<div class='tt-bar' style='background-color:%s'></div><div class='tt-container'><b> Geoplot</b><br><br>Geoplot is a Python library providing a selection of easy-to-use geospatial visualizations.<br><br> Being incredibly specific in its purpose, it's only utilised by 6% of respondents.</div>\",\n        \"Leaflet\": \"<div class='tt-bar' style='background-color:%s'></div><div class='tt-container'><b> Leaflet / Folium</b><br><br>Leaflet, an open-source JavaScript library, facilitates the development of interactive maps, but is designed to be used via JavaScript. Folium is the Python interface for using Leaflet.<br><br> Due to its specific application, its only picked up by 5% of respondents.</div>\",\n        \"None\": \"<div class='tt-bar' style='background-color:%s'></div><div class='tt-container'><b> None</b><br><br>7.5% of our respondents seem to not use any visualisation tools. Perhaps their job roles dont lend themselves to visualisation tasks.</div>\",\n        \"Other\": \"<div class='tt-bar' style='background-color:%s'></div><div class='tt-container'><b> Other</b><br><br>According to our responses, 4% of data professionals don't seem to use any of the visualisation tools listed in the survey options, so we're unclear exactly what they utilise for visualisation.<br><br>But if we're being honest it's clearly MS Paint, right?(just kidding!)</div>\"\n    }\n\n    function updateTooltip(text, val){\n        let tooltip = d3.selectAll(\".tooltip\")\n\n        tooltip\n            .html(tooltip_text[text].replace(\"%s\",colorScale(val)))\n            .style(\"display\",\"block\")\n            .transition()\n            .duration(225)\n            .style(\"height\", \"326px\")\n    }\n    \n    // Read data\n     d3.csv('viztools.csv', function(data) {\n    // d3.csv('https://raw.githubusercontent.com/schubert-da/Kaggle_DS_Survey_data/main/viz.csv', function(data) {\n    \n    var fontsizes = {\n        \"Matplotlib\": \"80px\",\n        \"Seaborn\": \"60px\",\n        \"Plotly\": \"32px\",\n        \"Ggplot\": \"32px\",\n        \"Shiny\": \"30px\",\n        \"D3\": \"28px\",\n        \"Altair\": \"0px\",\n        \"Bokeh\": \"28px\",\n        \"Geoplotlib\": \"28px\",\n        \"Leaflet\": \"0px\",\n        \"None\": \"28px\",\n        \"Other\": \"0px\"\n    }\n      // stratify the data: reformatting for d3.js\n      var root = d3.stratify()\n        .id(function(d) { return d.name; })   // Name of the entity (column name is name in csv)\n        .parentId(function(d) { return d.parent; })   // Name of the parent (column name is parent in csv)\n        (data);\n      root.sum(function(d) { return +d.value })   // Compute the numeric value for each entity\n    \n      // Then d3.treemap computes the position of each element of the hierarchy\n      // The coordinates are added to the root object above\n      d3.treemap()\n        .size([width, height])\n        .padding(4)\n        (root)\n    \n      // use this information to add rectangles:\n\n      // and to add the text labels        \n        })\n        \n});\n    </script>\n\n</body>\n</html>\n'''\njs_t2 = '''\n         require.config({\n            paths: {\n                d3: \"https://d3js.org/d3.v4.min\"\n             }\n             });\n        require([\"d3\"], function(d3) {\n        \n    // set the dimensions and margins of the graph\n    var margin = {top: 10, right: 10, bottom: 10, left: 10},\n      width = 600 - margin.left - margin.right,\n      height = 600 - margin.top - margin.bottom;\n      \n    var colorScale = d3.scaleLinear()\n        .range([\"#a2885e\",\"#f1efd9\",\"#235f83\"])\n        .domain([150, 800, 6256])\n\n    // append the svg object to the body of the page\n    var svg = d3.select(\"#my_dataviz2\")\n    .append(\"svg\")\n      .attr(\"width\", width + margin.left + margin.right)\n      .attr(\"height\", height + margin.top + margin.bottom)\n    .append(\"g\")\n      .attr(\"transform\",\n            \"translate(\" + margin.left + \",\" + margin.top + \")\");\n    \n    var tooltip_text = {\n        \"Matplotlib\": \"<div class='tt-bar' style='background-color:%s'></div><div class='tt-container'><b> Matplotlib</b><br><br>Matplotlib is almost every user's first step into data visualisation. This is evidenced by the fact that 71% of respondents have experience with the library.<br><br>   The areas where the library lacks is in interactive visualisations and the difficulty in customisation due to the level interface.</div>\",\n        \"Seaborn\": \"<div class='tt-bar' style='background-color:%s'></div><div class='tt-container'><b> Seaborn</b><br><br>Used by 53% of respondents, Seaborn is a Python data visualization library based on Matplotlib. It provides a higher-level wrapper on the library which makes it easier to use.<br><br>  The only drawback is that it doesnt have the same range of graphs that were available in Matplotlib.</div>\",\n        \"Plotly\": \"<div class='tt-bar' style='background-color:%s'></div><div class='tt-container'><b> Plotly</b><br><br>Plotly (and Plotly Express) is a visualisation library that provides interactive and publication-quality graphics.<br><br>   It does however require decent knowledge of data pre-processing to get the required data for certain kinds of graphs.</div>\",\n        \"Ggplot\": \"<div class='tt-bar' style='background-color:%s'></div><div class='tt-container'><b> Ggplot</b><br><br>ggplot2 is a data visualization package for the language R. Its an implementation of the Grammar of Graphics — a general scheme for data visualization which breaks up graphs into semantic components such as scales and layers.<br><br> Of all our respondents 29% have experience of working with ggplot.</div>\",\n        \"Shiny\": \"<div class='tt-bar' style='background-color:%s'></div><div class='tt-container'><b> Shiny</b><br><br>Shiny is an open R package that provides the tools for us to create interactive web pages. Without requiring knowledge of HTML, CSS and JS one can use Shiny to create powerful visualisations.<br><br> 10% of our respondents use Shiny.</div>\",\n        \"D3\": \"<div class='tt-bar' style='background-color:%s'></div><div class='tt-container'><b> D3.js</b><br><br>D3.js is a JavaScript library for producing dynamic, interactive data visualizations in web browsers( like this one!).<br><br> While it does provide an immense capability for customisation, it does require prior knowledge of HTML, CSS  and JS, probably why it is utilised by only 7% of data professionals.</div>\",\n        \"Altair\": \"<div class='tt-bar' style='background-color:%s'></div><div class='tt-container'><b> Altair</b><br><br>Altair is a declarative statistical visualization library for Python based on vega-lite, which makes it ideal for plots that require a lot of statistical transformation.<br><br> Altair is used by 2% of respondents. </div>\",\n        \"Bokeh\": \"<div class='tt-bar' style='background-color:%s'></div><div class='tt-container'><b> Bokeh</b><br><br>Bokeh is a flexible interactive visualization library that targets web browsers for representation. Its interface ranges from low to high, which makes it easy to produce both versatile and elegant graphics.<br><br> Bokeh is utilised by 7% of respondents.</div>\",\n        \"Geoplotlib\": \"<div class='tt-bar' style='background-color:%s'></div><div class='tt-container'><b> Geoplot</b><br><br>Geoplot is a Python library providing a selection of easy-to-use geospatial visualizations.<br><br> Being incredibly specific in its purpose, it's only utilised by 6% of respondents.</div>\",\n        \"Leaflet\": \"<div class='tt-bar' style='background-color:%s'></div><div class='tt-container'><b> Leaflet / Folium</b><br><br>Leaflet, an open-source JavaScript library, facilitates the development of interactive maps, but is designed to be used via JavaScript. Folium is the Python interface for using Leaflet.<br><br> Due to its specific application, its only picked up by 5% of respondents.</div>\",\n        \"None\": \"<div class='tt-bar' style='background-color:%s'></div><div class='tt-container'><b> None</b><br><br>7.5% of our respondents seem to not use any visualisation tools. Perhaps their job roles dont lend themselves to visualisation tasks.</div>\",\n        \"Other\": \"<div class='tt-bar' style='background-color:%s'></div><div class='tt-container'><b> Other</b><br><br>According to our responses, 4% of data professionals don't seem to use any of the visualisation tools listed in the survey options, so we're unclear exactly what they utilise for visualisation.<br><br>But if we're being honest it's clearly MS Paint, right?(just kidding!)</div>\"\n    }\n\n    // Read data\n    d3.csv('viztools.csv', function(data) {\n    //d3.csv('https://raw.githubusercontent.com/schubert-da/Kaggle_DS_Survey_data/main/viz.csv', function(data) {\n    \n\n    var fontsizes = {\n        \"Matplotlib\": \"80px\",\n        \"Seaborn\": \"60px\",\n        \"Plotly\": \"32px\",\n        \"Ggplot\": \"32px\",\n        \"Shiny\": \"30px\",\n        \"D3\": \"28px\",\n        \"Altair\": \"0px\",\n        \"Bokeh\": \"28px\",\n        \"Geoplotlib\": \"28px\",\n        \"Leaflet\": \"0px\",\n        \"None\": \"28px\",\n        \"Other\": \"0px\"\n    }\n      // stratify the data: reformatting for d3.js\n      var root = d3.stratify()\n        .id(function(d) { return d.name; })   // Name of the entity (column name is name in csv)\n        .parentId(function(d) { return d.parent; })   // Name of the parent (column name is parent in csv)\n        (data);\n      root.sum(function(d) { return +d.value })   // Compute the numeric value for each entity\n    \n      // Then d3.treemap computes the position of each element of the hierarchy\n      // The coordinates are added to the root object above\n      d3.treemap()\n        .size([width, height])\n        .padding(4)\n        (root)\n    \n      // use this information to add rectangles:\n      svg\n        .selectAll(\"rect\")\n        .data(root.leaves())\n        .enter()\n        .append(\"rect\")\n            .attr('x', function (d) { return d.x0; })\n            .attr('y', function (d) { return d.y0; })\n            .attr('width', function (d) { return d.x1 - d.x0; })\n            .attr('height', function (d) { return d.y1 - d.y0; })\n            .style(\"stroke\", \"black\")\n            .style(\"fill\", function (d) { return colorScale(d.value); })\n            .on(\"mouseover\", function(d){\n                let tooltip = d3.selectAll(\".tooltip\")\n\n                tooltip\n                    .html(tooltip_text[d.data.name].replace(\"%s\",colorScale(d.data.value)))\n                    .style(\"display\",\"block\")\n                    .style(\"height\", \"0px\")\n                    .transition()\n                    .duration(200)\n                    .style(\"height\", \"325px\")\n            })\n            .on(\"mouseleave\", function(d){\n                d3.selectAll(\".tooltip\")\n                .style(\"display\",\"none\")\n                .style(\"height\", \"0px\")\n            })\n            \n            \n\n\n      // and to add the text labels\n        svg\n        .selectAll(\"text\")\n        .data(root.leaves())\n        .enter()\n        .append(\"text\")\n            .attr(\"x\", function(d){ return d.x0+10})    // +10 to adjust position (more right)\n            .attr(\"y\", function(d){ return d.y0+20})    // +20 to adjust position (lower)\n            .text(function(d){ return d.data.name})\n            .attr(\"font-size\", \"18px\")\n            .attr(\"fill\", \"white\")\n            .on(\"mouseover\", function(d){\n                let tooltip = d3.selectAll(\".tooltip\")\n\n                tooltip\n                    .html(tooltip_text[d.data.name].replace(\"%s\",colorScale(d.data.value)))\n                    .style(\"display\",\"block\")\n                    .style(\"height\", \"325px\")\n            })\n          \n\n        svg\n        .selectAll(\"text.count\")\n        .data(root.leaves())\n        .enter()\n        .append(\"text\")\n            .attr(\"class\", function(d){ return \"count \"+d.data.name})\n            .attr(\"x\", function(d){ return (d.x1+d.x0)/2 })    // +10 to adjust position (more right)\n            .attr(\"y\", function(d){ return (d.y1+d.y0)/2 + 20})    // +20 to adjust position (lower)\n            .text(function(d){ return d.data.value.replace(/\\B(?=(\\d{3})+(?!\\d))/g, \",\");})\n            .attr(\"text-anchor\",\"middle\")\n            .style(\"font-size\", function(d){ return fontsizes[d.data.name] })\n            .attr(\"fill\", \"white\")\n            .style(\"-webkit-font-smoothing\", \"antialiased\")\n            .style(\"font-family\", \"Arial\")\n            .on(\"mouseover\", function(d){\n                let tooltip = d3.selectAll(\".tooltip\")\n\n                tooltip\n                    .html(tooltip_text[d.data.name].replace(\"%s\",colorScale(d.data.value)))\n                    .style(\"display\",\"block\")\n                    .style(\"height\", \"326px\")\n            })\n        })\n        \n});\n'''\nh = display(HTML(htmlt2))\n\nj = IPython.display.Javascript(js_t2)\nIPython.display.display_javascript(j)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above graph my main takeaway is that with visualization greatly aiding analysis its often **useful to have experience with at least one** of these tools under your belt. If your job role hinges on **creating impactful visualisations**, then maybe you might need to upskill yourself and learn to utilise tools with interactivity and higher degrees of customisation that help to convey your message better."},{"metadata":{},"cell_type":"markdown","source":"## <div class=\"subsection_title\">3.6 How much Machine Learning Experience do I need?</div>\n<a id='ml_experience'></a>\nAs students just starting out in their machine learning journey, it isn't uncommon to think that whatever ML knowledge we have isn't quite enough to make that first step into working in an ML-related role. Let's try to get a better understanding of how experienced data professionals are with machine learning at different age groups.\n\nMuch like the coding experience graph, you can **use the buttons to get more field-specific insights**. Note that cells without any text implies a count of zero. \n\n<div class=\"sidenote\">\n    Source: Kaggle 2020 DS and ML Survey - \n    <span style=\"font-style: italic;\"> Q15. For how many years have you used machine learning methods? \n    </span>\n</div>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Creating the CSV for d3 to use.\n\n# Creating the new labels for renaming, also defining the order of the labels in the graph\nml_labels = ['< 1 year', '1-2 years', '2-3 years','5-10 years', '3-4 years', 'Do not use','4-5 years','10-20 years', '> 20 years']\nordered_ml_labels = ['Do not use','< 1 year', '1-2 years', '2-3 years','3-4 years','4-5 years','5-10 years','10-20 years','> 20 years']\n\n# We will create the data for the 'all' tab of the visualisation\nml_age_heatmap = pd.DataFrame()\n\n# This line just helps to make sure that all the required indexes(ML experience labels) are present in the df, ignore the values we will just drop the column later anyways\nml_age_heatmap[\"placeholder\"] =  dataprofs[\"Q15\"].value_counts()\n\nfor agegroup in student_ages.keys():\n    ml_age_heatmap[agegroup] = dataprofs[dataprofs[\"Q1\"]==agegroup][\"Q15\"].value_counts()\n\n# Dropping the placeholder col, rename the labels and then reorder them    \nml_age_heatmap = ml_age_heatmap.drop(\"placeholder\",axis=1)\nml_age_heatmap.index = ml_labels\nml_age_heatmap = ml_age_heatmap.reindex(ordered_ml_labels)\n  \n    \nmlexpdata = ml_age_heatmap.values\nmlexpdata_list = []\n\nfor row in range(mlexpdata.shape[0]):\n    for col in range(mlexpdata.shape[1]):\n        mlexpdata_list.append([ordered_ml_labels[row],student_ages.keys()[col],mlexpdata[row][col],\"all\"])     \n\n# Same procedure as before, now we just iterate and do it once for each field.\nfor field in fields:\n    ml_age_heatmap = pd.DataFrame()\n    ml_age_heatmap[\"placeholder\"] =  dataprofs[\"Q15\"].value_counts()\n    for agegroup in student_ages.keys():\n        ml_age_heatmap[agegroup] = dataprofs[(dataprofs[\"Q1\"]==agegroup) & (dataprofs[\"Q5\"]==field)][\"Q15\"].value_counts()\n    \n    ml_age_heatmap = ml_age_heatmap.drop(\"placeholder\",axis=1)\n    ml_age_heatmap.index = ml_labels\n    ml_age_heatmap = ml_age_heatmap.reindex(ordered_ml_labels)\n\n    mlexpdata = ml_age_heatmap.values\n\n    for row in range(mlexpdata.shape[0]):\n        for col in range(mlexpdata.shape[1]):\n            mlexpdata_list.append([ordered_ml_labels[row],student_ages.keys()[col],mlexpdata[row][col],field])\n\n# Add column names and write to working directory\nmlexpdata_df = pd.DataFrame(mlexpdata_list,columns=['exp', 'age', 'value', 'field'])\nmlexpdata_df.to_csv(\"ml_age_heatmap.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"htmlt1 = '''\n<!DOCTYPE html>\n<html lang=\"en\">\n\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Document</title>\n    <style>\n        .dv3{\n            border: 1px solid #d7d7d7;\n            width: 700px;\n            height: 1000px\n            padding: 10px 15px;\n            box-shadow: 2px 2px 2px 1px rgba(0,0,0,0.3); \n        }\n        .btns_dv3{\n            margin-left: 10px;\n            margin-top: 10px;\n        }\n        .btns_dv3 button{\n            width: 167px;\n            position: static;\n            border-radius: 0;\n            font-size: 12px;\n            padding: 3px 6px;\n            color: #000;\n            background-color: #fff;\n            border: 1px solid #d7d7d7;\n            margin-bottom:5px;\n        }\n        .btns_dv3 button:hover{\n            border-radius: 0;\n            background-color: #d7d7d7;\n        }\n        .btns_dv3 button:focus{\n            outline: none;\n            border-radius: 0;\n            background-color: #4d4d4d;\n            color: #fff;\n        }\n    </style>\n</head>\n\n<body>\n    <div class = \"dv3\">\n    <div class=\"btns_dv3\">\n    <button value=\"all\">All</button>\n    <button value=\"Data Scientist\">Data Scientist</button>    \n    <button value=\"Data Engineer\">Data Engineer</button>\n    <button value=\"Data Analyst\">Data Analyst</button>\n    \n    <br>\n    <button value=\"Business Analyst\">Business Analyst</button>\n    <button value=\"Machine Learning Engineer\">ML Engineer</button>\n    <button value=\"Research Scientist\">Research Scientist</button>\n    <button value=\"Statistician\">Statistician</button>\n    \n    <br>\n    <button value=\"Product/Project Manager\">Project Manager</button>\n    <button value=\"DBA/Database Engineer\">DBA/Database Engineer</button>\n    <button value=\"Software Engineer\">Software Engineer</button>\n    <button value=\"Other\">Other</button>\n    </div>\n    <div id=\"my_dataviz3\"></div>\n    </div>\n</body>\n\n</html>'''\n\njs_t1 = '''\n         require.config({\n            paths: {\n                d3: \"https://d3js.org/d3.v4.min\"\n             }\n             });\n        require([\"d3\"], function(d3) {\n        var data;\n        // set the dimensions and margins of the graph\n        var margin = { top: 5, right: 65, bottom: 60, left: 70 },\n            width = 750 - margin.left - margin.right,\n            height = 600 - margin.top - margin.bottom;\n\n        // append the svg object to the body of the page\n        var svg = d3.select(\"#my_dataviz3\")\n            .append(\"svg\")\n            .attr(\"width\", width + margin.left + margin.right)\n            .attr(\"height\", height + margin.top + margin.bottom)\n            .append(\"g\")\n            .attr(\"transform\",\n                \"translate(\" + margin.left + \",\" + margin.top + \")\");\n\n        // Labels of row and columns\n        var xlabels = ['Do not use', '< 1 year', '1-2 years', '2-3 years', '3-4 years', '4-5 years','5-10 years', '10-20 years', '> 20 years']\n        var ylabels = ['18-21', '22-24', '25-29', '30-34', '35-39', '40-44', '45-49', '50-54', '55-59', '60-69', '70+']\n\n        // Build X scales and axis:\n        var x = d3.scaleBand()\n            .range([0, width])\n            .domain(ylabels)\n            .padding(0.03);\n\n        svg.append(\"g\")\n            .attr(\"transform\", \"translate(0,\" + height + \")\")\n            .call(d3.axisBottom(x))\n\n        // Build X scales and axis:\n        var y = d3.scaleBand()\n            .range([height, 0])\n            .domain(xlabels)\n            .padding(0.03);\n\n        svg.append(\"g\")\n            .call(d3.axisLeft(y));\n\n        // Build color scale\n        var myColor = d3.scaleLinear()\n            .range([\"#f5f5f5\", \"#29658c\"])\n            .domain([1, 216])\n\n        showData();\n        let buttons = d3.selectAll(\".dv3 button\")\n\n        buttons\n            .on(\"click\", function(){\n                showData(this.value)\n            })\n\n        function showData(field=\"all\"){\n                    d3.csv(\"ml_age_heatmap.csv\", function (data) {\n                    \n                    data = data.filter(function(d){\n                        return d.field == field;\n                    })\n                    \n                    var maxColor = d3.max(data, (d)=>{return +d.value})\n                    var myColor = d3.scaleLinear()\n                    .range([\"#f5f5f5\", \"#29658c\"])\n                    .domain([1, maxColor])\n\n                    var u = svg.selectAll(\"rect\")\n                    .data(data)\n\n                    u\n                    .enter()\n                    .append(\"rect\")\n                    .merge(u)\n                    .transition()\n                    .duration(1000)\n                    .attr(\"x\", function (d) {return x(d.age) })\n                    .attr(\"y\", function (d) {return y(d.exp) })\n                    .attr(\"width\", x.bandwidth())\n                    .attr(\"height\", y.bandwidth())\n                    .style(\"fill\", function (d) { if(d.value !==\"nan\"){return myColor(d.value);} return myColor(1);  })\n                    \n                    var v = svg.selectAll(\"svg > g > text\")\n                    .data(data)\n\n                    v\n                    .enter()\n                    .append(\"text\")\n                    .merge(v)\n                    .transition()\n                    .duration(1000)\n                    .text( function (d) { if(d.value !==\"nan\" && +d.value != 0){ return +d.value} return \" \"; })\n                    .attr(\"x\", function (d) { return x(d.age) })\n                    .attr(\"y\", function (d) { return y(d.exp) })\n                    .attr(\"transform\",\"translate(15,35)\")\n                    .style(\"font-family\",\"Didot\")\n                    .style(\"font-size\",\"18px\")\n                    .style(\"fill\", function (d){if(d.value > maxColor/2) { return \"#d7d7d7\"}; return \"black\";})\n        })\n    }\n});\n'''\n\n\nh = display(HTML(htmlt1))\n\nj = IPython.display.Javascript(js_t1)\nIPython.display.display_javascript(j)\n\n# ~3hr for this one, fastest d3 piece so far. Creating the csv for it took a while","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"While **\"1 year of ML experience\" can mean very different things** depending on where the individual studied, hands-on/work experience, how much time they actually devoted to learning, etc, we will use this to get a sense of how experienced individuals are with machine learning techniques, in their fields.\n\nWorking with data **does not always entail that machine learning be the end goal**. This is apparent because in many fields we no longer see the same dominant diagonal concentration of professionals that we saw in the [coding experience graph](#coding_experience). Professions like data analysts and business analysts both have significant number of individuals that have no ML experience. \n\nIn the age group **22-29 most individuals have between 0-2 years of machine learning experience**, a very reasonable goal for students to strive towards.\n\nThe professions where **higher ML experience is observed are those of data scientists, research scientists and machine learning engineers**."},{"metadata":{},"cell_type":"markdown","source":"## <div class=\"subsection_title\">3.7 What Machine Learning frameworks should I opt for?</div>\n\nLet's try to see what ML frameworks are commonly used in the industry.\n<div class=\"sidenote\">\n    Source: Kaggle 2020 DS and ML Survey - \n    <span style=\"font-style: italic;\"> Q16. Which of the following machine learning frameworks do you use on a regular basis? \n    </span>\n</div>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"q16 = [question for question in questions if 'Q16' in question]\n\n# List of labels\nmlframeworks = []\nfor qn in q16:\n    for val in dataprofs[qn].unique():\n        mlframeworks.append(val)\n        \nmlframeworks = [str.strip(mlframework) for mlframework in mlframeworks if str(mlframework)!='nan']\n\nmlframeworks_counts = dataprofs[q16].notnull().sum()\nmlframeworks_counts.index = mlframeworks\nmlframeworks_percentages = (mlframeworks_counts/dataprofs.shape[0]).sort_values(ascending = False)\n\n# Creating graph\ntrace1 = go.Bar(\n    y = mlframeworks_percentages,\n    x = mlframeworks_percentages.index,\n    marker = dict(color = [primary_blue]+[primary_grey]*15),\n)\n\nlayout = dict(\n    title = \"<b style='font-family:Times New Roman; font-size:22px'>Usage of Machine Learning Frameworks</b><br><span style='font-family:Tahoma; font-size:14px'>Scikit-Learn seems to be the go-to choice for most data professionals.</span>\",\n    margin = dict(t=30, pad=5),\n    xaxis = dict(\n        categoryorder = 'array',\n        categoryarray = mlframeworks_percentages.sort_values(ascending=False).keys(),\n        tickangle = -90,\n    ),\n    yaxis = dict(\n        zeroline = True,\n        zerolinecolor = \"#4d4d4d\",\n        zerolinewidth = 4,\n        gridcolor = \"#d7d7d7\",\n        tickformat = '%'\n    ),\n    bargap = 0.03,\n    width = 600,\n    height = 400,\n    plot_bgcolor = \"#fff\"\n)\n\ndata = [trace1]\n\nfig = go.Figure(data = data, layout = layout)\n\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A couple things to note:\n* **Scikit** is the most common choice among respondents. **Tensorflow and Keras** also seem to be popular choices in the second and third place.\n* **Xgboost vs LightGBM vs CatBoost**: A common question asked on Kaggle - when considering only Data Scientists, we see that **49% use Xgboost** making it the preferred choice over LightGBM at 26% and Catboost at 14%.\n\nWhile exploring the data for this analysis I noticed a rather peculiar behaviour - for some reason **Statisticians adopted Caret to a much greater extent** than any other field. On further analysis I realised that because this was a **group that had much higher usages of R**, an **R ML framework** like Caret had a much higher adoption rate. Let's see how the same chart differs if we instead look at those who only use R.\n<div class=\"sidenote\">\n    Source: Kaggle 2020 DS and ML Survey - \n    <span style=\"font-style: italic;\"> Q16. Which of the following machine learning frameworks do you use on a regular basis? \n    </span>\n</div>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"r_users = dataprofs[(dataprofs[\"Q7_Part_1\"].isnull()) & (dataprofs[\"Q7_Part_2\"].notnull())]\n\nmlframeworks_r_counts = r_users[q16].count()\nmlframeworks_r_counts.index = mlframeworks\n\nmlframeworks_r_percentages = (mlframeworks_r_counts / r_users.shape[0]).sort_values(ascending=False)\n\ntrace1 = go.Bar(\n    y = mlframeworks_r_percentages,\n    x = mlframeworks_r_percentages.index,\n    marker = dict(color = [primary_blue]+[primary_grey]*15),\n)\n\nlayout = dict(\n    title = \"<b style='font-family:Times New Roman; font-size:22px'>Usage of Machine Learning Frameworks in R</b><br><span style='font-family:Tahoma; font-size:14px'>When R is utilised for machine learning, Caret is the most popular framework used. </span>\",\n    margin = dict(t=30, pad=5),\n    xaxis = dict(\n        categoryorder = 'array',\n        categoryarray = mlframeworks_r_percentages.sort_values(ascending=False).keys(),\n        tickangle = -90,\n    ),\n    yaxis = dict(\n        zeroline = True,\n        zerolinecolor = \"#4d4d4d\",\n        zerolinewidth = 4,\n        gridcolor = \"#d7d7d7\",\n        tickformat = '%'\n    ),\n    bargap = 0.03,\n    width = 600,\n    height = 400,\n    plot_bgcolor = \"#fff\"\n)\n\ndata = [trace1]\n\nfig = go.Figure(data = data, layout = layout)\n\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seems like our results have changed when only considering R users. If students prefer R as their language of choice, **Caret** seems to be a good option to look into (Also notice how another R package like **TinyModels suddenly jumped up in the list**)\n\nThe lower percentages in general compared to the previous graph, as well as the presence of \"None\" in second place shows that most **R users value the language for purposes other than machine learning**. \n\n*I'm assuming we're seeing certain python packages popping up in this graph because the respondents had knowledge of them but didn't consider Python as a language they used regularly, in the survey responses.*"},{"metadata":{},"cell_type":"markdown","source":"## <div class=\"subsection_title\">3.8 Learning Platforms</div>\n\nEven with all the amazing resources available online, at times we all need a little guidance in developing a systematic learning plan and thats where learning platforms come to our rescue. Let's take a look at what we can learn from the way that data professionals consume online course content.\n\nWhile exploring the data I noticed how at each age group there were noticable **differences between both groups' learning habits** so I created an interactive piece to help you see just that. *(PRO TIP: After you've selected an age group option, using the up and down arrow keys to go through the options makes the graph a lot more interesting to use.)*\n\n<div class=\"sidenote\">\n    Source: Kaggle 2020 DS and ML Survey - \n    <span style=\"font-style: italic;\"> Q37. On which platforms have you begun or completed data science courses? \n    </span>\n</div>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Get the questions list\nq37 = [question for question in questions if 'Q37' in question]\n\nplatforms = []\nfor qn in q37:\n    for val in dataprofs[qn].unique():\n        platforms.append(val)\n        \nplatforms = [str.strip(platform) for platform in platforms if str(platform)!='nan']\n\n# Now we start creating the DataFrame for d3 to use\n\n# Professionals counts\nplatforms_counts = dataprofs[q37].notnull().sum()\nplatforms_counts.index = platforms\n\nplatform_percentages = (platforms_counts/dataprofs.shape[0]).sort_values(ascending = False)\nplatform_percentages.index = [platform.split(\"(\")[0] for platform in platform_percentages.index]\n\n# Students counts\nplatforms_students_counts = students[q37].notnull().sum()\nplatforms_students_counts.index = platforms\n\nplatform_students_percentages = (platforms_students_counts/students.shape[0]).sort_values(ascending = False)\nplatform_students_percentages.index = [platform.split(\"(\")[0] for platform in platform_students_percentages.index]\n\n# Professionals Data - \"all\" age group\nplatform_data = pd.DataFrame()\nplatform_data[\"platform\"] = [platform.split(\"(\")[0].split(\" \")[0] for platform in platform_percentages.index]\nplatform_data[\"value\"] = np.round(platform_percentages.values*100,1)\nplatform_data[\"age\"] = \"all\"\nplatform_data[\"category\"] = \"professional\"\n\n# Professionals Data - iterate and do the same for remaining age groups\nfor agegroup in student_ages.keys():\n    temp_df = pd.DataFrame()\n    \n    temp_data = dataprofs[dataprofs[\"Q1\"]==agegroup][q37]\n    temp_counts = temp_data.notnull().sum()\n    temp_counts.index = platforms\n\n    temp_percentages = (temp_counts/temp_data.shape[0]).sort_values(ascending = False)\n    temp_percentages.index = [platform.split(\"(\")[0].split(\" \")[0] for platform in temp_percentages.index]\n    \n    temp_df[\"platform\"] = temp_percentages.index\n    temp_df[\"value\"] = np.round(temp_percentages.values*100,1)\n    temp_df[\"age\"] = agegroup\n    temp_df[\"category\"] = \"professional\"\n    \n    platform_data = platform_data.append(temp_df,ignore_index = True)\n    \n# Students Data - \"all\" age group\ntemp_df = pd.DataFrame()\ntemp_df[\"platform\"] = [platform.split(\"(\")[0].split(\" \")[0] for platform in platform_students_percentages.index ]\ntemp_df[\"value\"] = np.round(platform_students_percentages.values*100,1)\ntemp_df[\"age\"] = \"all\"\ntemp_df[\"category\"] = \"student\"\nplatform_data = platform_data.append(temp_df,ignore_index = True)\n\n# Students Data - iterate and do the same for remaining age groups\nfor agegroup in student_ages.keys():\n    temp_df = pd.DataFrame()\n    \n    temp_data = students[students[\"Q1\"]==agegroup][q37]\n    temp_counts = temp_data.notnull().sum()\n    temp_counts.index = platforms\n\n    temp_percentages = (temp_counts/temp_data.shape[0]).sort_values(ascending = False)\n    temp_percentages.index = [platform.split(\"(\")[0].split(\" \")[0] for platform in temp_percentages.index]\n    \n    temp_df[\"platform\"] = temp_percentages.index\n    temp_df[\"value\"] = np.round(temp_percentages.values*100,1)\n    temp_df[\"age\"] = agegroup\n    temp_df[\"category\"] = \"student\"\n    \n    platform_data = platform_data.append(temp_df,ignore_index = True)\n\nplatform_data.to_csv(\"platform_full.csv\", index=False, header=[\"platform\",\"value\",\"age\",\"category\"])\n\nhtmlt1 = '''\n<head>\n<style>\n        .age_select{\n            border-radius: 0;\n            border: 1px solid #d7d7d7;\n\n        }\n        .select_container{\n            border: 1px solid #d7d7d7;\n            width: 160px;\n            padding: 3px 5px;\n            box-shadow: 1px 1px 1px 1px rgba(0,0,0,0.3);\n            position: relative;\n            left: 10px;\n            top: 10px;\n        }\n        .dv4{\n            width: 750px;\n            border: 1px solid #d7d7d7;\n            box-shadow: 2px 2px 2px 1px rgba(0,0,0,0.3); \n        }\n        .title{\n            font-size: 19.2px;\n            font-weight: 400;\n            font-family: Garamond;\n            position: relative;\n            left: 186px;\n            top: -21px;\n        }\n        .title_left{\n            position: absolute;\n            top: 62px;\n            left: 280px;\n            font-size: 17px;\n            font-weight: 600;\n            font-family: Lato;\n        }\n        .title_right{\n            position: absolute;\n            top: 62px;\n            left: 650px;\n            font-size: 17px;\n            font-weight: 600;\n            font-family: Lato;\n        }\n\n    </style>\n</head>\n<body>\n    <div class = \"dv4\">\n    <div class = \"select_container\">\n    Age group:\n    <select class=\"age_select\">\n        <option value=\"all\">All</option>\n        <option value=\"18-21\">18-21</option>    \n        <option value=\"22-24\">22-24</option>\n        <option value=\"25-29\">25-29</option>\n        <option value=\"30-34\">30-34</option>\n        <option value=\"35-39\">35-39</option>\n        <option value=\"40-44\">40-44</option>\n        <option value=\"45-49\">45-49</option>\n        <option value=\"50-54\">50-54</option>\n        <option value=\"55-59\">55-59</option>\n        <option value=\"60-69\">60-69</option>\n        <option value=\"70+\">70+</option>\n    </select>\n    </div>\n    <div class=\"title_left\"> Data Professional </div>\n    <div class=\"title_right\"> Student </div>\n    <span class=\"title\">Usage of Learning Platforms across age groups</span>\n    <br>\n    <div id=\"my_dataviz41\" style=\"display: inline;\"></div>\n    <div id=\"my_dataviz42\" style=\"display: inline;\"></div>\n    </div>\n</body>\n\n</html>'''\n\njs_t1 = '''\n         require.config({\n            paths: {\n                d3: \"https://d3js.org/d3.v4.min\"\n             }\n             });\n        require([\"d3\"], function(d3) {\n        \n        // set the dimensions and margins of the graph\n        var margin = {top: 20, right: 0, bottom: 40, left: 90},\n            width = 360 - margin.left - margin.right,\n            height = 400 - margin.top - margin.bottom;\n        \n        // append the svg object to the body of the page\n        var svg = d3.select(\"#my_dataviz41\")\n          .append(\"svg\")\n            .attr(\"width\", width + margin.left + margin.right)\n            .attr(\"height\", height + margin.top + margin.bottom)\n          .append(\"g\")\n            .attr(\"transform\", \"translate(\" + margin.left + \",\" + margin.top + \")\");\n\n        var svg2 = d3.select(\"#my_dataviz42\")\n            .append(\"svg\")\n                .attr(\"width\", width + margin.left + margin.right)\n                .attr(\"height\", height + margin.top + margin.bottom)\n            .append(\"g\")\n                .attr(\"transform\", \"translate(\" + margin.left + \",\" + margin.top + \")\");\n        \n        var x = d3.scaleLinear()\n            .domain([0, 56])\n            .range([ 0, width]);\n\n        showData();\n\n        var sel = d3.selectAll(\"div.dv4 .age_select\")\n                    .on(\"change\", function(){\n                        showData(this.value)\n                    })\n                    .transition()\n\n        var x = d3.scaleLinear()\n            .domain([0, 56])\n            .range([ 0, width]);\n        \n        var xAxis = svg.append(\"g\")\n            .attr(\"transform\", \"translate(0,0)\")\n            .call(d3.axisTop(x))\n\n        var xAxis2 = svg2.append(\"g\")\n            .attr(\"transform\", \"translate(0,0)\")\n            .call(d3.axisTop(x))\n        \n        var y = d3.scaleBand()\n            .range([ 0, height ])\n            .domain(['Coursera',\n                    'Udemy',\n                    'Kaggle Learn Courses',\n                    'University Courses ',\n                    'DataCamp',\n                    'edX',\n                    'Udacity',\n                    'LinkedIn Learning',\n                    'Other',\n                    'Fast.ai',\n                    'Cloud-certification programs ',\n                    'None'])\n            .padding(.1);\n        \n        var yAxis =svg.append(\"g\")\n            .call(d3.axisLeft(y))\n\n            var yAxis2 =svg2.append(\"g\")\n            .call(d3.axisLeft(y))\n        \n        function showData(age=\"all\") {\n        d3.csv(\"platform_full.csv\", function(data){\n        \n        var data_prof = data.filter(function(d){\n                        return ((d.category == \"professional\") && (d.age == age));\n                    })\n        data_prof = data_prof.sort(function(b,a){ return +a.value - (+b.value); })\n\n        var data_stud = data.filter(function(d){\n            return ((d.category == \"student\") && (d.age == age));\n        })\n        data_stud = data_stud.sort(function(b,a){ return +a.value - (+b.value); })\n\n        x.domain([0, 56])\n        xAxis.transition().duration(500).call(d3.axisTop(x))\n\n        y.domain(data_prof.map(function(d) { return d.platform; }))\n        yAxis.transition().duration(500).call(d3.axisLeft(y))\n        \n        var max_stud = d3.max(data_stud, d => +d.value)\n        var max_prof = d3.max(data_prof, d => +d.value)\n        \n        //  Bars\n        var d1 = svg.selectAll(\".rect1\")\n            .data(data_prof)\n\n        d1\n        .enter()\n        .append(\"rect\")\n        .merge(d1)\n        .attr(\"class\", \"rect1\")\n        .attr(\"x\", x(0) )\n        .attr(\"y\", function(d) { return y(d.platform); })\n        .transition()\n        .duration(1000)\n        .attr(\"width\", function(d) { return x(d.value); })\n        .attr(\"height\", y.bandwidth() )\n        .attr(\"fill\", (d) => { return (+d.value == max_prof? \"#496595\": \"#c6ccd8\") })\n\n        var v = svg.selectAll(\"#my_dataviz41 > svg > g > text\")\n                    .data(data_prof)\n\n        v\n        .enter()\n        .append(\"text\")\n        .merge(v)\n        .transition()\n        .duration(1000)\n        .text( function (d) { if(d.value !==\"nan\" && +d.value != 0){ return (d.value).split(\".\")[0] + \"%\"} return \" \"; })\n        .attr(\"x\", function (d) { return x(d.value) })\n        .attr(\"y\", function (d) { return y(d.platform) })\n        .attr(\"transform\",\"translate(-27,17)\")\n        .style(\"font-family\",\"Didot\")\n        .style(\"font-size\",\"13px\")\n        .style(\"fill\",\"#fff\")\n        \n        x.domain([0, 56])\n        xAxis2.transition().duration(500).call(d3.axisTop(x))\n        \n        y.domain(data_stud.map(function(d) { return d.platform; }))\n        yAxis2.transition().duration(500).call(d3.axisLeft(y))\n        \n        //  Bars\n        var d2 = svg2.selectAll(\"rect\")\n                    .data(data_stud)\n\n        d2\n        .enter()\n        .append(\"rect\")\n        .merge(d2)\n        .attr(\"class\", \"rect2\")\n        .attr(\"x\", x(0) )\n        .attr(\"y\", function(d) { return y(d.platform); })\n        .transition()\n        .duration(1000)\n        .attr(\"width\", function(d) { return x(d.value); })\n        .attr(\"height\", y.bandwidth() )\n        .attr(\"fill\", (d) => { return (+d.value == max_stud? \"#496595\": \"#c6ccd8\") })\n\n        var w = svg2.selectAll(\"#my_dataviz42 > svg > g > text\")\n                    .data(data_stud)\n\n        w\n        .enter()\n        .append(\"text\")\n        .merge(w)\n        .transition()\n        .duration(1000)\n        .text( function (d) { if(d.value !==\"nan\" && +d.value != 0){ return (d.value).split(\".\")[0] + \"%\"} return \" \"; })\n        .attr(\"x\", function (d) { return x(d.value) })\n        .attr(\"y\", function (d) { return y(d.platform) })\n        .attr(\"transform\",\"translate(-27,17)\")\n        .style(\"font-family\",\"Didot\")\n        .style(\"font-size\",\"13px\")\n        .style(\"fill\",\"#fff\")\n        })\n    }\n});\n'''\n\nh = display(HTML(htmlt1))\n\nj = IPython.display.Javascript(js_t1)\nIPython.display.display_javascript(j)\n\n# Took about ~5hrs to complete - First time working with subplots and horizontal bar charts","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* A common trend we see is that **data professionals are more likely to leverage these resources** - even when only comparing individuals in the same age group.\n* When considering online platforms we see that **Coursera** has cemented its place in our #1 spot. In the next few spots **Udemy, Kaggle Learning courses and Data Camp** are also popular among the two groups.\n* While **University Courses** do often pop up in the top 5 of our list, we see that **less than 30% of all data professionals have completed a data science course in university**. This goes to show that having **a degree in data science isn't always necessary** to work in this field."},{"metadata":{},"cell_type":"markdown","source":"## <div class=\"subsection_title\">3.9 Media and learning</div>\n\nThe field of data science and machine learning is advancing at a rapid rate. Let's look at some of the tools that will help you to continuously learn and keep in touch with the latest in your field.\n\n<div class=\"sidenote\">\n    Source: Kaggle 2020 DS and ML Survey - \n    <span style=\"font-style: italic;\"> Q39. Who/what are your favorite media sources that report on data science topics?\n    </span>\n</div>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Getting questions\nq39 = [question for question in questions if 'Q39' in question]\n\nmedia = []\nfor qn in q39:\n    for val in dataprofs[qn].unique():\n        media.append(val)\n        \nmedia = [str.strip(medium).split(\" (\")[0] for medium in media if str(medium)!='nan']\n\nmedia_counts = dataprofs[q39].notnull().sum()\nmedia_counts.index = media \n\nmedia_students_counts = students[q39].notnull().sum()\nmedia_students_counts.index = media\n\nmedia_percentages = media_counts / dataprofs.shape[0]\nmedia_student_percentages = media_students_counts / students.shape[0]\n\n# We pick the top 5 columns\nmedia_index = media_percentages.sort_values(ascending=False).keys()[:5]\n\n# Creating graph\ntrace1 = go.Bar(\n    y = media_index,\n    x = media_percentages[media_index],\n        name = \"<span style='font-family:Tahoma; font-size:17px'>Data professionals</span>\",\n    orientation = \"h\",\n    marker = dict(color = primary_blue),\n    hoverinfo = \"none\",\n    text = np.round(media_percentages[media_index]*100),\n    texttemplate =  \"<b style='color: #fff'>%{text}% </b>\",\n    textposition = \"inside\"\n)\n\ntrace2 = go.Bar(\n    y = media_index,\n    x = media_student_percentages[media_index],\n        name = \"<span style='font-family:Tahoma; font-size:17px'>Students</span>\",\n    orientation = \"h\",\n    marker = dict(color = primary_grey),\n    hoverinfo = \"none\",\n    text = np.round(media_student_percentages[media_index]*100),\n    texttemplate =  \"<b style='color: #fff'>%{text}% </b>\",\n    textposition = \"inside\"\n)\n\nlarge_title_format = \"<span style='font-size:40px; font-family:Times New Roman'>        Media and Learning</span>\"\n\nlayout = dict(\n    title = large_title_format,\n    legend=dict(\n#                 orientation = \"h\",\n                yanchor='top',\n                xanchor='center',\n                y= 1.2,\n                x= 0.75,\n                font=dict(size= 12),\n                traceorder='reversed',\n               ),\n    margin = dict(t=80,pad=10),\n    xaxis= dict(\n            side=\"top\",\n            gridcolor=\"#e7e7e7\",\n            zeroline=True,\n            zerolinewidth=0.5,\n            zerolinecolor=\"#4d4d4d\",\n            tickformat=\"%\",\n            domain=[0,.55]\n    ),\n    yaxis={'categoryorder':'array',\n           'categoryarray': media_percentages.sort_values(ascending=True).keys()\n          },\n    bargap = 0.1,\n    plot_bgcolor = \"#fff\",\n    width = 800\n)\n\ndata = [trace2, trace1]\n\nfig = go.Figure(data = data, layout = layout)\n\nmain_annot_format = \"<span style='font-size:14px; font-family:Tahoma;'></span><span style='font-size:13px; font-family:Tahoma;'><b> %s </b><br> %s</span>\"\n\ntext = 'When asked about how they supplement their <br>machine learning  and  data  science,  <b style=\"font-size:12px\">65%</b> of <br> respondents indicated  that  they used at least <br> one media channel to aid their learning.          '\ntext2 = 'A trend we see is that regardless of the source, <br>professionals  are   more   likely   to   use  it  to<br> learn. <b style=\"font-size:12px\">68% of professionals use at least 2</b> of the <br> sources  in  updating  themselves,  for  students<br> this same statistic is 41%.'\ntext3 = 'With the rapid advances in ML and data science,<br>a lot of <b style=\"font-size:12px\">data professionals are turning to blogs</b><br>to  keep   themselves   informed  about  current<br>news, trends, and  opinions from professionals. '\n\nfig.add_annotation(dict(\n        x=0.775,\n        y=0.88,\n        xref = \"paper\",\n        yref = \"paper\",\n        text= main_annot_format % (\"MEDIA SOURCES FOR LEARNING\",\n                                   text),\n        ax=0, ay=0\n))\n\nfig.add_annotation(dict(\n        x=0.775,\n        y=0.51,\n        xref = \"paper\",\n        yref = \"paper\",\n        text= main_annot_format % (\"PROFESSIONALS LEARN MORE\",\n                                   text2),\n        ax=0, ay=0\n))\n\nfig.add_annotation(dict(\n        x=0.775,\n        y=0.17,\n        xref = \"paper\",\n        yref = \"paper\",\n        text= main_annot_format % (\"BLOGS\",\n                                   text3),\n        ax=0, ay=0\n))\n\niplot(fig)\n\n# Quick one, ~2hr on this graph","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using media is a great way to catch up on trends and updates in our field. They provide information in a **more entertaining and informal manner** that one can always pick up at their own convenience, making them a great way to **supplement our more structured learning activities**. On seeing the trend that professionals seem to utilise more of these, perhaps students might want to look into a couple ML/DS related content creators on their favorite platforms.\n\nOther notable sources that didn't quite make the top 5 here are - **email newsletters, podcasts, slack communities, reddit**, etc."},{"metadata":{},"cell_type":"markdown","source":"## <div class=\"subsection_title\">3.10 Obstacles to working with data </div>\nWhile studying in preparation for working with data we tend to live in this bubble of ours, assuming that things will work out since we probably are qualified enough to work in our field of choice. We often neglect actually getting a sense of how the job market is and what are the struggles faced by those actively hunting for work in the same field.\n\nTo get an idea of the trappings that prevent students from landing that dream data role, we look at Ananconda's report where they asked students what was the biggest factor that prevented them from securing their ideal data science job.\n\n<div class=\"sidenote\">\n    Source: Anaconda's State of DS Report 2020 - \n    <span style=\"font-style: italic;\"> In your opinion, what is the biggest obstacle to obtaining your ideal data science job? \n    </span>\n</div>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Defining the data from Anaconda's report\nproblems_labels = [\"Experience\", \"Technical skills\", \"Soft skills\", \"Finding a job<br>that gives me a<br>sense of purpose\",\"Finding a job<br>that pays enough\",\"Limited job openings\"]\nproblems_percentages = np.float32([.40,.26,.18,.07,.04,.02])\n\ntrace = go.Bar(\n    y = problems_percentages,\n    x = problems_labels,\n    marker = dict(color = [primary_blue]+[primary_grey]*5),\n    text = [str(text)+\" %\" for text in np.int32(problems_percentages*100)],\n    textfont = dict(size = 15),\n    textposition = \"outside\",\n    width = 0.95\n)\n\nlayout = dict(\n    margin = dict(t=20,b=0, pad=5),\n    yaxis=dict(\n            showticklabels = False,\n            zeroline=True,\n            zerolinewidth=1,\n            zerolinecolor=\"#4d4d4d\",\n            ),\n    xaxis = dict(\n            tickangle = 0,\n            tickfont = dict(family=\"Tahoma\",size=11),\n            \n            ),\n    width = 750,\n    height= 450,\n    plot_bgcolor = \"#fff\"\n)\n\nlarge_title_format = \"<span style='font-size:32px; font-family:Times New Roman;'>Biggest obstacle to obtaining your<br><br>ideal data science job?</span>\"\nsmall_title_format = \"<span style='font-size:13px; font-family:Helvetica'>  Rather than limited job opportunities, most students responded<br>      that their main reason for not landing their ideal job was their<br><b style='color:#496595'>lack of experience and technical ability.</b>      </span>\"\n\nfig = go.Figure(data = trace, layout = layout)\n\n# title annotation\nfig.add_annotation(dict(\n                            x=3.0,\n                            y=0.33,\n                            showarrow=False,\n                            text= large_title_format + \"<br><br>\" + small_title_format,\n                            textangle=0,\n                            xref=\"x\",\n                            yref=\"y\"\n                           ))\n\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I initially expected that a lack of job openings would be a major factor, but turns out that this was hardly the case. Most students claimed that their reason for not securing their ideal job was that they **lacked the experience** for it. Often this will be due to companies asking for \"*x years of experience in...*\" which will turn away most students early in their careers, otherwise it might be experience working in a particular field or with specific tools.<br>  While there may be no direct workaround for this, **seeking internships** in a related area of work would go a long way as initial work experience. Data science **side-projects** are also a great way to showcase your ability, so long as the content is novel and well-thought out."},{"metadata":{},"cell_type":"markdown","source":"# <div class=\"section_title\">4. So you want to work in..?</div>\n\nIn this section I'll be going over some of the different areas of machine learning, namely - Computer Vision, Natural Language Processing and machine learning for analytics in general. Each domain has its own specialists and methods specific to them and I will briefly try to shed some light on these fields.\n\n"},{"metadata":{},"cell_type":"markdown","source":"## <div class=\"subsection_title\">4.1 Computer Vision</div>\nIn computer vision the main aim is to help machines develop a higher understanding of image or video data. In essence it seeks to automate (or improve) any task which otherwise relies on human vision.\n<div class=\"sidenote\">\n    Source: Kaggle 2020 DS and ML Survey \n</div>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"q18  = [question for question in questions if \"Q18\" in question]\nq18_not_none = q18[:5] + [q18[6]]\n\ncv_users = dataprofs[dataprofs[q18_not_none].notnull().sum(axis=1) >=1 ]\ncv_fields = cv_users[\"Q5\"].value_counts() / cv_users.shape[0]\n\n# Creating dataframe for computer vision fields \ncv_fields_df = pd.DataFrame()\ncv_fields_df[\"field\"] = cv_fields.index[:6]\ncv_fields_df[\"value\"] = cv_fields.values[:6] * 100\ncv_fields_df[\"field\"].replace([\"Machine Learning Engineer\"],[\"ML Engineer\"], inplace=True)\n\ncv_fields_df.to_csv(\"cv_fields.csv\", index=False, header=[\"field\",\"value\"])\n\n# Creating dataframe for computer vision tools\ncvtools = []\nfor qn in q18:\n    for val in dataprofs[qn].unique():\n        cvtools.append(val)\n        \ncvtools = [str.strip(cvtool) for cvtool in cvtools if str(cvtool)!='nan']\ncvtools[3] = \"General purpose networks (VGG, Inception, ResNet, etc.)\"\ncvtools_counts = cv_users[q18].count()\n\ncvtools_df = pd.DataFrame(columns=[\"name\",\"value\"])\ncvtools_df[\"name\"] = cvtools[:5] + [cvtools[6]]\ncvtools_df[\"value\"] = cvtools_counts.drop([\"Q18_Part_6\"]).values\n\ncvtools_df.to_csv(\"cv_tools.csv\", index=False, header=[\"name\",\"value\"])\n\n# We do something different this time around to create subplots\n# The javascript from later cells are able to access HTML elements from this cell\n# So we just create the HTML elements used in the later cells, here and it will display them all as though they were in the same graph\n# The only downside is that running the later graphs multiple times causes the graph to show multiple times here, just rerun this cell and then the later ones in that case.\n\nhtmlt1 = '''\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Document</title>\n    <style>\n        #cv_fields{\n            display: inline-block;\n            border: 1px solid #d7d7d7;\n            width: 350px;\n            box-shadow: 2px 2px 2px 1px rgba(0,0,0,0.3); \n        }\n        #cv_tools{\n            display: inline-block;\n            margin-left: 10px;\n            border: 1px solid #d7d7d7;\n            width: 350px;\n            box-shadow: 2px 2px 2px 1px rgba(0,0,0,0.3); \n        }\n    </style>\n</head>\n\n<body>    \n    <!-- Create a div where the graph will take place -->\n    <div id=\"cv_fields\"></div>\n    <div id=\"cv_tools\"></div>\n    <br>\n    <div id=\"cv_tree\">\n    <button id=\"tree_button1\">count</button>\n    <button id=\"tree_button2\">average salary (USD)</button>\n    </div>    \n    <br>\n    <div id=\"cv_heatmap\"></div>\n    <div id=\"cv_mlexp\"></div>\n    \n</body>\n</html>'''\n\njs_t1 = '''\n         require.config({\n            paths: {\n                d3: \"https://d3js.org/d3.v4.min\"\n             }\n             });\n        require([\"d3\"], function(d3) {\n        \n        // set the dimensions and margins of the graph\n        var margin = {top: 40, right: 20, bottom: 40, left: 98},\n            width = 350 - margin.left - margin.right,\n            height = 340 - margin.top - margin.bottom;\n        \n        // append the svg_fields object to the body of the page\n        var svg_fields = d3.select(\"#cv_fields\")\n          .append(\"svg\")\n            .attr(\"width\", width + margin.left + margin.right)\n            .attr(\"height\", height + margin.top + margin.bottom)\n          .append(\"g\")\n            .attr(\"transform\",\n                  \"translate(\" + margin.left + \",\" + margin.top + \")\");\n\n        svg_fields.append(\"text\")\n            .text(\"Percentage of Computer Vision users\")\n            .attr(\"x\",-80)\n            .attr(\"y\",-15)\n            .style(\"font-family\", \"Times New Roman\")\n            .style(\"font-size\", \"20px\")\n\n        // Parse the Data\n        d3.csv(\"cv_fields.csv\", function(data) {\n        \n        var max = d3.max(data, d=> +d.value)\n          // Add X axis\n          var x = d3.scaleLinear()\n            .domain([0, 32])\n            .range([ 0, width]);\n          svg_fields.append(\"g\")\n            .attr(\"transform\", \"translate(0,\" + height + \")\")\n            .call(d3.axisBottom(x))\n            .selectAll(\"text\")\n            //   .attr(\"transform\", \"translate(-10,0)rotate(-45)\")\n              .style(\"text-anchor\", \"end\");\n        \n            // Y axis\n            var y = d3.scaleBand()\n                .range([ 0, height ])\n                .domain(data.map(function(d) { return d.field; }))\n                .padding(.1);\n            svg_fields.append(\"g\")\n                .call(d3.axisLeft(y))\n        \n             //Bars\n            svg_fields.selectAll(\"myRect\")\n                .data(data)\n                .enter()\n                .append(\"rect\")\n                .attr(\"x\", x(0) )\n                .attr(\"y\", function(d) { return y(d.field); })\n                .attr(\"width\", function(d) { return x(d.value); })\n                .attr(\"height\", y.bandwidth() )\n                .attr(\"fill\", (d) => { return (+d.value == max? \"#3f4d63\": \"#c6ccd8\") } )\n        })\n\n        var margin_tools = {top: 40, right: 20, bottom: 40, left: 20},\n            width_tools = 350 - margin_tools.left - margin_tools.right,\n            height_tools = 340 - margin_tools.top - margin_tools.bottom;\n\n        var svg_tools = d3.select(\"#cv_tools\")\n            .append(\"svg\")\n                .attr(\"width\", width_tools + margin_tools.left + margin_tools.right)\n                .attr(\"height\", height_tools + margin_tools.top + margin_tools.bottom)\n            .append(\"g\")\n                .attr(\"transform\",\n                    \"translate(\" + margin_tools.left + \",\" + margin_tools.top + \")\");\n        \n        svg_tools.append(\"text\")\n            .text(\"Most used Computer Vision Methods\")\n            .attr(\"x\",0)\n            .attr(\"y\",-15)\n            .style(\"font-family\", \"Times New Roman\")\n            .style(\"font-size\", \"21px\")            \n\n        d3.csv(\"cv_tools.csv\", function(data) {\n\n            data = data.sort((a,b) => d3.descending(+a.value, +b.value))\n            var max = d3.max(data, d=> +d.value)\n            // Add X axis\n            var x = d3.scaleLinear()\n                .domain([0, 2200])\n                .range([ 0, width_tools]);\n                svg_tools.append(\"g\")\n                    .attr(\"transform\", \"translate(0,\" + height_tools + \")\")\n                    .call(d3.axisBottom(x))\n                    .selectAll(\"text\")\n                        .attr(\"transform\", \"translate(-10,0)\")\n                        .style(\"text-anchor\", \"end\");\n\n\n            // Y axis\n            var y = d3.scaleBand()\n            .range([ 0, height_tools ])\n            .domain(data.map(function(d) { return d.name; }))\n            .padding(.55);\n            svg_tools.append(\"g\")\n            .call(d3.axisLeft(y))\n                .selectAll(\"text\")\n                .attr(\"text-anchor\", \"start\")\n                .attr(\"transform\", \"translate(14,-16)\")\n                .style(\"font-family\", \"Tahoma\")\n                .style(\"font-size\", \"11px\")\n\n            //Bars\n            svg_tools.selectAll(\"myRect\")\n            .data(data)\n            .enter()\n            .append(\"rect\")\n            .attr(\"x\", x(0) )\n            .attr(\"y\", function(d) { return y(d.name); })\n            .attr(\"width\", function(d) { return x(d.value); })\n            .attr(\"height\", y.bandwidth() )\n            .attr(\"fill\", (d) => { return (+d.value == max? \"#3f4d63\": \"#c6ccd8\") }) //e9cf87\n            })\n});\n'''\n\n\nh = display(HTML(htmlt1))\n\nj = IPython.display.Javascript(js_t1)\nIPython.display.display_javascript(j)\n\n# ~3-4hrs on this one\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# ~2hrs\n\n# Creating heatmap data csv for CV users' team sizes\ncv_heatmap_data = cv_users.groupby([\"Q20\"])[\"Q21\"].value_counts()\n\ncv_heatmap_df = pd.DataFrame()\nfor cosize in dataprofs[\"Q20\"].unique():\n    cv_heatmap_df[cosize] = cv_heatmap_data[cosize]\n\ncv_heatmap_df.columns = [col.split(\" employees\")[0] for col in cv_heatmap_df.columns]\n\ncv_data_list = []\nfor cosize in cv_heatmap_df.columns:\n    for dssize in cv_heatmap_df.index:\n        cv_data_list.append([cosize, dssize, cv_heatmap_df[cosize].loc[dssize]])\n        \ncv_data_df =  pd.DataFrame(cv_data_list)\n\ncv_data_df.to_csv(\"cv_heatmap.csv\", index=False, header=[\"cosize\",\"dssize\",\"value\"])\n\n# Creating csv for machine learning experience bar chart\n\ncv_mlexp = cv_users[\"Q15\"].value_counts().sort_values(ascending=False)\n\n# Renaming the indexes and then reordering them (there are easier ways to do this though)\ncv_mlexp.index = [x+\" years\" for x in['1-2', '2-3', '0-1', '5-10', '3-4', '4-5', '10-20', '20+']]\ncv_mlexp = cv_mlexp.reindex(x+\" years\" for x in['0-1', '1-2', '2-3', '3-4', '4-5', '5-10', '10-20', '20+'])\n\ncv_mlexp_df = pd.DataFrame()\ncv_mlexp_df[\"exp\"] = cv_mlexp.index\ncv_mlexp_df[\"value\"] = cv_mlexp.values\n\ncv_mlexp_df.to_csv(\"cv_mlexp.csv\", index=False, header=[\"exp\",\"value\"])\n\nhtmlt1 = '''\n<html lang=\"en\">\n<head>\n    <title>Document</title>\n    <style>\n        #cv_heatmap{\n            display: inline-block;\n            border: 1px solid #d7d7d7;\n            width: 350px;\n            box-shadow: 2px 2px 2px 1px rgba(0,0,0,0.3); \n        }\n        #cv_mlexp{\n            display: inline-block;\n            margin-left: 10px;\n            border: 1px solid #d7d7d7;\n            width: 350px;\n            box-shadow: 2px 2px 2px 1px rgba(0,0,0,0.3); \n        }\n    </style>\n</head>\n<body>\n<!--\n<div id=\"cv_heatmap\"></div>\n<div id=\"cv_mlexp\"></div>\n-->\n</body>\n</html>'''\n\njs_t1 = '''\n         require.config({\n            paths: {\n                d3: \"https://d3js.org/d3.v4.min\"\n             }\n             });\n        require([\"d3\"], function(d3) {\n        \n        var margin_heatmap = {top: 33, right: 15, bottom: 40, left: 60},\n        width_heatmap = 350 - margin_heatmap.left - margin_heatmap.right,\n        height_heatmap = 340 - margin_heatmap.top - margin_heatmap.bottom;\n        \n        // append the svg object to the body of the page\n        var svg_heatmap = d3.selectAll(\"#cv_heatmap\")\n        .append(\"svg\")\n        .attr(\"width\", width_heatmap + margin_heatmap.left + margin_heatmap.right)\n        .attr(\"height\", height_heatmap + margin_heatmap.top + margin_heatmap.bottom)\n        .append(\"g\")\n        .attr(\"transform\",\n                \"translate(\" + margin_heatmap.left + \",\" + margin_heatmap.top + \")\");\n        \n        // add title\n        svg_heatmap.append(\"text\")\n            .text(\"Company and DS team sizes\")\n            .attr(\"x\",0)\n            .attr(\"y\",-10)\n            .style(\"font-family\", \"Times New Roman\")\n            .style(\"font-size\", \"21px\") \n\n        svg_heatmap.append(\"text\")\n            .text(\"Company size (employees)\")\n            .attr(\"x\", width_heatmap/2)\n            .attr(\"y\", height_heatmap + 32)\n            .attr(\"text-anchor\",\"middle\")\n            .style(\"font-weight\",\"600\")\n            .style(\"font-family\", \"Tahoma\")\n            .style(\"font-size\", \"12px\")\n        \n        svg_heatmap.append(\"text\")\n            .attr(\"transform\", \"rotate(-90)\")\n            .attr(\"y\", 0 - margin_heatmap.left + 6)\n            .attr(\"x\",0 - (height_heatmap / 2))\n            .attr(\"dy\", \"1em\")\n            .style(\"text-anchor\", \"middle\")\n            .style(\"font-weight\",\"600\")\n            .style(\"font-family\", \"Tahoma\")\n            .style(\"font-size\", \"13px\") \n            .text(\"Data Science team size\");  \n                        \n        // Labels of row and columns\n        var myGroups = ['0-49', '50-249', '250-999', '1000-9,999', '10,000 or more']\n        var myVars = ['0', '1-2', '3-4', '5-9', '10-14', '15-19', '20+']\n        \n        // Build X scales and axis:\n        var x = d3.scaleBand()\n        .range([ 0, width_heatmap ])\n        .domain(myGroups)\n        .padding(0.01);\n        svg_heatmap.append(\"g\")\n        .attr(\"transform\", \"translate(0,\" + height_heatmap + \")\")\n        .call(d3.axisBottom(x))\n        .selectAll(\"text\")\n            .style(\"font-size\",\"9px\")\n        \n        // Build X scales and axis:\n        var y = d3.scaleBand()\n        .range([ height_heatmap, 0 ])\n        .domain(myVars)\n        .padding(0.01);\n        svg_heatmap.append(\"g\")\n        .call(d3.axisLeft(y));\n        \n        // Build color scale\n        var myColor = d3.scaleLinear()\n        .range([\"#f7f7f7\", \"#29658c\"]) //e9cf87\n        .domain([1,300])\n        \n        //Read the data\n        d3.csv(\"cv_heatmap.csv\", function(data) {\n        \n        svg_heatmap.selectAll()\n            .data(data)\n            .enter()\n            .append(\"rect\")\n            .attr(\"x\", function(d) { return x(d.cosize) })\n            .attr(\"y\", function(d) { return y(d.dssize) })\n            .attr(\"width\", x.bandwidth() )\n            .attr(\"height\", y.bandwidth() )\n            .style(\"fill\", function(d) { return myColor(d.value)} )\n        \n        })\n\n        var margin_mlexp = {top: 35, right: 20, bottom: 40, left: 70},\n            width_mlexp  = 350 - margin_mlexp.left - margin_mlexp.right,\n            height_mlexp = 340 - margin_mlexp.top - margin_mlexp.bottom;\n\n        var svg_mlexp = d3.selectAll(\"#cv_mlexp\")\n            .append(\"svg\")\n                .attr(\"width\", width_mlexp + margin_mlexp.left + margin_mlexp.right)\n                .attr(\"height\", height_mlexp + margin_mlexp.top + margin_mlexp.bottom)\n            .append(\"g\")\n                .attr(\"transform\",\n                    \"translate(\" + margin_mlexp.left + \",\" + margin_mlexp.top + \")\");\n        \n        svg_mlexp.append(\"text\")\n            .text(\"Machine Learning experience\")\n            .attr(\"x\",-5)\n            .attr(\"y\",-10)\n            .style(\"font-family\", \"Times New Roman\")\n            .style(\"font-size\", \"21px\")\n            \n        svg_mlexp.append(\"text\")\n            .text(\"Respondent's count\")\n            .attr(\"x\", width_heatmap/2 - 10)\n            .attr(\"y\", height_heatmap + 32)\n            .attr(\"text-anchor\",\"middle\")\n            .style(\"font-weight\",\"600\")\n            .style(\"font-family\", \"Tahoma\")\n            .style(\"font-size\", \"12px\")\n\n        d3.csv(\"cv_mlexp.csv\", function(data) {\n\n            // data = data.sort((a,b) => d3.descending(+a.value, +b.value))\n            var max = d3.max(data, d=> +d.value)\n            // Add X axis\n            var x = d3.scaleLinear()\n                .domain([0, 800])\n                .range([ 0, width_mlexp]);\n            svg_mlexp.append(\"g\")\n                .attr(\"transform\", \"translate(0,\" + height_mlexp + \")\")\n                .call(d3.axisBottom(x))\n                .selectAll(\"text\")\n                    .attr(\"transform\", \"translate(-10,0)\")\n                    .style(\"text-anchor\", \"end\");\n\n            // Y axis\n            var y = d3.scaleBand()\n            .range([ 0, height_mlexp ])\n            .domain(data.map(function(d) { return d.exp; }))\n            .padding(.05);\n            svg_mlexp.append(\"g\")\n            .call(d3.axisLeft(y))\n                .selectAll(\"text\")\n                // .attr(\"text-anchor\", \"start\")\n                // .attr(\"transform\", \"translate(14,-16)\")\n                .style(\"font-family\", \"Tahoma\")\n                .style(\"font-size\", \"11px\")\n\n            // Bars\n            svg_mlexp.selectAll(\"myRect\")\n            .data(data)\n            .enter()\n            .append(\"rect\")\n                .attr(\"x\", x(0) )\n                .attr(\"y\", function(d) { return y(d.exp); })\n                .attr(\"width\", function(d) { return x(d.value); })\n                .attr(\"height\", y.bandwidth() )\n                .attr(\"fill\", (d) => { return (+d.value == max? \"#3f4d63\": \"#c6ccd8\") })\n            })\n});\n'''\n\n\nh = display(HTML(htmlt1))\n\nj = IPython.display.Javascript(js_t1)\nIPython.display.display_javascript(j)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# Top 10 countries by count along with their salaries .~2hrs on this graph\n\n# Will let us pick how many countries to consider.\ncutoff = 10\ncountries = list( cv_users[\"Q3\"].value_counts().index[:cutoff] )\ncountries_count = cv_users[\"Q3\"].value_counts()[countries]\n\n# Drop all individuals that didnt mention salary\ncv_users_with_salary = cv_users.dropna(subset = [\"Q24\"])\n\ncv_users_with_salary[\"Q24_amounts\"] = [(earnings_map[payrange]) for payrange in cv_users_with_salary[\"Q24\"]]\nsalary_data = np.int32(cv_users_with_salary.groupby([\"Q3\"])[\"Q24_amounts\"].mean()[countries])\n\n# Creating the dataframe\ncv_tree_df = pd.DataFrame(columns=[\"name\",\"parent\",\"value\",\"value2\"])\ncv_tree_df.loc[0] = [\"Origin\",\"\",\"\",\"\"]\n\ncv_tree_temp = pd.DataFrame(columns=[\"name\",\"parent\",\"value\",\"value2\"])\n\ncv_tree_temp[\"value\"] = cv_users[\"Q3\"].value_counts()[countries].values\ncv_tree_temp[\"value2\"]= salary_data\ncv_tree_temp[\"parent\"]= \"Origin\"\n\n# Editing label names\ncountries_new = countries\ncountries_new[7] = \"United Kingdom\"\ncv_tree_temp[\"name\"] = countries_new\n\ncv_tree_df = cv_tree_df.append(cv_tree_temp, ignore_index = True)\ncv_tree_df.to_csv(\"cv_tree.csv\", index=False, header=[\"name\",\"parent\",\"value\",\"value2\"])\n\nhtmlt1 = '''\n<html lang=\"en\">\n<head>\n    <title>Document</title>\n    <style>\n        #cv_tree{\n            display: inline-block;\n            margin: 10px 0px;\n            border: 1px solid #d7d7d7;\n            width: 714px;\n            box-shadow: 2px 2px 2px 1px rgba(0,0,0,0.3); \n        }\n        #tree_button1{\n            border-radius: 0;\n            background-color: #fff;\n            border: 1px solid #d7d7d7;\n            position: relative;\n            top:  5px;\n            width: 75px;\n            left: 621px;\n            color: #000;\n        }\n        #tree_button2{\n            border-radius: 0;\n            background-color: #fff;\n            border: 1px solid #d7d7d7;\n            position: relative;\n            top:  5px;\n            left: 373px;\n            color: #000;\n        }\n\n        #tree_button1:hover, #tree_button2:hover{\n            background-color: #d7d7d7;\n        }\n        #tree_button1:focus, #tree_button2:focus{\n            outline: none;\n            background-color: #4d4d4d;\n            color: #fff;\n        }\n\n    </style>\n</head>\n<body>\n    <!--\n    <div id=\"cv_tree\">\n    <button id=\"tree_button1\">count</button>\n    <button id=\"tree_button2\">average salary (USD)</button>\n    </div>\n    -->\n</body>\n</html>'''\n\njs_t1 = '''\n         require.config({\n            paths: {\n                d3: \"https://d3js.org/d3.v4.min\"\n             }\n             });\n        require([\"d3\"], function(d3) {\n        \n         var margin_tree = {top: 20, right: 10, bottom: 5, left: 10},\n            width_tree = 710 - margin_tree.left - margin_tree.right,\n            height_tree = 340 - margin_tree.top - margin_tree.bottom;\n        \n        // append the svg object to the body of the page\n        var svg_tree = d3.selectAll(\"#cv_tree\")\n        .append(\"svg\")\n            .attr(\"width\", width_tree + margin_tree.left + margin_tree.right)\n            .attr(\"height\", height_tree + margin_tree.top + margin_tree.bottom)\n        .append(\"g\")\n            .attr(\"transform\", \"translate(\" + margin_tree.left + \",\" + margin_tree.top + \")\");\n        \n        showData(\"count\")\n        document.getElementById(\"tree_button1\").addEventListener(\"click\", function(evt) {showData(\"count\")});\n        document.getElementById(\"tree_button2\").addEventListener(\"click\", function(evt) {showData(\"salary\")});\n\n        function showData(mode){\n        // Read data\n        \n        d3.csv('cv_tree.csv', function(data) {\n        var max = d3.max(data, (d)=> {return mode ==\"count\"?  +d.value: +d.value2;})\n       \n        var colorScale1 = d3.scaleLinear()\n        .range([\"#f1efd9\",\"#AF9973\",\"#a2885e\"]) //[\"#a2885e\",\"#f1efd9\",\"#235f83\"]\n        .domain([40,max/6, max])\n\n        var colorScale2 = d3.scaleLinear()\n        .range([\"#f1efd9\",\"#457791\",\"#235f83\"]) //[\"#a2885e\",\"#f1efd9\",\"#235f83\"]\n        .domain([5000,max/2, max])\n\n          // stratify the data: reformatting for d3.js\n        var root = d3.stratify()\n            .id(function(d) { return d.name; })   // Name of the entity (column name is name in csv)\n            .parentId(function(d) { return d.parent; })   // Name of the parent (column name is parent in csv)\n            (data);\n        root.sum(function(d) {return mode ==\"count\"?  +d.value: +d.value2; })   // Compute the numeric value for each entity\n        \n          // Then d3.treemap computes the position of each element of the hierarchy\n          // The coordinates are added to the root object above\n        d3.treemap()\n            .size([width_tree, height_tree])\n            .padding(4)\n            (root)\n\n        var u = svg_tree\n            .selectAll(\"rect\")\n            .data(root.leaves())\n            \n            u\n            .enter()\n            .append(\"rect\")\n            .merge(u)\n            .transition()\n            .duration(1000)\n            .attr('x', function (d) { return d.x0; })\n            .attr('y', function (d) { return d.y0; })\n            .attr('width', function (d) { return d.x1 - d.x0; })\n            .attr('height', function (d) { return d.y1 - d.y0; })\n            .style(\"stroke\", \"black\")\n            .style(\"fill\", (d) => {\n                return (mode ==\"count\"?  colorScale1(+d.value): colorScale2(+d.value))\n            });\n    \n        // and to add the text labels\n        var v = svg_tree\n            .selectAll(\"text\")\n            .data(root.leaves())\n\n            v\n            .enter()\n            .append(\"text\")\n            .merge(v)\n                .attr(\"x\", function(d){ return d.x0+10})    // +10 to adjust position (more right)\n                .attr(\"y\", function(d){ return d.y0+15})    // +20 to adjust position (lower)\n                .text(function(d){ return d.data.name})\n                .attr(\"font-size\", \"15px\")\n                .attr(\"fill\", \"white\")\n        \n        var w = svg_tree\n            .selectAll(\"text.count\")\n            .data(root.leaves())\n\n            w\n            .enter()\n            .append(\"text\")\n            .merge(w)\n                .attr(\"class\", function(d){ return \"count \"+d.data.name})\n                .attr(\"x\", function(d){ return (d.x1+d.x0)/2 })    // +10 to adjust position (more right)\n                .attr(\"y\", function(d){ return (d.y1+d.y0)/2 + 15})    // +20 to adjust position (lower)\n                .text(function(d){ return mode == \"count\"? d.data.value: (d.data.value2.replace(/\\B(?=(\\d{3})+(?!\\d))/g, \",\"));})\n                .attr(\"text-anchor\",\"middle\")\n                .style(\"font-size\", function(d){ \n                    return mode == \"count\"? \"30px\" : \"22px\";\n                })\n                .attr(\"fill\", \"white\")\n                .style(\"font-family\", \"Arial\")\n        \n        svg_tree\n            .append(\"text\")\n            .attr(\"class\",\"title\")\n            .text(\"Top Countries and their Salaries\")\n            .attr(\"x\", 5)\n            .attr(\"y\",-5)\n            .style(\"font-family\", \"Times New Roman\")\n            .style(\"font-size\", \"21px\")\n        })\n    }\n\n});\n'''\n\nh = display(HTML(htmlt1))\n\nj = IPython.display.Javascript(js_t1)\nIPython.display.display_javascript(j)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Data Scientists and Machine Learning Engineers** form the bulk of the group using computer vision methods.\n* The majority of respondents have **1-2 years of machine learning experience**. \n* It seems that gaining a **strong foundation in the working of general purpose networks** like VGG, ResNet, etc is important in this field. Familiarising one's self with image processing tools might also be beneficial in the long run.\n* Even though countries in Asia have larger counts of these professionals, **pays are higher in USA and European nations**(note that these aren't factoring in cost of living in these countries).\n* While the majority work in companies with less than 50 employees, it's also **common to find work in large companies with 10,000+ employees and large data science teams**. \n\n## <div class=\"subsection_title\"> What do they do?</div>\n\n<div class=\"sidenote\">\n    Source: Kaggle 2020 DS and ML Survey - \n    <span style=\"font-style: italic;\"> Q23. Select any activities that make up an important part of your role at work.\n    </span>\n</div>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# This will generate the json data for the d3 graphs\ndef get_radar_data(dataframe):\n    temp = dataframe[q23].count()\n    \n    #Remove \"none\" label\n    temp.index = labels[:-1]\n\n    temp = temp/dataframe.shape[0]\n\n    l1 = []\n    for label in labels[:-1]:\n        record = {}\n        record[\"axis\"] = label\n        record[\"value\"]= temp[label]\n        l1.append(record)\n    return l1\n\ndataprofs_radar = get_radar_data(dataprofs)\ncv_users_radar = get_radar_data(cv_users)\n\n# The code for this radar chart in d3 was by Nadieh Bremer(linked in references), with minor tweaks to get it working in the kaggle notebook \nhtmlt1 = '''\n<html>\n\t<head>\n\n        <!-- Google fonts -->\n        <link href=\"https://fonts.googleapis.com/css?family=Open+Sans:400,300\" rel='stylesheet' type='text/css'>\n        <link href='https://fonts.googleapis.com/css?family=Raleway' rel='stylesheet' type='text/css'>\n\n        <style>\n            body .radarChart_cv{\n                font-family: 'Open Sans', sans-serif;\n                font-size: 11px;\n                font-weight: 300;\n                fill: #242424;\n                text-align: center;\n                text-shadow: 0 1px 0 #fff, 1px 0 0 #fff, -1px 0 0 #fff, 0 -1px 0 #fff;\n                cursor: default;\n                width: 400px;\n                height: 400px;\n                padding: 10px 0px;\n                border: 1px solid #d7d7d7;\n                box-shadow: 2px 2px 2px 1px rgba(0,0,0,0.3);\n                margin: auto;\n            }\n\n            .radarChart_cv h2{\n                font-family: 'Open Sans', sans-serif;\n                font-size: 20px;\n                font-weight: 600;\n                fill: #242424;\n                text-align: center;\t\t\t\t\t\n            }\n\n            .radarChart_cv .legend {\n                font-family: 'Raleway', sans-serif;\n                fill: #333333;\n            }\n\n            .radarChart_cv .tooltip {\n                fill: #333333;\n            }\n        </style>\n    </head>\n    <body>\n        <div class=\"radarChart_cv\">\n            <h2>Roles in <span style=\"color:#496595\">Computer Vision</span> vs <span style=\"color:#bbb\">others</span></h2>\n        </div>\n    </body>\n'''\n\njs_t1 = '''\n         require.config({\n            paths: {\n                d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\"\n             }\n             });\n        require([\"d3\"], function(d3) {\n        \n         function RadarChart(id, data, options) {\n\tvar cfg = {\n\t w: 600,\t\t\t\t//Width of the circle\n\t h: 600,\t\t\t\t//Height of the circle\n\t margin: {top: 20, right: 20, bottom: 20, left: 20}, //The margins of the SVG\n\t levels: 3,\t\t\t\t//How many levels or inner circles should there be drawn\n\t maxValue: 0, \t\t\t//What is the value that the biggest circle will represent\n\t labelFactor: 1.26, \t//How much farther than the radius of the outer circle should the labels be placed\n\t wrapWidth: 60, \t\t//The number of pixels after which a label needs to be given a new line\n\t opacityArea: 0.35, \t//The opacity of the area of the blob\n\t dotRadius: 3, \t\t\t//The size of the colored circles of each blog\n\t opacityCircles: 0.1, \t//The opacity of the circles of each blob\n\t strokeWidth: 1, \t\t//The width of the stroke around each blob\n\t roundStrokes: false,\t//If true the area and stroke will follow a round path (cardinal-closed)\n\t color: d3.scaleOrdinal().range([\"#bbb\",\"#496595\"])\t//Color function\n\t};\n\t\n\t//Put all of the options into a variable called cfg\n\tif('undefined' !== typeof options){\n\t  for(var i in options){\n\t\tif('undefined' !== typeof options[i]){ cfg[i] = options[i]; }\n\t  }//for i\n\t}//if\n\t\n\t//If the supplied maxValue is smaller than the actual one, replace by the max in the data\n\tvar maxValue = Math.max(cfg.maxValue, d3.max(data, function(i){return d3.max(i.map(function(o){return o.value;}))}));\n\t\t\n\tvar allAxis = (data[0].map(function(i, j){return i.axis})),\t//Names of each axis\n\t\ttotal = allAxis.length,\t\t\t\t\t//The number of different axes\n\t\tradius = Math.min(cfg.w/2, cfg.h/2), \t//Radius of the outermost circle\n\t\tFormat = d3.format('.0%'),\t\t\t \t//Percentage formatting\n\t\tangleSlice = Math.PI * 2 / total;\t\t//The width in radians of each \"slice\"\n\t\n\t//Scale for the radius\n\tvar rScale = d3.scaleLinear()\n\t\t.range([0, radius])\n\t\t.domain([0, maxValue]);\n\t\t\n\t/////////////////////////////////////////////////////////\n\t//////////// Create the container SVG and g /////////////\n\t/////////////////////////////////////////////////////////\n\n\t//Remove whatever chart with the same id/class was present before\n\td3.select(id).select(\"svg\").remove();\n\t\n\t//Initiate the radar chart SVG\n\tvar svg = d3.select(id).append(\"svg\")\n\t\t\t.attr(\"width\",  cfg.w + cfg.margin.left + cfg.margin.right)\n\t\t\t.attr(\"height\", cfg.h + cfg.margin.top + cfg.margin.bottom)\n\t\t\t.attr(\"class\", \"radar\"+id);\n\t//Append a g element\t\t\n\tvar g = svg.append(\"g\")\n\t\t\t.attr(\"transform\", \"translate(\" + (cfg.w/2 + cfg.margin.left) + \",\" + (cfg.h/2 + cfg.margin.top) + \")\");\n\t\n\t/////////////////////////////////////////////////////////\n\t////////// Glow filter for some extra pizzazz ///////////\n\t/////////////////////////////////////////////////////////\n\t\n\t//Filter for the outside glow\n\tvar filter = g.append('defs').append('filter').attr('id','glow'),\n\t\tfeGaussianBlur = filter.append('feGaussianBlur').attr('stdDeviation','2.5').attr('result','coloredBlur'),\n\t\tfeMerge = filter.append('feMerge'),\n\t\tfeMergeNode_1 = feMerge.append('feMergeNode').attr('in','coloredBlur'),\n\t\tfeMergeNode_2 = feMerge.append('feMergeNode').attr('in','SourceGraphic');\n\n\t/////////////////////////////////////////////////////////\n\t/////////////// Draw the Circular grid //////////////////\n\t/////////////////////////////////////////////////////////\n\t\n\t//Wrapper for the grid & axes\n\tvar axisGrid = g.append(\"g\").attr(\"class\", \"axisWrapper\");\n\t\n\t//Draw the background circles\n\taxisGrid.selectAll(\".levels\")\n\t   .data(d3.range(1,(cfg.levels+1)).reverse())\n\t   .enter()\n\t\t.append(\"circle\")\n\t\t.attr(\"class\", \"gridCircle\")\n\t\t.attr(\"r\", function(d, i){return radius/cfg.levels*d;})\n\t\t.style(\"fill\", \"#fff\")\n\t\t.style(\"stroke\", \"#dedede\")\n\t\t.style(\"fill-opacity\", cfg.opacityCircles)\n\t\t.style(\"filter\" , \"url(#glow)\");\n\n\t//Text indicating at what % each level is\n\taxisGrid.selectAll(\".axisLabel\")\n\t   .data(d3.range(1,(cfg.levels+1)).reverse())\n\t   .enter().append(\"text\")\n\t   .attr(\"class\", \"axisLabel\")\n\t   .attr(\"x\", 4)\n\t   .attr(\"y\", function(d){return -d*radius/cfg.levels;})\n\t   .attr(\"dy\", \"0.4em\")\n\t   .style(\"font-size\", \"10px\")\n\t   .attr(\"fill\", \"#737373\")\n\t   .text(function(d,i) { return Format(maxValue * d/cfg.levels); });\n\n\t/////////////////////////////////////////////////////////\n\t//////////////////// Draw the axes //////////////////////\n\t/////////////////////////////////////////////////////////\n\t\n\t//Create the straight lines radiating outward from the center\n\tvar axis = axisGrid.selectAll(\".axis\")\n\t\t.data(allAxis)\n\t\t.enter()\n\t\t.append(\"g\")\n\t\t.attr(\"class\", \"axis\");\n\t//Append the lines\n\taxis.append(\"line\")\n\t\t.attr(\"x1\", 0)\n\t\t.attr(\"y1\", 0)\n\t\t.attr(\"x2\", function(d, i){ return rScale(maxValue*1.05) * Math.cos(angleSlice*i - Math.PI/2); })\n\t\t.attr(\"y2\", function(d, i){ return rScale(maxValue*1.05) * Math.sin(angleSlice*i - Math.PI/2); })\n\t\t.attr(\"class\", \"line\")\n\t\t.style(\"stroke\", \"#333\")\n\t\t.style(\"stroke-width\", \"1px\");\n\n\t//Append the labels at each axis\n\taxis.append(\"text\")\n\t\t.attr(\"class\", \"legend\")\n\t\t.style(\"font-size\", \"10px\")\n\t\t.attr(\"text-anchor\", \"middle\")\n\t\t.attr(\"dy\", \"-1em\")\n\t\t.attr(\"x\", function(d, i){ return rScale(maxValue * cfg.labelFactor) * Math.cos(angleSlice*i - Math.PI/2); })\n\t\t.attr(\"y\", function(d, i){ return rScale(maxValue * cfg.labelFactor) * Math.sin(angleSlice*i - Math.PI/2); })\n        .text(function(d){return d})\n        .style(\"font-weight\",600)\n\t\t.call(wrap, cfg.wrapWidth);\n\n\t/////////////////////////////////////////////////////////\n\t///////////// Draw the radar chart blobs ////////////////\n\t/////////////////////////////////////////////////////////\n\t\n\t//The radial line function\n\tvar radarLine = d3.lineRadial()\n\t\t.radius(function(d) { return rScale(d.value); })\n\t\t.angle(function(d,i) {\treturn i*angleSlice; })\n        .curve(d3.curveLinearClosed);\n\t\t\n\tif(cfg.roundStrokes) {\n\t\tradarLine.interpolate(\"cardinal-closed\");\n\t}\n\t\t\t\t\n\t//Create a wrapper for the blobs\t\n\tvar blobWrapper = g.selectAll(\".radarWrapper\")\n\t\t.data(data)\n\t\t.enter().append(\"g\")\n\t\t.attr(\"class\", \"radarWrapper\");\n\t\t\t\n\t//Append the backgrounds\t\n\tblobWrapper\n\t\t.append(\"path\")\n\t\t.attr(\"class\", \"radarArea\")\n\t\t.attr(\"d\", function(d,i) { return radarLine(d); })\n\t\t.style(\"fill\", function(d,i) { return cfg.color(i); })\n\t\t.style(\"fill-opacity\", cfg.opacityArea)\n\t\t.on('mouseover', function (d,i){\n\t\t\t//Dim all blobs\n\t\t\td3.selectAll(\".radarArea\")\n\t\t\t\t.transition().duration(200)\n\t\t\t\t.style(\"fill-opacity\", 0.1); \n\t\t\t//Bring back the hovered over blob\n\t\t\td3.select(this)\n\t\t\t\t.transition().duration(200)\n\t\t\t\t.style(\"fill-opacity\", 0.7);\t\n\t\t})\n\t\t.on('mouseout', function(){\n\t\t\t//Bring back all blobs\n\t\t\td3.selectAll(\".radarArea\")\n\t\t\t\t.transition().duration(200)\n\t\t\t\t.style(\"fill-opacity\", cfg.opacityArea);\n\t\t});\n\t\t\n\t//Create the outlines\t\n\tblobWrapper.append(\"path\")\n\t\t.attr(\"class\", \"radarStroke\")\n\t\t.attr(\"d\", function(d,i) { return radarLine(d); })\n\t\t.style(\"stroke-width\", cfg.strokeWidth + \"px\")\n\t\t.style(\"stroke\", function(d,i) { return cfg.color(i); })\n\t\t.style(\"fill\", \"none\")\n\t\t.style(\"filter\" , \"url(#glow)\");\t\t\n\t\n\t//Append the circles\n\tblobWrapper.selectAll(\".radarCircle\")\n\t\t.data(function(d,i) { return d; })\n\t\t.enter().append(\"circle\")\n\t\t.attr(\"class\", \"radarCircle\")\n\t\t.attr(\"r\", cfg.dotRadius)\n\t\t.attr(\"cx\", function(d,i){ return rScale(d.value) * Math.cos(angleSlice*i - Math.PI/2); })\n\t\t.attr(\"cy\", function(d,i){ return rScale(d.value) * Math.sin(angleSlice*i - Math.PI/2); })\n\t\t.style(\"fill\", function(d,i,j) { return data[0].map((d)=>d.value).includes(d.value)? cfg.color(0): cfg.color(1); })\n\t\t.style(\"fill-opacity\", 0.8);\n\n\t/////////////////////////////////////////////////////////\n\t//////// Append invisible circles for tooltip ///////////\n\t/////////////////////////////////////////////////////////\n\t\n\t//Wrapper for the invisible circles on top\n\tvar blobCircleWrapper = g.selectAll(\".radarCircleWrapper\")\n\t\t.data(data)\n\t\t.enter().append(\"g\")\n\t\t.attr(\"class\", \"radarCircleWrapper\");\n\t\t\n\t//Append a set of invisible circles on top for the mouseover pop-up\n\tblobCircleWrapper.selectAll(\".radarInvisibleCircle\")\n\t\t.data(function(d,i) { return d; })\n\t\t.enter().append(\"circle\")\n\t\t.attr(\"class\", \"radarInvisibleCircle\")\n\t\t.attr(\"r\", cfg.dotRadius*1.5)\n\t\t.attr(\"cx\", function(d,i){ return rScale(d.value) * Math.cos(angleSlice*i - Math.PI/2); })\n\t\t.attr(\"cy\", function(d,i){ return rScale(d.value) * Math.sin(angleSlice*i - Math.PI/2); })\n\t\t.style(\"fill\", \"none\")\n\t\t.style(\"pointer-events\", \"all\")\n\t\t.on(\"mouseover\", function(d,i) {\n\t\t\tnewX =  parseFloat(d3.select(this).attr('cx')) - 10;\n\t\t\tnewY =  parseFloat(d3.select(this).attr('cy')) - 10;\n\t\t\t\t\t\n\t\t\ttooltip\n\t\t\t\t.attr('x', newX)\n\t\t\t\t.attr('y', newY)\n\t\t\t\t.text(Format(d.value))\n\t\t\t\t.transition().duration(200)\n\t\t\t\t.style('opacity', 1);\n\t\t})\n\t\t.on(\"mouseout\", function(){\n\t\t\ttooltip.transition().duration(200)\n\t\t\t\t.style(\"opacity\", 0);\n\t\t});\n\t\t\n\t//Set up the small tooltip for when you hover over a circle\n\tvar tooltip = g.append(\"text\")\n\t\t.attr(\"class\", \"tooltip\")\n\t\t.style(\"opacity\", 0);\n\t\n\t/////////////////////////////////////////////////////////\n\t/////////////////// Helper Function /////////////////////\n\t/////////////////////////////////////////////////////////\n\n\t//Taken from http://bl.ocks.org/mbostock/7555321\n\t//Wraps SVG text\t\n\tfunction wrap(text, width) {\n\t  text.each(function() {\n\t\tvar text = d3.select(this),\n\t\t\twords = text.text().split(/\\s+/).reverse(),\n\t\t\tword,\n\t\t\tline = [],\n\t\t\tlineNumber = 0,\n\t\t\tlineHeight = 1.4, // ems\n\t\t\ty = text.attr(\"y\"),\n\t\t\tx = text.attr(\"x\"),\n\t\t\tdy = parseFloat(text.attr(\"dy\")),\n\t\t\ttspan = text.text(null).append(\"tspan\").attr(\"x\", x).attr(\"y\", y).attr(\"dy\", dy + \"em\");\n\t\t\t\n\t\twhile (word = words.pop()) {\n\t\t  line.push(word);\n\t\t  tspan.text(line.join(\" \"));\n\t\t  if (tspan.node().getComputedTextLength() > width) {\n\t\t\tline.pop();\n\t\t\ttspan.text(line.join(\" \"));\n\t\t\tline = [word];\n\t\t\ttspan = text.append(\"tspan\").attr(\"x\", x).attr(\"y\", y).attr(\"dy\", ++lineNumber * lineHeight + dy + \"em\").text(word);\n\t\t  }\n\t\t}\n\t  });}\n}\n\nvar margin_radar_cv = {top: 70, right: 50, bottom: 50, left: 50},\n\t\t\t\twidth_radar_cv = 350 - margin_radar_cv.left - margin_radar_cv.right,\n\t\t\t\theight_radar_cv = 350 - margin_radar_cv.top - margin_radar_cv.bottom - 20;\n\t\t\t\t\t\n\t\t\t////////////////////////////////////////////////////////////// \n\t\t\t////////////////////////// Data ////////////////////////////// \n\t\t\t////////////////////////////////////////////////////////////// \n\n\t\t\tvar data = [\n            [   \n                {'axis': 'Build the data infrastructure', 'value': 0.3797757950125829},\n\t\t\t\t{'axis': 'Analyze data for business', 'value': 0.7345001143902997},\n\t\t\t\t{'axis': 'Build ML prototypes in new areas', 'value': 0.458361930908259},\n                {'axis': 'Build ML services for products/workflows',\n                'value': 0.31171356668954475},\n                {'axis': 'Improving existing ML models', 'value': 0.3567833447723633},\n                {'axis': 'Research to advance ML', 'value': 0.2675589110043468}\n            ],\n            [   \n\t\t\t\t{'axis': 'Build the data infrastructure', 'value': 0.388731396172927},\n\t\t\t\t{'axis': 'Analyze data for business', 'value': 0.6371367824238129},\n                {'axis': 'Build ML prototypes in new areas', 'value': 0.5974486180014175},\n                {'axis': 'Build ML services for products/workflows',\n                'value': 0.4177888022678951},\n                {'axis': 'Improving existing ML models', 'value': 0.49893692416725727},\n                {'axis': 'Research to advance ML', 'value': 0.39936215450035434}\n            ]\n        ];\n\t\t\t////////////////////////////////////////////////////////////// \n\t\t\t//////////////////// Draw the Chart ////////////////////////// \n\t\t\t////////////////////////////////////////////////////////////// \n\n\t\t\t\t\n\t\t\tvar radarChartOptions = {\n\t\t\t  w: width_radar_cv,\n\t\t\t  h: height_radar_cv,\n\t\t\t  margin: margin_radar_cv,\n\t\t\t  maxValue: 0.8,\n\t\t\t  levels: 4,\n\t\t\t  roundStrokes: false,\n\t\t\t};\n\t\t\t//Call function to draw the Radar chart\n\t\t\tRadarChart(\".radarChart_cv\", data, radarChartOptions);\n\n});\n'''\n\nh = display(HTML(htmlt1))\n\nj = IPython.display.Javascript(js_t1)\nIPython.display.display_javascript(j)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see higher involvement of computer vision users in ML related activities as compared to its use in business intelligence. The main tasks will include:\n* Develop, test, and evaluate vision algorithms to control robots and other advanced hardware systems created for human interaction environments. \n* Implement and optimize analytics and machine learning algorithms using special purpose computing architectures. \n* Propose and implement creative, efficient solutions for vision and control problems.\n* Perform technical performance benchmarking and analyses to support engineering decisions. \n* Determine project specifications and project schedule, calculating time requirements and sequencing project elements.\n\nAs you can imagine this is an area where a good amount of knowledge is required. Like other roles related to machine learning, potential candidates will need to possess various skills including database management, as well as experience with component or object-oriented software, and fluency in C++, OpenCV, etc. Additionally, experience in 3D computer vision and video analytics algorithms, as well as machine learning algorithms for vision problems, including deep learning, is typically required."},{"metadata":{},"cell_type":"markdown","source":"## <div class=\"subsection_title\">4.2 Natural Language Processing</div>\n\nNatural language processing(or NLP for short) is the branch of artificial intelligence which is concerned with the interaction between humans and machines through the use of natural language. It allows the machine to make sense of, and derive information that is of value from human language.\n\n<div class=\"sidenote\">\n    Source: Kaggle 2020 DS and ML Survey\n</div>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"q19  = [question for question in questions if \"Q19\" in question]\nq19_not_none = q19[:4] + [q19[5]]\n\nnlp_users = dataprofs[dataprofs[q19_not_none].notnull().sum(axis=1) >=1 ]\nnlp_fields = nlp_users[\"Q5\"].value_counts() / nlp_users.shape[0]\n\n# Creating dataframe for NLP fields \nnlp_fields_df = pd.DataFrame()\nnlp_fields_df[\"field\"] = nlp_fields.index[:6]\nnlp_fields_df[\"value\"] = nlp_fields.values[:6] * 100\nnlp_fields_df[\"field\"].replace([\"Machine Learning Engineer\"],[\"ML Engineer\"], inplace=True)\n\nnlp_fields_df.to_csv(\"nlp_fields.csv\", index=False, header=[\"field\",\"value\"])\n\n# Creating dataframe for computer vision tools\nnlptools = []\nfor qn in q19:\n    for val in dataprofs[qn].unique():\n        nlptools.append(val)\n        \nnlptools = [str.strip(nlptool) for nlptool in nlptools if str(nlptool)!='nan']\nnlptools_counts = nlp_users[q19].count()\n\nnlptools_df = pd.DataFrame(columns=[\"name\",\"value\"])\nnlptools_df[\"name\"] = nlptools[:4] + [nlptools[5]]\nnlptools_df[\"value\"] = nlptools_counts.drop([\"Q19_Part_5\"]).values\n\nnlptools_df.to_csv(\"nlp_tools.csv\", index=False, header=[\"name\",\"value\"])\n\nnlp_users_radar = get_radar_data(nlp_users)\n\nhtmlt1 = '''\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Document</title>\n    <style>\n        #nlp_fields{\n            display: inline-block;\n            border: 1px solid #d7d7d7;\n            width: 350px;\n            box-shadow: 2px 2px 2px 1px rgba(0,0,0,0.3); \n        }\n        #nlp_tools{\n            display: inline-block;\n            margin-left: 10px;\n            border: 1px solid #d7d7d7;\n            width: 350px;\n            box-shadow: 2px 2px 2px 1px rgba(0,0,0,0.3); \n        }\n    </style>\n</head>\n\n<body>\n    <div id=\"nlp_fields\"></div>\n    <div id=\"nlp_tools\"></div>\n    <br>\n    <div id=\"nlp_tree\">\n    <button id=\"tree_button_nlp1\">count</button>\n    <button id=\"tree_button_nlp2\">average salary (USD)</button>\n    </div>\n    <br>\n    <div id=\"nlp_heatmap\"></div>\n    <div id=\"nlp_mlexp_nlp\"></div>\n</body>\n</html>'''\n\njs_t1 = '''\n         require.config({\n            paths: {\n                d3: \"https://d3js.org/d3.v4.min\"\n             }\n             });\n        require([\"d3\"], function(d3) {\n        \n         var margin_fields_nlp = {top: 40, right: 20, bottom: 40, left: 98},\n            width_fields_nlp = 350 - margin_fields_nlp.left - margin_fields_nlp.right,\n            height_fields_nlp = 340 - margin_fields_nlp.top - margin_fields_nlp.bottom;\n        \n        // append the svg_fields_nlp object to the body of the page\n        var svg_fields_nlp = d3.select(\"#nlp_fields\")\n          .append(\"svg\")\n            .attr(\"width\", width_fields_nlp + margin_fields_nlp.left + margin_fields_nlp.right)\n            .attr(\"height\", height_fields_nlp + margin_fields_nlp.top + margin_fields_nlp.bottom)\n          .append(\"g\")\n            .attr(\"transform\",\n                  \"translate(\" + margin_fields_nlp.left + \",\" + margin_fields_nlp.top + \")\");\n\n        svg_fields_nlp.append(\"text\")\n            .text(\"Percentage of NLP users\")\n            .attr(\"x\",0)\n            .attr(\"y\",-15)\n            .style(\"font-family\", \"Times New Roman\")\n            .style(\"font-size\", \"20px\")\n\n        // Parse the Data\n        d3.csv(\"nlp_fields.csv\", function(data) {\n        \n            var max = d3.max(data, d=> +d.value)\n          // Add X axis\n            var x = d3.scaleLinear()\n                .domain([0, 35])\n                .range([ 0, width_fields_nlp]);\n            svg_fields_nlp.append(\"g\")\n                .attr(\"transform\", \"translate(0,\" + height_fields_nlp + \")\")\n                .call(d3.axisBottom(x))\n                .selectAll(\"text\")\n                .style(\"text-anchor\", \"end\");\n        \n            // Y axis\n            var y = d3.scaleBand()\n                .range([ 0, height_fields_nlp ])\n                .domain(data.map(function(d) { return d.field; }))\n                .padding(.1);\n            svg_fields_nlp.append(\"g\")\n                .call(d3.axisLeft(y))\n        \n             //Bars\n            svg_fields_nlp.selectAll(\"myRect\")\n                .data(data)\n                .enter()\n                .append(\"rect\")\n                .attr(\"x\", x(0) )\n                .attr(\"y\", function(d) { return y(d.field); })\n                .attr(\"width\", function(d) { return x(d.value); })\n                .attr(\"height\", y.bandwidth() )\n                .attr(\"fill\", (d) => { return (+d.value == max? \"#3f4d63\": \"#c6ccd8\") })\n        })\n\n        var margin_tools_nlp = {top: 40, right: 20, bottom: 40, left: 20},\n            width_tools_nlp = 350 - margin_tools_nlp.left - margin_tools_nlp.right,\n            height_tools_nlp = 340 - margin_tools_nlp.top - margin_tools_nlp.bottom;\n\n        var svg_tools_nlp = d3.select(\"#nlp_tools\")\n            .append(\"svg\")\n                .attr(\"width\", width_tools_nlp + margin_tools_nlp.left + margin_tools_nlp.right)\n                .attr(\"height\", height_tools_nlp + margin_tools_nlp.top + margin_tools_nlp.bottom)\n            .append(\"g\")\n                .attr(\"transform\",\n                    \"translate(\" + margin_tools_nlp.left + \",\" + margin_tools_nlp.top + \")\");\n        \n        svg_tools_nlp.append(\"text\")\n            .text(\"Most used NLP Methods\")\n            .attr(\"x\",10)\n            .attr(\"y\",-15)\n            .style(\"font-family\", \"Times New Roman\")\n            .style(\"font-size\", \"21px\")            \n\n        d3.csv(\"nlp_tools.csv\", function(data) {\n\n            data = data.sort((a,b) => d3.descending(+a.value, +b.value))\n            var max = d3.max(data, d=> +d.value)\n            // Add X axis\n            var x = d3.scaleLinear()\n                .domain([0, 1450])\n                .range([ 0, width_tools_nlp]);\n                svg_tools_nlp.append(\"g\")\n                    .attr(\"transform\", \"translate(0,\" + height_tools_nlp + \")\")\n                    .call(d3.axisBottom(x))\n                    .selectAll(\"text\")\n                        .attr(\"transform\", \"translate(-10,0)\")\n                        .style(\"text-anchor\", \"end\");\n\n\n            // Y axis\n            var y = d3.scaleBand()\n            .range([ 0, height_tools_nlp ])\n            .domain(data.map(function(d) { return d.name; }))\n            .padding(.55);\n            svg_tools_nlp.append(\"g\")\n            .call(d3.axisLeft(y))\n                .selectAll(\"text\")\n                .attr(\"text-anchor\", \"start\")\n                .attr(\"transform\", \"translate(14,-16)\")\n                .style(\"font-family\", \"Tahoma\")\n                .style(\"font-size\", \"11px\")\n\n            // Bars\n            svg_tools_nlp.selectAll(\"myRect\")\n            .data(data)\n            .enter()\n            .append(\"rect\")\n            .attr(\"x\", x(0) )\n            .attr(\"y\", function(d) { return y(d.name); })\n            .attr(\"width\", function(d) { return x(d.value); })\n            .attr(\"height\", y.bandwidth() )\n            .attr(\"fill\", (d) => { return (+d.value == max? \"#3f4d63\": \"#c6ccd8\") })\n            })\n\n});\n'''\n\n\nh = display(HTML(htmlt1))\n\nj = IPython.display.Javascript(js_t1)\nIPython.display.display_javascript(j)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the above graphs we again see similar trends to what we observed in Computer vision - The bulk of our workforce is still data scientists, there is still a preference for working in smaller companies, and even the exact same countries were observed when looking at the top 10 employers.\n\nLet's now look at the NLP specific behaviours:\n* Understanding **Word Embeddings** is part of building a strong foundation in NLP. Word embeddings is a means of representing words in such a manner that words similar in meaning have similar representations.\n* **Transformer networks** function similar to Recurrent Neural Networks in the sense that they are useful to handle sequential. A key difference that makes this useful in NLP is the fact that they don't require data to be processed in order(so the beginning of the sentence needn't always be processed before the end). This makes parellisation easier, resulting in reduced training times.\n* **Encoder decoder models are used in sequence to sequence operations** like text summarising, question answering. They utilise one encoding network to encode the input sequence and another decoding network to convert this into the desired target.\n* **Contextualised word embeddings** provide additional information in the embedding regarding the context in which it was used. eg. \"ground\" has different meanings in \"ground coffee\" and \"training grounds\" which is determined based on context.\n\n## <div class=\"subsection_title\"> What do they do?</div>\n<div class=\"sidenote\">\n    Source: Kaggle 2020 DS and ML Survey - \n    <span style=\"font-style: italic;\"> Q23. Select any activities that make up an important part of your role at work.\n    </span>\n</div>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#\n\nhtmlt1 = '''\n<html>\n\t<head>\n        <style>\n            body .radarChart_nlp{\n                font-family: 'Open Sans', sans-serif;\n                font-size: 11px;\n                font-weight: 300;\n                fill: #242424;\n                text-align: center;\n                text-shadow: 0 1px 0 #fff, 1px 0 0 #fff, -1px 0 0 #fff, 0 -1px 0 #fff;\n                cursor: default;\n                width: 400px;\n                height: 420px;\n                padding: 10px 0px;\n                margin: auto;\n                border: 1px solid #d7d7d7;\n                box-shadow: 2px 2px 2px 1px rgba(0,0,0,0.3);\n            }\n\n            .radarChart_nlp h2{\n                font-family: 'Open Sans', sans-serif;\n                font-size: 20px;\n                font-weight: 600;\n                fill: #242424;\n                text-align: center;\t\t\t\t\t\n            }\n\n            .radarChart_nlp .legend {\n                font-family: 'Raleway', sans-serif;\n                fill: #333333;\n            }\n\n            .radarChart_nlp .tooltip {\n                fill: #333333;\n            }\n        </style>\n    </head>\n    <body>\n        <div class=\"radarChart_nlp\">\n            <h2>Roles in <span style=\"color:#496595\">Natural Language<br>Processing</span> vs <span style=\"color:#bbb\">others</span></h2>\n        </div>\n    </body>\n'''\n\njs_t1 = '''\n         require.config({\n            paths: {\n                d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\"\n             }\n             });\n        require([\"d3\"], function(d3) {\nfunction RadarChart(id, data, options) {\n\tvar cfg = {\n\t w: 600,\t\t\t\t//Width of the circle\n\t h: 600,\t\t\t\t//Height of the circle\n\t margin: {top: 20, right: 20, bottom: 20, left: 20}, //The margins of the SVG\n\t levels: 3,\t\t\t\t//How many levels or inner circles should there be drawn\n\t maxValue: 0, \t\t\t//What is the value that the biggest circle will represent\n\t labelFactor: 1.26, \t//How much farther than the radius of the outer circle should the labels be placed\n\t wrapWidth: 60, \t\t//The number of pixels after which a label needs to be given a new line\n\t opacityArea: 0.35, \t//The opacity of the area of the blob\n\t dotRadius: 3, \t\t\t//The size of the colored circles of each blog\n\t opacityCircles: 0.1, \t//The opacity of the circles of each blob\n\t strokeWidth: 1, \t\t//The width of the stroke around each blob\n\t roundStrokes: false,\t//If true the area and stroke will follow a round path (cardinal-closed)\n\t color: d3.scaleOrdinal().range([\"#bbb\",\"#496595\"])\t//Color function\n\t};\n\t\n\t//Put all of the options into a variable called cfg\n\tif('undefined' !== typeof options){\n\t  for(var i in options){\n\t\tif('undefined' !== typeof options[i]){ cfg[i] = options[i]; }\n\t  }//for i\n\t}//if\n\t\n\t//If the supplied maxValue is smaller than the actual one, replace by the max in the data\n\tvar maxValue = Math.max(cfg.maxValue, d3.max(data, function(i){return d3.max(i.map(function(o){return o.value;}))}));\n\t\t\n\tvar allAxis = (data[0].map(function(i, j){return i.axis})),\t//Names of each axis\n\t\ttotal = allAxis.length,\t\t\t\t\t//The number of different axes\n\t\tradius = Math.min(cfg.w/2, cfg.h/2), \t//Radius of the outermost circle\n\t\tFormat = d3.format('.0%'),\t\t\t \t//Percentage formatting\n\t\tangleSlice = Math.PI * 2 / total;\t\t//The width in radians of each \"slice\"\n\t\n\t//Scale for the radius\n\tvar rScale = d3.scaleLinear()\n\t\t.range([0, radius])\n\t\t.domain([0, maxValue]);\n\t\t\n\t/////////////////////////////////////////////////////////\n\t//////////// Create the container SVG and g /////////////\n\t/////////////////////////////////////////////////////////\n\n\t//Remove whatever chart with the same id/class was present before\n\td3.select(id).select(\"svg\").remove();\n\t\n\t//Initiate the radar chart SVG\n\tvar svg = d3.select(id).append(\"svg\")\n\t\t\t.attr(\"width\",  cfg.w + cfg.margin.left + cfg.margin.right)\n\t\t\t.attr(\"height\", cfg.h + cfg.margin.top + cfg.margin.bottom)\n\t\t\t.attr(\"class\", \"radar\"+id);\n\t//Append a g element\t\t\n\tvar g = svg.append(\"g\")\n\t\t\t.attr(\"transform\", \"translate(\" + (cfg.w/2 + cfg.margin.left) + \",\" + (cfg.h/2 + cfg.margin.top) + \")\");\n\t\n\t/////////////////////////////////////////////////////////\n\t////////// Glow filter for some extra pizzazz ///////////\n\t/////////////////////////////////////////////////////////\n\t\n\t//Filter for the outside glow\n\tvar filter = g.append('defs').append('filter').attr('id','glow'),\n\t\tfeGaussianBlur = filter.append('feGaussianBlur').attr('stdDeviation','2.5').attr('result','coloredBlur'),\n\t\tfeMerge = filter.append('feMerge'),\n\t\tfeMergeNode_1 = feMerge.append('feMergeNode').attr('in','coloredBlur'),\n\t\tfeMergeNode_2 = feMerge.append('feMergeNode').attr('in','SourceGraphic');\n\n\t/////////////////////////////////////////////////////////\n\t/////////////// Draw the Circular grid //////////////////\n\t/////////////////////////////////////////////////////////\n\t\n\t//Wrapper for the grid & axes\n\tvar axisGrid = g.append(\"g\").attr(\"class\", \"axisWrapper\");\n\t\n\t//Draw the background circles\n\taxisGrid.selectAll(\".levels\")\n\t   .data(d3.range(1,(cfg.levels+1)).reverse())\n\t   .enter()\n\t\t.append(\"circle\")\n\t\t.attr(\"class\", \"gridCircle\")\n\t\t.attr(\"r\", function(d, i){return radius/cfg.levels*d;})\n\t\t.style(\"fill\", \"#fff\")\n\t\t.style(\"stroke\", \"#dedede\")\n\t\t.style(\"fill-opacity\", cfg.opacityCircles)\n\t\t.style(\"filter\" , \"url(#glow)\");\n\n\t//Text indicating at what % each level is\n\taxisGrid.selectAll(\".axisLabel\")\n\t   .data(d3.range(1,(cfg.levels+1)).reverse())\n\t   .enter().append(\"text\")\n\t   .attr(\"class\", \"axisLabel\")\n\t   .attr(\"x\", 4)\n\t   .attr(\"y\", function(d){return -d*radius/cfg.levels;})\n\t   .attr(\"dy\", \"0.4em\")\n\t   .style(\"font-size\", \"10px\")\n\t   .attr(\"fill\", \"#737373\")\n\t   .text(function(d,i) { return Format(maxValue * d/cfg.levels); });\n\n\t/////////////////////////////////////////////////////////\n\t//////////////////// Draw the axes //////////////////////\n\t/////////////////////////////////////////////////////////\n\t\n\t//Create the straight lines radiating outward from the center\n\tvar axis = axisGrid.selectAll(\".axis\")\n\t\t.data(allAxis)\n\t\t.enter()\n\t\t.append(\"g\")\n\t\t.attr(\"class\", \"axis\");\n\t//Append the lines\n\taxis.append(\"line\")\n\t\t.attr(\"x1\", 0)\n\t\t.attr(\"y1\", 0)\n\t\t.attr(\"x2\", function(d, i){ return rScale(maxValue*1.05) * Math.cos(angleSlice*i - Math.PI/2); })\n\t\t.attr(\"y2\", function(d, i){ return rScale(maxValue*1.05) * Math.sin(angleSlice*i - Math.PI/2); })\n\t\t.attr(\"class\", \"line\")\n\t\t.style(\"stroke\", \"#333\")\n\t\t.style(\"stroke-width\", \"1px\");\n\n\t//Append the labels at each axis\n\taxis.append(\"text\")\n\t\t.attr(\"class\", \"legend\")\n\t\t.style(\"font-size\", \"10px\")\n\t\t.attr(\"text-anchor\", \"middle\")\n\t\t.attr(\"dy\", \"-1em\")\n\t\t.attr(\"x\", function(d, i){ return rScale(maxValue * cfg.labelFactor) * Math.cos(angleSlice*i - Math.PI/2); })\n\t\t.attr(\"y\", function(d, i){ return rScale(maxValue * cfg.labelFactor) * Math.sin(angleSlice*i - Math.PI/2); })\n        .text(function(d){return d})\n        .style(\"font-weight\",600)\n\t\t.call(wrap, cfg.wrapWidth);\n\n\t/////////////////////////////////////////////////////////\n\t///////////// Draw the radar chart blobs ////////////////\n\t/////////////////////////////////////////////////////////\n\t\n\t//The radial line function\n\tvar radarLine = d3.lineRadial()\n\t\t.radius(function(d) { return rScale(d.value); })\n\t\t.angle(function(d,i) {\treturn i*angleSlice; })\n        .curve(d3.curveLinearClosed);\n\t\t\n\tif(cfg.roundStrokes) {\n\t\tradarLine.interpolate(\"cardinal-closed\");\n\t}\n\t\t\t\t\n\t//Create a wrapper for the blobs\t\n\tvar blobWrapper = g.selectAll(\".radarWrapper\")\n\t\t.data(data)\n\t\t.enter().append(\"g\")\n\t\t.attr(\"class\", \"radarWrapper\");\n\t\t\t\n\t//Append the backgrounds\t\n\tblobWrapper\n\t\t.append(\"path\")\n\t\t.attr(\"class\", \"radarArea\")\n\t\t.attr(\"d\", function(d,i) { return radarLine(d); })\n\t\t.style(\"fill\", function(d,i) { return cfg.color(i); })\n\t\t.style(\"fill-opacity\", cfg.opacityArea)\n\t\t.on('mouseover', function (d,i){\n\t\t\t//Dim all blobs\n\t\t\td3.selectAll(\".radarArea\")\n\t\t\t\t.transition().duration(200)\n\t\t\t\t.style(\"fill-opacity\", 0.1); \n\t\t\t//Bring back the hovered over blob\n\t\t\td3.select(this)\n\t\t\t\t.transition().duration(200)\n\t\t\t\t.style(\"fill-opacity\", 0.7);\t\n\t\t})\n\t\t.on('mouseout', function(){\n\t\t\t//Bring back all blobs\n\t\t\td3.selectAll(\".radarArea\")\n\t\t\t\t.transition().duration(200)\n\t\t\t\t.style(\"fill-opacity\", cfg.opacityArea);\n\t\t});\n\t\t\n\t//Create the outlines\t\n\tblobWrapper.append(\"path\")\n\t\t.attr(\"class\", \"radarStroke\")\n\t\t.attr(\"d\", function(d,i) { return radarLine(d); })\n\t\t.style(\"stroke-width\", cfg.strokeWidth + \"px\")\n\t\t.style(\"stroke\", function(d,i) { return cfg.color(i); })\n\t\t.style(\"fill\", \"none\")\n\t\t.style(\"filter\" , \"url(#glow)\");\t\t\n\t\n\t//Append the circles\n\tblobWrapper.selectAll(\".radarCircle\")\n\t\t.data(function(d,i) { return d; })\n\t\t.enter().append(\"circle\")\n\t\t.attr(\"class\", \"radarCircle\")\n\t\t.attr(\"r\", cfg.dotRadius)\n\t\t.attr(\"cx\", function(d,i){ return rScale(d.value) * Math.cos(angleSlice*i - Math.PI/2); })\n\t\t.attr(\"cy\", function(d,i){ return rScale(d.value) * Math.sin(angleSlice*i - Math.PI/2); })\n\t\t.style(\"fill\", function(d,i,j) { return data[0].map((d)=>d.value).includes(d.value)? cfg.color(0): cfg.color(1); })\n\t\t.style(\"fill-opacity\", 0.8);\n\n\t/////////////////////////////////////////////////////////\n\t//////// Append invisible circles for tooltip ///////////\n\t/////////////////////////////////////////////////////////\n\t\n\t//Wrapper for the invisible circles on top\n\tvar blobCircleWrapper = g.selectAll(\".radarCircleWrapper\")\n\t\t.data(data)\n\t\t.enter().append(\"g\")\n\t\t.attr(\"class\", \"radarCircleWrapper\");\n\t\t\n\t//Append a set of invisible circles on top for the mouseover pop-up\n\tblobCircleWrapper.selectAll(\".radarInvisibleCircle\")\n\t\t.data(function(d,i) { return d; })\n\t\t.enter().append(\"circle\")\n\t\t.attr(\"class\", \"radarInvisibleCircle\")\n\t\t.attr(\"r\", cfg.dotRadius*1.5)\n\t\t.attr(\"cx\", function(d,i){ return rScale(d.value) * Math.cos(angleSlice*i - Math.PI/2); })\n\t\t.attr(\"cy\", function(d,i){ return rScale(d.value) * Math.sin(angleSlice*i - Math.PI/2); })\n\t\t.style(\"fill\", \"none\")\n\t\t.style(\"pointer-events\", \"all\")\n\t\t.on(\"mouseover\", function(d,i) {\n\t\t\tnewX =  parseFloat(d3.select(this).attr('cx')) - 10;\n\t\t\tnewY =  parseFloat(d3.select(this).attr('cy')) - 10;\n\t\t\t\t\t\n\t\t\ttooltip\n\t\t\t\t.attr('x', newX)\n\t\t\t\t.attr('y', newY)\n\t\t\t\t.text(Format(d.value))\n\t\t\t\t.transition().duration(200)\n\t\t\t\t.style('opacity', 1);\n\t\t})\n\t\t.on(\"mouseout\", function(){\n\t\t\ttooltip.transition().duration(200)\n\t\t\t\t.style(\"opacity\", 0);\n\t\t});\n\t\t\n\t//Set up the small tooltip for when you hover over a circle\n\tvar tooltip = g.append(\"text\")\n\t\t.attr(\"class\", \"tooltip\")\n\t\t.style(\"opacity\", 0);\n\t\n\t/////////////////////////////////////////////////////////\n\t/////////////////// Helper Function /////////////////////\n\t/////////////////////////////////////////////////////////\n\n\t//Taken from http://bl.ocks.org/mbostock/7555321\n\t//Wraps SVG text\t\n\tfunction wrap(text, width) {\n\t  text.each(function() {\n\t\tvar text = d3.select(this),\n\t\t\twords = text.text().split(/\\s+/).reverse(),\n\t\t\tword,\n\t\t\tline = [],\n\t\t\tlineNumber = 0,\n\t\t\tlineHeight = 1.4, // ems\n\t\t\ty = text.attr(\"y\"),\n\t\t\tx = text.attr(\"x\"),\n\t\t\tdy = parseFloat(text.attr(\"dy\")),\n\t\t\ttspan = text.text(null).append(\"tspan\").attr(\"x\", x).attr(\"y\", y).attr(\"dy\", dy + \"em\");\n\t\t\t\n\t\twhile (word = words.pop()) {\n\t\t  line.push(word);\n\t\t  tspan.text(line.join(\" \"));\n\t\t  if (tspan.node().getComputedTextLength() > width) {\n\t\t\tline.pop();\n\t\t\ttspan.text(line.join(\" \"));\n\t\t\tline = [word];\n\t\t\ttspan = text.append(\"tspan\").attr(\"x\", x).attr(\"y\", y).attr(\"dy\", ++lineNumber * lineHeight + dy + \"em\").text(word);\n\t\t  }\n\t\t}\n\t  });}\n}\n\nvar margin_radar_nlp = {top: 70, right: 50, bottom: 50, left: 50},\n\t\t\t\twidth_radar_nlp = 350 - margin_radar_nlp.left - margin_radar_nlp.right,\n\t\t\t\theight_radar_nlp = 350 - margin_radar_nlp.top - margin_radar_nlp.bottom - 20;\n\t\t\t\t\t\n\t\t\t////////////////////////////////////////////////////////////// \n\t\t\t////////////////////////// Data ////////////////////////////// \n\t\t\t////////////////////////////////////////////////////////////// \n\n\t\t\tvar data = [\n            [   \n            {'axis': 'Build the data infrastructure', 'value': 0.3797757950125829},\n            {'axis': 'Analyze data for business', 'value': 0.7345001143902997},\n            {'axis': 'Build ML prototypes in new areas', 'value': 0.458361930908259},\n            {'axis': 'Build ML services for products/workflows',\n            'value': 0.31171356668954475},\n            {'axis': 'Improving existing ML models', 'value': 0.3567833447723633},\n            {'axis': 'Research to advance ML', 'value': 0.2675589110043468}\n            ],\n            [ //NLP data\n             {'axis': 'Build the data infrastructure', 'value': 0.43927233814874267},\n             {'axis': 'Analyze data for business decisions', 'value': 0.6773675762439807},\n             {'axis': 'Build ML prototypes in new areas', 'value': 0.6260032102728732},\n             {'axis': 'Build ML services for products/workflows',\n              'value': 0.4724451578384163},\n             {'axis': 'Improving existing ML models', 'value': 0.545211342964152},\n             {'axis': 'Research to advance ML', 'value': 0.40823970037453183}]\n            ];\n\t\t\t////////////////////////////////////////////////////////////// \n\t\t\t//////////////////// Draw the Chart ////////////////////////// \n\t\t\t////////////////////////////////////////////////////////////// \n\n\t\t\t\t\n\t\t\tvar radarChartOptions = {\n\t\t\t  w: width_radar_nlp,\n\t\t\t  h: height_radar_nlp,\n\t\t\t  margin: margin_radar_nlp,\n\t\t\t  maxValue: 0.8,\n\t\t\t  levels: 4,\n\t\t\t  roundStrokes: false,\n\t\t\t};\n\t\t\t//Call function to draw the Radar chart\n\t\t\tRadarChart(\".radarChart_nlp\", data, radarChartOptions);\n\n});\n'''\n\nh = display(HTML(htmlt1))\n\nj = IPython.display.Javascript(js_t1)\nIPython.display.display_javascript(j)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"While the most common role of data professionals is analysing data for business decisions, NLP users are lacking in this area. Likely, this is because they **dont work with data analysis solely for business insights** and instead **focus their attention on the machine learning** aspects of the job. This is evident by how their radar chart shows **greater involvement in all ML related activities**.\n\n### Is it challenging to learn NLP?\n![](https://qphs.fs.quoracdn.net/main-qimg-01e1fa5e870bca9d7528ffb82584d767)\n<div style=\"text-align: center; font-style: italic\"> (from  Stanford's popular CS224d: Natural Language Processing with Deep Learning course) </div>\n<br>\nNatural language processing is a specialised area of machine learning with its own unique quirks and domain practices due to the nature of natural language(often text) data. One will see a lot of domain specific practices and techniques like tokenization, part-of-speech-tagging, stemming and lemmatization(breaking down works into their root component. eg. studying becomes study), stop word removal which are almost exclusively used with text data."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Creating heatmap data csv for nlp users' team sizes\nnlp_heatmap_data = nlp_users.groupby([\"Q20\"])[\"Q21\"].value_counts()\n\nnlp_heatmap_df = pd.DataFrame()\nfor cosize in dataprofs[\"Q20\"].unique():\n    nlp_heatmap_df[cosize] = nlp_heatmap_data[cosize]\n\nnlp_heatmap_df.columns = [col.split(\" employees\")[0] for col in nlp_heatmap_df.columns]\n\nnlp_data_list = []\nfor cosize in nlp_heatmap_df.columns:\n    for dssize in nlp_heatmap_df.index:\n        nlp_data_list.append([cosize, dssize, nlp_heatmap_df[cosize].loc[dssize]])\n        \nnlp_data_df =  pd.DataFrame(nlp_data_list)\n\nnlp_data_df.to_csv(\"nlp_heatmap.csv\", index=False, header=[\"cosize\",\"dssize\",\"value\"])\n\n# Creating csv for machine learning experience bar chart\n\nnlp_mlexp = nlp_users[\"Q15\"].value_counts().sort_values(ascending=False)\n\n# Renaming the indexes and then reordering them (there are easier ways to do this though)\nnlp_mlexp.index = [x+\" years\" for x in['1-2', '2-3', '0-1', '5-10', '3-4', '4-5', '10-20', '20+']]\nnlp_mlexp = nlp_mlexp.reindex(x+\" years\" for x in['0-1', '1-2', '2-3', '3-4', '4-5', '5-10', '10-20', '20+'])\n\nnlp_mlexp_df = pd.DataFrame()\nnlp_mlexp_df[\"exp\"] = nlp_mlexp.index\nnlp_mlexp_df[\"value\"] = nlp_mlexp.values\n\nnlp_mlexp_df.to_csv(\"nlp_mlexp.csv\", index=False, header=[\"exp\",\"value\"])\n\nhtmlt1 = '''\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Document</title>\n    <style>\n        #nlp_heatmap{\n            display: inline-block;\n            border: 1px solid #d7d7d7;\n            width: 350px;\n            box-shadow: 2px 2px 2px 1px rgba(0,0,0,0.3); \n        }\n        #nlp_mlexp_nlp{\n            display: inline-block;\n            margin-left: 10px;\n            border: 1px solid #d7d7d7;\n            width: 350px;\n            box-shadow: 2px 2px 2px 1px rgba(0,0,0,0.3); \n        }\n    </style>\n</head>\n<body>\n\n</body>\n</html>'''\n\njs_t1 = '''\n         require.config({\n            paths: {\n                d3: \"https://d3js.org/d3.v4.min\"\n             }\n             });\n        require([\"d3\"], function(d3) {\n        \n         var margin_heatmap_nlp = {top: 33, right: 15, bottom: 40, left: 60},\n        width_heatmap_nlp = 350 - margin_heatmap_nlp.left - margin_heatmap_nlp.right,\n        height_heatmap_nlp = 340 - margin_heatmap_nlp.top - margin_heatmap_nlp.bottom;\n        \n        // append the svg object to the body of the page\n        var svg_heatmap_nlp = d3.select(\"#nlp_heatmap\")\n        .append(\"svg\")\n        .attr(\"width\", width_heatmap_nlp + margin_heatmap_nlp.left + margin_heatmap_nlp.right)\n        .attr(\"height\", height_heatmap_nlp + margin_heatmap_nlp.top + margin_heatmap_nlp.bottom)\n        .append(\"g\")\n        .attr(\"transform\",\n                \"translate(\" + margin_heatmap_nlp.left + \",\" + margin_heatmap_nlp.top + \")\");\n        \n        // add title\n        svg_heatmap_nlp.append(\"text\")\n            .text(\"Company and DS team sizes\")\n            .attr(\"x\",0)\n            .attr(\"y\",-10)\n            .style(\"font-family\", \"Times New Roman\")\n            .style(\"font-size\", \"21px\") \n\n        svg_heatmap_nlp.append(\"text\")\n            .text(\"Company size (employees)\")\n            .attr(\"x\", width_heatmap_nlp/2)\n            .attr(\"y\", height_heatmap_nlp + 32)\n            .attr(\"text-anchor\",\"middle\")\n            .style(\"font-weight\",\"600\")\n            .style(\"font-family\", \"Tahoma\")\n            .style(\"font-size\", \"12px\")\n        \n        svg_heatmap_nlp.append(\"text\")\n            .attr(\"transform\", \"rotate(-90)\")\n            .attr(\"y\", 0 - margin_heatmap_nlp.left + 6)\n            .attr(\"x\",0 - (height_heatmap_nlp / 2))\n            .attr(\"dy\", \"1em\")\n            .style(\"text-anchor\", \"middle\")\n            .style(\"font-weight\",\"600\")\n            .style(\"font-family\", \"Tahoma\")\n            .style(\"font-size\", \"13px\") \n            .text(\"Data Science team size\");  \n                        \n        // Labels of row and columns\n        var myGroups = ['0-49', '50-249', '250-999', '1000-9,999', '10,000 or more']\n        var myVars = ['0', '1-2', '3-4', '5-9', '10-14', '15-19', '20+']\n        \n        // Build X scales and axis:\n        var x = d3.scaleBand()\n        .range([ 0, width_heatmap_nlp ])\n        .domain(myGroups)\n        .padding(0.01);\n        svg_heatmap_nlp.append(\"g\")\n        .attr(\"transform\", \"translate(0,\" + height_heatmap_nlp + \")\")\n        .call(d3.axisBottom(x))\n        .selectAll(\"text\")\n            .style(\"font-size\",\"9px\")\n        \n        // Build X scales and axis:\n        var y = d3.scaleBand()\n        .range([ height_heatmap_nlp, 0 ])\n        .domain(myVars)\n        .padding(0.01);\n        svg_heatmap_nlp.append(\"g\")\n        .call(d3.axisLeft(y));\n        \n        // Build color scale\n        var myColor = d3.scaleLinear()\n        .range([\"#f7f7f7\", \"#29658c\"]) //e9cf87\n        .domain([1,300])\n        \n        //Read the data\n        d3.csv(\"nlp_heatmap.csv\", function(data) {\n        \n        svg_heatmap_nlp.selectAll()\n            .data(data)\n            .enter()\n            .append(\"rect\")\n            .attr(\"x\", function(d) { return x(d.cosize) })\n            .attr(\"y\", function(d) { return y(d.dssize) })\n            .attr(\"width\", x.bandwidth() )\n            .attr(\"height\", y.bandwidth() )\n            .style(\"fill\", function(d) { return myColor(d.value)} )\n        \n        })\n\n        var margin_mlexp_nlp = {top: 35, right: 20, bottom: 40, left: 70},\n            width_mlexp_nlp  = 350 - margin_mlexp_nlp.left - margin_mlexp_nlp.right,\n            height_mlexp_nlp = 340 - margin_mlexp_nlp.top - margin_mlexp_nlp.bottom;\n\n        var svg_mlexp_nlp = d3.select(\"#nlp_mlexp_nlp\")\n            .append(\"svg\")\n                .attr(\"width\", width_mlexp_nlp + margin_mlexp_nlp.left + margin_mlexp_nlp.right)\n                .attr(\"height\", height_mlexp_nlp + margin_mlexp_nlp.top + margin_mlexp_nlp.bottom)\n            .append(\"g\")\n                .attr(\"transform\",\n                    \"translate(\" + margin_mlexp_nlp.left + \",\" + margin_mlexp_nlp.top + \")\");\n        \n        svg_mlexp_nlp.append(\"text\")\n            .text(\"Machine Learning experience\")\n            .attr(\"x\",-5)\n            .attr(\"y\",-10)\n            .style(\"font-family\", \"Times New Roman\")\n            .style(\"font-size\", \"21px\")\n            \n        svg_mlexp_nlp.append(\"text\")\n            .text(\"Respondent's count\")\n            .attr(\"x\", width_mlexp_nlp/2 - 10)\n            .attr(\"y\", height_mlexp_nlp + 32)\n            .attr(\"text-anchor\",\"middle\")\n            .style(\"font-weight\",\"600\")\n            .style(\"font-family\", \"Tahoma\")\n            .style(\"font-size\", \"12px\")\n\n        d3.csv(\"nlp_mlexp.csv\", function(data) {\n\n            // data = data.sort((a,b) => d3.descending(+a.value, +b.value))\n            var max = d3.max(data, d=> +d.value)\n\n            // Add X axis\n            var x = d3.scaleLinear()\n                .domain([0, 500])\n                .range([ 0, width_mlexp_nlp]);\n            svg_mlexp_nlp.append(\"g\")\n                .attr(\"transform\", \"translate(0,\" + height_mlexp_nlp + \")\")\n                .call(d3.axisBottom(x))\n                .selectAll(\"text\")\n                    .attr(\"transform\", \"translate(-10,0)\")\n                    .style(\"text-anchor\", \"end\");\n\n            // Y axis\n            var y = d3.scaleBand()\n            .range([ 0, height_mlexp_nlp ])\n            .domain(data.map(function(d) { return d.exp; }))\n            .padding(.05);\n            svg_mlexp_nlp.append(\"g\")\n            .call(d3.axisLeft(y))\n                .selectAll(\"text\")\n                // .attr(\"text-anchor\", \"start\")\n                // .attr(\"transform\", \"translate(14,-16)\")\n                .style(\"font-family\", \"Tahoma\")\n                .style(\"font-size\", \"11px\")\n\n            // Bars\n            svg_mlexp_nlp.selectAll(\"myRect\")\n            .data(data)\n            .enter()\n            .append(\"rect\")\n                .attr(\"x\", x(0) )\n                .attr(\"y\", function(d) { return y(d.exp); })\n                .attr(\"width\", function(d) { return x(d.value); })\n                .attr(\"height\", y.bandwidth() )\n                .attr(\"fill\", (d) => { return (+d.value == max? \"#3f4d63\": \"#c6ccd8\") })\n            })\n\n});\n'''\n\n\nh = display(HTML(htmlt1))\n\nj = IPython.display.Javascript(js_t1)\nIPython.display.display_javascript(j)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"\n# Will let us pick how many countries to consider.\ncutoff = 10\ncountries = list( nlp_users[\"Q3\"].value_counts().index[:cutoff] )\ncountries_count = nlp_users[\"Q3\"].value_counts()[countries]\n\n# Drop all individuals that didnt mention salary\nnlp_users_with_salary = nlp_users.dropna(subset = [\"Q24\"])\n\nnlp_users_with_salary[\"Q24_amounts\"] = [(earnings_map[payrange]) for payrange in nlp_users_with_salary[\"Q24\"]]\nsalary_data = np.int32(nlp_users_with_salary.groupby([\"Q3\"])[\"Q24_amounts\"].mean()[countries])\n\n# Creating the dataframe\nnlp_tree_df = pd.DataFrame(columns=[\"name\",\"parent\",\"value\",\"value2\"])\nnlp_tree_df.loc[0] = [\"Origin\",\"\",\"\",\"\"]\n\nnlp_tree_temp = pd.DataFrame(columns=[\"name\",\"parent\",\"value\",\"value2\"])\n\nnlp_tree_temp[\"value\"] = nlp_users[\"Q3\"].value_counts()[countries].values\nnlp_tree_temp[\"value2\"]= salary_data\nnlp_tree_temp[\"parent\"]= \"Origin\"\n\n# Editing label names\ncountries_new = countries\ncountries_new[-1] = \"United Kingdom\"\nnlp_tree_temp[\"name\"] = countries_new\n\nnlp_tree_df = nlp_tree_df.append(nlp_tree_temp, ignore_index = True)\n\nnlp_tree_df = shuffle(nlp_tree_df, random_state=100293)\n\nnlp_tree_df.to_csv(\"nlp_tree.csv\", index=False, header=[\"name\",\"parent\",\"value\",\"value2\"])\n\nhtmlt1 = '''\n<html lang=\"en\">\n<head>\n    <title>Document</title>\n    <style>\n        #nlp_tree{\n            display: inline-block;\n            margin: 10px 0px;\n            border: 1px solid #d7d7d7;\n            width: 714px;\n            box-shadow: 2px 2px 2px 1px rgba(0,0,0,0.3); \n        }\n        #tree_button_nlp1{\n            border-radius: 0;\n            background-color: #fff;\n            border: 1px solid #d7d7d7;\n            position: relative;\n            top:  5px;\n            width: 75px;\n            left: 621px;\n            color: #000;\n        }\n        #tree_button_nlp2{\n            border-radius: 0;\n            background-color: #fff;\n            border: 1px solid #d7d7d7;\n            position: relative;\n            top:  5px;\n            left: 373px;\n            color: #000;\n        }\n\n        #tree_button_nlp1:hover, #tree_button_nlp2:hover{\n            background-color: #d7d7d7;\n        }\n        #tree_button_nlp1:focus, #tree_button_nlp2:focus{\n            outline: none;\n            background-color: #4d4d4d;\n            color: #fff;\n        }\n\n    </style>\n</head>\n<body>\n    \n</body>\n</html>\n'''\n\njs_t1 = '''\n         require.config({\n            paths: {\n                d3: \"https://d3js.org/d3.v4.min\"\n             }\n             });\n        require([\"d3\"], function(d3) {\n        \n         // set the dimensions and margins of the graph\n        var margin_tree_nlp = {top: 20, right: 10, bottom: 5, left: 10},\n            width_tree_nlp = 710 - margin_tree_nlp.left - margin_tree_nlp.right,\n            height_tree_nlp = 340 - margin_tree_nlp.top - margin_tree_nlp.bottom;\n        \n        // append the svg object to the body of the page\n        var svg_tree_nlp = d3.select(\"#nlp_tree\")\n        .append(\"svg\")\n            .attr(\"width\", width_tree_nlp + margin_tree_nlp.left + margin_tree_nlp.right)\n            .attr(\"height\", height_tree_nlp + margin_tree_nlp.top + margin_tree_nlp.bottom)\n        .append(\"g\")\n            .attr(\"transform\", \"translate(\" + margin_tree_nlp.left + \",\" + margin_tree_nlp.top + \")\");\n        \n        showData(\"count\")\n        document.getElementById(\"tree_button_nlp1\").addEventListener(\"click\", function(evt) {showData(\"count\")});\n        document.getElementById(\"tree_button_nlp2\").addEventListener(\"click\", function(evt) {showData(\"salary\")});\n\n        function showData(mode){\n        // Read data\n        d3.csv('nlp_tree.csv', function(data) {\n        \n        var max = d3.max(data, (d)=> {return mode ==\"count\"?  +d.value: +d.value2;})\n       \n        var colorScale1 = d3.scaleLinear()\n        .range([\"#f1efd9\",\"#AF9973\",\"#a2885e\"]) //[\"#a2885e\",\"#f1efd9\",\"#235f83\"]\n        .domain([40,max/6, max])\n\n        var colorScale2 = d3.scaleLinear()\n        .range([\"#f1efd9\",\"#457791\",\"#235f83\"]) //[\"#a2885e\",\"#f1efd9\",\"#235f83\"]\n        .domain([5000,max/2, max])\n\n          // stratify the data: reformatting for d3.js\n        var root = d3.stratify()\n            .id(function(d) { return d.name; })   // Name of the entity (column name is name in csv)\n            .parentId(function(d) { return d.parent; })   // Name of the parent (column name is parent in csv)\n            (data);\n        root.sum(function(d) {return mode ==\"count\"?  +d.value: +d.value2; })   // Compute the numeric value for each entity\n        \n          // Then d3.treemap computes the position of each element of the hierarchy\n          // The coordinates are added to the root object above\n        d3.treemap()\n            .size([width_tree_nlp, height_tree_nlp])\n            .padding(4)\n            (root)\n\n        var u = svg_tree_nlp\n            .selectAll(\"rect\")\n            .data(root.leaves())\n            \n            u\n            .enter()\n            .append(\"rect\")\n            .merge(u)\n            .transition()\n            .duration(700)\n            .attr('x', function (d) { return d.x0; })\n            .attr('y', function (d) { return d.y0; })\n            .attr('width', function (d) { return d.x1 - d.x0; })\n            .attr('height', function (d) { return d.y1 - d.y0; })\n            .style(\"stroke\", \"black\")\n            .style(\"fill\", (d) => {\n                return (mode ==\"count\"?  colorScale1(+d.value): colorScale2(+d.value))\n            });\n    \n        \n\n        // and to add the text labels\n        var v = svg_tree_nlp\n            .selectAll(\"text\")\n            .data(root.leaves())\n\n            v\n            .enter()\n            .append(\"text\")\n            .merge(v)\n                .attr(\"x\", function(d){ return d.x0+10})    // +10 to adjust position (more right)\n                .attr(\"y\", function(d){ return d.y0+15})    // +20 to adjust position (lower)\n                .text(function(d){ return d.data.name})\n                .attr(\"font-size\", \"15px\")\n                .attr(\"fill\", \"white\")\n        \n        var w = svg_tree_nlp\n            .selectAll(\"text.count\")\n            .data(root.leaves())\n\n            w\n            .enter()\n            .append(\"text\")\n            .merge(w)\n                .attr(\"class\", function(d){ return \"count \"+d.data.name})\n                .attr(\"x\", function(d){ return (d.x1+d.x0)/2 })    // +10 to adjust position (more right)\n                .attr(\"y\", function(d){ return (d.y1+d.y0)/2 + 15})    // +20 to adjust position (lower)\n                .text(function(d){ return mode == \"count\"? d.data.value: (d.data.value2.replace(/\\B(?=(\\d{3})+(?!\\d))/g, \",\"));})\n                .attr(\"text-anchor\",\"middle\")\n                .style(\"font-size\", function(d){ \n                    return mode == \"count\"? \"30px\" : \"22px\";\n                })\n                .attr(\"fill\", \"white\")\n                .style(\"font-family\", \"Arial\")\n        \n        svg_tree_nlp\n            .append(\"text\")\n            .attr(\"class\",\"title\")\n            .text(\"Salaries and Counts of Countries\")\n            .attr(\"x\", 5)\n            .attr(\"y\",-5)\n            .style(\"font-family\", \"Times New Roman\")\n            .style(\"font-size\", \"21px\")\n        })\n    }\n\n});\n'''\n\n\nh = display(HTML(htmlt1))\n\nj = IPython.display.Javascript(js_t1)\nIPython.display.display_javascript(j)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <div class=\"subsection_title\">4.3 Machine learning in general</div>\n\nThis section covers the users of the other machine learning algorithms that the survey group under Q17( \"*machine learning algorithms used regularly\"* ). These are used for a wide range of applications and hopefully this analysis will help us understand how utilised they are in everyday applications.\n\n<div class=\"sidenote\">\n    Source: Kaggle 2020 DS and ML Survey\n</div>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"q17  = [question for question in questions if \"Q17\" in question]\nq17_not_none = q17[:10] + [q17[11]]\n\nml_users = dataprofs[dataprofs[q17_not_none].notnull().sum(axis=1) >=1 ]\nml_fields = ml_users[\"Q5\"].value_counts() / ml_users.shape[0]\n\n# Creating dataframe for ml fields \nml_fields_df = pd.DataFrame()\nml_fields_df[\"field\"] = ml_fields.index[:7]\nml_fields_df[\"value\"] = ml_fields.values[:7] * 100\nml_fields_df[\"field\"].replace([\"Machine Learning Engineer\"],[\"ML Engineer\"], inplace=True)\n\nml_fields_df.to_csv(\"ml_fields.csv\", index=False, header=[\"field\",\"value\"])\n\nmltools = []\nfor qn in q17:\n    for val in dataprofs[qn].unique():\n        mltools.append(val)\n        \nmltools = [str.strip(mltool) for mltool in mltools if str(mltool)!='nan']\nmltools_counts = ml_users[q17].count()\n\nmltools_df = pd.DataFrame(columns=[\"name\",\"value\"])\nmltools_df[\"name\"] = mltools[:10] + [mltools[11]]\nmltools_df[\"value\"] = mltools_counts.drop([\"Q17_Part_11\"]).values\n\nmltools_df.to_csv(\"ml_tools.csv\", index=False, header=[\"name\",\"value\"])\n\nml_users_radar = get_radar_data(ml_users)\n\nhtmlt1 = '''\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Document</title>\n    <style>\n        #ml_fields{\n            display: inline-block;\n            border: 1px solid #d7d7d7;\n            width: 350px;\n            box-shadow: 2px 2px 2px 1px rgba(0,0,0,0.3); \n        }\n        #ml_tools{\n            display: inline-block;\n            margin-left: 10px;\n            border: 1px solid #d7d7d7;\n            width: 350px;\n            box-shadow: 2px 2px 2px 1px rgba(0,0,0,0.3); \n        }\n    </style>\n</head>\n<body>\n    <div id=\"ml_fields\"></div>\n    <div id=\"ml_tools\"></div>\n    <br>\n    <div id=\"ml_tree\">\n    <button id=\"tree_button_ml1\">count</button>\n    <button id=\"tree_button_ml2\">average salary (USD)</button>\n    </div>\n    <br>\n    <div id=\"ml_heatmap\"></div>\n    <div id=\"ml_mlexp_ml\"></div>\n</body>\n</html>\n'''\n\njs_t1 = '''\n         require.config({\n            paths: {\n                d3: \"https://d3js.org/d3.v4.min\"\n             }\n             });\n        require([\"d3\"], function(d3) {\n        \n         var margin_fields_ml = {top: 40, right: 20, bottom: 40, left: 98},\n            width_fields_ml = 350 - margin_fields_ml.left - margin_fields_ml.right,\n            height_fields_ml = 340 - margin_fields_ml.top - margin_fields_ml.bottom;\n        \n        // append the svg_fields_ml object to the body of the page\n        var svg_fields_ml = d3.select(\"#ml_fields\")\n          .append(\"svg\")\n            .attr(\"width\", width_fields_ml + margin_fields_ml.left + margin_fields_ml.right)\n            .attr(\"height\", height_fields_ml + margin_fields_ml.top + margin_fields_ml.bottom)\n          .append(\"g\")\n            .attr(\"transform\",\n                  \"translate(\" + margin_fields_ml.left + \",\" + margin_fields_ml.top + \")\");\n\n        svg_fields_ml.append(\"text\")\n            .text(\"Percentage across Fields\")\n            .attr(\"x\",0)\n            .attr(\"y\",-13)\n            .style(\"font-family\", \"Times New Roman\")\n            .style(\"font-size\", \"22px\")\n\n        // Parse the Data\n        d3.csv(\"ml_fields.csv\", function(data) {\n        \n            var max = d3.max(data, d=> +d.value)\n          // Add X axis\n            var x = d3.scaleLinear()\n                .domain([0, 35])\n                .range([ 0, width_fields_ml]);\n            svg_fields_ml.append(\"g\")\n                .attr(\"transform\", \"translate(0,\" + height_fields_ml + \")\")\n                .call(d3.axisBottom(x))\n                .selectAll(\"text\")\n                .style(\"text-anchor\", \"end\");\n        \n            // Y axis\n            var y = d3.scaleBand()\n                .range([ 0, height_fields_ml ])\n                .domain(data.map(function(d) { return d.field; }))\n                .padding(.1);\n            svg_fields_ml.append(\"g\")\n                .call(d3.axisLeft(y))\n        \n             //Bars\n            svg_fields_ml.selectAll(\"myRect\")\n                .data(data)\n                .enter()\n                .append(\"rect\")\n                .attr(\"x\", x(0) )\n                .attr(\"y\", function(d) { return y(d.field); })\n                .attr(\"width\", function(d) { return x(d.value); })\n                .attr(\"height\", y.bandwidth() )\n                .attr(\"fill\", (d) => { return (+d.value == max? \"#3f4d63\": \"#c6ccd8\") })\n        })\n\n        var margin_tools_ml = {top: 40, right: 20, bottom: 40, left: 20},\n            width_tools_ml = 350 - margin_tools_ml.left - margin_tools_ml.right,\n            height_tools_ml = 340 - margin_tools_ml.top - margin_tools_ml.bottom;\n\n        var svg_tools_ml = d3.select(\"#ml_tools\")\n            .append(\"svg\")\n                .attr(\"width\", width_tools_ml + margin_tools_ml.left + margin_tools_ml.right)\n                .attr(\"height\", height_tools_ml + margin_tools_ml.top + margin_tools_ml.bottom)\n            .append(\"g\")\n                .attr(\"transform\",\n                    \"translate(\" + margin_tools_ml.left + \",\" + margin_tools_ml.top + \")\");\n        \n        svg_tools_ml.append(\"text\")\n            .text(\"Use of Machine Learning methods\")\n            .attr(\"x\",0)\n            .attr(\"y\",-14)\n            .style(\"font-family\", \"Times New Roman\")\n            .style(\"font-size\", \"22px\")\n            \n        \n\n        svg_tools_ml.append(\"text\")\n            .text(\"Respondent's count\")\n            .attr(\"x\", width_tools_ml/2)\n            .attr(\"y\", height_tools_ml + 32)\n            .attr(\"text-anchor\",\"middle\")\n            .style(\"font-weight\",\"600\")\n            .style(\"font-family\", \"Tahoma\")\n            .style(\"font-size\", \"12px\")\n\n        d3.csv(\"ml_tools.csv\", function(data) {\n\n            data = data.sort((a,b) => d3.descending(+a.value, +b.value))\n            var max = d3.max(data, d=> +d.value)\n            // Add X axis\n            var x = d3.scaleLinear()\n                .domain([0, 6000])\n                .range([ 0, width_tools_ml]);\n                svg_tools_ml.append(\"g\")\n                    .attr(\"transform\", \"translate(0,\" + height_tools_ml + \")\")\n                    .call(d3.axisBottom(x))\n                    .selectAll(\"text\")\n                        .attr(\"transform\", \"translate(-10,0)\")\n                        .style(\"text-anchor\", \"end\")\n                        .style(\"font-size\",\"9px\")\n\n\n            // Y axis\n            var y = d3.scaleBand()\n            .range([ 0, height_tools_ml ])\n            .domain(data.map(function(d) { return d.name; }))\n            .padding(.62);\n            svg_tools_ml.append(\"g\")\n            .call(d3.axisLeft(y))\n                .selectAll(\"text\")\n                .attr(\"text-anchor\", \"start\")\n                .attr(\"transform\", \"translate(12,-10)\")\n                .style(\"font-family\", \"Tahoma\")\n                .style(\"font-size\", \"10.8px\")\n\n            //Bars\n            svg_tools_ml.selectAll(\"myRect\")\n            .data(data)\n            .enter()\n            .append(\"rect\")\n            .attr(\"x\", x(0) )\n            .attr(\"y\", function(d) { return y(d.name); })\n            .attr(\"width\", function(d) { return x(d.value); })\n            .attr(\"height\", y.bandwidth() )\n            .attr(\"fill\", (d) => { return (+d.value == max? \"#3f4d63\": \"#c6ccd8\") })\n            })\n\n});\n'''\n\nh = display(HTML(htmlt1))\n\nj = IPython.display.Javascript(js_t1)\nIPython.display.display_javascript(j)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the first time we see Data Analyst ranked highly in the percentage of ml users across fields, this might mean that their focus is on predictive modelling and analytics, without the use of computer vision or NLP methods.\n\nIn countries we see how France and surprisingly China, have dropped off the top 10 list and are replaced by Spain and Nigeria. As the first African country to break the top 10 employers list, it shows that there is promise for machine learning and data science in Africa.\n\nLet's take a look at some of the methods that might be worth knowing in this area.\n* **Linear and Logistic regression:** As everyone's starting point in machine learning, it's important to gain a good understanding of how linear models work which will act as a solid foundation even when working with more complex algorithms.\n* **Decision Trees and Random Forests:** Decision trees work by making a series of sequential decisions leading to a particular prediction. Random forests combine the outputs of several randomly generated trees which improves the overall performance on unseen data, as opposed to using a single decision tree.\n* **Gradient Boosting machines(xgboost, lightGBM):** While I wont go into the specifics of how each one works, in general gradient boosting involves building a predictive model using an ensemble on weaker prediction models. \n* **Convolutional Neural Networks**: CNNs are a class of deep neural networks that form the backbone of image processing in artificial intelligence. They are a great fit whenever the data has a natural 2D(or even 3D) structure.\n\n## <div class=\"subsection_title\"> What do they do?</div>\n<div class=\"sidenote\">\n    Source: Kaggle 2020 DS and ML Survey - \n    <span style=\"font-style: italic;\"> Q23. Select any activities that make up an important part of your role at work.\n    </span>\n</div>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"htmlt1 = '''\n<html>\n\t<head>\n        <style>\n            body .radarChart_ml{\n                font-family: 'Open Sans', sans-serif;\n                font-size: 11px;\n                font-weight: 300;\n                fill: #242424;\n                text-align: center;\n                text-shadow: 0 1px 0 #fff, 1px 0 0 #fff, -1px 0 0 #fff, 0 -1px 0 #fff;\n                cursor: default;\n                width: 400px;\n                height: 400px;\n                padding: 10px 0px;\n                margin: auto;\n                border: 1px solid #d7d7d7;\n                box-shadow: 2px 2px 2px 1px rgba(0,0,0,0.3);\n            }\n\n            .radarChart_ml h2{\n                font-family: 'Open Sans', sans-serif;\n                font-size: 20px;\n                font-weight: 600;\n                fill: #242424;\n                text-align: center;\t\t\t\t\t\n            }\n\n            .radarChart_ml .legend {\n                font-family: 'Raleway', sans-serif;\n                fill: #333333;\n            }\n\n            .radarChart_ml .tooltip {\n                fill: #333333;\n            }\n        </style>\n    </head>\n    <body>\n        <div class=\"radarChart_ml\">\n            <h2>Roles in <span style=\"color:#496595\">Machine learning</span> vs <span style=\"color:#bbb\">all</span></h2>\n        </div>\n    </body>\n'''\n\njs_t1 = '''\n         require.config({\n            paths: {\n                d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\"\n             }\n             });\n        require([\"d3\"], function(d3) {\nfunction RadarChart(id, data, options) {\n\tvar cfg = {\n\t w: 600,\t\t\t\t//Width of the circle\n\t h: 600,\t\t\t\t//Height of the circle\n\t margin: {top: 20, right: 20, bottom: 20, left: 20}, //The margins of the SVG\n\t levels: 3,\t\t\t\t//How many levels or inner circles should there be drawn\n\t maxValue: 0, \t\t\t//What is the value that the biggest circle will represent\n\t labelFactor: 1.26, \t//How much farther than the radius of the outer circle should the labels be placed\n\t wrapWidth: 60, \t\t//The number of pixels after which a label needs to be given a new line\n\t opacityArea: 0.35, \t//The opacity of the area of the blob\n\t dotRadius: 3, \t\t\t//The size of the colored circles of each blog\n\t opacityCircles: 0.1, \t//The opacity of the circles of each blob\n\t strokeWidth: 1, \t\t//The width of the stroke around each blob\n\t roundStrokes: false,\t//If true the area and stroke will follow a round path (cardinal-closed)\n\t color: d3.scaleOrdinal().range([\"#bbb\",\"#496595\"])\t//Color function\n\t};\n\t\n\t//Put all of the options into a variable called cfg\n\tif('undefined' !== typeof options){\n\t  for(var i in options){\n\t\tif('undefined' !== typeof options[i]){ cfg[i] = options[i]; }\n\t  }//for i\n\t}//if\n\t\n\t//If the supplied maxValue is smaller than the actual one, replace by the max in the data\n\tvar maxValue = Math.max(cfg.maxValue, d3.max(data, function(i){return d3.max(i.map(function(o){return o.value;}))}));\n\t\t\n\tvar allAxis = (data[0].map(function(i, j){return i.axis})),\t//Names of each axis\n\t\ttotal = allAxis.length,\t\t\t\t\t//The number of different axes\n\t\tradius = Math.min(cfg.w/2, cfg.h/2), \t//Radius of the outermost circle\n\t\tFormat = d3.format('.0%'),\t\t\t \t//Percentage formatting\n\t\tangleSlice = Math.PI * 2 / total;\t\t//The width in radians of each \"slice\"\n\t\n\t//Scale for the radius\n\tvar rScale = d3.scaleLinear()\n\t\t.range([0, radius])\n\t\t.domain([0, maxValue]);\n\t\t\n\t/////////////////////////////////////////////////////////\n\t//////////// Create the container SVG and g /////////////\n\t/////////////////////////////////////////////////////////\n\n\t//Remove whatever chart with the same id/class was present before\n\td3.select(id).select(\"svg\").remove();\n\t\n\t//Initiate the radar chart SVG\n\tvar svg = d3.select(id).append(\"svg\")\n\t\t\t.attr(\"width\",  cfg.w + cfg.margin.left + cfg.margin.right)\n\t\t\t.attr(\"height\", cfg.h + cfg.margin.top + cfg.margin.bottom)\n\t\t\t.attr(\"class\", \"radar\"+id);\n\t//Append a g element\t\t\n\tvar g = svg.append(\"g\")\n\t\t\t.attr(\"transform\", \"translate(\" + (cfg.w/2 + cfg.margin.left) + \",\" + (cfg.h/2 + cfg.margin.top) + \")\");\n\t\n\t/////////////////////////////////////////////////////////\n\t////////// Glow filter for some extra pizzazz ///////////\n\t/////////////////////////////////////////////////////////\n\t\n\t//Filter for the outside glow\n\tvar filter = g.append('defs').append('filter').attr('id','glow'),\n\t\tfeGaussianBlur = filter.append('feGaussianBlur').attr('stdDeviation','2.5').attr('result','coloredBlur'),\n\t\tfeMerge = filter.append('feMerge'),\n\t\tfeMergeNode_1 = feMerge.append('feMergeNode').attr('in','coloredBlur'),\n\t\tfeMergeNode_2 = feMerge.append('feMergeNode').attr('in','SourceGraphic');\n\n\t/////////////////////////////////////////////////////////\n\t/////////////// Draw the Circular grid //////////////////\n\t/////////////////////////////////////////////////////////\n\t\n\t//Wrapper for the grid & axes\n\tvar axisGrid = g.append(\"g\").attr(\"class\", \"axisWrapper\");\n\t\n\t//Draw the background circles\n\taxisGrid.selectAll(\".levels\")\n\t   .data(d3.range(1,(cfg.levels+1)).reverse())\n\t   .enter()\n\t\t.append(\"circle\")\n\t\t.attr(\"class\", \"gridCircle\")\n\t\t.attr(\"r\", function(d, i){return radius/cfg.levels*d;})\n\t\t.style(\"fill\", \"#fff\")\n\t\t.style(\"stroke\", \"#dedede\")\n\t\t.style(\"fill-opacity\", cfg.opacityCircles)\n\t\t.style(\"filter\" , \"url(#glow)\");\n\n\t//Text indicating at what % each level is\n\taxisGrid.selectAll(\".axisLabel\")\n\t   .data(d3.range(1,(cfg.levels+1)).reverse())\n\t   .enter().append(\"text\")\n\t   .attr(\"class\", \"axisLabel\")\n\t   .attr(\"x\", 4)\n\t   .attr(\"y\", function(d){return -d*radius/cfg.levels;})\n\t   .attr(\"dy\", \"0.4em\")\n\t   .style(\"font-size\", \"10px\")\n\t   .attr(\"fill\", \"#737373\")\n\t   .text(function(d,i) { return Format(maxValue * d/cfg.levels); });\n\n\t/////////////////////////////////////////////////////////\n\t//////////////////// Draw the axes //////////////////////\n\t/////////////////////////////////////////////////////////\n\t\n\t//Create the straight lines radiating outward from the center\n\tvar axis = axisGrid.selectAll(\".axis\")\n\t\t.data(allAxis)\n\t\t.enter()\n\t\t.append(\"g\")\n\t\t.attr(\"class\", \"axis\");\n\t//Append the lines\n\taxis.append(\"line\")\n\t\t.attr(\"x1\", 0)\n\t\t.attr(\"y1\", 0)\n\t\t.attr(\"x2\", function(d, i){ return rScale(maxValue*1.05) * Math.cos(angleSlice*i - Math.PI/2); })\n\t\t.attr(\"y2\", function(d, i){ return rScale(maxValue*1.05) * Math.sin(angleSlice*i - Math.PI/2); })\n\t\t.attr(\"class\", \"line\")\n\t\t.style(\"stroke\", \"#333\")\n\t\t.style(\"stroke-width\", \"1px\");\n\n\t//Append the labels at each axis\n\taxis.append(\"text\")\n\t\t.attr(\"class\", \"legend\")\n\t\t.style(\"font-size\", \"10px\")\n\t\t.attr(\"text-anchor\", \"middle\")\n\t\t.attr(\"dy\", \"-1em\")\n\t\t.attr(\"x\", function(d, i){ return rScale(maxValue * cfg.labelFactor) * Math.cos(angleSlice*i - Math.PI/2); })\n\t\t.attr(\"y\", function(d, i){ return rScale(maxValue * cfg.labelFactor) * Math.sin(angleSlice*i - Math.PI/2); })\n        .text(function(d){return d})\n        .style(\"font-weight\",600)\n\t\t.call(wrap, cfg.wrapWidth);\n\n\t/////////////////////////////////////////////////////////\n\t///////////// Draw the radar chart blobs ////////////////\n\t/////////////////////////////////////////////////////////\n\t\n\t//The radial line function\n\tvar radarLine = d3.lineRadial()\n\t\t.radius(function(d) { return rScale(d.value); })\n\t\t.angle(function(d,i) {\treturn i*angleSlice; })\n        .curve(d3.curveLinearClosed);\n\t\t\n\tif(cfg.roundStrokes) {\n\t\tradarLine.interpolate(\"cardinal-closed\");\n\t}\n\t\t\t\t\n\t//Create a wrapper for the blobs\t\n\tvar blobWrapper = g.selectAll(\".radarWrapper\")\n\t\t.data(data)\n\t\t.enter().append(\"g\")\n\t\t.attr(\"class\", \"radarWrapper\");\n\t\t\t\n\t//Append the backgrounds\t\n\tblobWrapper\n\t\t.append(\"path\")\n\t\t.attr(\"class\", \"radarArea\")\n\t\t.attr(\"d\", function(d,i) { return radarLine(d); })\n\t\t.style(\"fill\", function(d,i) { return cfg.color(i); })\n\t\t.style(\"fill-opacity\", cfg.opacityArea)\n\t\t.on('mouseover', function (d,i){\n\t\t\t//Dim all blobs\n\t\t\td3.selectAll(\".radarArea\")\n\t\t\t\t.transition().duration(200)\n\t\t\t\t.style(\"fill-opacity\", 0.1); \n\t\t\t//Bring back the hovered over blob\n\t\t\td3.select(this)\n\t\t\t\t.transition().duration(200)\n\t\t\t\t.style(\"fill-opacity\", 0.7);\t\n\t\t})\n\t\t.on('mouseout', function(){\n\t\t\t//Bring back all blobs\n\t\t\td3.selectAll(\".radarArea\")\n\t\t\t\t.transition().duration(200)\n\t\t\t\t.style(\"fill-opacity\", cfg.opacityArea);\n\t\t});\n\t\t\n\t//Create the outlines\t\n\tblobWrapper.append(\"path\")\n\t\t.attr(\"class\", \"radarStroke\")\n\t\t.attr(\"d\", function(d,i) { return radarLine(d); })\n\t\t.style(\"stroke-width\", cfg.strokeWidth + \"px\")\n\t\t.style(\"stroke\", function(d,i) { return cfg.color(i); })\n\t\t.style(\"fill\", \"none\")\n\t\t.style(\"filter\" , \"url(#glow)\");\t\t\n\t\n\t//Append the circles\n\tblobWrapper.selectAll(\".radarCircle\")\n\t\t.data(function(d,i) { return d; })\n\t\t.enter().append(\"circle\")\n\t\t.attr(\"class\", \"radarCircle\")\n\t\t.attr(\"r\", cfg.dotRadius)\n\t\t.attr(\"cx\", function(d,i){ return rScale(d.value) * Math.cos(angleSlice*i - Math.PI/2); })\n\t\t.attr(\"cy\", function(d,i){ return rScale(d.value) * Math.sin(angleSlice*i - Math.PI/2); })\n\t\t.style(\"fill\", function(d,i,j) { return data[0].map((d)=>d.value).includes(d.value)? cfg.color(0): cfg.color(1); })\n\t\t.style(\"fill-opacity\", 0.8);\n\n\t/////////////////////////////////////////////////////////\n\t//////// Append invisible circles for tooltip ///////////\n\t/////////////////////////////////////////////////////////\n\t\n\t//Wrapper for the invisible circles on top\n\tvar blobCircleWrapper = g.selectAll(\".radarCircleWrapper\")\n\t\t.data(data)\n\t\t.enter().append(\"g\")\n\t\t.attr(\"class\", \"radarCircleWrapper\");\n\t\t\n\t//Append a set of invisible circles on top for the mouseover pop-up\n\tblobCircleWrapper.selectAll(\".radarInvisibleCircle\")\n\t\t.data(function(d,i) { return d; })\n\t\t.enter().append(\"circle\")\n\t\t.attr(\"class\", \"radarInvisibleCircle\")\n\t\t.attr(\"r\", cfg.dotRadius*1.5)\n\t\t.attr(\"cx\", function(d,i){ return rScale(d.value) * Math.cos(angleSlice*i - Math.PI/2); })\n\t\t.attr(\"cy\", function(d,i){ return rScale(d.value) * Math.sin(angleSlice*i - Math.PI/2); })\n\t\t.style(\"fill\", \"none\")\n\t\t.style(\"pointer-events\", \"all\")\n\t\t.on(\"mouseover\", function(d,i) {\n\t\t\tnewX =  parseFloat(d3.select(this).attr('cx')) - 10;\n\t\t\tnewY =  parseFloat(d3.select(this).attr('cy')) - 10;\n\t\t\t\t\t\n\t\t\ttooltip\n\t\t\t\t.attr('x', newX)\n\t\t\t\t.attr('y', newY)\n\t\t\t\t.text(Format(d.value))\n\t\t\t\t.transition().duration(200)\n\t\t\t\t.style('opacity', 1);\n\t\t})\n\t\t.on(\"mouseout\", function(){\n\t\t\ttooltip.transition().duration(200)\n\t\t\t\t.style(\"opacity\", 0);\n\t\t});\n\t\t\n\t//Set up the small tooltip for when you hover over a circle\n\tvar tooltip = g.append(\"text\")\n\t\t.attr(\"class\", \"tooltip\")\n\t\t.style(\"opacity\", 0);\n\t\n\t/////////////////////////////////////////////////////////\n\t/////////////////// Helper Function /////////////////////\n\t/////////////////////////////////////////////////////////\n\n\t//Taken from http://bl.ocks.org/mbostock/7555321\n\t//Wraps SVG text\t\n\tfunction wrap(text, width) {\n\t  text.each(function() {\n\t\tvar text = d3.select(this),\n\t\t\twords = text.text().split(/\\s+/).reverse(),\n\t\t\tword,\n\t\t\tline = [],\n\t\t\tlineNumber = 0,\n\t\t\tlineHeight = 1.4, // ems\n\t\t\ty = text.attr(\"y\"),\n\t\t\tx = text.attr(\"x\"),\n\t\t\tdy = parseFloat(text.attr(\"dy\")),\n\t\t\ttspan = text.text(null).append(\"tspan\").attr(\"x\", x).attr(\"y\", y).attr(\"dy\", dy + \"em\");\n\t\t\t\n\t\twhile (word = words.pop()) {\n\t\t  line.push(word);\n\t\t  tspan.text(line.join(\" \"));\n\t\t  if (tspan.node().getComputedTextLength() > width) {\n\t\t\tline.pop();\n\t\t\ttspan.text(line.join(\" \"));\n\t\t\tline = [word];\n\t\t\ttspan = text.append(\"tspan\").attr(\"x\", x).attr(\"y\", y).attr(\"dy\", ++lineNumber * lineHeight + dy + \"em\").text(word);\n\t\t  }\n\t\t}\n\t  });}\n}\n\nvar margin_radar_ml = {top: 70, right: 50, bottom: 50, left: 50},\n\t\t\t\twidth_radar_ml = 350 - margin_radar_ml.left - margin_radar_ml.right,\n\t\t\t\theight_radar_ml = 350 - margin_radar_ml.top - margin_radar_ml.bottom - 20;\n\t\t\t\t\t\n\t\t\t////////////////////////////////////////////////////////////// \n\t\t\t////////////////////////// Data ////////////////////////////// \n\t\t\t////////////////////////////////////////////////////////////// \n\n\t\t\tvar data = [\n            [   \n                {'axis': 'Build the data infrastructure', 'value': 0.3797757950125829},\n\t\t\t\t{'axis': 'Analyze data for business', 'value': 0.7345001143902997},\n\t\t\t\t{'axis': 'Build ML prototypes in new areas', 'value': 0.458361930908259},\n                {'axis': 'Build ML services for products/workflows',\n                'value': 0.31171356668954475},\n                {'axis': 'Improving existing ML models', 'value': 0.3567833447723633},\n                {'axis': 'Research to advance ML', 'value': 0.2675589110043468}\n            ],\n            [ // ML users             \n             {'axis': 'Build the data infrastructure', 'value': 0.3849462365591398},\n             {'axis': 'Analyze data for business decisions', 'value': 0.7206989247311828},\n             {'axis': 'Build ML prototypes in new areas', 'value': 0.511021505376344},\n             {'axis': 'Build ML services for products/workflows', 'value': 0.3467741935483871},\n             {'axis': 'Improving existing ML models', 'value': 0.4028225806451613},\n             {'axis': 'Research to advance ML', 'value': 0.2918010752688172}]\n            ];\n\t\t\t////////////////////////////////////////////////////////////// \n\t\t\t//////////////////// Draw the Chart ////////////////////////// \n\t\t\t////////////////////////////////////////////////////////////// \n\n\t\t\t\t\n\t\t\tvar radarChartOptions = {\n\t\t\t  w: width_radar_ml,\n\t\t\t  h: height_radar_ml,\n\t\t\t  margin: margin_radar_ml,\n\t\t\t  maxValue: 0.8,\n\t\t\t  levels: 4,\n\t\t\t  roundStrokes: false,\n\t\t\t};\n\t\t\t//Call function to draw the Radar chart\n\t\t\tRadarChart(\".radarChart_ml\", data, radarChartOptions);\n\n});\n'''\n\nh = display(HTML(htmlt1))\n\nj = IPython.display.Javascript(js_t1)\nIPython.display.display_javascript(j)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since there most data professionals tend to be familiar with at least one of these basic machine learning algorithms, we see that the radar for both groups is almost identical. This group has a **greater focus on delivering business insights** as compared to the two previous groups."},{"metadata":{"_kg_hide-input":true,"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Will let us pick how many countries to consider.\ncutoff = 10\ncountries = list( ml_users[\"Q3\"].value_counts().index[:cutoff] )\ncountries_count = ml_users[\"Q3\"].value_counts()[countries]\n\n# Drop all individuals that didnt mention salary\nml_users_with_salary = ml_users.dropna(subset = [\"Q24\"])\n\nml_users_with_salary[\"Q24_amounts\"] = [(earnings_map[payrange]) for payrange in ml_users_with_salary[\"Q24\"]]\nsalary_data = np.int32(ml_users_with_salary.groupby([\"Q3\"])[\"Q24_amounts\"].mean()[countries])\n\n# Creating the dataframe\nml_tree_df = pd.DataFrame(columns=[\"name\",\"parent\",\"value\",\"value2\"])\nml_tree_df.loc[0] = [\"Origin\",\"\",\"\",\"\"]\n\nml_tree_temp = pd.DataFrame(columns=[\"name\",\"parent\",\"value\",\"value2\"])\n\nml_tree_temp[\"value\"] = ml_users[\"Q3\"].value_counts()[countries].values\nml_tree_temp[\"value2\"]= salary_data\nml_tree_temp[\"parent\"]= \"Origin\"\n\n# Editing label names\ncountries_new = countries\ncountries_new[5] = \"United Kingdom\"\nml_tree_temp[\"name\"] = countries_new\n\nml_tree_df = ml_tree_df.append(ml_tree_temp, ignore_index = True)\n\nml_tree_df = shuffle(ml_tree_df, random_state=1000)\n\nml_tree_df.to_csv(\"ml_tree.csv\", index=False, header=[\"name\",\"parent\",\"value\",\"value2\"])\n\nhtmlt1 = '''\n<html lang=\"en\">\n<head>\n    <title>Document</title>\n    <style>\n        #ml_tree{\n           display: inline-block;\n            margin: 10px 0px;\n            border: 1px solid #d7d7d7;\n            width: 714px;\n            box-shadow: 2px 2px 2px 1px rgba(0,0,0,0.3); \n        }\n        #tree_button_ml1{\n            border-radius: 0;\n            background-color: #fff;\n            border: 1px solid #d7d7d7;\n            position: relative;\n            top:  5px;\n            width: 75px;\n            left: 621px;\n            color: #000;\n        }\n        #tree_button_ml2{\n            border-radius: 0;\n            background-color: #fff;\n            border: 1px solid #d7d7d7;\n            position: relative;\n            top:  5px;\n            left: 373px;\n            color: #000;\n        }\n\n        #tree_button_ml1:hover, #tree_button_ml2:hover{\n            background-color: #d7d7d7;\n        }\n        #tree_button_ml1:focus, #tree_button_ml2:focus{\n            outline: none;\n            background-color: #4d4d4d;\n            color: #fff;\n        }\n\n    </style>\n</head>\n<body>\n    \n</body>\n</html>\n'''\n\njs_t1 = '''\n         require.config({\n            paths: {\n                d3: \"https://d3js.org/d3.v4.min\"\n             }\n             });\n        require([\"d3\"], function(d3) {\n        \n         var margin_tree_ml = {top: 20, right: 10, bottom: 5, left: 10},\n            width_tree_ml = 710 - margin_tree_ml.left - margin_tree_ml.right,\n            height_tree_ml = 340 - margin_tree_ml.top - margin_tree_ml.bottom;\n        \n        // append the svg object to the body of the page\n        var svg_tree_ml = d3.select(\"#ml_tree\")\n        .append(\"svg\")\n            .attr(\"width\", width_tree_ml + margin_tree_ml.left + margin_tree_ml.right)\n            .attr(\"height\", height_tree_ml + margin_tree_ml.top + margin_tree_ml.bottom)\n        .append(\"g\")\n            .attr(\"transform\", \"translate(\" + margin_tree_ml.left + \",\" + margin_tree_ml.top + \")\");\n        \n        showData(\"count\")\n        document.getElementById(\"tree_button_ml1\").addEventListener(\"click\", function(evt) {showData(\"count\")});\n        document.getElementById(\"tree_button_ml2\").addEventListener(\"click\", function(evt) {showData(\"salary\")});\n\n        function showData(mode){\n        // Read data\n        d3.csv('ml_tree.csv', function(data) {\n        \n        var max = d3.max(data, (d)=> {return mode ==\"count\"?  +d.value: +d.value2;})\n       \n        var colorScale1 = d3.scaleLinear()\n        .range([\"#f1efd9\",\"#AF9973\",\"#a2885e\"]) //[\"#a2885e\",\"#f1efd9\",\"#235f83\"]\n        .domain([40,max/6, max])\n\n        var colorScale2 = d3.scaleLinear()\n        .range([\"#f1efd9\",\"#457791\",\"#235f83\"]) //[\"#a2885e\",\"#f1efd9\",\"#235f83\"]\n        .domain([5000,max/2, max])\n\n          // stratify the data: reformatting for d3.js\n        var root = d3.stratify()\n            .id(function(d) { return d.name; })   // Name of the entity (column name is name in csv)\n            .parentId(function(d) { return d.parent; })   // Name of the parent (column name is parent in csv)\n            (data);\n        root.sum(function(d) {return mode ==\"count\"?  +d.value: +d.value2; })   // Compute the numeric value for each entity\n        \n          // Then d3.treemap computes the position of each element of the hierarchy\n          // The coordinates are added to the root object above\n        d3.treemap()\n            .size([width_tree_ml, height_tree_ml])\n            .padding(4)\n            (root)\n\n        var u = svg_tree_ml\n            .selectAll(\"rect\")\n            .data(root.leaves())\n            \n            u\n            .enter()\n            .append(\"rect\")\n            .merge(u)\n            .transition()\n            .duration(700)\n            .attr('x', function (d) { return d.x0; })\n            .attr('y', function (d) { return d.y0; })\n            .attr('width', function (d) { return d.x1 - d.x0; })\n            .attr('height', function (d) { return d.y1 - d.y0; })\n            .style(\"stroke\", \"black\")\n            .style(\"fill\", (d) => {\n                return (mode ==\"count\"?  colorScale1(+d.value): colorScale2(+d.value))\n            });\n    \n        // and to add the text labels\n        var v = svg_tree_ml\n            .selectAll(\"text\")\n            .data(root.leaves())\n\n            v\n            .enter()\n            .append(\"text\")\n            .merge(v)\n                .attr(\"x\", function(d){ return d.x0+10})    // +10 to adjust position (more right)\n                .attr(\"y\", function(d){ return d.y0+15})    // +20 to adjust position (lower)\n                .text(function(d){ return d.data.name})\n                .attr(\"font-size\", \"15px\")\n                .attr(\"fill\", \"white\")\n        \n        var w = svg_tree_ml\n            .selectAll(\"text.count\")\n            .data(root.leaves())\n\n            w\n            .enter()\n            .append(\"text\")\n            .merge(w)\n                .attr(\"class\", function(d){ return \"count \"+d.data.name})\n                .attr(\"x\", function(d){ return (d.x1+d.x0)/2 })    // +10 to adjust position (more right)\n                .attr(\"y\", function(d){ return (d.y1+d.y0)/2 + 15})    // +20 to adjust position (lower)\n                .text(function(d){ return mode == \"count\"? d.data.value: (d.data.value2.replace(/\\B(?=(\\d{3})+(?!\\d))/g, \",\"));})\n                .attr(\"text-anchor\",\"middle\")\n                .style(\"font-size\", function(d){ \n                    return mode == \"count\"? \"30px\" : \"22px\";\n                })\n                .attr(\"fill\", \"white\")\n                .style(\"font-family\", \"Arial\")\n        \n        svg_tree_ml\n            .append(\"text\")\n            .attr(\"class\",\"title\")\n            .text(\"Salaries and Counts of Countries\")\n            .attr(\"x\", 5)\n            .attr(\"y\",-5)\n            .style(\"font-family\", \"Times New Roman\")\n            .style(\"font-size\", \"21px\")\n        })\n    }\n\n\n});\n'''\n\nh = display(HTML(htmlt1))\n\nj = IPython.display.Javascript(js_t1)\nIPython.display.display_javascript(j)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Creating heatmap data csv for ml users' team sizes\nml_heatmap_data = ml_users.groupby([\"Q20\"])[\"Q21\"].value_counts()\n\nml_heatmap_df = pd.DataFrame()\nfor cosize in dataprofs[\"Q20\"].unique():\n    ml_heatmap_df[cosize] = ml_heatmap_data[cosize]\n\nml_heatmap_df.columns = [col.split(\" employees\")[0] for col in ml_heatmap_df.columns]\n\nml_data_list = []\nfor cosize in ml_heatmap_df.columns:\n    for dssize in ml_heatmap_df.index:\n        ml_data_list.append([cosize, dssize, ml_heatmap_df[cosize].loc[dssize]])\n        \nml_data_df =  pd.DataFrame(ml_data_list)\n\nml_data_df.to_csv(\"ml_heatmap.csv\", index=False, header=[\"cosize\",\"dssize\",\"value\"])\n\n# Creating csv for machine learning experience bar chart\n\nml_mlexp = ml_users[\"Q15\"].value_counts().sort_values(ascending=False)\n\n# Renaming the indexes and then reordering them (there are easier ways to do this though)\nml_mlexp.index = [x+\" years\" for x in['1-2', '2-3', '0-1', '5-10', '3-4', '4-5', '10-20', '20+']]\nml_mlexp = ml_mlexp.reindex(x+\" years\" for x in['0-1', '1-2', '2-3', '3-4', '4-5', '5-10', '10-20', '20+'])\n\nml_mlexp_df = pd.DataFrame()\nml_mlexp_df[\"exp\"] = ml_mlexp.index\nml_mlexp_df[\"value\"] = ml_mlexp.values\n\nml_mlexp_df.to_csv(\"ml_mlexp.csv\", index=False, header=[\"exp\",\"value\"])\n\nhtmlt1 = '''\n<html lang=\"en\">\n<head>\n    <title>Document</title>\n    <style>\n        #ml_heatmap{\n            display: inline-block;\n            border: 1px solid #d7d7d7;\n            width: 350px;\n            box-shadow: 2px 2px 2px 1px rgba(0,0,0,0.3); \n        }\n        #ml_mlexp_ml{\n            display: inline-block;\n            margin-left: 10px;\n            border: 1px solid #d7d7d7;\n            width: 350px;\n            box-shadow: 2px 2px 2px 1px rgba(0,0,0,0.3); \n        }\n    </style>\n</head>\n<body>\n</body>\n</html>\n'''\n\njs_t1 = '''\n         require.config({\n            paths: {\n                d3: \"https://d3js.org/d3.v4.min\"\n             }\n             });\n        require([\"d3\"], function(d3) {\n        \n         var margin_heatmap_ml = {top: 40, right: 20, bottom: 40, left: 60},\n        width_heatmap_ml = 350 - margin_heatmap_ml.left - margin_heatmap_ml.right,\n        height_heatmap_ml = 340 - margin_heatmap_ml.top - margin_heatmap_ml.bottom;\n        \n        // append the svg object to the body of the page\n        var svg_heatmap_ml = d3.select(\"#ml_heatmap\")\n        .append(\"svg\")\n        .attr(\"width\", width_heatmap_ml + margin_heatmap_ml.left + margin_heatmap_ml.right)\n        .attr(\"height\", height_heatmap_ml + margin_heatmap_ml.top + margin_heatmap_ml.bottom)\n        .append(\"g\")\n        .attr(\"transform\",\n                \"translate(\" + margin_heatmap_ml.left + \",\" + margin_heatmap_ml.top + \")\");\n        \n        // add title\n        svg_heatmap_ml.append(\"text\")\n            .text(\"Company and DS team sizes\")\n            .attr(\"x\",0)\n            .attr(\"y\",-10)\n            .style(\"font-family\", \"Times New Roman\")\n            .style(\"font-size\", \"21px\") \n\n        svg_heatmap_ml.append(\"text\")\n            .text(\"Company size (employees)\")\n            .attr(\"x\", width_heatmap_ml/2)\n            .attr(\"y\", height_heatmap_ml + 32)\n            .attr(\"text-anchor\",\"middle\")\n            .style(\"font-weight\",\"600\")\n            .style(\"font-family\", \"Tahoma\")\n            .style(\"font-size\", \"12px\")\n        \n        svg_heatmap_ml.append(\"text\")\n            .attr(\"transform\", \"rotate(-90)\")\n            .attr(\"y\", 0 - margin_heatmap_ml.left + 6)\n            .attr(\"x\",0 - (height_heatmap_ml / 2))\n            .attr(\"dy\", \"1em\")\n            .style(\"text-anchor\", \"middle\")\n            .style(\"font-weight\",\"600\")\n            .style(\"font-family\", \"Tahoma\")\n            .style(\"font-size\", \"13px\") \n            .text(\"Data Science team size\");  \n                        \n        // Labels of row and columns\n        var myGroups = ['0-49', '50-249', '250-999', '1000-9,999', '10,000 or more']\n        var myVars = ['0', '1-2', '3-4', '5-9', '10-14', '15-19', '20+']\n        \n        // Build X scales and axis:\n        var x = d3.scaleBand()\n        .range([ 0, width_heatmap_ml ])\n        .domain(myGroups)\n        .padding(0.01);\n        svg_heatmap_ml.append(\"g\")\n        .attr(\"transform\", \"translate(0,\" + height_heatmap_ml + \")\")\n        .call(d3.axisBottom(x))\n        .selectAll(\"text\")\n            .style(\"font-size\",\"9px\")\n        \n        // Build X scales and axis:\n        var y = d3.scaleBand()\n        .range([ height_heatmap_ml, 0 ])\n        .domain(myVars)\n        .padding(0.01);\n        svg_heatmap_ml.append(\"g\")\n        .call(d3.axisLeft(y));\n        \n        // Build color scale\n        var myColor = d3.scaleLinear()\n        .range([\"#f7f7f7\", \"#29658c\"]) //e9cf87\n        .domain([1,1200])\n        \n        //Read the data\n        d3.csv(\"ml_heatmap.csv\", function(data) {\n        \n        svg_heatmap_ml.selectAll()\n            .data(data)\n            .enter()\n            .append(\"rect\")\n            .attr(\"x\", function(d) { return x(d.cosize) })\n            .attr(\"y\", function(d) { return y(d.dssize) })\n            .attr(\"width\", x.bandwidth() )\n            .attr(\"height\", y.bandwidth() )\n            .style(\"fill\", function(d) { return myColor(d.value)} )\n        \n        })\n\n        var margin_mlexp_ml = {top: 35, right: 20, bottom: 40, left: 70},\n            width_mlexp_ml  = 350 - margin_mlexp_ml.left - margin_mlexp_ml.right,\n            height_mlexp_ml = 340 - margin_mlexp_ml.top - margin_mlexp_ml.bottom;\n\n        var svg_mlexp_ml = d3.select(\"#ml_mlexp_ml\")\n            .append(\"svg\")\n                .attr(\"width\", width_mlexp_ml + margin_mlexp_ml.left + margin_mlexp_ml.right)\n                .attr(\"height\", height_mlexp_ml + margin_mlexp_ml.top + margin_mlexp_ml.bottom)\n            .append(\"g\")\n                .attr(\"transform\",\n                    \"translate(\" + margin_mlexp_ml.left + \",\" + margin_mlexp_ml.top + \")\");\n        \n        svg_mlexp_ml.append(\"text\")\n            .text(\"Machine Learning experience\")\n            .attr(\"x\",-5)\n            .attr(\"y\",-10)\n            .style(\"font-family\", \"Times New Roman\")\n            .style(\"font-size\", \"21px\")\n            \n        svg_mlexp_ml.append(\"text\")\n            .text(\"Respondent's count\")\n            .attr(\"x\", width_mlexp_ml/2 - 10)\n            .attr(\"y\", height_mlexp_ml + 32)\n            .attr(\"text-anchor\",\"middle\")\n            .style(\"font-weight\",\"600\")\n            .style(\"font-family\", \"Tahoma\")\n            .style(\"font-size\", \"12px\")\n\n        d3.csv(\"ml_mlexp.csv\", function(data) {\n\n            // data = data.sort((a,b) => d3.descending(+a.value, +b.value))\n            var max = d3.max(data, d=> +d.value)\n\n            // Add X axis\n            var x = d3.scaleLinear()\n                .domain([0, 2000])\n                .range([ 0, width_mlexp_ml]);\n            svg_mlexp_ml.append(\"g\")\n                .attr(\"transform\", \"translate(0,\" + height_mlexp_ml + \")\")\n                .call(d3.axisBottom(x))\n                .selectAll(\"text\")\n                    .attr(\"transform\", \"translate(-10,0)\")\n                    .style(\"text-anchor\", \"end\");\n\n            // Y axis\n            var y = d3.scaleBand()\n            .range([ 0, height_mlexp_ml ])\n            .domain(data.map(function(d) { return d.exp; }))\n            .padding(.05);\n            svg_mlexp_ml.append(\"g\")\n            .call(d3.axisLeft(y))\n                .selectAll(\"text\")\n                .style(\"font-family\", \"Tahoma\")\n                .style(\"font-size\", \"11px\")\n\n            // Bars\n            svg_mlexp_ml.selectAll(\"myRect\")\n            .data(data)\n            .enter()\n            .append(\"rect\")\n                .attr(\"x\", x(0) )\n                .attr(\"y\", function(d) { return y(d.exp); })\n                .attr(\"width\", function(d) { return x(d.value); })\n                .attr(\"height\", y.bandwidth() )\n                .attr(\"fill\", (d) => { return (+d.value == max? \"#3f4d63\": \"#c6ccd8\") })\n            })\n\n});\n'''\n\nh = display(HTML(htmlt1))\n\nj = IPython.display.Javascript(js_t1)\nIPython.display.display_javascript(j)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <div class=\"subsection_title\">Note </div>\nAs we have reached the end of the notebook, one might notice that I haven't touched on the topics of business intelligence tools, database specifics, big data products, ML automation, etc. The reason for this is not that I don't find these products relevant in the workplace, but rather that I felt that the choice of these tools are often dependent on existing company practices, rather than personal preference.\n\nWhile it could help to be familiar with these tools, I preferred to focus attention on the other tools/languages that form the core part of their foundations in working with data.\n"},{"metadata":{},"cell_type":"markdown","source":"# <div class=\"section_title\">5. Conclusion</div>\n\nI understand that throughout the course of this notebook I have bombarded you with a lot of information on working with data. It is easy to feel a little overwhelmed by all the different moving parts involved and think that you might have bit off a bit more than you can chew when you decided to try your hand at data science, especially when you are just starting out. \n\nTo this, I'd like to remind you that noone enters their first job( or even switching to a new role) knowing everything on day one - you will learn as you work and you are allowed to( *and will*) make mistakes. It's just a desire to learn and improve which makes things easier.\n\nThanks for joining me in this journey and I hope you found something of use in this notebook. <b style='color:#496595'>Stay safe and keep learning!</b>\n"},{"metadata":{},"cell_type":"markdown","source":"## <div class=\"section_title\">6. References</div>\n1. [The 2020 HackerEarth developer survey](https://www.hackerearth.com/recruit/developer-survey/): Helped to compare how surveys from different sources affects responses.\n2. [Anaconda's State of Data Science Report 2020](https://www.anaconda.com/state-of-data-science-2020): Another great survey with interesting insights on the current state of data science.\n3. [The Data Science Process: What a data scientist actually does day-to-day](https://medium.springboard.com/the-data-science-process-the-complete-laymans-guide-to-what-a-data-scientist-actually-does-ca3e166b7c67): Information about data life cycle.\n4. [The “Generic” Data Science Life-Cycle](https://towardsdatascience.com/stoend-to-end-data-science-life-cycle-6387523b5afc): Additional breakdown of data life cycle stages.\n5. [How to put machine learning models into production](https://stackoverflow.blog/2020/10/12/how-to-put-machine-learning-models-into-production/) Helped in giving background information for the Machine Learning Practices graph.\n6. [Python libraries for visualisation](https://www.techshenanigans.com/post/top-5-python-libraries-for-visualization): Provided a concise analysis of the different python visualisation tools.\n7. [Getting Started with Computer Vision Jobs | Udacity](https://blog.udacity.com/2020/09/getting-started-with-computer-vision-jobs.html)\n8. [Everything You Ever Wanted To Know About Computer Vision](https://towardsdatascience.com/everything-you-ever-wanted-to-know-about-computer-vision-heres-a-look-why-it-s-so-awesome-e8a58dfb641e) by Ilija Mihajlovic | Towards Data Science\n\n## <div class=\"subsection_title\">Massive thanks to these resources / notebooks on kaggle</div>\n* [Plotly Tutorial for Beginners](https://www.kaggle.com/kanncaa1/plotly-tutorial-for-beginners):  I was hesitant to switch away from my beloved Seaborn until I saw this notebook. The code in this notebook is clean and easy to understand. It showcases a wide range of plotly graphs and presents their code in a very \"to-the-point\" manner.\n* [Interactive D3.js Visualisations in Kaggle Kernels](https://www.kaggle.com/shivamb/interactive-d3-js-visualisations-in-kaggle-kernels):  Prior to this notebook I didn't know what D3 was, let alone that Kaggle supported it. I would definitely recommend it as a resource for getting your D3 visualisations up and running in Kaggle Notebooks.\n* [The D3 Graph Gallery](https://www.d3-graph-gallery.com/): D3 is a pain if you're going to create every graph from scratch. I tend to start every graph by taking the bare bones code from here, plugging in my own data and then modifying/adding interactivity as needed.\n* [A different look for the D3 radar chart](http://www.visualcinnamon.com/2015/10/different-look-d3-radar-chart.html): Nadieh Bremer's rework of [Alvaro Graves'](https://github.com/alangrafu/radar-chart-d3) d3 radar code.\n* [💎Treasure Hunt - what gives to be REALLY good?](https://www.kaggle.com/andradaolteanu/treasure-hunt-what-gives-to-be-really-good): Andrada's book was the first time I saw someone handle pays to remove regional biasing, albeit she goes the more fun route with the McMeal index.\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"# <div class=\"section_title\">What's new?</div>\n<span style=\"text-decoration:line-through\">So I've reached stage at which I will I'll be reworking a few of the older graphs and updating the writeups in previous sections</span> At least, I hope I've finished everything . Since it might not be obvious what was reworked, I'll list it out here so you know where to check out the new content:\n\n* [\"**Distribution based on company size**\"](#company_size_earnings)Wasn't a big fan of how cluttered it was and how the colours wouldn't intuitively help you find who was paid the most. Section now reworked in D3 with the new normalised pays, along with a new tab(\"Overall compensation\") to see where companies are spending money.\n* Table of Contents added.\n* [\"**How much Coding Experience?**\"](#coding_experience) and [\"**How much Machine Learning Experience?**\"](#ml_experience) both edited to keep the same theme as other d3 charts. [\"**Data roles**\"](#roles) now highlights the secondary roles also.\n* [**Workflows of Data Professionals**](#workflows) section was added to highlight where time is spent in the actual work of a data professional.\n* [**The Skills Gap**](#skillsgap)\n\n**~ 05-01-2021 - Completed work on the notebook**"},{"metadata":{},"cell_type":"markdown","source":"## Final notes<br>\nThis notebook was my first time using Plotly( or d3.js for that matter), so let me know if any part of my code is unclear or if you know a better way to do it! If any of the graphs aren't showing up or they have overlapping/hard-to-read text, let me know and I'll try my best to fix it.\n\nAdditionally if you have any other questions or would like me to clarify something about the notebook, feel free to reach out to me either in the comments or through Kaggle via email/LinkedIn."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}