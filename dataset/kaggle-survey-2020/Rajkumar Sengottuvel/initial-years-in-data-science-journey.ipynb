{"cells":[{"metadata":{},"cell_type":"markdown","source":"<div align=\"center\">\n    <h1>Initial years in Data Science Journey</h1>\n<img src=\"https://user-images.githubusercontent.com/48846576/102959431-1d7dac00-44a5-11eb-92fa-69f1e42bca45.jpg\"  width=\"800\" height=\"300\">\n<span>Photo by <a href=\"https://unsplash.com/@foxxmd?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Matt Duncan</a> on <a href=\"https://unsplash.com/s/photos/start?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Unsplash</a></span>\n</div><br>\n<div align=\"left\">\n    <h3>What most people do in their initial years of data science / machine learning journey?</h3>\n    \nIn this report, I try to analyze and understand what most people do during the initial years (1-3 years) of their career in data science, especially the experienced coders (with 5-20 years of coding experience) starting a new chapter in data science. As a data science enthusiast who fits this profile, my aim is to understand whether I am aligned with rest of the community.\n</div>\n<br>\n<div align=\"left\">\nI have segmented the participants into these categories for my analysis.\n</div>\n<br>\n<div align=\"left\">\n    <ul>\n<li>First few years (0-3 years) of using machine learning methods (everyone across roles and coding experience)</li>\n<li>Many years of coding (5-20 years) experience but have been using machine learning methods only for few (0-3) years</li>\n<li>Many years of coding (5-20 years) experience, have been using machine learning methods only for few (0-3) years and are currently performing data science / machine learning related jobs like Data Analyst, Data Engineer, Data Scientist, Machine Learning Engineer, Research Scientist & Statistician</li>\n</ul>\n</div>"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nsns.set()\n\nsurvey_df = pd.read_csv(\"/kaggle/input/kaggle-survey-2020/kaggle_survey_2020_responses.csv\" , low_memory=False, index_col=None)\nmaster = survey_df.copy() # Make a copy\nmaster = master.drop(0) # Drop first row containing questions\nq15 = master[master['Q15'].notna()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Plot below represents the number of survey participants that fall under my segmentation"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"import plotly.graph_objects as go\nfrom plotly.offline import iplot, init_notebook_mode\ninit_notebook_mode(connected=True)\n\nds_roles = ['Data Analyst','Data Engineer','Data Scientist','Machine Learning Engineer','Research Scientist','Statistician']\nff_df = q15[(q15['Q15'].str.contains('Under 1 year') | q15['Q15'].str.contains('1-2 years') | q15['Q15'].str.contains('2-3 years'))]\ncoding_df = q15[(q15['Q15'].str.contains('Under 1 year') | q15['Q15'].str.contains('1-2 years') | q15['Q15'].str.contains('2-3 years'))\n           & (q15['Q6'].str.contains('20+ years') | q15['Q6'].str.contains('10-20 years') | q15['Q6'].str.contains('5-10 years'))]\n#May not be using machine learning methods but doing data science job - I do not use machine learning methods??\nds_df = q15[(q15['Q15'].str.contains('Under 1 year|1-2 years|2-3 years'))\n    &(q15['Q6'].str.contains('20+ years|10-20 years|5-10 years'))\n    &(q15['Q5'].str.contains('Data Analyst|Data Engineer|Data Scientist|Machine Learning Engineer|Research Scientist|Statistician'))]\n# Under 1 year, 1-2 years, 2-3 years - 11402 (all)\n# Under 1 year, 1-2 years, 2-3 years - 2116 (5-10, 10-20+ years coding all)\n# Under 1 year, 1-2 years, 2-3 years - 828 (5-10, 10-20+ years coding data science roles) or 915\n#print(ds_df.shape)\nfig = go.Figure(go.Funnel(\n    y = [\"Using ML methods for upto 3 years\", \"Using ML methods for upto 3 years, <br>have 5-20 years of coding experience\", \"Using ML methods for upto 3 years, <br> have 5-20 years of coding experience and <br>currently in data science / ML jobs\"],\n    x = [11402, 2116, 828],\n    textposition = \"inside\",\n    textinfo = \"value+percent total\",\n    opacity = 0.85, marker = {\"color\": [\"slategray\", \"slategray\", \"slategray\" ],\n    \"line\": {\"width\": [6, 3, 3, ], \"color\": [\"plum\", \"springgreen\", \"indianred\" ]}},\n    connector = {\"line\": {\"color\": \"black\", \"dash\": \"dot\", \"width\": 3}})\n    )\nfig.update_traces(hoverinfo=\"x+y+percent total\", selector=dict(type='funnel'))\n#fig.update_traces(marker_colorbar_ticklabelposition='outside top', selector=dict(type='funnel'))\nfig.update_layout(font_size=14)\nfig.update_layout(font_color='#055')\nfig.update_layout(plot_bgcolor='#9acee7')\nfig.update_layout(title_text='Participant segments analyzed in this report',width=700,height=500)\n\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Next few plots are to understand the over all participants demographics "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"\n# Where there are 300+ participants\ncountry_list = ['India','United States of America','Brazil','Japan','Russia','United Kingdom of Great Britain and Northern Ireland','Nigeria','China','Germany','Turkey','Spain','France','Canada']\n#lambda x : True if (x > 10 and x < 20) else False\nmaster['country'] = master['Q3'].apply(lambda x: x if x in country_list else 'Rest of the world!')\n\nq15 = master[master['Q15'].notna()]\nq15_q5 = q15.groupby(['Q15','Q5']).count().reset_index()\nq15_q5 = q15_q5[['Q15','Q5','Q1']]\nq15_q5 = pd.pivot_table(q15_q5, index=['Q15'], columns='Q5', values='Q1', aggfunc=np.sum)\nq15_q5.sort_index(level=0, ascending=True, inplace=True)\nindx = ['Under 1 year', '1-2 years',  '2-3 years',  '3-4 years', '4-5 years', '5-10 years','10-20 years','20 or more years','I do not use machine learning methods']\ncols = [ 'Data Analyst', 'Data Engineer', 'Data Scientist', 'Machine Learning Engineer', 'Research Scientist', 'Software Engineer', 'Statistician','Business Analyst', 'DBA/Database Engineer',  'Product/Project Manager', 'Other', 'Currently not employed', 'Student']\n#q15_q5.index = pd.CategoricalIndex(q15_q5.index, categories= ['Under 1 year', '1-2 years',  '2-3 years',  '3-4 years', '4-5 years', '5-10 years','10-20 years','20 or more years','I do not use machine learning methods'])\n#q15_q5.sort_index(level=0, inplace=True)\nq15_q5 = q15_q5.reindex(index=indx, columns=cols)\n\nq6_cols = [ '< 1 years', '1-2 years','3-5 years','5-10 years', '10-20 years', '20+ years']\nq15_q6 = q15.groupby(['Q15','Q6']).count().reset_index()\nq15_q6 = q15_q6[['Q15','Q6','Q1']]\nq15_q6 = pd.pivot_table(q15_q6, index=['Q15'], columns='Q6', values='Q1', aggfunc=np.sum)\n#q15_q6.sort_index(level=0, ascending=True, inplace=True)\nq15_q6 = q15_q6.reindex(index=indx, columns=q6_cols)\n\nf = plt.figure(figsize=(15,12))\ngs = f.add_gridspec(2, 1)\n\nwith sns.axes_style(\"darkgrid\"):\n    sns.set_context(\"notebook\", font_scale=1.2, rc={\"lines.linewidth\": 3.5})\n    ax = f.add_subplot(gs[0, 0])\n    #g1 = sns.barplot(x='over', y='runs', data=MI_runs);\n    g1 = sns.heatmap(q15_q5, annot=True, fmt=\"g\", cmap='Oranges')\n    #g1.set_facecolor(\"#fdb913\")\n    #g1.set_yticks(range(0,60,10))\n    #g1.set_ylim(0,60)\n    g1.axes.set_title(\"Years using ML Methods vs Job Title\",fontsize=20)\n    g1.set_xlabel(None,fontsize=18)\n    g1.set_ylabel(None,fontsize=18)        \n    g1.set_xticklabels(g1.get_xticklabels(), rotation=80)\n    g1.set_yticklabels(g1.get_yticklabels(), rotation=0)\n    ax.hlines([3], *ax.get_xlim())\n    ax.vlines([7], *ax.get_ylim())\n    \nwith sns.axes_style(\"darkgrid\"):\n    sns.set_context(\"notebook\", font_scale=1.2, rc={\"lines.linewidth\": 3.5})\n    ax = f.add_subplot(gs[1, 0])\n    #g1 = sns.barplot(x='over', y='runs', data=MI_runs);\n    g1 = sns.heatmap(q15_q6, annot=True, fmt=\"g\", cmap='Purples')\n    #g1.set_facecolor(\"#fdb913\")\n    #g1.set_yticks(range(0,60,10))\n    #g1.set_ylim(0,60)\n    g1.axes.set_title(\"Years using ML Methods vs Coding Experience\",fontsize=20)\n    g1.set_xlabel(None,fontsize=18)\n    g1.set_ylabel(None,fontsize=18)        \n    g1.set_xticklabels(g1.get_xticklabels(), rotation=80)\n    g1.set_yticklabels(g1.get_yticklabels(), rotation=0)\n    ax.hlines([3], *ax.get_xlim())\n    ax.vlines([3], *ax.get_ylim())\nf.tight_layout(pad=3.0)\n\n#q4_cols = ['Bachelor’s degree','Master’s degree','Doctoral degree', 'Professional degree', 'Some college/university study without earning a bachelor’s degree','No formal education past high school','I prefer not to answer']\nq4_cols = ['Bachelor’s degree','Master’s degree','Doctoral degree', 'Professional degree', 'Some college/university study','No formal education past high school','I prefer not to answer']\nq15_q4 = q15.groupby(['Q15','Q4']).count().reset_index()\nq15_q4 = q15_q4[['Q15','Q4','Q1']]\nq15_q4 = pd.pivot_table(q15_q4, index=['Q15'], columns='Q4', values='Q1', aggfunc=np.sum)\nq15_q4 = q15_q4.rename(columns={'Some college/university study without earning a bachelor’s degree':'Some college/university study'})\n#q15_q6.sort_index(level=0, ascending=True, inplace=True)\nq15_q4 = q15_q4.reindex(index=indx, columns=q4_cols)\n\nf = plt.figure(figsize=(12,12))\ngs = f.add_gridspec(1, 1)    \nwith sns.axes_style(\"darkgrid\"):\n    sns.set_context(\"notebook\", font_scale=1.2, rc={\"lines.linewidth\": 3.5})\n    ax = f.add_subplot(gs[0,0])\n    #g1 = sns.barplot(x='over', y='runs', data=MI_runs);\n    g1 = sns.heatmap(q15_q4, annot=True, fmt=\"g\", cmap='Oranges')\n    #g1.set_facecolor(\"#fdb913\")\n    #g1.set_yticks(range(0,60,10))\n    #g1.set_ylim(0,60)\n    g1.axes.set_title(\"Years using ML Methods vs Degree\",fontsize=20)\n    g1.set_xlabel(None,fontsize=18)\n    g1.set_ylabel(None,fontsize=18)        \n    g1.set_xticklabels(g1.get_xticklabels(), rotation=90)\n    g1.set_yticklabels(g1.get_yticklabels(), rotation=0)\n    ax.hlines([3], *ax.get_xlim())\n    ax.vlines([7], *ax.get_ylim())    \nf.tight_layout(pad=3.0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> "},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":false},"cell_type":"code","source":"f = plt.figure(figsize=(10, 18))\ngs = f.add_gridspec(1, 1)\nwith sns.axes_style(\"darkgrid\"):\n    #sns.set_context(\"notebook\", font_scale=1.0, rc={\"lines.linewidth\": 3.5})    \n    ax = f.add_subplot(gs[0, 0])    \n    g1 = sns.countplot(y=\"Q3\", data=master,palette=\"twilight_shifted_r\", order = master['Q3'].value_counts().index )\n    #ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n    #ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n    #g1.set_facecolor(\"#fdb913\")\n    g1.axes.set_title(\"Participants by Country\",fontsize=20)\n    g1.set_xlabel(\"Number of participants\",fontsize=18)\n    g1.set_ylabel(None,fontsize=20)\n    ax.set_xticks(range(0,6000,500))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Countries where there are 300+ participants"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":false},"cell_type":"code","source":"f = plt.figure(figsize=(10, 8))\ngs = f.add_gridspec(1, 1)\nwith sns.axes_style(\"darkgrid\"):\n    #sns.set_context(\"notebook\", font_scale=1.0, rc={\"lines.linewidth\": 3.5})    \n    ax = f.add_subplot(gs[0, 0])    \n    g1 = sns.countplot(y=\"country\", data=master,palette=\"Paired\", order = master['country'].value_counts().index )\n    #ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n    #ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n    #g1.set_facecolor(\"#fdb913\")\n    g1.axes.set_title(\"Participants by Country\",fontsize=20)\n    g1.set_xlabel(\"Number of participants\",fontsize=18)\n    g1.set_ylabel(None,fontsize=20)\n    ax.set_xticks(range(0,7000,500))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import json\nimport random as rd\n\ndef generate_color(num):\n    clr_list =[]\n    for i in range(0, num):\n        clr = \"rgba({},{},{},{})\".format(rd.randint(0,255),rd.randint(0,255),rd.randint(0,255),round(rd.uniform(0, 1),1))\n        clr_list.append(clr)\n    return clr_list\n\nclass SData:\n    def __init__(self, df):\n        self._nodes = None\n        self._data = None\n        self._df = df\n        self._tup_list = []\n        self._json_data = None\n    def build_nodes(self,attr1, attr2):\n        df =  self._df.groupby([attr1,attr2]).sum().reset_index()\n        if self._nodes is None:\n            self._nodes  = list(df[attr1].unique())\n            #self._nodes.append(self._nodes.pop(self._nodes.index('Other-Countries'))) #Move 'Other' in countries to end of the countries list\n        else: \n            self._nodes  += list(df[attr1].unique())\n        self._nodes  += list(df[attr2].unique())\n        \n        self._tup_list.append((attr1,attr2))\n        \n        \n    def get_nodes(self):\n        return self._nodes\n    \n    def create_json(self):\n        \n        #Step 1 - Create Nodes\n        node_list = []\n        #i=0 \n        #clr_list = generate_color(70)\n        for item in self._nodes:\n            node = {}\n            node['label'] = item\n            node['visible'] = True\n            #node['color'] = clr_list[i]\n            node['color'] = \"rgba({},{},{},{})\".format(rd.randint(100,200),rd.randint(0,60),rd.randint(0,60),round(rd.uniform(0, 1),1))\n            #i+=1\n            node_list.append(node)\n        \n        #Step 2 - Create Links\n        links_list = []\n        #self._tup_list = [('country','degree'),('degree','job_title'),('job_title','years_coding'),('years_coding','years_using_ml')]\n        for tup in self._tup_list:\n            #print(tup[0], tup[1])\n            df =  self._df.groupby([tup[0],tup[1]]).sum().reset_index()\n            #print(df.shape)\n            for index, row in df.iterrows():\n                link = {}\n                source = self._nodes.index(row[tup[0]])\n                target = self._nodes.index(row[tup[1]])\n                count = row['participants']\n                link['source'] = source\n                link['target'] = target\n                link['value'] = count\n                link['label'] = '{}-{}'.format(row[tup[0]],row[tup[1]])\n                link['color'] = \"rgba({},{},{},{})\".format(rd.randint(0,200),rd.randint(0,220),rd.randint(0,230),round(rd.uniform(0, 1),1))\n                links_list.append(link)\n                \n\n        self._data = {}\n        self._data['layout'] = {\n            \"title\": \"First few years in Data Science\",\n            \"width\": 1600,\n            \"height\": 1000\n          }\n        self._data['data'] = [\n            {\n              \"type\": \"sankey\",\n              \"domain\": {\n                \"x\": [\n                  0,\n                  1\n                ],\n                \"y\": [\n                  0,\n                  1\n                ]\n              },\n              \"nodes\": node_list ,\n            \"links\" : links_list}]\n        \n        self._json_data = json.dumps(self._data)\n        #print(json_data)\n        return self._json_data\n    \n    def get_sankey_data(self):\n        data = json.loads(self._json_data)\n        label = []\n        color = []\n        for x in data['data'][0]['nodes']:\n            label.append(x['label'])\n            color.append(x['color'])\n\n        linkSource = []\n        linkValue = []    \n        linkTarget = []\n        linkLabel = []\n        linkColor = []\n        for x in data['data'][0]['links']:\n            linkLabel.append(x['label'])\n            linkSource.append(x['source'])\n            linkValue.append(x['value'])\n            linkTarget.append(x['target'])  \n            linkColor.append(x['color'])              \n\n        data_trace = dict(\n            type='sankey',\n            domain = dict(\n              x =  [0,1],\n              y =  [0,1]\n            ),\n            orientation = \"h\",\n            valueformat = \".0f\",\n            node = dict(\n              pad = 5,\n              thickness = 30,\n              line = dict(\n                color = \"black\",\n                width = 0.5\n              ),\n              label =  label,\n              color = color\n            ),\n            link = dict(\n              source = linkSource,\n              target = linkTarget,\n              value = linkValue,\n              label =  linkLabel,\n            color = linkColor\n          )\n        )    \n\n        layout =  dict(\n            #title = \"First few years in Data Science\",\n            height = 800,\n            width = 800,\n            font = dict(\n              size = 10\n            ),    \n        )\n\n        fig = dict(data=[data_trace], layout=layout)\n        return fig\n    \ndef build_menus():\n    labels = list(df_group['years_using_ml'].unique())\n    btn_lst = []\n    \n    for label in labels:\n        d = SData(df_group[df_group['years_using_ml'] == label])\n        d.build_nodes('years_using_ml','degree')\n        d.build_nodes('degree','job_title')    \n        d.build_nodes('job_title','country')        \n        jsn = d.create_json()\n        data = d.get_sankey_data()    \n        btn_dict = dict(label = label,\n                       method = \"animate\",\n                       args = [data])\n        btn_lst.append(btn_dict)\n\n    d = SData(df_group) # All values\n    d.build_nodes('years_using_ml','degree')\n    d.build_nodes('degree','job_title')    \n    d.build_nodes('job_title','country')        \n    jsn = d.create_json()\n    data = d.get_sankey_data()    \n    btn_dict = dict(label = \"All\",\n                   method = \"animate\",\n                   args = [data])\n    btn_lst.append(btn_dict)\n        \n    updatemenu = [dict(buttons = btn_lst, pad={\"r\": 10, \"t\": 10},\n            showactive=True,\n            x=0.11,\n            xanchor=\"right\",\n            y=1.1,\n            yanchor=\"top\")]\n    \n    return updatemenu\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> The demographics presented as interactive sankey"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":false},"cell_type":"code","source":"df_group = master.groupby(['country','Q4','Q5','Q6','Q15']).count().reset_index().sort_values('Q1',ascending=False)\ndf_group = df_group[['country','Q4','Q5','Q6','Q15','Q1']]\ndf_group = df_group.rename(columns={'Q1':'participants','Q4':'degree','Q5':'job_title','Q6':'years_coding', 'Q15':'years_using_ml'})\n#Q4 - degree\n#Q5 - Job\n#Q6 - years coding\ndf_group = master.groupby(['Q15','Q4','Q5','country']).count().reset_index().sort_values('Q1',ascending=False)\ndf_group = df_group[['Q15','Q4','Q5','Q1','country']]\ndf_group = df_group.rename(columns={'Q1':'participants','Q4':'degree','Q5':'job_title','Q15':'years_using_ml'})\n#master['Q15'].value_counts()\ndf_group\n\nd = SData(df_group)\nd.build_nodes('years_using_ml','degree')\nd.build_nodes('degree','job_title')    \nd.build_nodes('job_title','country')        \nd.create_json()\nall_data = d.get_sankey_data()\nupdatemenus = build_menus()\nfig = go.Figure(all_data)\nfig.update_layout(font_size=15, height = 800,\n    width = 800,updatemenus=updatemenus)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"ds_roles = ['Data Analyst','Data Engineer','Data Scientist','Machine Learning Engineer','Research Scientist','Statistician']\n#ff_df = q15[(q15['Q15'].str.contains('Under 1 year') | q15['Q15'].str.contains('1-2 years') | q15['Q15'].str.contains('2-3 years'))]\n#coding_df = q15[(q15['Q15'].str.contains('Under 1 year') | q15['Q15'].str.contains('1-2 years') | q15['Q15'].str.contains('2-3 years'))\n#           & (q15['Q6'].str.contains('20+ years') | q15['Q6'].str.contains('10-20 years') | q15['Q6'].str.contains('5-10 years'))]\n#May not be using machine learning methods but doing data science job - I do not use machine learning methods??\n#ds_df = q15[(q15['Q15'].str.contains('Under 1 year|1-2 years|2-3 years'))\n#    &(q15['Q6'].str.contains('20+ years|10-20 years|5-10 years'))\n#    &(q15['Q5'].str.contains('Data Analyst|Data Engineer|Data Scientist|Machine Learning Engineer|Research Scientist|Statistician'))]\n\n#cols = [qn for qn in list(master.columns) if 'Q19' in qn]\n#ff_df[cols].isna()\n#series = ff_df[cols].apply(lambda x: x.value_counts()).T.stack()\n#frm = series.to_frame().reset_index()\n#frm.drop(frm.columns[0], axis=1, inplace=True)\n#frm.rename(columns=({'level_1':'answer',0:'count'}),inplace=True)\n\n#ff_df\n#coding_df\n#ds_df\ndef get_chart_df(df, qn_substr):\n    \"\"\" Call this method ff_df, coding_df, ds_df to get pandas df for charting for each of the segment\"\"\"\n    cols = [qn for qn in list(master.columns) if qn_substr in qn]\n    series = df[cols].apply(lambda x: x.value_counts()).T.stack()\n    frm = series.to_frame().reset_index()\n    frm.drop(frm.columns[0], axis=1, inplace=True)\n    frm.rename(columns=({'level_1':'answer',0:'count'}),inplace=True)\n    frm['percent'] = round((frm['count'] / frm['count'].sum()) * 100,1)   \n    return frm\n\ndef get_chart_percent(df, qn_substr):\n    \"\"\" Call this method ff_df, coding_df, ds_df to get pandas df for charting for each of the segment\"\"\"\n    cols = [qn for qn in list(master.columns) if qn_substr in qn]\n    series = df[cols].apply(lambda x: x.value_counts()).T.stack()\n    frm = series.to_frame().reset_index()\n    frm.drop(frm.columns[0], axis=1, inplace=True)\n    frm.rename(columns=({'level_1':'answer',0:'count'}),inplace=True)\n    frm['percent'] = round((frm['count'] / frm['count'].sum()) * 100,1)\n    return frm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def get_fig(qn_substr, chart_title, x=None, vertical_spacing=0.2, shared_xaxes=True):\n    orientation='v'\n    fig = None\n    ff_data = get_chart_df(ff_df, qn_substr).sort_values(\"count\",ascending=False)\n    #plot_data.sort_values(\"count\",ascending=False)\n    fig = make_subplots(rows=2, cols=1, vertical_spacing=vertical_spacing,  shared_xaxes=shared_xaxes)\n\n    x_labels = None\n    if x is not None:\n        x_labels = x\n    else:\n        x_labels = ff_data['answer']\n        \n    bar1 = go.Bar(\n        x=x_labels,\n        y=ff_data['count'],\n        orientation=orientation,        \n        name='0-3 years of DS/ML Experience',\n        marker=dict(color='#484a8a'), legendgroup='lg1'\n    )\n\n    coding_data = get_chart_df(coding_df, qn_substr).sort_values(\"count\",ascending=False)\n\n    bar2 = go.Bar(\n        x=x_labels,\n        y=coding_data['count'],\n        orientation=orientation,\n        name='0-3 years of DS/ML Experience & <br> 5+ years of coding experience',\n        marker=dict(color='#f5ab3d'), legendgroup='lg2'\n    )\n\n    ds_data = get_chart_df(ds_df, qn_substr).sort_values(\"count\",ascending=False)\n    bar3= go.Bar(\n        x=x_labels,\n        y=ds_data['count'],\n        orientation=orientation,        \n        name='0-3 years of DS/ML Experience & <br> 5+ years of coding experience &<br> Currently in DS/ML Jobs',\n        marker=dict(color='#860f8c'), legendgroup='lg3'\n    )\n\n    fig.add_trace(bar1,row=1, col=1)\n    fig.add_trace(bar2,row=1, col=1)\n    fig.add_trace(bar3,row=1, col=1)\n    #fig.update_layout(height=600, width=800, title_text=\"Side By Side Subplots\")\n    fig.update_layout(height=600, width=650, title_text=\"Side By Side Subplots\")\n    fig.update_layout(barmode='group')  \n\n    fig.add_trace(go.Bar(name='Segment 1',orientation=orientation,x=x_labels, y=ff_data['percent'],marker=dict(color='#484a8a'),showlegend=False, legendgroup='lg1'),row=2, col=1)\n    fig.add_trace(go.Bar(name='Segment 2', orientation=orientation, x=x_labels, y=coding_data['percent'],marker=dict(color='#f5ab3d'),showlegend=False, legendgroup='lg2'),row=2, col=1)\n    fig.add_trace(go.Bar(name='Segment 3', orientation=orientation, x=x_labels, y=ds_data['percent'],marker=dict(color='#860f8c'),showlegend=False, legendgroup='lg3'),row=2, col=1)\n    fig.update_layout(\n        title=chart_title,\n    #    legend_title=\"Legend Title\",\n        font=dict(\n            family=\"Computer Modern\",\n            size=14,\n            color=\"#593232\"\n        )\n    )\n    fig['layout']['yaxis']['title']='Number of users'\n    fig['layout']['yaxis2']['title']='Percentage of users'\n    fig['layout']['yaxis2']['ticksuffix'] = '%'\n    fig['layout']['xaxis']['tickangle']= 45\n    fig['layout']['xaxis2']['tickangle']= 45\n    \n    return fig","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Q7 What programming languages do you use on a regular basis?\nPython is used by around 30% of the participants in the segment"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from plotly.subplots import make_subplots\n\nff_data = get_chart_df(ff_df, 'Q7').sort_values(\"count\",ascending=False)\n#plot_data.sort_values(\"count\",ascending=False)\nfig = make_subplots(rows=2, cols=1)\n\nbar1 = go.Bar(\n    x=ff_data['answer'],\n    y=ff_data['count'],\n    name='0-3 years of DS/ML Experience',\n    marker=dict(color='#484a8a'), legendgroup='lg1'\n)\n\ncoding_data = get_chart_df(coding_df, 'Q7').sort_values(\"count\",ascending=False)\n\nbar2 = go.Bar(\n    x=coding_data['answer'],\n    y=coding_data['count'],\n    name='0-3 years of DS/ML Experience & <br> 5+ years of coding experience',\n    marker=dict(color='#f5ab3d'), legendgroup='lg2'\n)\n\nds_data = get_chart_df(ds_df, 'Q7').sort_values(\"count\",ascending=False)\nbar3= go.Bar(\n    x=ds_data['answer'],\n    y=ds_data['count'],\n    name='0-3 years of DS/ML Experience & <br> 5+ years of coding experience &<br> Currently in DS/ML Jobs',\n    marker=dict(color='#860f8c'), legendgroup='lg3'\n)\n\nfig.add_trace(bar1,row=1, col=1)\n\nfig.add_trace(bar2,row=1, col=1)\nfig.add_trace(bar3,row=1, col=1)\nfig.update_layout(height=600, width=600, title_text=\" programming languages \")\nfig.update_layout(barmode='group')  \n\nfig.add_trace(go.Bar(name='Segment 1', x=ff_data['answer'], y=ff_data['percent'],marker=dict(color='#484a8a'),showlegend=False, legendgroup='lg1'),row=2, col=1)\nfig.add_trace(go.Bar(name='Segment 2', x=coding_data['answer'], y=coding_data['percent'],marker=dict(color='#f5ab3d'),showlegend=False, legendgroup='lg2'),row=2, col=1)\nfig.add_trace(go.Bar(name='Segment 3', x=ds_data['answer'], y=ds_data['percent'],marker=dict(color='#860f8c'),showlegend=False, legendgroup='lg3'),row=2, col=1)\nfig.update_layout(\n    title=\"Programming Languages\",\n#    legend_title=\"Legend Title\",\n    font=dict(\n        family=\"Computer Modern\",\n        size=14,\n        color=\"#593232\"\n    )\n)\n\n\nfig['layout']['yaxis']['title']='Number of Participants'\nfig['layout']['yaxis2']['title']='Percentage of Participants'\nfig['layout']['yaxis2']['ticksuffix'] = '%'\nfig['layout']['xaxis']['tickangle']= 45\nfig['layout']['xaxis2']['tickangle']= 45\n\niplot(fig);\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Q8 What programming language would you recommend an aspiring data scientist to learn first?\n\nAs expected python is recommended by 80% of the participants."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"iplot(get_fig('Q8', 'What programming language to learn first?',vertical_spacing=0.04))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Q9 - Which of the following integrated development environments (IDE's) do you use on a regular basis?"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"lst = ['Jupyter',\n 'RStudio',\n 'Visual Studio',\n 'VSCode',\n 'PyCharm',\n 'Spyder',\n 'Notepad++',\n 'Sublime Text',\n 'Vim / Emacs',\n 'MATLAB',\n 'None',\n 'Other']\nfig = get_fig('Q9', 'Integrated Development Environments',x=lst, vertical_spacing=0.04)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Q10 - Which of the following hosted notebook products do you use on a regular basis? "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x_labels = [x.strip() for x in list(get_chart_df(ff_df,'Q10')['answer'])]\nx_labels =  ['Kaggle',\n   'Colab',\n   'Azure',\n   'Paperspace / Gradient',\n   'Binder / JupyterHub',\n   'Code Ocean',\n   'IBM Watson Studio',\n   'Amazon Sagemaker',\n   'Amazon EMR',\n   'Google Cloud AI',\n   'Google Cloud Datalab',\n   'Databricks Collaborative',\n   'None',\n   'Other']\niplot(get_fig('Q10', 'Hosted Notebook Products', x=x_labels, vertical_spacing=0.04))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Q11 - What type of computing platform do you use most often for your data science projects?"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x_labels = [x.strip() for x in list(get_chart_df(ff_df,'Q11')['answer'])]\n#x_labels = [x.strip() for x in list(get_chart_df(ff_df,'Q11')['answer'])]\nx_labels =['Computer / Laptop',\n 'Cloud platform',\n 'Deep learning workstation',\n 'None',\n 'Other']\niplot(get_fig('Q11', 'Computing Platform Used',x=x_labels, vertical_spacing=0.04))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Q12 - Which types of specialized hardware do you use on a regular basis?"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"iplot(get_fig('Q12', 'Specialized hardware',vertical_spacing=0.04))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Q13 - Approximately how many times have you used a TPU (tensor processing unit)?"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"iplot(get_fig('Q13', 'TPU Usage', vertical_spacing=0.04))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q14 - What data visualization libraries or tools do you use on a regular basis?"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x_labels = [x.strip() for x in list(get_chart_df(ff_df,'Q14')['answer'])]\niplot(get_fig('Q14', 'Visualization libraries',x=x_labels,vertical_spacing=0.04))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q16 - Which of the following machine learning frameworks do you use on a regular basis? "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x_labels = [x.strip() for x in list(get_chart_df(ff_df,'Q16')['answer'])]\niplot(get_fig('Q16', 'Machine learning frameworks',x=x_labels,vertical_spacing=0.04))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q17 - Which of the following ML algorithms do you use on a regular basis? "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x_labels = [x.strip() for x in list(get_chart_df(ff_df,'Q17')['answer'])]\niplot(get_fig('Q17', 'Machine learning algorithms', x=x_labels,vertical_spacing=0.04))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q18 - Which categories of computer vision methods do you use on a regular basis? "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x_labels = [x.strip() for x in list(get_chart_df(ff_df,'Q18')['answer'])]\nx_labels = ['General purpose image/video tools',\n 'Image segmentation methods',\n 'Object detection methods',\n 'Image classification and <br>other general purpose networks',\n 'Generative Networks',\n 'None',\n 'Other']\n\nfig = get_fig('Q18', 'Computer vision methods ', x=x_labels,vertical_spacing=0.9,shared_xaxes=True)\nfig.update_layout(yaxis2={'domain': [0, 0.50]},yaxis={'domain': [0.51, 1]})\niplot(fig)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q19 - Which of the following natural language processing (NLP) methods do you use on a regular basis?"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x_labels = [x.strip() for x in list(get_chart_df(ff_df,'Q19')['answer'])]\n\nfig = get_fig('Q19', 'Natural Language Processing (NLP) methods', x=x_labels,vertical_spacing=1.0)\nfig.update_layout(yaxis2={'domain': [0, 0.49]},yaxis={'domain': [0.55, 1]})\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q20 - What is the size of the company where you are employed?"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x_labels = [x.strip() for x in list(get_chart_df(ff_df,'Q20')['answer'])]\nfig = get_fig('Q20', 'Company size', x=x_labels,vertical_spacing=1.0)\nfig.update_layout(yaxis2={'domain': [0, 0.50]},yaxis={'domain': [0.51, 1]})\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q21 - Approximately how many individuals are responsible for data science workloads at your place of business?"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"x_labels = [x.strip() for x in list(get_chart_df(ff_df,'Q21')['answer'])]\nfig = get_fig('Q21', 'Data Science Workload', x=x_labels,vertical_spacing=1.0)\nfig.update_layout(yaxis2={'domain': [0, 0.50]},yaxis={'domain': [0.51, 1]})\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q22 - Does your current employer incorporate machine learning methods into their business?\n"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"def get_horizontal_bar(x_data, y_data, colors):\n    fig = go.Figure()\n\n    for i in range(0, len(x_data[0])):\n        for xd, yd in zip(x_data, y_data):\n            fig.add_trace(go.Bar(\n                x=[xd[i]], y=[yd],\n                orientation='h',\n                marker=dict(\n                    color=colors[i],\n                    line=dict(color='rgb(248, 248, 249)', width=1)\n                )\n            ))\n\n    fig.update_layout(\n        xaxis=dict(\n            showgrid=False,\n            showline=False,\n            showticklabels=False,\n            zeroline=False,\n            domain=[0.15, 1]\n        ),\n        yaxis=dict(\n            showgrid=False,\n            showline=False,\n            showticklabels=False,\n            zeroline=False,\n        ),\n        barmode='stack',\n        paper_bgcolor='rgb(248, 255, 255)',\n        plot_bgcolor='rgb(248, 255, 255)',\n        margin=dict(l=120, r=10, t=140, b=80),\n        showlegend=False,\n    )\n\n    annotations = []\n\n    for yd, xd in zip(y_data, x_data):\n        # labeling the y-axis\n        annotations.append(dict(xref='paper', yref='y',\n                                x=0.14, y=yd,\n                                xanchor='right',\n                                text=str(yd),\n                                font=dict(family='Arial', size=14,\n                                          color='rgb(67, 67, 67)'),\n                                showarrow=False, align='right'))\n        # labeling the first percentage of each bar (x_axis)\n        annotations.append(dict(xref='x', yref='y',\n                                x=xd[0] / 2, y=yd,\n                                text=str(xd[0]) + '%',\n                                font=dict(family='Arial', size=14,\n                                          color='rgb(248, 248, 255)'),\n                                showarrow=False))\n        # labeling the first Likert scale (on the top)\n        if yd == y_data[-1]:\n            annotations.append(dict(xref='x', yref='paper',\n                                    x=xd[0] / 2, y=1.1,\n                                    text=top_labels[0],\n                                    font=dict(family='Arial', size=14,\n                                              color='rgb(67, 67, 67)'),\n                                    showarrow=False))\n        space = xd[0]\n        for i in range(1, len(xd)):\n                # labeling the rest of percentages for each bar (x_axis)\n                annotations.append(dict(xref='x', yref='y',\n                                        x=space + (xd[i]/2), y=yd,\n                                        text=str(xd[i]) + '%',\n                                        font=dict(family='Arial', size=14,\n                                                  color='rgb(248, 248, 255)'),\n                                        showarrow=False))\n                # labeling the Likert scale\n                if yd == y_data[-1]:\n                    annotations.append(dict(xref='x', yref='paper',\n                                            x=space + (xd[i]/2), y=1.1,\n                                            text=top_labels[i],\n                                            font=dict(family='Arial', size=14,\n                                                      color='rgb(67, 67, 67)'),\n                                            showarrow=False))\n                space += xd[i]\n\n    fig.update_layout(annotations=annotations)\n    \n    return fig","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"import math\ndef get_h_bar(y_data, df1, df2, df3, x_data):\n    fig = go.Figure()\n\n    fig.add_trace(go.Bar(\n        y=y_data,\n        x=list(df1['percent']),\n        name='0-3 years of DS/ML Experience',\n        legendgroup='lg1',\n        orientation='h',\n#        textposition='inside',\n#        hoverinfo='none',\n        marker=dict(color='#484a8a',\n            line=dict(color='#484a8a', width=1)\n        )\n    ))\n\n    fig.add_trace(go.Bar(\n        y=y_data,\n        x=list(df2['percent']),\n        name='0-3 years of DS/ML Experience & <br> 5+ years of coding experience',\n        orientation='h',\n        legendgroup='lg2',    \n#        textposition='inside',        \n#        hoverinfo='none',        \n        marker=dict(\n            color='#f5ab3d',\n            line=dict(color='#f5ab3d', width=1)\n        )\n    ))\n    fig.add_trace(go.Bar(\n        y=y_data,\n        x=list(df3['percent']),\n        name='0-3 years of DS/ML Experience & <br> 5+ years of coding experience &<br> Currently in DS/ML Jobs',\n        orientation='h',\n        legendgroup='lg3', \n#        textposition='inside',        \n#        hoverinfo='none',        \n        marker=dict(\n            color='#860f8c',\n            line=dict(color='#860f8c', width=1)\n        )\n    ))\n\n    fig.update_layout(\n            xaxis=dict(\n                showgrid=False,\n                showline=False,\n                showticklabels=True,\n                zeroline=False,\n                domain=[0.15, 1]\n            ),\n            yaxis=dict(\n                showgrid=False,\n                showline=False,\n                showticklabels=True,\n                zeroline=False,\n            ),\n            barmode='stack',\n            paper_bgcolor='rgb(248, 255, 255)',\n            plot_bgcolor='rgb(248, 255, 255)',\n            margin=dict(l=120, r=10, t=40, b=20),\n            showlegend=True,\n        )\n\n    annotations = []\n#[[25.4, 25.9, 26.3],\n# [19.7, 20.0, 12.8],\n# [17.2, 19.7, 24.4],\n# [14.1, 10.3, 7.8],\n# [12.2, 13.2, 16.1],\n# [11.4, 10.9, 12.6]]\n    for yd, xd in zip(y_data, x_data):\n        space = 0\n        for i in range(0, len(xd)):\n            #print(yd, xd, round(space + (xd[i]/2)))\n            \n            # labeling the rest of percentages for each bar (x_axis)\n            annotations.append(dict(xref='x', yref='y',\n                                            #x=space + (xd[i]/2), y=yd,\n                                            x= math.ceil(space + (xd[i]/2)), y=yd,\n                                            text=str(xd[i]) + '%',\n                                            font=dict(family='Arial', size=14,\n                                                      color='rgb(248, 248, 255)'),\n                                            showarrow=False))\n            space += xd[i]\n    #fig.update_layout(annotations=annotations)\n    return fig","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"from functools import reduce\nqn = 'Q22'\ndf1 = get_chart_df(ff_df,qn)\ndf2 = get_chart_df(coding_df,qn)\ndf3 = get_chart_df(ds_df,qn)\ndfs = [df1, df2, df3]\ndf_final = reduce(lambda left,right: pd.merge(left,right,on='answer'), dfs)\narr = df_final[['percent_x','percent_y','percent']].to_numpy()\nx_data = arr.tolist()\n\ny_data = ['We are exploring ML methods <br>(and may one day put a model into production)',\n       'No (we do not use ML methods)',\n       'We recently started using ML methods <br>(i.e., models in production for less than 2 years)',\n       'I do not know',\n       'We have well established ML methods <br>(i.e., models in production for more than 2 years)',\n       'We use ML methods for generating insights <br>(but do not put working models into production)']\n\n\nfig = get_h_bar(y_data,df1, df2, df3, x_data)\nfig.update_layout(title='Does your current employer incorporate <br>machine learning methods into their business?')\nfig['layout']['xaxis']['ticksuffix'] = '%'\nfig['layout']['xaxis']['tickangle']= 20\n\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q23 - Select any activities that make up an important part of your role at work"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import plotly.graph_objects as go\n\nqn = 'Q23'\ndf1 = get_chart_df(ff_df,qn)\ndf2 = get_chart_df(coding_df,qn)\ndf3 = get_chart_df(ds_df,qn)\ndfs = [df1, df2, df3]\ndf_final = reduce(lambda left,right: pd.merge(left,right,on='answer'), dfs)\narr = df_final[['percent_x','percent_y','percent']].to_numpy()\ndf_final\nx_data = arr.tolist()\n\ny_data = ['Analyze and understand data to <br> influence product or business decisions',\n       'Build and/or run the data infrastructure that my business <br> uses for storing, analyzing, and operationalizing data',\n       'Build prototypes to explore applying <br>machine learning to new areas',\n       'Build and/or run a machine learning service <br>that operationally improves my product or workflows',\n       'Experimentation and iteration to <br> improve existing ML models',\n       'Do research that advances the <br>state of the art of machine learning',\n       'None of these activities are an <br>important part of my role at work',\n       'Other']\n\n\nfig = get_h_bar(y_data,df1, df2, df3, x_data)\nfig.update_layout(title='Select any activities that make up an important part of your role at work')\nfig['layout']['xaxis']['ticksuffix'] = '%'\nfig['layout']['xaxis']['tickangle']= 20\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q24 - What is your current yearly compensation (approximate $USD)?\n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x_labels = [x.strip() for x in list(get_chart_df(ff_df,'Q24')['answer'])]\nfig = get_fig('Q24', 'Compensation', x=x_labels,vertical_spacing=1.0)\nfig.update_layout(yaxis2={'domain': [0, 0.45]},yaxis={'domain': [0.51, 1]})\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"sal_ff = ff_df.groupby(['Q24']).count().reset_index()\nsal_ff = sal_ff[['Q24','Q1']]\nsal_cd = coding_df.groupby(['Q24']).count().reset_index()\nsal_cd = sal_cd[['Q24','Q1']]\nsal_cd\n\nx0 = sal_ff['Q1']\n# Add 1 to shift the mean of the Gaussian distribution\nx1 = sal_cd['Q1']\n\nfig = go.Figure()\nfig.add_trace(go.Histogram(x=ff_df['Q24'], y=ff_df['Q1'], histfunc=\"count\", \n                                   name='0-3 years of DS/ML Experience',\n                        marker=dict(color='#484a8a'), legendgroup='lg1', histnorm='percent'))\nfig.add_trace(go.Histogram(x=coding_df['Q24'], y=coding_df['Q1'], histfunc=\"count\", \n                            name='0-3 years of DS/ML Experience & <br> 5+ years of coding experience',\n        marker=dict(color='#f5ab3d'), legendgroup='lg2', histnorm='percent'))\nfig.add_trace(go.Histogram(x=ds_df['Q24'], y=ds_df['Q1'], histfunc=\"count\",\n                           name='0-3 years of DS/ML Experience & <br> 5+ years of coding experience &<br> Currently in DS/ML Jobs',\n        marker=dict(color='#860f8c'), legendgroup='lg3', histnorm='percent'))\n\n# Overlay both histograms\nfig.update_layout(barmode='stack')\n# Reduce opacity to see both histograms\n#fig.update_traces(opacity=)\nfig.update_layout(title='Yearly compensation Stacked Histogram', paper_bgcolor='rgb(248, 255, 255)', plot_bgcolor='rgb(248, 248, 255)')\nfig['layout']['yaxis']['ticksuffix'] = '%'\nfig['layout']['xaxis']['tickangle']= 45\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q25 - Approximately how much money have you (or your team) spent on machine learning and/or cloud computing services at home (or at work) in the past 5 years (approximate $USD)?\n"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"x_labels = [x.strip() for x in list(get_chart_df(ff_df,'Q25')['answer'])]\nx_labels = ['0', '100-999', '1000-9,999', '1-99', '10,000-99,999', '100,000 or more']\nfig = get_fig('Q25', 'Money spent in the past 5 years (USD)', x=x_labels,vertical_spacing=1.0)\nfig.update_layout(yaxis2={'domain': [0, 0.50]},yaxis={'domain': [0.51, 1]})\niplot(fig)\n#print(x_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q26 - Which of the following cloud computing platforms do you use on a regular basis?"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x_labels = [x.strip() for x in list(get_chart_df(ff_df,'Q26')['answer'])]\nfig = get_fig('Q26', 'Cloud computing platforms', x=x_labels,vertical_spacing=1.0)\nfig.update_layout(yaxis2={'domain': [0, 0.50]},yaxis={'domain': [0.51, 1]})\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q27 - Do you use any of the following cloud computing products on a regular basis?"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x_labels = [x.strip() for x in list(get_chart_df(ff_df,'Q27')['answer'])]\nfig = get_fig('Q27', 'Cloud computing products', x=x_labels,vertical_spacing=1.0)\nfig.update_layout(yaxis2={'domain': [0, 0.50]},yaxis={'domain': [0.51, 1]})\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q28 - Do you use any of the following machine learning products on a regular basis? "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x_labels = [x.strip() for x in list(get_chart_df(ff_df,'Q28')['answer'])]\nfig = get_fig('Q28', 'Machine learning Products', x=x_labels,vertical_spacing=1.0)\nfig.update_layout(yaxis2={'domain': [0, 0.45]},yaxis={'domain': [0.51, 1]})\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q29 - Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis?"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x_labels = [x.strip() for x in list(get_chart_df(ff_df,'Q29')['answer'])]\nfig = get_fig('Q29', 'Big Data Products', x=x_labels,vertical_spacing=1.0)\nfig.update_layout(yaxis2={'domain': [0, 0.50]},yaxis={'domain': [0.51, 1]})\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q30 - Which of the following big data products (relational database, data warehouse, data lake, or similar) do you use most often? "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x_labels = [x.strip() for x in list(get_chart_df(ff_df,'Q30')['answer'])]\nfig = get_fig('Q30', 'Most often used big data products', x=x_labels,vertical_spacing=1.0)\nfig.update_layout(yaxis2={'domain': [0, 0.50]},yaxis={'domain': [0.51, 1]})\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q31 - Which of the following business intelligence tools do you use on a regular basis?"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x_labels = [x.strip() for x in list(get_chart_df(ff_df,'Q31')['answer'])]\nfig = get_fig('Q31', 'Business Intelligence Tools used on regular basis', x=x_labels,vertical_spacing=1.0)\nfig.update_layout(yaxis2={'domain': [0, 0.50]},yaxis={'domain': [0.51, 1]})\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q32 - Which of the following business intelligence tools do you use most often?"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"x_labels = [x.strip() for x in list(get_chart_df(ff_df,'Q32')['answer'])]\nfig = get_fig('Q32', 'Business Intelligence Tools used most often', x=x_labels,vertical_spacing=1.0)\nfig.update_layout(yaxis2={'domain': [0, 0.50]},yaxis={'domain': [0.51, 1]})\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q33 - Do you use any automated machine learning tools (or partial AutoML tools) on a regular basis?"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"import math\ndef get_simple_h_bar(y_data, df1, df2, df3, x_data):\n    fig = go.Figure()\n\n    fig.add_trace(go.Bar(\n        y=y_data,\n        x=list(df1['percent']),\n        name='0-3 years of DS/ML Experience',\n        legendgroup='lg1',\n        orientation='h',\n#        textposition='inside',\n        hoverinfo='none',\n        marker=dict(color='#484a8a',\n            line=dict(color='#484a8a', width=1)\n        )\n    ))\n\n    fig.add_trace(go.Bar(\n        y=y_data,\n        x=list(df2['percent']),\n        name='0-3 years of DS/ML Experience & <br> 5+ years of coding experience',\n        orientation='h',\n        legendgroup='lg2',    \n#        textposition='inside',        \n#        hoverinfo='none',        \n        marker=dict(\n            color='#f5ab3d',\n            line=dict(color='#f5ab3d', width=1)\n        )\n    ))\n    fig.add_trace(go.Bar(\n        y=y_data,\n        x=list(df3['percent']),\n        name='0-3 years of DS/ML Experience & <br> 5+ years of coding experience &<br> Currently in DS/ML Jobs',\n        orientation='h',\n        legendgroup='lg3', \n#        textposition='inside',        \n#        hoverinfo='none',        \n        marker=dict(\n            color='#860f8c',\n            line=dict(color='#860f8c', width=1)\n        )\n    ))\n\n    fig.update_layout(\n            barmode='stack',\n            paper_bgcolor='rgb(248, 255, 255)',\n            #plot_bgcolor='rgb(248, 255, 255)',\n            margin=dict(l=120, r=10, t=40, b=20),\n            showlegend=True,\n        )\n\n    annotations = []\n#[[25.4, 25.9, 26.3],\n# [19.7, 20.0, 12.8],\n# [17.2, 19.7, 24.4],\n# [14.1, 10.3, 7.8],\n# [12.2, 13.2, 16.1],\n# [11.4, 10.9, 12.6]]\n    for yd, xd in zip(y_data, x_data):\n        space = 0\n        for i in range(0, len(xd)):\n            #print(yd, xd, round(space + (xd[i]/2)))\n            \n            # labeling the rest of percentages for each bar (x_axis)\n            annotations.append(dict(xref='x', yref='y',\n                                            #x=space + (xd[i]/2), y=yd,\n                                            x= math.ceil(space + (xd[i]/2)), y=yd,\n                                            text=str(xd[i]) + '%',\n                                            font=dict(family='Arial', size=14,\n                                                      color='rgb(248, 248, 255)'),\n                                            showarrow=False))\n            space += xd[i]\n    #fig.update_layout(annotations=annotations)\n    return fig\nqn = 'Q33'\ndf1 = get_chart_df(ff_df,qn)\ndf2 = get_chart_df(coding_df,qn)\ndf3 = get_chart_df(ds_df,qn)\ndfs = [df1, df2, df3]\ndf_final = reduce(lambda left,right: pd.merge(left,right,on='answer'), dfs)\narr = df_final[['percent_x','percent_y','percent']].to_numpy()\ndf_final\nx_data = arr.tolist()\n\n\ny_data = ['Automated data augmentation <br>(e.g. imgaug, albumentations)',\n       'Automated feature engineering/selection <br>(e.g. tpot, boruta_py)',\n       'Automated model selection<br> (e.g. auto-sklearn, xcessiv)',\n       'Automated model architecture searches <br>(e.g. darts, enas)',\n       'Automated hyperparameter tuning <br>(e.g. hyperopt, ray.tune, Vizier)',\n       'Automation of full ML pipelines <br>(e.g. Google AutoML, H20 Driverless AI)',\n       'No / None', 'Other',\n       'Automation of full ML pipelines <br>(e.g. Google Cloud AutoML, H20 Driverless AI)',\n       'None']\n\n\nfig = get_simple_h_bar(y_data,df1, df2, df3, x_data)\nfig.update_layout(title='Use of automated machine learning tools (or partial AutoML tools)')\nfig.update_layout(\n            xaxis=dict(\n                showticklabels=True,\n            ),            plot_bgcolor='rgb(248, 255, 255)'\n)\nfig['layout']['xaxis']['ticksuffix'] = '%'\nfig['layout']['xaxis']['tickangle']= 20\niplot(fig)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q34 - Which of the following automated machine learning tools (or partial AutoML tools) do you use on a regular basis?"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"x_labels = [x.strip() for x in list(get_chart_df(ff_df,'Q34')['answer'])]\nfig = get_fig('Q34', 'Automated machine learning tools used', x=x_labels,vertical_spacing=1.0)\nfig.update_layout(yaxis2={'domain': [0, 0.50]},yaxis={'domain': [0.51, 1]})\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q35 - Do you use any tools to help manage machine learning experiments?"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x_labels = [x.strip() for x in list(get_chart_df(ff_df,'Q35')['answer'])]\nfig = get_fig('Q35', 'Tools to help manage machine learning experiments', x=x_labels,vertical_spacing=1.0)\nfig.update_layout(yaxis2={'domain': [0, 0.50]},yaxis={'domain': [0.51, 1]})\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q36 - Where do you publicly share or deploy your data analysis or machine learning applications?"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x_labels = [x.strip() for x in list(get_chart_df(ff_df,'Q36')['answer'])]\nfig = get_fig('Q36', 'Where do you publicly share or deploy your data analysis or machine learning applications?', x=x_labels,vertical_spacing=1.0)\nfig.update_layout(yaxis2={'domain': [0, 0.50]},yaxis={'domain': [0.51, 1]})\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q37 - On which platforms have you begun or completed data science courses?"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x_labels = [x.strip() for x in list(get_chart_df(ff_df,'Q37')['answer'])]\nx_labels = ['Coursera',\n 'edX',\n 'Kaggle Learn Courses',\n 'DataCamp',\n 'Fast.ai',\n 'Udacity',\n 'Udemy',\n 'LinkedIn Learning',\n 'Cloud-certification programs',\n 'University Courses',\n 'None',\n 'Other']\nfig = get_fig('Q37', 'On which platforms have you begun or completed data science courses?', x=x_labels,vertical_spacing=1.0)\nfig.update_layout(yaxis2={'domain': [0, 0.50]},yaxis={'domain': [0.51, 1]})\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q38 - What is the primary tool that you use at work or school to analyze data?"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"qn = 'Q38'\ndf1 = get_chart_df(ff_df,qn)\ndf2 = get_chart_df(coding_df,qn)\ndf3 = get_chart_df(ds_df,qn)\ndfs = [df1, df2, df3]\ndf_final = reduce(lambda left,right: pd.merge(left,right,on='answer'), dfs)\narr = df_final[['percent_x','percent_y','percent']].to_numpy()\ndf_final\nx_data = arr.tolist()\n\ny_data = ['Local development environments <br>(RStudio, JupyterLab, etc.)',\n       'Basic statistical software <br>(Microsoft Excel, Google Sheets, etc.)',\n       'Business intelligence software <br>(Salesforce, Tableau, Spotfire, etc.)',\n       'Cloud-based data software & APIs <br>(AWS, GCP, Azure, etc.)',\n       'Advanced statistical software <br>(SPSS, SAS, etc.)', 'Other']\n\nfig = get_simple_h_bar(y_data,df1, df2, df3, x_data)\nfig.update_layout(title='Primary tool to analyze data')\nfig['layout']['xaxis']['ticksuffix'] = '%'\nfig.update_layout(\n            xaxis=dict(\n                showgrid=False,\n                showline=False,\n                showticklabels=False,\n            ),\n            yaxis=dict(\n                showgrid=False,\n                showline=False,\n                showticklabels=True,\n                zeroline=False,\n            ),\n            barmode='stack',\n            paper_bgcolor='rgb(248, 255, 255)',\n            plot_bgcolor='rgb(248, 255, 255)',\n            margin=dict(l=120, r=10, t=40, b=20),\n            showlegend=True,\n        )\nfig['layout']['xaxis']['ticksuffix'] = '%'\nfig['layout']['xaxis']['tickangle']= 20\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q39 - Who/what are your favorite media sources that report on data science topics?"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x_labels = []\nx_labels = ['Twitter',\n \"Email newsletters\",\n 'Reddit',\n 'Kaggle',\n 'Course Forums',\n 'YouTube',\n 'Podcasts',\n 'Blogs',\n 'Journal Publications',\n 'Slack Communities',\n 'None',\n 'Other']\nfig = get_fig('Q39', 'Who/what are your favorite media sources that report on data science topics?', x=x_labels,vertical_spacing=1.0)\nfig.update_layout(yaxis2={'domain': [0, 0.50]},yaxis={'domain': [0.51, 1]})\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Long answers:\n* Twitter (data science influencers)\n* Email newsletters (Data Elixir, O'Reilly Data & AI, etc)\n* Reddit (r/machinelearning, etc)\n* Kaggle (notebooks, forums, etc)\n* Course Forums (forums.fast.ai, Coursera forums, etc)\n* YouTube (Kaggle YouTube, Cloud AI Adventures, etc)\n* Podcasts (Chai Time Data Science, O’Reilly Data Show, etc)\n* Blogs (Towards Data Science, Analytics Vidhya, etc)\n* Journal Publications (peer-reviewed journals, conference proceedings, etc)\n* Slack Communities (ods.ai, kagglenoobs, etc)"},{"metadata":{},"cell_type":"markdown","source":"### Q26 B - Which of the following cloud computing platforms do you hope to become more familiar with in the next 2 years?"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"qn = 'Q26_B_'\nx_labels = [x.strip() for x in list(get_chart_df(ff_df,qn)['answer'])]\nfig = get_fig(qn, 'Which of the following cloud computing platforms do you hope to become more familiar with in the next 2 years?', x=x_labels,vertical_spacing=1.0)\nfig.update_layout(yaxis2={'domain': [0, 0.50]},yaxis={'domain': [0.51, 1]})\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q27 B - In the next 2 years, do you hope to become more familiar with any of these specific cloud computing products?"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"qn = 'Q27_B_'\nx_labels = [x.strip() for x in list(get_chart_df(ff_df,qn)['answer'])]\nfig = get_fig(qn, 'In the next 2 years, do you hope to become more familiar with any of these <br>specific cloud computing products?', x=x_labels,vertical_spacing=1.0)\nfig.update_layout(yaxis2={'domain': [0, 0.50]},yaxis={'domain': [0.51, 1]})\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q28 B - In the next 2 years, do you hope to become more familiar with any of these specific machine learning products?"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"qn = 'Q28_B_'\nx_labels = [x.strip() for x in list(get_chart_df(ff_df,qn)['answer'])]\nfig = get_fig(qn, 'In the next 2 years, do you hope to become more familiar with any of these <br>specific machine learning products?', x=x_labels,vertical_spacing=1.0)\nfig.update_layout(yaxis2={'domain': [0, 0.50]},yaxis={'domain': [0.51, 1]})\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q29 B - Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you hope to become more familiar with in the next 2 years?"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"qn = 'Q29_B_'\nx_labels = [x.strip() for x in list(get_chart_df(ff_df,qn)['answer'])]\nfig = get_fig(qn, 'Which of the following big data products (relational databases, data warehouses, data lakes, <br>or similar) do you hope to become more familiar with in the next 2 years?', x=x_labels,vertical_spacing=1.0)\nfig.update_layout(yaxis2={'domain': [0, 0.50]},yaxis={'domain': [0.51, 1]})\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q31 B - Which of the following business intelligence tools do you hope to become more familiar with in the next 2 years?"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"qn = 'Q31_B_'\nx_labels = [x.strip() for x in list(get_chart_df(ff_df,qn)['answer'])]\nfig = get_fig(qn, 'Which of the following business intelligence tools do you hope to become more <br>familiar with in the next 2 years?', x=x_labels,vertical_spacing=1.0)\nfig.update_layout(yaxis2={'domain': [0, 0.50]},yaxis={'domain': [0.51, 1]})\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q33 B - Which categories of automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"qn = 'Q33_B_'\ndf1 = get_chart_df(ff_df,qn)\ndf2 = get_chart_df(coding_df,qn)\ndf3 = get_chart_df(ds_df,qn)\ndfs = [df1, df2, df3]\ndf_final = reduce(lambda left,right: pd.merge(left,right,on='answer'), dfs)\narr = df_final[['percent_x','percent_y','percent']].to_numpy()\ndf_final\nx_data = arr.tolist()\n\ny_data = ['Automated data augmentation <br>(e.g. imgaug, albumentations)',\n       'Automated feature engineering/selection <br>(e.g. tpot, boruta_py)',\n       'Automated model selection <br>(e.g. auto-sklearn, xcessiv)',\n       'Automated model architecture searches <br>(e.g. darts, enas)',\n       'Automated hyperparameter tuning <br>(e.g. hyperopt, ray.tune, Vizier)',\n       'Automation of full ML pipelines <br>(e.g. Google Cloud AutoML, H20 Driverless AI)',\n       'None', 'Other']\n\nfig = get_simple_h_bar(y_data,df1, df2, df3, x_data)\nfig.update_layout(title=' Which categories of automated machine learning tools (or partial AutoML tools) <br>do you hope to become more familiar with in the next 2 years?')\nfig['layout']['xaxis']['ticksuffix'] = '%'\nfig.update_layout(\n            xaxis=dict(\n                showgrid=False,\n                showline=False,\n                showticklabels=True,\n            ),\n            yaxis=dict(\n                showgrid=False,\n                showline=False,\n                showticklabels=True,\n                zeroline=False,\n            ),\n            barmode='stack',\n            paper_bgcolor='rgb(248, 255, 255)',\n            plot_bgcolor='rgb(248, 255, 255)',\n            margin=dict(l=120, r=10, t=40, b=20),\n            showlegend=True,\n        )\nfig['layout']['xaxis']['ticksuffix'] = '%'\nfig['layout']['xaxis']['tickangle']= 20\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q34 B - Which specific automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years? "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"qn = 'Q34_B_'\nx_labels = [x.strip() for x in list(get_chart_df(ff_df,qn)['answer'])]\nfig = get_fig(qn, 'Which specific automated machine learning tools (or partial AutoML tools) <br>do you hope to become more familiar with in the next 2 years?', x=x_labels,vertical_spacing=1.0)\nfig.update_layout(yaxis2={'domain': [0, 0.50]},yaxis={'domain': [0.51, 1]})\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q35 B - In the next 2 years, do you hope to become more familiar with any of these tools for managing ML experiments? "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"qn = 'Q35_B_'\nx_labels = [x.strip() for x in list(get_chart_df(ff_df,qn)['answer'])]\nfig = get_fig(qn, 'In the next 2 years, do you hope to become more familiar <br>with any of these tools for managing ML experiments?', x=x_labels,vertical_spacing=1.0)\nfig.update_layout(yaxis2={'domain': [0, 0.50]},yaxis={'domain': [0.51, 1]})\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Conclusion"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#list_org = ['Q7','Q7','Q7','Q7','Q7','Q7','Q7','Q7','Q7','Q7','Q7','Q7','Q9','Q9','Q9','Q9','Q9','Q9','Q9','Q9','Q9','Q9','Q9','Q10','Q10','Q10','Q10','Q10','Q10','Q10','Q10','Q10','Q10','Q10','Q10','Q10','Q12','Q12','Q12','Q14','Q14','Q14','Q14','Q14','Q14','Q14','Q14','Q14','Q14','Q14','Q16','Q16','Q16','Q16','Q16','Q16','Q16','Q16','Q16','Q16','Q16','Q16','Q16','Q16','Q16','Q17','Q17','Q17','Q17','Q17','Q17','Q17','Q17','Q17','Q17','Q17','Q18','Q18','Q18','Q18','Q18','Q18','Q19','Q19','Q19','Q19','Q19','Q23','Q23','Q23','Q23','Q23','Q23','Q23','Q26','Q26','Q26','Q26','Q26','Q26','Q26','Q26','Q26','Q26','Q26','Q27','Q27','Q27','Q27','Q27','Q27','Q27','Q27','Q27','Q27','Q27','Q28','Q28','Q28','Q28','Q28','Q28','Q28','Q28','Q28','Q28','Q29','Q29','Q29','Q29','Q29','Q29','Q29','Q29','Q29','Q29','Q29','Q29','Q29','Q29','Q29','Q29','Q29','Q31','Q31','Q31','Q31','Q31','Q31','Q31','Q31','Q31','Q31','Q31','Q31','Q31','Q31','Q33','Q33','Q33','Q33','Q33','Q33','Q33','Q34','Q34','Q34','Q34','Q34','Q34','Q34','Q34','Q34','Q34','Q34','Q35','Q35','Q35','Q35','Q35','Q35','Q35','Q35','Q35','Q35','Q36','Q36','Q36','Q36','Q36','Q36','Q36','Q36','Q36','Q37','Q37','Q37','Q37','Q37','Q37','Q37','Q37','Q37','Q37','Q37','Q39','Q39','Q39','Q39','Q39','Q39','Q39','Q39','Q39','Q39','Q39','Q26','Q26','Q26','Q26','Q26','Q26','Q26','Q26','Q26','Q26','Q26','Q27','Q27','Q27','Q27','Q27','Q27','Q27','Q27','Q27','Q27','Q27','Q28','Q28','Q28','Q28','Q28','Q28','Q28','Q28','Q28','Q28','Q29','Q29','Q29','Q29','Q29','Q29','Q29','Q29','Q29','Q29','Q29','Q29','Q29','Q29','Q29','Q29','Q29','Q31','Q31','Q31','Q31','Q31','Q31','Q31','Q31','Q31','Q31','Q31','Q31','Q31','Q31','Q33','Q33','Q33','Q33','Q33','Q33','Q33','Q34','Q34','Q34','Q34','Q34','Q34','Q34','Q34','Q34','Q34','Q34','Q35','Q35','Q35','Q35','Q35','Q35','Q35','Q35','Q35','Q35'\n#           ,'Q26_B','Q26_B','Q26_B','Q26_B','Q26_B','Q26_B','Q26_B','Q26_B','Q26_B','Q26_B','Q26_B','Q26_B','Q27_B','Q27_B','Q27_B','Q27_B','Q27_B','Q27_B','Q27_B','Q27_B','Q27_B','Q27_B','Q27_B','Q27_B','Q28_B','Q28_B','Q28_B','Q28_B','Q28_B','Q28_B','Q28_B','Q28_B','Q28_B','Q28_B','Q28_B','Q29_B','Q29_B','Q29_B','Q29_B','Q29_B','Q29_B','Q29_B','Q29_B','Q29_B','Q29_B','Q29_B','Q29_B','Q29_B','Q29_B','Q29_B','Q29_B','Q29_B','Q29_B','Q31_B','Q31_B','Q31_B','Q31_B','Q31_B','Q31_B','Q31_B','Q31_B','Q31_B','Q31_B','Q31_B','Q31_B','Q31_B','Q31_B','Q31_B','Q33_B','Q33_B','Q33_B','Q33_B','Q33_B','Q33_B','Q33_B','Q33_B','Q34_B','Q34_B','Q34_B','Q34_B','Q34_B','Q34_B','Q34_B','Q34_B','Q34_B','Q34_B','Q34_B','Q34_B','Q35_B','Q35_B','Q35_B','Q35_B','Q35_B','Q35_B','Q35_B','Q35_B','Q35_B','Q35_B','Q35_B']\n#lst_cols = []\n#[lst_cols.append(x) for x in list_org if x not in lst_cols] \nlst_cols = ['Q7', 'Q9', 'Q10', 'Q12', 'Q14', 'Q16', 'Q17', 'Q18', 'Q19', 'Q23', 'Q26', 'Q27', 'Q28', 'Q29', 'Q31', 'Q33', 'Q34', 'Q35', 'Q36', 'Q37', 'Q39', 'Q26_B', 'Q27_B', 'Q28_B', 'Q29_B', 'Q31_B', 'Q33_B', 'Q34_B', 'Q35_B']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Areas to focus during initial years of data science expedition (1-3 years)"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"wc_dict = {}\n\nfor q in lst_cols:\n    sub_qns = [qn for qn in list(master.columns) if q in qn]\n    for sub_q in sub_qns:\n        dct = ff_df[sub_q].value_counts().to_dict()\n        for key in dct:\n            if 'None' in key or 'Other' in key:\n                continue\n            wc_dict[key.strip()] = dct[key]\n#wc_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import wordcloud as w\n#wordcloud = w.WordCloud(collocations=False).generate_from_frequencies(wc_dict)\nwordcloud = w.WordCloud(collocations=False, repeat=True, max_font_size=100, max_words=len(wc_dict), \n                        background_color=\"#bdb7ac\", colormap='gist_heat',\n                        prefer_horizontal=1.0,\n                        min_font_size = 1).generate_from_frequencies(wc_dict)\n\n#wordcloud = w.WordCloud(collocations = False).generate(text)\nplt.figure(figsize = (60,30))\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis(\"off\")\nplt.show()\n#fig.tight_layout(pad=3.0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### After 3 years"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"expds_df = q15[(q15['Q15'].str.contains('3-4 years') | q15['Q15'].str.contains('4-5 years') | q15['Q15'].str.contains('5-10 years') |  q15['Q15'].str.contains('10-20 years') | q15['Q15'].str.contains('20 or more years'))]\nwc_dict = {}\n\nfor q in lst_cols:\n    sub_qns = [qn for qn in list(master.columns) if q in qn]\n    for sub_q in sub_qns:\n        dct = expds_df[sub_q].value_counts().to_dict()\n        for key in dct:\n            if 'None' in key or 'Other' in key:\n                continue\n            wc_dict[key.strip()] = dct[key]\n#wc_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#wordcloud = w.WordCloud(collocations=False).generate_from_frequencies(wc_dict)\nwordcloud = w.WordCloud(collocations=False, repeat=True, max_font_size=100, max_words=len(wc_dict), \n                        background_color=\"#bdb7ac\", colormap='summer',\n                        prefer_horizontal=1.0,\n                        min_font_size = 1).generate_from_frequencies(wc_dict)\n\n#wordcloud = w.WordCloud(collocations = False).generate(text)\nplt.figure(figsize = (60,30))\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis(\"off\")\nplt.show()\n#fig.tight_layout(pad=3.0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It's evident (and quite obvious) to spend time on or learn the following to start with \n\n* Python\n* Matplotlib\n* Scikit-learn\n* Linear / Logistic Regression\n* Decision Trees / Random Forests\n* Jupyter (Lab/Notebooks)\n* Kaggle (notebooks, forums)\n\nand move on to explore other areas such as\n\n* Seaborn\n* Kaggle (notebooks, forums)\n* Tensorflow, Keras, PyTorch\n* Gradient Boosting Machines (xgboost, lightgbm, etc)\n* Convolutional Neural Networks\n\nOf course this is not a comprehensive list. However, but a good starting list to plunge into data science world that aligns with the community !"},{"metadata":{},"cell_type":"markdown","source":"##### References\n\n* https://chart-studio.plotly.com/~alishobeiri/1591/plotly-sankey-diagrams/#/\n* https://www.kaggle.com/iyadavvaibhav/plotly-sankey-with-filters (Inspiration for Interactive Sankey)\n* https://plotly.com/python/"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}