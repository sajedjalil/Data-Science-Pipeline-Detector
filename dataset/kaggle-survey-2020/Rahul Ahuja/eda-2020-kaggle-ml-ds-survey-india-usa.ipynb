{"cells":[{"metadata":{},"cell_type":"markdown","source":"<header>\n<h1><center>Exploratory Data Analysis of the<br>2020 Kaggle Machine Learning & Data Science Survey</center></h1>\n<h5><center>Focused on the distributions for India vis-a-vis USA and Data Scientist vis-a-vis General trends</center></h5>\n</header>"},{"metadata":{},"cell_type":"markdown","source":"The data is for an industry-wide survey that presents a truly comprehensive view of the state of data science and machine learning and has 20,036 repondants from all over the world.<br>\n\n**The challenge objective**: tell a data story about a subset of the data science community represented in this survey, through a combination of both narrative text and data exploration.\n\n**Survey structure**: 39+ questions and 20,036 responses.<br>Responses to multiple choice questions (only a single choice can be selected) were recorded in individual columns. Responses to multiple selection questions (multiple choices can be selected) were split into multiple columns (with one column per answer choice).\n\n<a href=\"https://www.kaggle.com/c/kaggle-survey-2020\">Link to competition page</a>"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"toc\"></a>\n## Table of Contents\n1. [Prerequisites](#1.-Prerequisites)\n2. [Import data](#2.-Import-data)\n3. [Defined functions](#3.-Defined-functions)\n4. [Questions in the survey](#4.-Questions-in-the-survey)\n5. [Data preprocessing](#5.-Data-preprocessing)\n6. [Question analysis](#6.-Question-analysis)\n    - [Q1 - Age](#Q1---Age)\n    - [Q2 - Gender](#Q2---Gender)\n      - [Observations](#obs-q2.1)\n      - [Gender-Age Distribution](#Gender-Age-Distribution)\n        - [Observations](#obs-q1q2)\n    - [Q3 - Country of residence](#Q3---Country-of-residence)\n      - [Observations](#obs-q3.1)\n      - [Region-wise frequency distribution](#Region-wise-frequency-distribution)\n        - [Observations](#obs-q3.2)\n    - [Q4 - Education](#Q4---Education)\n      - [Observations](#obs-q4)\n    - [Q5 - Job role](#Q5---Job-role)\n      - [Observations](#obs-q5)\n    - [Q6 - Programming experience](#Q6---Programming-experience)\n      - [Observations](#obs-q6)\n    - [Q4 & Q5 - Education & Job role](#Q4-&-Q5---Education-&-Job-role)\n      - [a) Heatmap](#a%29-Heatmap)\n      - [b) Stacked Bar Chart](#b%29-Stacked-Bar-Chart)\n      - [c) Comparitive bar chart](#c%29-Comparitive-bar-chart)\n      - [Observations](#obs-q4q5)\n    - [Q4 & Q6 - Education & Coding experience](#Q4-&-Q6---Education-&-Coding-experience)\n      - [Observations](#obs-q4q6)\n    - [Q5 & Q6 - Job role and Coding experience](#Q5-&-Q6---Job-role-and-Coding-experience)\n      - [Observations](#obs-q5q6)\n    - [Q7 - Regularly used programming language](#Q7---Regularly-used-programming-language)\n      - [Observations](#obs-q7)\n    - [Q5 & Q7 - Role & Language](#Q5-&-Q7---Role-&-Language)\n      - [Observations](#obs-q5q7)\n    - [Q8 - Recommended Language](#Q8---Recommended-Language)\n      - [Observations](#obs-q8)\n    - [Q9 - IDE Used](#Q9---IDE-Used)\n      - [Observations](#obs-q9)\n    - [Q10 - Hosted notebook products regularly used](#Q10---Hosted-notebook-products-regularly-used)\n      - [Observations](#obs-q10)\n    - [Q11 - Computing platform](#Q11---Computing-platform)\n      - [Observations](#obs-q11)\n    - [Q12 - Specialized hardware](#Q12---Specialized-hardware)\n    - [Q13 - TPU usage in life](#Q13---TPU-usage-in-life)\n    - [Q14 - Visualization libraries](#Q14---Visualization-libraries)\n      - [Observations](#obs-q14)\n    - [Q15 - Machine Learning Methods](#Q15---Machine-Learning-Methods)\n      - [Observations](#obs-q15)\n    - [Q16 - Machine Learning Frameworks](#Q16---Machine-Learning-Frameworks)\n      - [Observations](#obs-q16)\n    - [Q17 - ML Algorithms](#Q17---ML-Algorithms)\n    - [Q18 - Computer Vision Methods](#Q18---Computer-Vision-Methods)\n      - [Observations](#obs-q18)\n    - [Q19 - Natural Language Processing](#Q19---Natural-Language-Processing)\n    - [Q20 - Company size](#Q20---Company-size)\n    - [Q21 - Individuals engaged in Data Science work at workplace](#Q21---Individuals-engaged-in-Data-Science-work-at-workplace)\n      - [Observations](#obs-q21)\n    - [Q22 - ML methods used in business](#Q22---ML-methods-used-in-business)\n      - [Observations](#obs-q22)\n    - [Q23 - Important work activities](#Q23---Important-work-activities)\n    - [Q24 - Yearly Compensation](#Q24---Yearly-Compensation)\n    - [Q25 - Money spent on ML / Cloud-computing](#Q25---Money-spent-on-ML-/-Cloud-computing)\n    - [Q26 - Cloud-computing platform](#Q26---Cloud-computing-platform)\n    - [Q27 - Cloud-computing products](#Q27---Cloud-computing-products)\n    - [Q28 - Machine learning products](#Q28---Machine-learning-products)\n    - [Q29 - Big Data Products](#Q29---Big-Data-Products)\n    - [Q30 - Most used big data products](#Q30---Most-used-big-data-products)\n    - [Q31 - Business Intelligence Tools](#Q31---Business-Intelligence-Tools)\n    - [Q32 - Business Intilligence tools used most often](#Q32---Business-Intilligence-tools-used-most-often)\n    - [Q33 - Automated ML Tools Category](#Q33---Automated-ML-Tools-Category)\n    - [Q34 - Automated ML tools](#Q34---Automated-ML-tools)\n    - [Q35 - ML experiments](#Q35---ML-experiments)\n    - [Q36 - Public sharing platforms](#Q36---Public-sharing-platforms)\n    - [Q37 - DS learning platforms](#Q37---DS-learning-platforms)\n    - [Q38 - Data Analysis Tool](#Q38---Data-Analysis-Tool)\n    - [Q39 - Favorite Media Sources](#Q39---Favorite-Media-Sources)\n\n7. [Notes](#Notes)\n8. [References](#Notebooks-Referenced)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### 1. Prerequisites"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Libraries\nimport os\nimport numpy as np\nimport pandas as pd\nimport re\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.offline as pyo\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.offline import init_notebook_mode\nimport plotly.figure_factory as ff\nfrom plotly import subplots\ninit_notebook_mode(connected=True)\n%matplotlib inline\nfrom textwrap import fill, wrap\nimport re\n\nplt.rcParams['figure.dpi'] = 150 # higher resolution","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### 2. Import data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load data\ndfo = pd.read_csv('/kaggle/input/kaggle-survey-2020/kaggle_survey_2020_responses.csv')\nprint(dfo.shape)\n\npd.set_option('display.max_columns',100)\ndfo.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfo.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### 3. Defined functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to forestall UserWarning\nimport warnings\ndef fxn():\n    warnings.warn(\"UserWarning arose\", UserWarning)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to create distribution of a variable based on 2 conditions\ndef fd(data, data1=None, criteria1=None, data2=None, criteria2=None, title='criteria', \n       strip=False, contains=False, otherthan1=False, otherthan2=False):\n    \"\"\"Create distribution of a variable based on 2 conditions.(order is important)\"\"\"\n    tempdf1 = data.copy()\n    if data1 is not None:\n        if isinstance(data1, pd.Series):\n            cdf1 = data1.copy().to_frame()\n        else:\n            cdf1 = data1.copy()\n    else:\n        cdf1 = None\n            \n    if data2 is not None:\n        if isinstance(data2, pd.Series):\n            cdf2 = data2.copy().to_frame()\n        else:\n            cdf2 = data2.copy()\n    else:\n        cdf2 = None\n    \n    if len(data.shape) > 1:\n        if data.shape[1] > 1:\n            tempdf1.columns = tempdf1.mode().values.tolist()[0]\n    if strip==True:\n        for df in [cdf1, cdf2]:\n            if df is not None:\n                for c in df:\n                    df[c] = df[c].apply(lambda x: x.strip() if isinstance(x, str) else x)\n\n    \n    if ((criteria1==None) & (criteria2==None)):\n        tempdf = tempdf1.copy()\n        case = 1\n    elif criteria1==None:\n        tempdf = pd.concat([cdf2, tempdf1], axis=1)\n        case = 2\n    elif criteria2==None:\n        tempdf = pd.concat([cdf1, tempdf1], axis=1)\n        case = 2\n    else:\n        tempdf = pd.concat([cdf1, cdf2, tempdf1], axis=1)\n        case = 3\n        \n    if case == 3:\n        if ((otherthan1 is True) and (otherthan2 is True)):\n            if contains==True:\n                tempdf = tempdf[~(tempdf.iloc[:,0].str.contains(r''+criteria1, regex=True, na=False)) &\n                            ~(tempdf.iloc[:,1].str.contains(r''+criteria2, regex=True, na=False))]\n            else:\n                tempdf = tempdf[(tempdf.iloc[:,0] != criteria1) & (tempdf.iloc[:,1] != criteria2)]\n        else:\n            if contains==True:\n                tempdf = tempdf[(tempdf.iloc[:,0].str.contains(r''+criteria1, regex=True, na=False)) &\n                            (tempdf.iloc[:,1].str.contains(r''+criteria2, regex=True, na=False))]\n            else:\n                tempdf = tempdf[(tempdf.iloc[:,0] == criteria1) & (tempdf.iloc[:,1] == criteria2)]\n        tempdf.drop(tempdf.columns[[0,1]], axis=1, inplace=True)\n            \n\n    if case == 2:\n        crit = criteria2 if criteria1==None else criteria1\n        otherthan = otherthan2 if criteria1==None else otherthan1\n        if otherthan:\n            if contains==True:\n                tempdf = tempdf[~tempdf.iloc[:,0].str.contains(r''+crit, regex=True, na=False)]\n            else:\n                tempdf = tempdf[tempdf.iloc[:,0] != crit]\n        else:\n            if contains==True:\n                tempdf = tempdf[tempdf.iloc[:,0].str.contains(r''+crit, regex=True, na=False)]\n            else:\n                tempdf = tempdf[tempdf.iloc[:,0] == crit]\n        tempdf.drop(tempdf.columns[0], axis=1, inplace=True)\n            \n\n    if len(data.shape) > 1:\n        if data.shape[1] > 1:\n            tempdf = tempdf.dropna(how='all')\n            n = tempdf.shape[0]\n\n            fd = tempdf.count().reset_index()\n            fd.columns = [title, 'freq']\n            fd['proportion'] = round(fd['freq']*100/n, 2)\n            return fd\n\n    fd = tempdf.value_counts().reset_index()\n    fd.columns = [title, 'freq']\n    fd['proportion'] = (tempdf.value_counts(normalize=True).values*100).round(2)\n    return fd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to create frequency distribution (multi-answer questions)\ndef fd_maq(data, title='criteria'):\n    \"\"\"Create frequency distribution for questions allowing multiple answers.\"\"\"\n    tempdf = data.copy()\n    tempdf.columns = tempdf.mode().values.tolist()[0]\n    tempdf = tempdf.dropna(how='all')\n    n = tempdf.shape[0]\n    fd = tempdf.count().reset_index()\n    fd.columns = [title, 'freq']\n    fd['proportion'] = round(fd['freq']*100/n, 2)\n    return fd\n\n# Function to create frequency distribution (single-answer questions)\ndef fd_saq(data, title='criteria', ordered=True):\n    \"\"\"Create frequency distribution for questions allowing single answer.\"\"\"\n    tempdf = data.dropna()\n    n = tempdf.shape[0]\n    fd = tempdf.value_counts(sort=ordered).reset_index()\n    fd.columns = [title, 'freq']\n    fd['proportion'] = round(fd['freq']*100/n, 2)\n    return fd\n\n# Function to create subset according to Country\ndef country_subset(data, country):\n    \"\"\"Create subset according to country.\"\"\"\n    tempdf1 = data.copy()\n    tempdf1['country'] = df['Q3'].copy()\n    tempdf = tempdf1[tempdf1['country'] == country]\n    tempdf.drop('country', axis=1, inplace=True)\n    return tempdf\n\n# Function to sort dataframe with custom order\ndef custom_sort(df, col, ordered_list, reverse=False):\n    \"\"\"Sort dataframe with custom order list.\"\"\"\n    tempdf1 = df.copy()\n    tempdf1 = tempdf1.set_index(col)\n    if reverse:\n        custom_order = ordered_list[::-1]\n    else:\n        custom_order = ordered_list\n    tempdf = tempdf1.loc[ordered_list, :].reset_index()\n    return tempdf\n\n# Function to sort dataframe with custom order (2)\ndef custom_sort2(df, col, ordered_list, reverse=False):\n    \"\"\"Sort dataframe with custom order list.\"\"\"\n    tempdf1 = df.copy()\n    if reverse:\n        custom_order = pd.DataFrame(ordered_list[::-1])\n    else:\n        custom_order = pd.DataFrame(ordered_list)\n    tempdf = custom_order.merge(tempdf1, how='left', left_on=0, right_on=col)\n    tempdf.drop(0, axis=1, inplace=True)\n    tempdf.dropna(how='all', inplace=True)\n    tempdf.reset_index(drop=True, inplace=True)\n    return tempdf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to create differential proportion graph\ndef differential_graph(qn, graph_title='Differential Proportion', order=None):\n    \"\"\"Create differential proportion graph for India and USA.\"\"\"\n    tempdf = qn.copy() \n    # Create value_counts table\n    qn_fd = qn.value_counts().rename('World').to_frame()\n    qni_fd = country_subset(qn,'India').value_counts().rename('India').to_frame()\n    qnu_fd = country_subset(qn,'United States of America').value_counts().rename('USA').to_frame()\n    qn_fd['India'] = qn_fd.index.map(qni_fd['India'])\n    qn_fd['USA'] = qn_fd.index.map(qnu_fd['USA'])\n    qn_fd.index.rename('criteria', inplace=True)\n    qn_fd.reset_index(inplace=True)\n\n    # India - Differential proportion compared with overall overall proportion of 0.292\n    diff = ((qn_fd['India']/qn_fd['World']) - 0.292).round(4)*100\n    clrs = list(np.where(diff.values < 0, '#B51A62', '#37659E'))\n\n    # Plot\n    fig1 = go.Figure(go.Bar(x=qn_fd['criteria'], y=diff.values, text=diff.values.round(3), \n                           marker_color=clrs))\n    title1 = f\"India - Change in {graph_title} compared with overall sample proportion (29.2%)<br>(in percentage points (%p))\"\n    fig1.update_layout(title={'text':title1, 'x':0.5, 'xanchor':'center'}, plot_bgcolor='#fff')\n    fig1.update_traces(texttemplate='%{text:i} %p', textposition='outside', textfont_size=9, \n                      textfont_color='black')\n    if order is not None:\n        fig1.update_xaxes(categoryorder='array', categoryarray=order, visible=True)\n    \n    \n    # USA - Differential proportion compared with overall overall proportion of 0.112\n    diff = ((qn_fd['USA']/qn_fd['World']) - 0.112).round(4)*100\n    clrs = list(np.where(diff.values < 0, '#B51A62', '#37659E'))\n\n    # Plot\n    fig2 = go.Figure(go.Bar(x=qn_fd['criteria'], y=diff.values, text=diff.values.round(3), \n                           marker_color=clrs))\n    title2 = f\"USA - Change in {graph_title} compared with overall sample proportion (11.2%)<br>(in percentage points (%p))\"\n    fig2.update_layout(title={'text':title2, 'x':0.5, 'xanchor':'center'}, plot_bgcolor='#fff')\n    fig2.update_traces(texttemplate='%{text:i} %p', textposition='outside', textfont_size=9, \n                      textfont_color='black')\n    if order is not None:\n        fig2.update_xaxes(categoryorder='array', categoryarray=order, visible=True)\n    \n    return fig1, fig2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to find % change in proportion of India and USA distributions\ndef diff_ind_usa(data, data2=None, criteria2=None, title='criteria', strip=False, contains=False, otherthan1=False, otherthan2=False):\n    \"\"\"Different in proportions for India and USA distributions.\"\"\"\n    o = fd(data, data2=data2, criteria2=criteria2, title=title, strip=strip, contains=contains, otherthan1=otherthan1, otherthan2=otherthan2)\n    i = fd(data, data1=qd['Q3'], criteria1='India', data2=data2, criteria2=criteria2, title=title, strip=strip, contains=contains, otherthan1=otherthan1, otherthan2=otherthan2)\n    u = fd(data, data1=qd['Q3'], criteria1='United States of America', data2=data2, criteria2=criteria2, title=title, strip=strip, contains=contains, otherthan1=otherthan1, otherthan2=otherthan2)\n    comp = o.iloc[:,[0,2]].set_index('criteria').rename(columns={'proportion':'world'})\n    comp['india'] = comp.index.map(i.set_index('criteria')['proportion'])\n    comp['usa'] = comp.index.map(u.set_index('criteria')['proportion'])\n    comp['diff %'] = ((comp['india'] - comp['usa'])/comp['world']).round(4)*100\n    return comp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fuction to build graph with USA and India distributions and filters\ndef build_graph(qn, qn2=None, graph_title='Comparitive Graph', ascending=False, order=None, \n                counts=False, label_angle=-15, title='criteria', hgt=600, wd=900, xsize=9, \n                adjust_margin=True, xmargin=None, tmargin=None):\n    \"\"\"Create plotly interactive graph with USA-India options\"\"\"\n    qdf = qn.copy()\n    output = 'freq' if counts==True else 'proportion'\n\n    # Create freqency distribution table\n    kind = ''\n    if len(qdf.shape) > 1:\n        if qdf.shape[1] > 1:\n            kind = 'df'\n            \n    if kind == 'df':\n        qdf.columns = qdf.mode().values.tolist()[0]\n        classes = qdf.columns\n        q_fds = fd_maq(qdf, title).sort_values(by='freq', ascending=False)\n        q_fdsi = fd_maq(country_subset(qdf, 'India'), title).sort_values(by='freq', ascending=False)\n        q_fdsu = fd_maq(country_subset(qdf, 'United States of America'), title).sort_values(by='freq', ascending=False)\n    else:\n        classes = qdf.iloc[:,0].unique()\n        q_fds = fd_saq(qdf, title).sort_values(by='freq', ascending=False)\n        q_fdsi = fd_saq(country_subset(qdf, 'India'), title).sort_values(by='freq', ascending=False)\n        q_fdsu = fd_saq(country_subset(qdf, 'United States of America'), title).sort_values(by='freq', ascending=False)\n        \n    # Comparitive Bar Chart    \n    fig = go.Figure()\n    name1 = 'World' if qn2 is None else '(legends applicable<br>when unfiltered)<br>World<br><br>'\n    fig.add_trace(go.Bar(x=q_fds[title], y=q_fds[output], name=name1,\n                         marker_color='thistle', text=q_fds[output]))\n    fig.add_trace(go.Bar(x=q_fdsi[title], y=q_fdsi[output], name='India', \n                         marker_color='#37659E', text=q_fdsi[output]))\n    fig.add_trace(go.Bar(x=q_fdsu[title], y=q_fdsu[output], name='USA',\n                         marker_color='teal', text=q_fdsu[output]))\n\n    \n    if qn2 is not None:\n        qdf2 = qn2.copy()\n        kind2=''\n        classes = qdf2.iloc[:,0].unique()\n        if len(qdf2.shape) > 1:\n            if qdf2.shape[1] > 1:\n                kind2 = 'df'\n                classes = qdf2.mode().values.tolist()[0]\n\n        button1=[]\n        button1.append(dict(method='restyle', label='All samples', visible=True,\n                            args=[{'y':[q_fds[output]], 'text':[q_fds[output]],\n                                   'x':[q_fds[title]],'type':'bar'},[0]]))\n\n        for i in range(len(list(classes))):\n            r = list(classes)[i]\n            for c in ['.','India','United States of America']:\n                cnt = c if c in ['India','United States of America'] else None\n                fd_r = fd(qdf, qn2, r, qd['Q3'], cnt) if kind2!='df' else fd(qdf, qn2.iloc[:,i], r, qd['Q3'], cnt)\n                button1.append(dict(method='restyle', label=str(r)[0:25]+' - '+str('World' if c == '.' else 'USA' if c == 'United States of America' else c), visible=True,\n                                   args=[{'y':[fd_r[output]],'x':[fd_r[title]],'type':'bar',\n                                          'text':[fd_r[output]]},[0]]))\n\n        button2=[]\n        button2.append(dict(method='restyle', label='All samples', visible=True,\n                            args=[{'y':[q_fds[output]], 'text':[q_fds[output]],\n                                   'x':[q_fds[title]],'type':'bar'},[1]]))\n\n        for i in range(len(list(classes))):\n            r = list(classes)[i]\n            for c in ['.','India','United States of America']:\n                cnt = c if c in ['India','United States of America'] else None\n                fd_r = fd(qdf, qn2, r, qd['Q3'], cnt) if kind2!='df' else fd(qdf, qn2.iloc[:,i], r, qd['Q3'], cnt)\n                button2.append(dict(method='restyle', label=str(r)[0:25]+' - '+str('World' if c == '.' else 'USA' if c == 'United States of America' else c), visible=True,\n                                   args=[{'y':[fd_r[output]],'x':[fd_r[title]],'type':'bar',\n                                          'text':[fd_r[output]]},[1]]))\n       \n        button3=[]\n        button3.append(dict(method='restyle', label='All samples', visible=True,\n                            args=[{'y':[q_fds[output]], 'text':[q_fds[output]],\n                                   'x':[q_fds[title]],'type':'bar'},[2]]))\n\n        for i in range(len(list(classes))):\n            r = list(classes)[i]\n            for c in ['.','India','United States of America']:\n                cnt = c if c in ['India','United States of America'] else None\n                fd_r = fd(qdf, qn2, r, qd['Q3'], cnt) if kind2!='df' else fd(qdf, qn2.iloc[:,i], r, qd['Q3'], cnt)\n                button3.append(dict(method='restyle', label=str(r)[0:25]+' - '+str('World' if c == '.' else 'USA' if c == 'United States of America' else c), visible=True,\n                                   args=[{'y':[fd_r[output]],'x':[fd_r[title]],'type':'bar',\n                                          'text':[fd_r[output]]},[2]]))\n    \n        button_layer_1_height = 1.16\n        updatemenus = list([dict(buttons=button1, direction='down',pad={'r':10,'t':10}, showactive=True,\n                                x=0.02, xanchor='left', y=button_layer_1_height, yanchor='top'),\n                            dict(buttons=button2, direction='down',pad={'r':10,'t':10}, showactive=True,\n                                x=0.45, xanchor='left', y=button_layer_1_height, yanchor='top'),\n                            dict(buttons=button3, direction='down',pad={'r':10,'t':10}, showactive=True,\n                                x=0.88, xanchor='left', y=button_layer_1_height, yanchor='top')])\n\n        fig.update_layout(updatemenus=updatemenus)\n        fig.update_layout(annotations=[dict(text=\"1\", x=0.0, xref=\"paper\", showarrow=False,\n                                            y=button_layer_1_height-0.05, yref=\"paper\"), \n                                       dict(text=\"2\", x=0.435, xref=\"paper\", showarrow=False,\n                                            y=button_layer_1_height-0.05, yref=\"paper\"),\n                                       dict(text=\"3\", x=0.87, xref=\"paper\", showarrow=False,\n                                            y=button_layer_1_height-0.05, yref=\"paper\")])\n\n\n    if ascending==False:\n        if order == None:\n            fig.update_xaxes(categoryorder='array', categoryarray=qdf.columns)\n        else:\n            fig.update_xaxes(categoryorder='array', categoryarray=order)\n    \n    fig.update_layout(plot_bgcolor='#fff')\n    title_text = str(graph_title)+'<br>(% of respondents)' if counts==False else str(graph_title)+'<br>(No. of respondents)'\n    fig.update_layout(title={'text':title_text,\n                             'x':0.49, 'xanchor':'center','y':0.97, 'yanchor':'top'})\n    fig.update_layout(autosize=False, width=wd, height=hgt, xaxis_tickangle=label_angle)\n    fig.update_traces(texttemplate='%{text:.2s}', textposition='outside', textfont_size=xsize)\n    if tmargin is not None:\n        fig.update_layout(margin=dict(t=tmargin))\n    if adjust_margin is False:\n        fig.update_xaxes(automargin=False)\n    if xmargin is not None:\n        fig.update_layout(margin=dict(b=xmargin))\n    \n    fig.show()\n\n# Notebook referenced : 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to create data subset based on upto 2 conditions\ndef create_subset(data, data1=None, criteria1=None, data2=None, criteria2=None, title='criteria', \n                  strip=False, contains=False, otherthan1=False, otherthan2=False):\n    \"\"\"Create subset of data based on upto 2 conditions.\"\"\"\n    tempdf1 = data.copy()\n    if data1 is not None:\n        if isinstance(data1, pd.Series):\n            cdf1 = data1.copy().to_frame()\n        else:\n            cdf1 = data1.copy()\n    else:\n        cdf1 = None\n            \n    if data2 is not None:\n        if isinstance(data2, pd.Series):\n            cdf2 = data2.copy().to_frame()\n        else:\n            cdf2 = data2.copy()\n    else:\n        cdf2 = None\n    \n    if strip==True:\n        for df in [cdf1, cdf2]:\n            if df is not None:\n                for c in df:\n                    df[c] = df[c].apply(lambda x: x.strip() if isinstance(x, str) else x)\n\n    \n    if ((criteria1==None) & (criteria2==None)):\n        tempdf = tempdf1.copy()\n        case = 1\n    elif criteria1==None:\n        tempdf = pd.concat([cdf2, tempdf1], axis=1)\n        case = 2\n    elif criteria2==None:\n        tempdf = pd.concat([cdf1, tempdf1], axis=1)\n        case = 2\n    else:\n        tempdf = pd.concat([cdf1, cdf2, tempdf1], axis=1)\n        case = 3\n        \n    if case == 3:\n        if ((otherthan1 is True) and (otherthan2 is True)):\n            if contains==True:\n                tempdf = tempdf[~(tempdf.iloc[:,0].str.contains(r''+criteria1, regex=True, na=False)) &\n                            ~(tempdf.iloc[:,1].str.contains(r''+criteria2, regex=True, na=False))]\n            else:\n                tempdf = tempdf[(tempdf.iloc[:,0] != criteria1) & (tempdf.iloc[:,1] != criteria2)]\n        else:\n            if contains==True:\n                tempdf = tempdf[(tempdf.iloc[:,0].str.contains(r''+criteria1, regex=True, na=False)) &\n                            (tempdf.iloc[:,1].str.contains(r''+criteria2, regex=True, na=False))]\n            else:\n                tempdf = tempdf[(tempdf.iloc[:,0] == criteria1) & (tempdf.iloc[:,1] == criteria2)]\n        tempdf.drop(tempdf.columns[[0,1]], axis=1, inplace=True)\n            \n\n    if case == 2:\n        crit = criteria2 if criteria1==None else criteria1\n        otherthan = otherthan2 if criteria1==None else otherthan1\n        if otherthan:\n            if contains==True:\n                tempdf = tempdf[~tempdf.iloc[:,0].str.contains(r''+crit, regex=True, na=False)]\n            else:\n                tempdf = tempdf[tempdf.iloc[:,0] != crit]\n        else:\n            if contains==True:\n                tempdf = tempdf[tempdf.iloc[:,0].str.contains(r''+crit, regex=True, na=False)]\n            else:\n                tempdf = tempdf[tempdf.iloc[:,0] == crit]\n        tempdf.drop(tempdf.columns[0], axis=1, inplace=True)\n            \n\n    if len(data.shape) > 1:\n        if data.shape[1] > 1:\n            tempdf = tempdf.dropna(how='all')\n            return tempdf\n\n    return tempdf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to create frequency distribution on upto 2 conditions and with overall weights of the criteria column\ndef fd2(data, data1=None, criteria1=None, data2=None, criteria2=None, title='criteria', \n        strip=False, contains=False):\n    \"\"\"Create distribution of a variable based on 2 conditions and get proportion of criteria population.\"\"\"\n    tempdf1 = data.copy()\n    if data1 is not None:\n        if isinstance(data1, pd.Series):\n            cdf1 = data1.copy().to_frame()\n        else:\n            cdf1 = data1.copy()\n    else:\n        cdf1 = None\n            \n    if data2 is not None:\n        if isinstance(data2, pd.Series):\n            cdf2 = data2.copy().to_frame()\n        else:\n            cdf2 = data2.copy()\n    else:\n        cdf2 = None\n    \n    if len(data.shape) > 1:\n        if data.shape[1] > 1:\n            tempdf1.columns = tempdf1.mode().values.tolist()[0]\n            full_fd = tempdf1.count()\n        else:\n            full_fd = tempdf1.value_counts().reset_index()\n            full_fd.columns = ['criteria','values']\n            full_fd = full_fd.set_index('criteria')\n    else:\n        full_fd = tempdf1.value_counts()\n        full_fd.columns = ['criteria','values']\n        full_fd = full_fd.set_index('criteria')\n\n    if strip==True:\n        for df in [cdf1, cdf2]:\n            if df is not None:\n                for c in df:\n                    df[c] = df[c].apply(lambda x: x.strip() if isinstance(x, str) else x)\n\n    \n    if ((criteria1==None) & (criteria2==None)):\n        tempdf = tempdf1.copy()\n        case = 1\n    elif criteria1==None:\n        tempdf = pd.concat([cdf2, tempdf1], axis=1)\n        case = 2\n    elif criteria2==None:\n        tempdf = pd.concat([cdf1, tempdf1], axis=1)\n        case = 2\n    else:\n        tempdf = pd.concat([cdf1, cdf2, tempdf1], axis=1)\n        case = 3\n    \n    if case == 3:\n        if contains==True:\n            tempdf = tempdf[(tempdf.iloc[:,0].str.contains(r''+criteria1, regex=True, na=False)) &\n                        (tempdf.iloc[:,1].str.contains(r''+criteria2, regex=True, na=False))]\n        else:\n            tempdf = tempdf[(tempdf.iloc[:,0] == criteria1) & (tempdf.iloc[:,1] == criteria2)]\n        tempdf.drop(tempdf.columns[[0,1]], axis=1, inplace=True)\n          \n    if case == 2:\n        crit = criteria2 if criteria1==None else criteria1\n        if contains==True:\n            tempdf = tempdf[tempdf.iloc[:,0].str.contains(r''+crit, regex=True, na=False)]\n        else:\n            tempdf = tempdf[tempdf.iloc[:,0] == crit]\n        tempdf.drop(tempdf.columns[0], axis=1, inplace=True)\n\n    if len(data.shape) > 1:\n        if data.shape[1] > 1:\n            tempdf = tempdf.dropna(how='all')\n            n = tempdf.shape[0]\n            fd = tempdf.count().reset_index()\n            fd.columns = [title, 'freq']\n            fd['proportion'] = round(fd['freq']*100/n, 2)\n            fd['criteria_weight'] = round(fd['freq']/fd.iloc[:,0].map(full_fd), 4)*100\n            return fd\n\n    fd = tempdf.value_counts().reset_index()\n    fd.columns = [title, 'freq']\n    fd['proportion'] = (tempdf.value_counts(normalize=True).values*100).round(2)\n    fd['criteria_weight'] = round(fd['freq']/fd.iloc[:,0].map(full_fd['values']), 4)*100\n    return fd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"## 4. Questions in the survey"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save questions separately\nqtext = [i+' - '+j for i,j in zip([re.split('_Part|_OTHER',c)[0] for c in dfo.columns], dfo.iloc[0,:])]\n\n# Generate unique question list\nqtext2 = [re.split('\\(Select all that apply\\)|- Selected Choice', q)[0].strip() for q in qtext]\nques = []\n[ques.append(q) for q in qtext2 if q not in ques]\n\nprint(len(ques))\nques","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dictionary of questions and their answers\nqans = {}\nqn = [re.split('_Part|_OTHER',c)[0] for c in dfo.columns]\nkeys = []\n[keys.append(q) for q in qn if q not in keys]\nfor k in keys:\n    if k in ['Q1','Q2','Q3']:\n        qans[k] = list(dfo[k].unique())\n    else:\n        if len([c for c in dfo.columns if c.startswith(k)]) == 1:\n            qans[k] = list(dfo[k].unique())\n        else:\n            quest = []\n            [quest.append(dfo.loc[0,c]) if len(quest) == 0 else None for c in dfo.columns if c.startswith(k)]\n            quest[0] = re.split('\\(Select all that apply\\)|- Selected Choice', quest[0])[0]\n            vals = [dfo[c].mode().values[0] for c in dfo.columns if c.startswith(k)]\n            quest = quest+vals\n            qans[k] = list(quest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Single-answer question\nqans['Q5']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Multi-answer question\nqans['Q7']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Check for missing data\n**Note:** Because of the way this dataset is structured, we can expect plenty of missing values in most of the columns. But we will still perform this check for the columns that ideally should not have any missing values."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Proportion of missing values in columns\npd.set_option('display.max_rows', dfo.shape[1])\n(dfo.loc[:,'Q1':'Q6'].isna().sum()*100 / dfo.shape[0]).round(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"## 5. Data preprocessing"},{"metadata":{},"cell_type":"markdown","source":"##### Remove non-essential data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove the row with question text\ndf = dfo.drop(dfo.index[0])\ndf.head(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Create subsets\nWe will create subsets for each question as a dictionary, where all the relevant columns for the question will be included as a list in value.\n\n<i>Notebook referenced : 1</i>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# List of unique questions\nqnums = list(dict.fromkeys([q.split('_')[0] for q in df.columns]))\nprint(qnums)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# Create dictionary\nqd = {}\nfor q in qnums:\n    if q in ['Q1','Q2','Q3']:    # not used c.startswith to prevent clubbing of columns Q10+, Q20 etc.\n        qd[q] = df[[q]]\n    else:\n        qd[q] = df[[c for c in df.columns if c.startswith(q)]]\n\n# Notebook referenced : 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"## 6. Question analysis"},{"metadata":{},"cell_type":"markdown","source":"### Q1 - Age"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Age distribution\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    fxn()\n    \n    fig, ax1 = plt.subplots(figsize=(13,5), facecolor='w')\n    q1_fd = fd_saq(qd['Q1'], 'Age groups', ordered=False)\n    labels = q1_fd['proportion']\n    ax1.bar(q1_fd['Age groups'], q1_fd['freq'], width=0.5, color='#37659E', edgecolor='teal', \n            linewidth=0.3)\n\n    for i in q1_fd.index:\n        ax1.annotate(f\"{labels[i]}%\", xy=(i, q1_fd['freq'][i] + 100), va='center',\n                    ha='center', fontfamily='serif', fontsize=9, color='#444444')\n\n    fig.text(0.40,0.95, 'Age Distribution', fontfamily='serif', fontweight='bold', fontsize=12)\n    ax1.set_ylim(0,4200)\n    ax1.set_xticklabels(q1_fd['Age groups'], fontfamily='serif', fontsize=9)\n    ax1.set_yticklabels(np.arange(0,4001,500),fontfamily='serif', fontsize=9)\n#     ax1.grid(axis='y', linestyle='-', alpha=0.2)\n    for s in ['top', 'left', 'right']:\n        ax1.spines[s].set_visible(False)\n\n# Notebook referenced : 2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<a id='obs-q1'></a>\n<b>Observations:</b><br>\n    - Most of the survey participants belong to younger age groups with 70% aged below 35.\n</div>"},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q2 - Gender"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gender frequency distribution\nq2_fd = fd_saq(qd['Q2'], 'gender')\nq2_fd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Pie chart"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Pie chart\nfig = px.pie(q2_fd, values=q2_fd.freq, names=q2_fd.gender, title='Gender Distribution',\n             color_discrete_sequence=px.colors.sequential.RdBu_r,\n             hover_data=['proportion'], labels={'proportion':'proportion'})\nfig.update_traces(textposition='inside', textinfo='percent+label')\nfig.update_layout(autosize=False, width=600, height=400)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<a id='obs-q2.1'></a>\n<b>Observations:</b><br>\n    - The gender ratio observed here corroborates the perception of under-representation of women in STEM domains.\n</div>"},{"metadata":{},"cell_type":"markdown","source":"### Gender-Age Distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create age subset for Man & Woman\ndf_ag = df[['Q1','Q2']].copy()\ndf_ag.loc[~df_ag.Q2.isin(['Man','Woman']),'Q2'] = 'Others'\nq1q2 = df_ag[df_ag['Q2'] != 'Others'].groupby(['Q2'])['Q1'].value_counts().unstack().sort_index()\nman = q1q2.loc['Man']\nwoman = q1q2.loc['Woman']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stacked bar chart\nfig, ax = plt.subplots(1,1,figsize=(13,5), facecolor='w')\nax.bar(man.index, man, width=0.5, label='Males', color='#C1D3E9')\nax.bar(woman.index, -woman, width=0.5, label='Females', color='#37659E')\nax.set_ylim(-1200,3500)\n\nfor i in man.index:\n    ax.annotate(f\"{man[i]}\", xy=(i,man[i]+100), va='center', ha='center', fontfamily='serif',\n                fontweight='light', fontsize=9, color='#444444')\n    \nfor i in woman.index:\n    ax.annotate(f\"{woman[i]}\", xy=(i,-woman[i]-100), va='center', ha='center', fontfamily='serif',\n                fontweight='light', fontsize=9, color='#444444')\n\nfor m in ['top','bottom','left','right']:\n    ax.spines[m].set_visible(False)\n\nfig.text(0.40,0.95, 'Gender-Age Distribution', fontfamily='serif', fontweight='bold', fontsize=12)\nax.set_yticks([])\nax.legend()\nplt.show()\n\n# Notebook referenced : 2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<a id='obs-q1q2'></a>\n<b>Observations:</b><br>\n    - Considering the ratios of no. of men per woman in the sample, the ratios get increasingly larger (> 4.3) in the 30+ age groups, whereas in the younger age groups (18-30), the ratios range between 3.2 to 3.8, which is less than the overall ratio (≈ 4).<br>\nThis augurs well for the correction of gender imbalance in this domain.\n</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"man/woman","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q3 - Country of residence"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Frequency Distribution of countries\nq3_fd = fd_saq(df['Q3'], 'country')\n\n# No. of countries\nprint(f\"Unique: {df['Q3'].nunique()}\")\n\n# Frequency Distribution of countries with respondents >300 (1.5% of sample)\nq3_fd[q3_fd['freq']>300]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Choropleth map\nfig = px.choropleth(q3_fd, locations='country', color='freq', locationmode='country names',\n                    color_continuous_scale='thermal', range_color = [0, 900])\nfig.show()\n\n# Notebook referenced : 3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<a id='obs-q3.1'></a>\n<b>Observations:</b><br>\n    - The survey sample has respondents from 54+ countries.<br>\n    - India and USA are the largest contributors to the sample, with every other country constituting < 4% of the sample.\n</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Subsets of data for the 2 top countries by respondents\ndfi = pd.DataFrame(df[df['Q3']=='India'])\ndfu = pd.DataFrame(df[df['Q3']=='United States of America'])\nprint(dfi.shape, dfu.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Region-wise Distribution"},{"metadata":{},"cell_type":"markdown","source":"###### Map region to country"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import country continent dataset\n# source : https://www.kaggle.com/statchaitya/country-to-continent\ncontinents = pd.read_csv('/kaggle/input/countrydataset/countryContinent.csv', encoding = \"ISO-8859-1\")\ncontinents.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sub regions\nprint(continents['sub_region'].nunique())\nprint(continents['sub_region'].unique())\n\n# Region dictionary\nregion_dict = {k:v for k,v in zip(continents['country'], continents['sub_region'])}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create separate dataframe\nq3_cont = pd.DataFrame({'country':df['Q3']})\n# Map continents\nq3_cont['continent'] = q3_cont['country'].map(continents.set_index('country')['continent'])\n# Map region\nq3_cont['sub_region'] = q3_cont['country'].map(region_dict)\nq3_cont.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace longer/obscure names with shorter/familiar names\ncountry_names_dict = {'United States of America':'USA',\n                      'United Kingdom of Great Britain and Northern Ireland':'UK',\n                      'Iran, Islamic Republic of...':'Iran',\n                      'Republic of Korea':'North Korea'}\n\nq3_cont['country'] = q3_cont['country'].replace(country_names_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Unmapped countries\nprint(q3_cont.isna().sum())\nunmapped = q3_cont['country'][q3_cont['continent'].isna()].unique().tolist()\nunmapped","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Track unmapped countries in continent data\ncontinents[continents['country'].str.contains(r'Russia|Korea|Taiwan|Iran')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Continent / Sub-region dict for unmapped countries\nregion_dict2 = {'Russia':['Europe','Eastern Europe'], 'South Korea':['Asia','Easter Asia'],\n                'Taiwan':['Asia','Eastern Asia'], 'Iran':['Asia','Southern Asia'],\n                'North Korea':['Asia','Eastern Asia'], 'Other':['Other','Other']}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Insert data for unmapped countries using region dict\nfor r in q3_cont[q3_cont['continent'].isna()].index:\n    q3_cont.loc[r, 'continent'] = region_dict2[q3_cont.loc[r,'country']][0]\n    q3_cont.loc[r, 'sub_region'] = region_dict2[q3_cont.loc[r,'country']][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Unmapped countries\nprint(q3_cont.isna().sum())\nq3_cont['country'][q3_cont['continent'].isna()].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confirm replacement\nq3_cont[q3_cont['country'].str.contains('Taiwan', na=False)].head(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Region-wise frequency distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Region-wise frequency distribution\nq3_cont_fd = fd_saq(q3_cont['sub_region'], title='sub_region')\n\n# Plotly bar graph\nfig = px.bar(q3_cont_fd, x='sub_region',y='freq', text='proportion', height=500, \n             title='Region-wise Distribution')\nfig.update_layout({'plot_bgcolor': 'rgba(0, 0, 0, 0)'})\nfig.update_traces(marker=dict(color='#37659E', opacity=1, line=dict(color='teal', width=0.3)))\nfig.update_traces(texttemplate='%{text:i}%', textposition='outside')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<a id='obs-q3.2'></a>\n<b>Observations:</b><br>\n    - Regions of Southern Asia (1.953b), Northern America (0.37b), and Eastern Asia (1.681b) make up 52% of the sample and are home to 51% of the world population (7.842b) as well.<br>\n    \n<i>Population figures (as of Jan 2021):</i>&ensp;\n    <a href=\"https://www.worldometers.info/world-population/southern-asia-population/\">Souther Asia</a>,&nbsp;\n    <a href=\"https://www.worldometers.info/world-population/northern-america-population/\">Northern America Asia</a>,&nbsp;\n    <a href=\"https://www.worldometers.info/world-population/eastern-asia-population/\">East Asia</a>,&nbsp;\n    <a href=\"https://www.worldometers.info/world-population/\">World</a>\n</div>"},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q4 - Education"},{"metadata":{"trusted":true},"cell_type":"code","source":"qans['Q4']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting custom order\nQ4_ans = [\"I prefer not to answer\",\"No formal education past high school\",\n          \"Some college/university study without earning a bachelor’s degree\",\n          \"Professional degree\", \"Bachelor’s degree\",\"Master’s degree\",\"Doctoral degree\"]\nQ4_ans_r = Q4_ans[::-1]\n\nq4_fd = fd_saq(df['Q4'],'education').set_index('education').loc[Q4_ans].reset_index()\nq4i_fd = fd_saq(df['Q4'],'education').set_index('education').loc[Q4_ans].reset_index()\nq4u_fd = fd_saq(dfu['Q4'],'education').set_index('education').loc[Q4_ans].reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar plot\nfig = plt.figure(figsize=(6,6), facecolor='w') # create figure\ngs = fig.add_gridspec(2, 2)\ngs.update(wspace=0.3, hspace=0.3)\nax0 = fig.add_subplot(gs[0, 0:2])\nax1 = fig.add_subplot(gs[1, 0], ylim=(0, 3500)) # create axes\nax2 = fig.add_subplot(gs[1, 1]) # create axes\n\nxlbl = q4_fd['education'].values.tolist()\n\nax0.bar(q4_fd['education'], q4_fd['freq'], width=0.5, label=xlbl, \n        color=sns.color_palette('mako',len(q4_fd)))\nax1.bar(q4i_fd['education'], q4i_fd['freq'], width=0.5, label=xlbl, \n        color=sns.color_palette('mako',len(q4_fd)))\nax2.bar(q4u_fd['education'], q4u_fd['freq'], width=0.5, label=xlbl, \n        color=sns.color_palette('mako',len(q4_fd)))\n\nclrs = dict(zip(q4_fd['education'].values.tolist(), sns.color_palette('mako',len(q4_fd))))\nlabels = list(clrs.keys())\nhandles = [plt.Rectangle((0,0),1,1, color=clrs[label]) for label in labels]\nlabels = [str(i)+' '+l for i,l in zip(range(1,len(q4_fd)+1), labels)]\nlabels = ['\\n   '.join(wrap(l, 30)) for l in labels]\nax0.legend(handles, labels, loc=0, prop={'size':7}, frameon=False, \n           bbox_to_anchor=(1.1, 0.5), borderaxespad=0)\n# ax2.legend(handles, labels, loc=0, prop={'size':7}, frameon=False, \n#            bbox_to_anchor=(1.45, 1), borderaxespad=0)\n\nfig.text(0.31,0.95, 'Maximum Level of Education', fontfamily='serif', fontweight='bold',fontsize=10)\nax0.text(ax0.get_xlim()[1]*0.4, ax0.get_ylim()[1]*1.03,'World', fontfamily='serif', fontsize=9)\nax1.text(ax1.get_xlim()[1]*0.4, ax1.get_ylim()[1]*1.03,'India', fontfamily='serif', fontsize=9)\nax2.text(ax2.get_xlim()[1]*0.4, ax2.get_ylim()[1]*1.03,'USA*', fontfamily='serif', fontsize=9)\nfig.text(0.2,0.07, '*Please note that the scale of plots for USA is different from India', \n         fontfamily='serif',fontsize=7)\n\nfor s in [\"top\",\"right\",\"left\"]:\n    ax1.spines[s].set_visible(False)\n    ax2.spines[s].set_visible(False)\n    ax0.spines[s].set_visible(False)\n\n\nfor f in [ax0,ax1,ax2]:\n    f.set_xticklabels(range(1,len(q4_fd)+1), fontsize=6)\n    f.yaxis.set_tick_params(labelsize=6)\n    f.tick_params(bottom=False)\n\n# Notebook referenced : 4","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<a id='obs-q4'></a>\n<b>Observations:</b><br>\n    - Participants having (or planning to complete) Master's are the largest group.<br>\n    - The distributions for India and USA are noticably different.<br><br> \n    <b>India</b><br>\n    - India's overall representation in the survey sample is 29%. <br>\n    - It's considerably under-representated in the educational categories of:<br>\n    &emsp;• No formal education past high school : 12% (WN 3)<br>\n    &emsp;• Some college/university study without earning a Bachelor's : 19% (WN 4)<br>\n    &emsp;• Doctoral degree : 12% (WN 5)<br>\n    - India has a larger proportion of Bachelor's (43%) than the overall proportion (36%). (WN 6)<br>\n    - In fact, the proportion of Bachelor's drops by 7 percentage points (or 7pp or 7%p) to 28.5%, if the  sample's from India are not taken into account. (WN 7)<br>\n    - And the proportion of Master's and Doctoral degree's increases by approx. 3%p each. (WN 7)<br><br>\n    <b>USA</b><br>\n    - USA's overall representation in the survey sample is 11%. <br>\n    - It has a significantly larger representation in the eduacational category of Doctoral (18%) and a  lesser representation in Bachelor's (8%), High School (5%) and Professionl (6%). (WN 8)<br>\n\n<i><b>Note: </b> percentage points have been denoted by %p.</i><br><br>\n<i>Workings below</i>\n</div>"},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"##### '################ workings"},{"metadata":{"trusted":true},"cell_type":"code","source":"# WN 1 - Country-wise survey distribution\nq3_fd.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# WN 2 - Distribution of Education\nq4_fd.iloc[::-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# WN 3 - Country-wise distribution of 'No formal education past high school'\nfd(qd['Q3'], qd['Q4'], 'high', contains=True).head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# WN 4 - Country-wise distribution of 'Some college .... without Bachelor's'\nfd(qd['Q3'], qd['Q4'], 'without', contains=True).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# WN 5 - Country-wise distribution of 'Doctoral degree'\nfd(qd['Q3'], qd['Q4'], \"Doctoral\", contains=True).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# WN 6 - Country-wise distribution of 'Bachelor's degree'\nfd(qd['Q3'], qd['Q4'], \"Bachelor\", contains=True).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# WN 7 - Educational distribution without India\ncustom_sort2(fd(qd['Q4'], qd['Q3'],'India', otherthan1=True), 'criteria', Q4_ans_r)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Country-wise distribution of 'Master's degree'\nfd(qd['Q3'], qd['Q4'], 'Master', contains=True).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# WN 8 - Educational Distribution - USA (with sample weights of classes in criteria)\ncustom_sort2(fd2(qd['Q4'], qd['Q3'], 'United States of America'), 'criteria', ordered_list=Q4_ans_r)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# WN 9 - Educational distribution - India\ncustom_sort2(fd(qd['Q4'], qd['Q3'],'India'), 'criteria', Q4_ans_r)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Difference in internal educational distribution of India vis-a-vis USA\ndiff_ind_usa(qd['Q4'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### #'################ workings'"},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q5 - Job role"},{"metadata":{"trusted":true},"cell_type":"code","source":"Q5_ans = ['Student','Currently not employed','Other','Business Analyst','Data Analyst',\n          'Product/Project Manager','Software Engineer','DBA/Database Engineer','Data Engineer',\n          'Research Scientist','Machine Learning Engineer','Statistician','Data Scientist']\nQ5_ans_r = Q5_ans[::-1]\nq5_fd = fd_saq(df['Q5'],'job_role').set_index('job_role').loc[Q5_ans].reset_index()\nq5i_fd = fd_saq(dfi['Q5'],'job_role').set_index('job_role').loc[Q5_ans].reset_index()\nq5u_fd = fd_saq(dfu['Q5'],'job_role').set_index('job_role').loc[Q5_ans].reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar plot\nfig = plt.figure(figsize=(6,6), facecolor='w')\ngs = fig.add_gridspec(2, 2)\ngs.update(wspace=0.3, hspace=0.3)\nax0 = fig.add_subplot(gs[0, 0:2])\nax1 = fig.add_subplot(gs[1, 0])\nax2 = fig.add_subplot(gs[1, 1])\n\nxlbl = q5_fd['job_role'].values.tolist()\n\nax0.bar(q5_fd['job_role'], q5_fd['freq'], width=0.5, label=xlbl, \n        color=sns.color_palette('mako',len(q5_fd)))\nax1.bar(q5i_fd['job_role'], q5i_fd['freq'], width=0.5, label=xlbl, \n        color=sns.color_palette('mako',len(q5_fd)))\nax2.bar(q5u_fd['job_role'], q5u_fd['freq'], width=0.5, label=xlbl, \n        color=sns.color_palette('mako',len(q5_fd)))\n\nclrs = dict(zip(q5_fd['job_role'].values.tolist(), sns.color_palette('mako',len(q5_fd))))\nlabels = list(clrs.keys())\nhandles = [plt.Rectangle((0,0),1,1, color=clrs[label]) for label in labels]\nlabels = [str(i)+' '+l for i,l in zip(range(1,len(q5_fd)+1), labels)]\nlabels = ['\\n'.join(wrap(l, 30)) for l in labels]\nax0.legend(handles, labels, loc=0, prop={'size':7}, frameon=False, \n           bbox_to_anchor=(1.1, 0.5), borderaxespad=0)\n\nfig.text(0.44,0.95, 'Job Role', fontfamily='serif', fontweight='bold',fontsize=10)\nax0.text(ax0.get_xlim()[1]*0.4, ax0.get_ylim()[1]*1.03,'World', fontfamily='serif', fontsize=9)\nax1.text(ax1.get_xlim()[1]*0.4, ax1.get_ylim()[1],'India', fontfamily='serif', fontsize=9)\nax2.text(ax2.get_xlim()[1]*0.4, ax2.get_ylim()[1],'USA*', fontfamily='serif', fontsize=9)\nfig.text(0.2,0.05, '*Please note that the scale of plots for USA is different from India', \n         fontfamily='serif',fontsize=7)\n\nfor s in [\"top\",\"right\",\"left\"]:\n    ax1.spines[s].set_visible(False)\n    ax2.spines[s].set_visible(False)\n    ax0.spines[s].set_visible(False)\n\nfor f in [ax0,ax1,ax2]:\n    f.set_xticklabels(range(1,len(q5_fd)+1), fontsize=6)\n    f.yaxis.set_tick_params(labelsize=6)\n    f.tick_params(bottom=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of Job-roles within sample (Overall, India, USA)\nbuild_graph(qd['Q5'], hgt=500, graph_title='Job-Role distribution')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## India - Differential proportion compared with overall proportion of 0.292\ndiff = ((q5i_fd['freq']/q5_fd['freq']) - 0.292).round(4)*100\nclrs = list(np.where(diff.values < 0, '#B51A62', '#37659E'))\n\n# Plot\nfig = go.Figure(go.Bar(x=q5_fd['job_role'], y=diff.values, text=diff.values.round(3), \n                       marker_color=clrs))\nfig.update_layout(title={'text':'India - Change in Job Role proportion compared with'+\n                        ' overall sample proportion (29.2%)<br>(in percentage points (%p))', \n                         'x':0.5, 'xanchor':'center'}, plot_bgcolor='#fff')\nfig.update_traces(texttemplate='%{text:i} %p', textposition='outside', textfont_size=9, \n                  textfont_color='black')\nfig.update_xaxes(categoryorder='array', categoryarray=q5i_fd['job_role'], visible=True)\nfig.show()\n\n\n## USA - Differential proportion compared with overall proportion of 0.112\ndiff = ((q5u_fd['freq']/q5_fd['freq']) - 0.112).round(4)*100\nclrs = list(np.where(diff.values < 0, '#B51A62', '#37659E'))\n\n# Plot\nfig = go.Figure(go.Bar(x=q5_fd['job_role'], y=diff.values, text=diff.values.round(3), \n                       marker_color=clrs))\nfig.update_layout(title={'text':'USA - Change in Job Role proportion compared with'+\n                        ' Overall sample proportion (11.2%)<br>(in percentage points (%p))', \n                         'x':0.5, 'xanchor':'center'}, plot_bgcolor='#fff')\nfig.update_traces(texttemplate='%{text:i} %p', textposition='outside', textfont_size=9, \n                  textfont_color='black')\nfig.update_xaxes(categoryorder='array', categoryarray=q5i_fd['job_role'])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<a id='obs-q5'></a>\n<b>Observations:</b><br>\n    - Students comprise the largest group in the survey sample (27%) and Data Scientists the 2nd largest (14%).<br>\n    - In this criteria, the difference between the distributions for India and USA is even more evident.<br><br> \n    <b>India</b><br>\n    - India's overall proportion in the survey sample is 29%. <br>\n    - India's proportion significantly changes from its  overall proportion in the roles of:<br>\n    &emsp; <i>Significantly more:</i><br>\n    &emsp;• Student : 43%<br>\n    &emsp; <i>Significantly less:</i><br>\n    &emsp;• Statistician : 12%<br>\n    &emsp;• Research Scientist : 12%<br>\n    &emsp;• Data Engineer : 11%<br>\n    &emsp;• Product/Project Manager : 11%<br><br>\n    <b>USA</b><br>\n    - USA's overall proportion in the survey sample is 11%. <br>\n    - USA's proportion is significantly different in the following roles:<br>\n    &emsp; <i>Significantly more:</i><br>\n    &emsp;• Product/Project Manager : 17%<br>\n    &emsp;• Data Engineer : 16%<br>\n    &emsp; <i>Significantly less:</i><br>\n    &emsp;• Student : 7%<br>\n\n<i>Workings below</i>\n</div>"},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"##### #'################ workings"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Frequency distribution - Students\nfd(qd['Q3'], qd['Q5'], 'Student').head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Frequency distribution - Statistician\nfd(qd['Q3'], qd['Q5'], 'Statistician').head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Frequency distribution - Research Scientist\nfd(qd['Q3'], qd['Q5'], 'Research Scientist').head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Frequency distribution - Product/Project Manager\nfd(qd['Q3'], qd['Q5'], 'Product/Project Manager').head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Frequency distribution - Data Engineer\nfd(qd['Q3'], qd['Q5'], 'Data Engineer').head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### #'################ workings'"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q6 - Programming experience"},{"metadata":{"trusted":true},"cell_type":"code","source":"Q6_ans = ['I have never written code','< 1 years','1-2 years','3-5 years','5-10 years',\n          '10-20 years','20+ years']\nQ6_ans_r = Q6_ans[::-1]\nq6_fd = fd_saq(df['Q6'],'prog_exp').set_index('prog_exp').loc[Q6_ans].reset_index()\nq6i_fd = fd_saq(dfi['Q6'],'prog_exp').set_index('prog_exp').loc[Q6_ans].reset_index()\nq6u_fd = fd_saq(dfu['Q6'],'prog_exp').set_index('prog_exp').loc[Q6_ans].reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar plot\nfig = plt.figure(figsize=(6,6), facecolor='w')\ngs = fig.add_gridspec(2, 2)\ngs.update(wspace=0.3, hspace=0.35)\nax0 = fig.add_subplot(gs[0, 0:2])\nax1 = fig.add_subplot(gs[1, 0])\nax2 = fig.add_subplot(gs[1, 1])\n\nxlbl = q6_fd['prog_exp'].values.tolist()\n\nax0.bar(q6_fd['prog_exp'], q6_fd['freq'], width=0.5, label=xlbl, \n        color=sns.color_palette('mako',len(q6_fd)))\nax1.bar(q6i_fd['prog_exp'], q6i_fd['freq'], width=0.5, label=xlbl, \n        color=sns.color_palette('mako',len(q6_fd)))\nax2.bar(q6u_fd['prog_exp'], q6u_fd['freq'], width=0.5, label=xlbl, \n        color=sns.color_palette('mako',len(q6_fd)))\n\nclrs = dict(zip(q6_fd['prog_exp'].values.tolist(), sns.color_palette('mako',len(q6_fd))))\nlabels = list(clrs.keys())\nhandles = [plt.Rectangle((0,0),1,1, color=clrs[label]) for label in labels]\nax0.legend(handles, labels, loc=0, prop={'size':7}, frameon=False, \n           bbox_to_anchor=(1.1, 0.5), borderaxespad=0)\n\nfig.text(0.35,0.95, 'Programming Experience', fontfamily='serif', fontweight='bold',fontsize=10)\nax0.text(ax0.get_xlim()[1]*0.4, ax0.get_ylim()[1]*1.03,'World', fontfamily='serif', fontsize=9)\nax1.text(ax1.get_xlim()[1]*0.4, ax1.get_ylim()[1],'India', fontfamily='serif', fontsize=9)\nax2.text(ax2.get_xlim()[1]*0.4, ax2.get_ylim()[1],'USA*', fontfamily='serif', fontsize=9)\nfig.text(0.2,0.02, '*Please note that the scale of plots for USA is different from India', \n         fontfamily='serif',fontsize=7)\n\nfor s in [\"top\",\"right\",\"left\"]:\n    ax1.spines[s].set_visible(False)\n    ax2.spines[s].set_visible(False)\n    ax0.spines[s].set_visible(False)\n\nfor f in [ax0,ax1,ax2]:\n    f.set_xticklabels(['Never']+labels[1:], fontsize=6, rotation=45)\n    f.yaxis.set_tick_params(labelsize=6)\n    f.tick_params(bottom=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<a id='obs-q6'></a>\n<b>Observations:</b><br>\n    - Around 70% of the respondants have programming experience of &lt; 5 years.<br>\n    - Shape of the distribution for India is denser towards classes with programming experience &lt;5 yrs, with approx. 84% respondents falling within those classes.<br>\n    - Shape of the distribution for USA is denser towards classes with programming experience &gt;3 yrs, with approx. 73% respondents falling within those classes.<br>\n    - Looking at the differential proportion graphs below, we can see that: <br>\n    &emsp;• India has very few respondents with 10+ yrs expericence<br>\n    &emsp;• USA has significantly more respondents with 10+ yrs expericence<br>\n\n<i>Workings below</i>\n</div>"},{"metadata":{},"cell_type":"markdown","source":"##### '################ workings"},{"metadata":{"trusted":true},"cell_type":"code","source":"a,b = differential_graph(qd['Q6'], order=Q6_ans)\na.update_layout(autosize=False, width=850, height=450)\nb.update_layout(autosize=False, width=850, height=450)\na.show()\nb.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Frequency distribution - World\nq6_fd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Frequency distribution - India\nq6i_fd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Frequency distribution - USA\nq6u_fd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### '################ workings'"},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q4 & Q5 - Education & Job role"},{"metadata":{},"cell_type":"markdown","source":"##### a) Heatmap"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Heatmap\nfig = px.density_heatmap(df, x='Q5',y='Q4', color_continuous_scale='Blues',\n                         category_orders={'Q5':Q5_ans, 'Q4':Q4_ans_r})\nfig.update_layout(title={'text':'Education & Job Role', 'x':0.68, 'xanchor': 'center'})\nfig.update_layout(autosize=False, width=990, height=500)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### b) Stacked Bar Chart"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shortened names\nrole_dict = {'Doctoral degree': 'Doctoral degree',\n             'Master’s degree': 'Master’s degree',\n             'Bachelor’s degree': 'Bachelor’s degree',\n             'Professional degree': 'Professional degree',\n             'Some college/university study without earning a bachelor’s degree': 'Study without degree',\n             'No formal education past high school': 'High school',\n             'I prefer not to answer': 'No answer'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Percentage Distribution\nedu_role1 = pd.DataFrame()\nedu_role1['Overall'] = df['Q4'].value_counts(normalize=True, sort=False)\nfor role in Q5_ans:\n    edu_role1[role] = df[df.Q5==role]['Q4'].value_counts(normalize=True, sort=False)\nedu_role = edu_role1.reindex(Q4_ans_r, copy=True)\nedu_role.round(4)*100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stacked Bar Chart\nfig = go.Figure()\nclrs = ['rgba'+str(clr) for clr in sns.color_palette('ocean_r',len(edu_role.index))]\nclrs1 = sns.color_palette('ocean_r', len(edu_role.index))\n\n# Subplot for color key\ncolorscale = ff.create_annotated_heatmap(z=[[1,2,3,4,5,6,7]],\n                annotation_text=[[\"<span style='font-size:12px; font-family: Tahoma'>\"+text+\"</span>\" \n                    for text in [re.sub('\\n','<br>',fill(role_dict[w],14)) for w in edu_role.index]]],\n                colorscale=clrs,\n                font_colors = ['white','white','white','white','white','white','white'],\n                xgap = 0.05, showscale = False)\n\ntrcs = ['trace'+str(i) for i in range(1,len(edu_role.index)+1)]\ni = 0\nfor trc in trcs:\n    globals()[trc] = go.Bar(y=edu_role.columns, x=edu_role.iloc[i,:], orientation=\"h\",\n                            name=edu_role.index[i], marker=dict(color=clrs[i]))\n    i += 1\n\nfig = subplots.make_subplots(rows=2, cols=1, shared_yaxes=True, shared_xaxes=False, \n                             horizontal_spacing = 0, vertical_spacing = 0.01, \n                             row_heights=[0.18, 0.82])\nfig.append_trace(colorscale.data[0],1,1)\n\nfor trc in trcs:\n    fig.append_trace(globals()[trc],2,1)\n\norder = edu_role.loc['Doctoral degree'].sort_values(ascending=True).keys().tolist()\norder.remove('Overall')\nfig.update_layout(\n    title={'text':'Education & Job Role - Percentage Distribution', 'x':0.57,'xanchor': 'center'},\n    yaxis2={'categoryorder':'array', 'categoryarray':order+['Overall']},\n    barmode=\"relative\", bargap = 0.05,\n    plot_bgcolor = '#fff',\n    xaxis = dict(title=\"<span style='font-size:13px; font-family:Helvetica'><b>Color Keys: </b>Educational qualifications by job role</span>\", \n                 side=\"top\",title_standoff=0, domain=[0,0.95], showticklabels = False),\n    yaxis = dict(domain=[0.85,1], showticklabels = False),\n    xaxis2 = dict(domain=[0,1], tickformat = '%'),\n    legend=dict(orientation=\"h\"), showlegend=False,\n    autosize=False, width=850, height=600,\n    margin=dict(l=0, r=0, b=0, pad=3))\n\n# Workaround to show annotations with ff.create_annotated_heatmap() subplots.\nannot1 = list(colorscale.layout.annotations)\nfor k in range(len(annot1)):\n    annot1[k]['xref'] = 'x'\n    annot1[k]['yref'] = 'y'\nfig.update_layout(annotations=annot1) \n\nfig.show()\n\n# Notebook referenced : 5","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### c) Comparitive bar chart"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Role-wise distribution of Educational Qualifications\nbuild_graph(qd['Q4'], qd['Q5'], 'Distribution of Educational Qualifications', order=Q4_ans_r, hgt=550)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<a id='obs-q4q5'></a>\n<b>Observations:</b><br>\n    1. <b>Students</b><br>\n    &emsp;<i>Overall</i><br>\n    &emsp;• largest proportion : Bachelor's : 50%<br>\n    &emsp;<i>India</i><br>\n    &emsp;• largest proportion : Bachelor's : 63%<br>\n    &emsp;<i>USA</i><br>\n    &emsp;• largest proportion : Master's : 44%<br>\n    &emsp;• with Bachelor's degree - 27%, which is significantly lower than the overall Bachelor's student percentage of 50%.<br>\n    2. <b>Data Scientist</b><br>\n    &emsp;<i>Overall</i><br>\n    &emsp;• largest proportion : Master's : 51%<br>\n    &emsp;• Doctoral : 17%, Bachelor's : 24%<br>\n    &emsp;<i>India</i><br>\n    &emsp;• largest proportion : Master's : 44%<br>\n    &emsp;• Doctoral : 5%, Bachelor's : 42%<br> \n    &emsp;<i>USA</i><br>\n    &emsp;• largest proportion : Master's : 52%<br>\n    &emsp;• Doctoral : 30%, Bachelor's : 15%<br> \n    3. <b>Statistician</b><br>\n    &emsp;<i>Overall</i><br>\n    &emsp;• largest proportion : Master's : 40%<br>\n    &emsp;• Doctoral : 28%, Bachelor's : 23%<br>\n    &emsp;<i>India</i><br>\n    &emsp;• largest proportion : Master's : 62%<br>\n    &emsp;• Doctoral : 21%, Bachelor's : 9%<br> \n    &emsp;<i>USA</i><br>\n    &emsp;• largest proportion : Doctoral : 47%<br>\n    &emsp;• Master's : 37%, Bachelor's : 8%<br> \n    \n</div>"},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q4 & Q6 - Education & Coding experience"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Heatmap\nfig = px.density_heatmap(df, x='Q6',y='Q4', color_continuous_scale='Blues',\n                         category_orders={'Q4':Q4_ans_r, 'Q6':Q6_ans})\nfig.update_layout(title={'text':'Education & Coding Experience', 'x':0.68, 'xanchor': 'center'})\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<a id='obs-q4q6'></a>\n<b>Observations:</b><br>\n    - Majority of the involvement in the survey was by those who have learned coding within the last 5 yrs and have a Bachelor's or Master's degree (≈50%).\n</div>"},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q5 & Q6 - Job role and Coding experience"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Heatmap\nfig = px.density_heatmap(df, x='Q6',y='Q5', color_continuous_scale='Blues',\n                         category_orders={'Q5':Q5_ans, 'Q6':Q6_ans})\nfig.update_layout(title={'text':'Job role & Coding Experience', 'x':0.58, 'xanchor': 'center'})\nfig.update_layout(autosize=False, width=800, height=550)\nfig.update_yaxes(dict(ticks = \"outside\", tickcolor='white', ticklen=0))\nfig.update_xaxes(domain=[0.2, 1])\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Comparitive bar chart (interactive)\nbuild_graph(qd['Q6'], qd['Q5'], 'Coding Experience', order=Q6_ans, label_angle=-10, hgt=450)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<a id='obs-q5q6'></a>\n<b>Observations:</b><br>\n    1. <b>Data Scientist</b><br>\n    &emsp;<i>Overall</i> - Distribution is slightly left-skewed, with 50% having programming experience of 3-10 yrs.<br>\n    &emsp;<i>India</i> - Distribution is roughly symmetrical, with 50% having 3-10 yrs experience.<br>\n    &emsp;<i>USA</i> - Distribution is negatively skewed, with 54% having 3-10 yrs experience and 90%+ with experience &gt;3 yrs.<br>\n    2. <b>Statistician</b><br>\n    &emsp;<i>Overall</i> - Distribution is spread out.<br>\n    &emsp;<i>India</i> - Approx. 88% have experience &lt;5 yrs.<br>\n    &emsp;<i>USA</i> - Approx. 85% have experience &gt;3 yrs.<br>\n    \n    \n</div>"},{"metadata":{},"cell_type":"markdown","source":"##### '################ workings"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Frequency distribution for Programming Experience - Data Scientist\ncustom_sort2(fd(qd['Q6'], qd['Q5'], 'Data Scientist', qd['Q3'], 'India'), 'criteria', Q6_ans)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Frequency distribution for Programming Experience - Data Scientist\ncustom_sort2(fd(qd['Q6'], qd['Q5'], 'Data Scientist', qd['Q3'], 'United States of America'), \n             'criteria', Q6_ans)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### '################ workings'"},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q7 - Regularly used programming language"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Frequency distribution\nq7_fd = fd(qd['Q7'], title='language')\nq7i_fd = fd(qd['Q7'], qd['Q3'], 'India', title='language')\nq7u_fd = fd(qd['Q7'], qd['Q3'], 'United States of America', title='language')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar chart with plotly go\nfig = go.Figure([go.Bar(x = q7_fd.language, y = q7_fd.freq, marker_color='#37659E',\n                       marker_line_color='teal',marker_line_width=0.3, opacity=1, text=q7_fd.freq)])\nfig.update_layout(title={'text':'Regularly Used Programming Language', 'x':0.5, 'xanchor': 'center'})\nfig.update_layout(autosize=False, width=750, height=480)\nfig.update_layout({'plot_bgcolor': '#fff'})\nfig.update_traces(texttemplate='%{text:.2}', textposition='outside', textfont_size=9)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Comparitive bar plot - Overall v India v USA\nbuild_graph(qd['Q7'], hgt=450, graph_title='Regularly Used Programming Language')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<a id='obs-q7'></a>\n<b>Observations:</b><br>\n    - The overall trends and the trends in India and USA seem to be more or less similar.<br>\n    - USA has higher usage of R, SQL and Bash and lesser usage of C and C++, as compared with India and the overall trend.<br>\n    - India has a higher usage C.\n</div>"},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q5 & Q7 - Role & Language"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Role-wise distribution of preferred programming language\nbuild_graph(qd['Q7'], qd['Q5'], 'Preferred Programming Language', hgt=500, label_angle=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<a id='obs-q5q7'></a>\n<b>Observations:</b><br>\n    1. <b>Data Scientist</b><br>\n    &emsp;- Data Scientists display a very high usage of Python with 94% of the respondents using it on a regular basis. The trend is similarly high in India (98%) and USA (89%).<br>\n    &emsp;- Data Scientists in USA have a higher usage for using:<br>\n    &emsp;&nbsp; • SQL (72%) when compared with India (50%) or overall world trend (56%).<br>\n    &emsp;&nbsp; • Bash (24%) when compared with India (7%)  or overall world trend (16%).<br>\n    &emsp;- India has a higher usage of :<br>\n    &emsp;&nbsp; • C (18%) when compared with USA (4%) and overall (9%).<br>\n    &emsp;&nbsp; • C++ (17%) when compared with USA (6%).<br>\n    2. <b>Statistician</b><br>\n    &emsp;- Statisticians use R (69%) more than Python (63%) and use SQL (29%) less often than the overall trend (42%).<br>\n    &emsp;- Usage patterns of programming languages are similar for Indian and USA statisticians.<br>\n    &emsp;- Usage of R by statisticians in both India & USA (≈81%) is higher than the overall usage (69%).<br>\n    &emsp;- Usage of C by Indian statisticians (22%) is slightly higher than global usage (10%).<br>\n    3. <b>Student</b><br>\n    &emsp;- Python is the language most used by students globally (90%) and this the trend is mirrored in India (93%) and USA (87%) as well.<br>\n    &emsp;- Students in USA have a higher regular usage of R (39%) compared with India (14%) and global usage (19%).<br>\n    &emsp;- Students in India have a considerably higher usage of C at 46%. The global usage is 31% and merely 12% in USA.<br>\n    &emsp;- C++ usage is at 45% in India, 18% in USA and 34% globally.<br>\n    4. <b>Software Engineer</b><br>\n    &emsp;- High usage of Python (78%) and SQL (52%) and very few use R regularly (8%).<br>\n    &emsp;- High usage of Java (38%) and Javascript (44%) <br>\n    &emsp;- USA particulary has a higher usage of Bash at 29%, with India at 9% and global usage at 16%.<br>\n    5. <b>Data Analyst</b><br>\n    &emsp;- High usage of Python (83%) and SQL (60%).<br>\n    &emsp;- USA has a higher usage of :<br>\n    &emsp;&nbsp;•  R (45%) compared with India (31%) and global (35%).<br>\n    &emsp;&nbsp;•  SQL (74%) compared with India (59%) and global (60%).<br>\n    6. <b>Machine Learning Engineer</b><br>\n    &emsp;- MLEs have a very high regular usage of Python at 97%.<br>\n    &emsp;- 32% of the MLEs of USA use Bash regularly whereas global MLE usage for Bash is at 15% and is 6% in India.<br>\n    7. <b>Business Analyst</b><br>\n    &emsp;- Python (77%) and SQL (59%) are the regularly used programming languages for a large no. of Business Analysts globally.<br>\n    &emsp;- Indian BAs use Python (87%) more often than the BAs in USA (67%).\n</div>"},{"metadata":{},"cell_type":"markdown","source":"##### #'################ workings"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fd(qd['Q7'], qd['Q5'], 'Data Scientist')","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fd2(qd['Q5'], qd['Q7']['Q7_Part_1'], 'Python')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### #'################ workings'"},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q8 - Recommended Language"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Interactive bar plot\nbuild_graph(qd['Q8'], qd['Q5'], hgt=500, \n            graph_title='Language Recommended for Initiation to Aspiring Data Scientists')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<a id='obs-q8'></a>\n<b>Observations:</b><br>\n    - Python is the most recommended initiation language across the board with 80% global recommendation, (84% in India, and 74% in USA), with R being a distant 2nd with 7% recommending it as the ideal jump-start for a data science path.<br>\n    - Data Scientists themselves recommend Python as the ideal starting point with 80% globally, 87% in India & 81% in USA recommending it.<br>\n    &ensp;Again, R (global : 8%, India : 1%, USA : 3%) and SQL (global : 7%, India : 4%, USA : 10%) are the distant runners-up.\n</div>"},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q9 - IDE Used"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Interactive Bar plot\nbuild_graph(qd['Q9'], qd['Q5'], graph_title='IDEs Used Regularly', hgt=500, label_angle=15, \n            ascending=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<a id='obs-q9'></a>\n<b>Observations:</b><br>Top IDEs<br>\n    - <b>Globally</b><br>\n    &emsp;• Jupyter : 64% (India : 74%, USA : 60%).<br>\n    &emsp;• VSCode : 33% (India : 33%, USA : 30%).<br>\n    &emsp;• PyCharm : 29% (India : 30%, USA : 23%).<br>\n    &emsp;• RStudio : 22% (India : 18%, USA : 33%)<br>\n    -  <b>India</b> : Jupyter, VSCode, PyCharm<br>\n    -  <b>USA</b> : Jupyter, RStudio, VSCode<br>\n    -  <b>Data Scientists</b><br> \n    &emsp;• Jupyter : 74% (India : 75%, USA : 70%).<br>\n    &emsp;• VSCode : 33% (India : 22%, USA : 29%).<br>\n    &emsp;• PyCharm : 32% (India : 22%, USA : 26%).<br>\n    &emsp;• RStudio : 31% (India : 25%, USA : 41%)<br>\n    - Jupyter is the undisputedly preferred IDE.\n</div>"},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q10 - Hosted notebook products regularly used"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Interactive Bar Chart\nbuild_graph(qd['Q10'], qd['Q5'], graph_title='Regularly used Hosted Notebooks', hgt=480, \n            label_angle=15, ascending=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<a id='obs-q10'></a>\n<b>Observations:</b><br>Most-used hosted notebooks :<br>\n    - <b>Globally</b><br>\n    &emsp;• Colab Notebooks : 37% (India : 47%, USA : 25%).<br>\n    &emsp;• Kaggle Notebooks : 35% (India : 43%, USA : 24%).<br>\n    &emsp;• None : 31% (India : 22%, USA : 43%).<br>\n    &emsp;• Binder/JupyterHub : 12% (India : 15%, USA : 14%)<br>\n    -  <b>India</b> : Colab Notebooks, Kaggle Notebooks, None<br>\n    -  <b>USA</b> : None, Colab Notebooks, Kaggle Notebooks<br>\n    -  <b>Data Scientists</b><br> \n    &emsp;&nbsp;• Colab Notebooks : 41% (India : 55%, USA : 25%).<br>\n    &emsp;&nbsp;• Kaggle Notebooks : 36% (India : 49%, USA : 20%).<br>\n    &emsp;&nbsp;• None : 26% (India : 13%, USA : 39%).<br>\n    &emsp;&nbsp;• Binder/JupyterHub : 13% (India : 16%, USA : 15%)<br>\n    &emsp;- Indian data scientists use Colab and Kaggle Notebooks much more than their global or US contempories do.<br> \n    &emsp;-  A signigicant number of data scientists in USA do not use any hosted notebook platform.\n</div>"},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q11 - Computing platform"},{"metadata":{"trusted":true},"cell_type":"code","source":"qans['Q11']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Interactive Bar Chart\nbuild_graph(qd['Q11'], qd['Q5'], graph_title='Most Used Computing Platform', hgt=550, \n            label_angle=10, ascending=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<a id='obs-q11'></a>\n<b>Observations:</b><br>\n    <b>Overall</b><br>\n    - Personal computer is the most used computing platform (Global-78%, India-80%, USA-75%)<br>\n    - A significant minority primarily uses cloud-computing (Global-14%, India-13%, USA-17%).<br>\n    <b>Data Scientists</b><br> \n    - Those working as data scientists have a :<br>\n    &emsp;&nbsp;• slightly lesser primary usage of personal computers (Global-67%, India-70%, USA-58%), and<br> \n    &emsp;&nbsp;• slightly higher primary usage of cloud-computing platforms (Global-24%, India-20%, USA-34%).<br> \n    - Data scientists from USA primarily use cloud-computing platforms at almost twice the overall cloud-computing usage rate in USA .<br>\n    <b>Deep learning workstation</b><br> \n    - ML Engineers (12%) and Research Scientists (12%) are the roles with a small but significant number of users that primarily use a deep learning workstation.<br>\n    <br><i>Workings below</i>\n</div>"},{"metadata":{},"cell_type":"markdown","source":"##### '################ workings"},{"metadata":{"trusted":true},"cell_type":"code","source":"fd2(qd['Q5'], qd['Q11'], 'deep', contains=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### '################ workings'"},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q12 - Specialized hardware"},{"metadata":{"trusted":true},"cell_type":"code","source":"qans['Q12']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Interactive Bar Chart\nbuild_graph(qd['Q12'], qd['Q5'], graph_title='Specialized Hardware Regularly Used', hgt=480, \n            label_angle=0, ascending=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q13 - TPU usage in life"},{"metadata":{"trusted":true},"cell_type":"code","source":"qans['Q13']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Q13_ans = ['Never','Once','2-5 times','6-25 times','More than 25 times']\n\n# Interactive Bar Chart\nbuild_graph(qd['Q13'], graph_title='TPU Usage in life', hgt=450, label_angle=0, order=Q13_ans)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q14 - Visualization libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"qans['Q14']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Interactive Bar Chart\nbuild_graph(qd['Q14'], qd['Q5'], graph_title='Visualization Libraries used Regularly', hgt=500, \n            ascending=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<a id='obs-q14'></a>\n<b>Observations:</b><br>\n    - <b>Overall</b> : Matplotlib (75%), Seaborn (54%), Plotly (25%) and ggplot2 (25%).<br>\n    -  <b>India</b> : Matplotlib (83%), Seaborn (64%), Plotly (28%) and ggplot2 (23%).<br>\n    -  <b>USA</b> : Matplotlib (67%), Seaborn (47%), ggplot2 (34%) and Plotly (27%).<br>\n    &emsp; Higher ggplot/ggplot2 usage in USA is commensurate with the fact that ggplot is an R package, which has a higher usage in USA.<br>\n    -  <b>Data Scientists</b><br> \n    &ensp;- <b>Overall</b> : Matplotlib (82%), Seaborn (67%), Plotly (41%) and ggplot2 (37%).<br>\n    &ensp;-  <b>India</b> : Matplotlib (90%), Seaborn (76%), Plotly (47%) and ggplot2 (37%).<br>\n    &ensp;-  <b>USA</b> : Matplotlib (73%), Seaborn (58%), ggplot2 (47%) and Plotly (38%).<br>\n    &ensp;- Matplotlib, Seaborn & ggplot have a jump of around 7-12 %p in usage proportion for data scientists, while plotly has a slightly higher jump of around 11-19 %p.\n</div>"},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q15 - Machine Learning Methods"},{"metadata":{"trusted":true},"cell_type":"code","source":"qans['Q15']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Q15_ans = ['I do not use machine learning methods','Under 1 year','1-2 years','2-3 years','3-4 years',\n           '4-5 years','5-10 years','10-20 years''20 or more years']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Interactive Bar Chart\nbuild_graph(qd['Q15'], qd['Q5'], graph_title='Machine Learning Methods Usage Time', hgt=480, \n            label_angle=15, order=Q15_ans)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Q15_ans = ['I do not use machine learning methods','Under 1 year','1-2 years','2-3 years','3-4 years',\n          '4-5 years','5-10 years','10-20 years','20 or more years']\n\n# Interactive Bar Chart\nbuild_graph(qd['Q15'], qd['Q5'], graph_title='Machine Learning Methods Usage Time', hgt=480, \n            label_angle=15, order=Q15_ans)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<a id='obs-q15'></a>\n<b>Observations:</b><br>\n    - <b>Overall</b> : 60% have been using ML methods for under 2 yrs and 26% for 2+ yrs.<br>\n    -  <b>India</b> : India has a large no. of new users with approx. 71% that have been using ML methods for under 2 years (49% under 1 yr) and only 16% that have been using for 2+ yrs.<br>\n    -  <b>USA</b> : Respondents from USA have a longer exposure to ML methods with only 42% with less than 2 yrs usage period. 45% have been using for 2+ yrs. There is a significant difference in the proportion of respondents that have been using ML methods for &gt;3 yrs in USA compared with India and overall. US has a larger proportion of experienced users.<br>\n    -  <b>Data Scientists</b><br> \n    &ensp;- <b>Overall</b> : Data scientists have been conversant with ML methods for a longer time than the overall data suggests. Only 40% have &lt;2 yrs experience. 42% have 3+ yrs usage experience. <br>\n    &ensp;- <b>USA</b> : Data scientists from USA have a left-skewed distribution, i.e. they generally have more experience. Approx. 49% have been using ML methods for &gt;4 yrs.<br>\n</div>"},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q16 - Machine Learning Frameworks"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Interactive Bar Chart\nbuild_graph(qd['Q16'], qd['Q5'], graph_title='Machine Learning Frameworks Regularly Used', hgt=480, \n            label_angle=15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<a id='obs-q16'></a>\n<b>Observations:</b><br>\n    - <b>Overall</b><br>\n    &emsp;• Scikit-Learn (72%), TensorFlow (49%), Keras (44%) are amongst the frameworks regularly used by majority of the respondents.<br>\n    &emsp;• India and USA have largely similar usage patterns. However, Indians usage of TenserFlow (54%) and Keras (49%) is notably more than their US counterparts (40% & 30% respectively).<br>\n    -  <b>Data Scientists</b><br> \n    &emsp;&nbsp;• Data Scientistis usage of Scikit-Learn (83%), Tensorflow (51%), Keras (51%) is slightly higher. Usage of Xgboost (48%) is a significantly higher than overall (28%).<br>\n    &emsp;&nbsp;• India and USA comparitive patterns are same as noted above.\n</div>"},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q17 - ML Algorithms"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q17'], graph_title='ML Algorithms Used Regularly', hgt=500, label_angle=15)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q17'], qd['Q5'], 'Data Scientist'), label_angle=15, hgt=500,\n            graph_title='Data Scientists - Machine Learning Algorithms Regularly Used')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<a id='obs-q17'></a>\n<b>Observations:</b><br>\n    - Usage of Decision Trees or Random Forests by Data Scientists seems to be more than their overall usage.\n</div>"},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q18 - Computer Vision Methods"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q18'], graph_title='Computer Vision Methods Used Regularly', hgt=480, \n            label_angle=12, adjust_margin=False, xmargin=120)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q18'], qd['Q5'], 'Data Scientist'), label_angle=12, hgt=480,\n            graph_title='Data Scientists - Computer Vision Methods Used Regularly', \n            adjust_margin=False, xmargin=120)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<a id='obs-q18'></a>\n<b>Observations:</b><br>\n    <b>Data Scientists</b><br>\n    - Roughly 90% of Indian Data Scientists use some computer vision method regularly.<br>\n    - A considerably larger proportion of US Data Scientists does not use any computer vision methods regularly, when compared with India or overall figure.\n</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"diff_ind_usa(qd['Q18'], qd['Q5'], 'Data Scientist')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q19 - Natural Language Processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"qans['Q19']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q19'], graph_title='NLP Methods Used Regularly', hgt=480, label_angle=12)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q19'], qd['Q5'], 'Data Scientist'), label_angle=12, hgt=480,\n            graph_title='Data Scientists - NLP Methods Used Regularly')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q20 - Company size"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Order\nQ20_ans = ['0-49 employees','50-249 employees','250-999 employees','1000-9,999 employees',\n           '10,000 or more employees']\n\n# Bar Chart\nbuild_graph(qd['Q20'], graph_title='Company Size', label_angle=15, hgt=400, order=Q20_ans)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q20'], qd['Q5'], 'Data Scientist'), label_angle=15, hgt=400,\n            graph_title='Data Scientists - Company Size', order=Q20_ans)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<a id='obs-q20'></a>\n<b>Observations:</b><br>\n    - Largest proportion of Indian Data Scientists work in companies with less than 50 employees.<br>\n</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"custom_sort(diff_ind_usa(qd['Q20'], qd['Q5'], 'Data Scientist').reset_index(), 'criteria', Q20_ans)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q21 - Individuals engaged in data science work at workplace"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Order\nQ21_ans = ['0','1-2','3-4','5-9','10-14','15-19','20+']\n\n# Bar Chart\nbuild_graph(qd['Q21'], graph_title='Individuals Engaged in Data Science Work at Workplace', \n            label_angle=0, hgt=420, order=Q21_ans)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q21'], qd['Q5'], 'Data Scientist'), label_angle=0,hgt=420, order=Q21_ans,\n            graph_title='Data Scientists - Individuals Engaged in Data Science Work at Workplace')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<a id='obs-q21'></a>\n<b>Observations:</b><br>\n    - For both India (25%) and USA (33%), largest proportion of respondents belong to organizations that have at least 20 individuals engaged in data science work at their place of work. This indicates an organized setup dedicated to Data Science.<br>\n    - <b>Data Scientists</b><br>\n    &emsp;• USA : Largest proportion &rarr; 20+ individuals &rarr; 37%<br>\n    &emsp; &emsp; &emsp; &nbsp; Lowest proportion &rarr; 0 individuals &rarr; 2%<br>\n    &emsp;• India : Largest proportion &rarr; 20+ individuals &rarr; 25%<br>\n    &emsp; &emsp; &emsp; &nbsp; Lowest proportion &rarr; 15-19 individuals &rarr; 3.1%<br>\n    &emsp; The proportion for respondents that have 20+ individuals engaged in Data Science work at their workplace is notably larger for USA (37%) than overall (23%) and for India (25%).<br> \n    &emsp; The proportion for respondents that have 0 individuals engaged in Data Science work at their workplace is notably larger for India (14%) than for US (2.2%).\n</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"custom_sort(diff_ind_usa(qd['Q21'], qd['Q5'], 'Data Scientist').reset_index(), 'criteria', Q21_ans)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q22 - ML methods used in business"},{"metadata":{"trusted":true},"cell_type":"code","source":"Q22_ans = ['I do not know',\n           'No (we do not use ML methods)',\n           'We use ML methods for generating insights (but do not put working models into production)',\n           'We are exploring ML methods (and may one day put a model into production)', \n           'We recently started using ML methods (i.e., models in production for less than 2 years)',\n           'We have well established ML methods (i.e., models in production for more than 2 years)']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q22'], graph_title='ML Methods Incorporation in Business', label_angle=15, hgt=500, \n            order=Q22_ans, adjust_margin=False, xmargin=150)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q22'], qd['Q5'], 'Data Scientist'), label_angle=15, hgt=500,\n            graph_title='Data Scientists - ML Methods Incorporation in Business', order=Q22_ans,\n            adjust_margin=False, xmargin=150)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<a id='obs-q22'></a>\n<b>Observations:</b><br>\n    &nbsp;<b>World</b><br>\n    - Highest proportion &rarr; Exploring ML : 21%<br>\n    - Second highest  &rarr; ML not used : 20%<br>\n    &nbsp;<b>India</b><br>\n    - Highest proportion &rarr; Exploring ML : 22%<br>\n    - Second highest  &rarr; Well established ML : 18%<br>\n    &nbsp;<b>USA</b><br>\n    - Highest proportion &rarr; Well established ML : 26%<br>\n    - Second highest  &rarr; Exploring ML : 16%<br>\n    &nbsp;<b>Data Scientists</b><br>\n    - The proportion of Data Scientists working at places with active incorporation of ML in business is larger than the general trend.<br>\n    - 55% respondents work in places which have incorporated ML methods in their business (compared with 33% overall).<br>\n    - The proportion is significantly larger for US at 67% (46% with well-established ML incorporation) than for India (54%).<br>\n</div>"},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q23 - Important work activities"},{"metadata":{"trusted":true},"cell_type":"code","source":"qans['Q23']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q23'], graph_title='Important Job Role Activities', label_angle=15, hgt=480,\n            adjust_margin=False, xmargin=150)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q23'], qd['Q5'], 'Data Scientist'), label_angle=15, hgt=480,\n            graph_title='Data Scientists - Important Job Role Activities', \n            adjust_margin=False, xmargin=150)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q24 - Yearly Compensation"},{"metadata":{"trusted":true},"cell_type":"code","source":"Q24_ans = ['$0-999','1,000-1,999','2,000-2,999','3,000-3,999','4,000-4,999','5,000-7,499',\n           '7,500-9,999','10,000-14,999','15,000-19,999','20,000-24,999','25,000-29,999',\n           '30,000-39,999','40,000-49,999','50,000-59,999','60,000-69,999','70,000-79,999',\n           '80,000-89,999','90,000-99,999','150,000-199,999','200,000-249,999',\n           '250,000-299,999','300,000-500,000','> $500,000']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q24'], graph_title='Current Yearly Compensation', \n            label_angle=-25, hgt=420, order=Q24_ans, wd=960)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q24'], qd['Q5'], 'Data Scientist'),\n            graph_title='Data Scientists - Current Yearly Compensation',\n            label_angle=-25, hgt=420, order=Q24_ans, wd=960)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<a id='obs-qxx'></a>\n<b>Observations:</b><br>\n    <i>Any comprehensive comparison of the compensational distribution between India and USA would require the conversion of compensation data according to purchasing power parity of the 2 countries. This is a point to be improved upon later.</i>\n</div>"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q25 - Money spent on ML / Cloud-computing"},{"metadata":{"trusted":true},"cell_type":"code","source":"qans['Q25']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Q25_ans1 = ['$0 ($USD)','$1-$99','$100-$999','$1000-$9,999','$10,000-$99,999',\n           '$100,000 or more ($USD)']\nQ25_ans = [s.replace('$','') for s in Q25_ans1]\nprint(Q25_ans)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nq25_df = qd['Q25'].replace({'\\$':''}, regex = True)\nbuild_graph(q25_df, graph_title='Money Spent on ML / Cloud-computing Services (past 5 yrs)', \n            label_angle=-25, hgt=420, order=Q25_ans)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(q25_df, qd['Q5'], 'Data Scientist'),\n            graph_title='Data Scientists - Money Spent on ML / Cloud-computing Services (past 5 yrs)',\n            label_angle=-25, hgt=420, order=Q25_ans)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q26 - Cloud-computing platform"},{"metadata":{},"cell_type":"markdown","source":"#### 26A - Platform regularly used"},{"metadata":{"trusted":true},"cell_type":"code","source":"qans['Q26_A']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q26'].iloc[:,0:12], graph_title='Cloud-computing Platform Used Regularly', \n            label_angle=17, hgt=420)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q26'].iloc[:,0:12], qd['Q5'], 'Data Scientist'),\n            graph_title='Data Scientists - Cloud-computing Platform Used Regularly',\n            label_angle=17, hgt=420)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 26B - Platform to familiarize with"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q26'].iloc[:,12:], graph_title='Cloud-computing Platform to Familiarize with (within next 2 yrs)', \n            label_angle=17, hgt=420)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q26'].iloc[:,12:], qd['Q5'], 'Data Scientist'),\n            graph_title='Data Scientists - Cloud-computing Platform to Familiarize with (within next 2 yrs)',\n            label_angle=17, hgt=420)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q27 - Cloud-computing products"},{"metadata":{},"cell_type":"markdown","source":"#### 27A - Product used regularly"},{"metadata":{"trusted":true},"cell_type":"code","source":"qans['Q27_A']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q27'].iloc[:,0:12], graph_title='Cloud-computing Products Used Regularly', \n            label_angle=17, hgt=420)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q27'].iloc[:,0:12], qd['Q5'], 'Data Scientist'),\n            graph_title='Data Scientists - Cloud-computing Products Used Regularly',\n            label_angle=17, hgt=420)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 27B - Product to familiarize with"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q27'].iloc[:,12:], graph_title='Cloud-computing Products to Familiarize with (within next 2 yrs)', \n            label_angle=17, hgt=420)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q27'].iloc[:,12:], qd['Q5'], 'Data Scientist'),\n            graph_title='Data Scientists - Cloud-computing Products to Familiarize with (within next 2 yrs)',\n            label_angle=17, hgt=420)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q28 - Machine learning products"},{"metadata":{},"cell_type":"markdown","source":"#### 28A - ML Product used regularly"},{"metadata":{"trusted":true},"cell_type":"code","source":"qans['Q28_A']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q28'].iloc[:,0:11], graph_title='Machine Learning Products Used Regularly', \n            label_angle=17, hgt=420)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q28'].iloc[:,0:11], qd['Q5'], 'Data Scientist'),\n            graph_title='Data Scientists - Machine Learning Products Used Regularly',\n            label_angle=17, hgt=420)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 28B - ML Product to familiarize with"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q28'].iloc[:,11:], graph_title='Machine Learning Products to Familiarize with (next 2 yrs)', \n            label_angle=17, hgt=420)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q28'].iloc[:,11:], qd['Q5'], 'Data Scientist'),\n            graph_title='Data Scientists - Machine Learning Products to Familiarize with (next 2 yrs)',\n            label_angle=17, hgt=420)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q29 - Big Data Products"},{"metadata":{},"cell_type":"markdown","source":"#### 29A - Big data products used regularly"},{"metadata":{"trusted":true},"cell_type":"code","source":"qans['Q29_A']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Q29_ans = ['MySQL ','PostgresSQL ','SQLite ','Oracle Database ','MongoDB ','Snowflake ','IBM Db2 ',\n           'Microsoft SQL Server ','Microsoft Access ','Microsoft Azure Data Lake Storage ',\n           'Amazon Redshift ','Amazon Athena ','Amazon DynamoDB ','Google Cloud BigQuery ',\n           'Google Cloud SQL ','Google Cloud Firestore ','None','Other']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q29'].iloc[:,0:18], graph_title='Big Data Products Used Regularly', \n            label_angle=17, hgt=420, order=Q29_ans)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q29'].iloc[:,0:18], qd['Q5'], 'Data Scientist'),\n            graph_title='Data Scientists - Big Data Products Used Regularly',\n            label_angle=17, hgt=420, order=Q29_ans)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 29B - Big data products to familiarize with"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q29'].iloc[:,18:], graph_title='Big Data Products to Familiarize with (next 2 yrs)', \n            label_angle=17, hgt=420, order=Q29_ans)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q29'].iloc[:,18:], qd['Q5'], 'Data Scientist'),\n            graph_title='Data Scientists - Big Data Products to Familiarize with (next 2 yrs)',\n            label_angle=17, hgt=420, order=Q29_ans)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q30 - Most used big data products"},{"metadata":{"trusted":true},"cell_type":"code","source":"qans['Q30']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q30'], graph_title='Big Data Products Most Used', \n            label_angle=17, hgt=420)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q30'], qd['Q5'], 'Data Scientist'),\n            graph_title='Data Scientists - Big Data Products Most Used',\n            label_angle=17, hgt=420)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q31 - Business Intelligence Tools"},{"metadata":{},"cell_type":"markdown","source":"#### 31A - Business Intelligence tools used regularly"},{"metadata":{"trusted":true},"cell_type":"code","source":"qans['Q31_A']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Q31_ans = ['Amazon QuickSight','Microsoft Power BI','Google Data Studio','Looker','Tableau',\n           'Salesforce','Einstein Analytics','Qlik','Domo','TIBCO Spotfire','Alteryx ','Sisense ',\n           'SAP Analytics Cloud ','Other','None']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q31'].iloc[:,0:15], graph_title='Business Intelligence Tools Used Regularly', \n            label_angle=17, hgt=420, order=Q31_ans)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q31'].iloc[:,0:15], qd['Q5'], 'Data Scientist'),\n            graph_title='Data Scientists - Business Intelligence Tools Used Regularly',\n            label_angle=17, hgt=420, order=Q31_ans)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 31B - Business Intelligence tools to familiarize with"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q31'].iloc[:,15:], graph_title='Business Intelligence Tools to Familiarize with (next 2 yrs)', \n            label_angle=17, hgt=420, order=Q31_ans)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q31'].iloc[:,15:], qd['Q5'], 'Data Scientist'),\n            graph_title='Data Scientists - Business Intelligence Tools to Familiarize with (next 2 yrs)',\n            label_angle=17, hgt=420, order=Q31_ans)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Q32 - Business Intilligence tools used most often"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q32'], graph_title='Business Intelligence Tools Most Used', \n            label_angle=17, hgt=420, order=Q31_ans)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q32'], qd['Q5'], 'Data Scientist'),\n            graph_title='Data Scientists - Business Intelligence Tools Most Used',\n            label_angle=17, hgt=420, order=Q31_ans)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q33 - Automated ML Tools Category"},{"metadata":{},"cell_type":"markdown","source":"#### 33A - Automated ML Tools Category"},{"metadata":{"trusted":true},"cell_type":"code","source":"qans['Q33_A']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q33'].iloc[:,0:8], graph_title='Category of Automated ML Tools Used Regularly', \n            label_angle=15, hgt=500, adjust_margin=False, xmargin=150)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q33'].iloc[:,0:8], qd['Q5'], 'Data Scientist'),\n            graph_title='Data Scientists - Category of Automated ML Tools Used Regularly',\n            label_angle=15, hgt=500, adjust_margin=False, xmargin=150)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 33B - Automated ML Tools to familiarize with"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q33'].iloc[:,8:], graph_title='Category of Automated ML Tools to Familiarize with (next 2 yrs)', \n            label_angle=15, hgt=500, adjust_margin=False, xmargin=150)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q33'].iloc[:,8:], qd['Q5'], 'Data Scientist'),\n            graph_title='Data Scientists - Category of Automated ML Tools to Familiarize with (next 2 yrs)',\n            label_angle=15, hgt=500, adjust_margin=False, xmargin=150)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q34 - Automated ML tools"},{"metadata":{},"cell_type":"markdown","source":"#### 34A - Automated ML tools regularly used"},{"metadata":{"trusted":true},"cell_type":"code","source":"qans['Q34_A']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q34'].iloc[:,0:12], graph_title='Automated ML Tools Used Regularly', \n            label_angle=17, hgt=420)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q34'].iloc[:,0:12], qd['Q5'], 'Data Scientist'),\n            graph_title='Data Scientists - Automated ML Tools Used Regularly',\n            label_angle=17, hgt=420)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 34B - Automated ML tools to familiarize with"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q34'].iloc[:,12:], graph_title='Automated ML Tools to Familiarize with (next 2 yrs)', \n            label_angle=17, hgt=420)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q34'].iloc[:,12:], qd['Q5'], 'Data Scientist'),\n            graph_title='Data Scientists - Automated ML Tools to Familiarize with (next 2 yrs)',\n            label_angle=17, hgt=420)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q35 - ML experiments"},{"metadata":{},"cell_type":"markdown","source":"#### 35A - Tools used to manage ML experiments"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q35'].iloc[:,0:11], graph_title='ML Experiments Mangement Tools Used', \n            label_angle=15, hgt=420)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q35'].iloc[:,0:11], qd['Q5'], 'Data Scientist'),\n            graph_title='Data Scientists - ML Experiments Mangement Tools Used',\n            label_angle=15, hgt=420)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 35B - Tools to familiarize with"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q35'].iloc[:,11:], graph_title='ML Experiment Mangement Tools to Familiarize with (next 2 yrs)', \n            label_angle=15, hgt=420)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q35'].iloc[:,11:], qd['Q5'], 'Data Scientist'),\n            graph_title='Data Scientists - ML Experiment Mangement Tools to Familiarize with (next 2 yrs)',\n            label_angle=15, hgt=420)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q36 - Public sharing platforms"},{"metadata":{"trusted":true},"cell_type":"code","source":"qans['Q36']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q36'], graph_title='Platforms used for Sharing Data Science Project / Applications', \n            label_angle=15, hgt=400)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q36'], qd['Q5'], 'Data Scientist'),\n            graph_title='Data Scientists - Platforms used for Sharing Data Science Project / Applications',\n            label_angle=15, hgt=400)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q37 - DS learning platforms"},{"metadata":{"trusted":true},"cell_type":"code","source":"qans['Q37']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q37'], graph_title='Platforms used for Data Science Learning', label_angle=15, \n            hgt=500, adjust_margin=False, xmargin=100)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q37'], qd['Q5'], 'Data Scientist'), label_angle=15,\n            graph_title='Data Scientists - Platforms used for Data Science Learning',\n            hgt=500, adjust_margin=False, xmargin=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q38 - Data Analysis Tool"},{"metadata":{"trusted":true},"cell_type":"code","source":"qans['Q38']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q38'], graph_title='Primary Tool for Data Analysis', label_angle=15, \n            hgt=500, adjust_margin=False, xmargin=150)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q38'], qd['Q5'], 'Data Scientist'), label_angle=15,\n            graph_title='Data Scientists - Primary Tool for Data Analysis',\n            hgt=500, adjust_margin=False, xmargin=150)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Q39 - Favorite Media Sources"},{"metadata":{"trusted":true},"cell_type":"code","source":"qans['Q39']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bar Chart\nbuild_graph(qd['Q39'], graph_title='Favorite Media Sources for Data Science', label_angle=15, \n            hgt=500, adjust_margin=False, xmargin=150)\n\n# Bar Chart - Data Scientists\nbuild_graph(create_subset(qd['Q39'], qd['Q5'], 'Data Scientist'), label_angle=15,\n            graph_title='Data Scientists - Favorite Media Sources for Data Science',\n            hgt=500, adjust_margin=False, xmargin=150)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<a id='obs-qxx'></a>\n<b>Observations:</b><br>\n    - <b>Overall</b><br>\n    &ensp;- xx<br>\n    &emsp;• xx : xx% (India : xx%, USA : xx%).<br>\n    -  <b>India</b> : <br>\n    -  <b>USA</b> : <br>\n    -  <b>Data Scientists</b><br> \n    &ensp;- xx<br>\n    &emsp;• xx : xx% (India : xx%, USA : xx%).<br>\n    \n</div>"},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"##### Notes\nI have deliberately kept, within this notebook, some of the code which was part of my learning journey.  \nI've incorporated more efficited codes/methods as the notebook progresses.\n\n***Points of improvement:***  \na) Q24 Compensation : comparisons to be made according to purchasing power parity."},{"metadata":{},"cell_type":"markdown","source":"###### ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"### Notebooks Referenced\n1. https://www.kaggle.com/kenjee/kaggle-project-from-scratch<br>\n2. https://www.kaggle.com/subinium/kaggle-2020-visualization-analysis<br>\n3. https://www.kaggle.com/paultimothymooney/2020-kaggle-data-science-machine-learning-survey<br>\n4. https://www.kaggle.com/dwin183287/kagglers-seen-by-continents<br>\n5. https://www.kaggle.com/spitfire2nd/enthusiast-to-data-professional-what-changes<br>\n6. https://www.kaggle.com/kenjee/analyzing-gender-and-earning-potential-in-tech"},{"metadata":{},"cell_type":"markdown","source":"[back to top](#toc)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}