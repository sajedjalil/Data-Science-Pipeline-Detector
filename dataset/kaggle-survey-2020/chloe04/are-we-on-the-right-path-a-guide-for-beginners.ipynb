{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Are we on the right path? Are we learning what we need in future career?** \n**--learning from the experienced in the industry**\n![](http://s3.amazonaws.com/thumbnails.illustrationsource.com/huge.58.293880.JPG)\n(image reference:http://www.bianoti.com/walking-path-cartoon.html)"},{"metadata":{},"cell_type":"markdown","source":"# Introduction\nIt is undeniable that the data science industry is booming in the decade, especially in 2020, the pandemic is accelerating the growth of digital transformation, which means there will be more job opportunities in the industry. Meanwhile, more and more people are on the learning path of data science, including me, as we can foresee the industry would keep growing in the future. However, there are so many aspects of data science, some of us may be confused as we are not sure where to start or whether we are working the right way, therefore, I hope to find out some clues for us, who are the beginner in data analytics, coding, ML algorithms, etc., from the experienced in the Kaggle community."},{"metadata":{},"cell_type":"markdown","source":"# How is this analysis conduct?\n**What data did I analyzed and why?**  \n  \nIn order to know more about the industry and what should beginner prepare before we can step into the industry, I used the response from people who have work experience in data science-related roles, all levels of experience are included in this analysis. I think we can learn from the experience of these respondents, and get some insight from the experienced to help us to learn.\n\n**How is the data organized?**  \n  \nAccording to the survey, there are 10 job titles options for respondents, I classified the experienced respondent according to the job titles that they select as below:\n* Data Engineer\n* Software Engineer\n* Data Scientist\n* Data Analyst\n* Research Scientist\n* Statistician\n* Product/Project Manager\n* Machine Learning Engineer\n* Business Analyst\n* DBA/Database Engineer\n\nThe analysis will be segmented by the above job title, so as to get a better understanding of nature, knowledge and skills needed of various paths in the data science world."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"answer2020 = pd.read_csv('/kaggle/input/kaggle-survey-2020/kaggle_survey_2020_responses.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"job_list=list(answer2020['Q5'].unique())\njob_list.remove('Select the title most similar to your current role (or most recent title if retired): - Selected Choice')\njob_list.remove('Student')\n\njob_list.remove('Other')\njob_list.remove('Currently not employed')\njob_list = [x for x in job_list if str(x) != 'nan']\n\n#clean data\nworker=answer2020[~(answer2020['Q5']==\"Student\")]\nworker=worker[~((worker['Q5']=='Other') |(worker['Q5']=='Currently not employed'))].reset_index(drop=True)\nworker = worker.drop([0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Job nature and the basic education information"},{"metadata":{},"cell_type":"markdown","source":"**Job nature**  \n  \nBefore starting our learning path, we have to understand what are the job duties of various data science-related roles, so that we can decide our direction according to the job nature as well as our preference and ability. There are 8 options that respondents can choose from to represent the daily actitvities of their jobs:\n* Analyze and understand data to influence product or business decisions\n* Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data\n* Build prototypes to explore applying machine learning to new areas\n* Build and/or run a machine learning service that operationally improves my product or workflows\n* Experimentation and iteration to improve existing ML models\n* Do research that advances the state of the art of machine learning\n* None of these activities are an important part of my role at work\n* Other"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#job duties of data engineer\ndata_engineer=worker[(worker['Q5']=='Data Engineer')].reset_index()\ntemp_list=['Q5','Q23_Part_1','Q23_Part_2','Q23_Part_3','Q23_Part_4','Q23_Part_5','Q23_Part_6','Q23_Part_7','Q23_OTHER']\njd_data_engineer=data_engineer[temp_list]\n# jd_list=['Analyze and understand data to influence product or business decisions','Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data','Build prototypes to explore applying machine learning to new areas','Build and/or run a machine learning service that operationally improves my product or workflows', 'Experimentation and iteration to improve existing ML models','Do research that advances the state of the art of machine learning', 'None of these activities are an important part of my role at work','Other']\njd_data_engineer.columns=['jobname','Analyze and understand data to influence product or business decisions','Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data','Build prototypes to explore applying machine learning to new areas','Build and/or run a machine learning service that operationally improves my product or workflows', 'Experimentation and iteration to improve existing ML models','Do research that advances the state of the art of machine learning', 'None of these activities are an important part of my role at work','Other']\n\n#create raw data for bar chart\njd_list =[i for n, i in enumerate(jd_data_engineer.columns) if n in [1,2,3,4,5,6,7,8]]\njd_data_engineer_raw=list()\nfor i in jd_list:\n    temp=jd_data_engineer[i].notnull().sum()\n    jd_data_engineer_raw.append(temp)\n    \n\n#job duties of software engineer\nsoftware_engineer=worker[(worker['Q5']=='Software Engineer')].reset_index()\ntemp_list=['Q5','Q23_Part_1','Q23_Part_2','Q23_Part_3','Q23_Part_4','Q23_Part_5','Q23_Part_6','Q23_Part_7','Q23_OTHER']\njd_software_engineer=software_engineer[temp_list]\n# jd_list=['Analyze and understand data to influence product or business decisions','Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data','Build prototypes to explore applying machine learning to new areas','Build and/or run a machine learning service that operationally improves my product or workflows', 'Experimentation and iteration to improve existing ML models','Do research that advances the state of the art of machine learning', 'None of these activities are an important part of my role at work','Other']\njd_software_engineer.columns=['jobname','Analyze and understand data to influence product or business decisions','Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data','Build prototypes to explore applying machine learning to new areas','Build and/or run a machine learning service that operationally improves my product or workflows', 'Experimentation and iteration to improve existing ML models','Do research that advances the state of the art of machine learning', 'None of these activities are an important part of my role at work','Other']\n\n#raw data for chart\njd_software_engineer_raw=list()\nfor i in jd_list:\n    temp=jd_software_engineer[i].notnull().sum()\n    jd_software_engineer_raw.append(temp)\n    \n\n#job duties of data scientist\ndata_scientist=worker[(worker['Q5']=='Data Scientist')].reset_index()\ntemp_list=['Q5','Q23_Part_1','Q23_Part_2','Q23_Part_3','Q23_Part_4','Q23_Part_5','Q23_Part_6','Q23_Part_7','Q23_OTHER']\njd_data_scientist=data_scientist[temp_list]\n# jd_list=['Analyze and understand data to influence product or business decisions','Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data','Build prototypes to explore applying machine learning to new areas','Build and/or run a machine learning service that operationally improves my product or workflows', 'Experimentation and iteration to improve existing ML models','Do research that advances the state of the art of machine learning', 'None of these activities are an important part of my role at work','Other']\njd_data_scientist.columns=['jobname','Analyze and understand data to influence product or business decisions','Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data','Build prototypes to explore applying machine learning to new areas','Build and/or run a machine learning service that operationally improves my product or workflows', 'Experimentation and iteration to improve existing ML models','Do research that advances the state of the art of machine learning', 'None of these activities are an important part of my role at work','Other']\n\n#raw data for chart\njd_data_scientist_raw=list()\nfor i in jd_list:\n    temp=jd_data_scientist[i].notnull().sum()\n    jd_data_scientist_raw.append(temp)\n    \n\n#job duties of data analyst\ndata_analyst=worker[(worker['Q5']=='Data Analyst')].reset_index()\ntemp_list=['Q5','Q23_Part_1','Q23_Part_2','Q23_Part_3','Q23_Part_4','Q23_Part_5','Q23_Part_6','Q23_Part_7','Q23_OTHER']\njd_data_analyst=data_analyst[temp_list]\njd_data_analyst.columns=['jobname','Analyze and understand data to influence product or business decisions','Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data','Build prototypes to explore applying machine learning to new areas','Build and/or run a machine learning service that operationally improves my product or workflows', 'Experimentation and iteration to improve existing ML models','Do research that advances the state of the art of machine learning', 'None of these activities are an important part of my role at work','Other']\n\n#raw data for chart\njd_data_analyst_raw=list()\nfor i in jd_list:\n    temp=jd_data_analyst[i].notnull().sum()\n    jd_data_analyst_raw.append(temp)\n    \n#job duties of research scientist\nresearch_scientist=worker[(worker['Q5']=='Research Scientist')].reset_index()\ntemp_list=['Q5','Q23_Part_1','Q23_Part_2','Q23_Part_3','Q23_Part_4','Q23_Part_5','Q23_Part_6','Q23_Part_7','Q23_OTHER']\njd_research_scientist=research_scientist[temp_list]\n# jd_list=['Analyze and understand data to influence product or business decisions','Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data','Build prototypes to explore applying machine learning to new areas','Build and/or run a machine learning service that operationally improves my product or workflows', 'Experimentation and iteration to improve existing ML models','Do research that advances the state of the art of machine learning', 'None of these activities are an important part of my role at work','Other']\njd_research_scientist.columns=['jobname','Analyze and understand data to influence product or business decisions','Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data','Build prototypes to explore applying machine learning to new areas','Build and/or run a machine learning service that operationally improves my product or workflows', 'Experimentation and iteration to improve existing ML models','Do research that advances the state of the art of machine learning', 'None of these activities are an important part of my role at work','Other']\n\n#raw data for chart\njd_research_scientist_raw=list()\nfor i in jd_list:\n    temp=jd_research_scientist[i].notnull().sum()\n    jd_research_scientist_raw.append(temp)\n    \n\n#job duties of statistician\nstatistician=worker[(worker['Q5']=='Statistician')].reset_index()\ntemp_list=['Q5','Q23_Part_1','Q23_Part_2','Q23_Part_3','Q23_Part_4','Q23_Part_5','Q23_Part_6','Q23_Part_7','Q23_OTHER']\njd_statistician=statistician[temp_list]\njd_statistician.columns=['jobname','Analyze and understand data to influence product or business decisions','Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data','Build prototypes to explore applying machine learning to new areas','Build and/or run a machine learning service that operationally improves my product or workflows', 'Experimentation and iteration to improve existing ML models','Do research that advances the state of the art of machine learning', 'None of these activities are an important part of my role at work','Other']\n\n#raw data for chart\njd_statistician_raw=list()\nfor i in jd_list:\n    temp=jd_statistician[i].notnull().sum()\n    jd_statistician_raw.append(temp)\n    \n\n#job duties of product/project manager\npm=worker[(worker['Q5']=='Product/Project Manager')].reset_index()\ntemp_list=['Q5','Q23_Part_1','Q23_Part_2','Q23_Part_3','Q23_Part_4','Q23_Part_5','Q23_Part_6','Q23_Part_7','Q23_OTHER']\njd_pm=pm[temp_list]\njd_pm.columns=['jobname','Analyze and understand data to influence product or business decisions','Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data','Build prototypes to explore applying machine learning to new areas','Build and/or run a machine learning service that operationally improves my product or workflows', 'Experimentation and iteration to improve existing ML models','Do research that advances the state of the art of machine learning', 'None of these activities are an important part of my role at work','Other']\n\n\n#raw data for chart\njd_pm_raw=list()\nfor i in jd_list:\n    temp=jd_pm[i].notnull().sum()\n    jd_pm_raw.append(temp)\n    \n#job duties of ML engineer\nml_engineer=worker[(worker['Q5']=='Machine Learning Engineer')].reset_index()\ntemp_list=['Q5','Q23_Part_1','Q23_Part_2','Q23_Part_3','Q23_Part_4','Q23_Part_5','Q23_Part_6','Q23_Part_7','Q23_OTHER']\njd_ml_engineer=ml_engineer[temp_list]\njd_ml_engineer.columns=['jobname','Analyze and understand data to influence product or business decisions','Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data','Build prototypes to explore applying machine learning to new areas','Build and/or run a machine learning service that operationally improves my product or workflows', 'Experimentation and iteration to improve existing ML models','Do research that advances the state of the art of machine learning', 'None of these activities are an important part of my role at work','Other']\n\n\n#raw data for chart\njd_ml_engineer_raw=list()\nfor i in jd_list:\n    temp=jd_ml_engineer[i].notnull().sum()\n    jd_ml_engineer_raw.append(temp)\n    \n\n#job duties of business analyst\nbusiness_analyst=worker[(worker['Q5']=='Business Analyst')].reset_index()\ntemp_list=['Q5','Q23_Part_1','Q23_Part_2','Q23_Part_3','Q23_Part_4','Q23_Part_5','Q23_Part_6','Q23_Part_7','Q23_OTHER']\njd_business_analyst=business_analyst[temp_list]\njd_business_analyst.columns=['jobname','Analyze and understand data to influence product or business decisions','Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data','Build prototypes to explore applying machine learning to new areas','Build and/or run a machine learning service that operationally improves my product or workflows', 'Experimentation and iteration to improve existing ML models','Do research that advances the state of the art of machine learning', 'None of these activities are an important part of my role at work','Other']\n\n\n#raw data for chart\njd_business_analyst_raw=list()\nfor i in jd_list:\n    temp=jd_business_analyst[i].notnull().sum()\n    jd_business_analyst_raw.append(temp)\n    \n\n#job duties of dba/database engineer\ndba=worker[(worker['Q5']=='DBA/Database Engineer')].reset_index()\ntemp_list=['Q5','Q23_Part_1','Q23_Part_2','Q23_Part_3','Q23_Part_4','Q23_Part_5','Q23_Part_6','Q23_Part_7','Q23_OTHER']\njd_dba=dba[temp_list]\njd_dba.columns=['jobname','Analyze and understand data to influence product or business decisions','Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data','Build prototypes to explore applying machine learning to new areas','Build and/or run a machine learning service that operationally improves my product or workflows', 'Experimentation and iteration to improve existing ML models','Do research that advances the state of the art of machine learning', 'None of these activities are an important part of my role at work','Other']\n\n#raw data for chart\njd_dba_raw=list()\nfor i in jd_list:\n    temp=jd_dba[i].notnull().sum()\n    jd_dba_raw.append(temp)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nr = [0,1,2,3,4,5,6,7,8,9]\nbar_list = ['Analyze', 'Infrustructure', 'Prototypes', 'ML Service', 'Improve models', 'Research', 'None of the above', 'Other']\ndf=pd.DataFrame([jd_data_engineer_raw,jd_software_engineer_raw,jd_data_scientist_raw,jd_data_analyst_raw,jd_research_scientist_raw,jd_statistician_raw,jd_pm_raw,jd_ml_engineer_raw,jd_business_analyst_raw,jd_dba_raw],columns=bar_list)\ndf['Job title'] = job_list\ndf['total'] = [0] * len(df)\nfor col in bar_list:\n    df['total'] += df[col]\nfor col in bar_list:\n    df[col] = df[col] / df['total'] * 100\ndel df['total']\nsns.set(rc={'figure.figsize':(16,7)})\ndf.set_index('Job title').plot.barh(stacked=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above stacked graph is showing how each job are composed by different activities, we can learn more about the job nature of different job title from the graph.  \n  \nHere are some points that worth to mentioned:\n* \"**Data Scientist**\" has a relatively even distribution of job duties, it seems not heavily relying on any aspect of job. This also means that the knowledge and skills needed for the job are more diverse, we have to gain a certain level of proficiency in these job duties in order to get or handle this kind of job well.\n* In contrast, \"**Business analyst**\" and \"**Data analyst**\" rely heavily on \"Analyze and understand data to influence product or business decisions\", which requires high level of analytical skills so as to turn data into strategies and plans. To master this kind of job, we should not only focus on enhancing our coding and data science skills, but also the ability to analyze and present the data to influence product or business decision.\n* We can also notice that \"**DBA/Database engineer**\" and \"**Data engineer**\" focus more on \"Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data\" than the others, meaning their job duties are more related to data infrasture, if we are good at or interested in jobs related to data infrastruture, we may work towards this directon.\n"},{"metadata":{},"cell_type":"markdown","source":"**Basic education information**  \n  \nBefore looking into specific skills and knowledge, we can first take a look at the general education level of various jobs."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"edu_lv_list=list(worker['Q4'].unique())\nedu_lv_list.remove('I prefer not to answer')\nedu_lv_list=[x for x in edu_lv_list if str(x) != 'nan']\n\n#create edu level df\ndfname=pd.DataFrame(columns=edu_lv_list)\nfor i in job_list:\n    temp=worker[(worker['Q5']==i)]\n    raw=list()\n    for j in edu_lv_list:\n        number=(temp['Q4']==j).sum()\n        raw.append(number)\n    dfname.loc[i]=raw\n\nedu_col_list = ['No formal education past high school', 'Some college/university study without earning a bachelor’s degree',\\\n                'Professional degree', 'Bachelor’s degree', 'Master’s degree', 'Doctoral degree']\ndfname = dfname[edu_col_list]\ndfname = dfname.rename(columns=\n                       {'No formal education past high school': 'No formal education',\n                        'Some college/university study without earning a bachelor’s degree': 'College/university study'})\ndfname['total'] = [0] * len(dfname)\nfor col in dfname.columns[:-1]:\n    dfname['total'] += dfname[col]\nfor col in dfname.columns:\n    dfname[col] = dfname[col] / dfname['total'] * 100\ndel dfname['total']\n\ny_label, x_label = list(dfname.index), list(dfname.columns)\ndfname.reset_index(drop=True, inplace=True)\nax = sns.heatmap(np.array(dfname).astype('float32'), cmap=\"RdYlGn\",annot=True)\nax.set_yticklabels(y_label, rotation=0)\nax.set_xticklabels(x_label, rotation=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the majority of most job titles is getting a \"**Master's degree**\", it may because of the roles require high level of data science knowledge and skills, as well as research experience, since postgraduate students are usually taking up research roles in school. We may have to obtain a \"Master's degree\" sooner or later if we are planning to develop in the data science field, but we can see some difference in the role of \"Research scientist\" and \"Software engineer\"\n* Most of the responsed \"Research scientist\" (**59%**) have finished their \"Doctoral degree\", which is relatively high proportion, it may imply that this kind of job needs to have a very in-depth knowledge and high level proficiency of data science. If we are planning to take up research-related duties, we may have to plan for a doctoral degree.\n* It is worth to mention that respondents who taking up \"Software engineer\" job have similar proportion in both \"**Bachelor's degree**\" and \"**Master's degree**\", \"**Bachelor's degree**\" is even a bit higher(**5%**). If we are planning to take up \"Software Engineer\" job, we try to apply it when we have obtained our \"Bachelor's degree\" and decide whether we have to obtain a higher degree later."},{"metadata":{},"cell_type":"markdown","source":"# What can we learn from the data?"},{"metadata":{},"cell_type":"markdown","source":"The following part will explore the usage of some critical data science skills and knowledge, as well as some oftenly-used tools from the response of the experienced. I hope this can help everyone who want to join the data science and get ourselves well prepared."},{"metadata":{},"cell_type":"markdown","source":"**(1) Programming language** "},{"metadata":{},"cell_type":"markdown","source":"Programming language is a critical part of learning data science, but there are so many choices out there, which one should we learn first? which one we have to master it? We will examine the programming language that the experienced use on a regular basis and which programming language they recommend for the beginner in this part."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"question7=['Q7_Part_1','Q7_Part_2','Q7_Part_3','Q7_Part_4','Q7_Part_5','Q7_Part_6','Q7_Part_7','Q7_Part_8','Q7_Part_9','Q7_Part_10','Q7_Part_11','Q7_Part_12','Q7_OTHER']\n# for i in question7:\n#     print(worker.loc[0,i])\nprogramming_lang=['Python','R','SQL','C','C++','Java','Javascript','Julia','Swift','Bash','MATLAB','None','Other']\n#programming language use on regular basis\n#create df with one job title & question7 only\ndf_freq_program_lang=pd.DataFrame(columns=programming_lang)\nfor i in job_list:\n    #create df with one job title & question7 only\n    temp = worker[(worker[\"Q5\"]==i)]\n    temp_list=question7\n    freq_program_lang=temp[temp_list]\n    freq_program_lang.columns=programming_lang\n    #create raw date of programming language\n    temp_raw=list()\n    for j in programming_lang:\n        temp1=freq_program_lang[j].notnull().sum()\n        temp_raw.append(temp1)\n    df_freq_program_lang.loc[i]=temp_raw\n    \ntemp_df = df_freq_program_lang.copy()\ny_label = list(df_freq_program_lang.index)\nx_label = list(df_freq_program_lang.columns)\n\ndf_freq_program_lang['total'] = [0] * len(df_freq_program_lang)\nfor col in df_freq_program_lang.columns[:-1]:\n    df_freq_program_lang['total'] += df_freq_program_lang[col]\nfor col in df_freq_program_lang.columns:\n    df_freq_program_lang[col] = df_freq_program_lang[col] / df_freq_program_lang['total'] * 100\ndel df_freq_program_lang['total']\n\ndf_freq_program_lang.reset_index(drop=True, inplace=True)\nax = sns.heatmap(np.array(df_freq_program_lang).astype('float32'), cmap=\"YlGnBu\", annot=True)\nax.set_yticklabels(y_label, rotation=0)\nax.set_xticklabels(x_label, rotation=20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is undoubtable that Python is the most frequently used programming language in the data science world nowadays, followed by SQL. This may because of Python is easy to use and understand, it is an intuitive programming language with high processing speed. SQL is also popular, it is essential while dealing with database, it is not surprising that SQL is widely used. There are some more points to note:  \n* We can see that \"**Java**\" and \"**Javascript**\" are also widely used by \"Software engineer\" on the regular basis, as these two languages are often used when buliding website and different software.\n* \"R\" is even more often used by \"Statistician\" than \"Python\", this may because \"R\" is widely used in statistic, therefore \"Statistician\" uses it on a regular basis. \n  \nPython seems to be the essential need if we need to take up data science related roles, however, if we are interested in being \"Statistician\" or \"Software engineer\", we should not forget about the importance of \"R\", \"Java\" and \"Javascript\"."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import plotly.express as px\n\ndf = pd.DataFrame({'Language': worker.Q8.value_counts().index, 'counts': list(worker.Q8.value_counts())})\nfig = px.pie(df, values='counts', names='Language')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\"**Python**\" is the top 1 recommended by the experienced respondents to beginner, followed by \"R\" and \"SQL\". This is similar to the frequency that the languages are used, as experienced respondents may consider the practical usage of the languages. Also, \"Python\" is relatively easy to learn and understand, that's may be another reason the experienced recommend it to us."},{"metadata":{},"cell_type":"markdown","source":"**(2) Integrated development environments (IDE's)**  "},{"metadata":{},"cell_type":"markdown","source":"When we start coding, we will use the IDE's frequently, that is where we write our code, a popular and nice IDE's will enhance our efficiency and save us a lot of time. We can take the IDE's that used most frequently on regular basis as reference, and choose a better one when we use it on our own."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def get_df(question_list,col_name, title, x_rotate=20):\n    #create the final data frame here first\n    df=pd.DataFrame(columns=col_name)\n    job_counts = []\n    for i in job_list:\n        #create df with one job title & question9 only\n        temp = worker[(worker[\"Q5\"]==i)]\n        job_counts.append(len(temp))\n        temp_list=question_list\n        temp_df=temp[temp_list]\n        temp_df.columns=col_name\n        #create raw date of programming language\n        temp_raw=list()\n        for j in col_name:\n            temp1=temp_df[j].notnull().sum()\n            temp_raw.append(temp1)\n        df.loc[i]=temp_raw\n        \n    y_label = list(df.index)\n    x_label = list(df.columns)\n    \n    temp_df = df.copy()\n    temp_df['counts'] = job_counts\n    for col in temp_df.columns:\n        temp_df[col] = temp_df[col] / temp_df['counts'] * 100\n    del temp_df['counts']\n\n    ax = sns.heatmap(np.array(temp_df).astype('float32'), cmap=\"YlGnBu\", annot=True)\n    ax.set_yticklabels(y_label, rotation=0)\n    ax.set_xticklabels(x_label, rotation=x_rotate)\n    ax.axes.set_title(title,fontsize=18)\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#integrated development environments (IDE's) use on a regular basis\nquestion9=['Q9_Part_1','Q9_Part_2','Q9_Part_3','Q9_Part_4','Q9_Part_5','Q9_Part_6','Q9_Part_7','Q9_Part_8','Q9_Part_9','Q9_Part_10','Q9_Part_11','Q9_OTHER']\nide_list=['Jupyter','RStudio','Visual Studio','VSCode','PyCharm','Spyder','Notepad++', 'Sublime','Vim, Emacs','MATLAB','None','Other']\ntitle = 'IDE used by occupation (%)'\ndf_freq_ide=get_df(question9,ide_list, title)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\"**Jupyter**\" is the most popular, followed by \"RStudio\", \"VSCode\", \"PyCharm\" and \"Notepad++\". There are some points to note:\n* \"**RStudio**\" is widely used on regular basis by \"Statistician\", as they use \"R\" regularly.\n* \"**Notepad++**\" is also often used among \"DBA/Database Engineer\", \"Data engineer\" and \"Software enginee\", it may because the enviornment is more suitable and convenient for the programming languages they are using.\nIf we are planning to engage in certain job, we can also try to get familiar with the IDE's that the experienced respondents are using."},{"metadata":{},"cell_type":"markdown","source":"**(3) Data visualization library**"},{"metadata":{},"cell_type":"markdown","source":"Data visualization is important, it turns our data into graphs, which can clearly present our findings to audience, and let them catch the main point quickly. Data visualization libraries can help us to visualize data quickly and nicely, we can find out some popular visualization libraries from the below graph."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#data visualization libraries or tools use on a regular basis\nquestion14=['Q14_Part_1','Q14_Part_2','Q14_Part_3','Q14_Part_4','Q14_Part_5','Q14_Part_6','Q14_Part_7','Q14_Part_8','Q14_Part_9','Q14_Part_10','Q14_Part_11','Q14_OTHER']\nvisual_lib_list=['Matplotlib','Seaborn','Plotly', 'Ggplot', 'Shiny','D3js','Altair','Bokeh','Geoplotlib','Leaflet / Folium','None','Other']\ntitle = 'Visualization tools used by occupation (%)'\ndf_freq_visual_lib=get_df(question14,visual_lib_list, title)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**\"Matplotlib**\" is the most frequently used visualization library, followed by Seaborn, Ggplot and Plotly, these libraries can help us draw most of the widely used graph, such as: heatmap(the graph I used here), bar chart, pie chart, scattered plot, etc.. Let's highlight some points below:\n* \"**Ggplot**\" is heavily relied by the \"Statistician\", this may because it has some nice function for Statistic usage. People who are planning to dive into statistic can take a look at this library.\n* We can also see there are quite a number of people from most jobs chose \"**None**\" here, this may imply that they do not have to work on the data visualization part. However, there are three groups of respondents which have a relatively low proportion in choosing \"None\", \"**Machine learning Engineer**\", \"**Research scientist**\" and \"**Data scientist**\", this somehow imply data visualization is somehow inevitable in these kinds of job, if you want to be any one of these jobs, you should master data visualization."},{"metadata":{},"cell_type":"markdown","source":"**(4) Machine Learning**"},{"metadata":{},"cell_type":"markdown","source":"Machine learning is widely used in the data science world while predicting, analyzing, etc., it can help us to build complex model, we can see some of the frequently used algorithms here, and there are some frameworks that can help us to do so."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#ML framework use on a regular basis\nquestion16=['Q16_Part_1','Q16_Part_2','Q16_Part_3','Q16_Part_4','Q16_Part_5','Q16_Part_6','Q16_Part_7','Q16_Part_8','Q16_Part_9','Q16_Part_10','Q16_Part_11','Q16_Part_12','Q16_Part_13','Q16_Part_14','Q16_Part_15','Q16_OTHER']\nml_framework_list=['Scikit-learn','TensorFlow','Keras','PyTorch','Fast.ai','MXNet','Xgboost','LightGBM','CatBoost' ,'Prophet','H2O3','Caret','Tidymodels','JAX','None','Other']\ntitle = 'ML framework used by occupation (%)'\ndf_freq_ml_framework=get_df(question16,ml_framework_list, title)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**\"Scikit-learn\"** is the most popular, but many other frameworks are also widely used. It is worth to mention that there is a number of \"Statistician\" chose \"none\", which means they are not using these framework, but then we can see that they actually uses a lot of Machine learning algorithms, if you are interested in \"Statistician\" role, you may have to figure out more about this."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#ML algorithms use on regular basis\nquestion17=['Q17_Part_1','Q17_Part_2','Q17_Part_3','Q17_Part_4','Q17_Part_5','Q17_Part_6','Q17_Part_7','Q17_Part_8','Q17_Part_9','Q17_Part_10','Q17_Part_11','Q17_OTHER']\nml_algorithm_list=['Linear / Logistic','Decision Trees / Random Forests','Gradient Boosting Machines','Bayesian','Evolutionary Approaches','Dense Neural Networks','CNN','GAN','RNN','Transformer Networks','None','Other']\ntitle = 'ML algorithms used by occupation (%)'\ndf_freq_ml_algorithm=get_df(question17,ml_algorithm_list, title, x_rotate=90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In generel, \"**Linear or Logistic Regression**\" and \"**Decision Trees or Random Forests**\" are the most often used algorithms, followed by \"**Gradient Boosting Machines (xgboost, lightgbm, etc)**, \"**Bayesian Approaches**\" and \"**Convolutional Neural Networks(CNN)**\", we can tell from the result that the mentioned algorithms are important in handling the job duties of most data science roles, we should probably invest more time on learning and practising these algorithms. Here are some highlights we can take a look at:\n\n*  Most of the algorithms are used by \"Data Scientist\", \"Research scientist\" and \"Machine Learning engineer\" on regular basis, this implies that we should not only focus on the widely used ones by the majority, but to gain deeper understanding of various algorithms so as to handle these jobs.\n* \"**Convolutional Neural Networks(CNN)**\" are used quite often among most of the roles, however, we notice that the proportion of \"Data analyst\", \"Business analyst\", \"Statistician\" and \"DBA/Database\" that often use \"**CNN**\" is significantly lower than the other roles. This may be because of \"**CNN**\" usually use on **computer vision** and **natural language processing** but not analyzing data for insights that influence products or business decisions, which takes up a large part of their job duties(referring to the job nature part). \n  \nWhen we are planning on study various algorithms, we should take this into consideration, it is always great to learn as many as we can, but if sometimes we are limited by time and other resources, we can then prioritize those are more critical according to our goals and purposes."},{"metadata":{},"cell_type":"markdown","source":"**(5) Computer vision**"},{"metadata":{},"cell_type":"markdown","source":"Computer vision is to analyze, process and understand image, we can see from below which role uses computer vision methods more often."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#computer vision methods use on a regular basis\nquestion18=['Q18_Part_1','Q18_Part_2','Q18_Part_3','Q18_Part_4','Q18_Part_5','Q18_Part_6','Q18_OTHER']\ncv_list=['General purpose','Image segmentation methods','Object detection','Image classification and others','Generative Networks','None','Other']\ntitle = 'Computer vision methods used by occupation (%)'\n# df_freq_cv=get_df(question18,cv_list,title, x_rotate=90)\n\n#people that does not use computer vision\npercent_no_cv={'job':[], 'use_cv_ratio':[]}\nfor k in job_list:\n    #create df with one job title & question only\n    temp = worker[(worker[\"Q5\"]==k)]\n    temp_df=temp[question18].reset_index(drop=True)\n    no_cv_count = 0\n#check those not answering this question\n    for i in range(len(temp_df)):\n        c = 0\n        for col in question18:\n            a=temp_df.loc[i, col]\n            if isinstance(a, str):\n                c =+1\n        if c == 0:\n            no_cv_count += 1\n    percent_no_cv['use_cv_ratio'].append(1 - (no_cv_count/len(temp_df)))\n    percent_no_cv['job'].append(k)\n\nno_cv_df = pd.DataFrame(percent_no_cv)\n\nno_cv_df['use_cv_ratio'] = no_cv_df['use_cv_ratio'] * 100\nno_cv_df['no_use_cv_ratio'] = (100 - no_cv_df['use_cv_ratio'])\nno_cv_df = no_cv_df.sort_values(['use_cv_ratio'], ascending=False).reset_index(drop=True)\nsns.set(rc={'figure.figsize':(16,7)})\nno_cv_df.set_index('job').plot.barh(stacked=True, color={'use_cv_ratio':\"#496595\", 'no_use_cv_ratio': \"#c6ccd8\"},\n                                    title='Percentage of CV method used by occupation (%)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**(6) Natural language processing (NLP)**"},{"metadata":{},"cell_type":"markdown","source":"NLP is important and useful, it applies on many thing around us, like our phone voice regconition, online translation, online grammar correction stuff, etc., we will examine which roles deal with NLP more frequently here."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#natural language processing (NLP) methodsuse on a regular basis\nquestion19=['Q19_Part_1','Q19_Part_2','Q19_Part_3','Q19_Part_4','Q19_Part_5','Q19_OTHER']\nnlp_list=['Word embeddings','Encoder-decoder models','Contextualized embeddings','Transformer' ,'None','Other']\ntitle = 'NLP methods used by occupation (%)'\n# df_freq_nlp=get_df(question19,nlp_list, title, x_rotate=90)\n\n#people do not use NLP \npercent_no_nlp={'job':[], 'use_nlp_ratio':[]}\nfor k in job_list:\n    #create df with one job title & question only\n    temp = worker[(worker[\"Q5\"]==k)]\n    temp_df=temp[question19].reset_index(drop=True)\n    no_nlp_count = 0\n#check those not answering this question\n    for i in range(len(temp_df)):\n        c = 0\n        for col in question19:\n            a=temp_df.loc[i, col]\n            if isinstance(a, str):\n                c =+1\n        if c == 0:\n            no_nlp_count += 1\n    percent_no_nlp['use_nlp_ratio'].append(1 - (no_nlp_count/len(temp_df)))\n    percent_no_nlp['job'].append(k)\n\nno_nlp_df = pd.DataFrame(percent_no_nlp)\n\nno_nlp_df['use_nlp_ratio'] = no_nlp_df['use_nlp_ratio'] * 100\nno_nlp_df['no_use_nlp_ratio'] = (100 - no_nlp_df['use_nlp_ratio'])\nno_nlp_df = no_nlp_df.sort_values(['use_nlp_ratio'], ascending=False).reset_index(drop=True)\nsns.set(rc={'figure.figsize':(16,7)})\nno_nlp_df.set_index('job').plot.barh(stacked=True, color={'use_nlp_ratio':\"#496595\", 'no_use_nlp_ratio': \"#c6ccd8\"},\n                                    title='Percentage of NLP method used by occupation (%)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compare to **data visualization** and **machine learning**(over 50% usage of all jobs), **computer vision(CV)** and **natural language processing(NLP)** are used not that often, less than **50%** of respondents from most of the categories use CV and NLP methods on regular basis. The result tells us that some of the jobs may not apply CV and NLP that often, it is good to learn and practise these knowledge and skills, but if we are planning on developing a career in roles that do not have to use CV and NLP methods on regular basis, we can focus more on other data science skills so as to enhance our competitiveness in those particular roles. Below are something worth to notice:  \n* It is worth to notice that \"**Data analyst**\", \"**Business analyst**\", \"**Statistician**\" and \"**DBA/Database engineer**\" are less likely to use NLP and CV methods, as their jobs duties are mainly analyzing and interpret data and turn them into valuable insights for the sake of influencing products or business decisions(referring to the job nature part). In addition, NLP and CV are more advanced data science knowledge, requiring us to have deeper understanding of the usage of some complex algorithms, which  \"**Data Scientist**\", \"**Research scientist**\" and \"**Machine Learning engineer**\" are the ones who often deal with them, meaning these three kinds of jobs required relatively high proficiency of related skills and knowledge, that's may be one of the reasons that their general education levels are higher than other roles(referring to the basic education information part)."},{"metadata":{},"cell_type":"markdown","source":"# Conclusion"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Through examinating the experienced Kaggler in the data science world, I hope all of us, the beginner, can get some insights and clues when formulating our own learning direction and plans, at least get to know some of the job nature and functions, programming language we can start from and the usage of various data science skills and knowledge of different data science related roles. This notebook is not perfect, but I did learn and practise a lot while working on it, as well as understanding more about the data science world, let's keep working on it!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}