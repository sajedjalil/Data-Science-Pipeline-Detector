{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 align=\"center\"> IS DATA SCIENCE A RISING CAREER IN 2020? </h1>\n<h1 align=\"center\"> PART I: EDUCATION LEVEL </h1>\n<img align = \"center\" src=\"https://i.postimg.cc/zv50Hrh9/data-science-rising-career.jpg\" width=500>\n\n\n<h3> \n    Hello to all experts on Kaggle. I am a new member and would love to hear and learn from all of you. In this Notebook, I try to create functions that can be reusable to check or extract additional information according to the user's preferences and requirements. We hope to receive your recommendations to make my notebook more complete, your comments will be the motivation for me to continue working on the next notebooks. <h3>\n    \n\n<h3> Based on the current database (survey questions), we can divide the survey content into 8 topics related to data science. Before going to discuss each topic, I will try firstly to creat some generic functions.\n    <h3>","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/kaggle-survey-2020/kaggle_survey_2020_responses.csv')","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)\ndf.head(2)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_rows', None)\ndf.T.iloc[:,0]","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The database is extracted into: the \"questions\" and the \"data\" (which is used in this Notebook)","metadata":{}},{"cell_type":"code","source":"question = df.iloc[0,:]\ndf = df.iloc[1:,:]\ndf['Q12_Part_1'].head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3> The database contain all objects, not numerical data. We use the following function to count the data in each column, base on the column name and the gender (Man or Woman). The coldat0 is used to collect column data and coldat2 is used to separately collect data for Man and Woman.<h3>","metadata":{}},{"cell_type":"code","source":"def coldat0(serie):\n    X0 = df[[i for i in df.columns if serie in i]]\n    X = pd.Series(dtype='int')\n    for i in X0.columns:\n        X[X0[i].value_counts().index[0]] = X0[i].count()\n    return X.sort_values()\ndef coldat2(serie):\n    dman = df[(df['Q2']=='Man').values]\n    dwoman = df[(df['Q2']=='Woman').values]  \n    man0 = dman[[i for i in df.columns if serie in i]]\n    man = pd.Series(dtype='int')\n    woman0 = dwoman[[i for i in df.columns if serie in i]]\n    woman = pd.Series(dtype='int')\n    for i in man0.columns:\n        man[man0[i].value_counts().index[0]] = man0[i].count()\n    for i in woman0.columns:\n        woman[woman0[i].value_counts().index[0]] = -woman0[i].count()    \n    return man.sort_values(), woman.sort_values()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3> The first graphical type we want to plot is the DISTRIBUTION. The Plot_dix function bellow has been created for such purpose.<h3>","metadata":{}},{"cell_type":"code","source":"def Plot_dix(title, serie, order):\n    check = ['Q7', 'Q9', 'Q10', 'Q12', 'Q14', 'Q16', 'Q17', 'Q18', 'Q19', 'Q23','Q26_A','Q26_B','Q27_A','Q27_B','Q28_A','Q28_B',\n             'Q29_A','Q29_B', 'Q31_A', 'Q31_B','Q33_A','Q33_B', 'Q34_A', 'Q34_B','Q35_A','Q35_B','Q36', 'Q37', 'Q39']\n        \n    f = plt.figure(figsize=(24,7)) \n    \n    ax=f.add_subplot(121)\n    if serie in check:\n        X = coldat0(serie)\n    else:\n        X = df[serie].value_counts()[order]\n    ax.bar(X.index, X, width=0.4,edgecolor='darkgreen', color='grey',linewidth=0.7)\n    ma = round(X.max()+1000,3) * 0.02\n    for i in X.index:\n        ax.annotate(f\"{X[i]}\", xy=(i, X[i] + ma), va = 'center', ha='center',fontweight='light', fontsize=12, fontfamily='serif',color='black')\n    ax.set_xticklabels(X.index, fontfamily='serif',rotation=90, fontweight='bold', fontsize=14)\n    f.text(0.1, 0.95, title, fontsize=16, fontweight='bold', fontfamily='serif')   \n    ax.grid(axis='y', linestyle='-', alpha=0.4)\n\n    ax=f.add_subplot(122)    \n    if serie in check:\n        man, woman = coldat2(serie)\n    else:\n        dman = df[(df['Q2']=='Man').values]\n        dwoman = df[(df['Q2']=='Woman').values]\n        man = dman[serie].value_counts()[order]\n        woman = -dwoman[serie].value_counts()[order]\n    mp = round(man.max()+1000,3) * 0.02\n    mn = - round(woman.min()-1000,3) * 0.05\n    ax.bar(man.index, man, width=0.4, color='green', alpha=0.8, label='Man')\n    ax.bar(woman.index, woman, width=0.4, color='red', alpha=0.8, label='Woman')\n    for i in man.index:\n        ax.annotate(f\"{man[i]}\", xy=(i, man[i] + mp),va = 'center', ha='center',fontsize=12,fontfamily='serif',color='black')\n    for i in woman.index:\n        ax.annotate(f\"{-woman[i]}\", xy=(i, woman[i] - mn), va = 'center', ha='center',fontsize=12,fontfamily='serif',color='black')    \n    \n    ax.set_xticklabels(man.index, fontfamily='serif', rotation =90, fontweight='bold', fontsize=14)\n    ax.legend()\n    f.text(0.55, 0.95, title + '\\n of man vs woman', fontsize=16, fontweight='bold', fontfamily='serif')  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In order to have the list of order, it's quite simple by using:","metadata":{}},{"cell_type":"code","source":"list(df['Q1'].unique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3> The second graphical type we might need to use is the heatmap. A combination of Pivot_table and heatmap plot has been created. <h3>","metadata":{}},{"cell_type":"code","source":"def Plot_heatmap(title, serie1, order1, serie2, order2):\n    df['count'] = 1\n    fig, ax = plt.subplots(1, 1, figsize=(15, 15))\n\n    sns.heatmap(pd.pivot_table(df, values='count', index=[serie1], columns=[serie2], aggfunc=np.sum).loc[order1, order2],cmap='viridis', square=True, linewidth=3, cbar=False, ax=ax,annot=True, fmt='n')\n    \n    fig.text(0.4, 1, title, fontweight='bold', fontfamily='serif', fontsize=15)\n    ax.set_yticklabels(ax.get_yticklabels(), fontfamily='serif', rotation = 0, fontsize=12)\n    ax.set_xticklabels(ax.get_xticklabels(), fontfamily='serif', rotation = 90, fontsize=12)\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3> A third illustration to show the dependency between two series data was also generated by calling the Plot_muldix function. <h3>","metadata":{}},{"cell_type":"code","source":"def Plot_Muldix(title, serie1, serie2, order2):\n    didj = pd.pivot_table(df, values='count', index=[serie1], columns=[serie2], aggfunc=np.sum).fillna(0).astype(int).loc[:,order2]\n    didj = (didj.T / didj.sum(axis=1))\n    \n    fig, ax = plt.subplots(len(didj.columns),1,figsize=(13, 25), sharex=True)\n    for idx2, idx1 in enumerate(didj.columns):\n        ax[idx2].text(-1.6 ,0 ,idx1, fontfamily='serif', fontsize=11,ha=\"right\")\n        ax[idx2].bar(didj[idx1].index, didj[idx1], color='green', edgecolor='black', linewidth=0.6, width=0.6)\n        ax[idx2].set_yticks([])\n    \n    fig.text(0.13, 0.90, title, fontsize=17, fontweight='bold', fontfamily='serif') \n    plt.subplots_adjust(hspace=0)\n    ax[-1].set_xticklabels(order2, fontfamily='serif', rotation=90)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h3> And finally, the distribution plot of two series of data has been also created for a single illustration or for a distinguished (gender) plot.","metadata":{}},{"cell_type":"code","source":"# https://stackoverflow.com/questions/56337732/how-to-plot-scatter-pie-chart-using-matplotlib\ndef drawPieMarker(xs, ys, ratios, sizes, colors, ax):\n    markers = []\n    previous = 0\n    # calculate the points of the pie pieces\n    for color, ratio in zip(colors, ratios):\n        this = 2 * np.pi * ratio + previous\n        x  = [0] + np.cos(np.linspace(previous, this, 30)).tolist() + [0]\n        y  = [0] + np.sin(np.linspace(previous, this, 30)).tolist() + [0]\n        xy = np.column_stack([x, y])\n        previous = this\n        markers.append({'marker':xy, 's':np.abs(xy).max()**2*np.array(sizes), 'facecolor':color})\n    # scatter each of the pie pieces to create pies\n    for marker in markers:\n        ax.scatter(xs, ys, **marker, alpha=0.7)\n\ndef Pivot_ij(serie1, serie2, order1, order2):\n    return pd.pivot_table(df, values='count', index=[serie1], columns=[serie2],aggfunc=np.sum).fillna(0).astype(int).loc[order1, order2].stack()\n\ndef Pivot_ijk(serie1, serie2, order1, order2, gender):\n    return pd.pivot_table(df[df['Q2']==gender], values='count', index=[serie1], columns=[serie2],aggfunc=np.sum).fillna(0).astype(int).loc[order1, order2].stack()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Plot_matrix0(title, serie1, serie2, order1, order2):\n    \n    fig = plt.figure(figsize=(20, 23), dpi=200)\n    gs = fig.add_gridspec(5, 5)\n\n    ax_plot = fig.add_subplot(gs[1:4, 0:4]) \n    data_ij = Pivot_ij(serie1, serie2, order1, order2)   \n    for idx1 in order1[::-1]:\n        for idx2 in order2:\n            dat = data_ij[idx1][idx2]\n            ax_plot.scatter(idx2, idx1, s=dat, color='darkblue')\n    ax_plot.grid(linewidth=0.2, zorder=0)        \n    ax_plot.set_yticklabels(idx1, fontfamily='serif', fontsize=15)\n    ax_plot.set_xticklabels(idx2, fontfamily='serif', fontsize=15, rotation=90)\n# Pos\n    ax_pos = fig.add_subplot(gs[0, :4], sharex=ax_plot) \n    data_j = df[serie2].value_counts()[order2]\n    ax_pos.bar(data_j.index, data_j, width=0.35, alpha=0.85, color='darkblue')\n    plt.setp(ax_pos.get_xticklabels(), visible=False)\n# Exp\n    ax_exp = fig.add_subplot(gs[1:4, 4], sharey=ax_plot) \n    data_i = df[serie1].value_counts()[order1]\n    ax_exp.barh(data_i.index[::-1], data_i[::-1], height=0.35, alpha=0.85, color='darkblue')\n    plt.setp(ax_exp.get_yticklabels(), visible=False)\n# Spines\n    for s in ['top', 'left', 'right', 'bottom']:\n        ax_plot.spines[s].set_visible(False)\n        ax_pos.spines[s].set_visible(False)\n        ax_exp.spines[s].set_visible(False)\n    fig.text(0.8, 0.9, title, fontweight='bold', fontfamily='serif', fontsize=35, ha='right') \n    plt.tight_layout()\n    plt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Plot_matrix2(title, serie1, serie2, order1, order2):\n    \n    data_ij = Pivot_ij(serie1, serie2, order1, order2)\n    data_ij_man = Pivot_ijk(serie1, serie2, order1, order2, 'Man')\n    data_ij_woman = Pivot_ijk(serie1,serie2, order1, order2, 'Woman')\n\n    fig = plt.figure(figsize=(20, 23), dpi=200)\n    gs = fig.add_gridspec(5, 5)\n    ax_plot = fig.add_subplot(gs[1:4, 0:4])\n    for idx1 in order1[::-1]:\n        for idx2 in order2:\n            man = data_ij_man[idx1][idx2]\n            woman = data_ij_woman[idx1][idx2]\n            manwoman = data_ij[idx1][idx2]\n            drawPieMarker([idx2],[idx1], [man/(man+woman), woman/(man+woman)] ,[manwoman*3], ['darkblue', '#990000'], ax=ax_plot)\n    ax_plot.grid(linewidth=0.2, zorder=0)        \n    ax_plot.set_yticklabels(idx1, fontfamily='serif', fontsize=15)\n    ax_plot.set_xticklabels(idx2, fontfamily='serif', fontsize=15, rotation=90)\n    ax_pos = fig.add_subplot(gs[0, :4], sharex=ax_plot) \n    data_j_woman = df[df['Q2']=='Woman'][serie2].value_counts()[order2]\n    ax_pos.bar(data_j_woman.index, data_j_woman, width=0.4, alpha=0.7, color='#990000')\n    data_j_man = df[df['Q2']=='Man'][serie2].value_counts()[order2]\n    ax_pos.bar(data_j_man.index, data_j_man, bottom=data_j_woman , width=0.4, alpha=0.7, color='darkblue')\n    plt.setp(ax_pos.get_xticklabels(), visible=False)\n# Exp\n    ax_exp = fig.add_subplot(gs[1:4, 4], sharey=ax_plot) \n    data_i_woman = df[df['Q2']=='Woman'][serie1].value_counts()[order1]\n    ax_exp.barh(data_i_woman.index[::-1], data_i_woman[::-1], height=0.4, alpha=0.7, color='#990000')\n    data_i_man = df[df['Q2']=='Man'][serie1].value_counts()[order1]\n    ax_exp.barh(data_i_man.index[::-1], data_i_man[::-1], left= data_i_woman[::-1],height=0.4, alpha=0.7, color='darkblue')\n    plt.setp(ax_exp.get_yticklabels(), visible=False)\n    fig.text(0.7, 0.9, title, fontweight='bold', fontfamily='serif', fontsize=20, ha='right') \n    plt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Input parameter preparation ...","metadata":{}},{"cell_type":"code","source":"q1order = ['18-21','22-24', '25-29', '30-34', '35-39', '40-44', '45-49', '50-54','55-59', '60-69', '70+']\nq3order = ['India','United States of America','Brazil','Japan','Russia',\n           'United Kingdom of Great Britain and Northern Ireland','Nigeria','China','Germany','Turkey',\n           'Spain','France','Canada','Indonesia','Pakistan','Taiwan','Italy','Australia','Mexico', 'South Korea']\nq4order = ['I prefer not to answer','No formal education past high school','Professional degree','Some college/university study without earning a bachelor’s degree',\n    'Bachelor’s degree','Master’s degree','Doctoral degree']\nq5order =['Currently not employed', 'Student','Data Analyst','Business Analyst', 'Data Scientist','Software Engineer',\n          'Research Scientist', 'Machine Learning Engineer', 'Product/Project Manager', 'Data Engineer', 'Statistician',\n          'DBA/Database Engineer','Other']\nq6order = ['I have never written code','< 1 years','1-2 years','3-5 years', '5-10 years', '10-20 years', '20+ years']\nq7order = ['Python','R','SQL','C','C++','Java','Javascript','Julia','Swift','Bash','MATLAB','None','Other']\nq8order = ['Python','R','C++','SQL','Java','MATLAB','C','Javascript','Julia','Swift','Bash','None','Other']\nq9order = ['None','Other']\nq10order = ['None','Other']\nq11order = ['A personal computer or laptop','A cloud computing platform (AWS, Azure, GCP, hosted notebooks, etc)',\n            'A deep learning workstation (NVIDIA GTX, LambdaLabs, etc)','None','Other']\nq12order = ['GPUs','TPUs','None']\nq13order = ['Never','Once','2-5 times','6-25 times','More than 25 times']\nq14order = ['Matplotlib','Seaborn','Plotly / Plotly Express','Ggplot / ggplot2','Shiny','D3 js','Altair','Bokeh','Geoplotlib','Leaflet / Folium','None','Other']\nq15order = ['I do not use machine learning methods','Under 1 year','1-2 years','2-3 years','3-4 years','4-5 years',\n            '5-10 years','10-20 years','20 or more years']\nq16order = ['None']\nq17order = ['Linear or Logistic Regression','Decision Trees or Random Forests','Gradient Boosting Machines (xgboost, lightgbm, etc)',\n            'Bayesian Approaches','Evolutionary Approaches', 'Dense Neural Networks (MLPs, etc)','Convolutional Neural Networks',\n            'Generative Adversarial Networks','Recurrent Neural Networks','Transformer Networks (BERT, gpt-3, etc)','None','Other']\nq18order = ['None']\nq19order = ['None']\nq20order = ['0-49 employees','50-249 employees','250-999 employees','1000-9,999 employees','10,000 or more employees']\nq21order = ['0','1-2','3-4','5-9','10-14','15-19','20+']\nq22order = ['We use ML methods for generating insights (but do not put working models into production)',\n            'We recently started using ML methods (i.e., models in production for less than 2 years)',\n            'We have well established ML methods (i.e., models in production for more than 2 years)',\n            'We are exploring ML methods (and may one day put a model into production)',\n            'No (we do not use ML methods)','I do not know']\nq23order = ['Analyze and understand data to influence product or business decisions',\n            'Build prototypes to explore applying machine learning to new areas',\n            'Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data',\n            'Build and/or run a machine learning service that operationally improves my product or workflows',\n            'Experimentation and iteration to improve existing ML models',\n            'Do research that advances the state of the art of machine learning',\n            'None of these activities are an important part of my role at work']\nq24order = ['$0-999', '1,000-1,999', '2,000-2,999', '3,000-3,999', '4,000-4,999', '5,000-7,499', '7,500-9,999',\n'10,000-14,999','15,000-19,999', '20,000-24,999', '25,000-29,999', '30,000-39,999', '40,000-49,999', '50,000-59,999', '60,000-69,999', '70,000-79,999', '80,000-89,999', '90,000-99,999',\n'100,000-124,999', '125,000-149,999',  '150,000-199,999', '200,000-249,999',  '250,000-299,999', '300,000-500,000', '> $500,000']\nq25order = ['$0 ($USD)','$1-$99','$100-$999','$1000-$9,999','$10,000-$99,999','$100,000 or more ($USD)']\nq26aorder = ['None']\nq27aorder = ['None']\nq28aorder = ['None']\nq29aorder = ['None']\nq30order = ['MySQL ','PostgresSQL ','Microsoft SQL Server ','MongoDB ','Oracle Database ','Google Cloud BigQuery ',\n           'SQLite ','Amazon Redshift ','Microsoft Azure Data Lake Storage ','Amazon Athena ','Snowflake ',\n           'IBM Db2 ','Amazon DynamoDB ','Google Cloud SQL ','Microsoft Access ','Google Cloud Firestore ','Other']\nq31aorder = ['None','Other']\nq32order = ['Microsoft Power BI','Tableau','Google Data Studio','Other','SAP Analytics Cloud ','TIBCO Spotfire',\n            'Qlik','Salesforce','Looker','Amazon QuickSight','Alteryx ','Domo']\nq33aorder = ['None','Other']\nq34aorder = ['None','Other']\nq35aorder = ['None','Other']\nq36order = ['None','Other']\nq37order = ['None','Other']\nq38order = ['Local development environments (RStudio, JupyterLab, etc.)',\n            'Basic statistical software (Microsoft Excel, Google Sheets, etc.)',\n            'Business intelligence software (Salesforce, Tableau, Spotfire, etc.)',\n            'Cloud-based data software & APIs (AWS, GCP, Azure, etc.)',\n            'Advanced statistical software (SPSS, SAS, etc.)','Other']\nq39order = ['None','Other']","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<H3> Let's start <h3>\n    \n <h3> Topic 1: General information <h3>\n\n    Q1: What is your age (# years)?\n    Q2: What is your gender?\n    Q3: In which country do you currently reside?","metadata":{}},{"cell_type":"code","source":"Plot_dix('Age distribution','Q1',q1order)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that, in 2020, more than 55% of the total is under 30 years old and nearly 80% are Man.","metadata":{}},{"cell_type":"code","source":"Plot_dix('Residence contry distribution','Q3',q3order)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Distribution for the top 20 countries in the number of responses. India is still the \"top\" contry in number, and then the US. \nThe rate of woman is around 20-25%.","metadata":{}},{"cell_type":"markdown","source":"**<h3> Topic 2. Education and coding experience <h3>**\n    + Q4: What is the highest level of formal education that you have attained or plan to attain within the next 2 years?\n    + Q6: For how many years have you been writing code and/or programming?\n    + Q37_Part_1: On which platforms have you begun or completed data science courses?","metadata":{}},{"cell_type":"code","source":"Plot_dix('Current education level or plan to attain (next 2 years) distribution','Q4',q4order)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wow, this data is quite supprising, over 75% earned bachelor or master degree. Upto 40% are masters and 12% are PhD holders.\n\nA question can be posed here: is the \"career switch\" to Data Science from other scientific or technical fields dominate? How many percent of people graduated from computer science in this group?","metadata":{}},{"cell_type":"code","source":"Plot_heatmap('Pivot Table : Education & Country', 'Q3', q3order, 'Q4',  q4order)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In almost country, there are the most masters.","metadata":{}},{"cell_type":"code","source":"Plot_dix('Writing code and/or programming experience','Q6',q6order)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You see, there are over 70% of people with less than 5 years of working and 47% with more than 2 years. Meanwhile, MANY EMPLOYERS require applicants to have more than 5 years of experience to be recruited.","metadata":{}},{"cell_type":"code","source":"Plot_heatmap('Pivot Table : Education & coding experience', 'Q6',  q6order, 'Q4', q4order)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most of Data Expert are graduated or after-graduated and having 1-5 years of coding experience.","metadata":{}},{"cell_type":"code","source":"Plot_matrix2('Gender & Education & Age','Q1','Q4',q1order, q4order)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Most people are very young (<30), bachelor degree holders, women aged 24-30 with master degree are majority, while men, by contrast, maybe women are diligent and braver than men when continuing to master.\n\nThe first step in your journey to becoming a data scientist is probably to choose some form of education or courses to enhance your knowledge. But how do you know what kind of education you need or where to find related courses?","metadata":{}},{"cell_type":"code","source":"Plot_dix('Platforms to begin or complete data science courses','Q37',q37order)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As observed in 2019, a majority of them, 21%, have used Coursera’s data science courses. unlike last year, Kaggle has surpassed University, Udemy, and Datacamp to become the second choice for beginners. Congratulations to Kaggle on this outstanding achievement.","metadata":{}},{"cell_type":"markdown","source":"**<h3> Topic 3. Job position & company<h3>**\n    + Q5: Select the title most similar to your current role (or most recent title if retired)?\n    + Q20: What is the size of the company where you are employed?\n    + Q21: Approximately how many individuals are responsible for data science workloads at your place of business?\n    + Q24: What is your current yearly compensation (approximate $USD)?","metadata":{}},{"cell_type":"code","source":"Plot_dix('Current job position distribution','Q5',q5order)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After \"Student\", \"Data Scientist\" is the most common job role.\nThe \"Unemployed\" rate is 8.5%, if including the \"Student\" rate, this rate is: 35%. Rub.","metadata":{}},{"cell_type":"code","source":"Plot_dix('Size of data science company', 'Q20', q20order)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"However, the data gives hope for those are new to this industry, with job-opportunities highest is in small companies (<50 employees). Besides, the opportunity to enter large companies is also optimistic.","metadata":{}},{"cell_type":"code","source":"Plot_dix('Number of individuals are responsible for data science workloads', 'Q21', q21order)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"But, it's probably note that, to enter the \"big\" company, \"team work\" could be an important requirement in the data science. That's nice that in the big team, we have both gender.","metadata":{}},{"cell_type":"code","source":"Plot_dix('Yearly compensation distribution ($USD)', 'Q24', q24order)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And of course, income is always the most concerned question. This distribution is very interesting, it has not a clear tendency, showing several picks. And at the very high paying rate, there is NO WOMAN, are these positions very stressful?\nSo, what factors are related to the salary?","metadata":{}},{"cell_type":"code","source":"Plot_Muldix('Pivot Table : Compensation & Contry', 'Q3', 'Q24', q24order)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The HIGH PICK salary is found in: USA, UAE, Switzeland, Israel, Canada and Austraylia. Is the data science industry very developed in these countries or is it due to differences in average income by country?","metadata":{}},{"cell_type":"code","source":"Plot_Muldix('Pivot Table : Compensation & Working experience', 'Q6', 'Q24', q24order)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Wow, that's suprising, is'nt it? Even you have < 5 years of experience, you could have chance to be paid up to > $250,000 yearly. Amazing. ","metadata":{}},{"cell_type":"code","source":"Plot_matrix2('Gender & Education & Salary','Q24','Q4',q24order, q4order)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And with a Master's degree, you can have a higher chance of succeeding in career development and earning an admirable salary.","metadata":{}},{"cell_type":"markdown","source":"... to be continued in Part 2.","metadata":{}}]}