{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport plotly.graph_objects as go \nimport plotly.express as px \nimport seaborn as sns\nimport scipy.stats as stats\nfrom math import sqrt\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>First notebook</h1>\n\nIn this notebook I will try to answer a really simple question.\nWho was fastest in answering the survey.\n\nThis might seem like a silly question to answer, and I agree!\nBut seeing as this is my first attempt it seem like a good start, and I will hopefully learn from writing this words and untill it is published. \nAny feedback is welcome! And please upvote if you feel like I deserve it :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/kaggle-survey-2020/kaggle_survey_2020_responses.csv')\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Removing top row\ndf_fin = df.iloc[1:,:]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_fin","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This turned out to be way more difficult than I first imagined. I made some scatter plots which failed to render, and the ones that did looked terrible because of the spread in the data. I think now it might be because I don't really at this point have a clear picture of what I want to find out. I am leaving in my fumbling because I want this notebook to show my progress and process, or lack thereof. \n\nSo here I am, thinking aloud with words. What I want to do is split the data into series for each country. I then want to see how well those countries does it by looking at averages, spread (and more? I'm still learning this as well). This is bloody difficult, but at least it's still fun :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Want to know how many unique countries there are\ncountries = df_fin[\"Q3\"]\ncountryList = []\nfor country in df_fin[\"Q3\"]:\n    if not country in countryList:\n        countryList.append(country)\n\nprint(len(countryList))\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So this approach did work. I wanted to know how many countries there are, and this did the job. \n\nI also wanted to make one series for each country, and each series containing each of the times. I don't at this point fully understand how, or why my attempts didn't work, so i continue struggling with this. "},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\ni = 0\ncounter = 0\ndf_countryAndTimes = pd.DataFrame()\n\nfor country in df_fin[\"Q3\"]:\n    temp_array = []\n    i = 0\n    for temp_country in df_fin[\"Q3\"]:\n        if temp_country == country:\n            time = int(df_fin.iloc[i,0])\n            temp_array.append(time)\n        i += 1\n    df_temp = pd.DataFrame({country:temp_array})\n    df_countryAndTimes = df_countryAndTimes.append(df_temp)\n\n\"\"\"\n  \n\n \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This was kind of hillarious. This code ran for foreeever! And it made a dataframe, but something felt off about it.  It showed that out of about 20 000 answers, 3 million were from India. Trying again! But! I felt like I was on the right track, I just needed to fix ... something "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Make dataframe with countries and times, and also filter out times that are above 3600. If you spend more than one hour, it doesnt count. (Arbitrary limit is arbitrary)\n\ncountriesCompleted = []\ndf_countryAndTimes = pd.DataFrame()\n\nfor country in df_fin[\"Q3\"]:\n    if not country in countriesCompleted:\n        countriesCompleted.append(country)\n        temp_array = []\n        i = 0\n        for temp_country in df_fin[\"Q3\"]:\n\n            if temp_country == country:\n                time = int(df_fin.iloc[i,0])\n                if time < 3600:\n                    temp_array.append(time)\n            i += 1\n        df_temp = pd.DataFrame({country:temp_array})\n        df_countryAndTimes = df_countryAndTimes.append(df_temp)\n\ndf_countryAndTimes =pd.concat([pd.Series(df_countryAndTimes[c].dropna().values, name=c) for c in df_countryAndTimes], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_countryAndTimes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally it worked! And wow! More than 25% of the answers were from India, cool! But this approach did work! Now to try and do something with the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_countryAndTimes.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I see that there is a lot of variety in the data. I also notice a lot of outliers. I assume a lot of them are because people forgot about the survey, or got distracted? So I decide to set a max limit on 3600 seconds. If you use more than one hour, you are disqualified. Let's see if I can do that.\n\nNarrator: \"He did not.\"\n\nSo I wrote this text before I did the fix. I decided to disqualify the above 3600s when I generated the dataframe. It was a simple solution, but if anyone can show me a better way I would appreciate it. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ctmean = df_countryAndTimes.mean().sort_values(ascending = False)\npd.options.plotting.backend = \"plotly\"\n\n# using Plotly Express via the Pandas backend\nfig1 = df_ctmean.plot.barh(height=1000)\nfig1.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And there we go! The fastest country is Ireland with an average value of 561. Now, I will try to plot the spread of each dataset. With 55 countries this might be messy, but maybe not? "},{"metadata":{"trusted":true},"cell_type":"code","source":"for country in countryList:\n    df_temp = df_countryAndTimes[country].dropna()\n    h = np.asarray(df_temp)\n    h = sorted(h)\n \n    #use the scipy stats module to fit a normal distirbution with same mean and standard deviation\n    fit = stats.norm.pdf(h, np.mean(h), np.std(h)) \n    \n\n    #plot both series on the histogram\n    plt.plot(h,fit,'-',linewidth = 2,label=\"Normal distribution with same mean and var\")\n    plt.hist(h,density = True, bins = 50,label=\"Actual distribution\")  \n    plt.xlabel(country)\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I did it! It isn't very pretty, but I managed to plot every single country with a normal distribution with same values.\n\nFrom this I can see that India has most of their times around 500 seconds, or around 8 minutes. I can also see that China has a lot of answers which take more than 1000 seconds, or about 16 minutes. Does this mean that the chinese are slower? \n\nOther countries that show a lot of answers above 1000 seconds are:\n Canada\n Switzerland\n South Africa\n Egypt\n Poland\n United Arab Emirates\n Ireland\n \n \nI notice the distribution on Sri Lanka and Romania was kinda broken around the end. I imagine this is a result of the outliers in the data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#Make dataframe with countries and times, this time with every time.\n\ncountriesCompleted = []\ndf_countryAndTimesWithAllData = pd.DataFrame()\n\nfor country in df_fin[\"Q3\"]:\n    if not country in countriesCompleted:\n        countriesCompleted.append(country)\n        temp_array = []\n        i = 0\n        for temp_country in df_fin[\"Q3\"]:\n\n            if temp_country == country:\n                time = int(df_fin.iloc[i,0])\n                temp_array.append(time)\n            i += 1\n        df_temp = pd.DataFrame({country:temp_array})\n        df_countryAndTimesWithAllData = df_countryAndTimesWithAllData.append(df_temp)\n\ndf_countryAndTimesWithAllData =pd.concat([pd.Series(df_countryAndTimesWithAllData[c].dropna().values, name=c) for c in df_countryAndTimesWithAllData], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ctmean = df_countryAndTimesWithAllData.mean().sort_values(ascending = False)\npd.options.plotting.backend = \"plotly\"\n\n# using Plotly Express via the Pandas backend\nfig1 = df_ctmean.plot.barh(height=1000)\nfig1.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for country in countryList:\n    df_temp = df_countryAndTimesWithAllData[country].dropna()\n    h = np.asarray(df_temp)\n    h = sorted(h)\n \n    #use the scipy stats module to fit a normal distirbution with same mean and standard deviation\n    fit = stats.norm.pdf(h, np.mean(h), np.std(h)) \n    \n\n    #plot both series on the histogram\n    plt.plot(h,fit,'-',linewidth = 2,label=\"Normal distribution with same mean and var\")\n    plt.hist(h,density = True, bins = 20,label=\"Actual distribution\")  \n    plt.xlabel(country)\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"chosenCountries = [\"United States of America\", \"Republic of Korea\", \"Sweden\"]\nfor country in chosenCountries:\n    df_temp = df_countryAndTimes[country].dropna()\n    h = np.asarray(df_temp)\n    h = sorted(h)\n \n    #use the scipy stats module to fit a normal distirbution with same mean and standard deviation\n    fit = stats.norm.pdf(h, np.mean(h), np.std(h)) \n    \n\n    #plot both series on the histogram\n    plt.plot(h,fit,'-',linewidth = 2,label=\"Normal distribution with same mean and var\")\n    plt.hist(h,density = True, bins = 20,label=\"Actual distribution\")  \n    plt.xlabel(country)\n    plt.legend()\n    plt.show()\n    \nfor country in chosenCountries:\n    df_temp = df_countryAndTimesWithAllData[country].dropna()\n    h = np.asarray(df_temp)\n    h = sorted(h)\n \n    #use the scipy stats module to fit a normal distirbution with same mean and standard deviation\n    fit = stats.norm.pdf(h, np.mean(h), np.std(h)) \n    \n\n    #plot both series on the histogram\n    plt.plot(h,fit,'-',linewidth = 2,label=\"Normal distribution with same mean and var\")\n    plt.hist(h,density = True, bins = 20,label=\"Actual distribution\")  \n    plt.xlabel(country)\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This was kind of hillarious. I feel confident now that I should exclude the outliers. These plots look terrible! It least compared to the ones without the outliers. And the winner in average time now is sweden, where almost no participants used more than 4000 seconds. \n\nAnd this concludes my notebook. I learned a lot! \nI learned how I can extract data from dataframes, and get useful numerical data. \nI learned how to plot normal distributions and bar horisontal bar diagrams.\nI learned that it is useful to exclude outliers. I still don't know where to set the line, so any feedback in that regards is very much appreciated. \n\nCongratulation Sweden and Ireland with winning the survey-time-competition that you didn't know you participated in. "}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}