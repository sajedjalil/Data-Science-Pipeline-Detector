{"cells":[{"metadata":{},"cell_type":"markdown","source":"The Incomes Table is taken from my own Kaggle Notebook\nhttps://www.kaggle.com/mpwolke/what-s-up-kagglers \n\n#Adapted from AbdulWanab Kabani https://www.kaggle.com/abdulwahabkabani/a-swot-analysis-of-the-world-of-data-science"},{"metadata":{},"cell_type":"markdown","source":"![](https://cdn.corporatefinanceinstitute.com/assets/SWOT.png)corporatefinanceinstitut.com"},{"metadata":{},"cell_type":"markdown","source":"#SWOT analysis (or SWOT matrix)\n\nIt's a strategic planning technique used to help a person or organization identify strengths, weaknesses, opportunities, and threats related to business competition or project planning.\n\nThis technique, which operates by 'peeling back layers of the company'is designed for use in the preliminary stages of decision-making processes and can be used as a tool for evaluation of the strategic position of organizations of many kinds (for-profit enterprises, local and national governments, NGOs, etc.)https://en.wikipedia.org/wiki/SWOT_analysis"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":false,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](https://reliefweb.int/sites/reliefweb.int/files/styles/report-small/public/resources-pdf-previews/1430738-WEF_GGGR_2020.png?itok=KkCtGh13)reliefweb.int"},{"metadata":{},"cell_type":"markdown","source":"#Half of the world’s talent. Nearly a century to achieve parity?!!!\n\nAt the dawn of the 2020s, building fairer and more inclusive economies must be the goal of global, national and industry leaders. To get there, instilling gender parity across education, health, politics and across all forms of economic participation will be critical.\n\nOver the past 14 years the Global Gender Gap Index has served as a compass to track progress on relative gaps between women and men on health, education, economy and politics. Through this annual yardstick, stakeholders within each country are able to set priorities relevant in each specific economic, political and cultural context.\n\nThis year’s report highlights the growing urgency for action. Without the equal inclusion of half of the world’s talent, we will not be able to deliver on the promise of the Fourth Industrial Revolution for all of society, grow our economies for greater shared prosperity or achieve the UN Sustainable Development Goals. At the present rate of change, it will take nearly a century to achieve parity, a timeline we simply cannot accept in today’s globalized world, especially among younger generations who hold increasingly progressive views of gender equality. https://reliefweb.int/report/world/global-gender-gap-report-2020"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"import torch\nimport fastai\nfrom fastai.tabular.all import *\nfrom fastai.text.all import *\nfrom fastai.vision.all import *\n\nfrom fastai import *\n\nimport time\nfrom datetime import datetime\n\nprint(f'Notebook last run on {datetime.fromtimestamp(time.time()).strftime(\"%Y-%m-%d, %H:%M:%S UTC\")}')\nprint('Using fastai version ',fastai.__version__)\nprint('And torch version ',torch.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#High, Upper-Middle and Lower-Middle Incomes\n\nKaggler's Countries are divided according to their income Group: High, Upper-Middle and Lower-Middle Incomes. That division was made by the World Bank. The World Development Indicators Dataset was added to determine which country belongs to one of the groups. There are no low income countries in the survey."},{"metadata":{},"cell_type":"markdown","source":"##SWOT analysis (or SWOT matrix)\n\nSTRENGTHS, \n\nWEAKNESSES, \n\nOPPORTUNITIES, \n\nTHREATS\n\n#You can SWOT a concept, a department, a new initiative. And according to \"Silicon Valley\" #you can SWOT a person, although you have to be careful, they might SWOT you back."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from PIL import Image\n\nimg = Image.open(\"../input/cusersmarilonedriveimagenskagglerspng/kagglers.png\")\nimg","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Women percentage is rising, though the incomes are NOT!\n\nWomen percentage of participants is low across all 3 income groups. Women in lower-middle income economies have the smallest gap. The percentage of Women participants in lower-middle income countries(21.83%) is slightly better than the percentage of Woman participants in high income countries (18.11%). The gap is the largest in upper-middle income countries and the Woman participation is only (18.36%).https://www.kaggle.com/mpwolke/what-s-up-kagglers/notebook"},{"metadata":{"trusted":true},"cell_type":"code","source":"TensorTypes = (TensorImage,TensorMask,TensorPoint,TensorBBox)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#The gap in terms of average salary across the different income groups.\n\nIn lower-middle income countries, the average salary gap is $ 10 K.\n\nIn high income countries, the average salaray gap is $16K.\n\nThe gap is $9K for upper-middle income countries.\n\nhttps://www.kaggle.com/mpwolke/what-s-up-kagglers/notebook"},{"metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"cell_type":"code","source":"def _add1(x): return x+1\ndumb_tfm = RandTransform(enc=_add1, p=0.5)\nstart,d1,d2 = 2,False,False\nfor _ in range(40):\n    t = dumb_tfm(start, split_idx=0)\n    if dumb_tfm.do: test_eq(t, start+1); d1=True\n    else:           test_eq(t, start)  ; d2=True\nassert d1 and d2\ndumb_tfm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#High Income Strengths\n\nWomen are more likely to have an advanced degree (masters and PhDs.)Great Salaries that grow\nsignificantly.\n\n#High Income Weaknesses\n\nLarge Gender Gap. Low Number of young Kagglers.\n\n#High Income Opportunities\n\nWomen are more likely to have postgraduate degree.Initiatives to close the\nsalary gap are likely to lead to more women graduates and hires.\n\n#High Income Threats\n\nGender Bias issues are possible because most people doing data science are man.\nThe percentage of younger Kagglers is much lower than middle income categories.\nThis could lead to expertise shortage in the future.\nhttps://www.kaggle.com/mpwolke/what-s-up-kagglers/notebook"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"_,axs = subplots(1,2)\nshow_image(img, ctx=axs[0], title='original')\nshow_image(img.flip_lr(), ctx=axs[1], title='flipped');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#What a Gap!\n\nThe largest gap is in lower-middle income countries because the gap is 141.83% (Men earn twice as much as Women). On the other hand, the salary percentage gap is 22.53% and 73.22% for high and upper-middle income groups, respectively.https://www.kaggle.com/mpwolke/what-s-up-kagglers/notebook"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"img.resize((64,64))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Upper Income Strengths\n\nWomen are more likely to have an advanced degree(masters and PhDs.). Youthful Population of \nKagglers.\n\n#Upper Income Weaknesses\n\nLarge Gender Gap.Has Largest gender gap when measured by survey participtation. Salaries are relatively low and they don't grow much. \n\n#Upper Income Opportunities\n\nWomen are more likely to have postgraduate degree.Initiatives to close the salary gap are likely to lead to more women graduates and hires.Decent supply of young expertise to fill future jobs.\n\n#Upper Income Threats\n\nGender Bias issues are possible because most people doing data science are male.\nhttps://www.kaggle.com/mpwolke/what-s-up-kagglers/notebook"},{"metadata":{"trusted":true},"cell_type":"code","source":"timg = TensorImage(image2tensor(img))\ntpil = PILImage.create(timg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Women and Masters/Doctoral degrees \n\nWomen are more likely to hold a masters degree or a doctoral degree in all three income groups. In lower-middle income countries where the salary gap is almost double, Women hold a doctoral degree by 2.74%.\n\nLast year women in Lower-middle income countries hold a doctoral degree by 6%.\nhttps://www.kaggle.com/mpwolke/what-s-up-kagglers/notebook"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"TensorTypes = (TensorImage,TensorMask,TensorPoint,TensorBBox)\n\ndef flip_lr(x:Image.Image): return x.transpose(Image.FLIP_LEFT_RIGHT)\ndef flip_lr(x:TensorImageBase): return x.flip(-1)\ndef flip_lr(x:TensorPoint): return TensorPoint(_neg_axis(x.clone(), 0))\ndef flip_lr(x:TensorBBox):  return TensorBBox(TensorPoint(x.view(-1,2)).flip_lr().view(-1,4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"img = PILImage(PILImage.create(timg).resize((600,400)))\nimg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"_,axs = plt.subplots(1,3,figsize=(12,4))\nfor ax,sz in zip(axs.flatten(), [300, 500, 700]):\n    show_image(img.crop_pad(sz), ctx=ax, title=f'Size {sz}');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Lower Income Strengths\n\nWomen are more likely to have an advanced degrees (masters and PhDs.). Tend to have the youngest Kagglers.\n\n#Lower Income Weaknesses\n\nLarge Gender Gap. Has Largest gender gap when measured by salary (Men paid 2x Women).\nSalaries are relatively low and they don't grow much. \n\n#Lower Income Opportunities\n\nWomen are more likely to have postgraduate degree.Initiatives to close the salary gap are likely to lead to more women graduates and hires. Large supply of young expertise to fill future jobs.\n\n#Lower Income Threats\n\nGender Bias issues are possible because most people doing data science are male.\nhttps://www.kaggle.com/mpwolke/what-s-up-kagglers/notebook"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"_,axs = plt.subplots(1,3,figsize=(12,4))\nfor ax,mode in zip(axs.flatten(), [PadMode.Zeros, PadMode.Border, PadMode.Reflection]):\n    show_image(img.crop_pad((600,700), pad_mode=mode), ctx=ax, title=mode);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"_,axs = plt.subplots(1,3,figsize=(12,4))\nf = RandomCrop(200)\nfor ax in axs: show_image(f(img), ctx=ax);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"_,axs = plt.subplots(1,3,figsize=(12,4))\nfor ax in axs: show_image(f(img, split_idx=1), ctx=ax);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"test_eq(ResizeMethod.Squish, 'squish')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"Resize(224)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"_,axs = plt.subplots(1,3,figsize=(12,4))\nfor ax,method in zip(axs.flatten(), [ResizeMethod.Squish, ResizeMethod.Pad, ResizeMethod.Crop]):\n    rsz = Resize(256, method=method)\n    show_image(rsz(img, split_idx=0), ctx=ax, title=method);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"crop = RandomResizedCrop(256)\n_,axs = plt.subplots(3,3,figsize=(9,9))\nfor ax in axs.flatten():\n    cropped = crop(img)\n    show_image(cropped, ctx=ax);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"_,axs = subplots(1,3)\nfor ax in axs.flatten(): show_image(crop(img, split_idx=1), ctx=ax);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"test_eq(cropped.shape, [256,256])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"RatioResize(256)(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"test_eq(RatioResize(256)(img).size[0], 256)\ntest_eq(RatioResize(256)(img.dihedral(3)).size[1], 256)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"timg = TensorImage(array(img)).permute(2,0,1).float()/255.\ndef _batch_ex(bs): return TensorImage(timg[None].expand(bs, *timg.shape).clone())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"tflip = FlipItem(p=1.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"bbox = TensorBBox(((tensor([[1.,0., 2.,1]]) -1)[None]))\nx=test_eq(tflip(bbox,split_idx=0), tensor([[1.,0., 0.,1]]) -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"_,axs = subplots(2, 4)\nfor ax in axs.flatten():\n    show_image(DihedralItem(p=1.)(img, split_idx=0), ctx=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"x = flip_mat(torch.randn(100,4,3))\ntest_eq(set(x[:,0,0].numpy()), {-1,1}) #might fail with probability 2*2**(-100) (picked only 1s or -1s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"crop = RandomResizedCrop(256)\n_,axs = plt.subplots(3,3,figsize=(9,9))\nfor ax in axs.flatten():\n    cropped = crop(img)\n    show_image(cropped, ctx=ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#Codes by Naim Mhedhbi https://www.kaggle.com/naim99/data-augmentation-techniques"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# importing all the required libraries\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport skimage.io as io\nfrom skimage.transform import rotate, AffineTransform, warp\nfrom skimage.util import random_noise\nfrom skimage.filters import gaussian\nimport matplotlib.pyplot as plt\nimport PIL.Image\nimport matplotlib.pyplot as plt\nimport torch\nfrom torchvision import transforms","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def imshow(img, transform):\n    \"\"\"helper function to show data augmentation\n    :param img: path of the image\n    :param transform: data augmentation technique to apply\"\"\"\n    \n    img = PIL.Image.open(img)\n    fig, ax = plt.subplots(1, 2, figsize=(15, 4))\n    ax[0].set_title(f'original image {img.size}')\n    ax[0].imshow(img)\n    img = transform(img)\n    ax[1].set_title(f'transformed image {img.size}')\n    ax[1].imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"loader_transform = transforms.Resize((140, 140))\n\nimshow('../input/cusersmarilonedriveimagenskagglerspng/kagglers.png', loader_transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print('Rotated Image')\n#rotating the image by 45 degrees\nrotated = rotate(img, angle=45, mode = 'wrap')\n#plot the rotated image\nio.imshow(rotated)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#flip image up-to-down\nflipUD = np.flipud(img)\n\nplt.imshow(flipUD)\nplt.title('Up Down Flipped')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Hue can be described of as the shade of the colors in an image\n\nimg = PIL.Image.open('../input/cusersmarilonedriveimagenskagglerspng/kagglers.png')\nfig, ax = plt.subplots(2, 2, figsize=(16, 10))\n\n# brightness\nloader_transform1 = transforms.ColorJitter(brightness=2)\nimg1 = loader_transform1(img)\nax[0, 0].set_title(f'brightness')\nax[0, 0].imshow(img1)\n\n# contrast\nloader_transform2 = transforms.ColorJitter(contrast=2)\nimg2 = loader_transform2(img)\nax[0, 1].set_title(f'contrast')\nax[0, 1].imshow(img2)\n\n# saturation\nloader_transform3 = transforms.ColorJitter(saturation=2)\nimg3 = loader_transform3(img)\nax[1, 0].set_title(f'saturation')\nax[1, 0].imshow(img3)\nfig.savefig('color augmentation', bbox_inches='tight')\n\n# hue\nloader_transform4 = transforms.ColorJitter(hue=0.2)\nimg4 = loader_transform4(img)\nax[1, 1].set_title(f'hue')\nax[1, 1].imshow(img4)\n\nfig.savefig('color augmentation', bbox_inches='tight')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Code by Olga Belitskaya https://www.kaggle.com/olgabelitskaya/sequential-data/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#eb3434','#eb3446','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https://fonts.googleapis.com/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';</style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s</h1>\"\"\"%string))\n    \n    \ndhtml('Marília Prata, not a DS, shh! @mpwolke Was here' )","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}