{"cells":[{"metadata":{},"cell_type":"markdown","source":"![Behind the codes](https://www.fidesloop.com/wp-content/uploads/2017/03/Demo-BG.jpg)"},{"metadata":{},"cell_type":"markdown","source":"# Behind The Screens\n\n## Who are the people behind the screens? \nWhether you have just dropped in to check what Kaggle really is all about or you have already earned the much coveted Kaggle Grandmaster titles, one thing that must interest you, is the data science community and its evolution over the years. So the questions that keep tickling are regarding -  <i>who are the data scientists? Are they a growing community of people? Are they exclusively a bunch of boys in their hoodies, perhaps mostly college droupouts sitting behind their screens in the U.S.? Or are they, rather are we much more diversified and therefore there is some way to break in and be a part of the esteemed community of the data scientists?</i> Well, it's not that hard to find out, when we have such an involved community; a community that cares enough to share its data through the Kaggle annual survey every year <i>(since 2017)</i>. So, what are we waiting for. Let's dig right in!\n\n## <span style=\"color:darkorange\"><u> Don't forget to upvote this notebook (if you like it of course)! Just remember that your upvote especially means a lot! Please do upvote! </u></span> üòäüôè\n\n\n---\n\n\n### Introduction:\n\nThe [2020 Kaggle Machine Learning & Data Science Survey Competition](https://www.kaggle.com/c/kaggle-survey-2020) is the 4th generation of the much renowned annual Kaggle survey competitions. As with most upgrades from advanced communities, the 2020 survey is also more topical and structured compared to its previous versions. As a result, on one hand, it yields ample scope for historical trend analysis, especially as far as the demographic data is concerned, and on the other hand, it highlights the prevailing and emerging trends in the ever-evolving world of data-science.<br> \n\nThis paper is organized in 5 broad sections which are further subdivided into sub-sections; in the first section, we underline the broad topic areas covered in the 2020 questionnaire [[1.1.](#q1a)], and set the scope of analysis for the exercise at hand accordingly and summarize our work on data-sanity-checks (sample size, response rate, etc.) [[1.2.](#q2a)]. In section 2, we undertake longitudinal and cross-sectional analyses of the demographic data to evaluate the demographic evolution of the data science community over the years.  Sections 3 and 4 brief the findings from the different cross-sectional analyses conducted through the course of this competition, to uncover the most useful and popular data-science/ML/ cloud related tools/ techniques and services. Section 5 highlights the data science courses begun/completed, and the public forums, and the media channels frequented by the data-science community for the purpose of knowledge-sharing and/or knowledge update/ upgrade.   \n \n\n---\n\n<div class=\"alert alert-block alert-success\" style=\"font-size:12px; font-family:comfortaa; line-height: 3.0em;\">\n    üìå &nbsp; <p style=\"font-size:20px; color:orangered; font-family:verdana;\"><b><u>Key Findings: </u></b></p>\n<p style=\"font-size:16px; color:orangered; font-family:comfortaa;\"><b>\n<br>1. Most of the growth in the community is due to the young data-enthusiats from India.<br><br>\n    <i>In the coming decades, India could potentially overtake U.S.A to become a major data-science hub, if both countries continue with their respective growth trajectories (as indicated by the 2017-20 Kaggle survey data). Given the paucity of respondents from countries like China, it is hard to estimate their actual position in the community!</i><br><br>\n<br>2. The growing number of women in the community is promising, but we have a long way to go.<br><br>\n    <i> in India in particular, (which accounts for most of the sharp rise in the number of female respondents in 2020) fewer women/ LGBTQA+ with only a Bachelor's degree (or no degree at all) have access to Kaggle compared to their male counterparts. An equal access, across genders and qualification levels, to platforms like Kaggle is essential to continue the women's growth story in the community.<br><br> \n<br>3. Developed western countries have many more highly qualified professionals compared to the emerging nations like India.\n<br>4. Python is the undisputed favorite programming lanuage and Jupyter is the favorite IDE.\n<br>5. A personal computer/ laptop with access to GPU is enough for the most part to have a career in adat-science.\n<br>\n        <br><br></i></b>\n    </p>\n</div>\n\n---\n\n<a id = \"qa\"></a>\n### 1. Understanding the data: \nAs mentioned in [Section 1](#qa), the demography-related questions are asked every year, and therefore present us with the opportunity to conduct longitudinal trend analyses. In this section, we dive into each of these data points and conduct historical analyses to uncover the demographic evolution in the community in these four years. The factors considered in this section are:\n* [1.1. Broad topic areas covered and the survey format](#q1a)\n* [1.2. Scope of analysis](#q1b)\n\n### 2. The Demographics:\n\nThe topics covered in this section are:\n\n* [2.1. Gender distribution](#q2a)\n* [2.2. Country-wise expanse](#q2b)\n* [2.3. Age distribution](#q2c)\n* [2.4. Formal education](#q2d)\n* [2.5. Profession (including compensation, company/ team size, and job profile)](#q2e)\n\n### 3. General programming and data science related questions:\n\nThe topics covered in this section are:\n\n* [3.1. Coding experience, in years](#q3a)\n* [3.2. Programming languages, data visualization libraries/tools and BI tools](#q3b)\n* [3.3. Integrated Development Environments (IDE's)](#q3c)\n* [3.4. Hosted notebook products](#q3d) \n* [3.5. Computing platform and specialized hardwares](#q3e)\n\n\n### 4. Machine Learning and cloud computing related questions:\n\nThe topics covered in this section are:\n\n* [4.1. Machine Learning experience, in years](#q4a)\n* [4.2. Machine Learning Frameworks and algorithms](#q4b)\n* [4.3. Machine Learning/ cloud related spending, in past 5 years](#q4c)\n* [4.4. Machine Learning/ cloud/ Big data products and services](#q4d)\n* [4.5. Auto ML and Partial Auto ML](#q5d)\n\n\n### 5. Platforms and Media:\n\nThe topics covered in this section are:\n\n* [5.1. Data science courses](#q5a)\n* [5.2. Analysis and application sharing](#q5b)\n* [5.3. Favorite media sources](#q5c)\n\n<br>\n\n---\n\n<br>\n\n### Future work:\n\nThe Kaggle survey datasets are a treasure of information and therefore there remains much scope for further research and analysis involving these datasets. One such possible area for future work could be to run CART analyses on the data to distinguish the professionals from the non-professionals (hopefully the future professionals ü§û)\n\n---\n### Data Sources:\n\n* Kaggle survey data - (2017 - 2020)\n* Meta-Kaggle datasets\n* Population by country (source: [United Nations](https://population.un.org/wpp/Download/Standard/Population))\n* `kaggle_survey_2020_methodology.pdf`\n* `kaggle_survey_2020_answer_choices.pdf`\n\n\n---\n\n*Limitations: This survey data captures the demographics and practices of data-entusiasts and data scientists who took part in the extensive survey, and thus might over-represent the part of the community that has the time and the willingness to take part in such long surveys (e.g. the students and the first-time Kaggle survey participants).* \n\n\n---\n\n<a id = \"q1a\"></a>\n### 1.1. Broad topic areas covered and the survey format\n\nEven a cursory glance at the list of questions asked through the Kaggle annual surveys reveals that apart from the quintessential demographic-questions, which are asked every year, the survey questionnaire is regularly updated to exhaustively cover all the data-science related topics on the circuit. So there is some merit in highlighting the broad topic areas addressed through the 2020 survey upfront. \n\n#### Topics that the 2020 survey focused on: \n* 7 questions demography-related questions *(Age, gender, Location, Education, Current role, and compensation, USD, company size)*\n* Data-science related questions *(AI, BI, cloud, programming, etc. related).\n\n#### Question categories: \nThis year's survey asked **39 questions** including \n* <b>24 main questions</b>,\n* <b>7 follow-up questions</b> <a id = \"s1\"></a> - <i>(These are optional questions which were presented only to a few participants (based on their response to a related main questions)</i> \n* <b>8 supplementary questions</b> - <i>(These questions have 2 versions, one for the professionals and the other for the non-professionals i.e. respondents who identified themselves either as students, or currently unemployed, and the respondents who have never spent any money in the cloud. The difference  between the two versions is simply this: these ask the professionals about their actual experience/ spending behavior, etc. relating to cloud/ ML/ AI, etc. products/ services, and the non-professionals about their plans regarding the same products/ services over the next 2 years.</i> \n\n#### Question formats:\nThe 2020 survey asked \n* 18 multiple choice üîò and \n* 21 multiple select questions ‚úÖ\n\n*Apart from the answers to all these questions, Kaggle also provides us with the time taken by each user to complete the survey.*\n\n"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"%reset -f\n!pip -q install --upgrade pip\nimport numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import (AutoMinorLocator, MultipleLocator)\nfrom matplotlib import cm\nfrom mpl_toolkits.axes_grid1.inset_locator import inset_axes\nimport os\nimport gc\nimport warnings\nimport pycountry\nimport plotly\nimport plotly.offline as pyo\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nfrom itertools import product\n#from textwrap import fill\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator \nimport matplotlib.ticker as ticker\nimport seaborn as sns\nfrom matplotlib.ticker import FuncFormatter\nfrom matplotlib.font_manager import FontProperties\nimport squarify\nfrom IPython.display import HTML\nimport plotly.offline as pyo\npyo.init_notebook_mode()\n\nsns.set(font_scale=1.2)\n\nwarnings.filterwarnings(\"ignore\")\ngc.enable()\n\n!pip -q install millify\nfrom millify import millify\n\npd.options.display.max_colwidth=250\n\nplt.style.use('seaborn-white')\nplt.rcParams['axes.labelsize'] = 20\nplt.rcParams['axes.titlesize'] = 20\nplt.rcParams['font.sans-serif'] = \"Comfortaa\"\ncmaps=['Oranges', 'Greys']\n\ndef highlight(val):\n    style = 'background-color: bisque' if val == 0 else ''\n    return style\n\ndef font(val):\n    white = 'color: whitesmoke' if val == 0 else ''\n    return white\n\ndef highlight_cols(s):\n    color = '#FFFFFF'\n    return 'background-color: %s' % color\ndef font_cols(s):\n    color = 'grey'\n    return 'color: %s' % color","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Number of active Kagglers by year\ndf_list = ['Users','Submissions','TeamMemberships']\nfor i in range(len(df_list)):\n    globals()[df_list[i]]=pd.read_csv('/kaggle/input/meta-kaggle/'+df_list[i]+'.csv')\n    \nUsers['RegisterDate']=pd.to_datetime(Users['RegisterDate'])\nUsers['RegYear']=Users['RegisterDate'].dt.year\nUsers=Users[Users['RegYear']<=2020]\n\ncount=Users.shape[0]\nSubmissions['SubmissionDate']=pd.to_datetime(Submissions['SubmissionDate'])\nSubmissions['Year'] = Submissions['SubmissionDate'].dt.year\nactive=Submissions[Submissions['Year'].isin(range(2017,2021))]\nactive=active[['TeamId','SubmittedUserId', 'Year']].drop_duplicates(subset=['Year','TeamId'])\nactive=active.merge(TeamMemberships.drop(columns=['Id', 'RequestDate']), on=['TeamId'])\nactive=active.drop_duplicates(subset=['Year','UserId'])\nactive.Year = active.Year.astype(str)\nactive=pd.DataFrame(active['Year'].value_counts()).sort_index()\nactive.columns=['Active']\n\n\n#data preparation\nsurvey_2017MCQ = pd.read_csv('/kaggle/input/kaggle-survey-2017/multipleChoiceResponses.csv',encoding='latin1')\nsurvey_2018MCQ = pd.read_csv('/kaggle/input/kaggle-survey-2018/multipleChoiceResponses.csv',encoding='latin1')\nsurvey_2019MCQ = pd.read_csv('/kaggle/input/kaggle-survey-2019/multiple_choice_responses.csv')\nsurvey_2020MCQ = pd.read_csv('/kaggle/input/kaggle-survey-2020/kaggle_survey_2020_responses.csv')\n\nfor i in range(2018,2021):\n    globals()['survey_'+str(i)+'Q']=pd.DataFrame(eval('survey_'+str(i)+'MCQ').iloc[[0]]).T\n    globals()['survey_'+str(i)+'Q'].columns=['questions']\n    globals()['survey_'+str(i)+'MCQ'] = eval('survey_'+str(i)+'MCQ').drop(eval('survey_'+str(i)+'MCQ').index[0])\n\n\n#format gender variable uniformly\nsurvey_2020MCQ.loc[survey_2020MCQ['Q2'] == 'Man', 'Q2'] = 'Male'\nsurvey_2020MCQ.loc[survey_2020MCQ['Q2'] == 'Woman', 'Q2'] = 'Female'\n\nage_list=[21,24,29,34,39,44,49,54,59]\na=len(age_list)\nx1=x2=0\n#Create Age-groups\nfor i in range(a):\n    x1=age_list[i]\n    if i in range(1,a):\n        x2=age_list[i-1]+1            \n        p=str(x2)+\"-\"+str(x1)\n        survey_2017MCQ.loc[survey_2017MCQ['Age'].isin(range(x2,x1)), 'Agegroup'] = p\n    \nsurvey_2017MCQ.loc[survey_2017MCQ['Age']<=21, 'Agegroup'] = \"<=21\"\nsurvey_2017MCQ.loc[survey_2017MCQ['Age']>=60, 'Agegroup'] = \">=60\"\n        \n\nvar_list=['Country','Q3','Q3','Q3']\ncountry_list=['States','Kingdom','China','Iran','Emirates','disclose']\nshort_list=['U.S.A.','U.K.','China','Iran','U.A.E.','Other']\nagevar_list=['Age','Q2','Q1','Q1']\nqualvar_list=['FormalEducation','Q4','Q4','Q4']\n\nfor i in range(4):\n    df=globals()['survey_'+str(i+2017)+'MCQ']\n    df=df.fillna('NA')\n    for j in range(len(short_list)):\n        df.loc[df[var_list[i]].str.contains(country_list[j], na=False), var_list[i]] = short_list[j]\n        globals()['survey_'+str(i+2017)+'MCQ']=df\n    \n    if i>0:\n        df.loc[df[agevar_list[i]].isin(['60-69','70-79','70+','80+']), agevar_list[i]] = '>=60'\n        df.loc[df[agevar_list[i]]=='18-21', agevar_list[i]] = '<=21'\n        \n    for j in range(len(qualvar_list)):\n        df.loc[df[qualvar_list[i]].str.contains('Some', na=False), qualvar_list[i]] = 'College dropout'\n        df.loc[df[qualvar_list[i]].str.contains('high', na=False), qualvar_list[i]] = 'High School'\n        df.loc[df[qualvar_list[i]].str.contains('Bach', na=False), qualvar_list[i]] = 'Bachelors'\n        df.loc[df[qualvar_list[i]].str.contains('Mast', na=False), qualvar_list[i]] = 'Masters'\n        df.loc[df[qualvar_list[i]].str.contains('refer', na=False), qualvar_list[i]] = 'NA'\n        df[qualvar_list[i]] = df[qualvar_list[i]].str.replace(' degree','')\n        df=df.replace('NA',np.nan) #remove all NAs\n    globals()['survey_'+str(i+2017)+'MCQ']=df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"survey_2020Q[['Q','part','P','N']] = survey_2020Q.index.to_series().str.split('_',expand=True)\nsurvey_2020Q.loc[survey_2020Q.part.isna(),'type']='MCQ'\nsurvey_2020Q.loc[~survey_2020Q.part.isna(),'type']='MSQ'\nsurvey_2020Q.drop(columns=['P','N'],inplace=True)\n\nreplace = ['what ', 'which ', 'these', 'their', 'in ', 'is ', '?', 'your ', 'you', 'does', 'do', 'reside', 'currently',\n          'of', 'the', 'following', 'types', 'type', 'how', 'many', 'where', ' are', 'employed',\n           'categories']\n\nrep = ['education', 'current role'\n      ]\n\nrep2 = ['use on a regular basis', 'Business Intelligence', 'machine learning', ' or ', 'computer vision',\n        'automated machine learning'\n       ]\nput2 = ['used regularly', 'BI', 'ML', '/', 'CV', 'Auto ML'\n       ]\n\ncap = ['ml', 'Ide', 'Nlp', 'Tpu', 'Bi', 'usd', 'Cv']\ncap1 = ['specialized', 'hosted']\n\nsurvey_2020Q['clean_questions'] = survey_2020Q['questions'].str.lower()\nsurvey_2020Q['clean_questions'] = survey_2020Q['clean_questions'].str.split('-').str[0]\nsurvey_2020Q['clean_questions'] = survey_2020Q['clean_questions'].str.split('(').str[0]\nsurvey_2020Q['clean_questions'] = survey_2020Q['clean_questions'].str.split('?').str[0]\n\nsurvey_2020Q['short_questions'] = survey_2020Q['clean_questions']\n\nfor i in range(len(replace)):\n    survey_2020Q['short_questions'] = survey_2020Q['short_questions'].str.replace(replace[i],'')\n    \nfor i in range(len(rep)):    \n    survey_2020Q.loc[survey_2020Q['short_questions'].str.contains(rep[i]),'short_questions'] = rep[i].title()\n\nfor i in range(len(rep2)):    \n    survey_2020Q['short_questions'] = survey_2020Q['short_questions'].str.replace(rep2[i],put2[i])\nsurvey_2020Q.short_questions = survey_2020Q.short_questions.str.title()\nfor i in range(len(cap)):\n    survey_2020Q['short_questions'] = survey_2020Q['short_questions'].str.replace(cap[i],cap[i].upper())\n\nfor i in range(len(cap1)):\n    survey_2020Q['short_questions'] = survey_2020Q['short_questions'].str.replace(cap1[i],cap1[i].capitalize())\n\n\n\nsurvey_2020Q.loc[survey_2020Q['short_questions'].str.contains('used ML methods'),'short_questions'] = 'Experience in ML methods (#years)'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Time'),'short_questions'] = 'Survey duration, seconds'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q5'),'short_questions'] = 'Current-role'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q6'),'short_questions'] = 'Coding-experience'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q7'),'short_questions'] = 'Programming languages used regularly'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q8'),'short_questions'] = 'Recommended 1st programming language'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q9'),'short_questions'] = 'IDE used regularly'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q10'),'short_questions'] = 'Hosted notebook used regularly'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q11'),'short_questions'] = 'Computing platform used'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q12'),'short_questions'] = 'Specialized hardware used regularly'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q13'),'short_questions'] = 'TPU used(#times)'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q14'),'short_questions'] = 'Data visualization libraries/ tools used regularly'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q15'),'short_questions'] = 'ML experience(#years)'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q16'),'short_questions'] = 'ML frameworks used regularly'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q19'),'short_questions'] = 'NLP methods used regularly'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q20'),'short_questions'] = 'Company-size'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q21'),'short_questions'] = 'Data Science team size'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q22'),'short_questions'] = 'ML used at job(Y/N)'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q23'),'short_questions'] = 'Data/ML role in current job'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q24'),'short_questions'] = 'CompensationUSD'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q25'),'short_questions'] = 'ML/ cloud expense in past 5 years, USD'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q26'),'short_questions'] = 'Cloud computing platforms used regularly'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q27'),'short_questions'] = 'Cloud computing products used regularly'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q28'),'short_questions'] = 'ML products used regularly'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q29'),'short_questions'] = 'Big data products used regularly'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q30'),'short_questions'] = 'Preferred Big data product'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q31'),'short_questions'] = 'BI tools used regularly'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q32'),'short_questions'] = 'Preferred BI tool'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q33'),'short_questions'] = 'Auto ML/ Partial Auto ML tools used(Y/N)'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q34'),'short_questions'] = 'Auto ML/ Partial Auto ML tools used regularly'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q35'),'short_questions'] = 'ML experiment managing tool used regularly'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q36'),'short_questions'] = 'DA/ML app. sharing/ deployment platform'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q37'),'short_questions'] = 'Platform for  data science courses'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q38'),'short_questions'] = 'Primary data analysis tool used'\nsurvey_2020Q.loc[survey_2020Q.index.str.contains('Q39'),'short_questions'] = 'Favorite media sources for data science topics'\n \nshortQ2020=survey_2020Q[['Q','questions','type','clean_questions','short_questions','part']].reset_index(drop=True)\nshortQ2020.drop_duplicates(subset=['Q'],inplace=True)\n\nshortQ2020.loc[shortQ2020.Q.isin(['Q1','Q2','Q3','Q4','Q5','Q20','Q24']), 'category'] = 'demographics'\nshortQ2020.loc[shortQ2020.Q.isin(['Q1','Q2','Q3','Q4','Q5','Q20','Q24']), 'topic'] = shortQ2020['short_questions']\nshortQ2020.loc[shortQ2020.Q.isin(['Q20']), 'clean_questions'] = shortQ2020['short_questions']\n\nshortQ2020.loc[shortQ2020.clean_questions.str.contains('big data'),'topic'] = 'Big Data'\nshortQ2020.loc[shortQ2020.clean_questions.str.contains('programming'),'topic'] = 'Programming'\nshortQ2020.loc[shortQ2020.clean_questions.str.contains('data visualization'),'topic'] = 'Data Visualizing'\nshortQ2020.loc[shortQ2020.clean_questions.str.contains('machine learning'),'topic'] = 'ML'\nshortQ2020.loc[shortQ2020.clean_questions.str.contains('ml'),'topic'] = 'ML'\nshortQ2020.loc[shortQ2020.clean_questions.str.contains('integrated development environments'),'topic'] = 'IDE'\nshortQ2020.loc[shortQ2020.clean_questions.str.contains('hosted notebook'),'topic'] = 'Hosted Notebook'\nshortQ2020.loc[shortQ2020.clean_questions.str.contains('computing platform'),'topic'] = 'Computing Platform'\nshortQ2020.loc[shortQ2020.clean_questions.str.contains('specialized hardware'),'topic'] = 'Specialized Hardware'\nshortQ2020.loc[shortQ2020.clean_questions.str.contains('tpu'),'topic'] = 'TPU'\nshortQ2020.loc[shortQ2020.clean_questions.str.contains('computer vision'),'topic'] = 'CV'\nshortQ2020.loc[shortQ2020.clean_questions.str.contains('natural language processing'),'topic'] = 'NLP'\nshortQ2020.loc[shortQ2020.clean_questions.str.contains('cloud'),'topic'] = 'Cloud'\nshortQ2020.loc[shortQ2020.clean_questions.str.contains('business intelligence'),'topic'] = 'BI'\nshortQ2020.loc[shortQ2020.clean_questions.str.contains('courses'),'topic'] = 'courses'\nshortQ2020.loc[shortQ2020.clean_questions.str.contains('media sources'),'topic'] = 'media sources'\nshortQ2020.loc[shortQ2020.clean_questions.str.contains('role'),'topic'] = 'data duty'\nshortQ2020.loc[shortQ2020.Q.str.contains('Q38'),'topic'] = 'primary tool'\nshortQ2020.loc[shortQ2020.Q.str.contains('Q25'),'topic'] = 'expense'\nshortQ2020.loc[shortQ2020.Q.str.contains('Q21'),'topic'] = shortQ2020['short_questions']\n\n\ndemo=shortQ2020[~shortQ2020['topic'].isna()][shortQ2020['category']=='demographics']['short_questions'].to_list()\ndemo=' '.join(demo)\ntext=shortQ2020[~shortQ2020['topic'].isna()][shortQ2020['category']!='demographics']['topic'].to_list()\ntext=' '.join(text)\n\nfig, ax = plt.subplots(1, 2, figsize=(15,6), gridspec_kw={'width_ratios': [1, 2]})\nfig.suptitle('Topics covered in the 2020 survey', fontsize=24, y=1.1)\nax[0].set_title('Re: demography', color='dimgrey', fontsize=24)\ndemowc = WordCloud(width=400, height=400, colormap='Greys_r',background_color='orangered').generate(str(demo)) \n\nax[1].set_title('Re: data science', color='orangered', fontsize=24)\nwordcloud = WordCloud(width=800, height=400, colormap=\"Oranges_r\").generate(str(text))#background_color='silver', \n#plt.figure(figsize=(15, 5), facecolor='grey')\nax[0].imshow(demowc)\nax[1].imshow(wordcloud)\nax[0].axis(\"off\")\nplt.axis(\"off\")\nfootnote='\\n\\n$\\it Source:\\ 2020\\ survey\\ data $'\nax[0].annotate(footnote, xy=(0, -0.1), xycoords='axes fraction')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<i>[Go back to the top](#qa)</i>"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"q1b\"></a>\n### 1.2. Scope of analysis\n\nAmong the many questions that clutter the mind, the one that occupies the top spot is this:<br>. \n<i>Who does this survey data respresent?<br></i> In this section, we try to address this very question by looking at the sample data (2020 survey data), the auxiliary documents (viz. the `kaggle_survey_2020_methodology.pdf` and the`kaggle_survey_2020_answer_choices.pdf`), the <b>meta-kaggle</b> datasets. We argue that given the survey methodology ([see detailed below](#method)), most of the survey respondents are active Kaggle users and therefore <b><i><u>represent the actively involved data-enthusiasts and data-science-experts</u></i></b> (especially the ones who are involved enough to fill up a long multiple choice/ multiple selection survey).\n\nAbout the meta-kaggle data: Along with many other details, the meta-kaggle datasets contain the list of Kaggle 'Users' with their registration date (on Kaggle), the 'User Achievements', and the list of 'Submissions' made by the users (with data of submission). As expected the 'Users' data shows exponetial growth in Kaggle userbase over time - since inception (2010), every year, the number of new registrations on the platform has multiplied; starting with a humble 4558 users, today kaggle userbase is reaching a humongous ~6 million! Out of these ~6M users, more than a third registered in 2020 itself. "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Kaggle - Yearwise registered user count chart\n#------------------------------------------------\nfig, ax = plt.subplots(1, 1, figsize=(12,4))\nfig.suptitle('Number of new Kagglers registering per year', fontsize=20, y=1.0)\n    \nfor i in range(4):\n    Users['RegYear'].value_counts(ascending=True).plot.bar(ax=ax, width=0.3, color='grey')\n    ax.spines[\"top\"].set_visible(False)\n    ax.spines[\"right\"].set_visible(False)\n    ax.spines[\"left\"].set_visible(False)\n    \n    \n    y_axis = ax.axes.get_yaxis()\n    y_axis.set_visible(False)\n    \n    for p in  ax.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        if height > 1000000:\n            ax.annotate(millify(height,precision=2), \n                        (x+0.15, height+25000), fontsize=12, ha='center',weight='normal', size='large')\n        else:\n            ax.annotate(millify(height), \n                        (x+0.15, height+25000), fontsize=12, ha='center',weight='normal', size='large')\n\nfootnote='$\\it{Source:\\ meta-kaggle\\ user\\ data}$'\n \nplt.figtext(0.15, -0.1, footnote, ha=\"center\", fontsize=14, bbox={\"facecolor\":\"white\",\"alpha\":0.5, \"pad\":5})\n\nplt.xticks(rotation=0)            \nplt.tight_layout()\nplt.show()   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"However compared to these huge numbers, the number of users who participated in the survey in 2020 seems too tiny at ~20k, and indicates that only a fraction of these ~6M registered users might be  actively involved in the community. To confirm the same, we chart out the number of tiered users. Turns out that as suspected, **less than 2% of all registered users, i.e. 102419 users on Kaggle are tiered** (*There are 4 performance tiers - contributor, expert, master, and grandmaster*).\n<br><br>\n\n---\n\n\n<a id = \"method\"></a>\n\nThis year the survey-invitation was sent out to the community via e-mails (anyone who\nopted-in to the Kaggle Email List was invited). The survey was also promoted on the Kaggle website and on the Kaggle Twitter channel. So the target audience included both \n* professionals and non-professionals (students/ unemployed/ ones who never spent any money on cloud)\n* males/ females/ LGBTQA+\n* 18 years and older\n* people with or without any formal education\n* people residing in 171 countries\n\n<i>The 20,036 people who responded, can accordingly be grouped under any of these broad categories or a combintion thereof.</i>\n\n<i>[Source: `kaggle_survey_2020_methodology.pdf`]</i>\n\n<b><u>NOTE:</u></b><i> Though a respondent did not need to be registered Kaggle user to fill up the Kaggle survey, because the survey was promoted on the Kaggle website and the Kaggle Twitter channel and the invitations to participate in the survey were sent to anyone who\nopted-in to the Kaggle Email List, it seems highly likely that most survey respondents are registered users because otherwise they would have been unlikely to see any of the survey promotions.</i>\n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"colors = ['khaki','goldenrod','darkorange','orangered']\nUsers=Users[~Users['PerformanceTier'].isin([0,5])]\nuser_count=pd.DataFrame(Users['PerformanceTier'].value_counts())\nuser_count=user_count[user_count.index!=0]\nperf0=1-int(user_count.sum())/count\nuser_count.sort_values(by=['PerformanceTier'], ascending=False,inplace=True)\nuser_count=user_count.iloc[:,0].to_list()\ntier = ['Contributors', 'Experts', 'Masters', 'Grandmasters']\n\nfig, ax = plt.subplots(1, 4, figsize=(15,2))  \nfig.suptitle('Less than 2% of all registered users are tiered', fontsize=20, y=1.1)\nfor i in range(4):\n    ax[i].set_facecolor(colors[i])\n    y_axis = ax[i].axes.get_yaxis()\n    x_axis = ax[i].axes.get_xaxis()\n    y_axis.set_visible(False)\n    x_axis.set_visible(False)\n    text = '\\n'.join((str(user_count[i]),tier[i]))\n    if i<3:\n        ax[i].text(0.5, 0.5, text, fontsize=20, va='center', ha='center',weight='heavy')\n    else:\n        ax[i].text(0.5, 0.5, text, fontsize=20, va='center', ha='center',weight='heavy',c='white')\nplt.subplots_adjust(wspace=0.01, hspace=0)\n\n    \n\n#g=sns.heatmap(user_count, annot=True, fmt='g', yticklabels='',  annot_kws={\"size\": 14},ax=ax, cmap=cm) #cbar_kws={\"orientation\": \"horizontal\", \"shrink\": 10})\n\nfootnote='Total no. of registered users on Kaggle = ' + str(count) + '\\n' + 'Novice Kagglers (i.e. untiered) =' + str(\"{:.0%}\".format(perf0))\nfootnote=footnote + '\\n\\n' + '$\\it{Source:\\ meta-kaggle\\ user\\ achievements\\ data}$'\n\nax[0].annotate(footnote, xy=(-0.1, -.8), xycoords='axes fraction')\n\nplt.tight_layout(pad=1.9)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Similarly, the number of users who made at least one submission in that year, are consistently low. Less than 90k users have made any submission on Kaggle in 2020. So turns out that every year, <b>the number of users on Kaggle who made at least one submission in the year is at most about 5 times the number of people who filled up the Kaggle survey in that year.<br>\n<b><u>Takeaway: Based on the number of respondents, the sample seems to be large enough  to be representative of the active Kaggle users' community (and therfore the data science community at large).</u></b><br><br><br>\n\n\n---\n\n<i>Active users: For the purpose of this analyis we have labeled a user as active in any particular year if s/he made at least 1 submission on Kaggle that year.</i>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def kilo(x, pos):\n    return '%1.0fk' % (x * 1e-3)\n\nformatter = FuncFormatter(kilo)\n\nvar_list=['GenderSelect','Q1','Q2','Q2']\n\nfor i in range(4):\n    x=str(i+2017)\n    globals()['g'+x]=pd.DataFrame(eval('survey_'+x+'MCQ')[var_list[i]].value_counts(dropna=False))\n    globals()['g'+x].columns=[x]\n    df=globals()['g'+x]\n    df.loc['LGBTQA+ /Not-specified']=df[~df.index.str.contains('ale', na=False)].sum(axis=0)\n    df=df.loc[['Male','Female','LGBTQA+ /Not-specified']]\n    df.loc['Overall']=df.sum(axis=0)\n    globals()['g'+x]=df\n    \n    if i>0:\n        gender=gender.merge(df,left_index=True, right_index=True)\n    else:\n        gender=df\n        \ngender=gender.T\ngender=gender.merge(active, left_index=True, right_index=True)\ngender['%Participation']=gender['Overall']/gender['Active']\n\nplt.rcParams['axes.labelsize'] = 20\n\nfig, ax1 = plt.subplots(figsize=(10,5))\nfig.suptitle('The annual survey participation rate is more than a fifth of active* userbase every year', fontsize=20, y=1.01)\nax2 = ax1.twinx()  # set up the 2nd axis\nax1.bar(width=0.3,height=gender['Active'],x=gender.index, color='grey', label='Kagglers with >=1 submission') \nax2.plot(gender.index,gender['%Participation'], \n         color='orangered', linestyle='--', marker='o', markersize=8,\n            label='Survey participation rate (%)')\n\ny1label = '\\n'.join((r'No. of Kagglers with',\n                         'at least 1 submission')) \n\nax1.set_ylabel(y1label, fontsize=14)\nax1.yaxis.set_major_formatter(formatter)\nax1.tick_params(length=0)\n\nax2.set_ylabel('Survey participation rate', fontsize=14)\nax2.set_ylim(0,0.75)\nax2.tick_params(length=0)\n\ni=0\nfor spine in ax1.spines.values():\n    if list(ax1.spines.keys())[i]!='bottom':\n        spine.set_visible(False)\n    i=i+1\n     \ni=0\nfor spine in ax2.spines.values():\n    if list(ax2.spines.keys())[i]!='bottom':\n        spine.set_visible(False)\n    i=i+1\n    \nax2.yaxis.set_major_formatter(ticker.PercentFormatter(decimals=0,xmax=1))\n\nfor p in  ax1.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        ax1.annotate(millify(height, precision=1), (x, height*1.05), fontsize=14)\n        \n#labels=['Kagglers with >=1 submission','Survey participation rate']\n\nfootnote=\"\\n Note: Users who made at least one submission in the year have been considered to be active Kagglers*\"\nfootnote='\\n'.join((footnote,'Survey participation rate is calculated as the number of suvery respondents (expressed as a percentage ',\n                    'of the number of users who made at least 1 submission in the year)'))\n\nfootnote=footnote + '\\n\\n' + '$\\it{Source:\\ meta-kaggle\\ Submissions\\ data\\ &\\ (2017-20)\\ survey\\ data}$'\nfig.subplots_adjust(wspace=0.0, hspace=0, top=0.2, bottom=.1)\nfig.legend(bbox_to_anchor=(.65, 1), frameon=True, prop={'size': 12})\nplt.tight_layout(pad=1.0)\nplt.annotate(footnote, xy=(-0.2, -0.6), xycoords='axes fraction')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Response rate - question-wise and participant-wise:\n\nNow that the total number of survey participants has been put in perspective, couple of questions regarding the 2020 survey demand our attention next: \n\n1. How many of the survey-questions did each survey-respondent answer?\n2. How many of the survey-respondents did answer any particular survey-question?\n\nRegarding the first question, we find that in 2020, approximately, \n* 15k participants (75% of the respondents) answered half the questions. \n* 10k participants (half of the respondents) answered 30 or more questions.\n* a thousand of the respondents i.e. ~5% of all respondents responded to 5 questions or less.<br><br>\n\n---\n\n<b>Note: </b><i>Thoughout this analysis, 'NA' responses are considered as missing responses.</i>\n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"count_na=pd.DataFrame()\nls=survey_2020MCQ.loc[:,~survey_2020MCQ.columns.str.contains('_')].columns\n\nfor i in range(39):\n    col='Q'+str(i+1)\n    if col in ls:\n        df=survey_2020MCQ[[col]]\n    else:\n        df=survey_2020MCQ.filter(regex=col)\n    count_na[col]=df.shape[1]-df.isna().sum(axis=1)\ncount_na=count_na.replace(0,np.nan)\ncount_na['count_NA']=count_na.shape[1]-count_na.isna().sum(axis=1)\ncount_na=pd.DataFrame(count_na['count_NA'].value_counts())\ncount_na.sort_index(inplace=True)\ncount_na['cumsum']=count_na['count_NA'].cumsum()\n\n#count_na=count_na[['count_NA']].sort_values(by=['count_NA']).reset_index(drop=True)\n\n\nfig, ax = plt.subplots(1, 1, figsize=(10,5))\nfig.suptitle('Number of questions answered by 2020-survey-repondents*:', fontsize=20, y=1.05)\n    \ncount_na['cumsum'].plot(ax=ax, color='dimgrey', legend=False)\nax.spines[\"top\"].set_visible(False)\nax.spines[\"right\"].set_visible(False)\nax.yaxis.set_minor_locator(AutoMinorLocator())\nax.xaxis.set_minor_locator(AutoMinorLocator())    \n\nfootnote='$\\it{*all\\ \\'NA\\'s\\ are\\ considered\\ as\\ missing\\ response}$'\nplt.annotate(footnote, xy=(-0.1, -0.3), xycoords='axes fraction', fontsize=16, color='grey')\n\nax.set(xlim=(0, 40), ylim=(0, 20500))\n#ax.yaxis.set_major_formatter(ticker.PercentFormatter(decimals=0,xmax=1))\n\nax.grid(which='major', color='peachpuff', linestyle='--')\nax.grid(which='minor', color='peachpuff', linestyle=':')\n\nplt.ylabel('Number of respondents')\nplt.xlabel('Number of questions answered')\n\nplt.yticks(fontsize=14,rotation=0)            \nplt.tight_layout(pad=1)\nplt.grid(True)\nplt.show()   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before addressing the second question (i.e. what percentage of respondents answered a particular question), it is important to note that -\n* <b><u>7 of the questions were follow-up questions</u></b> and therefore shown to a few respondents only (selected based on their response to the related mandatory questions). These follow up are: <u>Q18, Q19, Q27A, Q28A, Q30, Q32, and Q34.</u>\n* <b><u>8 questions</u></b> (Q26-Q29, Q31, and Q33-35) all <b><u>had two versions</u></b> (A, and B) - version A was for the professionals and version B was for the non-professionals (as discussed earlier in [[1](#s1)])\n<i>So throughout this analysis, we combine the responses to the two versions of each of these questions wherever needed.</i>\n\nSo given all these details, it is but natural that the questions with worst response rates are the follow-up questions (which were asked to a very few respondents to begin with and therefore only a tiny fraction of the 2020 survey respondents answered these questions).\n\nIt is also worth noting that:\n* The demographic-questions, like age, gender, country of residence, etc. have the highest response rate i.e. most respondents answered these questions properly (with non-NA replies).\n* Most respondents (more than 4-out-of-5) also answered all the questions relating to their current designation and programming experience (languages, notebooks, IDEs, etc.)\n* Apart from the follow-up questions (which naturally have low response rate), the questions relating to professional details and practices, and paid services (e.g. team size, company size, compensation, Auto ML/ cloud products and services,etc.) have relatively poor response rate. \n\n<b><u>Note:</u><br> The question-wise response rates clearly hint at a high percentage of non-professionals (students, unemployed, and people who have never spent any money on cloud/ML products/services) among the respondents.</b> üí≠\n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"ls=survey_2020MCQ.loc[:,~survey_2020MCQ.columns.str.contains('_')].columns\n\ncount_na=survey_2020Q[['Q','short_questions']].drop_duplicates(subset=['Q'])\ncount_na.set_index('Q',inplace=True)\ndf=survey_2020MCQ[['Time from Start to Finish (seconds)']]\ncount_na.loc['Time from Start to Finish (seconds)','%NA']=df[(df.shape[1]-df.isna().sum(axis=1))==0].shape[0]\nfor i in range(39):\n    col='Q'+str(i+1)\n    if col in ls:\n        df=survey_2020MCQ[[col]]\n    else:\n        df=survey_2020MCQ.filter(regex=col)\n    count_na.loc[col,'%NA']=df[(df.shape[1]-df.isna().sum(axis=1))==0].shape[0]\ncount_na['%NA']=1-count_na['%NA']/df.shape[0]\ncount_na.reset_index(inplace=True)\ncount_na['Topic'] = count_na[count_na.columns[:2]].apply(lambda x: '- '.join(x.dropna().astype(str)),axis=1)\ncount_na['Topic'] = count_na['Topic'].str.strip()\ncount_na.loc[count_na['Topic']=='Time from Start to Finish (seconds)- Survey duration, seconds', 'Topic']='Survey-duration (seconds)**'\ncount_na.set_index('Topic', inplace=True)\ncount_na.sort_values(by=['%NA'], inplace=True)\ncount_na=count_na[['%NA']]\ncount_na['color']='silver'\ncount_na.loc[count_na['%NA']>0.5,'color']='khaki'\ncount_na.loc[count_na['%NA']>0.655,'color']='goldenrod'\ncount_na.loc[count_na['%NA']>0.815,'color']='orange'\ncount_na.loc[count_na['%NA']>0.945,'color']='darkorange'\ncount_na.loc[count_na['%NA']==1,'color']='orangered'\n\n\nfig, ax = plt.subplots(1, 1, figsize=(15,12))\nfig.suptitle('(%) 2020-survey-repondents who answered the question*:', fontsize=24, y=1.05)\n    \ncount_na['%NA'].plot.barh(ax=ax, width=0.5, legend=False, color=count_na['color'])\nax.spines[\"top\"].set_visible(False)\nax.spines[\"right\"].set_visible(False)\nax.spines[\"bottom\"].set_visible(False)\n    \n    \nx_axis = ax.axes.get_xaxis()\nx_axis.set_visible(False)\n    \nfor p in  ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(f'{width:.0%}', \n                        (width+0.04, y+.075), fontsize=14, ha='center',weight='normal')\n\nfootnote='$\\it{*all\\ \\'NA\\'s\\ are\\ considered\\ as\\ missing\\ response}$'\nfootnote=footnote+'\\n'+'$\\it{**Survey-duration\\ (seconds)\\ is\\ not\\ a\\ question-topic.\\ It\\ is\\ the\\ time\\ taken\\ by\\ individual\\ responents\\ to\\ finish\\ the\\ survey.}$'\nplt.annotate(footnote, xy=(-0.5, -0.08), xycoords='axes fraction', fontsize=16, color='dimgrey')\n\nplt.yticks(fontsize=14,rotation=0)            \nplt.tight_layout(pad=1)\nplt.show()   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Time taken to complete the survey:</b>\n\nBefore moving on further, it might be worth noting that while the survey seems to be longish, <b><i>the median user took about 10 mins only to complete the survey</i></b>, and even the median professional user, who by design was faced with more questions (relating to their profession and data-science related spending behavior and experiences), completed the survey in only 12.5 minutes. <b><i>~85% repondents completed the 2020 survey in less than half an hour.</i><b>\n<br><br>\n\n---\n\n<i>Note that, 95% of all respondents completed the 2020 survey in less than 4 hours. So we have removed the respondents who took more than 4 hrs to complete the survey while creating the following chart. </i>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df=survey_2020MCQ[['Time from Start to Finish (seconds)','Q5']]\ndf.rename(columns={'Time from Start to Finish (seconds)':'t(sec)'}, inplace=True)\ndf['t(sec)']=df['t(sec)'].astype(int)\ndf['t(min)']=df['t(sec)']/60\ndf.sort_values(by=['t(sec)'], inplace=True)\n#df=df[df['t(min)']<df['t(min)'].quantile(.95)]\ndf.loc[df.Q5.isna(),'Q5']='NA'\nt=pd.DataFrame(df.groupby('Q5')['t(min)'].median())\nt.loc['All','t(min)']=df['t(min)'].median()\nt['colors']='silver'\nt.loc['All','colors']='orangered'\nt.sort_values(by=['t(min)'], inplace=True)\nt.index.name=None\n\nlim=df['t(min)'].quantile(.95)\npro=t.index.tolist()\n\nfig, ax = plt.subplots(len(pro), 1, figsize =(10, 5)) \n\nfor i in range(len(pro)):\n    data=df[df.Q5==pro[i]][df['t(min)']<lim]['t(min)']; colors=['silver']\n    if pro[i]=='All':\n        data=df[df['t(min)']<lim]['t(min)']\n        colors=['orangered']\n        \n    bp = ax[i].boxplot(data, patch_artist = True, \n                notch ='False', vert = 0, showfliers=False, widths=(100)) \n    \n    ax[i].spines[\"top\"].set_visible(False)\n    ax[i].spines[\"right\"].set_visible(False)\n    ax[i].spines[\"bottom\"].set_visible(False)\n    ax[i].spines[\"left\"].set_visible(False)\n  \n     \n  \n    for patch, color in zip(bp['boxes'], colors): \n        patch.set_facecolor(color)\n    for whisker in bp['whiskers']: \n        whisker.set(color ='silver', \n                    linewidth = 1.5, \n                    linestyle =\":\") \n    for cap in bp['caps']: \n        cap.set(color ='dimgrey', \n                linewidth = 2) \n    for median in bp['medians']: \n        median.set(color ='black', \n                   linewidth = 3) \n\n    ax[i].set_yticklabels(pro[i:]) \n    ax[i].set(xlim=(0, 32))\n    x_axis = ax[i].axes.get_xaxis()\n    if i!= len(pro)-1:\n        x_axis.set_visible(False)\n    else:\n        ax[i].set_xlabel('Time (minutes)')\n\nfootnote='\\n'+'$\\it{*For\\ this\\ chart,\\ anyone\\ who\\ took\\ more\\ that\\ ~4\\ hours\\ to\\ complete\\ the\\ survey\\ were\\ ignored.\\ (5%\\ of\\ the\\ respondents)}$'\nplt.annotate(footnote, xy=(0.5, .8), xycoords='axes fraction', fontsize=16, color='dimgrey')\n\nfig.suptitle(\"Time taken to complete the 2020 survey (in  minutes):\", y=1.02) \nplt.tight_layout()\nplt.show(bp) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<i>[Go back to the top](#qa)</i>"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"q2a\"></a>\n### 2.1. Gender distribution\nAccoring to [United Nations](https://population.un.org/wpp/Download/Standard/Population) estimates, the world housed 49.58% females, as of 1 July 2020. Compared to that, only 21% of the survey participants in 2020 identified themselved as female/ LGBTQA+! So </u>as far as gender-equality is concerned, we as a community, have a lot to do.</u> <br> On the brighter side however, this **21% participation rate in 2020** implies a significant **improvement (by 3%)** over the previous year (2019), when the female/ LGBTQA+ survey participation rate was 18%!"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"gender['%Male']=gender['Male']/gender['Overall']\ngender['%Female']=gender['Female']/gender['Overall']\ngender['%LGBTQA+ /Not-specified']=gender['LGBTQA+ /Not-specified']/gender['Overall']\n\nvalue2020=int((gender.loc['2020', '%Female']+gender.loc['2020', '%LGBTQA+ /Not-specified'])*100)\nvalue2019=int((gender.loc['2019', '%Female']+gender.loc['2019', '%LGBTQA+ /Not-specified'])*100)\nfig = go.Figure(go.Indicator(\n    mode = \"gauge+number+delta\",\n    value = value2020,\n    number = {'suffix': \"%\"},\n    domain = {'x': [0, 1], 'y': [0, 1]},\n    title = {'text': \"<span style='font-size:1.0em;color:black'>~1-in-5 survey participants is female/LGBTQA <br><i><span style='font-size:0.8em;color:grey'> a far cry from equal representation</i></span>\", \n             'font': {'size': 24}},\n    delta = {'reference': value2019, 'increasing': {'color': \"grey\"}},\n    gauge = {\n        'axis': {'range': [None, 100], 'tickwidth': 1, 'tickcolor': \"darkblue\"},\n        'bar': {'color': \"orangered\"},\n        'bgcolor': \"white\",\n        'borderwidth': 2,\n        'bordercolor': \"grey\",\n        'steps': [\n            {'range': [0, 49.58], 'color': 'grey'}#,\n            ],#{'range': [250, 400], 'color': 'royalblue'}\n        'threshold': {\n            'line': {'color': \"red\", 'width': 4},\n            'thickness': 0.75,\n            'value': value2020}}))\n\nfig.update_layout(autosize=False, \n                  height=400, \n                  width=800, \n                  paper_bgcolor = \"white\", font = {'color': \"orangered\", 'family': \"comfortaa\"})\n\nfig.add_annotation(text=\"<b><i>Note: The participation from female/LGBTQA+ improved (up 3%) - from 18% in 2019 to 21% in 2020</i></b>\",\n                  xref=\"paper\", yref=\"paper\",\n                  x=0, y=-0.2, showarrow=False)\n\nfig.add_annotation(dict(font=dict(color='grey',size=12),\n                                        x=0,\n                                        y=-0.3,\n                                        showarrow=False,\n                                        text=\"<i>Source: Kaggle 2019-20 survey data<i>\",\n                                        textangle=0,\n                                        xanchor='left',\n                                        xref=\"paper\",\n                                        yref=\"paper\"))\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"On dissecting the data further, we find that <b><i>the improvement in the gender-distribution data comes purely from the female segment (and not LGBTQA+) of participants</i></b>."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"colors = ['dimgrey', 'orangered', 'dimgrey', 'dimgrey']\n#colorsl = ['#676767', 'darkorange', '#808080', '#ff7e5b']\nvar_list=['Overall','Female','Male','LGBTQA+ /Not-specified'] \nfig, ax = plt.subplots(2, 2, figsize=(12,10))\nfig.suptitle('Female Kagglers are on the rise', fontsize=20, y=1.02)\n    \nfor i in range(4):\n    gender[var_list[i]].plot(ax=ax[int(i/2)][i%2], color=[colors[i]], \n                             legend=False, marker='o', linestyle='--', markersize='10')\n    ax[int(i/2)][i%2].spines[\"top\"].set_visible(False)\n    ax[int(i/2)][i%2].spines[\"right\"].set_visible(False)\n    ax[int(i/2)][i%2].spines[\"left\"].set_visible(False)\n    ax[int(i/2)][i%2].set_title(var_list[i], y=1.5)\n    \n    y_axis = ax[int(i/2)][i%2].axes.get_yaxis()\n    y_axis.set_visible(False)\n    \n    for x, y in zip(range(4),gender[var_list[i]]):\n        label = \"{:.0f}\".format(y)\n        if (x==2):\n            x1=x\n            y1=y\n        ax[int(i/2)][i%2].annotate(label,\n                                   (x,y),\n                                   textcoords=\"offset points\",\n                                   xytext=(0,20),\n                                   ha='center',\n                                   color=colors[i],\n                                   fontsize=14)\n        if (i==1 and x==3):\n            ax[int(i/2)][i%2].annotate('', \n                               xy=(x-.15, y-200),  xycoords='data',\n                               xytext=(x1, y1-100), textcoords='data',\n                               arrowprops=dict(facecolor='black', shrink=0.2),\n                               horizontalalignment='right', verticalalignment='top',\n                               )\n\n    textstr = '\\n'.join((r'$2019-20:$',\n                         'Total number of Kagglers surveyed remained stable...'))\n    ax[0][0].text(0, 1.5, textstr, transform=ax[0][0].transAxes, fontsize=14,\n        verticalalignment='top', c='dimgrey')\n    \n    textstr = 'stable base'\n    ax[0][0].text(0.7, 0.4, textstr, transform=ax[0][0].transAxes, fontsize=14,\n        verticalalignment='top', c='dimgrey')\n    \n    textstr = '\\n'.join((r'$2019-20:$',\n                         '...number of female Kagglers increased')) \n    ax[0][1].text(0.18, 1.5, textstr, transform=ax[0][1].transAxes, fontsize=14,\n        verticalalignment='top', c='orangered')\n    \n    textstr = 'sharp rise'\n    ax[0][1].text(0.8, 0.5, textstr, transform=ax[0][1].transAxes, fontsize=14,\n        verticalalignment='top', c='orangered')\n\nfootnote='\\n\\n$\\it Source:\\ 2017-20\\ survey\\ data $'\nax[1][0].annotate(footnote, xy=(0, -0.5), xycoords='axes fraction')\nplt.tight_layout()\nplt.show()    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The improvement in gender-distribution in the community in 2020 becomes even more pronounced when we look at all 4 years of survey data (adjusted for the total number of participants in each of those years). We find that the **female participation rate in 2020 has seen a sharp 3% improvement this year** and after remaining stable for past three years (2017-2019). \n\n<b><u>Takeaway:</u><br> Female Kagglers are on the rise.</b> üìà"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"colors1 = ['silver', 'orangered', 'silver', 'silver']\ncolors = ['dimgrey', 'orangered', 'dimgrey', 'dimgrey']\nvar_list=['%Male','%Female','%LGBTQA+ /Not-specified'] \nfig, ax = plt.subplots(1, 3, figsize=(12,4))\nfig.suptitle('2020 saw a sudden rise in female participation%', fontsize=20, y=1.05)\n    \nfor i in range(3):\n    gender[var_list[i]].plot(ax=ax[i], color=[colors1[i]], \n                             legend=False, marker='o', linestyle='--', markersize='10')\n    ax[i].spines[\"top\"].set_visible(False)\n    ax[i].spines[\"right\"].set_visible(False)\n    ax[i].spines[\"left\"].set_visible(False)\n    \n    ax[i].set_title(var_list[i], y=1.2)\n    \n    \n    y_axis = ax[i].axes.get_yaxis()\n    y_axis.set_visible(False)\n    \n    for x, y in zip(range(4),gender[var_list[i]]):\n        if y>.02:\n            label = \"{:.0%}\".format(y)\n        else:\n            label = \"{:.1%}\".format(y)\n        if (x==2):\n            x1=x\n            y1=y\n        ax[i].annotate(label,\n                                   (x,y),\n                                   textcoords=\"offset points\",\n                                   xytext=(-10,10),\n                                   ha='center',\n                                   color=colors[i],\n                                   fontsize=14)\n        if (i==1 and x==3):\n            ax[i].annotate('', \n                               xy=(x+.055, y-.005),  xycoords='data',\n                               xytext=(x1+.08, y1-.005), textcoords='data',\n                               arrowprops=dict(facecolor='black', shrink=0.2),\n                               horizontalalignment='right', verticalalignment='top',\n                               )\n            \nfootnote='\\n\\n$\\it Source:\\ 2017-20\\ survey\\ data $'\nax[0].annotate(footnote, xy=(-10, -50), xycoords='axes pixels')\nplt.tight_layout()\nplt.show()    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<i>[Go back to the top](#qa)</i>"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"q2b\"></a>\n### 2.2. Country-wise expanse\nGiven the enormous amount of data being generated every day (source: [visualcapitalist](https://www.visualcapitalist.com/wp-content/uploads/2019/04/data-generated-each-day-full.html)), it is but obvious that the world is in need for a large number of sufficiently trained people capable of handling and utilizing it. The natural question then is how well-distributed is our community? Do we have enough people distributed around the world addressing the world's data needs or are there specific data-expert-hubs, that could cater to the data science needs of the rest of the world. <br> This year (2020), the survey was sent out to Kagglers in 171 countries, and to protect the identities of the survey-respondents, countries with less than 50 respondents were grouped together under the common country bucket - 'Other'. As a result, in 2020, we had *54 countries*, each with 50 or more survey-participants and another group of countries, under the name 'Other'.\nCharting world population estimates , as of 1 July 2020, from [United Nations](https://population.un.org/wpp/Download/Standard/Population) and the country-wise survey partication on world maps placed side-by-side, it becomes clear that -\n* At ~30%, India has the highest head-count contribution to the 2020 survey. This is much greater than India's contribution to the world population, which currently stands at ~17.5%\n* While less than 5% of the world's population resides in the U.S.A, and yet more than 11% of the 2020 survey participants reside in the U.S.A.\n* The world's largest country by population, China (>20%), has a suspiciously low participation rate in the 2020 survey (<2.5%). Given that China is one of the leading nations when it comes to data science according to different media sources including [Analytics Insight](https://www.analyticsinsight.net/countries-which-hold-the-greatest-opportunities-for-data-scientists), this low rate of participation from China seems to point at a cultural difference between different countries regarding survey participation. \n\n*Note that for the world population chart, we have used only the data pertaining to people in the age bracket of 15 years or older, since our survey data includes people of age (i.e. 18 years or older only). We could not use 18 years as the minimum age for the UN world-popuation data, because the in raw data from UN, the people in the age bucket 15-19 years were grouped together.*"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"pop_by_country=pd.read_csv('../input/population-by-country-undata/UN_2020population.csv',encoding='latin1')\npop_by_country.rename(columns={'Region, subregion, country or area *':'Country'}, inplace=True)\npop_by_country['Tot']=pop_by_country['Total']\npop_by_country['Total'] = pop_by_country['Total'].div(pop_by_country['Total'].sum())\npop_by_country[pop_by_country['Country']=='India']\nc_list = ['Congo', 'Iran', 'Hong Kong', 'Macao', 'Taiwan', 'Korea', 'Virgin Islands', 'Bolivia', 'Venezuela', 'Micronesia']\nfor i in range(len(c_list)):\n    pop_by_country.loc[pop_by_country.Country.str.contains(c_list[i]),'Country'] = c_list[i]\n\npop_by_country=pop_by_country[pop_by_country['Country']!='Channel Islands']\n\n\n#Code courtesy: This block of code is written following the code at:\n#https://opensource.com/article/20/4/python-map-covid-19\nlist_countries = pop_by_country['Country'].unique().tolist()\nd_country_code = {}  # To hold the country names and their ISO\nfor country in list_countries:\n    try:\n        country_data = pycountry.countries.search_fuzzy(country)\n        country_code = country_data[0].alpha_3\n        d_country_code.update({country: country_code})\n    except:\n        print('could not add ISO 3 code for ->', country)\n        d_country_code.update({country: ' '})\n\nfor k, v in d_country_code.items():\n    pop_by_country.loc[(pop_by_country.Country == k), 'iso_alpha'] = v\n    \n    \n##################################################################################\n\n#Top 5 Countries where most Kagglers reside in\nvar_list=['GenderSelect','Q1','Q2','Q2']\ncountryvar_list = ['Country','Q3','Q3','Q3']\n#colors = ['#E8E7D2', '#C9BA9B', '#BDC2BB', '#FFD0A6']\ncolors = ['grey']*4\ncolors.extend(['orangered'])\n    \npop_by_country=pop_by_country[pop_by_country['Country']!='Channel Islands']\n\nall=pd.DataFrame()\nfem=all\nfor i in range(4):\n    x=str(i+2017)\n    df=globals()['survey_'+x+'MCQ']\n    df=df[~df[countryvar_list[i]].isna()]\n    df=pd.DataFrame(df[countryvar_list[i]].value_counts(normalize=True,ascending=False,dropna=False))\n    if x=='2020':\n        d_2020=df[df.index!='Other']\n    df.columns=[x]\n    df= df[df.index!='Other'].head(n=5)\n    df.sort_values(by=[x], inplace=True)\n    globals()['all'+x]=df\n    all=pd.concat([all, df], axis=1)   \n    df=globals()['survey_'+x+'MCQ']\n    df=pd.DataFrame(df[df[var_list[i]]!='Male'][~df[countryvar_list[i]].isna()][countryvar_list[i]].value_counts(normalize=True,ascending=False,dropna=False))\n    df.columns=[x]\n    df= df[~df.index.isin(['NA','Other'])].head(n=5)\n    df.sort_values(by=[x], inplace=True)\n    globals()['g'+x]=df\n    fem=pd.concat([fem, df], axis=1)\n\nall = all.replace(np.nan, 0, regex=True)\nfem = fem.replace(np.nan, 0, regex=True) \n    \nlist_countries = d_2020.index.tolist()\nd_country_code = {}  # To hold the country names and their ISO\nfor country in list_countries:\n    try:\n        country_data = pycountry.countries.search_fuzzy(country)\n        country_code = country_data[0].alpha_3\n        d_country_code.update({country: country_code})\n    except:\n        #print('could not add ISO 3 code for ->', country)\n        d_country_code.update({country: ' '})\n\nfor k, v in d_country_code.items():\n    d_2020.loc[(d_2020.index == k), 'iso_alpha'] = v\n    \n\nd_2020.loc[(d_2020.index == 'U.S.A.'), 'iso_alpha'] = 'USA'\nd_2020.loc[(d_2020.index == 'South Korea'), 'iso_alpha'] = 'KOR' \nd_2020.loc[(d_2020.index == 'U.K.'), 'iso_alpha'] = 'GBR'\nd_2020.loc[(d_2020.index == 'U.A.E.'), 'iso_alpha'] = 'ARE' \n\nabb=['U.S.A.', 'U.K.']\nfullname=['United States of America', 'United Kingdom']\nfor i in range(len(abb)):\n    pop_by_country.loc[pop_by_country.Country==fullname[i], 'Country'] = abb[i]\n\npop_by_country.loc[pop_by_country.Country.str.contains('Virgin'),'iso_alpha'] = 'VIR'\n###########################################################################\n\nrows = 1\ncols = 2\nfig = make_subplots(\n    rows=rows, cols=cols,\n    specs = [[{'type': 'choropleth'} for c in np.arange(cols)] for r in np.arange(rows)],\n    subplot_titles = ('Population', 'Survey Participation'), horizontal_spacing = 0.0)\n\npop_by_country['text'] = pop_by_country['Country'].astype(str) + ': <br>' + (round(pop_by_country['Total']*100,2)).astype(str) + '%'                                    \ntext = pop_by_country['text'].tolist()\nd_2020['text'] = d_2020.index.astype(str) + ': <br>' + (round(d_2020['Q3']*100,2)).astype(str) + '%'                                    \n\nfor i in range(cols):\n    if i == 0:\n        fig.append_trace(go.Choropleth(hovertext=pop_by_country.text,                          \n            locations=pop_by_country.iso_alpha,\n            z = pop_by_country.Total,zmin=0, zmax=0.3,\n            #locationmode = 'USA-states', # set of locations match entries in `locations`\n            marker_line_color='white', colorscale='Oranges', showscale=True,\n            hoverinfo='text',\n            colorbar=dict(\n            title=\"Concentration\",\n            tickmode=\"array\",\n            tickvals=[0,.15,.3*.95],\n            ticktext=['0%', str(round(max(pop_by_country.Total)*50))+'%',str(30)+'%'])\n        ), row = i//cols+1, col = i%cols+1)\n    else:\n        fig.append_trace(go.Choropleth(hovertext=d_2020.text,\n            locations=d_2020.iso_alpha,\n            z = d_2020.Q3,zmin=0, zmax=0.3,\n            #locationmode = 'USA-states', # set of locations match entries in `locations`\n            marker_line_color='white', colorscale='Oranges', showscale=False,\n            hoverinfo='text',                           \n            #zmin = 0,\n            marker_line_width=0\n            #zmax = max(state_count['total']),\n            #colorbar_title = \"Population\",\n        ), row = i//cols+1, col = i%cols+1)\n        \nfig.update_layout(height=350, margin={\"r\":0},#,\"t\":0,\"l\":0,\"b\":0\n    title_text = 'Population vs. Survey Participation, 2020 - Country-wise distribution',title_font_size=20,\n                 title_x=0.49)\n\nfootnote=\"<b><i>Question: Is China Survey-shy?</i></b>\"\nfootnote=footnote + \"<br><br><i>Source: 2020 survey data</i>\"\nfig.add_annotation(text=footnote,\n                  xref=\"paper\", yref=\"paper\",\n                  x=0, y=-0.5, showarrow=False)\n\nfig.show()\n\nall = all.sort_values(by=['2020'], ascending=False).T\nfem = fem.sort_values(by=['2020'], ascending=False).T\ntop10=all.columns.to_list()\ntop10f=fem.columns.to_list()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at the historical survey data (2017-20), we find that consistently :\n* India has replaced U.S.A. to become the home to the largest number of Kaggle survey participants. (Almost a third of the 2020 survey participants live in India).\n* With more than 1-in-10 participants residing in the U.S.A., U.S.A. is currently home to the second largest number of participants.\n* ~40% of the survey participants live in just two countries, India and U.S.A.\n* ~Half of the survey participants come from just 5 countries every year.\n* Russia with ~3% of the survey participants has also consistently featured in the list of top 5 countries where the participants lived in 2017-20. "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"colorlist=['orangered','darkorange','goldenrod','khaki','whitesmoke','silver','dimgrey',]\ncolorlist1=['black']*6; colorlist1.extend(['white'])\n\nfig = plt.figure(constrained_layout=True, figsize=(12,6))\ngs = fig.add_gridspec(3, 3)\nax0 = fig.add_subplot(gs[0, :])\nax1 = fig.add_subplot(gs[1:, :])\nall.plot.barh(ax=ax1, color=colorlist, stacked=True, legend=False, width=0.8)\nall.loc['Label']=1/(all.shape[1]*2)\nlabels=pd.DataFrame(all.loc['Label'])\nall=all[all.index!='Label']\nlabels.T.plot.barh(ax=ax0, color=colorlist,stacked=True, legend=False, width=0.6)\n\nax1.spines[\"bottom\"].set_visible(False)\nax1.spines[\"top\"].set_visible(False)\nax1.spines[\"right\"].set_visible(False)\n    \nax0.spines[\"bottom\"].set_visible(False)\nax0.spines[\"top\"].set_visible(False)\nax0.spines[\"right\"].set_visible(False)\n\nx_axis = ax0.axes.get_xaxis()\nx_axis.set_visible(False)\nx_axis = ax1.axes.get_xaxis()\nx_axis.set_visible(False)\ny_axis = ax0.axes.get_yaxis()\ny_axis.set_visible(False)\n\n\nax1.set_yticklabels(all.index, fontsize=20)\nax0.spines[\"left\"].set_visible(False)\nax1.spines[\"left\"].set_visible(False)\n\nfor p in  ax1.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        if width>0:\n            if (abs(width-all['China'][0])<0.0001) or (abs(width-all['China'][1])<0.0001):\n                colors0='white'\n            else:\n                colors0='black'\n            ax1.annotate(f'{width:.0%}', (x+width*.4, y+0.3), fontsize=16, weight='bold', color=colors0)\nf0=[0.3,0.25,0.25,0.25,0.22,0.3,0.25]        \nfor p in  ax0.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        if width>0:\n                l=int(x/width)\n                ax0.annotate(labels.index[l], (x+width*f0[l], y+0.25), fontsize=16, weight='bold',color=colorlist1[l])\nfig.suptitle('Top 5: countries with highest number of respondents (2017-2020)', fontsize=20, y=1.05)\nfootnote='\\n\\nNote: This chart shows the #respondendents from the country as a % of all respondents in the year.'\nfootnote=footnote + '\\n$\\it Source:\\ 2017-20\\ survey\\ data $'\nplt.annotate(footnote, xy=(-25, -50), xycoords='axes pixels')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at the female/LGBTQA+ participants only, we find that \n* India and U.S.A. again feature at the top and in that order.\n* U.K. consistently comes third with ~3% of the female/LGBTQA+ participants.\n* Russia did not feature among the top 5 countries after 2018.\n* ~Half of the female/LGBTQA+ reside in just the top 2 countries, viz. India and U.S.A.\n* Interestingly, Turkey with 95 female/LGBTQA+ respondants has stormed its way into the list of top 5 countries for female/LGBTQA+ users in the 2020."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"all=fem[fem.index!='Label']\ncolorlist=['orangered','darkorange','goldenrod','khaki','whitesmoke','silver','dimgrey','black']\n\nfig = plt.figure(constrained_layout=True, figsize=(15,7))\ngs = fig.add_gridspec(3, 3)\nax0 = fig.add_subplot(gs[0, :])\nax1 = fig.add_subplot(gs[1:, :])\nall.plot.barh(ax=ax1, color=colorlist, stacked=True, legend=False, width=0.8)\nall.loc['Label']=1/(all.shape[1]*2)\nlabels=pd.DataFrame(all.loc['Label'])\nall=all[all.index!='Label']\nlabels.T.plot.barh(ax=ax0, color=colorlist,stacked=True, legend=False, width=0.6)\n\nax1.spines[\"bottom\"].set_visible(False)\nax1.spines[\"top\"].set_visible(False)\nax1.spines[\"right\"].set_visible(False)\n    \nax0.spines[\"bottom\"].set_visible(False)\nax0.spines[\"top\"].set_visible(False)\nax0.spines[\"right\"].set_visible(False)\n\nx_axis = ax0.axes.get_xaxis()\nx_axis.set_visible(False)\nx_axis = ax1.axes.get_xaxis()\nx_axis.set_visible(False)\ny_axis = ax0.axes.get_yaxis()\ny_axis.set_visible(False)\n\n\nax1.set_yticklabels(all.index, fontsize=20)\nax0.spines[\"left\"].set_visible(False)\nax1.spines[\"left\"].set_visible(False)\n\nf=0.3; f0=0.4; colors='black'; colors0='black'\nfor p in  ax1.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        if width>0:\n            l=int(x/width)\n            if l>2:\n                    f0=0.25\n                    if width==all.loc['2019','Canada']:\n                        colors0='white'\n                    else:\n                        colors0='black'\n            ax1.annotate(f'{width:.0%}', (x+width*f0, y+0.3), fontsize=16, weight='bold',color=colors0)\n                \nfor p in  ax0.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        if width>0:\n                l=int(x/width)\n                if l>2:\n                    f=0.2\n                if labels.index[l]=='Canada':\n                    colors='white'\n                ax0.annotate(labels.index[l], (x+width*f, y+0.25), fontsize=16, weight='bold', color=colors)\n                \nfig.suptitle('Top 5: countries with highest number of female/ LGBTQA+ respondents (2017-2020)', fontsize=20, y=1.05)\nfootnote='\\n\\nNote: This chart shows the #female/LGBTQA+ respondendents from the country as a % of all female/LGBTQA+ respondents in the year.'\nfootnote=footnote + '\\n$\\it Source:\\ 2017-20\\ survey\\ data $'\nplt.annotate(footnote, xy=(-25, -50), xycoords='axes pixels')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A closer look reveals that among the 10 countries with largest number of female/LGBTQA+ participants in 2020:\n* Indonesia(30%) and Turkey (27%) have the highest share of female/LGBTQA+ participants.\n* Brazil(13%) and Russia(15%) have the lowest share of female/LGBTQA+ participants.\n* Only 5 out of these top 10 countries have average or above-average share of female/LGBTQA+ respondents ([21% of all respondents are female/LGBTQA+](#q3)).\n\n<b><u>Takeaway:</u><br> The jump in the proportion of female respondents is largely driven by the rise in female participation from India.</b>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df=survey_2020MCQ[['Q3', 'Q2','Q1']]\ndf.loc[df['Q2']!='Male','Q2']='female/LGBTQA+'\ndf=pd.crosstab(df.Q3,df.Q2).sort_values(by=['female/LGBTQA+'], ascending=False)\ndf['%female/LGBTQA+']=df['female/LGBTQA+']/(df['Male']+df['female/LGBTQA+'])\ndf=df[df.index!='Other'].head(n=10).sort_values(by=['female/LGBTQA+'], ascending=False)\n\nfig, ax1 = plt.subplots(figsize=(12,5))\nfig.suptitle('Top 10: Countries with largest number of female/LGBTQA+ participants, 2020', fontsize=20, y=1.1)\nax2 = ax1.twinx()  # set up the 2nd axis\nax1.bar(width=0.6,height=df['female/LGBTQA+'],x=df.index, color='grey', \n        label='Number of female/LGBTQA+ respondents') \n\nax2.vlines(df.index,ymin=0, ymax=df['%female/LGBTQA+'], color='navajowhite', linestyle='--')\nax2.plot(df.index, df['%female/LGBTQA+'], \"o\", color='orangered', markersize=8)\n\ny1label = 'Number of female/LGBTQA+ respondents\\n' \nax1.set_ylabel(y1label, fontsize=14).set_color('grey')\nax1.tick_params(length=0, colors='dimgrey')\n\nax2.set_ylabel('\\nfemale/LGBTQA+ respondents\\n (as a % of all respondents in the country)', fontsize=14).set_color('orange')\nax2.set_ylim(0,0.35)\nax2.tick_params(length=0, colors='sandybrown')\n\ni=0\nfor spine in ax1.spines.values():\n    if list(ax1.spines.keys())[i]!='bottom':\n        spine.set_visible(False)\n    i=i+1\n     \ni=0\nfor spine in ax2.spines.values():\n    if list(ax2.spines.keys())[i]!='bottom':\n        spine.set_visible(False)\n    i=i+1\n    \nax2.yaxis.set_major_formatter(ticker.PercentFormatter(decimals=0,xmax=1))\ncounter=-1\nfor p in  ax1.patches:\n        counter=counter+1\n        h=int(df['%female/LGBTQA+'][counter]*100)\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        ax1.annotate(height, (x, height*1.05), fontsize=14, color='dimgrey')\n        ax2.annotate(str(h)+'%',(x+0.1, (h*.01)+.02), color='orange')\n\n\nfootnote='$\\it Source:\\ 2020\\ survey\\ data $'\nplt.annotate(footnote, xy=(-50, -75), xycoords='axes pixels')\nplt.tight_layout(pad=2.0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<u>India vs. U.S.A: A comparative analysis of the paticipation trends</u>**\n\n* As already noted previously, there is a conistently growing number of Indians among the survey-participants (29% in 2020). \n* The same holds true for the cohort of female/LGBTQA+ survey-participants; Indians account for 32% of the female/LGBTQA+ survey participants.\n* Meanwhile, it is a bit surprising to see that even based on the absolute numbers of survey-participants, Americans are a shrinking community as far as the Kaggle surveys are concerned. \n* Another positive takeaway from India: the share of female/LGBTQA+ respondents in India saw a sharp jump this year (thus taking the number of female/LGBTQA+ among every 100 Indian survey-participants to 23, straight up from 17 just a year ago!)\n* The share of female/LGBTQA+ respondents in the U.S.A. meanwhile remained stable at ~25%\n<br><br>\n\n---\n\n<i>The receding number of respondents from U.S.A. adds to our inhibition that there might be a fewer number of repeat survey-respondents i.e. people who submit the survey once, might be less enthusiastic about filling it up again. This is just a hunch and at the moment unverifiable using the available data.</i> <br><br><br>\n<b><u>Relevant suggestions:</u></b>üí°\n- <i>Going forward, it might be worthwhile to ask the respondents to select whether or not they filled the Kaggle survey in any of the previous years.\n- A prefilled survey (with data from the user's public Kaggle profile) could also be provided to the users to encourage more users to respond to the annual survey.</i>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_list = ['all', 'g']\ncounter=0\n\nall=pd.DataFrame()\ng=pd.DataFrame()\ntitle_list = ['Overall', 'Female/ LGBTQA+',\n              'Overall', 'Female/ LGBTQA+']\nfor i in range (2):\n    globals()[df_list[i]]=pd.DataFrame()\n    for j in range(4):\n        x=str(j+2017)\n        df=globals()[df_list[i]+x]\n        df=df.loc[['India', 'U.S.A.']]\n        globals()[df_list[i]]=pd.concat([globals()[df_list[i]],df], axis=1)\n            \n    globals()[df_list[i]]=globals()[df_list[i]].T  \n    \n    \nfor i in range(4):\n    x=str(i+2017)\n    df1=globals()['survey_'+x+'MCQ']\n    df1=df1[df1[countryvar_list[i]].isin(['India', 'U.S.A.'])]\n    df1=pd.DataFrame(df1[countryvar_list[i]].value_counts(dropna=False))\n    df1.columns=[x]\n    df2=globals()['survey_'+x+'MCQ']\n    df2=df2[df2[countryvar_list[i]].isin(['India', 'U.S.A.'])]\n    df2=pd.DataFrame(df2[df2[var_list[i]]!='Male'][countryvar_list[i]].value_counts(dropna=False))\n    df2.columns=[x]\n    if i==0:\n        InUS=df1\n        fem=df2\n    else:\n        InUS=InUS.merge(df1,left_index=True, right_index=True)\n        fem=fem.merge(df2,left_index=True, right_index=True)\n\nInUS=InUS.T\nfem=fem.T\n\nInUS=InUS[['India', 'U.S.A.']]\nfem=fem[['India', 'U.S.A.']]\n\npctf=pd.DataFrame()\npctf['India']=fem['India']/InUS['India']\npctf['U.S.A.']=fem['U.S.A.']/InUS['U.S.A.']\n\nc=2\ndf_list = ['all', 'g','InUS', 'pctf']\n\nfig, ax = plt.subplots(2, c, figsize=(12,9))\nfig.suptitle('Participation from India vs. U.S.A.', fontsize=20, y=1.05)\n\nfor i in range (c*2):\n    df=globals()[df_list[i]]\n    l=df.plot.line(ax=ax[int(i/c)][i%c],legend=False, \n                   markersize=8, marker='o',\n                   linestyle='--',color=['orangered', 'grey'])\n    \n    ax[int(i/c)][i%c].spines['right'].set_visible(False)\n    ax[int(i/c)][i%c].spines['top'].set_visible(False)\n    ax[int(i/c)][i%c].spines['left'].set_visible(False)\n\n    ax[int(i/c)][i%c].set_title(title_list[i], fontsize=20,pad=40)\n\n    \n    for x, y in zip(range(4),df.iloc[:,1].to_list()):\n        \n        if i<=1:\n            label = \"{:.0%}\".format(y)\n        else: \n            label = \"{:.0f}\".format(y)\n        if i==3:\n            label = \"{:.0%}\".format(y)\n            \n        if i==2:\n            off=-20\n                \n        ax[int(i/c)][i%c].annotate(label,\n                                   (x,y),\n                                   textcoords=\"offset points\",\n                                   xytext=(0,10),\n                                   ha='center',\n                                   color='dimgrey',\n                                   fontsize=12)\n        \n    \n    for x, y in zip(range(4),df.iloc[:,0].to_list()):\n        off1=0\n        \n        if i<=1:\n            label = \"{:.0%}\".format(y)\n        else: \n            label = \"{:.0f}\".format(y)\n        if i==3:\n            label = \"{:.0%}\".format(y)\n            \n        if i==0:\n            off=-20\n            \n        if i in ([1,3]):\n            off=10\n            \n        if i in ([2,4]):\n            off1=10\n             \n        ax[int(i/c)][i%c].annotate(label,\n                                   (x,y),\n                                   textcoords=\"offset points\",\n                                   xytext=(off1,off),\n                                   ha='center',\n                                   color='orangered',\n                                   fontsize=12)\n         \n\n\n    y_axis = ax[int(i/c)][i%c].axes.get_yaxis()\n    y_axis.set_visible(False)\n    \nplt.legend(bbox_to_anchor=(-0.1, 1.5), loc='top center', frameon=True, borderaxespad=0.)\ntextstr = '$\\it{(as\\ a\\ percentage\\ of\\ all\\ respondents)}$' \nax[0][0].text(0.15, 1.175, textstr, transform=ax[0][0].transAxes, fontsize=12,\n        verticalalignment='top', c='grey')\ntextstr = '$\\it{(as\\ a\\ percentage\\ of\\ all\\ female/LGBTQA+ respondents)}$' \nax[0][1].text(0.0, 1.175, textstr, transform=ax[0][1].transAxes, fontsize=12,\n        verticalalignment='top', c='grey')\ntextstr = '$\\it{(as\\ a\\ percentage\\ of\\ all\\ respondents\\ from\\ the\\ country)}$' \nax[1][1].text(0.0, 1.175, textstr, transform=ax[1][1].transAxes, fontsize=12,\n        verticalalignment='top', c='grey')\n\nfootnote='$\\it Source:\\ 2017-20\\ survey\\ data $'\nax[1][0].annotate(footnote, xy=(-50, -75), xycoords='axes pixels')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<i>[Go back to the top](#qa)</i>"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"q2c\"></a>\n### 2.3. Age distribution\nComparing all four years of data, it is clear that on an overall basis, age-group-wise:\n* Historically, (25-29) year old paricipants formed the single largest user-group.\n* The <=21 and (22-24) year old groups are catching up fast. \n* So combining these three age buckets, we find that more than half of the participants are less than 30 years old.\n* Less than 10% respondents are above 50.\n* The <=21 year old cohort is the only consistently expanding age-group. <br><br>\n\n---\n\n<i>2018 onward, the survey-participants were asked to select their agegroup (out of **10 options**). Only in 2017, the respondents were given a free-choice to specify their age. As a result, in 2017, the respondents had an option of not specifying their age (which ~20% of the people exercised). For the purpose of this analysis therefore, we disregarded the participants who did not specify their age (so the data for 2017 consists of only ~13.5k (instead of 16.7k) users.  </i>\n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"var_list=['Agegroup','Q2','Q1','Q1']\ngendervar_list=['GenderSelect','Q1','Q2','Q2']\n\nall=pd.DataFrame()\nfem=pd.DataFrame()\n\nfor i in range(4):\n    x=str(i+2017)\n    df=globals()['survey_'+x+'MCQ']\n    df=pd.DataFrame(df[~df[var_list[i]].isna()][var_list[i]].value_counts(normalize=True))\n    df.columns=[x]\n    globals()['all'+x]=df[df.index=='<=21'].append(df[df.index!='<=21'].sort_index())\n    df=globals()['all'+x]\n    all=pd.concat([all,df], axis=1)\n    df=globals()['survey_'+x+'MCQ']\n    df=pd.DataFrame(df[df[gendervar_list[i]]!='Male'][~df[var_list[i]].isna()][var_list[i]].value_counts(normalize=True))\n    df.columns=[x]\n    globals()['g'+x]=df[df.index=='<=21'].append(df[df.index!='<=21'].sort_index())\n    df=globals()['g'+x]\n    fem=pd.concat([fem,df], axis=1)\nall=all.T\nfem=fem.T\n    \ncolorlist=['orangered','darkorange','goldenrod','chocolate','tan','khaki','whitesmoke','silver','dimgrey','black']\n\nfig = plt.figure(constrained_layout=True, figsize=(12,7))\ngs = fig.add_gridspec(3, 3)\nax0 = fig.add_subplot(gs[0, :])\nax1 = fig.add_subplot(gs[1:, :])\nall.plot.barh(ax=ax1, color=colorlist, stacked=True, legend=False, width=0.8)\nall.loc['Label']=1/(all.shape[1]*2)\nlabels=pd.DataFrame(all.loc['Label'])\nall=all[all.index!='Label']\nlabels.T.plot.barh(ax=ax0, color=colorlist,stacked=True, legend=False, width=0.6)\n\nax1.spines[\"bottom\"].set_visible(False)\nax1.spines[\"top\"].set_visible(False)\nax1.spines[\"right\"].set_visible(False)\n    \nax0.spines[\"bottom\"].set_visible(False)\nax0.spines[\"top\"].set_visible(False)\nax0.spines[\"right\"].set_visible(False)\n\nx_axis = ax0.axes.get_xaxis()\nx_axis.set_visible(False)\nx_axis = ax1.axes.get_xaxis()\nx_axis.set_visible(False)\ny_axis = ax0.axes.get_yaxis()\ny_axis.set_visible(False)\n\n\nax1.set_yticklabels(all.index, fontsize=20)\nax0.spines[\"left\"].set_visible(False)\nax1.spines[\"left\"].set_visible(False)\n\nf=0.3; f0=0.4; colors='black'; colors0='black';fs=14;pcount0=0\nfor p in  ax1.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        pcount0=pcount0+1\n        if pcount0>28:\n            fs=8                \n        if pcount0>36:\n                    colors0='silver'\n        if width>0:\n            l=int(x/width)\n            if l>2:\n                    f0=0.25\n            \n            ax1.annotate(f'{width:.0%}', (x+width*f0, y+0.3), fontsize=fs, weight='bold',color=colors0)\nl=-1               \nfor p in  ax0.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        if width>0:\n                l=l+1\n                if l>2:\n                    f=0.2\n                if labels.index[l]=='>=60':\n                    colors='silver'\n                ax0.annotate(labels.index[l], (x+width*f, y+0.25), fontsize=14, weight='bold', color=colors)\n                \nfig.suptitle('Age-wise distribution of respondents: 2017-2020', fontsize=20, y=1.05)\nfootnote='$\\it Source:\\ 2017-20\\ survey\\ data $'\nplt.annotate(footnote, xy=(-50, -75), xycoords='axes pixels')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Limiting our analysis to the female/LGBTQA+ respondents, we find that:\n* 63% of all female/LGBTQA+ respondents are below 40 (vs 56% below 40 out of all survey-respondents).\n* The trend however remains largely same among female/LGBTQA+ participants as well."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"all=fem\nfig = plt.figure(constrained_layout=True, figsize=(12,6))\ngs = fig.add_gridspec(3, 3)\nax0 = fig.add_subplot(gs[0, :])\nax1 = fig.add_subplot(gs[1:, :])\nall.plot.barh(ax=ax1, color=colorlist, stacked=True, legend=False, width=0.8)\nall.loc['Label']=1/(all.shape[1]*2)\nlabels=pd.DataFrame(all.loc['Label'])\nall=all[all.index!='Label']\nlabels.T.plot.barh(ax=ax0, color=colorlist,stacked=True, legend=False, width=0.6)\n\nax1.spines[\"bottom\"].set_visible(False)\nax1.spines[\"top\"].set_visible(False)\nax1.spines[\"right\"].set_visible(False)\n    \nax0.spines[\"bottom\"].set_visible(False)\nax0.spines[\"top\"].set_visible(False)\nax0.spines[\"right\"].set_visible(False)\n\nx_axis = ax0.axes.get_xaxis()\nx_axis.set_visible(False)\nx_axis = ax1.axes.get_xaxis()\nx_axis.set_visible(False)\ny_axis = ax0.axes.get_yaxis()\ny_axis.set_visible(False)\n\n\nax1.set_yticklabels(all.index, fontsize=20)\nax0.spines[\"left\"].set_visible(False)\nax1.spines[\"left\"].set_visible(False)\n\nf=0.3; f0=0.4; colors='black'; colors0='black';fs=14;pcount0=0\nfor p in  ax1.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        pcount0=pcount0+1\n        if pcount0>28:\n            fs=8                \n        if pcount0>36:\n                    colors0='silver'\n        if width>0:\n            l=int(x/width)\n            if l>2:\n                    f0=0.25\n            \n            ax1.annotate(f'{width:.0%}', (x+width*f0, y+0.3), fontsize=fs, weight='bold',color=colors0)\nl=-1               \nfor p in  ax0.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        if width>0:\n                l=l+1\n                if l>2:\n                    f=0.2\n                if labels.index[l]=='>=60':\n                    colors='silver'\n                ax0.annotate(labels.index[l], (x+width*f, y+0.25), fontsize=14, weight='bold', color=colors)\n                \nfig.suptitle('Age-wise distribution of Female/LGBTQA+ respondents: 2017-2020', fontsize=20, y=1.05)\nfootnote='$\\it Source:\\ 2017-20\\ survey\\ data $'\nplt.annotate(footnote, xy=(-50, -75), xycoords='axes pixels')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dissecting the data further, we find that <b>among the top 10 countries with largest number of 2020 survey participants</b>: \n* India has an overwhelmingly high proportion of very young (<=21 year old) survey respondents. \n* Apart from India, China, Nigeria, and Turkey also have a lot of young respondents (younger than 30).\n* On the other end of the spectrum, most of the respondents from countries like U.S.A,, Japan, U.K., and Germany are above 30. <br><br> \n\n---\n\n\n*Note that the following table shows the percentage of respondents in each age-group in each of the top 10 countries (by total number of respondents in 2020). Thus, for instance, it shows that 79% of all Indian survey-participants in 2020 are aged 21 years or less, and only 2% of all survey-participants in 2020 were aged 60 years or above.*"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"top10=pd.DataFrame(survey_2020MCQ[survey_2020MCQ['Q3']!='Other']['Q3'].value_counts(ascending=False).head(n=10)).index.to_list()\nageorder=['<=21','22-24','25-29','30-34','35-39','40-44','45-49','50-54','55-59','>=60']\ntop10.extend(['Rest','Total'])\n#top10.reverse()\ndf=survey_2020MCQ[['Q3', 'Q1']]\ndf=pd.crosstab(df.Q3,df.Q1)\ndf.index.name=None\ndf.columns.name=None\ndf=df[ageorder]\ndf.loc['Total']=df.sum(axis=0)\ndf.loc['Rest']=df[~df.index.isin(top10)].sum(axis=0)\ndf=df[df.index.isin(top10)].reindex(top10)\ndf['Count']=df.sum(axis=1)\npct=int(df.loc['Total','Count'])\n\nfor i in range(len(ageorder)):\n    df[ageorder[i]]=df[ageorder[i]]/df['Count']\ndf['Percent']=df['Count']/pct\nTotal=df['Count'].to_list()\npct=df['Percent'].to_list()\ndf=df.drop(columns=['Count','Percent'])\ntuples = list(product(['Age-groups:']\n                      , df.columns))\ndf.columns = pd.MultiIndex.from_tuples(tuples)\ndf.insert(0, ('2020 respondents:','Count'), Total)\ndf.insert(1, ('2020 respondents:','Percentage'), pct)\n\ndisplay(HTML('<h3>Age-distribution of respondents from different countries in 2020:</h3>'))\n\ndf.style.background_gradient(\n    cmap='Oranges', axis=0, subset=(df.index[:-1],df.columns[2:])).background_gradient(\n    cmap='Greys', axis=1, subset=(df.index[-1],df.columns[2:])).format('{:.0%}').set_properties(**{\n    'font-size': '10pt'}).set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', 'black'),\n        ('font-size', '20px'),\n        ('font-weight', 'bold')\n    ]\n}]).applymap(highlight_cols, subset=df.columns[0:2]).applymap(font_cols, subset=df.columns[0:2]).format({('2020 respondents:','Count'): \"{:.0f}\"})\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The findings from this analyis on the female/LGBTQA+ participants (i.e. all participants excluding the ones who identified as male) are <b>similar but more pronounced</b>. \n* Only 13% of the female/LGBTQA+ respondents are 40 or above (vs 20% above 40 among all respondents in 2020).\n* More than half of the 60+ female/LGBTQA+ participants in 2020 are based in U.S.A, while there are no above 60 year old female/ LGBTQA+ participants from India! \n* Among the top 10 countries by number of female/LGBTQA+ respondents, U.S.A., U.K., Brazil, and Germany have the highest number of elderly participants,  "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"top10=pd.DataFrame(survey_2020MCQ[survey_2020MCQ['Q2']!='Male'][~survey_2020MCQ['Q3'].isin(['Other','NA'])]['Q3'].value_counts(ascending=False).head(n=10)).index.to_list()\nageorder=['<=21','22-24','25-29','30-34','35-39','40-44','45-49','50-54','55-59','>=60']\ntop10.extend(['Rest','Female/LGBTQA+'])\n#top10.reverse()\ndf=survey_2020MCQ[['Q3', 'Q2', 'Q1']][survey_2020MCQ['Q2']!='Male']\ndf=pd.crosstab(df.Q3,df.Q1)\ndf.index.name=None\ndf.columns.name=None\ndf=df[ageorder]\ndf.loc['Female/LGBTQA+']=df.sum(axis=0)\ndf.loc['Rest']=df[~df.index.isin(top10)].sum(axis=0)\ndf=df[df.index.isin(top10)].reindex(top10)\ndf['Count']=df.sum(axis=1)\npct=int(df.loc['Female/LGBTQA+','Count'])\n\nfor i in range(len(ageorder)):\n    df[ageorder[i]]=df[ageorder[i]]/df['Count']\ndf['Percent']=df['Count']/pct\nTotal=df['Count'].to_list()\npct=df['Percent'].to_list()\ndf=df.drop(columns=['Count','Percent'])\ntuples = list(product(['Age-groups:']\n                      , df.columns))\ndf.columns = pd.MultiIndex.from_tuples(tuples)\ndf.insert(0, ('2020 respondents:','Count'), Total)\ndf.insert(1, ('2020 respondents:','Percentage'), pct)\n\ndisplay(HTML('<h3>Age-distribution of female/LGBTQA+ respondents from different countries in 2020:</h3>'))\n\ndf.style.background_gradient(\n    cmap='Oranges', axis=0, subset=(df.index[:-1],df.columns[2:])).background_gradient(\n    cmap='Greys', axis=1, subset=(df.index[-1],df.columns[2:])).format('{:.0%}').set_properties(**{\n    'font-size': '10pt'}).set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', 'black'),\n        ('font-size', '20px'),\n        ('font-weight', 'bold')\n    ]\n}]).applymap(highlight_cols, subset=df.columns[0:2]).applymap(font_cols, subset=df.columns[0:2]).format({('2020 respondents:','Count'): \"{:.0f}\"})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking back at the historical data (2017-20) for India and U.S.A., we find that:\n* The young Indians (<=21 year old) are the most consistently growing bunch.\n* In comparison, the U.S.A. cohort seems to be much more stagnant with minor growth in the older age-groups.\n* Currently, more than a third of the Indian respondents are <=21 year old (vs only 5% users in U.S.A aged <=21 years). \n* The users in the U.S.A. are much more uniformly distributed across different age groups.\n* And a significant 8% of the users in the U.S.A. are aged 60 years or above.\n\nThe age-distribution is largely similar among female/LGBTQA+ Kagglers as well, though -\n* In India: \n    - female/LGBTQA+ are still younger (2-out-of-3 below 25 year old).\n    - In India, only 62 female/LGBTQA+ Kagglers are 40 years or above.\n    - there are no female/LGBTQA+ Kagglers older than 60 years.\n* In U.S.A:\n    - as well, very few women (only 40 female/LGBTQA+ respondents) are in 55 years old or above."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"var_list=['Agegroup','Q2','Q1','Q1']\ngendervar_list=['GenderSelect','Q1','Q2','Q2']\ncountryvar_list = ['Country','Q3','Q3','Q3']\nIU=['India','U.S.A.']\nIUdf=['In','US','Inf','USf']\n\nfor j in range(len(IU)):\n    globals()[IUdf[j]]=pd.DataFrame()\n    globals()[IUdf[j+2]]=pd.DataFrame()\n    for i in range(4):\n        x=str(i+2017)\n        df=globals()['survey_'+x+'MCQ']\n        df=pd.DataFrame(df[df[countryvar_list[i]]==IU[j]][df[var_list[i]]!='NA'][var_list[i]].value_counts(normalize=True))\n        df.columns=[x]\n        df=df[df.index=='<=21'].append(df[df.index!='<=21'].sort_index())\n        globals()[IUdf[j]]=pd.concat([globals()[IUdf[j]],df], axis=1)\n        df=globals()['survey_'+x+'MCQ']\n        df=pd.DataFrame(df[df[countryvar_list[i]]==IU[j]][df[gendervar_list[i]]!='Male'][df[var_list[i]]!='NA'][var_list[i]].value_counts(normalize=True))\n        df.columns=[x]\n        df=df[df.index=='<=21'].append(df[df.index!='<=21'].sort_index())\n        globals()[IUdf[j+2]]=pd.concat([globals()[IUdf[j+2]],df], axis=1)\n    globals()[IUdf[j]]=globals()[IUdf[j]].T\n    globals()[IUdf[j+2]]=globals()[IUdf[j+2]].T\n\ncolorlist=['orangered','darkorange','goldenrod','chocolate','tan','khaki','whitesmoke','silver','dimgrey','black']\n\nfig = plt.figure(constrained_layout=True, figsize=(15,12))\ngs = fig.add_gridspec(5, 6)\nax0 = fig.add_subplot(gs[0, :])\nax1 = fig.add_subplot(gs[1:3, :3])\nax2 = fig.add_subplot(gs[3:, :3])\nax3 = fig.add_subplot(gs[1:3, 3:])\nax4 = fig.add_subplot(gs[3:, 3:])\n\nIn.plot.barh(ax=ax1, color=colorlist, stacked=True, legend=False, width=0.8)\nIn.loc['Label']=1/(In.shape[1]*2)\nlabels=pd.DataFrame(In.loc['Label'])\nIn=In[In.index!='Label']\nlabels.T.plot.barh(ax=ax0, color=colorlist,stacked=True, legend=False, width=0.6)\n\nInf.plot.barh(ax=ax3, color=colorlist, stacked=True, legend=False, width=0.8)\nUS.plot.barh(ax=ax2, color=colorlist, stacked=True, legend=False, width=0.8)\nUSf.plot.barh(ax=ax4, color=colorlist, stacked=True, legend=False, width=0.8)\n\nax1.set_title(IU[0]+\" - Overall\")\nax2.set_title(IU[1]+\" - Overall\")\nax3.set_title(IU[0]+\" - Female/LGBTQA+\")\nax4.set_title(IU[1]+\" - Female/LGBTQA+\")\n\n\nax0.spines[\"bottom\"].set_visible(False)\nax0.spines[\"top\"].set_visible(False)\nax0.spines[\"right\"].set_visible(False)\nax0.spines[\"left\"].set_visible(False)\n\nax1.spines[\"bottom\"].set_visible(False)\nax1.spines[\"top\"].set_visible(False)\nax1.spines[\"right\"].set_visible(False)\nax1.spines[\"left\"].set_visible(False)\n\nax2.spines[\"bottom\"].set_visible(False)\nax2.spines[\"top\"].set_visible(False)\nax2.spines[\"right\"].set_visible(False)\nax2.spines[\"left\"].set_visible(False)\n\nax3.spines[\"bottom\"].set_visible(False)\nax3.spines[\"top\"].set_visible(False)\nax3.spines[\"right\"].set_visible(False)\nax3.spines[\"left\"].set_visible(False)\n\nax4.spines[\"bottom\"].set_visible(False)\nax4.spines[\"top\"].set_visible(False)\nax4.spines[\"right\"].set_visible(False)\nax4.spines[\"left\"].set_visible(False)\n    \nx_axis = ax0.axes.get_xaxis()\nx_axis.set_visible(False)\nx_axis = ax1.axes.get_xaxis()\nx_axis.set_visible(False)\nx_axis = ax2.axes.get_xaxis()\nx_axis.set_visible(False)\nx_axis = ax3.axes.get_xaxis()\nx_axis.set_visible(False)\nx_axis = ax4.axes.get_xaxis()\nx_axis.set_visible(False)\n\ny_axis = ax0.axes.get_yaxis()\ny_axis.set_visible(False)\ny_axis = ax3.axes.get_yaxis()\ny_axis.set_visible(False)\ny_axis = ax4.axes.get_yaxis()\ny_axis.set_visible(False)\n\nax1.set_yticklabels(In.index, fontsize=20)\nax2.set_yticklabels(In.index, fontsize=20)\n\n\nf=0.3; f0=0.4; colors='black'; colors0='black';fs=14;pcount0=0\nfor p in  ax1.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        pcount0=pcount0+1\n        if pcount0>28:\n            fs=8                \n        if pcount0>36:\n                    colors0='silver'\n        if width>0:\n            l=int(x/width)\n            if width<.1:\n                    f0=0.25\n            if width>0.03:\n                ax1.annotate(f'{width:.0%}', (x+width*f0, y+0.3), fontsize=14, weight='bold',color=colors0)\n\nf=0.3; f0=0.4; colors='black'; colors0='black';fs=14;pcount0=0            \nfor p in  ax2.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        pcount0=pcount0+1\n        if pcount0>28:\n            fs=8                \n        if pcount0>36:\n                    colors0='silver'\n        if width>0:\n            l=int(x/width)\n            if width<.1:\n                    f0=0.25\n            if width>0.03:\n                ax2.annotate(f'{width:.0%}', (x+width*f0, y+0.3), fontsize=14, weight='bold',color=colors0)\n            \nf=0.3; f0=0.4; colors='black'; colors0='black';fs=14;pcount0=0\nfor p in  ax3.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        pcount0=pcount0+1\n        if pcount0>28:\n            fs=8                \n        if pcount0>36:\n                    colors0='silver'\n        if width>0:\n            l=int(x/width)\n            if width<.1:\n                    f0=0.25\n            if width>0.03:\n                ax3.annotate(f'{width:.0%}', (x+width*f0, y+0.3), fontsize=14, weight='bold',color=colors0)\n\nf=0.3; f0=0.4; colors='black'; colors0='black';fs=14;pcount0=0\nfor p in  ax4.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        pcount0=pcount0+1\n        if pcount0>28:\n            fs=8                \n        if pcount0>36:\n                    colors0='silver'\n        if width>0:\n            l=int(x/width)\n            if width<.1:\n                    f0=0.25\n            \n            if width>0.03:\n                ax4.annotate(f'{width:.0%}', (x+width*f0, y+0.3), fontsize=14, weight='bold',color=colors0)\n            \nl=-1               \nfor p in  ax0.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        if width>0:\n                l=l+1\n                if l>2:\n                    f=0.2\n                if labels.index[l]=='>=60':\n                    colors='silver'\n                ax0.annotate(labels.index[l], (x+width*f, y+0.25), fontsize=16, weight='bold', color=colors)\n                \nfig.suptitle('India vs. U.S.A.: Participants by age group: 2017-2020', fontsize=24)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<i>[Go back to the top](#qa)</i>"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"q2d\"></a>\n### 2.4. Formal education\nWhile people with masters degree continue to dominate the Kaggling community, the number of users with bachelors degree has started to catch up. There is a sharp drop in the percentage of docatoral candidates this year. Very few users (< 7%) possess no formal degree at all and roughly about 3% users have a professional degree."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"var_list=['FormalEducation','Q4','Q4','Q4']\ngendervar_list=['GenderSelect','Q1','Q2','Q2']\n\nall=pd.DataFrame()\nfem=pd.DataFrame()\n\nfor i in range(4):\n    x=str(i+2017)\n    df=globals()['survey_'+x+'MCQ']\n    df=pd.DataFrame(df[var_list[i]].value_counts(normalize=True))\n    df.columns=[x]\n    globals()['all'+x]=df#[df.index=='<=21'].append(df[df.index!='<=21'].sort_index())\n    df=globals()['all'+x]\n    all=pd.concat([all,df], axis=1)\n    df=globals()['survey_'+x+'MCQ']\n    df=pd.DataFrame(df[df[gendervar_list[i]]!='Male'][var_list[i]].value_counts(normalize=True))\n    df.columns=[x]\n    globals()['g'+x]=df#[df.index=='<=21'].append(df[df.index!='<=21'].sort_index())\n    df=globals()['g'+x]\n    fem=pd.concat([fem,df], axis=1)\nall=all.T\nfem=fem.T\n    \n#colorlist=['orangered','darkorange','goldenrod','chocolate','khaki','whitesmoke','silver','dimgrey','black']\ncolorlist=['orangered','darkorange','goldenrod','chocolate','tan','silver','dimgrey','black']\n\nfig = plt.figure(constrained_layout=True, figsize=(12,6))\ngs = fig.add_gridspec(3, 3)\nax0 = fig.add_subplot(gs[0, :])\nax1 = fig.add_subplot(gs[1:, :])\nall.plot.barh(ax=ax1, color=colorlist, stacked=True, legend=False, width=0.8)\nall.loc['Label']=1/(all.shape[1]*2)\nlabels=pd.DataFrame(all.loc['Label'])\nall=all[all.index!='Label']\nlabels.T.plot.barh(ax=ax0, color=colorlist,stacked=True, legend=False, width=0.6)\n\nax1.spines[\"bottom\"].set_visible(False)\nax1.spines[\"top\"].set_visible(False)\nax1.spines[\"right\"].set_visible(False)\n    \nax0.spines[\"bottom\"].set_visible(False)\nax0.spines[\"top\"].set_visible(False)\nax0.spines[\"right\"].set_visible(False)\n\nx_axis = ax0.axes.get_xaxis()\nx_axis.set_visible(False)\nx_axis = ax1.axes.get_xaxis()\nx_axis.set_visible(False)\ny_axis = ax0.axes.get_yaxis()\ny_axis.set_visible(False)\n\n\nax1.set_yticklabels(all.index, fontsize=20)\nax0.spines[\"left\"].set_visible(False)\nax1.spines[\"left\"].set_visible(False)\n\nf=0.2; f0=0.4; colors='black'; colors0='black';fs=14;pcount0=0\nfor p in  ax1.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        pcount0=pcount0+1\n        if pcount0>28:\n            fs=8                \n        if pcount0>36:\n                    colors0='silver'\n        if width>0:\n            l=int(x/width)\n            if l>2:\n                    f0=0.25\n            \n            ax1.annotate(f'{width:.0%}', (x+width*f0, y+0.3), fontsize=fs, weight='bold',color=colors0)\nl=-1               \nfor p in  ax0.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        \n        if width>0:\n                l=l+1\n                lbl=labels.index[l]; y0=0.25\n                if lbl=='College dropout':\n                    lbl='College\\n dropout'; y0=0.175\n                if l>=4:\n                    f=0.1\n                if labels.index[l]=='>=60':\n                    colors='silver'\n                ax0.annotate(lbl, (x+width*f, y+y0), fontsize=14, weight='bold', color=colors)\n                \nfig.suptitle('Participants by level of formal education: 2017-2020', fontsize=20, y=1.05)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**<u>Takeaways: </u>**\n1. Users with higher degrees dominate Kaggle for the time being (more than half of the users have doctoral, master's, or professional degrees).\n2. Users with only a bachelor's degree or no degree at all are fast catching up (reaching 50%).\n3. The trend is similar across genders.\n\n<b><u>These developments seem to directly connect with the growing number of young respondents from India.</u></b>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"all=fem\ncolorlist=['orangered','darkorange','goldenrod','chocolate','tan','silver','dimgrey','black']\n\nfig = plt.figure(constrained_layout=True, figsize=(12,6))\ngs = fig.add_gridspec(3, 3)\nax0 = fig.add_subplot(gs[0, :])\nax1 = fig.add_subplot(gs[1:, :])\nall.plot.barh(ax=ax1, color=colorlist, stacked=True, legend=False, width=0.8)\nall.loc['Label']=1/(all.shape[1]*2)\nlabels=pd.DataFrame(all.loc['Label'])\nall=all[all.index!='Label']\nlabels.T.plot.barh(ax=ax0, color=colorlist,stacked=True, legend=False, width=0.6)\n\nax1.spines[\"bottom\"].set_visible(False)\nax1.spines[\"top\"].set_visible(False)\nax1.spines[\"right\"].set_visible(False)\n    \nax0.spines[\"bottom\"].set_visible(False)\nax0.spines[\"top\"].set_visible(False)\nax0.spines[\"right\"].set_visible(False)\n\nx_axis = ax0.axes.get_xaxis()\nx_axis.set_visible(False)\nx_axis = ax1.axes.get_xaxis()\nx_axis.set_visible(False)\ny_axis = ax0.axes.get_yaxis()\ny_axis.set_visible(False)\n\n\nax1.set_yticklabels(all.index, fontsize=20)\nax0.spines[\"left\"].set_visible(False)\nax1.spines[\"left\"].set_visible(False)\n\nf=0.2; f0=0.4; colors='black'; colors0='black';fs=14;pcount0=0\nfor p in  ax1.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        pcount0=pcount0+1\n        if pcount0>28:\n            fs=8                \n        if pcount0>36:\n                    colors0='silver'\n        if width>0:\n            l=int(x/width)\n            if l>2:\n                    f0=0.25\n            if l==6:\n                f0==0.3\n            \n            ax1.annotate(f'{width:.0%}', (x+width*f0, y+0.3), fontsize=fs, weight='bold',color=colors0)\nl=-1               \nfor p in  ax0.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        \n        if width>0:\n                l=l+1\n                lbl=labels.index[l]; y0=0.25\n                if lbl=='College dropout':\n                    lbl='College\\n dropout'; y0=0.175\n                if l>=4:\n                    f=0.1\n                if labels.index[l]=='>=60':\n                    colors='silver'\n                ax0.annotate(lbl, (x+width*f, y+y0), fontsize=14, weight='bold', color=colors)\n                \nfig.suptitle('Female/LGBTQA+ Participants by level of formal education: 2017-2020', fontsize=20, y=1.05)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* As expected, more than half of the Indian responents in 2020 hold a Bachelors degree.\n* 1-in-4 respondents from U.K. and Germany have a doctoral degree.\n* About 1-in-10 of the respondents from Japan, Russia, and China are college drop-outs (i.e. studied at some college/ university without any degree). "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"top10=pd.DataFrame(survey_2020MCQ[survey_2020MCQ['Q3']!='Other']['Q3'].value_counts(ascending=False).head(n=10)).index.to_list()\n#ageorder=['<=21','22-24','25-29','30-34','35-39','40-44','45-49','50-54','55-59','>=60']\ndegorder=['High School','College dropout','Bachelors', 'Professional','Masters', 'Doctoral']\ntop10.extend(['Rest','Total'])\ndf=survey_2020MCQ[['Q3', 'Q4']]\ndf=pd.crosstab(df.Q3,df.Q4)\ndf.index.name=None\ndf.columns.name=None\ndf=df[degorder]\ndf.loc['Total']=df.sum(axis=0)\ndf.loc['Rest']=df[~df.index.isin(top10)].sum(axis=0)\ndf=df[df.index.isin(top10)].reindex(top10)\ndf['Count']=df.sum(axis=1)\npct=int(df.loc['Total','Count'])\n\nfor i in range(len(degorder)):\n    df[degorder[i]]=df[degorder[i]]/df['Count']\ndf['Percent']=df['Count']/pct\nTotal=df['Count'].to_list()\npct=df['Percent'].to_list()\ndf=df.drop(columns=['Count','Percent'])\ntuples = list(product(['Highest educational degree:']\n                      , df.columns))\ndf.columns = pd.MultiIndex.from_tuples(tuples)\ndf.insert(0, ('2020 respondents:','Count'), Total)\ndf.insert(1, ('2020 respondents:','Percentage'), pct)\n\ndisplay(HTML('<h2>Education-level of respondents from different countries in 2020:</h2><br><i>(excluding the 866 respondents who did not disclose their educational qualification)</i>'))\n\ndf.style.background_gradient(\n    cmap='Oranges', axis=0, subset=(df.index[:-1],df.columns[2:])).background_gradient(\n    cmap='Greys', axis=1, subset=(df.index[-1],df.columns[2:])).format('{:.0%}').set_properties(**{\n    'font-size': '10pt', 'width': '50px'}).set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', 'black'),\n        ('font-size', '20px'),\n        ('font-weight', 'bold')\n    ]\n}]).applymap(highlight_cols, subset=df.columns[0:2]).applymap(font_cols, subset=df.columns[0:2]).format({('2020 respondents:','Count'): \"{:.0f}\"})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Similarly among the female/LGBTQA+ respondents, \n* Germany, U.S.A., U.K. and China have the a higher share of respondents with masters and doctoral degrees.\n* 1-in-10 respondents from Brazil and Russia have a professional degree.\n* Russia has 4% respondents with only high school qualification (vs. 1% with high school qualification among all female/ LGBTQA+ respondents) \n\n<b><u><i>Gender seems to have relatively little impact on the level of formal education of the respondents.</i></u></b>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"top10=pd.DataFrame(survey_2020MCQ[survey_2020MCQ['Q2']!='Male'][survey_2020MCQ['Q3']!='Other']['Q3'].value_counts(ascending=False).head(n=10)).index.to_list()\n#ageorder=['<=21','22-24','25-29','30-34','35-39','40-44','45-49','50-54','55-59','>=60']\ntop10.extend(['Rest','Total'])\ndf=survey_2020MCQ[['Q3', 'Q2', 'Q4']][survey_2020MCQ['Q2']!='Male']\ndf=pd.crosstab(df.Q3,df.Q4)\ndf.index.name=None\ndf.columns.name=None\ndf=df[degorder]\ndf.loc['Total']=df.sum(axis=0)\ndf.loc['Rest']=df[~df.index.isin(top10)].sum(axis=0)\ndf=df[df.index.isin(top10)].reindex(top10)\ndf['Count']=df.sum(axis=1)\npct=int(df.loc['Total','Count'])\n\nfor i in range(len(degorder)):\n    df[degorder[i]]=df[degorder[i]]/df['Count']\ndf['Percent']=df['Count']/pct\nTotal=df['Count'].to_list()\npct=df['Percent'].to_list()\ndf=df.drop(columns=['Count','Percent'])\ntuples = list(product(['Highest educational degree:']\n                      , df.columns))\ndf.columns = pd.MultiIndex.from_tuples(tuples)\ndf.insert(0, ('2020 respondents:','Count'), Total)\ndf.insert(1, ('2020 respondents:','Percentage'), pct)\n\ndisplay(HTML('<h2>Education-level of female/LGBTQA+ respondents from different countries in 2020:</h2><br><i>(excluding the 242 female/LGBTQA+ respondents who did not disclose their educational qualification)</i>'))\n\ndf.style.background_gradient(\n    cmap='Oranges', axis=0, subset=(df.index[:-1],df.columns[2:])).background_gradient(\n    cmap='Greys', axis=1, subset=(df.index[-1],df.columns[2:])).format('{:.0%}').set_properties(**{\n    'font-size': '10pt', 'width': '50px'}).set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', 'black'),\n        ('font-size', '20px'),\n        ('font-weight', 'bold')\n    ]\n}]).applymap(highlight_cols, subset=df.columns[0:2]).applymap(font_cols, subset=df.columns[0:2]).format({('2020 respondents:','Count'): \"{:.0f}\"})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Majority of the Kagglers in India only have a Bachelor's degree or no degree at all.\n* On the contrary, majority of the Kagglers in U.S.A have a higher degree (master's, doctoral or professional).\n* It is interesting to note that, in India, on a percentage basis, female/LGBTQA+ respondents are consitently more qualified (have a masters degree or higher) compared to their male counterparts. <b>49% females/ LGBTQA+ respondents have a higher degree (masters, doctoral, or professional) vs. 40% male respondents with higher degrees in India.</b> \n\n<b><u>Takeaway</u></b>\n\n* A lot of very young Indians are getting involved in Kaggling. Given their age, they are mostly students/ youngsters with Bachelor's degree only. Given that these young Indians constitute a significantly large portion of the overall user base, their demographics dominate the survey data (and trends) on the whole. \n\n* Though the overall trend is similar across genders, it seems that <b>in India in particular, fewer women/ LGBTQA+ with only a Bachelor's degree (or no degree at all) have access to Kaggle.</b>\n"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#Formal education\ngendvar_list=['GenderSelect','Q1','Q2','Q2']\nqualvar_list=['FormalEducation','Q4','Q4','Q4']\ntitle_list = ['Overall', 'Female/ LGBTQA+']\n\nall=pd.DataFrame()\nfem=pd.DataFrame()\n\nfor i in range(4):\n    x=str(i+2017)\n    df=globals()['survey_'+x+'MCQ'] \n    df=df[~df[qualvar_list[i]].isna()]\n    df1=df[df[gendvar_list[i]]!='Male']\n    df=pd.DataFrame(df[qualvar_list[i]].value_counts(ascending=False,dropna=False))\n    df.columns=[x]\n    df1=pd.DataFrame(df1[qualvar_list[i]].value_counts(ascending=False,dropna=False))\n    df1.columns=[x]\n    all=pd.concat([all,df],axis=1)\n    fem=pd.concat([fem,df1],axis=1)\n        \nall=all.T\nfem=fem.T\nall['All']=all.sum(axis=1)\nfem['All']=fem.sum(axis=1)\n\n#all['Higher degree']=(all['Masters']+all['Doctoral']+all['Professional'])/all['All']\nall['Bachelors/ No degree']=(all['Bachelors']+all['College dropout']+all['High School'])/all['All']\n\n#fem['Higher degree']=(fem['Masters']+fem['Doctoral']+fem['Professional'])/fem['All']\nfem['Bachelors/ No degree']=(fem['Bachelors']+fem['College dropout']+fem['High School'])/fem['All']\n\n\nall=all[['Bachelors/ No degree']]\nall.columns=['All countries']\nfem=fem[['Bachelors/ No degree']]\nfem.columns=['All countries']\nallc=all.copy()\nfemc=fem.copy()\n\n\ngendvar_list=['GenderSelect','Q1','Q2','Q2']\nqualvar_list=['FormalEducation','Q4','Q4','Q4']\ncountryvar_list = ['Country','Q3','Q3','Q3']\ncolors1 = ['orangered','dimgrey', 'black']\ncolors = ['orangered','grey', 'black']\nclist=['India','U.S.A.']\nall=pd.DataFrame()\nfem=all\n\nfor i in range(4):\n    x=str(i+2017)\n    df=globals()['survey_'+x+'MCQ'] \n    df=df[~df[qualvar_list[i]].isna()]\n    df1=df[df[gendvar_list[i]]!='Male']\n    df=df[df[countryvar_list[i]].isin(clist)]\n    df1=df1[df1[countryvar_list[i]].isin(clist)]\n    df=pd.DataFrame(df.groupby(countryvar_list[i])[qualvar_list[i]].value_counts(normalize=True,ascending=False,dropna=False))\n    df=df.unstack(level=0)\n    df=df.droplevel(None, axis=1)\n    df.index.name=None\n    df.columns.name=None\n    df.columns=['India','U.S.A.']\n    df=df.loc[~df.index.isin(['Masters','Doctoral','Professional'])]\n    df.loc[x]=df.sum()\n    df=df.loc[df.index.isin([x])]   \n    all=all.append(df)\n    \n    df1=pd.DataFrame(df1.groupby(countryvar_list[i])[qualvar_list[i]].value_counts(normalize=True,ascending=False,dropna=False))\n    df1=df1.unstack(level=0)\n    df1=df1.droplevel(None, axis=1)\n    df1.index.name=None\n    df1.columns.name=None\n    df1.columns=['India','U.S.A.']\n    df1=df1.loc[~df1.index.isin(['Masters','Doctoral','Professional'])]\n    df1.loc[x]=df1.sum()\n    df1=df1.loc[df1.index.isin([x])]   \n    fem=fem.append(df1)\n\nall=pd.concat([all,allc],axis=1)\nfem=pd.concat([fem,femc],axis=1)\n\ndf_list=['all','fem']\nfig, ax = plt.subplots(1, 2, figsize=(15,7))\nfig.suptitle('U.S.A. vs. India - %Kagglers with Bachelors/ No degree', fontsize=20, y=1.05)\n \n\nfor i in range(len(df_list)):\n    df=globals()[df_list[i]]\n    l=df.plot.line(ax=ax[i],legend=False, \n                   markersize=8, marker='o',\n                   linestyle='--',color=colors)\n    \n    ax[i].spines['right'].set_visible(False)\n    ax[i].spines['top'].set_visible(False)\n    ax[i].spines['left'].set_visible(False)\n\n    ax[i].set_title(title_list[i], fontsize=16,pad=25)\n   \n\n    y_axis = ax[i].axes.get_yaxis()\n    y_axis.set_visible(False)\n    y_axis.set_major_formatter(ticker.PercentFormatter(1.0, decimals=0))\n    \n    for j in range(3):\n        for x, y in zip(range(4),df.T.iloc[j].to_list()):\n            label = \"{:.0%}\".format(y)\n            ax[i].annotate(label,\n                                       (x,y),\n                                       textcoords=\"offset points\",\n                                       xytext=(16,4),\n                                       ha='center',\n                                       color=colors1[j],\n                                       fontsize=16)\n    \n\nax[0].annotate('$\\it *excluding\\ respondents\\ with\\ highest\\ degree\\ =\\ NA$',xy=(0, -0.15), xycoords='axes fraction')\nplt.legend(bbox_to_anchor=(-0.05, 0.75), loc='top center', frameon=True, borderaxespad=0., prop={'size': 16})\nplt.tight_layout()\nplt.show()  \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<i>[Go back to the top](#qa)</i>"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"q2e\"></a>\n### 2.5. Profession (including compensation, company/ team size, and job profile)\n\n* 1-in-4 male respondents is a student.\n* A slightly higher proportion (1-in-3) female/ LGBTQA+ Kagglers is student.\n* Among the professionals, as expected, majority are data scientists (~1-in-10).\n* Software engineers form the next most dominant group (overall).\n* A sizeable portion of the respondents is also currently not employed (about 1-in-10). \n\n<b><u>Note:</u></b> \n* Compared to the group of male users, the group of female/ LGBTQA+ users have a higher proportion of students and unemployed people (i.e. non-professionals).  \n* Overall 27+9=36% are either students or unemployed. \n* Another ~4% (759 respondents) left their profession as 'NA' and are therefore left out of any analyses involving the profession of the respondents. <br><br>"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df=survey_2020MCQ[['Q3','Q2','Q24','Q5']]\ndf.loc[~df['Q2'].str.contains('Male', na=False), 'Q2'] = 'Female/ LGBTQA+'\npd.options.display.float_format = '{:,.0%}'.format  \ndf=df.groupby(['Q2'])['Q5'].value_counts(normalize=True, ascending=True).unstack(level=[0])\ndf.index.name=None\ndf.columns.name=None\ndf.sort_values(['Female/ LGBTQA+'], ascending=False, inplace=True)\n\nall=survey_2020MCQ[['Q3','Q2','Q24','Q5']]\nall=all[~all.Q5.isin(['NA'])]\nall=pd.DataFrame(all['Q5'].value_counts(normalize=True, ascending=True))\nall.index.name=None\nall.columns.name=None\nall.columns=['Overall']\nall.sort_values(['Overall'], ascending=False, inplace=True)\n\n\nfig, ax = plt.subplots(1, 3, figsize=(16,8))  \nfig.suptitle('#Kagglers by current role, 2020', fontsize=20, y=1.05)\nsns.set(font_scale=1.4)\nfor i in range(3):\n    ax[i].xaxis.tick_top()\n    ax[i].xaxis.set_label_position('top')\n    ax[i].tick_params(length=0)\n    \nfmt = lambda x,pos: '{:.0%}'.format(x)\ng=sns.heatmap(all.filter(regex='Overall'), annot=True, fmt='.0%',\n            cbar_kws={'format': FuncFormatter(fmt)}, annot_kws={\"size\": 14},ax=ax[0], cmap=\"Greys\")\ng=sns.heatmap(df.filter(regex='Female/ LGBTQA+'), annot=True, fmt='.0%',\n            cbar_kws={'format': FuncFormatter(fmt)}, annot_kws={\"size\": 14},ax=ax[1], cmap=\"Oranges\")\ndf.sort_values(['Male'], ascending=False, inplace=True)\ng=sns.heatmap(df.filter(regex='Male'), annot=True , fmt='.0%',\n            cbar_kws={'format': FuncFormatter(fmt)}, annot_kws={\"size\": 14},ax=ax[2], cmap=\"Oranges\")\n\nfootnote='*Percentages are calculated after excluding the users who marked their current role as NA (<4%)'\nplt.figtext(0.4, 0.0, footnote, ha=\"center\", fontsize=14, bbox={\"facecolor\":\"white\",\"alpha\":0.5, \"pad\":5})\nplt.tight_layout(pad=2.0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at the country-wise data, we find that:\n* Both India (40%) and China (50%) have high percantage of student respondents.\n* In each of Nigeria (15%), Russia (10%) and India (10%), at least 1-in-10 respondents is currently not employed."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"top10=pd.DataFrame(survey_2020MCQ[survey_2020MCQ['Q3']!='Other']['Q3'].value_counts(ascending=False).head(n=10)).index.to_list()\ntop10.extend(['Rest','Total'])\n\ndf=survey_2020MCQ[['Q3', 'Q5']]\nproflist=pd.DataFrame(df.Q5.value_counts(ascending=False)).index.tolist()\ndf=pd.crosstab(df.Q3,df.Q5)\ndf.index.name=None\ndf.columns.name=None\ndf=df[proflist]\ndf.loc['Total']=df.sum(axis=0)\ndf.loc['Rest']=df[~df.index.isin(top10)].sum(axis=0)\ndf=df[df.index.isin(top10)].reindex(top10)\ndf['Count']=df.sum(axis=1)\npct=int(df.loc['Total','Count'])\n\nfor i in range(len(proflist)):\n    df[proflist[i]]=df[proflist[i]]/df['Count']\ndf['Percent']=df['Count']/pct\nTotal=df['Count'].to_list()\npct=df['Percent'].to_list()\ndf=df.drop(columns=['Count','Percent'])\n\ntuples = list(product(['Current roles:']\n                      , pd.DataFrame(df.columns).replace('/', '/ ', regex=True)[0].tolist()))\ndf.columns = pd.MultiIndex.from_tuples(tuples)\ndf.insert(0, ('2020 respondents:','Count'), Total)\ndf.insert(1, ('2020 respondents:','%'), pct)\n\ndisplay(HTML('<h3>Profession-wise-distribution of respondents from different countries in 2020:</h3>'))\n\ndf.style.background_gradient(\n    cmap='Oranges', axis=0, subset=(df.index[:-1],df.columns[2:])).background_gradient(\n    cmap='Greys', axis=1, subset=(df.index[-1],df.columns[2:])).format('{:.0%}').set_properties(**{\n    'font-size': '10pt', 'width':'20px'}).set_table_styles([{\n    #'selector': 'caption',\n    'props': [\n        ('color', 'black'),\n        ('font-size', '10.5px'),\n        ('font-weight', 'bold')\n    ]\n}]).applymap(highlight_cols, subset=df.columns[0:2]).applymap(font_cols, subset=df.columns[0:2]).format({('2020 respondents:','Count'): \"{:.0f}\"})\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* U.K., Nigeria, U.S.A., all have a high proportion of data-scientists among their female/LGBTQA+ respondents.\n* Countries like India, Turkey, and China also have very high number of students, and very low number of data-scientists among their female/LGBTQA+ folks.\n* It is interesting however to note that, Turkey and China have the highest number of ML engineers among their non-male respondents. "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"top10=pd.DataFrame(survey_2020MCQ[survey_2020MCQ['Q3']!='Other'][survey_2020MCQ.Q2!='Male']['Q3'].value_counts(ascending=False).head(n=10)).index.to_list()\ntop10.extend(['Rest','Total'])\n\ndf=survey_2020MCQ[['Q3', 'Q5', 'Q2']][survey_2020MCQ.Q2!='Male']\nproflist=pd.DataFrame(df.Q5.value_counts(ascending=False)).index.tolist()\ndf=pd.crosstab(df.Q3,df.Q5)\ndf.index.name=None\ndf.columns.name=None\ndf=df[proflist]\ndf.loc['Total']=df.sum(axis=0)\ndf.loc['Rest']=df[~df.index.isin(top10)].sum(axis=0)\ndf=df[df.index.isin(top10)].reindex(top10)\ndf['Count']=df.sum(axis=1)\npct=int(df.loc['Total','Count'])\n\nfor i in range(len(proflist)):\n    df[proflist[i]]=df[proflist[i]]/df['Count']\ndf['Percent']=df['Count']/pct\nTotal=df['Count'].to_list()\npct=df['Percent'].to_list()\ndf=df.drop(columns=['Count','Percent'])\n\ntuples = list(product(['Current roles:']\n                      , pd.DataFrame(df.columns).replace('/', '/ ', regex=True)[0].tolist()))\ndf.columns = pd.MultiIndex.from_tuples(tuples)\ndf.insert(0, ('2020 respondents:','Count'), Total)\ndf.insert(1, ('2020 respondents:','%'), pct)\n\ndisplay(HTML('<h3>Profession-wise-distribution of female/LGBTQA+ respondents from different countries in 2020:</h3>'))\n\ndf.style.background_gradient(\n    cmap='Oranges', axis=0, subset=(df.index[:-1],df.columns[2:])).background_gradient(\n    cmap='Greys', axis=1, subset=(df.index[-1],df.columns[2:])).format('{:.0%}').set_properties(**{\n    'font-size': '10pt', 'width':'20px'}).set_table_styles([{\n    #'selector': 'caption',\n    'props': [\n        ('color', 'black'),\n        ('font-size', '10.5px'),\n        ('font-weight', 'bold')\n    ]\n}]).applymap(highlight_cols, subset=df.columns[0:2]).applymap(font_cols, subset=df.columns[0:2]).format({('2020 respondents:','Count'): \"{:.0f}\"})\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<div class=\"alert alert-warning\" role=\"alert\" style=\"font-size:12px; font-family:comfortaa; line-height: 2.0em;\">\n    üìù &nbsp; <p style=\"font-size:20px; color:orangered; font-family:verdana;\">\n    <b><u>Job description - options provided in 2020 survey  </u></b></p>\n\n<i>Following is the list of options( relating to activities that make up important part(s) of their role at work) that survey participants were asked to choose from in th 2020 survey:</i><br>\n<ul style=\"font-size:16px; color:black; font-family:comfortaa;\">\n  <li>Analyze and understand data to influence product or business decisions</li>\n  <li>Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data</li>\n  <li>Build prototypes to explore applying machine learning to new areas</li>\n  <li>Build and/or run a machine learning service that operationally improves my product or workflows</li>\n   <li>Experimentation and iteration to improve existing ML models</li>\n   <li>Do research that advances the state of the art of machine learning</li>\n   <li>None of these activities are an important part of my role at work</li>\n   <li>Other</li>\n    \n</ul>      \n    \n</div>\n\n\n---\n\nFrom the table below, it is very clear that:\n* Almost all machine learning engineers, and data scientists are required to undertake most of the data-responsibilities listed above as a part of their daily jobs.\n* Software engineers and people in 'Other' professions are least likely to undertake any of these data-related responsibilities at their day jobs.\n* Half of the professionals, irrespective of their jobs are responsible for one or two of these afore-mentioned data-duties.\n\n---\n\n<i>\nQ23 specifically asks about the data-responsibilities at the daily job; it is a question specific to the professionals and therefore has been left unanswered (NA) by all students and currently unemployed respondents. SO all students, currently unemployed and anyone else who left the question with an NA answer is removed from this analysis.</i>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df=survey_2020MCQ[['Q23_Part_7','Q5']]\ndf=df.replace('NA',np.nan)\ndf1=pd.crosstab(df['Q5'],df['Q23_Part_7'])\ndf1.columns=[0]\n\ndf=survey_2020MCQ.filter(regex='Q23').drop(columns=['Q23_Part_7'])\ndf=df.replace('NA',np.nan)\ndf=df.replace('None of these activities are an important part of my role at work',np.nan)\ndf['count']=df.shape[1]-df.isna().sum(axis=1)\ndf=pd.concat([df[['count']],survey_2020MCQ[['Q5']]], axis=1)\ndf=df[~df.Q5.isin(['Student','Currently not employed'])]\ndf=pd.crosstab(df['Q5'],df['count'])\ndf.drop(columns=[0], inplace=True)\ndf=pd.concat([df1,df], axis=1)\ndf.index.name=None\ndf.columns.name=None\ndf['Total']=df.sum(axis=1)\ndf.loc['Total']=df.sum(axis=0)\nfor i in range(df.shape[1]-1):\n    df.iloc[:,i]=df.iloc[:,i]/df['Total']\ndf['grp']=0\ndf.loc[df[0]==1,'grp']=1\ndf.loc['Total','grp']=-1\ndf=df.sort_values(by=['grp',6,5,4,3,2,1,'Total'], ascending=False)\ndf.drop(columns=['grp'], inplace=True)\ndf['pct']=df['Total']/df.loc['Total','Total']\nTotal=df['Total'].to_list()\npct=df['pct'].to_list()\ndf=df.drop(columns=['Total','pct'])\ntuples = list(product(['Number of data-responsibilities that form an integral part of the daily job:'], range(8)))\ndf.columns = pd.MultiIndex.from_tuples(tuples)\ndf.insert(0, ('2020 respondents:','Count'), Total)\ndf.insert(1, ('2020 respondents:','Percentage'), pct)\n\ndisplay(HTML('Number of data-responsibilities undertaken regularly by the professionals at their daily jobs:'))\ndf.style.background_gradient(\n    cmap='Oranges').background_gradient(\n    cmap='Greys', axis=1, subset=(df.index[-1],df.columns[2:])).format('{:.1%}').set_properties(**{\n    'font-size': '10pt', 'width': '60px'}).set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', 'black'),\n        ('font-size', '20px'),\n        ('font-weight', 'bold')\n    ]\n}]).applymap(highlight).applymap(font).applymap(highlight_cols, subset=df.columns[0:2]).applymap(font_cols,subset=df.columns[0:2]).format({('2020 respondents:','Count'): \"{:.0f}\"})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* As expected, data analysis is the most common data responsibility and is undertaken by more than half of all professionals who have at least one data responsibility\n* Building prototypes to explore applying machine learning to new areas is the next most common data-task at daily jobs for the professional respondents.\n\n<b>It is especially promising to see high proportion of professional involved in building prototypes to find new application areas for ML. With this finding in place, one can be doubly sure of the future growth prospects in the industrial use of data-science and especially machine learning.</b>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df=survey_2020MCQ[~survey_2020MCQ.Q5.isin(['Student','Currently not employed'])].filter(regex='Q23')\ndf=df.replace('NA',np.nan)\ndf=df[df.Q23_Part_7!='None of these activities are an important part of my role at work']\ndf.drop(columns=['Q23_Part_7'])\ndf['Count']=df.shape[1]-df.isna().sum(axis=1)\ntot=df.shape[0]\nall=pd.DataFrame()\n\nfor i in range(df.shape[1]-1):\n    df1=df[~df.iloc[:,i].isna()]\n    all[df.columns.tolist()[i]]=df1['Count'].value_counts(ascending=False)\n\ndata_duties=pd.DataFrame(survey_2020Q[survey_2020Q.index.str.contains('Q23')]['questions'].str.split('-',expand=True)[2])\ndata_duties.columns=['duties']\nall=pd.merge(data_duties,all.T, left_index=True,right_index=True)\nall.set_index('duties', inplace=True)\nall.index.name=None\nall['Total']=all.sum(axis=1)\nfor i in range(all.shape[1]-1):\n    all[i+1]=all[i+1]/all['Total']\nall['Percent']=all['Total']/tot\nall=all[all.Percent>0]\nTotal=all['Total']\npct=all['Percent']\ndf=all.drop(columns=['Total','Percent'])\n\ntuples = list(product(['Number of data/ML related responsibilities at work:'], range(1,8)))\ndf.columns = pd.MultiIndex.from_tuples(tuples)\ndf.insert(0, ('2020 respondents:','Count'), Total)\ndf.insert(1, ('2020 respondents:','Percentage'), pct)\n\ndisplay(HTML('<h3>Number of data/ML related responsibilities undertaken regularly by different professionals in 2020:</h3><br><i>excluding respondents who left their data/ML respondibilities as NA</i>'))\n\ndf.sort_values(by=[('2020 respondents:','Percentage')], ascending=False).style.background_gradient(\n    cmap='Oranges', axis=0).format('{:.0%}').bar(subset=[('2020 respondents:','Percentage')], color='gainsboro').set_properties(**{\n    'font-size': '10pt', 'width': '40px'}).set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', 'black'),\n        ('font-size', '20px'),\n        ('font-weight', 'bold')\n    ]\n}]).applymap(highlight_cols, subset=df.columns[0:2]).applymap(font_cols, subset=df.columns[0:2]).format({('2020 respondents:','Count'): \"{:.0f}\"})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Size of employer companies:</b>\n\n* More than a third of the professionals in the data community are employed with small startups with less than 50 employees.\n* Of these professionals, ML engineers stand out as more than half of these ML enineers are employed with small startups with less than 50 employees.\n* Large and very large companies are much more likely to have professionals in traditional data roles like Data Engineer, Data Scintist, Software Engineer, and Business Analyst.\n\n\n---\n\n\nüí≠<b><i> These observations seem to suggest that much of the cutting edge data science work is being undertaken at small startups. The largest firms (with more than 10k employees), meanwhile, are taking a more traditional approach with their data.</i></b>"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df=survey_2020MCQ[~survey_2020MCQ.Q5.isin(['Student','Currently not employed'])][['Q5','Q20','Q21']]\ndf.Q20=df.Q20.str.replace(' employees','')\ndf1=pd.crosstab(df.Q5,df.Q20)\ndf1=df1[['0-49','50-249','250-999', '1000-9,999', '10,000 or more']]\ndf1['Total']=df1.sum(axis=1)\ndf1.sort_values(by=['Total'], ascending=False, inplace=True)\ndf1.loc['Total']=df1.sum(axis=0);\nfor i in range(df1.shape[1]-1):\n    df1.iloc[:,i]=df1.iloc[:,i]/df1['Total']\n\nTotal=df1['Total']\npct=df1['Total']/df1.loc['Total','Total']\ndf1.drop(columns=['Total'], inplace=True)\n\ntuples = list(product(['Company size (Number of employees):'], df1.columns))\ndf1.columns = pd.MultiIndex.from_tuples(tuples)\ndf1.insert(0, ('2020 respondents:','Count'), Total)\ndf1.insert(1, ('2020 respondents:','Percentage'), pct)\ndf1.index.name=None\n\ndisplay(HTML('<h3>Size of the companies where the professional are employed in, 2020:</h3><br><i>excluding respondents who left their company size as NA</i>'))\n\ndf1.style.background_gradient(\n    cmap='Oranges', axis=0).background_gradient(\n    cmap='Greys', axis=1, subset=(df1.index[-1],df1.columns[2:])).format('{:.0%}').set_properties(**{\n    'font-size': '10pt', 'width': '60px'}).set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', 'black'),\n        ('font-size', '20px'),\n        ('font-weight', 'bold')\n    ]\n}]).applymap(highlight_cols, subset=df1.columns[0:2]).applymap(font_cols, subset=df1.columns[0:2]).format({('2020 respondents:','Count'): \"{:.0f}\"})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<b>Data-Team size: <b>\n\nNo surpises here! \n* Larger the company, larger is the data-team size (usually).\n    \n\n---\n    \n    \nThere seems to be a handsomely large community of data-professionals either working in the startup environment. It seems only reasonable to expect that a good number of these data professionals are working with/ founding startups whose core business is in the field of data science.\n    \n    \n   \n---\n\n\nüí≠<b><i> These observations are reassuring - it is likely that a lot of startups are being founded by the data professionals/ working toward the advancement of ML applications. \n<br>Also note that countries like India, U.S.A, Russia, and China have a large number of ML engineers, and as a percentage of the total number of respondens in the country, Turkey and Japan, also are leading nations in this arena.   \n</i></b>\n    \n    \n"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df1=pd.crosstab(df.Q20,df.Q21)\ndf1=df1[['0','1-2','3-4','5-9', '10-14', '15-19', '20+']]\ndf1['Total']=df1.sum(axis=1)\ndf1=df1.reindex(['0-49','50-249','250-999', '1000-9,999', '10,000 or more'])\ndf1.loc['Total']=df1.sum(axis=0);\nfor i in range(df1.shape[1]-1):\n    df1.iloc[:,i]=df1.iloc[:,i]/df1['Total']\n\nTotal=df1['Total']\npct=df1['Total']/df1.loc['Total','Total']\ndf1.drop(columns=['Total'], inplace=True)\n\ntuples = list(product(['Data-team size (Number of employees):'], df1.columns))\ndf1.columns = pd.MultiIndex.from_tuples(tuples)\ndf1.insert(0, ('2020 respondents:','Count'), Total)\ndf1.insert(1, ('2020 respondents:','Percentage'), pct)\ndf1.index.name=None\n\n\ndisplay(HTML('<h3>Size of the companies vs. size of their data-teams, 2020:</h3><br><i>excluding respondents who left their company size as NA</i>'))\n\ndf1.style.background_gradient(\n    cmap='Oranges', axis=0).background_gradient(\n    cmap='Greys', axis=1, subset=(df1.index[-1],df1.columns[2:])).format('{:.0%}').set_properties(**{\n    'font-size': '10pt', 'width': '60px'}).set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', 'black'),\n        ('font-size', '20px'),\n        ('font-weight', 'bold')\n    ]\n}]).applymap(highlight_cols, subset=df1.columns[0:2]).applymap(font_cols, subset=df1.columns[0:2]).format({('2020 respondents:','Count'): \"{:.0f}\"})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Given the growing number of younger users, with bachelor's degree or lower, it is expected that the compensation earned by the pool of Kagglers in their daily jobs would not see much rise. But before even digging into the data, it is important to check the data availability over the years. \n\n - Percentage of users who disclosed their salary in 2017 is pretty low (only 27%).\n - In 2018, this this percentage went up sharply to 65%\n - The percentages in 2019 and 2020 are a bit lower but still consistently above 50%.\n \nSince the pay scales vary vastly depending on the country of residence, it is imperative that we dissect the data by country.\n\nWe focus on our top 2 countries (i.e. countries where highest number of Kagglers reside) - <u> India and U.S.A. </u>\n\n**<u> Takeaways: </u>** \n* The USD compensation data is in line with the demographics of the users in India and U.S.A. respectively, along with the purchasing power parity of these countries.\n* At a cursory glance, there also seems to be a **visible gender pay gap both in India and U.S.A.** (especially given that female/ LGBTQA+ kagglers are at least equally educated formally if not more (as in the case of India)). But this could also be explained partly by the age gap between the genders (on a percentage basis, Kaggle has slightly higher percentage of female/ LGBTQA+ users (compared to their male counterparts).\n\n**<u> Note: </u>** The gender pay gap could also be due to a differnce in the professional designations that male Kagglers are employed in (vs. their female/ LGBTQA+ counteparts), and/ or their coding experience, etc. So, let's check out those parameters next ...\n\n**A final not on compensation: U.S.A. vs India**\n\nDue to the differences in the purchasing power parities between different countries, it makes little sense to compare the USD compensations across differnt counties in general. However, from the analyses so far, and the chart below, it is quite evident that apart from PPP, a part of the the stark difference in the levels of compensations between India and U.S.A and even between the males the females/LGBTQA+ of these two countries can be explained by the difference in level of age, experience, and formal educational qualifications between these cohorts."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"comp=survey_2020MCQ[~survey_2020MCQ.Q24.isin(['NA'])][['Q2','Q3','Q24']]\ncomp.loc[~comp['Q2'].str.contains('Male', na=False), 'Q2'] = 'Female/ LGBTQA+'\ncomp=comp[comp.Q3.isin(['India','U.S.A.'])]\nuser_count=pd.DataFrame(comp.groupby(['Q3','Q2'])['Q24']\n                        .value_counts(normalize=True, ascending=True)).unstack(level=[0,1])\nuser_count.columns = user_count.columns.droplevel(0)\nuser_count.columns = [' '.join(col).strip('_') for col in user_count.columns]\n#user_count = user_count.replace(np.nan, '', regex=True)\nuser_count[['comp','B2']] = user_count.index.to_series().str.split('-',expand=True)\n\n#user_count['B2'] = user_count['B2'].str.replace('$','')\nuser_count['B2'] = user_count['B2'].str.replace(',','')\nuser_count['B2'] = user_count['B2'].str.replace('>','')\nuser_count['B2'] = user_count['B2'].str.replace('NA','')\nuser_count.B2=pd.to_numeric(user_count.B2, errors=\"coerce\")\nuser_count.sort_values(by=['B2'], inplace=True)\nuser_count.index.name=None\n\npd.options.display.float_format = '{:,.0%}'.format\nuser_count.loc[user_count.B2<=500000, 'comp'] = '100,000 - 500,000'\nuser_count.loc[user_count.B2<100000, 'comp'] = '10,000 - 99,999'\nuser_count.loc[user_count.B2<10000, 'comp'] = '1,000 - 9,999'\nuser_count.loc[user_count.B2<1000, 'comp'] = '< $1,000'\nuser_count=pd.DataFrame(user_count.drop(columns='B2').groupby('comp').sum())\nuser_count=user_count[user_count.index=='< $1,000'].append(user_count[user_count.index!='< $1,000'])\nuser_count.index.name=None\n\nfmt = lambda x,pos: '{:.0%}'.format(x)\nfig, ax = plt.subplots(1, 4, figsize=(12,5))  \nfig.suptitle('India & U.S.A - #Kagglers by $compensation, 2020', fontsize=20, y=1.05)\nsns.set(font_scale=1.2)\nfor i in range(4):\n    ax[i].xaxis.tick_top()\n    ax[i].xaxis.set_label_position('top')\n    ax[i].tick_params(length=0)\n\n\ng=sns.heatmap(user_count.filter(regex='India Female'), annot=True, fmt='.0%', \n              cbar_kws={'format': FuncFormatter(fmt)},annot_kws={\"size\": 14},ax=ax[0], cmap=\"Oranges\")\ng=sns.heatmap(user_count.filter(regex='India Male'), \n              cbar_kws={'format': FuncFormatter(fmt)},annot=True, fmt='.0%', yticklabels='', annot_kws={\"size\": 14},ax=ax[1], cmap=\"Oranges\")\ng=sns.heatmap(user_count.filter(regex='U.S.A. Female'), \n              cbar_kws={'format': FuncFormatter(fmt)},annot=True, fmt='.0%', yticklabels='', annot_kws={\"size\": 14},ax=ax[2], cmap=\"Greys\")\ng=sns.heatmap(user_count.filter(regex='U.S.A. Male'), \n              cbar_kws={'format': FuncFormatter(fmt)},annot=True, fmt='.0%', yticklabels='', annot_kws={\"size\": 14},ax=ax[3], cmap=\"Greys\")\n\n#ax.set_title('Less than 2% of all registered users are tiered', pad=10)\n#plt.annotate(footnote, xy=(-0.05, -1.25), xycoords='axes fraction')\nplt.tight_layout(pad=2.0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"cmaps=['Oranges', 'Greys']\ndf=survey_2020MCQ[['Q3','Q2','Q24','Q5']]\ndf=df[df.Q3.isin(['India', 'U.S.A.'])]\ndf.loc[~df['Q2'].str.contains('Male', na=False), 'Q2'] = 'Female/ LGBTQA+'\nall_count=pd.DataFrame(df.groupby(['Q3'])['Q2'].value_counts())\nall_count.columns=['Overall count']\n#all_count\ndf=df[~df.Q24.isin(['NA'])]\ndf=df[~df.Q5.isin(['NA', 'Other'])]\npd.options.display.float_format = '{:,.0f}'.format  \ndf[['comp','B2']] = df.Q24.str.split('-',expand=True)\ndf['B2'] = df['B2'].str.replace(',','')\ndf['B2'] = df['B2'].str.replace('>','')\ndf['B2'] = df['B2'].str.replace('NA','')\ndf.B2=pd.to_numeric(df.B2, errors=\"coerce\")\ndf.loc[df.B2<=500000, 'comp'] = '100,000 - 500,000'\ndf.loc[df.B2<100000, 'comp'] = '10,000 - 99,999'\ndf.loc[df.B2<10000, 'comp'] = '1,000 - 9,999'\ndf.loc[df.B2<1000, 'comp'] = '< $1,000'\ndf=pd.DataFrame(df.drop(columns=['B2','Q24']).groupby(['Q3','Q2','Q5'])['comp'].\n                value_counts()).unstack(3).replace(np.nan, 0, regex=True).droplevel(0, axis=1).reset_index()\ndf.index.name=None\ndf.columns.name=None\n#df['sort']=1\n#df.loc[df.comp=='< $1,000','sort']=0\n#df.loc[df.comp=='> $500,000','sort']=2\n#df.sort_values(by=['Q3','Q2', 'sort','comp'], inplace=True)\n#df.drop(columns=['sort'], inplace=True)\ndf=df[['Q3','Q2','Q5','< $1,000', '1,000 - 9,999', '10,000 - 99,999', '100,000 - 500,000', '> $500,000']]\n\ndf_count=df.groupby(['Q3','Q2']).sum()\ndf_count['count']=df_count.sum(axis=1)\ndf_count=df_count.merge(all_count,left_index=True,right_index=True).reset_index()\ndf_count.index.name=None\ndf_count.columns.name=None\n#df_count\n\nfig, ax = plt.subplots(4, 1, figsize=(15,20))  \nfig.suptitle('India & U.S.A - #Kagglers by current role and $compensation, 2020', fontsize=20, y=1.02)\nsns.set(font_scale=1.2)\nfor i in range(4):\n    ax[i].xaxis.tick_top()\n    ax[i].xaxis.set_label_position('top')\n    ax[i].tick_params(length=0)\n    #ax[i].set_xticklabels(df_sub.columns.to_list(),wrap=True)\n    u=int(df_count.loc[i,'count'])\n    if i>1:\n        c='U.S.A.'\n        clr='grey'\n    else:\n        c='India'\n        clr='orange'\n    if i%2==0:\n        g='Female/ LGBTQA+'\n    else:\n        g='Male'\n        \n    df_sub=df[df.Q3==c] \n    df_sub=df_sub[df_sub.Q2==g]\n    df_sub=df_sub.drop(columns=['Q2','Q3']).set_index('Q5')\n    df_sub.index.name=None\n    \n    ax[i].set_title(c+' - '+g + '(Total '+ str(u) +' users): ', \n                    x=0, fontdict={'fontsize': 16, 'fontweight': 'medium'}, color=clr, pad=5)\n    g=sns.heatmap(df_sub, \n                  annot=True, fmt='.0f', \n                  annot_kws={\"size\": 14},ax=ax[i], \n                  cmap=cmaps[int(i/2)])\nplt.tight_layout(pad=2.0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br><i>[Go back to the top](#qa)</i>"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"q3a\"></a>\n### 3.1. Coding experience, in years\n\n* The median male user has 3-5 years of coding experience whereas the median female/LGBTQA+ user has only 1-2 year of coding expierence. \n* ~Half the users (male and female/ LGBTQA+ taken together) have 1-5 years of coding experience.  \n* 9% female/LGBTQA+ and 5% male users (6% overall) have never coded. \n* 9% female/LGBTQA+ and 18% male users (7% overall) have more than a decade of coding experience.\n\n**<u>Takeaway</u>**<br>\nThe cohort of male Kagglers have more coding experience compared to the cohort of female/ LGBTQA+ Kagglers."},{"metadata":{},"cell_type":"markdown","source":"* Across grenders, there is a general move towards longer coding experience. <br> There are far fewer people in the the less than 1 year coding experience bucket and an increasing number of people in the more than 1 year of coding experience-buckets (including the 20+ years of coding experience)."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#Coding experience:\nproglist=['Q24','Q15','Q6']\n\nall=pd.DataFrame()\nfem=pd.DataFrame()\n\nfor i in range(len(proglist)):\n    x=str(i+2018)\n    df=globals()['survey_'+x+'MCQ']\n    df.loc[df[proglist[i]].str.contains('I have never written', na=False),proglist[i]]='None'\n    df.loc[df[proglist[i]].str.contains('<', na=False),proglist[i]]='<1 year'\n    df.loc[df[proglist[i]].isin(['20-30 years','30-40 years','40+ years']),proglist[i]]='20+ years'\n    df=pd.DataFrame(df[~df[proglist[i]].isna()][proglist[i]].value_counts(normalize=True))\n    df.columns=[x]\n    globals()['all'+x]=df#[df.index=='<=21'].append(df[df.index!='<=21'].sort_index())\n    df=globals()['all'+x]\n    all=pd.concat([all,df], axis=1)\n    df=globals()['survey_'+x+'MCQ']\n    df=pd.DataFrame(df[~df[proglist[i]].isna()][df[gendervar_list[i+1]]!='Male'][proglist[i]].value_counts(normalize=True))\n    df.columns=[x]\n    globals()['g'+x]=df#[df.index=='<=21'].append(df[df.index!='<=21'].sort_index())\n    df=globals()['g'+x]\n    fem=pd.concat([fem,df], axis=1)\nall=all.T\nfem=fem.T\n\nyorder=['None','<1 year','1-2 years','3-5 years','5-10 years','10-20 years','20+ years']\nall=all[yorder]\nfem=fem[yorder]\n    \n#colorlist=['orangered','darkorange','goldenrod','chocolate','khaki','whitesmoke','silver','dimgrey','black']\ncolorlist=['orangered','darkorange','goldenrod','chocolate','tan','silver','dimgrey','black']\nclr=['black']*6\nclr.extend(['white'])\n\nfig = plt.figure(constrained_layout=True, figsize=(15,7))\ngs = fig.add_gridspec(3, 3)\nax0 = fig.add_subplot(gs[0, :])\nax1 = fig.add_subplot(gs[1:, :])\nall.plot.barh(ax=ax1, color=colorlist, stacked=True, legend=False, width=0.8)\nall.loc['Label']=1/(all.shape[1]*2)\nlabels=pd.DataFrame(all.loc['Label'])\nall=all[all.index!='Label']\nlabels.T.plot.barh(ax=ax0, color=colorlist,stacked=True, legend=False, width=0.6)\n\nax1.spines[\"bottom\"].set_visible(False)\nax1.spines[\"top\"].set_visible(False)\nax1.spines[\"right\"].set_visible(False)\n    \nax0.spines[\"bottom\"].set_visible(False)\nax0.spines[\"top\"].set_visible(False)\nax0.spines[\"right\"].set_visible(False)\n\nx_axis = ax0.axes.get_xaxis()\nx_axis.set_visible(False)\nx_axis = ax1.axes.get_xaxis()\nx_axis.set_visible(False)\ny_axis = ax0.axes.get_yaxis()\ny_axis.set_visible(False)\n\n\nax1.set_yticklabels(all.index, fontsize=20)\nax0.spines[\"left\"].set_visible(False)\nax1.spines[\"left\"].set_visible(False)\n\nf=0.2; f0=0.4; colors='black'; colors0='black';fs=16;pcount0=0\nfor p in  ax1.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy(); \n        pcount0=pcount0+1\n        if pcount0>28:\n            fs=8                \n        if width>0:\n            l=int(x/width)\n            if l>2:\n                    f0=0.25\n            if x>0.92:\n                colors0='white';\n            else:\n                colors0='black'\n            ax1.annotate(f'{width:.0%}', (x+width*f0, y+0.3), fontsize=fs, weight='bold',color=colors0)\n            \nl=-1               \nfor p in  ax0.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        \n        if width>0:\n                l=l+1\n                lbl=labels.index[l]; y0=0.25\n                if lbl=='College dropout':\n                    lbl='College\\n dropout'; y0=0.175\n                if l>=4:\n                    f=0.15\n                if labels.index[l]=='>=60':\n                    colors='silver'    \n                ax0.annotate(lbl, (x+width*f, y+y0), fontsize=16, weight='bold', color=clr[l])\n                \n\nfootnote='\\n$\\it *excluding\\ respondents\\ who\\ did\\ not\\ disclose\\ (put\\ NA\\ as)\\ their\\ coding\\ experience$'\nplt.annotate(footnote, xy=(-25, -50), xycoords='axes pixels')                \nfig.suptitle('Participants by years of coding experience: 2018-2020*', fontsize=20, y=1.05)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"all=fem\nfig = plt.figure(constrained_layout=True, figsize=(15,7))\ngs = fig.add_gridspec(3, 3)\nax0 = fig.add_subplot(gs[0, :])\nax1 = fig.add_subplot(gs[1:, :])\nall.plot.barh(ax=ax1, color=colorlist, stacked=True, legend=False, width=0.8)\nall.loc['Label']=1/(all.shape[1]*2)\nlabels=pd.DataFrame(all.loc['Label'])\nall=all[all.index!='Label']\nlabels.T.plot.barh(ax=ax0, color=colorlist,stacked=True, legend=False, width=0.6)\n\nax1.spines[\"bottom\"].set_visible(False)\nax1.spines[\"top\"].set_visible(False)\nax1.spines[\"right\"].set_visible(False)\n    \nax0.spines[\"bottom\"].set_visible(False)\nax0.spines[\"top\"].set_visible(False)\nax0.spines[\"right\"].set_visible(False)\n\nx_axis = ax0.axes.get_xaxis()\nx_axis.set_visible(False)\nx_axis = ax1.axes.get_xaxis()\nx_axis.set_visible(False)\ny_axis = ax0.axes.get_yaxis()\ny_axis.set_visible(False)\n\n\nax1.set_yticklabels(all.index, fontsize=20)\nax0.spines[\"left\"].set_visible(False)\nax1.spines[\"left\"].set_visible(False)\n\nf=0.2; f0=0.4; colors='black'; colors0='black';fs=16;pcount0=0\nfor p in  ax1.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy(); \n        pcount0=pcount0+1\n        if pcount0>28:\n            fs=8                \n        if width>0:\n            l=int(x/width)\n            if l>2:\n                    f0=0.25\n            if x>0.96:\n                colors0='white';\n            else:\n                colors0='black'\n            ax1.annotate(f'{width:.0%}', (x+width*f0, y+0.3), fontsize=fs, weight='bold',color=colors0)\n            \nl=-1               \nfor p in  ax0.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        \n        if width>0:\n                l=l+1\n                lbl=labels.index[l]; y0=0.25\n                if lbl=='College dropout':\n                    lbl='College\\n dropout'; y0=0.175\n                if l>=4:\n                    f=0.15\n                if labels.index[l]=='>=60':\n                    colors='silver'    \n                ax0.annotate(lbl, (x+width*f, y+y0), fontsize=16, weight='bold', color=clr[l])\n                \n\nfootnote='\\n$\\it *excluding\\ respondents\\ who\\ did\\ not\\ disclose\\ (put\\ NA\\ as)\\ their\\ coding\\ experience$'\nplt.annotate(footnote, xy=(-25, -50), xycoords='axes pixels')                \nfig.suptitle('Female/LGBTQA+ participants by years of coding experience: 2018-2020*', fontsize=20, y=1.05)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Male users residing in the U.S.A., U.K., Japan, and Germany are clearly ahead of the others in terms coding experience.\n* The female/ LGBTQA+ users in the U.S.A., and U.K. are also very experienced coders.\n* There is little difference between male and female/ LGBTQA+ users in India, and on the whole, most of them have 1-5 years of coding experience.\n\n**<u>Takeaway</u>**<br>\nA part of the the difference in compensation between different gender groups could perhaps be explained by the difference in the coding experience (especially in the U.S.A.). "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"top10=pd.DataFrame(survey_2020MCQ[survey_2020MCQ['Q3']!='Other']['Q3'].value_counts(ascending=False).head(n=10)).index.to_list()\n\ndf=survey_2020MCQ[['Q6','Q3']][~survey_2020MCQ['Q6'].isna()]\ndf.loc[~df.Q3.isin(top10),'Q3']='Rest'\ntop10.extend(['Rest', 'Total'])\ndf=df.replace('I have never written code','None')\ndf=pd.crosstab(df['Q3'],df['Q6'])\ndf.index.name=None\ndf.columns.name=None\ncol=['None','<1 year','1-2 years', '3-5 years','5-10 years','10-20 years', '20+ years']\ndf=df[col]\ndf=df.reindex(top10)\ndf['Total']=df.sum(axis=1)\ndf.loc['Total']=df.sum(axis=0)\nfor i in range(df.shape[1]-1):\n    df.iloc[:,i]=df.iloc[:,i]/df['Total']\ndf['pct']=df['Total']/df.loc['Total','Total']\nTotal=df['Total'].to_list()\npct=df['pct'].to_list()\ndf=df.drop(columns=['Total','pct'])\ntuples = list(product(['Coding experience(#years):'], df.columns))\ndf.columns = pd.MultiIndex.from_tuples(tuples)\ndf.insert(0, ('2020 respondents:','Count'), Total)\ndf.insert(1, ('2020 respondents:','Percentage'), pct)\ndisplay(HTML('<h2>Coding experience (#years) of respondents from top 10 countries:</h2>'))\ndisplay(HTML('<i>*excluding respondents who marked their coding experience as NA</i>'))\ndf.style.background_gradient(\n    cmap='Oranges').background_gradient(\n    cmap='Greys', axis=1, subset=(df.index[-1],df.columns[2:])).format('{:.1%}').set_properties(**{\n    'font-size': '10pt', 'width': '60px'}).set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', 'black'),\n        ('font-size', '20px'),\n        ('font-weight', 'bold')\n    ]\n}]).applymap(highlight).applymap(font).applymap(highlight_cols, subset=df.columns[0:2]).applymap(font_cols,subset=df.columns[0:2]).format({('2020 respondents:','Count'): \"{:.0f}\"})\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"top10=pd.DataFrame(survey_2020MCQ[survey_2020MCQ['Q3']!='Other'][survey_2020MCQ['Q2']!='Male']['Q3'].value_counts(ascending=False).head(n=10)).index.to_list()\n\ndf=survey_2020MCQ[survey_2020MCQ['Q2']!='Male'][['Q6','Q3']][~survey_2020MCQ['Q6'].isna()]\ndf.loc[~df.Q3.isin(top10),'Q3']='Rest'\ntop10.extend(['Rest', 'Total'])\ndf=df.replace('I have never written code','None')\ndf=pd.crosstab(df['Q3'],df['Q6'])\ndf.index.name=None\ndf.columns.name=None\ncol=['None','<1 year','1-2 years', '3-5 years','5-10 years','10-20 years', '20+ years']\ndf=df[col]\ndf=df.reindex(top10)\ndf['Total']=df.sum(axis=1)\ndf.loc['Total']=df.sum(axis=0)\nfor i in range(df.shape[1]-1):\n    df.iloc[:,i]=df.iloc[:,i]/df['Total']\ndf['pct']=df['Total']/df.loc['Total','Total']\nTotal=df['Total'].to_list()\npct=df['pct'].to_list()\ndf=df.drop(columns=['Total','pct'])\ntuples = list(product(['Coding experience(#years):'], df.columns))\ndf.columns = pd.MultiIndex.from_tuples(tuples)\ndf.insert(0, ('2020 respondents:','Count'), Total)\ndf.insert(1, ('2020 respondents:','Percentage'), pct)\ndisplay(HTML('<h2>Coding experience (#years) of female/LGBTQA+ respondents from top 10 countries:</h2>'))\ndisplay(HTML('<i>*excluding respondents who marked their coding experience as NA</i>'))\ndf.style.background_gradient(\n    cmap='Oranges').background_gradient(\n    cmap='Greys', axis=1, subset=(df.index[-1],df.columns[2:])).format('{:.1%}').set_properties(**{\n    'font-size': '10pt', 'width': '60px'}).set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', 'black'),\n        ('font-size', '20px'),\n        ('font-weight', 'bold')\n    ]\n}]).applymap(highlight).applymap(font).applymap(highlight_cols, subset=df.columns[0:2]).applymap(font_cols,subset=df.columns[0:2]).format({('2020 respondents:','Count'): \"{:.0f}\"})\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br><i>[Go back to the top](#qa)</i>"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"q3b\"></a>\n### 3.2. Programming languages, data visualization libraries/tools and BI tools\n\n<b>Programming Languages:</b>\nAmong the respondents in 2020:\n* 24% did not use any programming language\n* More than half the respondents used 1-2 programming lanuages.\n* Only 5% of the respondents used more than 4 programming languages on a regular basis."},{"metadata":{"trusted":true},"cell_type":"code","source":"df=survey_2020MCQ[['Q7_Part_12','Q5']]\ndf=df.replace('NA',np.nan)\ndf1=pd.crosstab(df['Q5'],df['Q7_Part_12'])\ndf1.columns=[0]\n\ndf=survey_2020MCQ.filter(regex='Q7').drop(columns=['Q7_Part_12'])\ndf=df.replace('NA',np.nan)\ndf['count']=df.shape[1]-df.isna().sum(axis=1)\ndf=pd.concat([df[['count']],survey_2020MCQ[['Q5']]], axis=1)\ndf=pd.crosstab(df['Q5'],df['count'])\ndf.drop(columns=[0], inplace=True)\ndf=pd.concat([df1,df], axis=1)\n\ndf.index.name=None\ndf.columns.name=None\ndf['Total']=df.sum(axis=1)\ndf.loc['Total']=df.sum(axis=0)\nfor i in range(df.shape[1]-1):\n    df.iloc[:,i]=df.iloc[:,i]/df['Total']\n\ndf=df.sort_values(by=['Total'], ascending=False)\ndf=df.drop(['Total'], axis=0).append(df.loc['Total'])\ndf['pct']=df['Total']/df.loc['Total','Total']\nTotal=df['Total'].to_list()\npct=df['pct'].to_list()\ndf=df.drop(columns=['Total','pct'])\ntuples = list(product(['Number of programming languages used regularly:'], range(df.shape[1])))\ndf.columns = pd.MultiIndex.from_tuples(tuples)\ndf.insert(0, ('2020 respondents:','Count'), Total)\ndf.insert(1, ('2020 respondents:','Percentage'), pct)\n\ndisplay(HTML('<h2>Number of programming languages used on a regular basis:</h2>'))\ndisplay(HTML('<i>*excluding respondents who put NA for in response</i>'))\n\n\ndf.style.background_gradient(\n    cmap='Oranges', axis=0).background_gradient(\n    cmap='Greys', axis=1, subset=(df.index[-1],df.columns[2:])).format('{:.1%}').set_properties(**{\n    'font-size': '10pt', 'width': '40px'}).set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', 'black'),\n        ('font-size', '20px'),\n        ('font-weight', 'bold')\n    ]\n}]).applymap(highlight).applymap(font).applymap(highlight_cols, subset=df.columns[0:2]).applymap(font_cols,subset=df.columns[0:2]).format({('2020 respondents:','Count'): \"{:.0f}\"}).format({('2020 respondents:','Percentage'): \"{:.0%}\"})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By looking at each particular programming language indiviadually, we find that:\n* With 78% of the respondents using Python on a regular basis, it is the undisputed favorite programming language for the data-science community\n* SQL and R are also used regularly by a sizable portion of the population.\n* More than 25% those who use these three languages, (viz. Python, SQl, and R), do so exclusively.<br> This goes to show how powerful these languages are, even on a standalone basis.\n* All the rest of the languages specified in teh survey are predominantly used alongside with one or more of the other programming languages.\n* Julia, and Swift, for instance, are only used by a tiny minority, and that too in unison with a host of other programming languages. "},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df=survey_2020MCQ[survey_2020MCQ['Q7_Part_12']!='None'].filter(regex='Q7').drop(columns=['Q7_Part_12'])\ndf=df.replace('NA',np.nan)\ndf['Count']=df.shape[1]-df.isna().sum(axis=1)\ntot=df.shape[0]\nall=pd.DataFrame()\n\nfor i in range(df.shape[1]-1):\n    df1=df[~df.iloc[:,i].isna()]\n    all[df.columns.tolist()[i]]=df1['Count'].value_counts(ascending=False)\n\nprogs=pd.DataFrame(survey_2020Q[survey_2020Q.index.str.contains('Q7')]['questions'].str.split('-',expand=True)[2])\nprogs.columns=['progs']\nall=pd.merge(progs,all.T, left_index=True,right_index=True)\nall.set_index('progs', inplace=True)\nall.index.name=None\nall['Total']=all.sum(axis=1)\nall[10]=all[10]+all[11]+all[12]\nall.drop(columns=[11,12], inplace=True)\nfor i in range(all.shape[1]-1):\n    all[i+1]=all[i+1]/all['Total']\nall['Percent']=all['Total']/tot\nall.sort_values(by=['Total'], ascending=False, inplace=True)\nTotal=all['Total']\npct=all['Percent']\ndf=all.drop(columns=['Total','Percent'])\n\ntuples = list(product(['Number of programming languages used regularly:'], range(1,df.shape[1]+1)))\ndf.columns = pd.MultiIndex.from_tuples(tuples)\ndf.insert(0, ('2020 respondents:','Count'), Total)\ndf.insert(1, ('2020 respondents:','Percentage'), pct)\ndf.rename(columns={10:'10+'}, inplace=True)\n\ndisplay(HTML('<h3>The regularly used programming languages:</h3><br><i>excluding respondents who did not disclose their programming language preferences</i>'))\n\ndf.style.background_gradient(\n    cmap='Oranges', axis=0).format('{:.1%}').bar(subset=[('2020 respondents:','Percentage')], color='gainsboro').set_properties(**{\n    'font-size': '10pt', 'width': '50px'}).set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', 'black'),\n        ('font-size', '20px'),\n        ('font-weight', 'bold')\n    ]\n}]).applymap(highlight_cols, subset=df.columns[0:2]).applymap(font_cols, subset=df.columns[0:2]).format({('2020 respondents:','Count'): \"{:.0f}\"}).format({('2020 respondents:','Percentage'): \"{:.0%}\"})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Over the years, Python is gaining ground as the community favorite (even as the recommended first programming language for aspiring data scientists); meanwhile, R is phasing out."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"proglist = ['LanguageRecommendationSelect', 'Q18','Q19','Q8']\nall=pd.DataFrame()\nfem=pd.DataFrame()\n\nfor i in range(len(proglist)):\n    x=str(i+2017)\n    df=globals()['survey_'+x+'MCQ']\n    df.loc[df[proglist[i]].isin(['C','C++']),proglist[i]]='C/C++/C#'\n    df.loc[df[proglist[i]].isin(['MATLAB']),proglist[i]]='Matlab'\n    df=pd.DataFrame(df[~df[proglist[i]].isna()][proglist[i]].value_counts(normalize=True))\n    df.columns=[x]\n    globals()['all'+x]=df#[df.index=='<=21'].append(df[df.index!='<=21'].sort_index())\n    df=globals()['all'+x]\n    all=pd.concat([all,df], axis=1)\n    df=globals()['survey_'+x+'MCQ']\n    df.loc[df[proglist[i]].isin(['C','C++']),proglist[i]]='C/C++/C#'\n    df.loc[df[proglist[i]].isin(['MATLAB']),proglist[i]]='Matlab'\n    df=pd.DataFrame(df[~df[proglist[i]].isna()][df[gendervar_list[i]]!='Male'][proglist[i]].value_counts(normalize=True))\n    df.columns=[x]\n    globals()['g'+x]=df#[df.index=='<=21'].append(df[df.index!='<=21'].sort_index())\n    df=globals()['g'+x]\n    fem=pd.concat([fem,df], axis=1)\nall=all.head(n=5).T\nfem=fem.head(n=5).T\n    \n#colorlist=['orangered','darkorange','goldenrod','chocolate','khaki','whitesmoke','silver','dimgrey','black']\ncolorlist=['orangered','darkorange','goldenrod','tan','silver','dimgrey','black']\n\nfig = plt.figure(constrained_layout=True, figsize=(15,7))\ngs = fig.add_gridspec(3, 3)\nax0 = fig.add_subplot(gs[0, :])\nax1 = fig.add_subplot(gs[1:, :])\nall.plot.barh(ax=ax1, color=colorlist, stacked=True, legend=False, width=0.8)\nall.loc['Label']=1/(all.shape[1]*2)\nlabels=pd.DataFrame(all.loc['Label'])\nall=all[all.index!='Label']\nlabels.T.plot.barh(ax=ax0, color=colorlist,stacked=True, legend=False, width=0.6)\n\nax1.spines[\"bottom\"].set_visible(False)\nax1.spines[\"top\"].set_visible(False)\nax1.spines[\"right\"].set_visible(False)\n    \nax0.spines[\"bottom\"].set_visible(False)\nax0.spines[\"top\"].set_visible(False)\nax0.spines[\"right\"].set_visible(False)\n\nx_axis = ax0.axes.get_xaxis()\nx_axis.set_visible(False)\nx_axis = ax1.axes.get_xaxis()\nx_axis.set_visible(False)\ny_axis = ax0.axes.get_yaxis()\ny_axis.set_visible(False)\n\n\nax1.set_yticklabels(all.index, fontsize=20)\nax0.spines[\"left\"].set_visible(False)\nax1.spines[\"left\"].set_visible(False)\n\nf=0.3; f0=0.4; colors='black'; colors0='black';fs=16;pcount0=0\nfor p in  ax1.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        pcount0=pcount0+1\n        if pcount0>28:\n            fs=8                \n        if pcount0>36:\n                    colors0='silver'\n        if width>0:\n            l=int(x/width)\n            if l>2:\n                    f0=0.25\n            \n            ax1.annotate(f'{width:.0%}', (x+width*f0, y+0.3), fontsize=fs, weight='bold',color=colors0)\nl=-1               \nfor p in  ax0.patches:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        \n        if width>0:\n                l=l+1\n                lbl=labels.index[l]; y0=0.25\n                if lbl=='College dropout':\n                    lbl='College\\n dropout'; y0=0.175\n                if l>=4:\n                    f=0.35\n                if labels.index[l]=='>=60':\n                    colors='silver'\n                ax0.annotate(lbl, (x+width*f, y+y0), fontsize=16, weight='bold', color=colors)\n\n#footnote='\\n$\\it *excluding\\ respondents\\ who\\ did\\ not\\ disclose\\ (put\\ NA\\ as)\\ their\\ coding\\ experience$'\n#plt.annotate(footnote, xy=(-25, -50), xycoords='axes pixels')                \nfig.suptitle('Recommended programming language to be learnt first by aspiring data scientists: 2017-2020*', fontsize=20, y=1.05)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br><i>[Go back to the top](#qa)</i>"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"q3c\"></a>\n### 3.3. Integrated Development Environments (IDE's)\n\n* 80% of the respondents use 1-3 IDEs.\n* More than 1-in-4 users use one IDE only.\n* Very few (~2%) users do not use any IDE at all.\n\n---\n\nThis goes to show the importance of IDE in the field of data science. One can hardly do without a good IDE!"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df=survey_2020MCQ[['Q9_Part_11','Q5']]\ndf=df.replace('NA',np.nan)\ndf1=pd.crosstab(df['Q5'],df['Q9_Part_11'])\ndf1.columns=[0]\n\ndf=survey_2020MCQ[survey_2020MCQ.Q9_Part_11!='None'].filter(regex='Q9').drop(columns=['Q9_Part_11'])\ndf=df.replace('NA',np.nan)\ndf['count']=df.shape[1]-df.isna().sum(axis=1)\ndf=pd.concat([df[['count']],survey_2020MCQ[['Q5']]], axis=1)\ndf=pd.crosstab(df['Q5'],df['count'])\ndf.drop(columns=[0], inplace=True)\ndf=pd.concat([df1,df], axis=1)\n\ndf.index.name=None\ndf.columns.name=None\ndf['Total']=df.sum(axis=1)\ndf.loc['Total']=df.sum(axis=0)\nfor i in range(df.shape[1]-1):\n    df.iloc[:,i]=df.iloc[:,i]/df['Total']\n\ndf=df.sort_values(by=['Total'], ascending=False)\ndf=df.drop(['Total'], axis=0).append(df.loc['Total'])\ndf['pct']=df['Total']/df.loc['Total','Total']\nTotal=df['Total'].to_list()\npct=df['pct'].to_list()\ndf=df.drop(columns=['Total','pct'])\ntuples = list(product(['Number of IDE(s) used regularly:'], range(df.shape[1])))\ndf.columns = pd.MultiIndex.from_tuples(tuples)\ndf.insert(0, ('2020 respondents:','Count'), Total)\ndf.insert(1, ('2020 respondents:','Percentage'), pct)\n\ndisplay(HTML('<h3>The regularly used IDEs:</h3><br><i>excluding respondents who did not disclose their IDE preferences</i>'))\n\ndf.style.background_gradient(\n    cmap='Oranges', axis=0).background_gradient(\n    cmap='Greys', axis=1, subset=(df.index[-1],df.columns[2:])).format('{:.1%}').set_properties(**{\n    'font-size': '10pt', 'width': '40px'}).set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', 'black'),\n        ('font-size', '20px'),\n        ('font-weight', 'bold')\n    ]\n}]).applymap(highlight).applymap(font).applymap(highlight_cols, subset=df.columns[0:2]).applymap(font_cols,subset=df.columns[0:2]).format({('2020 respondents:','Count'): \"{:.0f}\"}).format({('2020 respondents:','Percentage'): \"{:.0%}\"})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Among the list of IDEs provided in the 2020 survey -\n* Jupyter is the community favorite.\n* Visual studio and Pycharm are next in line.\n* ~1-in-5 users, use a single IDE exclusivel, and very few use more than 3 IDE. This clearly shows how powerful and self-sufficient each of these IDEs are.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"df=survey_2020MCQ[survey_2020MCQ.Q9_Part_11!='None'].filter(regex='Q9').drop(columns=['Q9_Part_11'])\ndf=df.replace('NA',np.nan)\ndf['VS']=2-df[['Q9_Part_3','Q9_Part_4']].isna().sum(axis=1)\ndf.loc[df.VS==0,'VS']=np.nan; df=df.drop(columns=['Q9_Part_3','Q9_Part_4'])\ndf['Count']=df.shape[1]-df.isna().sum(axis=1)\ndf.rename({'VS':'Q9_Part_3'}, axis=1, inplace=True)\ntot=df.shape[0]\nall=pd.DataFrame()\n\nfor i in range(df.shape[1]-1):\n    df1=df[~df.iloc[:,i].isna()]\n    all[df.columns.tolist()[i]]=df1['Count'].value_counts(ascending=False)\n\nprogs=pd.DataFrame(survey_2020Q[survey_2020Q.index.str.contains('Q9')]['questions'].str.split('-',expand=True)[2])\nprogs.columns=['progs']\nall=pd.merge(progs,all.T, left_index=True,right_index=True)\nall.set_index('progs', inplace=True)\nall.index.name=None\nall['Total']=all.sum(axis=1)\nfor i in range(all.shape[1]-1):\n    all[i+1]=all[i+1]/all['Total']\nall['Percent']=all['Total']/tot\nall.sort_values(by=['Total'], ascending=False, inplace=True)\nTotal=all['Total']\npct=all['Percent']\ndf=all.drop(columns=['Total','Percent'])\n\ntuples = list(product(['Number of IDEs used regularly:'], range(1,df.shape[1]+1)))\ndf.columns = pd.MultiIndex.from_tuples(tuples)\ndf.insert(0, ('2020 respondents:','Count'), Total)\ndf.insert(1, ('2020 respondents:','Percentage'), pct)\n\ndisplay(HTML('<h3>The most regularly used IDEs in 2020:</h3><br><i>excluding respondents who did not disclose their IDE choices</i>'))\n\ndf.style.background_gradient(\n    cmap='Oranges', axis=0).format('{:.1%}').bar(subset=[('2020 respondents:','Percentage')], color='gainsboro').set_properties(**{\n    'font-size': '10pt', 'width': '50px'}).set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', 'black'),\n        ('font-size', '20px'),\n        ('font-weight', 'bold')\n    ]\n}]).applymap(highlight_cols, subset=df.columns[0:2]).applymap(font_cols, subset=df.columns[0:2]).format({('2020 respondents:','Count'): \"{:.0f}\"}).format({('2020 respondents:','Percentage'): \"{:.0%}\"})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br><i>[Go back to the top](#qa)</i>"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"q3d\"></a>\n### 3.4. Hosted notebook products\n\n* More than 30% users do not use any hosted notebook products.\n* Most of those who use any hosted notebook products use 1 or 2 such products.\n* Colab and Kaggle are the top two used hosted notebook products, each being used by more than 40% of the userbase.\n"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df=survey_2020MCQ[['Q10_Part_13','Q5']]\ndf=df.replace('NA',np.nan)\ndf1=pd.crosstab(df['Q5'],df['Q10_Part_13'])\ndf1.columns=[0]\n\ndf=survey_2020MCQ[survey_2020MCQ['Q10_Part_13']!='None'].filter(regex='Q10').drop(columns=['Q10_Part_13'])\ndf['count']=(df.shape[1]-df.isna().sum(axis=1)).astype(int)\ndf=pd.concat([df[['count']],survey_2020MCQ[['Q5']]], axis=1)\ndf=pd.crosstab(df['Q5'],df['count'])\ndf.drop(columns=[0], inplace=True)\ndf=pd.concat([df1,df], axis=1)\n\ndf.index.name=None\ndf.columns.name=None\ndf['Total']=df.sum(axis=1)\ndf.loc['Total']=df.sum(axis=0)\nfor i in range(df.shape[1]-1):\n    df.iloc[:,i]=df.iloc[:,i]/df['Total']\n\ndisplay(HTML('<h3>The regularly used hosted notebook productss:</h3><br><i>excluding respondents who did not disclose their hosted notebook preferences</i>'))\n\n    \ndf=df.sort_values(by=['Total'], ascending=False)\ndf=df.drop(['Total'], axis=0).append(df.loc['Total'])\ndf['pct']=df['Total']/df.loc['Total','Total']\nTotal=df['Total'].to_list()\npct=df['pct'].to_list()\ndf=df.drop(columns=['Total','pct'])\ntuples = list(product(['Number of hosted notebook product(s) used regularly:'], df.columns.tolist()))\ndf.columns = pd.MultiIndex.from_tuples(tuples)\ndf.insert(0, ('2020 respondents:','Count'), Total)\ndf.insert(1, ('2020 respondents:','Percentage'), pct)\n\ndf.style.background_gradient(\n    cmap='Oranges', axis=0).background_gradient(\n    cmap='Greys', axis=1, subset=(df.index[-1],df.columns[2:])).format('{:.1%}').set_properties(**{\n    'font-size': '10pt', 'width': '40px'}).set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', 'black'),\n        ('font-size', '20px'),\n        ('font-weight', 'bold')\n    ]\n}]).applymap(highlight).applymap(font).applymap(highlight_cols, subset=df.columns[0:2]).applymap(font_cols,subset=df.columns[0:2]).format({('2020 respondents:','Count'): \"{:.0f}\"}).format({('2020 respondents:','Percentage'): \"{:.0%}\"})","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df=survey_2020MCQ[survey_2020MCQ['Q10_Part_13']!='None'].filter(regex='Q10').drop(columns=['Q10_Part_13'])\ndf=df.replace('NA',np.nan)\ndf['Count']=df.shape[1]-df.isna().sum(axis=1)\ntot=df.shape[0]\nall=pd.DataFrame()\n\nfor i in range(df.shape[1]-1):\n    df1=df[~df.iloc[:,i].isna()]\n    all[df.columns.tolist()[i]]=df1['Count'].value_counts(ascending=False)\n\nprogs=pd.DataFrame(survey_2020Q[survey_2020Q.index.str.contains('Q10')]['questions'].str.split('-',expand=True)[2])\nprogs.columns=['progs']\nall=pd.merge(progs,all.T, left_index=True,right_index=True)\nall.set_index('progs', inplace=True)\nall.index.name=None\nall['Total']=all.sum(axis=1)\nfor i in range(all.shape[1]-1):\n    all.iloc[:,i]=all.iloc[:,i]/all['Total']\nall['Percent']=all['Total']/tot\nall.sort_values(by=['Total'], ascending=False, inplace=True)\nTotal=all['Total']\npct=all['Percent']\ndf=all.drop(columns=['Total','Percent'])\nls=df.columns.tolist()\nls.sort()\ndf=df[ls].replace(np.nan,0)\ntuples = list(product(['Number of IDEs used regularly:'], ls))\ndf.columns = pd.MultiIndex.from_tuples(tuples)\ndf.insert(0, ('2020 respondents:','Count'), Total)\ndf.insert(1, ('2020 respondents:','Percentage'), pct)\n\ndisplay(HTML('<h3>Hosted notebook products used regularly in 2020:</h3><br><i>excluding respondents who did not disclose their notebook preference:</i>'))\n\ndf.style.background_gradient(\n    cmap='Oranges', axis=0).format('{:.1%}').bar(subset=[('2020 respondents:','Percentage')], color='gainsboro').set_properties(**{\n    'font-size': '10pt', 'width': '50px'}).set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', 'black'),\n        ('font-size', '20px'),\n        ('font-weight', 'bold')\n    ]\n}]).applymap(highlight_cols, subset=df.columns[0:2]).applymap(font_cols, subset=df.columns[0:2]).format({('2020 respondents:','Count'): \"{:.0f}\"}).format({('2020 respondents:','Percentage'): \"{:.0%}\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=survey_2020MCQ[survey_2020MCQ['Q10_Part_13']!='None'].filter(regex='Q10').drop(columns=['Q10_Part_13']); c=df.shape[1]\nfor i in range(c):\n    df.iloc[:,i]=df.iloc[:,i].str.replace('Notebooks','')\ndf['Count']=df.shape[1]-df.isna().sum(axis=1)\ndf['combined'] = df[df.columns[:c]].apply(lambda x: ','.join(x.dropna().astype(str)),axis=1)\ndf=df[df.combined!='']\ndf=pd.DataFrame(df['combined'].value_counts(normalize=True, ascending=False))\ndf['cumsum']=df['combined'].cumsum()\ndf.sort_values(by=['combined'], inplace=True)\n#df['combined']=df['combined'].map('{:,.1%}'.format)\ndf1=df.tail(n=25)\n\ncolorlist=['dimgrey']*7\ncolorlist.extend(['orangered'])\nfig, ax = plt.subplots(1, 1, figsize=(15,10))\nfig.suptitle('Most used hosted notebook products (among those who used these) ', fontsize=24, y=1.025)\n    \ndf1['combined'].plot.barh(ax=ax, width=0.5, color='grey')\nax.spines[\"top\"].set_visible(False)\nax.spines[\"right\"].set_visible(False)\nax.spines[\"bottom\"].set_visible(False)\n    \n    \nx_axis = ax.axes.get_xaxis()\nx_axis.set_visible(False)\n    \nfor p in  ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    if width>0.02:\n        label = \"{:.0%}\".format(width)\n    else:\n        label = \"{:.1%}\".format(width)#f'{width:.0%}'\n    ax.annotate(label,(width+0.008, y+.075), fontsize=16, ha='center',weight='normal')\n\nplt.yticks(fontsize=18,rotation=0)            \nplt.tight_layout(pad=1)\nplt.show()   ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br><i>[Go back to the top](#qa)</i>"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"q3e\"></a>\n### 3.5. Computing platform and specialized hardwares\nFrom the responses regarding computing platforms and specialized hardwares, it is evident that:\n* A personal computer/ laptop and access to a\n* GPU\nare sufficient for a data-science career for the most part."},{"metadata":{"trusted":true},"cell_type":"code","source":"colorlist=['dimgrey']*4\ncolorlist.extend(['orangered'])\nfig, ax = plt.subplots(1, 1, figsize=(16,5))\nfig.suptitle('Computing platform used most often for data science projects by 2020 survey-respondents ', fontsize=24, y=1.1)\n    \nsurvey_2020MCQ['Q11'].value_counts(normalize=True,ascending=True).plot.barh(ax=ax, width=0.4, color=colorlist)\nax.spines[\"top\"].set_visible(False)\nax.spines[\"right\"].set_visible(False)\nax.spines[\"bottom\"].set_visible(False)\n    \n    \nx_axis = ax.axes.get_xaxis()\nx_axis.set_visible(False)\n    \nfor p in  ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(f'{width:.0%}', \n                        (width+0.04, y+.075), fontsize=18, ha='center',weight='normal')\n\n#footnote='$\\it{Source:\\ meta-kaggle\\ user\\ data}$'\n \n#plt.figtext(0.15, -0.1, footnote, ha=\"center\", fontsize=14, bbox={\"facecolor\":\"white\",\"alpha\":0.5, \"pad\":5})\n\n\nplt.yticks(fontsize=18,rotation=0)            \nplt.tight_layout(pad=1)\nplt.show()   ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df=survey_2020MCQ[['Q12_Part_3','Q5']]\ndf=df.replace('NA',np.nan)\ndf1=pd.crosstab(df['Q5'],df['Q12_Part_3'])\ndf1.columns=[0]\n\ndf=survey_2020MCQ[survey_2020MCQ.Q12_Part_3!='None'].filter(regex='Q12').drop(columns=['Q12_Part_3'])\ndf['count']=df.shape[1]-df.isna().sum(axis=1)\ndf=pd.concat([df[['count']],survey_2020MCQ[['Q5']]], axis=1)\ndf=pd.crosstab(df['Q5'],df['count'])\ndf.drop(columns=[0], inplace=True)\ndf=pd.concat([df1,df], axis=1)\ndf.index.name=None\ndf.columns.name=None\ndf['Total']=df.sum(axis=1)\ndf.loc['Total']=df.sum(axis=0)\nfor i in range(df.shape[1]-1):\n    df.iloc[:,i]=df.iloc[:,i]/df['Total']\n\ndf=df.sort_values(by=['Total'], ascending=False)\ndf=df.drop(['Total'], axis=0).append(df.loc['Total'])\ndf['pct']=df['Total']/df.loc['Total','Total']\nTotal=df['Total'].to_list()\npct=df['pct'].to_list()\ndf=df.drop(columns=['Total','pct'])\ntuples = list(product(['Types of specialized hardware(s) used regularly:'], range(df.shape[1])))\ndf.columns = pd.MultiIndex.from_tuples(tuples)\ndf.insert(0, ('2020 respondents:','Count'), Total)\ndf.insert(1, ('2020 respondents:','Percentage'), pct)\n\ndisplay(HTML('<h3>Types of specialized hardwares used regularly in 2020:</h3><br><i>excluding respondents who did not disclose their hardware preference:</i>'))\n\ndf.style.background_gradient(\n    cmap='Oranges', axis=0).background_gradient(\n    cmap='Greys', axis=1, subset=(df.index[-1],df.columns[2:])).format('{:.1%}').set_properties(**{\n    'font-size': '10pt', 'width': '40px'}).set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', 'black'),\n        ('font-size', '20px'),\n        ('font-weight', 'bold')\n    ]\n}]).applymap(highlight).applymap(font).applymap(highlight_cols, subset=df.columns[0:2]).applymap(font_cols,subset=df.columns[0:2]).format({('2020 respondents:','Count'): \"{:.0f}\"}).format({('2020 respondents:','Percentage'): \"{:.0%}\"})","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df=survey_2020MCQ[survey_2020MCQ.Q12_Part_3!='None'].filter(regex='Q12').drop(columns=['Q12_Part_3'])\ndf['Count']=df.shape[1]-df.isna().sum(axis=1)\ndf['combined'] = df[df.columns[:3]].apply(lambda x: ','.join(x.dropna().astype(str)),axis=1)\ndf.loc[df.combined=='','combined']='None'\n\ncolorlist=['dimgrey']*7\ncolorlist.extend(['orangered'])\nfig, ax = plt.subplots(1, 1, figsize=(16,5))\nfig.suptitle('Specialized hardwares used most regularly in 2020', fontsize=24, y=1.1)\n    \ndf['combined'].value_counts(normalize=True, ascending=True).plot.barh(ax=ax, width=0.4, color=colorlist)\nax.spines[\"top\"].set_visible(False)\nax.spines[\"right\"].set_visible(False)\nax.spines[\"bottom\"].set_visible(False)\n    \n    \nx_axis = ax.axes.get_xaxis()\nx_axis.set_visible(False)\n    \nfor p in  ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    if width>0.01:\n        label = \"{:.0%}\".format(width)\n    else:\n        label = \"{:.1%}\".format(width)#f'{width:.0%}'\n    ax.annotate(label,(width+0.025, y+.075), fontsize=18, ha='center',weight='normal')\n\nplt.yticks(fontsize=18,rotation=0)            \nplt.tight_layout(pad=1)\nplt.show()   ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"df=survey_2020MCQ[survey_2020MCQ.Q12_Part_3!='None'].filter(regex='Q12').drop(columns=['Q12_Part_3'])\ndf=df.replace('NA',np.nan)\ndf['Count']=df.shape[1]-df.isna().sum(axis=1)\ntot=df.shape[0]\nall=pd.DataFrame()\n\nfor i in range(df.shape[1]-1):\n    df1=df[~df.iloc[:,i].isna()]\n    all[df.columns.tolist()[i]]=df1['Count'].value_counts(ascending=False)\n\nprogs=pd.DataFrame(survey_2020Q[survey_2020Q.index.str.contains('Q12')]['questions'].str.split('-',expand=True)[2])\nprogs.columns=['progs']\nall=pd.merge(progs,all.T, left_index=True,right_index=True)\nall.set_index('progs', inplace=True)\nall.index.name=None\nall['Total']=all.sum(axis=1)\nfor i in range(all.shape[1]-1):\n    all.iloc[:,i]=all.iloc[:,i]/all['Total']\nall['Percent']=all['Total']/tot\nall.sort_values(by=['Total'], ascending=False, inplace=True)\nTotal=all['Total']\npct=all['Percent']\ndf=all.drop(columns=['Total','Percent'])\nls=df.columns.tolist()\nls.sort()\ndf=df[ls].replace(np.nan,0)\ntuples = list(product(['Number of IDEs used regularly:'], ls))\ndf.columns = pd.MultiIndex.from_tuples(tuples)\ndf.insert(0, ('2020 respondents:','Count'), Total)\ndf.insert(1, ('2020 respondents:','Percentage'), pct)\n\ndisplay(HTML('<h3>Number of hosted notebook products used regularly in 2020:</h3><br><i>excluding respondents who did not disclose their data/ML respondibilities</i>'))\n\ndf.style.background_gradient(\n    cmap='Oranges', axis=0).format('{:.1%}').bar(subset=[('2020 respondents:','Percentage')], color='gainsboro').set_properties(**{\n    'font-size': '10pt', 'width': '50px'}).set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', 'black'),\n        ('font-size', '20px'),\n        ('font-weight', 'bold')\n    ]\n}]).applymap(highlight_cols, subset=df.columns[0:2]).applymap(font_cols, subset=df.columns[0:2]).format({('2020 respondents:','Count'): \"{:.0f}\"}).format({('2020 respondents:','Percentage'): \"{:.0%}\"})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br><i>[Go back to the top](#qa)</i>"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"q4a\"></a>\n### 4.1. Machine Learning experience, in years\n\n* In India, 88% female/ LGBTQA+ users and 84% male users have ML experience of only 2 years or less.\n* Half of all users in India, male or female/ LGBTQA+, have less than 1 year of ML experience.\n* Compared to users in India, users in U.S.A. are more experienced in ML, especially the U.S.A. males. (Male users from U.S.A. are the most experienced in ML, among all users in India and U.S.A.)\n\n**<u>Takeaway</u>**<br>\nConsistent with the previous analysis, we find that between India ans U.S.A., the male users from U.S.A. are most experienced, followed by the female/ LGBTQA+ users. Indian users are mostly younger with fewer years of coding experience and ML experience as well.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df=survey_2020MCQ[~survey_2020MCQ.Q15.isin(['NA'])][['Q2','Q15']]\ndf.loc[~df['Q2'].str.contains('Male', na=False), 'Q2'] = 'Female/ LGBTQA+'\npd.options.display.float_format = '{:,.0%}'.format  \ndf.loc[df['Q15'].str.contains('not', na=False), 'Q15'] = 'None'\ndf.loc[df['Q15'].str.contains('Under', na=False), 'Q15'] = '<1 year'\ndf.loc[df['Q15'].str.contains('more', na=False), 'Q15'] = '>=20 years'\ndf['Q15'] = df['Q15'].str.replace(' years','')\ndf=df.groupby(['Q2'])['Q15'].value_counts(normalize=True,ascending=True).unstack(level=[0])\ndf.index.name=None\n\nall=survey_2020MCQ[~survey_2020MCQ.Q15.isin(['NA'])][['Q15']]\nall.loc[all['Q15'].str.contains('not', na=False), 'Q15'] = 'None'\nall.loc[all['Q15'].str.contains('Under', na=False), 'Q15'] = '<1 year'\nall.loc[all['Q15'].str.contains('more', na=False), 'Q15'] = '>=20 years'\nall['Q15'] = all['Q15'].str.replace(' years','')\nall=pd.DataFrame(all['Q15'].value_counts(normalize=True,ascending=True))\nall.index.name=None\nall.columns=['Overall']\nall=all.merge(df, left_index=True, right_index=True)\nall.sort_index(inplace=True)\nall=all.loc[['None']].append(all.loc[['<1 year']]).append(all[~all.index.isin(['None','<1 year','10-20','>=20'])]).append(all[all.index.isin(['10-20','>=20'])])\nall.rename(index={'>=20':'20+ years'},inplace=True)\n\nfmt = lambda x,pos: '{:.0%}'.format(x)\nsns.set(font_scale=1.4)\n    \nfig, ax = plt.subplots(1, 3, figsize=(10,6))  \nfig.suptitle('#Kagglers by ML experience, 2020', fontsize=20, y=1.05)\nsns.set(font_scale=1.2)\nfor i in range(3):\n    ax[i].xaxis.tick_top()\n    ax[i].xaxis.set_label_position('top')\n    ax[i].tick_params(length=0)\n    if i==0:\n                g=sns.heatmap(pd.DataFrame(all.iloc[:,i]), \n                      annot=True, fmt='.0%', \n                      cbar_kws={'format': FuncFormatter(fmt)},\n                      annot_kws={\"size\": 14},ax=ax[i],\n                      cmap=cmaps[1])\n    else:\n        g=sns.heatmap(pd.DataFrame(all.iloc[:,i]), \n                      annot=True, fmt='.0%', \n                      cbar_kws={'format': FuncFormatter(fmt)},\n                      annot_kws={\"size\": 16},ax=ax[i],yticklabels='',\n                      cmap=cmaps[0])\n\n\nfootnote='*Percentages are calculated after excluding the users who marked their coding experience as NA(~18%)'\nplt.figtext(0.5, 0.0, footnote, ha=\"center\", fontsize=14, bbox={\"facecolor\":\"white\",\"alpha\":0.5, \"pad\":5})\nplt.tight_layout(pad=2.0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br><i>[Go back to the top](#qa)</i>"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"q4b\"></a>\n### 4.2. Machine Learning Frameworks and algorithms\n"},{"metadata":{},"cell_type":"markdown","source":"<br><i>[Go back to the top](#qa)</i>"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"q4c\"></a>\n### 4.3. Machine Learning/ cloud related spending, in past 5 years\n* More than a third of the users (who are currently employed) never spent any money on the cloud. \n* Another third spent less than a thousand dollars (USD) on cloud/ ML related services and products in last 5 years.\n* Given that many of the data scientists are employed by large corporations, it is natural that it is only a number of these data scientists, who (in individual capacity or on company budget) could invest in expensive cloud and ML services.\n\n---\n\n<i>Given that these expenses included money spent by the employer company, it is quite evident that at the moment, a professional career in data science does not command heavy investments on clous/ ML products.</i>\n"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"survey_2020MCQ.loc[survey_2020MCQ.Q25.isin(['NA', '$0 ($USD)']),'cloud_exp']='None'\nsurvey_2020MCQ.loc[~survey_2020MCQ.Q25.isin(['NA', '$0 ($USD)']),'cloud_exp']=survey_2020MCQ.Q25\nsurvey_2020MCQ['cloud_exp'] = survey_2020MCQ['cloud_exp'].str.replace('$','\\$')\n\ndf=pd.crosstab(survey_2020MCQ['Q5'],survey_2020MCQ['cloud_exp'])\ndf.index.name=None\ndf.columns.name=None\ndf['Total']=df.sum(axis=1)\ndf.loc['Total']=df.sum(axis=0)\nfor i in range(df.shape[1]-1):\n    df.iloc[:,i]=df.iloc[:,i]/df['Total']\ndf.rename(columns={'\\$100,000 or more (\\$USD)' : '>\\$100,000'}, inplace=True)\ndf=df[['None','\\$1-\\$99','\\$100-\\$999','\\$1000-\\$9,999','\\$10,000-\\$99,999','>\\$100,000', 'Total']]\ndf['grp']=0\ndf.loc[df['None']==1,'grp']=1\ndf.loc['Total','grp']=-1\ncollist=df.columns.tolist()\ncollist.remove('Total')\ncollist.insert(0,'Total')\ncollist.reverse()\ndf=df.sort_values(by=collist, ascending=False)\ndf.drop(columns=['grp'], inplace=True)\ndf['pct']=df['Total']/df.loc['Total','Total']\nTotal=df['Total'].to_list()\npct=df['pct'].to_list()\ndf=df.drop(columns=['Total','pct'])\ntuples = list(product(['ML/cloud related spending (own or team money) in past 5 years (approx. USD):']\n                      , df.columns))\ndf.columns = pd.MultiIndex.from_tuples(tuples)\ndf.insert(0, ('2020 respondents:','Count'), Total)\ndf.insert(1, ('2020 respondents:','Percentage'), pct)\n\ndisplay(HTML('<h3>ML/Cloud USD spending by respondents from different professions in past 5 years:</h3>'))\n\ndf.style.background_gradient(\n    cmap='Oranges', axis=0, subset=(df.index[:-1],df.columns[2:])).background_gradient(\n    cmap='Greys', axis=1, subset=(df.index[-1],df.columns[2:])).format('{:.0%}').set_properties(**{\n    'font-size': '10pt'}).set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', 'black'),\n        ('font-size', '20px'),\n        ('font-weight', 'bold')\n    ]\n}]).applymap(highlight_cols, subset=df.columns[0:2]).applymap(font_cols, subset=df.columns[0:2]).format({('2020 respondents:','Count'): \"{:.0f}\"})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br><i>[Go back to the top](#qa)</i>"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"q4d\"></a>\n### 4.4. Machine Learning/ cloud/ Big data products and services\n"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def highlight(val):\n    style = 'background-color: bisque' if val == 0 else ''\n    return style\n\ndef font(val):\n    white = 'color: whitesmoke' if val == 0 else ''\n    return white\n\ndef highlight_cols(s):\n    color = '#FFFFFF'\n    return 'background-color: %s' % color\ndef font_cols(s):\n    color = 'grey'\n    return 'color: %s' % color\n\ndf=survey_2020MCQ.filter(regex='Q26')\ndf=df.replace('NA',np.nan)\ndf['count']=df.shape[1]-df.isna().sum(axis=1)\ndf=pd.concat([df[['count']],survey_2020MCQ[['Q5']]], axis=1)\ndf=df[df['Q5']!='NA']\ndf=pd.crosstab(df['Q5'],df['count'])\ndf.index.name=None\ndf.columns.name=None\ndf['Total']=df.sum(axis=1)\ndf.loc['Total']=df.sum(axis=0)\nfor i in range(df.shape[1]-1):\n    df.iloc[:,i]=df.iloc[:,i]/df['Total']\ndf['grp']=0\ndf.loc[df[0]==1,'grp']=1\ndf.loc['Total','grp']=-1\ndf=df.sort_values(by=['grp',6,5,4,3,2,1,'Total'], ascending=False)\ndf.drop(columns=['grp'], inplace=True)\ndf['pct']=df['Total']/df.loc['Total','Total']\nTotal=df['Total'].to_list()\npct=df['pct'].to_list()\ndf=df.drop(columns=['Total','pct'])\ntuples = list(product(['#Cloud computing platforms used/ planning to use:'], range(df.shape[1])))\ndf.columns = pd.MultiIndex.from_tuples(tuples)\ndf.insert(0, ('2020 respondents:','Count'), Total)\ndf.insert(1, ('2020 respondents:','Percentage'), pct)\n\ndf.style.background_gradient(\n    cmap='Oranges').format('{:.0%}').set_properties(**{\n    'font-size': '10pt', 'width': '50px'}).set_table_styles([{\n    'selector': 'caption',\n    'props': [\n        ('color', 'black'),\n        ('font-size', '20px'),\n        ('font-weight', 'bold')\n    ]\n}]).applymap(highlight).applymap(font).applymap(highlight_cols, subset=df.columns[0:2]).applymap(font_cols,subset=df.columns[0:2]).format({('2020 respondents:','Count'): \"{:.0f}\"})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<br><i>[Go back to the top](#qa)</i>"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"q4e\"></a>\n### 4.5. Auto ML and Partial Auto ML"},{"metadata":{},"cell_type":"markdown","source":"<br><i>[Go back to the top](#qa)</i>"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"q5a\"></a>\n### 5.1. Data science courses"},{"metadata":{},"cell_type":"markdown","source":"<br><i>[Go back to the top](#qa)</i>"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"q5b\"></a>\n### 5.2. Analysis and application sharing"},{"metadata":{},"cell_type":"markdown","source":"<br><i>[Go back to the top](#qa)</i>"},{"metadata":{},"cell_type":"markdown","source":"<a id = \"q5c\"></a>\n### 5.3. Favorite media sources"},{"metadata":{},"cell_type":"markdown","source":"<br><i>[Go back to the top](#qa)</i>\n\n\n\n---\n\n# <span style=\"color:lime\"> If you liked this notebook  <b><u>PLEASE UPVOTE </u></b> ! </span> üòäüôè\n\n---"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}