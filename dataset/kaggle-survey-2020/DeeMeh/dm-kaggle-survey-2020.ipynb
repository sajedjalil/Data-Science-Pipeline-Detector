{"cells":[{"metadata":{},"cell_type":"markdown","source":"# The challenge objective:\n\n### To tell a data story about a subset of the data science community represented in this survey, through a combination of both narrative text and data exploration."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n\n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!/opt/conda/bin/python3.7 -m pip install --upgrade pip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Supress Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Import the NumPy and Pandas libraries\nimport numpy as np\nimport pandas as pd\n\n# Display all the columns in dataset \nfrom IPython.display import display \npd.options.display.max_columns = None\n\n# Import libraries to visualize the dataset\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n# Import interactive Shell\nfrom IPython.core.interactiveshell import InteractiveShell \nInteractiveShell.ast_node_interactivity = \"all\"\n\n# Import Profiling package of Pandas\nimport pandas_profiling\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"-   **Blue Alert Box: Inference**\n\n<div class=\"alert alert-block alert-info\">\n<b>Tip:</b> Use blue boxes for inferences, insights and notes. \n</div>"},{"metadata":{},"cell_type":"markdown","source":"-   **Yellow Alert Box: Add**\n\n<div class=\"alert alert-block alert-warning\">  \n<b>Example:</b> Yellow Boxes are generally used to include additional examples or mathematical formulas.  \n</div>"},{"metadata":{},"cell_type":"markdown","source":"-   **Green Alert Box: Info**\n\n<div class=\"alert alert-block alert-success\">  \nLink: Use green box only when necessary such as to display web links to related content.  \n</div>"},{"metadata":{},"cell_type":"markdown","source":"-   **Red Alert Box: Warning**\n\n<div class=\"alert alert-block alert-danger\">  \nAlert: It is good to avoid red boxes but can be used to alert users to not delete some important part of code etc.   \n</div>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Read and display file\n\ndf = pd.read_csv('../input/kaggle-survey-2020/kaggle_survey_2020_responses.csv') # load data\n\ndf.head() # check top ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove top unmarked row and inserting original header on top\n\nheader = df.iloc[0] # initiate 'header' for dataset\n\ndf = df[1:] # slice original dataset to remove unmarked row and original header\n\ndf.columns = header # re-insert columns as 'header'\n\ndf.head() # check top five rows of dataframe\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail() # check bottom five rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count countries with percentage data science enthusiasts\n\ndf['In which country do you currently reside?'].value_counts(normalize=True)*100 # percentage value count","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Our analysis will be based on the Kaggle survey information in the subset for India and USA.\n\n<div class=\"alert alert-block alert-info\">\n<b>Tip:</b> It is evident from the overall analysis that India and USA are the countries with most Data Science Enthusiasts (more than 40%).\n</div>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create and display new dataset for survey data from kaggle users in India\n\ndf_Ind = df[df['In which country do you currently reside?']=='India'] # filter a subset for India\ndf_Ind.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create and display new dataset for survey data from kaggle users in USA\n\ndf_USA = df[df['In which country do you currently reside?']=='United States of America'] # filter a subset for USA\ndf_USA.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_Ind.shape # row and column number in India subset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_USA.shape # row and column in USA subset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find null values in each column\n\ndf_Ind.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find null values in each column\n\ndf_USA.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop column with null values more than 3000 or 60% of total values in a column\n\nfor i in df_Ind.columns:\n    if df_Ind[i].isna().sum()>3000:\n        df_Ind.drop(i,1,inplace=True)\n\ndf_Ind.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop column with null values more than 1200 or 60% of total values in a column\n\nfor i in df_USA.columns:\n    if df_USA[i].isna().sum()>1200:\n        df_USA.drop(i,1,inplace=True)\n\ndf_USA.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check shape of dataframe\n\nprint('No. of rows:', df_Ind.shape[0]) # print no. of rows\nprint('No. of columns:', df_Ind.shape[1]) # print no. of columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check shape of dataframe\n\nprint('No. of rows:', df_USA.shape[0]) # print no. of rows\nprint('No. of columns:', df_USA.shape[1]) # print no. of columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check statistical information for each column\n\ndf_Ind.describe(include='all') # describe India subset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The description of subset for India is as follows:\n\n<div class=\"alert alert-block alert-info\">\n<b>Inferences:</b>\n    1. Most of the survey respondents from India are male student in age group of 18-21 with Bachelor's degree.\n    2. Python is most used, recommended language and matplotlib most used visualization library for data science on a PC. \n    3. Jupyter notebook IDE users in India have most frequent experience of coding in python within 1-2 year bracket.\n    4. Seaborn is second most used visualization library in python for exploratory data analysis.\n    5. Machine Learning is a growing field in data science with most frequent users of ML algorithm are under 1 year.\n    6. SKLearn is the most used frame work, Linear or Logistic regression the frequently used algorithm in ML.\n    7. Local development environment such as R Studio and Jupyter is the primary tool at work and school to analyze data.\n   \n</div>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check statistical information for each column\n\ndf_USA.describe(include='all') # describe USA subset","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The description of subset for USA is as follows:\n\n<div class=\"alert alert-block alert-info\">\n<b>Inferences:</b>\n    1. Most of the survey respondents from USA are male Data Scientists in age group of 30-34 with Master's degree.\n    2. Python, SQL is most used, recommended language and matplotlib most used visualization library on a PC for DS. \n    3. Jupyter notebook IDE users in USA have most frequent experience of coding in python within 3-5 year bracket.\n    4. Companies with 10k and more employees has most no. of surveyors on kaggle who work in a group of 20+ members.\n    5. Machine Learning is a growing field in data science with most frequent users of ML algorithm are under 1 year.\n    6. SKLearn is the most used frame work used in ML at United States of America.\n    7. Local development environment such as R Studio and Jupyter is the primary tool at work and school to analyze data.\n    8. Linear or Logistic regression, Decision Tree or Random forest are frequently used ML algorithm.\n    9. Compensation for survey respondents in USA is highest for a range of 100k to 125k USD.\n    10.There is a lot of scope to invest in Data Science courses in USA as most of the respondents has not spent anything on DS in last 5 years.\n   \n</div>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Rename column names\n\ndf_Ind.rename(columns={'What is your age (# years)?':'Age','What is your gender? - Selected Choice':'Gender', \n                       'In which country do you currently reside?':'Country', \n                       'What is the highest level of formal education that you have attained or plan to attain within the next 2 years?':'Highest Education',\n                       'Select the title most similar to your current role (or most recent title if retired): - Selected Choice': 'Job Title',\n                       'For how many years have you been writing code and/or programming?': 'Coding Experience',\n                       \"What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - Python\" : 'Language Used',\n                       'What programming language would you recommend an aspiring data scientist to learn first? - Selected Choice':'Language Recommended',\n                       \"Which of the following integrated development environments (IDE's) do you use on a regular basis? (Select all that apply) - Selected Choice - Jupyter (JupyterLab, Jupyter Notebooks, etc)\" : \"IDE Used\",\n                       \"What type of computing platform do you use most often for your data science projects? - Selected Choice\":\"Platform Used\",\n                       \"Approximately how many times have you used a TPU (tensor processing unit)?\":\"TPU Used\",\n                       \"What data visualization libraries or tools do you use on a regular basis? (Select all that apply) - Selected Choice - Matplotlib\" : \"Matplotlib\",\n                       \"What data visualization libraries or tools do you use on a regular basis? (Select all that apply) - Selected Choice - Seaborn\" : \"Seaborn\",\n                       \"For how many years have you used machine learning methods?\":\"ML Usage\",\n                       \"Which of the following machine learning frameworks do you use on a regular basis? (Select all that apply) - Selected Choice - Scikit-learn\" : \"sklearn\",\n                       \"Which of the following ML algorithms do you use on a regular basis? (Select all that apply): - Selected Choice - Linear or Logistic Regression\":\"Regression\",\n                       \"What is the primary tool that you use at work or school to analyze data? (Include text response) - Selected Choice\":\"Primary Tool\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import profiling in pandas\nimport pandas_profiling\n\ndf_Ind.profile_report() # profile report for subset of India ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The Profile Report of subset for India:\n\n<div class=\"alert alert-block alert-info\">\n<b>Tip:</b> The profile report is self explainatory for each variable in the subset.   \n</div>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_USA.profile_report()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### The Profile Report of subset for USA:\n\n<div class=\"alert alert-block alert-info\">\n<b>Tip:</b> The profile report is self explainatory for each variable in the subset.   \n</div>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check name of columns in subset for India\n\ndf_Ind.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check name of columns in subset for USA\n\ndf_USA.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combine both the subsets to form a new data set for comaprison\n\ndf1 = pd.concat([df_Ind, df_USA], ignore_index=True) # concatenate India, USA subset in a new Data Frame\ndf1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check no. of columns and rows in new data frame\n\ndf1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop rows with high NaN values \n\nfor i in df1.columns: # for loop in new concatenated data frame\n    if df1[i].isna().sum()>2000: # apply condition\n        df1.drop(i,1,inplace=True) # drop columns as per condition\n\ndf1.head() # display top rows of newly formed data frame","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check no. of rows and columns after dropping columns with high NaNs\n\ndf1.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n<div class=\"alert alert-block alert-info\">\n<b>Tip:</b> Number of columns has reduced from 26 to 12. Out of it only 11 are useful for further analysis.   \n</div>\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check basic information such as data type, non-null count, rows and columns\n\ndf1.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n<div class=\"alert alert-block alert-info\">\n<b>Tip:</b> As all the columns are 'object' data type only bar graph or count plot can be build to compare and analyze the data.   \n</div>\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count plot to compare age of respondents in India and USA\n\nplt.figure(figsize=(18,10)) # define figure size\n\nsns.set(style=\"whitegrid\", color_codes=True) # set style\n\n# define count plot in seaborn\nplot = sns.catplot(y='What is your age (# years)?', # define y-axis\n                 hue='In which country do you currently reside?', # define hue\n                 kind='count', # define kind of categorical plot\n                 palette=\"pastel\", # define color\n                 edgecolor=\".6\", # define color of edge \n                 data=df1.sort_values(by='What is your age (# years)?')) # sort data frame for age groups\n\nplt.ylabel('Age', \n           fontdict=\n           {'fontsize': 15, \n            'color' : 'Blue'}) # rename y-axis\n\nplot._legend.set_title('Country') # rename legend\n\nplt.title('Age Distribution in Data Science Community', \n          fontdict={'fontsize': 20, 'color' : 'Blue'}) # title name\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n<div class=\"alert alert-block alert-info\">\n<b>Tip:</b> India has highest survey respondents in age group of 18-21. However, USA has highest number in age group of 30-34 which is closely followed by 25 -29. It clearly indicates that average age of data science enthusiasts in USA is more than that in India.   \n</div>\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count plot to comapre gender\n\nsns.set(style=\"whitegrid\", color_codes=True) # set style in seaborn\n\n# Plot categorical graph for gender column \nplot = sns.catplot(y='What is your gender? - Selected Choice', \n                   hue='In which country do you currently reside?',\n                   kind='count', \n                   palette=\"pastel\", \n                   edgecolor=\".6\", \n                   data=df1.sort_values(by='What is your gender? - Selected Choice'))\n\n# define y-axis\nplt.ylabel('Gender', \n           fontdict=\n           {'fontsize': 15, \n            'color' : 'Blue'})\n\n# rename legend\nplot._legend.set_title('Country')\n\n# rename title\nplt.title('Gender Distribution in Data Science', \n          fontdict={'fontsize': 20, 'color' : 'Blue'})\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n<div class=\"alert alert-block alert-info\">\n<b>Tip:</b> The field of data science is male dominant in India as well as USA. There are few respondents with non-binary and self-descriptive gender which is an encouraging sign for the future of any area.    \n</div>\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Categorical plot of column for highest formal education\n\nsns.set(style=\"whitegrid\", color_codes=True) # set style\n\n# define count plot \nplot = sns.catplot(y='What is the highest level of formal education that you have attained or plan to attain within the next 2 years?', \n                   hue='In which country do you currently reside?',\n                   kind='count',\n                   palette=\"pastel\", \n                   edgecolor=\".6\", \n                   data=df1.sort_values(by='What is the highest level of formal education that you have attained or plan to attain within the next 2 years?'))\n# define y-axis\nplt.ylabel('Education', \n           fontdict=\n           {'fontsize': 15, \n            'color' : 'Blue'})\n\n# rename legend\nplot._legend.set_title('Country')\n\n# define title\nplt.title('Distribution of Education in Data Science', \n          fontdict={'fontsize': 20, 'color' : 'Blue'})\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n<div class=\"alert alert-block alert-info\">\n<b>Tip:</b> India has highest proportion of Bachelor's degree holders in survey. However, USA had highest proportion Master's degree. The graph clearly indicates that data science enthusiasts in USA has high proportion of masters and doctorate degree. Whereas, India has higher proportion of bachelor and master degree in the field of data science.\n</div>\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count plot for Current role in DS\n\nplt.figure(figsize=(18,10)) # define figure size\n\nsns.set(style=\"whitegrid\", color_codes=True) # set style of graph on seaborn\n\n# define count plot\nax = sns.countplot(y='Select the title most similar to your current role (or most recent title if retired): - Selected Choice', \n                   hue='In which country do you currently reside?',\n                   palette=\"pastel\", \n                   edgecolor=\".6\",\n                   data=df1.sort_values(by='Select the title most similar to your current role (or most recent title if retired): - Selected Choice'))\n\n# redefine y-axis\nplt.ylabel('Job Title', \n           fontdict=\n           {'fontsize': 15, \n            'color' : 'Blue'})\n\n# redefine legend\nlegend_labels, _= ax.get_legend_handles_labels()\nax.legend(legend_labels, ['India','USA'], bbox_to_anchor=(1,1))\n\n# define title of the graph\nplt.title('Distribution of Role in Data Science', \n          fontdict={'fontsize': 20, 'color' : 'Blue'})\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n<div class=\"alert alert-block alert-info\">\n<b>Tip:</b> India has highest survey respondents as students. However, USA has highest proportion of Data Scientist among respondents. It clearly indicates that maturity of data science field in USA is more whereas, data science is at a primitive stage in India.   \n</div>\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count plot for experience of programming\n\nplt.figure(figsize=(18,10)) # define figure size\n\nsns.set(style=\"whitegrid\", color_codes=True) # define style of graph in seaborn\n\n# define count plot\nax = sns.countplot(y='For how many years have you been writing code and/or programming?', \n                   hue='In which country do you currently reside?',\n                   palette=\"pastel\", \n                   edgecolor=\".6\",\n                   data=df1.sort_values(by='For how many years have you been writing code and/or programming?'))\n\n# covert numbers in to percentage\ntotal = len(df1['For how many years have you been writing code and/or programming?'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()/2\n        ax.annotate(percentage, (x, y))\n\n# redefine y-axis\nplt.ylabel('Programming Experience', \n           fontdict=\n           {'fontsize': 15, \n            'color' : 'Blue'})\n\n# redefine legend\nlegend_labels, _= ax.get_legend_handles_labels()\nax.legend(legend_labels, ['USA', 'India'], bbox_to_anchor=(1,1))\n\n# define title\nplt.title('Distribution of Coding Experience in Data Science', \n          fontdict={'fontsize': 20, 'color' : 'Blue'})\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n<div class=\"alert alert-block alert-info\">\n<b>Tip:</b> India has most frequent coding experience candidate of 1-2 years. However, USA has proportionally high programming experience of 3-5 years. It again indicated coding community of data science is more mature in USA. However, the number of coding community is high in India.  \n</div>\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count plot for usage of Python\n\nplt.figure(figsize=(12,6)) # define figure size\n\nsns.set(style=\"whitegrid\", color_codes=True) # define style of plot in seaborn\n\n# define count plot \nax = sns.countplot(y='What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - Python', \n                   hue='In which country do you currently reside?',\n                   palette=\"pastel\", \n                   edgecolor=\".6\",\n                   data=df1)\n\n# convert numbers in bars to percentage\ntotal = len(df1['What programming languages do you use on a regular basis? (Select all that apply) - Selected Choice - Python'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()/2\n        ax.annotate(percentage, (x, y))\n\n# redefine y-axis\nplt.ylabel('Python User', \n           fontdict=\n           {'fontsize': 15, \n            'color' : 'Blue'})\n\n# redefine legend\nlegend_labels, _= ax.get_legend_handles_labels()\nax.legend(legend_labels, ['India','USA'], bbox_to_anchor=(1,1))\n\n# define title\nplt.title('Python User Distribution in Data Science', \n          fontdict={'fontsize': 20, 'color' : 'Blue'})\n\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n<div class=\"alert alert-block alert-info\">\n<b>Tip:</b> Number of users of python in India is 58.3% which is much higher than that in USA (21.1%).   \n</div>\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count plot for recommended coding language\n\nplt.figure(figsize=(18,10)) # define figure size\n\nsns.set(style=\"whitegrid\", color_codes=True) # define style in seaborn\n\n# define count plot\nax = sns.countplot(y='What programming language would you recommend an aspiring data scientist to learn first? - Selected Choice', \n                   hue='In which country do you currently reside?',\n                   palette=\"pastel\", \n                   edgecolor=\".6\",\n                   data=df1)\n\n# redefine y-axis\nplt.ylabel('Programming Language', \n           fontdict=\n           {'fontsize': 15, \n            'color' : 'Blue'})\n\n# redefine legend\nlegend_labels, _= ax.get_legend_handles_labels()\nax.legend(legend_labels, ['India','USA'], bbox_to_anchor=(1,1))\n\n# define title\nplt.title('Programming Language Distribution in Data Science',\n          fontdict={'fontsize': 20, 'color' : 'Blue'})\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n<div class=\"alert alert-block alert-info\">\n<b>Tip:</b> The recommended programming languages for data science enthusiasts is same for India and USA. The most popular coding language is python followed by R, SQL, C, C++ and java.   \n</div>\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count plot for computing platform\n\nplt.figure(figsize=(18,10)) # define figure size\n\nsns.set(style=\"whitegrid\", color_codes=True) # define style on seaborn\n\n# define count plot\nax = sns.countplot(y='What type of computing platform do you use most often for your data science projects? - Selected Choice', \n                   hue='In which country do you currently reside?',\n                   palette=\"pastel\", \n                   edgecolor=\".6\",\n                   data=df1.sort_values(by='What type of computing platform do you use most often for your data science projects? - Selected Choice'))\n\n# convert no. to percentage\ntotal = len(df1['What type of computing platform do you use most often for your data science projects? - Selected Choice'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()/2\n        ax.annotate(percentage, (x, y))\n\n# redefine y-axis\nplt.ylabel('Computing Platform', \n           fontdict=\n           {'fontsize': 15, \n            'color' : 'Blue'})\n\n# redefine legend\nlegend_labels, _= ax.get_legend_handles_labels()\nax.legend(legend_labels, ['USA','India'], bbox_to_anchor=(1,1))\n\n\n# define title\nplt.title('Distribution of Computing Platform in Data Science', \n          fontdict={'fontsize': 20, 'color' : 'Blue'})\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n<div class=\"alert alert-block alert-info\">\n<b>Tip:</b> India and USA has similar trend in terms of distribution of computing platform for data science project. It is personal computer or laptop followed by cloud computing platforms such as AWS, Azure, GCP. It clearly indicates that PC is most popular among data science community. However, cloud computing platforms has good growth prospect in data science followed by deep learning work stations such as NVIDIA, GTX, LambdaLabs, etc.\n</div>\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count plot for TPU usage\n\nplt.figure(figsize=(18,10)) # define fu=igure size\n\nsns.set(style=\"whitegrid\", color_codes=True) # define style in seaborn\n\n# define count plot \nax = sns.countplot(y='Approximately how many times have you used a TPU (tensor processing unit)?', \n                   hue='In which country do you currently reside?',\n                   palette=\"pastel\", \n                   edgecolor=\".6\",\n                   data=df1.sort_values(by='Approximately how many times have you used a TPU (tensor processing unit)?'))\n\n# convert no. to percentage\ntotal = len(df1['Approximately how many times have you used a TPU (tensor processing unit)?'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()/2\n        ax.annotate(percentage, (x, y))\n\n# redefine y-axis\nplt.ylabel('Tensor Processing Unit Usage', \n           fontdict=\n           {'fontsize': 15, \n            'color' : 'Blue'})\n\n# redefine y-axis\nlegend_labels, _= ax.get_legend_handles_labels()\nax.legend(legend_labels, ['India','USA'], bbox_to_anchor=(1,1))\n\n# define title \nplt.title('TPU Usage Distribution in Data Science', \n          fontdict={'fontsize': 20, 'color' : 'Blue'})\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n<div class=\"alert alert-block alert-info\">\n<b>Tip:</b> TPU usage folows same trend proportionally for India and USA. It goes as 'Never' for most of respondensts, followed by 2-5 times, 'Once', 6-25 times and lastly more than 25 times. It also indicates vast scope of growth in usage of Tensor Processing Units in the field of data science. \n</div>\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count plot for ML use\n\nplt.figure(figsize=(18,10)) # define figure size\n\nsns.set(style=\"whitegrid\", color_codes=True) # define style in seaborn\n\n# define count plot\nax = sns.countplot(y='For how many years have you used machine learning methods?', \n               hue='In which country do you currently reside?',\n               palette=\"pastel\", \n               edgecolor=\".6\",\n               data=df1.sort_values(by='For how many years have you used machine learning methods?'))\n\n# convert number in to percentage\ntotal = len(df1['For how many years have you used machine learning methods?'])\nfor p in ax.patches:\n        percentage = '{:.1f}%'.format(100 * p.get_width()/total)\n        x = p.get_x() + p.get_width() + 0.02\n        y = p.get_y() + p.get_height()/2\n        ax.annotate(percentage, (x, y))\n\n# redefine y-axis\nplt.ylabel('Machine Learning Experience', \n           fontdict=\n           {'fontsize': 15, \n            'color' : 'Blue'})\n\n# redefine legend\nlegend_labels, _= ax.get_legend_handles_labels()\nax.legend(legend_labels, ['USA','India'], bbox_to_anchor=(1,1))\n\n# define title\nplt.title('Distribution of ML Experience in Data Science', \n          fontdict={'fontsize': 20, 'color' : 'Blue'})\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n<div class=\"alert alert-block alert-info\">\n<b>Tip:</b> Usage of Machine Learning methods follows similar trend propotionally in India as  well as USA. It goes as under 1 year followed by 1-2 years. It clearly indicates that ML method have high scope to grow in futute of data science.   \n</div>\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}