{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Table of contents\n* [Introduction](#section-one)\n     *      [Methodology to analyze past years surevy responses](#subsection-one)\n* [Which country sees the huge impact because of Covid19?](#section-two)\n* [Which segments of kagglers are highly impacted by pandemic?](#section-three)\n     *      [Coding Experience](#subsection-two)\n     *      [Age Group](#subsection-three)\n     *      [Education Background](#subsection-four)\n     *      [ML Experience](#subsection-five)\n* [How Data Scientist profile evolved over time and across countries?](#section-four)\n* [Conclusion](#section-five)\n* [References](#section-six)","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfrom pandas.plotting import parallel_coordinates\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sb\n\nimport warnings\nwarnings.filterwarnings(action = 'ignore')\n\n!pip install pycountry-convert\nimport pycountry_convert as pc\n\n## plotly library\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-08-27T07:56:31.821838Z","iopub.execute_input":"2021-08-27T07:56:31.822174Z","iopub.status.idle":"2021-08-27T07:56:45.554911Z","shell.execute_reply.started":"2021-08-27T07:56:31.822145Z","shell.execute_reply":"2021-08-27T07:56:45.55402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## main class to load and clean past years surveys responses\nclass kaggle_survey:\n    def __init__(self):\n        self.jobs_oths_2018 = [\"Consultant\",\"Research Assistant\",\"Manager\",\"Chief Officer\",\"Developer Advocate\",\n                               \"Marketing Analyst\",\"Salesperson\",\"Principal Investigator\",\"Data Journalist\"]\n        self.top_countries = [\"India\",\"United States of America\",\"Brazil\",\"Japan\",\"Russia\"]\n        self.sea_countires = [\"Indonesia\",\"Malaysia\",\"Thailand\",\"Singapore\",\"Philippines\",\"Viet Nam\"]\n        self.job_grp = {\"Scientist\":[\"Data Scientist\",\"Statistician\",\"Research Scientist\",\"Machine Learning Engineer\"],\n                   \"Engineer\" : [\"DBA/Database Engineer\",\"Software Engineer\",\"Data Engineer\"],\n                   \"Business\": [\"Business Analyst\",\"Product/Project Manager\"]}\n        \n        self.ml_exp_mapping = {\"I do not use machine learning methods\":{\"grp\":\"grp1_[I do not use ML methods]\",\"num\":0 },\"10+ years\" : {\"grp\":\"grp8_[10+]\",\"num\":12.5},\n                                 \"Under 1 year\" : {\"grp\":\"grp2_[<1]\",\"num\":0.5 }, \"1-2 years\" : {\"grp\":\"grp3_[1-2]\",\"num\":1.5 },\n                                 \"2-3 years\" : {\"grp\":\"grp4_[2-3]\",\"num\":2.5 }, \"3-4 years\":{\"grp\":\"grp5_[3-4]\",\"num\":3.5 },\n                                 \"4-5 years\" : {\"grp\":\"grp6_[4-5]\",\"num\": 4.5}, \"5-10 years\" : {\"grp\":\"grp7_[5-10]\",\"num\":7.5 }}\n        \n        self.coding_exp_mapping = {\"I have never written code\":{\"grp\":\"grp1_[0]\",\"num\":0 },\"20+ years\" : {\"grp\":\"grp7_[20+]\",\"num\":22.5},\n                                 \"< 1 years\" : {\"grp\":\"grp2_[<1]\",\"num\":0.5 }, \"1-2 years\" : {\"grp\":\"grp3_[1-2]\",\"num\":1 },\n                                 \"3-5 years\" : {\"grp\":\"grp4_[3-5]\",\"num\":4 }, \"5-10 years\":{\"grp\":\"grp5_[5-10]\",\"num\":7.5 },\n                                 \"10-20 years\" : {\"grp\":\"grp6_[10-20]\",\"num\": 15}}\n        \n        self.employer_size_mapping = {\"0-49 employees\":{\"grp\":\"grp1_[0-49]\",\"num\": 25 },\"10,000 or more employees\" : {\"grp\":\"grp5_[10,000+]\",\"num\":12000},\n                                 \"50-249 employees\" : {\"grp\":\"grp2_[50-249]\",\"num\":150 }, \"250-999 employees\" : {\"grp\":\"grp3_[250-999]\",\"num\": 625},\n                                 \"1000-9,999 employees\" : {\"grp\":\"grp4_[1000-9,999]\",\"num\":5500 }}\n        \n        self.ds_workloads_mapping = {\"0\":{\"grp\":\"grp1_[0]\",\"num\": 0 },\n                             \"1-2\" : {\"grp\":\"grp2_[1-10]\",\"num\":5},'3-4' : {\"grp\":\"grp2_[1-10]\",\"num\":5},\n                             '5-9' : {\"grp\":\"grp2_[1-10]\",\"num\":5},\n                             '10-14' : {\"grp\":\"grp3_[10+]\",\"num\":15},'15-19' : {\"grp\":\"grp3_[10+]\",\"num\":15},\n                             '20+' : {\"grp\":\"grp3_[10+]\",\"num\":15}}\n        \n        self.ml_usage_mapping = {\"I do not know\":{\"grp\":\"grp1_[I do not know]\"},\n                             \"No (we do not use ML methods)\" : {\"grp\":\"grp2_[No (we do not use ML methods)]\"},\n                             'We use ML methods for generating insights (but do not put working models into production)' : {\"grp\":\"grp3_[We use ML methods for generating insights (but do not put working models into production)]\"},\n                             'We are exploring ML methods (and may one day put a model into production)' : {\"grp\":\"grp4_[We are exploring ML methods (and may one day put a model into production)]\"},\n                             'We recently started using ML methods (i.e., models in production for less than 2 years)' : {\"grp\":\"grp5_[We recently started using ML methods (i.e., models in production for less than 2 years)]\"},\n                             '\"We have well established ML methods (i.e., models in production for more than 2 years)' : {\"grp\":\"grp6_[We have well established ML methods (i.e., models in production for more than 2 years)]\"}}\n                                    \n                                \n        \n    def load_past_years_data(self):\n        self.data_2020 = pd.read_csv('/kaggle/input/kaggle-survey-2020/kaggle_survey_2020_responses.csv')\n        self.data_2019 = pd.read_csv('/kaggle/input/kaggle-survey-2019/multiple_choice_responses.csv')\n        self.data_2018 = pd.read_csv('/kaggle/input/kaggle-survey-2018/multipleChoiceResponses.csv')\n        self.data_2017 = pd.read_csv('/kaggle/input/kaggle-survey-2017/multipleChoiceResponses.csv',engine='python')\n    \n    @staticmethod    \n    def country_continent(row):\n        try:\n            country_code = pc.country_name_to_country_alpha2(row, cn_name_format=\"default\")\n            continent_name = pc.country_alpha2_to_continent_code(country_code)\n\n        except KeyError:\n            continent_name = \"Other\"\n            if row not in [\"Other\",\"I do not wish to disclose my location\"]:\n                print (row)\n        \n        return continent_name\n\n    def preprocess_data(self):\n        '''\n        This function performes cleaning of past years responses.\n        '''\n        self.data_2020['Year'] = [2020]*len(self.data_2020)\n        self.data_2019['Year'] = [2019]*len(self.data_2019)\n        self.data_2018['Year'] = [2018]*len(self.data_2018)\n        self.data_2017['Year'] = [2017]*len(self.data_2017)\n\n        self.data_2020['cnt'] = [1]*len(self.data_2020)\n        self.data_2019['cnt'] = [1]*len(self.data_2019)\n        self.data_2018['cnt'] = [1]*len(self.data_2018)\n        self.data_2017['cnt'] = [1]*len(self.data_2017)\n\n        self.data_2020 = self.data_2020.loc[1:].reset_index(drop=True)\n        self.data_2019 = self.data_2019.loc[1:].reset_index(drop=True)\n        self.data_2018 = self.data_2018.loc[1:].reset_index(drop=True)\n\n        self.data_2017 = self.data_2017[self.data_2017.Age>=18]\n        \n    def get_gender(self):\n        self.data_2017['Q2'] =  self.data_2017['GenderSelect']\n        self.data_2020['Q2'] = np.where(self.data_2020['Q2']==\"Man\",\"Male\",self.data_2020['Q2'])\n        self.data_2020['Q2'] = np.where(self.data_2020['Q2']==\"Woman\",\"Female\",self.data_2020['Q2'])\n    \n    def clean_country_col(self):\n        '''\n         This function performes cleaning of country question response over the years.\n        '''\n        self.data_2017['Q3'] = self.data_2017['Country']\n        self.data_2017['Q3'] = np.where(self.data_2017['Q3'] == \"United States\",\"United States of America\",self.data_2017['Q3'])\n        \n        self.data_2020['country'] = self.data_2020[\"Q3\"]\n        self.data_2019['country'] = self.data_2019[\"Q3\"]\n        self.data_2018['country'] = self.data_2018[\"Q3\"]\n        self.data_2017['country'] = self.data_2017[\"Q3\"]\n        \n        \n        self.data_2020['country'] = np.where(self.data_2020['country'] == \"United Kingdom of Great Britain and Northern Ireland\",\"United Kingdom\",self.data_2020['country'] )\n        self. data_2019['country'] = np.where(self.data_2019['country'] == \"United Kingdom of Great Britain and Northern Ireland\",\"United Kingdom\",self.data_2019['country'] )\n        self.data_2018['country'] = np.where(self.data_2018['country'] == \"United Kingdom of Great Britain and Northern Ireland\",\"United Kingdom\",self.data_2018['country'] )\n        \n        self.data_2020['country'] = np.where(self.data_2020['country'] == \"Iran, Islamic Republic of...\",\"Iran\",self.data_2020['country'] )\n        self. data_2019['country'] = np.where(self.data_2019['country'] == \"Iran, Islamic Republic of...\",\"Iran\",self.data_2019['country'] )\n        self.data_2018['country'] = np.where(self.data_2018['country'] == \"Iran, Islamic Republic of...\",\"Iran\",self.data_2018['country'] )\n\n        self.data_2020['country'] = np.where(self.data_2020['country'] == \"Republic of Korea\",\"South Korea\",self.data_2020['country'] )\n        self.data_2019['country'] = np.where(self.data_2019['country'] == \"Republic of Korea\",\"South Korea\",self.data_2019['country'] )\n        self.data_2018['country'] = np.where(self.data_2018['country'] == \"Republic of Korea\",\"South Korea\",self.data_2018['country'] )\n\n        self. data_2019['country'] = np.where(self.data_2019['country'] == \"Hong Kong (S.A.R.)\",\"Hong Kong\",self.data_2019['country'] )\n        self.data_2018['country'] = np.where(self.data_2018['country'] == \"Hong Kong (S.A.R.)\",\"Hong Kong\",self.data_2018['country'] )\n\n        self.data_2017['country'] = np.where(self.data_2017['country'].isin([\"People 's Republic of China\",\"Republic of China\"]),\"China\",self.data_2017['country'] )\n        self.data_2017['country'] = np.where(self.data_2017['country'].isin([\"Vietnam\"]),\"Viet Nam\",self.data_2017['country'] )\n\n        self.data_2017['country'] = self.data_2017['country'].fillna(\"Other\")\n        \n        self.data_2020[\"country_grp\"] = self.data_2020['country'].apply(self.country_continent)\n        self.data_2019[\"country_grp\"] = self.data_2019['country'].apply(self.country_continent)\n        self.data_2018[\"country_grp\"] = self.data_2018['country'].apply(self.country_continent)\n        self.data_2017[\"country_grp\"] = self.data_2017['country'].apply(self.country_continent)\n        \n        \n        self.data_2020[\"top_countries\"] = np.where(self.data_2020['country'].isin(self.top_countries),self.data_2020['country'],\"Others\")\n        self.data_2020[\"top_countries\"] = np.where(self.data_2020['country'].isin(self.sea_countires),\"SEA\",self.data_2020['top_countries'])\n\n        self.data_2019[\"top_countries\"] = np.where(self.data_2019['country'].isin(self.top_countries),self.data_2019['country'],\"Others\")\n        self.data_2019[\"top_countries\"] = np.where(self.data_2019['country'].isin(self.sea_countires),\"SEA\",self.data_2019['top_countries'])\n\n        self.data_2018[\"top_countries\"] = np.where(self.data_2018['country'].isin(self.top_countries),self.data_2018['country'],\"Others\")\n        self.data_2018[\"top_countries\"] = np.where(self.data_2018['country'].isin(self.data_2018),\"SEA\",self.data_2018['top_countries'])\n\n        self.data_2017[\"top_countries\"] = np.where(self.data_2017['country'].isin(self.top_countries),self.data_2017['country'],\"Others\")\n        self.data_2017[\"top_countries\"] = np.where(self.data_2017['country'].isin(self.sea_countires),\"SEA\",self.data_2017['top_countries'])\n\n    \n    def get_age(self):\n        '''\n         This function performes cleaning of age response over the years.\n         '''\n        self.data_2018['Q2'] = np.where(self.data_2018['Q2'].isin([\"70-79\",\"80+\"]),\n                                  \"70+\", self.data_2018['Q2'])\n        \n    def get_job(self):\n        '''\n         This function performes cleaning of job question response over the years.\n         '''\n        self.data_2018['Q6'] = np.where(self.data_2018['Q6'].isin(self.jobs_oths_2018),\"Other\",self.data_2018['Q6'] )\n        self.data_2020['Q5'] = np.where(self.data_2020['Q5'] == \"Currently not employed\",\"Not employed\",self.data_2020['Q5'])\n\n        self.data_2020['job'] = self.data_2020[\"Q5\"]\n        self.data_2020['job'] = np.where(self.data_2020['job'] == \"Machine Learning Engineer\",\"Data Scientist\",self.data_2020['job'] )\n\n        self.data_2019['job'] = self.data_2019[\"Q5\"]\n        self.data_2018['job'] = self.data_2018[\"Q6\"]\n        \n        self.data_2017['job'] = np.where(self.data_2017['EmploymentStatus'].isin(['Not employed, but looking for work','Not employed, and not looking for work']),\n                                         \"Not employed\",self.data_2017['CurrentJobTitleSelect'])\n        self.data_2020['job_grp'] = self.data_2020['job']\n        self.data_2019['job_grp'] = self.data_2019['job']\n        self.data_2018['job_grp'] = self.data_2018['job']\n        self.data_2017['job_grp'] = self.data_2017['job']\n        for key, values in self.job_grp.items():\n            self.data_2020['job_grp'] = np.where(self.data_2020['job'].isin(values),key,self.data_2020['job_grp'])\n            self.data_2019['job_grp'] = np.where(self.data_2019['job'].isin(values),key,self.data_2019['job_grp'])\n            self.data_2018['job_grp'] = np.where(self.data_2018['job'].isin(values),key,self.data_2018['job_grp'])\n            self.data_2017['job_grp'] = np.where(self.data_2017['job'].isin(values),key,self.data_2017['job_grp'])\n\n\n    def create_num(self,df,col,mapping,final_col):\n        '''\n         This function convert bining data into integer.\n        '''\n        df[final_col] = df[col]\n        for key,value in mapping.items():\n            df[final_col] = np.where(df[final_col]==key,value['num'],df[final_col])\n        #display(df[final_col])\n        df[final_col] = df[final_col].astype(float)\n        return df\n    \n    def create_grp(self,df,col,mapping,final_col):\n        '''\n         This function convert bining data into order for presenting purpose.\n        '''\n        df[final_col] = df[col]\n        for key,value in mapping.items():\n            df[final_col] = np.where(df[final_col]==key,value['grp'],df[final_col])\n        return df\n        \n    def get_ml_exp(self):\n        '''\n         This function performes cleaning of ML experience question response over the years.\n        '''\n        \n        self.data_2018['Q25'] = np.where(self.data_2018['Q25'] == \"< 1 year\",\"Under 1 year\",self.data_2018['Q25'])\n        self.data_2018['Q25'] = np.where(self.data_2018.Q25.isin(['10-15 years','20+ years']), \"10+ years\", self.data_2018.Q25)\n        self.data_2018['Q25'] = np.where(self.data_2018.Q25.isin(['I have never studied machine learning but plan to learn in the future','I have never studied machine learning and I do not plan to']),\n                                    \"I do not use machine learning methods\", self.data_2018.Q25)\n        \n        self.data_2019['Q23'] = np.where(self.data_2019.Q23.isin(['10-15 years','20+ years']), \"10+ years\", self.data_2019.Q23)\n        self.data_2019['Q23'] = np.where(self.data_2019['Q23'] == \"< 1 years\",\"Under 1 year\",self.data_2019['Q23'])\n        \n        self.data_2020['Q15'] = np.where(self.data_2020.Q15.isin(['10-20 years','20 or more years']), \"10+ years\", self.data_2020.Q15)\n              \n        self.data_2020 = self.create_num(self.data_2020,\"Q15\",self.ml_exp_mapping,\"ml_exp_num\" )\n        self.data_2020 = self.create_grp(self.data_2020,\"Q15\",self.ml_exp_mapping,\"ml_exp_grp\" )\n        \n        self.data_2019 = self.create_num(self.data_2019,\"Q23\",self.ml_exp_mapping,\"ml_exp_num\" )\n        self.data_2019 = self.create_grp(self.data_2019,\"Q23\",self.ml_exp_mapping,\"ml_exp_grp\" )\n        \n        self.data_2018 = self.create_num(self.data_2018,\"Q25\",self.ml_exp_mapping,\"ml_exp_num\" )\n        self.data_2018 = self.create_grp(self.data_2018,\"Q25\",self.ml_exp_mapping,\"ml_exp_grp\" )\n        \n        \n    def get_coding_exp(self):\n        '''\n         This function performes cleaning of coding experience question response over the years.\n        '''\n        \n        self.data_2020 = self.create_num(self.data_2020,\"Q6\",self.coding_exp_mapping,\"coding_exp_num\" )\n        self.data_2020 = self.create_grp(self.data_2020,\"Q6\",self.coding_exp_mapping,\"coding_exp_grp\" )\n        \n        self.data_2019 = self.create_num(self.data_2019,\"Q15\",self.coding_exp_mapping,\"coding_exp_num\" )\n        self.data_2019 = self.create_grp(self.data_2019,\"Q15\",self.coding_exp_mapping,\"coding_exp_grp\" )\n        \n        self.data_2018['Q24'] = np.where(self.data_2018.Q24.isin([\"20-30 years\",\"30-40 years\",\"40+ years\"]), \"20+ years\" , self.data_2018['Q24'])\n        self.data_2018['Q24'] = np.where(self.data_2018.Q24.isin([\"I have never written code but I want to learn\",\"I have never written code and I do not want to learn\"]),\n                                    \"I have never written code\" ,self.data_2018['Q24'])\n        self.data_2018['Q24'] = np.where(self.data_2018.Q24.isin([\"< 1 year\"]),\"< 1 years\" ,self.data_2018['Q24'])\n        self.data_2018 = self.create_num(self.data_2018,\"Q24\",self.coding_exp_mapping,\"coding_exp_num\" )\n        self.data_2018 = self.create_grp(self.data_2018,\"Q24\",self.coding_exp_mapping,\"coding_exp_grp\" )\n        \n        \n        \n    def get_company_size(self):\n        '''\n         This function performes cleaning of employer size question response over the years.\n        '''\n        self.data_2020 = self.create_num(self.data_2020,\"Q20\",self.employer_size_mapping,\"employer_size_num\" )\n        self.data_2020 = self.create_grp(self.data_2020,\"Q20\",self.employer_size_mapping,\"employer_size_grp\" )\n        \n        \n        self.data_2019['Q6'] = np.where(self.data_2019['Q6'].isin([\"> 10,000 employees\"]), \"10,000 or more employees\" , self.data_2019['Q6'])\n        self.data_2019 = self.create_num(self.data_2019,\"Q6\",self.employer_size_mapping,\"employer_size_num\" )\n        self.data_2019 = self.create_grp(self.data_2019,\"Q6\",self.employer_size_mapping,\"employer_size_grp\" )\n        \n    def get_ds_workloads(self):\n        '''\n         This function performes cleaning of ML workload size question response over the years.\n        '''\n        \n        self.data_2020 = self.create_num(self.data_2020,\"Q21\",self.ds_workloads_mapping,\"ds_workloads_num\" )\n        self.data_2020 = self.create_grp(self.data_2020,\"Q21\",self.ds_workloads_mapping,\"ds_workloads_grp\" )\n        \n        self.data_2019 = self.create_num(self.data_2019,\"Q7\",self.ds_workloads_mapping,\"ds_workloads_num\" )\n        self.data_2019 = self.create_grp(self.data_2019,\"Q7\",self.ds_workloads_mapping,\"ds_workloads_grp\" )\n       \n        \n    def get_ml_usage(self):       \n        '''\n         This function performes cleaning of ML usage question response over the years.\n        '''\n        self.data_2020 = self.create_grp(self.data_2020,\"Q22\",self.ml_usage_mapping,\"ml_usage_grp\" )\n        self.data_2019 = self.create_grp(self.data_2019,\"Q8\",self.ml_usage_mapping,\"ml_usage_grp\" )\n        self.data_2018 = self.create_grp(self.data_2018,\"Q10\",self.ml_usage_mapping,\"ml_usage_grp\" )\n                                 \n                                 \n    def get_past_data(self):\n        '''\n         Main function to call above functions.\n        '''\n        self.load_past_years_data()\n        self.preprocess_data()\n        self.get_gender()\n        self.clean_country_col()\n        self.get_age()\n        self.get_job()\n        self.get_ml_exp()\n        self.get_ml_usage()\n        self.get_coding_exp()\n        self.get_company_size()\n        self.get_ds_workloads()\n        \n        return self.data_2020,self.data_2019,self.data_2018,self.data_2017\n        \n        ","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-08-27T07:56:45.556679Z","iopub.execute_input":"2021-08-27T07:56:45.556949Z","iopub.status.idle":"2021-08-27T07:56:45.637579Z","shell.execute_reply.started":"2021-08-27T07:56:45.556922Z","shell.execute_reply":"2021-08-27T07:56:45.636545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## load data\nks = kaggle_survey()\ndata_2020,data_2019,data_2018,data_2017 = ks.get_past_data()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-08-27T07:56:45.638741Z","iopub.execute_input":"2021-08-27T07:56:45.639023Z","iopub.status.idle":"2021-08-27T07:56:52.764486Z","shell.execute_reply.started":"2021-08-27T07:56:45.638984Z","shell.execute_reply":"2021-08-27T07:56:52.763331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"default = [\"ALL\"]\ncommon_countries = [\"India\",\"United States of America\"]\ntop4_countries = [\"India\",\"United States of America\",'Brazil','Japan']\nyears_color_code = {\"2020\":\"#CF7224\",\"2019\":\"#17B0EB\",\"2018\":\"#3D17EB\"}","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-27T07:56:52.765758Z","iopub.execute_input":"2021-08-27T07:56:52.766072Z","iopub.status.idle":"2021-08-27T07:56:52.772562Z","shell.execute_reply.started":"2021-08-27T07:56:52.766034Z","shell.execute_reply":"2021-08-27T07:56:52.771494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Common Functions \n\ndef yearly_trends_NE(data_sets = {\"2020\":data_2020,\n                                  \"2019\":data_2019,\n                                  \"2018\":data_2018} ,\n                     columns = {\"2020\": \"Q1\",\n                                \"2019\": \"Q1\",\n                                \"2018\": \"Q1\"}, \n                     filters = {\"countries\" : [\"ALL\"], \"job\" : ['ALL']},\n                     exclude_null = True, threshold_per_year = 10,sort_values = True,figure_hgt = 400,\n                     title_values = {\"main\":\"Title\",\"xaxis\":\"xaxis\",\"yaxis\":\"yaxis\"},\n                     color_range = years_color_code ):\n    \n    '''\n    This function creates a grouped bar chart.\n    \n    It has the following dependencies:\n    plotly express: 0.4.1\n    \n    import plotly.express as px\n    '''\n    \n    yearly_data = pd.DataFrame()\n    for year in columns.keys() :\n        tmp_col = columns[year]\n        tmp_data = data_sets[year].copy()\n        tmp_data = tmp_data[~tmp_data.job.isnull()]\n        tmp_data['not_emplyed'] = np.where(tmp_data.job == \"Not employed\",1,0)\n        \n        #add availabe filters\n        for filter_col,values in filters.items():\n            if values[0] != \"ALL\":\n                tmp_data = tmp_data[tmp_data[filter_col].isin(values)] \n                \n        #exclude null values\n        if exclude_null:\n            tmp_data = tmp_data[~tmp_data[tmp_col].isnull()]\n        \n        df = tmp_data.groupby([tmp_col,'Year'])['not_emplyed'].agg({\"count\",\"mean\",\"sum\"}).reset_index()\n        df['mean'] = 100*df['mean']  \n        df.rename(columns= {tmp_col:\"var\"}, inplace = True)        \n        yearly_data = pd.concat([yearly_data,df], axis=0)\n        \n\n    \n    if (sort_values): \n        # sorting based on yearly change in trend \n        a = yearly_data.pivot_table(index = \"var\",columns = \"Year\",values = \"mean\").reset_index()\n        a['2020_2019'] = a[2020] - a[2019]\n        a['2019_2018'] = a[2019] - a[2018]\n        a['yearly_cahange'] = a['2020_2019']/a['2019_2018']\n        a.sort_values(by =['yearly_cahange'], inplace = True)\n\n        #removing insufficient data points \n        b = yearly_data.pivot_table(index = \"var\",columns = \"Year\",values = \"sum\").reset_index()\n        b['total_sum'] = b.sum(axis=1)\n        a = a.merge(b,on=['var'], how = \"inner\")\n        \n        #implement both the sorting\n        fil_val = list(a[a.total_sum>threshold_per_year*len(columns.keys())]['var'].values)\n\n        dummy_df = pd.DataFrame()\n        dummy_df['var'] = list(fil_val)\n        dummy_df['ranking'] = range(0,len(dummy_df))\n        \n        #sorting the columns\n        yearly_data = yearly_data.merge(dummy_df,on=['var'], how = \"inner\")\n        yearly_data.sort_values(by = ['ranking'], inplace = True)\n    \n    # Draw Plot\n    fig = go.Figure()\n    for year in list(columns.keys())[::-1]:\n        tmp_data = yearly_data[yearly_data.Year==int(year)]\n        fig.add_trace(go.Bar( x=tmp_data['var'],\n                                y=tmp_data['mean'],\n                                name=year,\n                                marker_color=color_range[year]))\n\n    fig.update_layout(barmode='group', xaxis_tickangle=-45, title = title_values['main'], width = 1300, height = figure_hgt)\n    fig.update_xaxes(title=dict(text = title_values['xaxis']))\n    fig.update_yaxes(title=dict(text = title_values['yaxis']))\n    fig.show()\n\n    \ndef plotly_bar_chart(response_counts,title,y_axis_title,orientation):\n    '''\n    This function creates a bar chart.\n    \n    It has the following dependencies:\n    plotly express: 0.4.1\n    \n    import plotly.express as px\n    '''\n    response_counts_series = pd.Series(response_counts)\n    fig = px.bar(response_counts_series,\n             labels={\"index\": '',\"value\": y_axis_title},\n             text=response_counts_series.values,\n             orientation=orientation,)\n    fig.update_layout(showlegend=False,\n                      title={'text': title,\n                             'y':0.95,\n                             'x':0.5,})\n    fig.show()\n    \n    \ndef multilevel_cols(df):\n    new_col = []\n    for i in df.columns:\n        if len(i[1]):\n            new_col.append(i[0]+\"_\"+i[1])\n        else:\n             new_col.append(i[0])\n    return new_col\n\ndef yearly_trends_job_title(data_sets = {\"2020\":data_2020,\n                                  \"2019\":data_2019,\n                                  \"2018\":data_2018} ,\n                            years = ['2020','2019','2018'],\n                            countries_comp = ['India'],job = ['Data Scientist'],\n                            figure_hgt = 500,x = \"ml_exp_num\",y=\"coding_exp_num\",\n                            title_values = {\"main\":\"Title\",\"xaxis\":\"xaxis\",\"yaxis\":\"yaxis\"}):\n    \n    '''\n    This function creates a grouped bar chart.\n    \n    It has the following dependencies:\n    plotly express: 0.4.1\n    \n    import plotly.express as px\n    '''\n    \n    res = pd.DataFrame()\n    for year in years:\n        df = data_sets[year].groupby(['country','job'])[[x,y]].agg({\"mean\",\"count\"}).reset_index()\n        df.columns = multilevel_cols(df)\n        df = df[df['job'].isin(job)]\n        df = df[df.country.isin(countries_comp)]\n        df['Year'] = [year]*len(df)\n        res = pd.concat([res,df], axis=0)\n    size_col = x+\"_count\"\n    x+= \"_mean\"\n    y+= \"_mean\"\n    \n    ##Draw plot \n    fig = px.scatter(res, x=x, y=y, text=\"country\", log_x=True, size_max=100, color=\"Year\",size = size_col,\n                     title=title_values['main'])\n    fig.update_traces(textposition='top center')\n    fig.update_layout(xaxis_tickangle=-45, width = 1400, height = figure_hgt)\n    fig.update_xaxes(title=dict(text = title_values['xaxis']))\n    fig.update_yaxes(title=dict(text = title_values['yaxis']))\n\n    fig.show()\n    ","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-27T07:56:52.774908Z","iopub.execute_input":"2021-08-27T07:56:52.775185Z","iopub.status.idle":"2021-08-27T07:56:52.809155Z","shell.execute_reply.started":"2021-08-27T07:56:52.775159Z","shell.execute_reply":"2021-08-27T07:56:52.80811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <a id=\"section-one\"></a>[](http://)\n<font color='#2A6FBB' size=5 >(1) Introduction</font><br>  \n\nIt's no secret that how [the novel coronavirus 2019 (COVID-19)](https://en.wikipedia.org/wiki/COVID-19_pandemic) outbreak is affecting millions of lives around the world, many companies shut down, lots of people lose their jobs. In this notebook/work, I’ve analyzed the impact of Covid19 pandemic impact on kagglers. The kaggle survey was live for 3.5 weeks in October, so I believe by diagnostic survey responses, we can get some initial trend of pandemic on data science and machine learning communiity. I’ve also included past year kaggle surveys responses to highlight changes in trend of year-2020 as compared to 2019, 2018. I’ve not not included available 2017 survey responses as there was no significant overlap in questions.  \n \nIn this work, I’ve analyzed ***Select the title most similar to your current role (or most recent title if retired)*** question from the survey and especially focused on understanding the Not Employed segment of kagglers and analyzed past years' trend to draw parallel insights of pandemic impact. The main focus of this work to understand the pandemic impact and help to answer the below questions? \n \n- `Which country sees the huge impact because of Covid19?`\n- `Which segments of kagglers are highly impacted by pandemic?`\n\n\nLets begin with understanding the country wise responses count of 2020 survey.\n\n[](http://)","metadata":{}},{"cell_type":"code","source":"percentages = round(100*data_2020['country'].value_counts(normalize = True)[:10],2)\ntitle_for_chart = '<b>Most Common Nationalities (2020 Survey)<b>'\ntitle_for_y_axis = '% of respondents'\norientation_for_chart = 'h'\nplotly_bar_chart(response_counts=percentages,\n                 title=title_for_chart,\n                 y_axis_title=title_for_y_axis,\n                 orientation=orientation_for_chart)","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2021-08-27T07:56:52.810719Z","iopub.execute_input":"2021-08-27T07:56:52.811066Z","iopub.status.idle":"2021-08-27T07:56:53.853767Z","shell.execute_reply.started":"2021-08-27T07:56:52.810974Z","shell.execute_reply":"2021-08-27T07:56:53.85297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- It seems India and USA contributed close to 41% of overall responses. In order to reduce the bias from these two countries on overall insights across the world, I’ve tried to analyze these 2 countries' data separately where required. \n- To analyze covid19 impact on kagglers jobs, I’ve especially forced on **\"Not employed”** kagglers extracted from Q5 of the survey “Select the title most similar to your current role (or most recent title if retired)”  ","metadata":{}},{"cell_type":"code","source":"rows=2\ncols=3\nfig = make_subplots(\n    rows=rows, cols=cols,\n    specs=[[{\"type\": \"pie\",\"rowspan\":2},{\"type\": \"pie\"},{\"type\": \"pie\"}],\n           [None, {\"type\": \"pie\"},{\"type\": \"pie\"}]],horizontal_spacing = 0.05,vertical_spacing = 0.25,\n    print_grid=False)\n\nnot_employed_2020 = data_2020['job'].value_counts(normalize = True)\npull = [0.2]*len(not_employed_2020)\npull = pull*(not_employed_2020.index==\"Not employed\")\nfig.add_trace(go.Pie(labels=not_employed_2020.index, values=not_employed_2020.values, pull=pull,title = \"<b>2020 Survey - All responses<b>\"),row=1,col=1)\nfor count,country in enumerate(common_countries+ ['Brazil','Japan']):\n    row = int(count/rows)+1\n    column = count +1-rows*int(count/rows)+1\n    not_employed_country = data_2020[data_2020.country==country].Q5.value_counts(normalize = True)\n    pull = [0.2]*len(not_employed_country)\n    pull = pull*(not_employed_country.index==\"Not employed\")\n    fig.add_trace(go.Pie(labels=not_employed_country.index, values=not_employed_country.values, pull=pull,title = '<b>' + country + '</b>'),row=row,col=column)\nfig.show()\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-27T08:00:03.31366Z","iopub.execute_input":"2021-08-27T08:00:03.314025Z","iopub.status.idle":"2021-08-27T08:00:03.416261Z","shell.execute_reply.started":"2021-08-27T08:00:03.313976Z","shell.execute_reply":"2021-08-27T08:00:03.415299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- In the 2020 survey, out of 19,277 non-null responses on Q5 questions participants, 1652 kagglers are ‘Not Employed’, which is 8.57% of the total. \n- Not employed % varies from 4% to 10.1% among the top responded countries, India with the highest percentage of 10.1%. \n- **Just looking at the 2020 numbers is not enough to make any conclusion whether high not employed occurring because of some external events( Covid19) or its normal to have such high %. Analysing past years trends will help to answer the main cause of high not employed% in 2020.**","metadata":{}},{"cell_type":"markdown","source":"<a id=\"subsection-one\"></a>[](http://)\n<font color='#2A6FBB' size=5> Methodology to analyze past years surevy responses</font><br>  \nI’ve consider the following methodology to effectively compare the past years data and to generate insights further \n- As base populations change over time and also the distribution of dimensions (country, age,job) which we can use for generating insights also varies across years. \n- For example: For USA nationality, count of responded kagglers decreased from 3085(year-2019) to 2237(year-2020) whereas no. of total survey count increased in 2020 as compared to 2019. To normalize this, **I’ve tracked how a fraction of not-employed changes over time across different dimensions (country, age,job) rather than using absolute not employed responses count**\n- I’ve apply minimum condition on not-employed/total count across dimensions to remove unwanted noise from the data.\n- In the end, I’ve sorted data into based on year-wise increment in % of non-employed changes from 2018-19 to 2019-2020\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-two\"></a>[](http://)\n<font color='#2A6FBB' size=5 >Q1) Which country sees the huge impact because of Covid19?</font><br>  \n[](http://)","metadata":{}},{"cell_type":"code","source":"yearly_trends_NE(columns = {\"2020\": \"country\",\n                            \"2019\": \"country\",\n                            \"2018\": \"country\"},\n                 threshold_per_year = 15 , \n                 title_values = {\"main\":\"Not Employed yearly trend <b>(Countries Wise)</b>\", \"xaxis\" : \"country\", \"yaxis\":\"% of responses Not Employed\"})","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-27T07:56:54.19351Z","iopub.execute_input":"2021-08-27T07:56:54.193787Z","iopub.status.idle":"2021-08-27T07:56:55.49122Z","shell.execute_reply.started":"2021-08-27T07:56:54.193761Z","shell.execute_reply":"2021-08-27T07:56:55.490193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Insights\n\n\n- In 2020, Not employed% increased in all the major countries as compared to 2019, indicating occurrence of some world event **(COVID19)** which resulted in huge job loss in data science and machine learning community \n- In Russia/Indonesia/Turkey, not-employed trends was in downward side in 2018-19 but drastically increased in 2019-20\n- India, USA, and Spain are the highly affected countries based on year-to-year changes in rate.\n- All highly impacted countries based on not-employed rate are also heavily impacted by Covid19, [reported by World Health Organization (WHO)](https://covid19.who.int/?gclid=Cj0KCQiA3NX_BRDQARIsALA3fILEptDxsQZ0WhYMBincH-NmbFHk81OCudjm0I8AJ4qy7hlXDQjO_rMaAm13EALw_wcB)\n\n\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-three\"></a>[](http://)\n<font color='#2A6FBB' size=5 >Q2) Which segments of kagglers are highly impacted by pandemic?</font><br> \n* Analyzed not employed population on different segments of kagglers breaking using coding experience, machine learning experience, education background, and age group dimensions. \n[](http://) ","metadata":{}},{"cell_type":"markdown","source":"<a id=\"subsection-two\"></a>[](http://)\n<font color='#2A6FBB' size=5> Coding Experience</font><br> ","metadata":{}},{"cell_type":"code","source":"for country in [\"ALL\"] + common_countries:\n    title = \"Not Employed yearly trend <b> Coding Experience-({}) </b>\".format(country)\n    yearly_trends_NE(columns = {\"2020\": \"coding_exp_grp\",\n                            \"2019\": \"coding_exp_grp\",\n                            \"2018\": \"coding_exp_grp\"},\n                 filters = {\"country\":[country]},\n                 sort_values=True, figure_hgt=350,\n                 title_values = {\"main\":title, \"xaxis\" : \"coding exp (years)\", \"yaxis\":\"% of responses Not Employed\"})\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-27T07:56:55.492434Z","iopub.execute_input":"2021-08-27T07:56:55.492706Z","iopub.status.idle":"2021-08-27T07:56:58.935787Z","shell.execute_reply.started":"2021-08-27T07:56:55.492678Z","shell.execute_reply":"2021-08-27T07:56:58.93481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Insights\n\n- Experienced kagglers(10+ experience) survied well, as less numbers of kagglers impacted by external worldwide event (covid19) as the year-to-year change in not-employed rate is not that high as compared to beginners in coding.  \n- In USA, fraction of not-employed in experience coding bucket decrease in 2020\n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"subsection-three\"></a>[](http://)\n<font color='#2A6FBB' size=5> Age Group </font><br> ","metadata":{}},{"cell_type":"code","source":"for country in [\"ALL\"] + common_countries:\n    title = \"Not Employed yearly trend <b> Age Group-({}) </b>\".format(country)\n    yearly_trends_NE(columns = {\"2020\": \"Q1\",\n                            \"2019\": \"Q1\",\n                            \"2018\": \"Q2\"},\n                 filters = {\"country\":[country]},\n                 sort_values=True,figure_hgt=350,threshold_per_year=5,\n                 title_values = {\"main\":title, \"xaxis\" : \"Age (years)\", \"yaxis\":\"% of responses Not Employed\"})\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Insights\n\n- Not-employed rate increased for all the age group\n- 25-29 and 45-49: not-employed fraction changes heavily in 2019-2020 (middle experienced employee affected may be because of layoff)\n- In 22-24 group, fraction of not-employed rate is highest among the group (decrease in demand of new jobs because of covid19) \n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"subsection-four\"></a>[](http://)\n<font color='#2A6FBB' size=5> Education Background</font><br> ","metadata":{}},{"cell_type":"code","source":"for country in [\"ALL\"] + common_countries:\n    title = \"Not Employed yearly trend <b> Education Background-({}) </b>\".format(country)\n    yearly_trends_NE(columns = {\"2020\": \"Q4\",\n                            \"2019\": \"Q4\",\n                            \"2018\": \"Q4\"},\n                 filters = {\"country\":[country]},\n                 sort_values=True,figure_hgt=350,threshold_per_year = 10,\n                 title_values = {\"main\":title, \"xaxis\" : \"Education Background\", \"yaxis\":\"% of responses Not Employed\"})\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Insights\n\n- Kagglers with no formal education background less impacted, as in first place they usually not opt for corporate job and most of them work on their own business/startup/freelance  \n- Kagglers with Bachelors education background affected the most, as companies growth slows down during pandemic period and they not hired/fired recent pass out \n- In USA, Doctoral degree professional affected the most \n\n- Because of covid19, [lots of companies business impacted and they revoked offers](https://www.forbes.com/sites/poetsandquants/2020/03/29/how-covid-19-is-crashing-on-the-class-of-2020-job-offers-already-disappearing/?sh=5b0f93b63ffb) or [delayed joining to new joiners (fresh pass out from colleges)](https://economictimes.indiatimes.com/jobs/covid-19-to-delay-job-interviews-impact-hiring-experts/articleshow/74757861.cms?from=mdr) which resulted increase in not-employed rate for kagglers who just starting their careers in data science machine \n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"subsection-five\"></a>[](http://)\n<font color='#2A6FBB' size=5> ML Experience</font><br> ","metadata":{}},{"cell_type":"code","source":"for country in [\"ALL\"] + common_countries:\n    title = \" Not Employed yearly trend <b> Machine Learning Experience-({}) </b>\".format(country)\n    yearly_trends_NE(columns = {\"2020\": \"ml_exp_grp\",\n                            \"2019\": \"ml_exp_grp\",\n                            \"2018\": \"ml_exp_grp\"},\n                 filters = {\"country\":[country]},\n                 sort_values=True,figure_hgt=400,threshold_per_year = 10,\n                 title_values = {\"main\":title, \"xaxis\" : \"ML Experience (years)\", \"yaxis\":\"% of responses Not Employed\"})\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Insights\n- Experienced ML kagglers(4+ experience) survied well, as less numbers of kagglers impacted based on the year-to-year change in not-employed rate is not that high as compared to beginners in ML.  ","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-four\"></a>[](http://)\n<font color='#2A6FBB' size=5 >Q3) How Data Scientist profile evolved over time and across countries?</font><br> \n- In this section, I've analyzed data scientist profile in respect to coding experience, ML experience,and employer size.  \n- I've converted the binning(window) group into numerical information by picking the middle point of the window and for the corner window, I've considered the high capped point and added the gap/2 of the previous window. \n- Example used 7.5 for window [5,10], and used 12.5 for [10+] window \n\n\n[](http://) ","metadata":{}},{"cell_type":"markdown","source":"<a id=\"subsection-six\"></a>[](http://)\n<font color='#2A6FBB' size=5> Evolution of Data Scientist </font><br> ","metadata":{}},{"cell_type":"code","source":"job = ['Data Scientist']\ntitle = \"Evolution of <b>\" + job[0] + \"</b> Profile over time (Experience in ML and Coding)\"\nyearly_trends_job_title(countries_comp=top4_countries,figure_hgt=600,job = job ,\n                        title_values = {\"main\":title,\n                                        \"xaxis\" : \"Avg. ML Experience (Years)\", \n                                        \"yaxis\":\"Avg. Coding Experience (Years)\"})\n\ntitle = \"Evolution of <b>\" + job[0] + \"</b> Profile over time (Experience in ML and Employer size)\"\nyearly_trends_job_title(countries_comp=top4_countries,figure_hgt=600,job = job ,\n                        x = \"ml_exp_num\", y = \"employer_size_num\",\n                        years = ['2020','2019'],\n                        title_values = {\"main\":title,\n                                        \"xaxis\" : \"Avg. ML Experience (Years)\", \n                                        \"yaxis\":\"Avg. Employer Size\"})","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Insights\n\n- It seems in the USA, a data scientist profile is highly experienced in ML and coding. Based on the 2020 survey, average 5 years of ML experience and average 10 years of coding experience, which is highest among the countries.\n- Data Scientists in India have minimal experience in coding and ML as compared to other major countries. In short we can say that the Data scientist position in the USA its kind of a managerial role whereas in India its entry role position.    \n- From 2019-2020, India shifted towards the left side in the above graph, meaning lots of new fresh data scientists (with minimal experience in ML) added in 2020. Whereas there is not that much shift in the USA, indicates the data scientist market in the USA is kind of stable with respect to coding and ML experience. \n- From 2019-2020, Japan and Brazil shifted in upward directions, indicating data scientist profiles move towards software/developer profiles where high experience in coding is required.   \n\n### Employer Size\n- From 2019-2020, India shifted towards left bottom, indicating lot of small companies (startup) hiring freshers as data scientists\nUSA is placed at top-right position, meaning big companies leveraging ML solutions, which is true as lot of technical giants companies as their headquarters in USA   \n","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-five\"></a>[](http://)\n<font color='#2A6FBB' size=5 >Conclusion</font><br> \n- In 2020, Not employed% increased in all the major countries as compared to 2019, indicating occurrence of some world event **(COVID19)** which resulted in huge job loss in data science and machine learning community \n- All highly impacted countries based on not-employed rate are also heavily impacted by Covid19, [reported by World Health Organization (WHO)](https://covid19.who.int/?gclid=Cj0KCQiA3NX_BRDQARIsALA3fILEptDxsQZ0WhYMBincH-NmbFHk81OCudjm0I8AJ4qy7hlXDQjO_rMaAm13EALw_wcB)\n- Experienced(coding or ML) kagglers survied well in 2020, as less fraction of kagglers impacted by external worldwide event (covid19)\n- Kagglers with no formal education background less impacted, as in first place they usually not opt for corporate job and most of them work on thor own business/startup/freelance  \n- Kagglers with Bachelors education background affected the most, as companies growth slow down during pandemic period and they not hired recent/fired recent pass out","metadata":{}},{"cell_type":"markdown","source":"<a id=\"section-six\"></a>[](http://)\n<font color='#2A6FBB' size=5 >References </font><br> \n- [2020 Kaggle Data Science & Machine Learning Survey](https://www.kaggle.com/paultimothymooney/2020-kaggle-data-science-machine-learning-survey) by Paul Mooney\n- [ Who codes what and how long - a story told through a heatmap](https://www.kaggle.com/tkubacka/a-story-told-through-a-heatmap) by Teresa Kubacka\n- [WHO Report - COVID 19](https://covid19.who.int/?gclid=Cj0KCQiA3NX_BRDQARIsALA3fILEptDxsQZ0WhYMBincH-NmbFHk81OCudjm0I8AJ4qy7hlXDQjO_rMaAm13EALw_wcB)","metadata":{}}]}