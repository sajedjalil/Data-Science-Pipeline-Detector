{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing the packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport copy\nimport matplotlib.pyplot as plt\nimport plotly\nimport seaborn as sns\nimport plotly.graph_objects as go\n!pip install pygal\n# Importing pygal and its styles\nimport pygal\nfrom pygal.style import Style\n\nfrom IPython.display import display, HTML\nfrom datetime import datetime, timedelta\nfrom mlxtend.preprocessing import TransactionEncoder\n\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import preprocessing\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\n\nfrom sklearn.model_selection import train_test_split\nplotly.offline.init_notebook_mode (connected = True)\nplt.rcParams['figure.dpi'] = 500\n\n\n!pip install apyori\nfrom apyori import apriori\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# This is helper function to render plot in html format\nbase_html = \"\"\"\n<!DOCTYPE html>\n<html>\n  <head>\n  <script type=\"text/javascript\" src=\"http://kozea.github.com/pygal.js/javascripts/svg.jquery.js\"></script>\n  <script type=\"text/javascript\" src=\"https://kozea.github.io/pygal.js/2.0.x/pygal-tooltips.min.js\"\"></script>\n  </head>\n  <body>\n    <figure>\n      {rendered_chart}\n    </figure>\n  </body>\n</html>\n\"\"\"\n\ndef pygalplot(chart):\n    rendered_chart = chart.render(is_unicode=True)\n    plot_html = base_html.format(rendered_chart=rendered_chart)\n    display(HTML(plot_html))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Importing the data and having the first look of the data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Importing the data\ndata=pd.read_csv('../input/kaggle-survey-2020/kaggle_survey_2020_responses.csv',low_memory=False)\n\n# Getting the first 20 columns and some more specific columns from the data\ncolumnss=list(data.columns[:20])\ncolumnsss=['Q15','Q20','Q21','Q24','Q25']\ncolumnss.extend(columnsss)\n\n# Filtering the data\ndata=data[columnss]\n\n# Code to change the name of the columns\ndata.columns=data.iloc[0,:].values\n\n# code to remove the first row\ndata.drop(index=0,inplace=True)\n\n# So we are dropping all the rows with nan values in the first 5 columns\ndata.dropna(subset=data.columns[:6],inplace=True)\ndata.dropna(subset=data.columns[20:],inplace=True)\n\n# Having a look at the data\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Number of Responses of the survey all over the world"},{"metadata":{"trusted":true},"cell_type":"code","source":"# here we gonna put all the names of the countries in the variable a and all the values of the counts in \n# variable b\na=data['In which country do you currently reside?'].value_counts().index\nb=data['In which country do you currently reside?'].value_counts().values\n\na=list(a)\nb=list(b)\n\n\n\nfig = go.Figure(data=go.Choropleth(\n    locations=a, # Spatial coordinates\n    z = b, # Data to be color-coded\n    locationmode = 'country names', # set of locations match entries in `locations`\n    colorscale = 'Reds',\n    colorbar_title = \"Total Number\",\n))\n\nfig.update_layout(\n    title_text = 'Data Analysis on the basis of number of survey in different countries',\n    geo_scope='world', # limite map scope to USA\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Having a look at the Response of certaing age groups"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Grouping the data on the basis of age and gender\ngg=data.groupby(['What is your age (# years)?','What is your gender? - Selected Choice']).count()\n\n# getting the array of the index of the grouped dataframe\nindexx=np.array(gg.index)\n\n# Making a dataframe\nage_group=pd.DataFrame()\n\nindexx=np.array(list(indexx))\n\nage_group['Age']=indexx[:,0]\nage_group['Gender']=indexx[:,1]\nage_group['Number']=list(gg['Duration (in seconds)'].values)\n\n# Plotting the plot\npx.bar(data_frame=age_group,x='Age',y='Number',color='Gender',template='plotly_dark')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Having a look at the duration of the Survey and how much time it takes to respond to it"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style(\"darkgrid\")\npt=sns.distplot(data['Duration (in seconds)'])\npt.set(xlim=(0,200000),ylim={0,0.000001})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Having a look at the composition of People who gave the survey"},{"metadata":{"trusted":true},"cell_type":"code","source":"nam=data['Select the title most similar to your current role (or most recent title if retired): - Selected Choice'].value_counts()\npx.pie(values=nam.values,names=nam.index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Having a look at the Salary Composition of the People who gave the survey"},{"metadata":{"trusted":true},"cell_type":"code","source":"salary_order = ['$0-999', '1,000-1,999', '2,000-2,999', '3,000-3,999', \n                '4,000-4,999', '5,000-7,499', '7,500-9,999', '10,000-14,999',\n                '15,000-19,999', '20,000-24,999', '25,000-29,999', \n                '30,000-39,999', '40,000-49,999', '50,000-59,999', \n                '60,000-69,999', '70,000-79,999', '80,000-89,999', \n                '90,000-99,999', '100,000-124,999', '125,000-149,999',\n                '150,000-199,999', '200,000-249,999', '250,000-299,999', \n                '300,000-500,000', '> $500,000']\nsalary = data['What is your current yearly compensation (approximate $USD)?'].fillna('unknown').value_counts()[salary_order]\n\npx.bar(x = salary, \n         y = salary.index,labels={'x':'Total Number','y':'Salary Range of the person'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking the count by Sex and Age"},{"metadata":{"trusted":true},"cell_type":"code","source":"max_salary = data['What is your current yearly compensation (approximate $USD)?'].fillna('unknown-unknown') \\\n    .apply(lambda x: x.replace('$', '') \\\n    .replace('> 500,000', '500,000-500,000') \\\n    .replace(',', '') \\\n    .split(\"-\")[1]).replace('unknown', np.nan).astype('float64') + 1\n\nnew_df = pd.DataFrame({'max_salary': max_salary, 'age': data['What is your age (# years)?']})\nnew_df['sex'] = data['What is your gender? - Selected Choice']\n\nhm = pd.DataFrame(new_df[new_df.sex.isin(['Man', 'Woman'])][['sex', 'age']] \\\n                  .value_counts()).reset_index().pivot('sex', 'age', 0) \\\n                  .fillna(0).astype('int')\n\nplt.figure(figsize=(10, 5))\nplt.title('Count by sex and age', size = 15, fontweight = 'bold', fontfamily = 'serif')\nsns.heatmap(hm, annot = True, fmt = \"d\", linewidths=.5)\nplt.xlabel('Age', fontfamily = 'serif')\nplt.ylabel('Sex', fontfamily = 'serif')\nplt.xticks(fontfamily = 'serif')\nplt.yticks(fontfamily = 'serif')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking the count by position and Education"},{"metadata":{"trusted":true},"cell_type":"code","source":"education_order = ['No formal education past high school', \n              'Some college/university study without earning a bachelor’s degree',\n              'Professional degree', 'Bachelor’s degree', \n              'Master’s degree', 'Doctoral degree']\nnew_df['education'] = data['What is the highest level of formal education that you have attained or plan to attain within the next 2 years?']\n\nnew_df['position'] = data['Select the title most similar to your current role (or most recent title if retired): - Selected Choice']\n\nnew_df['experience'] = data['For how many years have you been writing code and/or programming?']\n\nhm = pd.DataFrame(new_df[['position', 'education']].value_counts()) \\\n    .reset_index().pivot('position', 'education', 0) \\\n    .fillna(0).astype('int')[education_order]\n\nplt.figure(figsize=(10, 6))\nplt.title('Count by position and education', size = 15, \n          fontweight = 'bold', fontfamily = 'serif')\nsns.heatmap(hm, annot = True, fmt = \"d\", linewidths=.5)\n\nplt.xlabel('Education', fontfamily = 'serif')\nplt.ylabel('Position', fontfamily = 'serif')\nplt.xticks(fontfamily = 'serif')\nplt.yticks(fontfamily = 'serif')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Salary and Age Distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['What is your age (# years)?'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"salary=[]\nfor i in data['What is your age (# years)?'].unique():\n    t=[]\n    for j in data[data['What is your age (# years)?']==i]['What is your current yearly compensation (approximate $USD)?'].values:\n        if j=='> $500,000':\n            t.append(500000)\n        else:\n            k=int(j.split('-')[1].replace(',',''))\n            t.append(k)\n    salary.append(t)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"box_plot = pygal.Box(box_mode='tukey')\nbox_plot.title = 'Salar vs Age'\nx=data['What is your age (# years)?'].unique()\nfor i in range(len(x)):\n    box_plot.add(x[i],salary[i])\npygalplot(box_plot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Salary Composition Of Data Scientists :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"group=data[data['Select the title most similar to your current role (or most recent title if retired): - Selected Choice']=='Data Scientist'].groupby('What is your current yearly compensation (approximate $USD)?').count()\ngauge_chart = pygal.Gauge(human_readable=True)\ngauge_chart.title = 'Composition of Salary Of Data Scientists'\ngauge_chart.range = [0, max(group['Select the title most similar to your current role (or most recent title if retired): - Selected Choice'])]\nfor i in range(len(group)):\n    gauge_chart.add(group.index[i],group['Select the title most similar to your current role (or most recent title if retired): - Selected Choice'].values[i])\npygalplot(gauge_chart)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tree Map of Salary Vs Education"},{"metadata":{"trusted":true},"cell_type":"code","source":"salary=[]\nxx=data['What is the highest level of formal education that you have attained or plan to attain within the next 2 years?'].unique()\nfor i in xx:\n    t=[]\n    for j in data[data['What is the highest level of formal education that you have attained or plan to attain within the next 2 years?']==i]['What is your current yearly compensation (approximate $USD)?'].values:\n        if j=='> $500,000':\n            t.append(500000)\n        else:\n            k=int(j.split('-')[1].replace(',',''))\n            t.append(k)\n    salary.append(t)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"treemap = pygal.Treemap()\ntreemap.title = 'Salary Vs Education'\nfor i in range(len(xx)):\n    treemap.add(xx[i],salary[i])\npygalplot(treemap)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's have a look at whats the mean salary of people with different education levels :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"mm=[]\nfor i in salary:\n    mm.append(np.array(i).mean())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gauge = pygal.SolidGauge(inner_radius=0.70)\n\nfor i in range(len(xx)):\n    gauge.add(xx[i],[{'value': mm[i], 'max_value': 100000}])\npygalplot(gauge)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Salary By Experience"},{"metadata":{"trusted":true},"cell_type":"code","source":"salarys=[]\nxxx=['< 1 years','1-2 years','3-5 years','5-10 years','10-20 years','20+ years']\nfor i in xxx:\n    t=[]\n    for j in data[data['For how many years have you been writing code and/or programming?']==i]['What is your current yearly compensation (approximate $USD)?'].values:\n        if j=='> $500,000':\n            t.append(500000)\n        else:\n            k=int(j.split('-')[1].replace(',',''))\n            t.append(k)\n    salarys.append(t)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"funnel_chart = pygal.Funnel()\nfunnel_chart.title = 'Salary By Experience'\nfor i in range(len(xxx)):\n    funnel_chart.add(xxx[i],salarys[i])\npygalplot(funnel_chart)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Age Distribution Of the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1,1, figsize=(15,6))\ndata_q1 = data['What is your age (# years)?'].value_counts().sort_index()\nax.bar(data_q1.index, data_q1, width=0.55, \n       edgecolor='darkgray', color='#d4dddd',\n      linewidth=0.7)\n\nfor i in data_q1.index:\n    ax.annotate(f\"{data_q1[i]}\",\n                xy=(i, data_q1[i] + 100),\n               va ='center', ha='center', fontweight='light',\n               fontfamily='serif', color='#4a4a4a')\n    \nfor s in ['top', 'left', 'right']:\n    ax.spines[s].set_visible(False)\n    \nax.set_ylim(0,4200)\nax.set_xticklabels(data_q1.index, fontfamily='serif')\nax.set_yticklabels(np.arange(0, 4001, 500), fontfamily='serif')\nfig.text(0.1, 0.95, 'Age Distribution', fontsize=15, fontweight='bold',\n        fontfamily='serif')\nax.grid(axis='y', linestyle='-', alpha=0.4)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Age/Gender Distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"data1=copy.deepcopy(data)\ndata1['What is your gender? - Selected Choice'] = data['What is your gender? - Selected Choice'].apply(lambda x : 'ETC' if x not in ['Man', \n                                                             'Woman']\n                              else x)\ndata_q1q2=data1[data1['What is your gender? - Selected Choice'] != 'ETC'].groupby(['What is your gender? - Selected Choice'])['What is your age (# years)?'].value_counts().unstack().sort_index()\nman = data_q1q2.loc['Man']\nwoman = -data_q1q2.loc['Woman']\n\nfig, ax = plt.subplots(1,1, figsize=(15,6))\nax.bar(man.index, man, width=0.55, color='#004c70', alpha=0.8,\n      label='Male')\nax.bar(woman.index, woman, width=0.55, color='#990000', alpha=0.8, \n      label='Female')\nax.set_ylim(-1200,3500)\n\nfor i in man.index:\n    ax.annotate(f\"{man[i]}\",\n               xy=(i, man[i] + 100),\n               va = 'center', ha='center', fontweight='light',\n               fontfamily='serif', color='#4a4a4a')\n    \nfor i in woman.index:\n    ax.annotate(f\"{-woman[i]}\",\n               xy=(i, woman[i] - 100),\n               va = 'center', ha='center', fontweight='light',\n               fontfamily='serif', color='#4a4a4a')\n    \nfor s in ['top', 'left', 'right', 'bottom']:\n    ax.spines[s].set_visible(False)\n    \nax.set_xticklabels(data_q1q2.columns, fontfamily='serif')\nax.set_yticks([])\nax.legend()\nfig.text(0.16, 0.95, 'Age / Gender Distribution', fontsize=15,\n        fontweight='bold', fontfamily='serif')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Converting Categorical to numerical values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's compact the data\ndf2=copy.deepcopy(data)\n\ndf2=df2.fillna('nan')\n\nnum=[]\nfor i in df2.iloc[:,7:].values:\n    count=0\n    for j in i:\n        if j=='nan':\n            pass\n        else:\n            count+=1\n    num.append(count)\ndf2=df2.iloc[:,:7]\ndf2['Total number of languages known']=num\ndf2.sort_values('Total number of languages known',ascending=False).head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cou=df2.columns[1:7]\ndef factorize(name,data):\n    for i in name:\n        data[i]=pd.factorize(data[i])[0]\n    return data\ndf2=factorize(cou,df2)\n\ndf2.columns=['Duration','Age','Gender','Country','Education','Title','Experience','Total number of languages known ']\n\ndf2.isna().sum()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Doing Clustering on Age , Experience and Number of languages known"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df2[['Age','Experience','Total number of languages known ']].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Building the Model\n#KMeans Algorithm to decide the optimum cluster number , KMeans++ using Elbow Mmethod\n#to figure out K for KMeans, I will use ELBOW Method on KMEANS++ Calculation\nfrom sklearn.cluster import KMeans\nwcss=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(1,11):\n    kmeans = KMeans(n_clusters= i, init='k-means++', random_state=0)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\n\n    #inertia_ is the formula used to segregate the data p","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualizing the ELBOW method to get the optimal value of K \nplt.plot(range(1,11), wcss,'bx-')\nplt.title('The Elbow Method')\nplt.xlabel('no of clusters')\nplt.ylabel('wcss')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of the clusters looks like 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters= 3, init='k-means++', random_state=0)\nkmeans.fit(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clusters=kmeans.fit_predict(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"px.scatter_3d(df2,x='Age',y='Experience',z='Total number of languages known ',color=clusters)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Doing clustering on the basis of all the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df2.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wcss=[]\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters= i, init='k-means++', random_state=0)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\n\n    #inertia_ is the formula used to segregate the data p","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visualizing the ELBOW method to get the optimal value of K \nplt.plot(range(1,11), wcss,'bx-')\nplt.title('The Elbow Method')\nplt.xlabel('no of clusters')\nplt.ylabel('wcss')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Still the number of clusters is 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans = KMeans(n_clusters= 3, init='k-means++', random_state=0)\nkmeans.fit(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clusters=kmeans.fit_predict(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding cluster column in the dataframe\ndf2['Clusters']=clusters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Having a look at the file \ndf2.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Making the dataframe for apriori"},{"metadata":{"trusted":true},"cell_type":"code","source":"apriori_data=data.iloc[1:,7:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"apriori_data.columns=[i for i in range(len(apriori_data.columns))]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"apriori_data.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Trying out the functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"records = []\nfor i in range(0, len(apriori_data)):\n    records.append([str(apriori_data.values[i, j]) for j in range(0, 10)])\n    \nfreq_langs = apriori(records, min_support=0.0045, min_confidence=0.2, min_lift=3, min_length=2)\nresults = list(freq_langs)\n\nprint(\"There are {} Relation derived.\".format(len(results)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lift = []\nassociation = []\nfor i in range (0, len(results)):\n    lift.append(results[:len(results)][i][2][0][3])\n    association.append(list(results[:len(results)][i][0]))\n    \nrank = pd.DataFrame([association, lift]).transpose()\nrank.columns = ['Association', 'Lift']\n\n# Show top 10 higher lift scores\nrank.sort_values('Lift', ascending=False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Putting all transactions in a single list\nlangs = []\nfor i in range(0, len(records)):\n    langs.extend(records[i])\n\n# Finding unique items from transactions\nuniquelangs = list(set(langs))\n\nuniquelangs\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Trying Eclat on pairs of languages"},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove nan values:-\nrecord = []\nfor sublist in records:\n    clean_sublist = [item for item in sublist if item is not np.nan]\n    record.append(clean_sublist)\n    \n#In eclat we have to change data to 0 1 format :-\n\nte = TransactionEncoder()\nte_ary = te.fit(record).transform(record)\ndf_x = pd.DataFrame(te_ary, columns=te.columns_) # encoding\n\npair = []\nfor j in range(0, len(uniquelangs)):\n    k = 1;\n    while k <= len(uniquelangs):\n        try:\n            pair.append([uniquelangs[j], uniquelangs[j+k]])\n        except IndexError:\n            pass\n        k = k + 1;\npair\npairs=[]\nfor i in pair :\n    if 'nan' in i:\n        continue\n        \n    else:\n        pairs.append(i)\nscore = []\nfor i in pairs:\n    cond = []\n    for lang in i:\n        cond.append('(\"%s\") in s' %lang)\n    mycode = ('[s for s in record if ' + ' and '.join(cond) + ']')\n    #mycode = \"print 'hello world'\"\n    score.append(len(eval(mycode))/len(apriori_data))\nranking_ECLAT = pd.DataFrame([pairs, score]).transpose()\nranking_ECLAT.columns = ['Pair', 'Score']\n\nranking_ECLAT.sort_values('Score', ascending=False).head(10)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Trying out ECLAT on trios of languages"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating trios\ntrio = []\nfor j in range(0, len(uniquelangs)):\n    for k in range(j, len(uniquelangs)):\n        for l in range(k, len(uniquelangs)):\n            if (k != j) and (j != l) and (k != l):\n                try:\n                    trio.append([uniquelangs[j], uniquelangs[j+k], uniquelangs[j+l]])\n                except IndexError:\n                    pass \n\ntrios=[]\nfor i in trio:\n    if 'nan' in i:\n        continue\n    else:\n        trios.append(i)\n\nscore_trios = []\nfor i in trios:\n    cond = []\n    for lang in i:\n        cond.append('(\"%s\") in s' %lang)\n    mycode = ('[s for s in record if ' + ' and '.join(cond) + ']')\n    #mycode = \"print 'hello world'\"\n    score_trios.append(len(eval(mycode))/len(apriori_data))\nranking_ECLAT_trios = pd.DataFrame([trios, score_trios]).transpose()\nranking_ECLAT_trios.columns = ['Trio', 'Score']\n\nranking_ECLAT_trios.sort_values('Score', ascending=False).head(10)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's Try to make a Salary prediction System :)"},{"metadata":{},"cell_type":"markdown","source":"## Step 1 .. Let's Select Some Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(columns=data.columns[7:20],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step 2 converting categorical to numerical"},{"metadata":{"trusted":true},"cell_type":"code","source":"df3=copy.deepcopy(data)\ndf3=factorize(df3.columns[1:],df3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df3.drop(columns=['What is your current yearly compensation (approximate $USD)?']).values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=df3['What is your current yearly compensation (approximate $USD)?'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dc=RandomForestClassifier()\ndc.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('The accuracy score is :',accuracy_score(dc.predict(X_test),y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}