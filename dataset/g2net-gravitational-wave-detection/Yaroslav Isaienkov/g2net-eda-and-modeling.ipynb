{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# G2Net Gravitational Wave Detection - Exploratory Data Analysis\n\nQuick Exploratory Data Analysis for [G2Net Gravitational Wave Detection](https://www.kaggle.com/c/g2net-gravitational-wave-detection) challenge    ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"![](https://storage.googleapis.com/kaggle-competitions/kaggle/23249/logos/header.png)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"top\"></a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='color:white; background:#1777C4; border:0' role=\"tab\" aria-controls=\"home\"><center>Quick Navigation</center></h3>\n\n* [Overview](#1)\n* [Data Visualization](#2)\n* [Signal Transformations - Spectogram](#3)\n* [Signal Transformations - MFCC](#4)\n* [Signal Transformations - Q-transform](#5)\n    \n\n* [Competition Metric](#10)\n* [Sample Submission](#20)\n    \n\n* [Modeling](#100)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n<h2 style='background:#1777C4; border:0; color:white'><center>Overview<center><h2>","metadata":{}},{"cell_type":"markdown","source":"The work uses some ideas from next great works:\n- [PyCBC: Making Images](https://www.kaggle.com/alexnitz/pycbc-making-images)\n- [nnAudio Constant Q-transform Demonstration](https://www.kaggle.com/atamazian/nnaudio-constant-q-transform-demonstration)\n- [G2Net melspectrogram starter code [LB: 0.830]](https://www.kaggle.com/c/g2net-gravitational-wave-detection/discussion/250278)","metadata":{}},{"cell_type":"markdown","source":"In this competition you are provided with a training set of time series data containing simulated gravitational wave measurements from a network of 3 gravitational wave interferometers (LIGO Hanford, LIGO Livingston, and Virgo). Each time series contains either detector noise or detector noise plus a simulated gravitational wave signal. The task is to identify when a signal is present in the data (target=1).","metadata":{}},{"cell_type":"markdown","source":"### Files\n**train/** - the training set files, one npy file per observation; labels are provided in a files shown below   \n**test/** - the test set files; you must predict the probability that the observation contains a gravitational wave   \n**training_labels.csv** - target values of whether the associated signal contains a gravitational wave   \n**sample_submission.csv** - a sample submission file in the correct format","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport random\nimport collections\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-07-09T07:53:07.860506Z","iopub.execute_input":"2021-07-09T07:53:07.861355Z","iopub.status.idle":"2021-07-09T07:53:08.323527Z","shell.execute_reply.started":"2021-07-09T07:53:07.861262Z","shell.execute_reply":"2021-07-09T07:53:08.322052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n<h2 style='background:#1777C4; border:0; color:white'><center>Data Visualization<center><h2>","metadata":{}},{"cell_type":"code","source":"def convert_image_id_2_path(image_id: str, is_train: bool = True) -> str:\n    folder = \"train\" if is_train else \"test\"\n    return \"../input/g2net-gravitational-wave-detection/{}/{}/{}/{}/{}.npy\".format(\n        folder, image_id[0], image_id[1], image_id[2], image_id \n    )","metadata":{"execution":{"iopub.status.busy":"2021-07-09T07:53:08.33898Z","iopub.execute_input":"2021-07-09T07:53:08.339409Z","iopub.status.idle":"2021-07-09T07:53:08.351536Z","shell.execute_reply.started":"2021-07-09T07:53:08.339365Z","shell.execute_reply":"2021-07-09T07:53:08.349034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/g2net-gravitational-wave-detection/training_labels.csv\")\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2021-07-09T07:53:08.354601Z","iopub.execute_input":"2021-07-09T07:53:08.358369Z","iopub.status.idle":"2021-07-09T07:53:08.712653Z","shell.execute_reply.started":"2021-07-09T07:53:08.358325Z","shell.execute_reply":"2021-07-09T07:53:08.711679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(data=train_df, x=\"target\")","metadata":{"execution":{"iopub.status.busy":"2021-07-09T07:53:08.713856Z","iopub.execute_input":"2021-07-09T07:53:08.714191Z","iopub.status.idle":"2021-07-09T07:53:08.863468Z","shell.execute_reply.started":"2021-07-09T07:53:08.714162Z","shell.execute_reply":"2021-07-09T07:53:08.8627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Each data sample (npy file) contains 3 time series (1 for each detector) and each spans 2 sec and is sampled at 2,048 Hz.","metadata":{}},{"cell_type":"code","source":"def visualize_sample(\n    _id, \n    target, \n    colors=(\"black\", \"red\", \"green\"), \n    signal_names=(\"LIGO Hanford\", \"LIGO Livingston\", \"Virgo\")\n):\n    path = convert_image_id_2_path(_id)\n    x = np.load(path)\n    plt.figure(figsize=(16, 7))\n    for i in range(3):\n        plt.subplot(4, 1, i + 1)\n        plt.plot(x[i], color=colors[i])\n        plt.legend([signal_names[i]], fontsize=12, loc=\"lower right\")\n        \n        plt.subplot(4, 1, 4)\n        plt.plot(x[i], color=colors[i])\n    \n    plt.subplot(4, 1, 4)\n    plt.legend(signal_names, fontsize=12, loc=\"lower right\")\n\n    plt.suptitle(f\"id: {_id} target: {target}\", fontsize=16)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T07:53:08.865616Z","iopub.execute_input":"2021-07-09T07:53:08.866218Z","iopub.status.idle":"2021-07-09T07:53:08.874491Z","shell.execute_reply.started":"2021-07-09T07:53:08.866171Z","shell.execute_reply":"2021-07-09T07:53:08.873614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in random.sample(train_df.index.tolist(), 3):\n    _id = train_df.iloc[i][\"id\"]\n    target = train_df.iloc[i][\"target\"]\n\n    visualize_sample(_id, target)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T07:53:08.875582Z","iopub.execute_input":"2021-07-09T07:53:08.876107Z","iopub.status.idle":"2021-07-09T07:53:10.276682Z","shell.execute_reply.started":"2021-07-09T07:53:08.876069Z","shell.execute_reply":"2021-07-09T07:53:10.275765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"3\"></a>\n<h2 style='background:#1777C4; border:0; color:white'><center>Signal Transformations - Spectogram<center><h2>","metadata":{"execution":{"iopub.status.busy":"2021-07-01T07:40:45.589199Z","iopub.execute_input":"2021-07-01T07:40:45.589856Z","iopub.status.idle":"2021-07-01T07:40:45.601296Z","shell.execute_reply.started":"2021-07-01T07:40:45.589711Z","shell.execute_reply":"2021-07-01T07:40:45.599811Z"}}},{"cell_type":"code","source":"import librosa\nimport librosa.display","metadata":{"execution":{"iopub.status.busy":"2021-07-09T07:53:10.277893Z","iopub.execute_input":"2021-07-09T07:53:10.27837Z","iopub.status.idle":"2021-07-09T07:53:10.768482Z","shell.execute_reply.started":"2021-07-09T07:53:10.278331Z","shell.execute_reply":"2021-07-09T07:53:10.767567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_sample_spectogram(\n    _id, \n    target,\n    signal_names=(\"LIGO Hanford\", \"LIGO Livingston\", \"Virgo\")\n):\n    x = np.load(convert_image_id_2_path(_id))\n    plt.figure(figsize=(16, 5))\n    for i in range(3):\n        X = librosa.stft(x[i] / x[i].max())\n        Xdb = librosa.amplitude_to_db(abs(X))\n        plt.subplot(1, 3, i + 1)\n        librosa.display.specshow(Xdb, sr=2048, x_axis=\"time\", y_axis=\"hz\", vmin=-30, vmax=50) \n        plt.colorbar()\n        plt.title(signal_names[i], fontsize=14)\n\n    plt.suptitle(f\"id: {_id} target: {target}\", fontsize=16)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T07:53:10.771779Z","iopub.execute_input":"2021-07-09T07:53:10.772163Z","iopub.status.idle":"2021-07-09T07:53:10.780024Z","shell.execute_reply.started":"2021-07-09T07:53:10.772123Z","shell.execute_reply":"2021-07-09T07:53:10.778394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in random.sample(train_df.index.tolist(), 3):\n    _id = train_df.iloc[i][\"id\"]\n    target = train_df.iloc[i][\"target\"]\n\n    visualize_sample_spectogram(_id, target)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T07:53:10.782429Z","iopub.execute_input":"2021-07-09T07:53:10.782814Z","iopub.status.idle":"2021-07-09T07:53:12.356358Z","shell.execute_reply.started":"2021-07-09T07:53:10.782754Z","shell.execute_reply":"2021-07-09T07:53:12.355532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"4\"></a>\n<h2 style='background:#1777C4; border:0; color:white'><center>Signal Transformations - MFCC<center><h2>","metadata":{}},{"cell_type":"code","source":"def visualize_sample_mfcc(\n    _id, \n    target,\n    signal_names=(\"LIGO Hanford\", \"LIGO Livingston\", \"Virgo\"),\n    sr=2048,\n):\n    x = np.load(convert_image_id_2_path(_id))\n    plt.figure(figsize=(16, 5))\n    for i in range(3):\n        mfccs = librosa.feature.mfcc(x[i] / x[i].max(), sr=sr)\n        plt.subplot(1, 3, i + 1)\n        librosa.display.specshow(mfccs, sr=sr, x_axis=\"time\", vmin=-200, vmax=50, cmap=\"coolwarm\")\n        plt.title(signal_names[i], fontsize=14)\n        plt.colorbar()\n\n    plt.suptitle(f\"id: {_id} target: {target}\", fontsize=16)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T07:53:12.357705Z","iopub.execute_input":"2021-07-09T07:53:12.358072Z","iopub.status.idle":"2021-07-09T07:53:12.365376Z","shell.execute_reply.started":"2021-07-09T07:53:12.358034Z","shell.execute_reply":"2021-07-09T07:53:12.364431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in random.sample(train_df.index.tolist(), 3):\n    _id = train_df.iloc[i][\"id\"]\n    target = train_df.iloc[i][\"target\"]\n\n    visualize_sample_mfcc(_id, target)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T07:53:12.36683Z","iopub.execute_input":"2021-07-09T07:53:12.367188Z","iopub.status.idle":"2021-07-09T07:53:14.075093Z","shell.execute_reply.started":"2021-07-09T07:53:12.36715Z","shell.execute_reply":"2021-07-09T07:53:14.074228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"5\"></a>\n<h2 style='background:#1777C4; border:0; color:white'><center>Signal Transformations - Q-transform<center><h2>","metadata":{"execution":{"iopub.status.busy":"2021-07-02T08:46:00.181912Z","iopub.execute_input":"2021-07-02T08:46:00.182312Z","iopub.status.idle":"2021-07-02T08:46:00.188979Z","shell.execute_reply.started":"2021-07-02T08:46:00.182274Z","shell.execute_reply":"2021-07-02T08:46:00.187378Z"}}},{"cell_type":"code","source":"# !pip install pycbc -qq\n# import pycbc.types","metadata":{"execution":{"iopub.status.busy":"2021-07-09T07:53:14.076363Z","iopub.execute_input":"2021-07-09T07:53:14.076754Z","iopub.status.idle":"2021-07-09T07:53:14.082519Z","shell.execute_reply.started":"2021-07-09T07:53:14.076716Z","shell.execute_reply":"2021-07-09T07:53:14.081546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q nnAudio -qq\nimport torch\nfrom nnAudio.Spectrogram import CQT1992v2","metadata":{"execution":{"iopub.status.busy":"2021-07-09T07:53:14.084053Z","iopub.execute_input":"2021-07-09T07:53:14.084437Z","iopub.status.idle":"2021-07-09T07:53:20.717768Z","shell.execute_reply.started":"2021-07-09T07:53:14.0844Z","shell.execute_reply":"2021-07-09T07:53:20.716781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Q_TRANSFORM = CQT1992v2(sr=2048, fmin=20, fmax=1024, hop_length=32)\n\ndef visualize_sample_qtransform(\n    _id, \n    target,\n    signal_names=(\"LIGO Hanford\", \"LIGO Livingston\", \"Virgo\"),\n    sr=2048,\n):\n    x = np.load(convert_image_id_2_path(_id))\n    plt.figure(figsize=(16, 5))\n    for i in range(3):\n        waves = x[i] / np.max(x[i])\n        waves = torch.from_numpy(waves).float()\n        image = Q_TRANSFORM(waves)\n        \n        plt.subplot(1, 3, i + 1)\n        plt.imshow(image.squeeze())\n        plt.title(signal_names[i], fontsize=14)\n\n    plt.suptitle(f\"id: {_id} target: {target}\", fontsize=16)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T07:53:20.719204Z","iopub.execute_input":"2021-07-09T07:53:20.719561Z","iopub.status.idle":"2021-07-09T07:53:20.750948Z","shell.execute_reply.started":"2021-07-09T07:53:20.719519Z","shell.execute_reply":"2021-07-09T07:53:20.750075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in random.sample(train_df.index.tolist(), 5):\n    _id = train_df.iloc[i][\"id\"]\n    target = train_df.iloc[i][\"target\"]\n\n    visualize_sample(_id, target)\n    visualize_sample_qtransform(_id, target)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T07:53:20.752165Z","iopub.execute_input":"2021-07-09T07:53:20.752755Z","iopub.status.idle":"2021-07-09T07:53:25.130236Z","shell.execute_reply.started":"2021-07-09T07:53:20.752711Z","shell.execute_reply":"2021-07-09T07:53:25.129227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"10\"></a>\n<h2 style='background:#1777C4; border:0; color:white'><center>Competition Metric<center><h2>","metadata":{}},{"cell_type":"markdown","source":"\nSubmissions are evaluated on [area under the ROC curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) between the predicted probability and the observed target.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, roc_curve, auc","metadata":{"execution":{"iopub.status.busy":"2021-07-09T07:53:25.13161Z","iopub.execute_input":"2021-07-09T07:53:25.131987Z","iopub.status.idle":"2021-07-09T07:53:25.136845Z","shell.execute_reply.started":"2021-07-09T07:53:25.131947Z","shell.execute_reply":"2021-07-09T07:53:25.135761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_y_true = [\n    [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n    [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n    [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.], #  IMBALANCE\n]\nlist_y_pred = [\n    [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n    [0.9, 0.9, 0.9, 0.9, 0.1, 0.9, 0.9, 0.1, 0.9, 0.1, 0.1, 0.5],\n    [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], #  IMBALANCE\n]\n\nfor y_true, y_pred in zip(list_y_true, list_y_pred):\n    fpr, tpr, _ = roc_curve(y_true, y_pred)\n    roc_auc = auc(fpr, tpr)\n\n    plt.figure(figsize=(5, 5))\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([-0.01, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-09T07:53:25.138369Z","iopub.execute_input":"2021-07-09T07:53:25.13878Z","iopub.status.idle":"2021-07-09T07:53:25.531968Z","shell.execute_reply.started":"2021-07-09T07:53:25.138744Z","shell.execute_reply":"2021-07-09T07:53:25.530969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"20\"></a>\n<h2 style='background:#1777C4; border:0; color:white'><center>Sample Submission<center><h2>","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/g2net-gravitational-wave-detection/sample_submission.csv\")\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T07:53:25.533566Z","iopub.execute_input":"2021-07-09T07:53:25.533963Z","iopub.status.idle":"2021-07-09T07:53:26.350332Z","shell.execute_reply.started":"2021-07-09T07:53:25.533924Z","shell.execute_reply":"2021-07-09T07:53:26.349393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"100\"></a>\n<h2 style='background:#1777C4; border:0; color:white'><center>Modeling<center><h2>","metadata":{}},{"cell_type":"code","source":"!pip install efficientnet_pytorch -qq","metadata":{"execution":{"iopub.status.busy":"2021-07-09T07:53:26.351639Z","iopub.execute_input":"2021-07-09T07:53:26.352046Z","iopub.status.idle":"2021-07-09T07:53:32.101294Z","shell.execute_reply.started":"2021-07-09T07:53:26.352006Z","shell.execute_reply":"2021-07-09T07:53:32.099997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\n\nimport torch\nfrom torch import nn\nfrom torch.utils import data as torch_data\nfrom sklearn import model_selection as sk_model_selection\nfrom torch.nn import functional as torch_functional\nfrom torch.autograd import Variable\nimport efficientnet_pytorch\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2021-07-09T07:53:32.104977Z","iopub.execute_input":"2021-07-09T07:53:32.105265Z","iopub.status.idle":"2021-07-09T07:53:32.114805Z","shell.execute_reply.started":"2021-07-09T07:53:32.105235Z","shell.execute_reply":"2021-07-09T07:53:32.113977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n\n\nset_seed(42)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T07:53:32.118176Z","iopub.execute_input":"2021-07-09T07:53:32.118415Z","iopub.status.idle":"2021-07-09T07:53:32.149761Z","shell.execute_reply.started":"2021-07-09T07:53:32.118391Z","shell.execute_reply":"2021-07-09T07:53:32.148974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataRetriever(torch_data.Dataset):\n    def __init__(self, paths, targets):\n        self.paths = paths\n        self.targets = targets\n        \n        self.q_transform = CQT1992v2(\n            sr=2048, fmin=20, fmax=1024, hop_length=32\n        )\n          \n    def __len__(self):\n        return len(self.paths)\n    \n    def __get_qtransform(self, x):\n        image = []\n        for i in range(3):\n            waves = x[i] / np.max(x[i])\n            waves = torch.from_numpy(waves).float()\n            channel = self.q_transform(waves).squeeze().numpy()\n            image.append(channel)\n            \n        return torch.tensor(image).float()\n    \n    def __getitem__(self, index):\n        file_path = convert_image_id_2_path(self.paths[index])\n        x = np.load(file_path)\n        image = self.__get_qtransform(x)\n        \n        y = torch.tensor(self.targets[index], dtype=torch.float)\n            \n        return {\"X\": image, \"y\": y}","metadata":{"execution":{"iopub.status.busy":"2021-07-09T07:53:32.150946Z","iopub.execute_input":"2021-07-09T07:53:32.151313Z","iopub.status.idle":"2021-07-09T07:53:32.159686Z","shell.execute_reply.started":"2021-07-09T07:53:32.151277Z","shell.execute_reply":"2021-07-09T07:53:32.158832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = efficientnet_pytorch.EfficientNet.from_pretrained(\"efficientnet-b7\")\n        n_features = self.net._fc.in_features\n        self.net._fc = nn.Linear(in_features=n_features, out_features=1, bias=True)\n    \n    def forward(self, x):\n        out = self.net(x)\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-07-09T07:53:32.161045Z","iopub.execute_input":"2021-07-09T07:53:32.161585Z","iopub.status.idle":"2021-07-09T07:53:32.168808Z","shell.execute_reply.started":"2021-07-09T07:53:32.161548Z","shell.execute_reply":"2021-07-09T07:53:32.167734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LossMeter:\n    def __init__(self):\n        self.avg = 0\n        self.n = 0\n\n    def update(self, val):\n        self.n += 1\n        # incremental update\n        self.avg = val / self.n + (self.n - 1) / self.n * self.avg\n\n        \nclass AccMeter:\n    def __init__(self):\n        self.avg = 0\n        self.n = 0\n        \n    def update(self, y_true, y_pred):\n        y_true = y_true.cpu().numpy().astype(int)\n        y_pred = y_pred.cpu().numpy() >= 0\n        last_n = self.n\n        self.n += len(y_true)\n        true_count = np.sum(y_true == y_pred)\n        # incremental update\n        self.avg = true_count / self.n + last_n / self.n * self.avg","metadata":{"execution":{"iopub.status.busy":"2021-07-09T07:53:32.170046Z","iopub.execute_input":"2021-07-09T07:53:32.170649Z","iopub.status.idle":"2021-07-09T07:53:32.18102Z","shell.execute_reply.started":"2021-07-09T07:53:32.170619Z","shell.execute_reply":"2021-07-09T07:53:32.18006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Trainer:\n    def __init__(\n        self, \n        model, \n        device, \n        optimizer, \n        criterion, \n        loss_meter, \n        score_meter\n    ):\n        self.model = model\n        self.device = device\n        self.optimizer = optimizer\n        self.criterion = criterion\n        self.loss_meter = loss_meter\n        self.score_meter = score_meter\n        \n        self.best_valid_score = -np.inf\n        self.n_patience = 0\n        \n        self.messages = {\n            \"epoch\": \"[Epoch {}: {}] loss: {:.5f}, score: {:.5f}, time: {} s\",\n            \"checkpoint\": \"The score improved from {:.5f} to {:.5f}. Save model to '{}'\",\n            \"patience\": \"\\nValid score didn't improve last {} epochs.\"\n        }\n    \n    def fit(self, epochs, train_loader, valid_loader, save_path, patience):        \n        for n_epoch in range(1, epochs + 1):\n            self.info_message(\"EPOCH: {}\", n_epoch)\n            \n            train_loss, train_score, train_time = self.train_epoch(train_loader)\n            valid_loss, valid_score, valid_time = self.valid_epoch(valid_loader)\n            \n            self.info_message(\n                self.messages[\"epoch\"], \"Train\", n_epoch, train_loss, train_score, train_time\n            )\n            \n            self.info_message(\n                self.messages[\"epoch\"], \"Valid\", n_epoch, valid_loss, valid_score, valid_time\n            )\n\n            if True:\n#             if self.best_valid_score < valid_score:\n                self.info_message(\n                    self.messages[\"checkpoint\"], self.best_valid_score, valid_score, save_path\n                )\n                self.best_valid_score = valid_score\n                self.save_model(n_epoch, save_path)\n                self.n_patience = 0\n            else:\n                self.n_patience += 1\n            \n            if self.n_patience >= patience:\n                self.info_message(self.messages[\"patience\"], patience)\n                break\n            \n    def train_epoch(self, train_loader):\n        self.model.train()\n        t = time.time()\n        train_loss = self.loss_meter()\n        train_score = self.score_meter()\n        \n        for step, batch in enumerate(train_loader, 1):\n            X = batch[\"X\"].to(self.device)\n            targets = batch[\"y\"].to(self.device)\n            self.optimizer.zero_grad()\n            outputs = self.model(X).squeeze(1)\n            \n            loss = self.criterion(outputs, targets)\n            loss.backward()\n\n            train_loss.update(loss.detach().item())\n            train_score.update(targets, outputs.detach())\n\n            self.optimizer.step()\n            \n            _loss, _score = train_loss.avg, train_score.avg\n            message = 'Train Step {}/{}, train_loss: {:.5f}, train_score: {:.5f}'\n            self.info_message(message, step, len(train_loader), _loss, _score, end=\"\\r\")\n        \n        return train_loss.avg, train_score.avg, int(time.time() - t)\n    \n    def valid_epoch(self, valid_loader):\n        self.model.eval()\n        t = time.time()\n        valid_loss = self.loss_meter()\n        valid_score = self.score_meter()\n\n        for step, batch in enumerate(valid_loader, 1):\n            with torch.no_grad():\n                X = batch[\"X\"].to(self.device)\n                targets = batch[\"y\"].to(self.device)\n\n                outputs = self.model(X).squeeze(1)\n                loss = self.criterion(outputs, targets)\n\n                valid_loss.update(loss.detach().item())\n                valid_score.update(targets, outputs)\n                \n            _loss, _score = valid_loss.avg, valid_score.avg\n            message = 'Valid Step {}/{}, valid_loss: {:.5f}, valid_score: {:.5f}'\n            self.info_message(message, step, len(valid_loader), _loss, _score, end=\"\\r\")\n        \n        return valid_loss.avg, valid_score.avg, int(time.time() - t)\n    \n    def save_model(self, n_epoch, save_path):\n        torch.save(\n            {\n                \"model_state_dict\": self.model.state_dict(),\n                \"optimizer_state_dict\": self.optimizer.state_dict(),\n                \"best_valid_score\": self.best_valid_score,\n                \"n_epoch\": n_epoch,\n            },\n            save_path,\n        )\n    \n    @staticmethod\n    def info_message(message, *args, end=\"\\n\"):\n        print(message.format(*args), end=end)","metadata":{"execution":{"iopub.status.busy":"2021-07-09T07:53:32.182689Z","iopub.execute_input":"2021-07-09T07:53:32.183182Z","iopub.status.idle":"2021-07-09T07:53:32.20775Z","shell.execute_reply.started":"2021-07-09T07:53:32.183145Z","shell.execute_reply":"2021-07-09T07:53:32.206891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\nskf = StratifiedKFold(n_splits=2, random_state=42, shuffle=True)\nfor fold, (train_index, valid_index) in enumerate(skf.split(train_df, train_df[\"target\"])):\n    train_X = train_df.iloc[train_index]\n    valid_X = train_df.iloc[valid_index][:20000] # Reduce calculation time\n    print(train_X.shape, valid_X.shape)\n\n    train_data_retriever = DataRetriever(\n        train_X[\"id\"].values, \n        train_X[\"target\"].values, \n    )\n\n    valid_data_retriever = DataRetriever(\n        valid_X[\"id\"].values, \n        valid_X[\"target\"].values,\n    )\n\n    train_loader = torch_data.DataLoader(\n        train_data_retriever,\n        batch_size=32,\n        shuffle=True,\n        num_workers=8,\n    )\n\n    valid_loader = torch_data.DataLoader(\n        valid_data_retriever, \n        batch_size=32,\n        shuffle=False,\n        num_workers=8,\n    )\n\n    model = Model()\n    model.to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    criterion = torch_functional.binary_cross_entropy_with_logits\n\n    trainer = Trainer(\n        model, \n        device, \n        optimizer, \n        criterion, \n        LossMeter, \n        AccMeter\n    )\n\n    history = trainer.fit(\n        1, \n        train_loader, \n        valid_loader, \n        f\"best-model-{fold}.pth\", \n        100,\n    )","metadata":{"execution":{"iopub.status.busy":"2021-07-09T07:53:32.212601Z","iopub.execute_input":"2021-07-09T07:53:32.212969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = []\nfor i in range(2):\n    model = Model()\n    model.to(device)\n    \n    checkpoint = torch.load(f\"best-model-{i}.pth\")\n    model.load_state_dict(checkpoint[\"model_state_dict\"])\n    model.eval()\n    \n    models.append(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataRetriever(torch_data.Dataset):\n    def __init__(self, paths):\n        self.paths = paths\n\n        self.q_transform = CQT1992v2(\n            sr=2048, fmin=20, fmax=1024, hop_length=32\n        )\n          \n    def __len__(self):\n        return len(self.paths)\n    \n    def __get_qtransform(self, x):\n        image = []\n        for i in range(3):\n            waves = x[i] / np.max(x[i])\n            waves = torch.from_numpy(waves).float()\n            channel = self.q_transform(waves).squeeze().numpy()\n            image.append(channel)\n            \n        return torch.tensor(image).float()\n    \n    def __getitem__(self, index):\n        file_path = convert_image_id_2_path(self.paths[index], is_train=False)\n        x = np.load(file_path)\n        image = self.__get_qtransform(x)\n            \n        return {\"X\": image, \"id\": self.paths[index]}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data_retriever = DataRetriever(\n    submission[\"id\"].values, \n)\n\ntest_loader = torch_data.DataLoader(\n    test_data_retriever,\n    batch_size=32,\n    shuffle=False,\n    num_workers=8,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = []\nids = []\n\nfor e, batch in enumerate(test_loader):\n    print(f\"{e}/{len(test_loader)}\", end=\"\\r\")\n    with torch.no_grad():\n        tmp_pred = np.zeros((batch[\"X\"].shape[0], ))\n        for model in models:\n            tmp_res = torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n            tmp_pred += tmp_res / 2\n        y_pred.extend(tmp_pred)\n        ids.extend(batch[\"id\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\"id\": ids, \"target\": y_pred})\nsubmission.to_csv(\"model_submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### WORK IN PROGRESS ...","metadata":{}}]}