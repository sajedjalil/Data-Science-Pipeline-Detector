{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1>**SAR COV 2 Forecast**</h1>\nbinhlc@gmail.com\n\nPredict by each country, region. Apply Auto ARIMA, Machine Learning and Deep Learning\nData up to T-1 and update forecast to train each of day.\nAfter try many algorithm, ARIMA is best choise to forcast.\n\nARIMA SAVE VERSION.\n\nJUST ONLY FOR TUTORIAL..."},{"metadata":{},"cell_type":"markdown","source":"Setup enviroment"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"../input/covid19-global-forecasting-week-1/test.csv\")\ntrain = pd.read_csv(\"../input/covid19-global-forecasting-week-1/train.csv\")\ntrain['Province/State'].fillna('', inplace=True)\ntest['Province/State'].fillna('', inplace=True)\ntrain['Date'] =  pd.to_datetime(train['Date'])\ntest['Date'] =  pd.to_datetime(test['Date'])\ntrain = train.sort_values(['Country/Region','Province/State','Date'])\ntest = test.sort_values(['Country/Region','Province/State','Date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# top country\ntrain.groupby(['Country/Region']).max().sort_values(['ConfirmedCases'],ascending = False).head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pmdarima","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.metrics import mean_squared_error\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()\n\ncountry_plot = 'Vietnam'\n\ndef RMSLE(pred,actual):\n    return np.sqrt(np.mean(np.power((np.log(pred+1)-np.log(actual+1)),2)))\n\ndef RMSLE_Cal(pred_data):\n    df = pd.DataFrame(pred_data)\n    df.columns = ['Date','Country/Region','Province/State','ForecastId','ConfirmedCases','Fatalities']\n    df_val = pd.merge(df,train[['Date','Country/Region','Province/State','ConfirmedCases','Fatalities']],on=['Date','Country/Region','Province/State'], how='left')\n    df_val = df_val.sort_values('Date')\n    val_size = df_val[df_val['ConfirmedCases_y'].notnull() == True].shape[0]\n    return RMSLE(df_val['ConfirmedCases_y'][0:val_size-1].values, df_val['ConfirmedCases_x'][0:val_size-1].values)\n    \ndef plotPrediction(pred_data):\n    df = pd.DataFrame(pred_data)\n    df.columns = ['Date','Country/Region','Province/State','ForecastId','ConfirmedCases','Fatalities']\n    # Fix code: plot and caclulate only for Viet Nam\n    df = df[df['Country/Region'] == country_plot]\n    df_val = pd.merge(df,train[['Date','Country/Region','Province/State','ConfirmedCases','Fatalities']],on=['Date','Country/Region','Province/State'], how='left')\n    df_val = df_val.sort_values('Date')\n    fig, axes = plt.subplots(nrows=1,ncols=2,figsize=(20, 7))\n    axes[0].plot(df_val['Date'], df_val['ConfirmedCases_y'], label = 'Confirmed Cases')\n    axes[0].plot(df_val['Date'], df_val['ConfirmedCases_x'], label = 'Confirmed Cases Forecast')\n    axes[1].plot(df_val['Date'], df_val['Fatalities_y'], label = 'Fatalities')\n    axes[1].plot(df_val['Date'], df_val['Fatalities_x'], label = 'Fatalities Forecast')\n    axes[0].legend()\n    axes[1].legend()\n    fig.autofmt_xdate()\n    \n    #return mean_squared_error(df_val['ConfirmedCases_y'][0:val_size-1], df_val['ConfirmedCases_x'][0:val_size-1])\n    return RMSLE(df_val['ConfirmedCases_y'][0:val_size-1].values, df_val['ConfirmedCases_x'][0:val_size-1].values)\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Auto ARIMA"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pmdarima as pm\n#import statsmodels.tsa.arima_model as ARIMA\n\npred_data = []\nfor country in train['Country/Region'].unique():\n#for country in [country_plot]:\n    for province in train[(train['Country/Region'] == country)]['Province/State'].unique():\n        for forcast in test[(test['Country/Region'] == country) & (test['Province/State'] == province)]['ForecastId'].unique():\n        #for forcast in [test[(test['Country/Region'] == country) & (test['Province/State'] == province)].max()['ForecastId']]:\n            testdate = test[(test['Country/Region'] == country) & (test['Province/State'] == province) & (test['ForecastId'] == forcast)]['Date'].max()\n            X_train = train[(train['Country/Region'] == country) & (train['Province/State'] == province) & (train['ConfirmedCases'] > 0) & (train['Date']<testdate)]['ConfirmedCases'].values\n            if (len(X_train) < 1):\n                ConfirmedCases_hat = 0\n            elif (len(X_train) < 5):\n                ConfirmedCases_hat = X_train[-1]\n            elif((X_train[-1] == X_train[-2]) & (X_train[-2] == X_train[-3])):\n                ConfirmedCases_hat = X_train[-1]\n            else:\n                #if (len(X_train) < 30):\n                #    model = ARIMA.ARMA(X_train, order=(1,0,0))\n                #else:\n                #    model = ARIMA.ARMA(X_train, order=(3,0,3))\n                \n                if (testdate <= train[(train['Country/Region'] == country) & (train['Province/State'] == province)]['Date'].max()):\n                    # Only train one time when have not train data to update\n                    model_c = pm.auto_arima(X_train, suppress_warnings=True, seasonal=False, error_action=\"ignore\")\n                    #model = pm.auto_arima(X_train, suppress_warnings=True, seasonal=False, error_action=\"ignore\")\n                    #ConfirmedCases_hat = model.fit(disp=0).predict(start = len(X_train), end = len(X_train)+1)[0]\n                    ConfirmedCases_hat = model_c.predict(n_periods=1)[-1]\n                else:\n                    n_period = testdate - train[(train['Country/Region'] == country) & (train['Province/State'] == province)]['Date'].max()\n                    #ConfirmedCases_hat = model.fit(disp=0).predict(start = 0, end = len(X_train) + n_period.days)[-1]\n                    ConfirmedCases_hat = model_c.predict(n_periods=n_period.days + 1)[-1]\n                # For big change in a day  -- Andorra case  \n                if (ConfirmedCases_hat < X_train[-1]):\n                    ConfirmedCases_hat = X_train[-1]\n                    \n            # Don't overlap train and test data                    \n            X_train = train[(train['Country/Region'] == country) & (train['Province/State'] == province) & (train['Fatalities'] > 0) & (train['Date']<testdate)]['Fatalities'].values\n            if (len(X_train) < 1):\n                Fatalities_hat = 0\n            elif (len(X_train) < 5):\n                Fatalities_hat = X_train[-1]\n            elif((X_train[-1] == X_train[-2]) & (X_train[-2] == X_train[-3])):\n                Fatalities_hat = X_train[-1]\n            else:            \n                #if (len(X_train) < 30):\n                #    model = ARIMA.ARMA(X_train, order=(1,0,0))\n                #else:\n                #    model = ARIMA.ARMA(X_train, order=(3,0,3))\n                \n                if (testdate < train[(train['Country/Region'] == country) & (train['Province/State'] == province)]['Date'].max()):\n                    model_f = pm.auto_arima(X_train, suppress_warnings=True, seasonal=False, error_action=\"ignore\")\n                    #Fatalities_hat = model.fit(disp=0).predict(start = 0, end = len(X_train)+1)[-1]\n                    Fatalities_hat = model_f.predict(n_periods=1)[-1]\n                else:\n                    n_period = testdate - train[(train['Country/Region'] == country) & (train['Province/State'] == province)]['Date'].max()\n                    #Fatalities_hat = model.fit(disp=0).predict(start = 0, end = len(X_train) + n_period.days)[-1]\n                    Fatalities_hat = model_f.predict(n_periods=n_period.days + 1)[-1]\n                # For big change in a day  -- Andorra case  \n                if (Fatalities_hat < X_train[-1]):\n                    Fatalities_hat = X_train[-1]                    \n            pred_data.append([testdate,country,province,forcast,ConfirmedCases_hat,Fatalities_hat])\n    rmsle = RMSLE_Cal(pred_data)\n    print(country + ' ' + str(rmsle))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot and RMSLE only for Vietnam\nplotPrediction(pred_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_past = pd.merge(test,train,on = ['Province/State','Date','Country/Region','Lat','Long'], how = 'inner').drop(['Id','Lat','Long'],axis=1)\ndf_future = pd.DataFrame(pred_data)\ndf_future.columns = ['Date','Country/Region','Province/State','ForecastId','ConfirmedCases','Fatalities']\ndf_future = df_future[(df_future['Date'] > df_past['Date'].max())]\n\nsubmission = df_past.append(df_future, sort = True)\nsubmission[['ForecastId','ConfirmedCases','Fatalities']].to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=train[train['Country/Region'] == country_plot]\npd.set_option('mode.chained_assignment', None)\ndf['Cases'] = df['ConfirmedCases'] - df['ConfirmedCases'].shift(1)\nfig, axes = plt.subplots(nrows=1,ncols=2,figsize=(20, 7))\naxes[0].plot(df['Date'], df['ConfirmedCases'], label = 'Total cases ' + df['Date'].max().strftime('%Y-%m-%d'))\naxes[0].legend()\naxes[1].bar(df['Date'], df['Cases'], label = 'New cases ' + df['Date'].max().strftime('%Y-%m-%d'))\naxes[1].legend()\nfig.autofmt_xdate()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Regresor with Machine Learning</h2>"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#from catboost import CatBoostRegressor\n#import xgboost as xgb\n#from sklearn.linear_model import LinearRegression\n#from sklearn.linear_model import RidgeCV,LassoLars\n#from sklearn.preprocessing import PolynomialFeatures\n\nfrom sklearn.tree import DecisionTreeRegressor\n\n\n#poly_reg = PolynomialFeatures(degree=1)\n\ndf_train = train.copy()\ndf_test = test.copy()\ntrain_period = 10\nfeature_Confirmed = ['ConfirmedCases'] + ['ConfirmedCases_B' + str(i) for i in range(1,train_period)]\nfeature_Fatalities = ['Fatalities'] + ['Fatalities_B' + str(i) for i in range(1,train_period)]\n\npred_data = []\n\n#model = CatBoostRegressor(loss_function = 'RMSE')\n#model = LinearRegression()\n#model = RidgeCV()\n#model = LassoLars()\nmodel = DecisionTreeRegressor(max_depth=5)\n#for country in df_train['Country/Region'].unique():\nfor country in [country_plot,'Vietnam']:\n    for province in df_train[(df_train['Country/Region'] == country)]['Province/State'].unique():\n        max_train_date = df_train[(df_train['Country/Region'] == country) & (df_train['Province/State'] == province)]['Date'].max()\n        for forcast in df_test[(df_test['Country/Region'] == country) & (df_test['Province/State'] == province)]['ForecastId'].unique():\n        #for forcast in [test[(test['Country/Region'] == country) & (test['Province/State'] == province)].max()['ForecastId']]:\n            testdate = df_test[(df_test['Country/Region'] == country) & (df_test['Province/State'] == province) & (df_test['ForecastId'] == forcast)]['Date'].max()           \n            data = df_train[(df_train['Country/Region'] == country) & (df_train['Province/State'] == province) & (df_train['ConfirmedCases'] > 0) & (df_train['Date']<testdate)][['Date','ConfirmedCases','Fatalities']]\n            for i in range(1,train_period):\n                data['ConfirmedCases_B' + str(i)] = data['ConfirmedCases'].shift(i)\n                data['Fatalities_B' + str(i)] = data['Fatalities'].shift(i)   \n\n            # Remove not change day \n            data = data[(data.ConfirmedCases_B1 != data.ConfirmedCases) & (data.ConfirmedCases_B2 != data.ConfirmedCases)]\n\n            X_train_confirmed = data[feature_Confirmed][train_period-1:-1]\n            #X_train_confirmed = poly_reg.fit_transform(X_train_confirmed)\n            y_train_confirmed = data['ConfirmedCases'][train_period-1:-1]\n            feature_Confirmed = ['ConfirmedCases'] + ['ConfirmedCases_B' + str(i) for i in range(1,train_period)]            \n\n            if (len(X_train_confirmed) < 2):\n                ConfirmedCases_hat = 0\n            elif (len(X_train_confirmed) < train_period):\n                ConfirmedCases_hat = X_train_confirmed['ConfirmedCases'].values[-1:][0]\n            else:               \n                # Only train one time when have not train data to update                \n                model.fit(X_train_confirmed,y_train_confirmed)\n                X_pred_confirmed = data[feature_Confirmed][-1:]\n                #X_pred_confirmed = poly_reg.fit_transform(X_pred_confirmed)\n                ConfirmedCases_hat = model.predict(X_pred_confirmed)[-1]\n            \n            data = data[(data.Fatalities_B1 != data.Fatalities) & (data.Fatalities_B2 != data.Fatalities)]\n            X_train_fatalities = data[feature_Fatalities][train_period-1:-1]\n            y_train_fatalities = data['Fatalities'][train_period-1:-1]\n            feature_Fatalities = ['Fatalities'] + ['Fatalities_B' + str(i) for i in range(1,train_period)]\n            if (len(X_train_fatalities) < 1):\n                Fatalities_hat = 0\n            elif (len(X_train_fatalities) < train_period):\n                Fatalities_hat = X_train_fatalities['Fatalities'].values[-1:][0]\n            else:               \n                # Only train one time when have not train data to update                \n                model.fit(X_train_fatalities,y_train_fatalities)\n                X_pred_fatalities = data[feature_Fatalities][-1:]\n                Fatalities_hat = model.predict(X_pred_fatalities)[-1]\n                \n            pred_data.append([testdate,country,province,forcast,ConfirmedCases_hat,Fatalities_hat])    \n            if (testdate > max_train_date):\n                # Update Train data\n                lat = df_test[(df_test['Country/Region'] == country) & (df_test['Province/State'] == province) & (df_test['ForecastId'] == forcast)]['Lat'].max()\n                long = df_test[(df_test['Country/Region'] == country) & (df_test['Province/State'] == province) & (df_test['ForecastId'] == forcast)]['Long'].max()\n                df_train.loc[len(df_train)] = [int(forcast),province,country,lat,long,testdate,float(ConfirmedCases_hat),float(Fatalities_hat)]\n                                                ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot and RMSLE only for Vietnam\nplotPrediction(pred_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Forecast base on num of day feature\ndef CreateInput(data):\n    feature = []\n    for day in [1,100,200,500,1000]:\n        #Get information in train data\n        data['Number day from ' + str(day) + ' case'] = 0\n        if (train[(train['Country/Region'] == country) & (train['Province/State'] == province) & (train['ConfirmedCases'] > day)]['Date'].count() > 0):\n            fromday = train[(train['Country/Region'] == country) & (train['Province/State'] == province) & (train['ConfirmedCases'] < day)]['Date'].max()        \n        else:\n            fromday = pd.Timestamp('2020-12-31')        \n        for i in range(0, len(data)):\n            if (data['Date'].iloc[i] > fromday):\n                day_denta = data['Date'].iloc[i] - fromday\n                data['Number day from ' + str(day) + ' case'].iloc[i] = day_denta.days \n        feature = feature + ['Number day from ' + str(day) + ' case']\n    \n    return data[feature]\n   \n    \nfrom catboost import CatBoostRegressor\nfrom sklearn.linear_model import LinearRegression\nimport xgboost as xgb\n#df_train = train\n#df_test = test\n#model = CatBoostRegressor(loss_function = 'RMSE')\n#model = LinearRegression()\nmodel = xgb.XGBRegressor()\npred_data = []\n#for country in train['Country/Region'].unique():\nfor country in ['Vietnam']:\n    for province in train[(train['Country/Region'] == country)]['Province/State'].unique():\n        df_train = train[(train['Country/Region'] == country) & (train['Province/State'] == province)]\n        df_test = test[(test['Country/Region'] == country) & (test['Province/State'] == province)]\n        X_train = CreateInput(df_train)\n        y_train_confirmed = df_train['ConfirmedCases']\n        y_train_fatalities = df_train['Fatalities']\n        X_pred = CreateInput(df_test)\n        # Check not change\n        if (y_train_confirmed[-5:].mean() == y_train_confirmed.iloc[-1]):            \n            y_hat_confirmed = np.repeat(y_train_confirmed.iloc[-1], len(X_pred))\n        else:\n            model.fit(X_train,y_train_confirmed)        \n            y_hat_confirmed = model.predict(X_pred)\n\n        if (y_train_fatalities[-5:].mean() == y_train_fatalities.iloc[-1]):            \n            y_hat_fatalities = np.repeat(y_train_fatalities.iloc[-1], len(X_pred))\n        else:\n            model.fit(X_train,y_train_fatalities)        \n            y_hat_fatalities = model.predict(X_pred)            \n        \n        for i in range(0,len(y_hat_confirmed)):\n            pred_data.append([df_test['Date'].iloc[i],country,province,df_test['ForecastId'].iloc[i],y_hat_confirmed[i],y_hat_fatalities[i]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_plot = 'Vietnam'\nplotPrediction(pred_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h2>Regresor with Deep Learning</h2>"},{"metadata":{},"cell_type":"markdown","source":"### Deep learning by separate country (6 day obs)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\ntrain_period = 6\nfeature_Confirmed = ['ConfirmedCases'] + ['ConfirmedCases_B' + str(i) for i in range(1,train_period)]\nfeature_Fatalities = ['Fatalities'] + ['Fatalities_B' + str(i) for i in range(1,train_period)]\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(256, activation='relu', input_shape=[len(feature_Confirmed)]),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Dense(1)\n  ])\n\noptimizer = \"rmsprop\"\nmodel.compile(loss='mse', optimizer=optimizer, metrics=['mse','mae'])\nEPOCHS = 10\nBATCH_SIZE = 1\n\ndf_train = train.copy()\ndf_test = test.copy()\n\npred_data = []\n#for country in df_train['Country/Region'].unique():\nfor country in [country_plot,'Vietnam']:\n    for province in df_train[(df_train['Country/Region'] == country)]['Province/State'].unique():\n        max_train_date = df_train[(df_train['Country/Region'] == country) & (df_train['Province/State'] == province)]['Date'].max()\n        for forcast in df_test[(df_test['Country/Region'] == country) & (df_test['Province/State'] == province)]['ForecastId'].unique():\n        #for forcast in [test[(test['Country/Region'] == country) & (test['Province/State'] == province)].max()['ForecastId']]:\n            testdate = df_test[(df_test['Country/Region'] == country) & (df_test['Province/State'] == province) & (df_test['ForecastId'] == forcast)]['Date'].max()           \n            data = df_train[(df_train['Country/Region'] == country) & (df_train['Province/State'] == province) & (df_train['ConfirmedCases'] > 0) & (df_train['Date']<testdate)][['Date','ConfirmedCases','Fatalities']]\n            for i in range(1,train_period):\n                data['ConfirmedCases_B' + str(i)] = data['ConfirmedCases'].shift(i)\n                data['Fatalities_B' + str(i)] = data['Fatalities'].shift(i)   \n\n            # Remove not change day \n            data = data[(data.ConfirmedCases_B1 != data.ConfirmedCases) & (data.ConfirmedCases_B2 != data.ConfirmedCases)]\n\n            \n            X_train_confirmed = data[feature_Confirmed][train_period-1:-1]\n            #X_train_confirmed = poly_reg.fit_transform(X_train_confirmed)\n            y_train_confirmed = data['ConfirmedCases'][train_period-1:-1]\n            \n            #model = CatBoostRegressor(loss_function = 'RMSE')\n            \n            #model = RidgeCV()\n            if (len(X_train_confirmed) < 1):\n                ConfirmedCases_hat = 0\n            elif (len(X_train_confirmed) < train_period):\n                ConfirmedCases_hat = X_train_confirmed['ConfirmedCases'].values[-1:][0]\n            else:               \n                # Only train one time when have not train data to update                \n                model.fit(X_train_confirmed, y_train_confirmed ,batch_size=BATCH_SIZE, epochs=EPOCHS, verbose = 0)\n                X_pred_confirmed = data[feature_Confirmed][-1:]\n                #X_pred_confirmed = poly_reg.fit_transform(X_pred_confirmed)\n                ConfirmedCases_hat = model.predict(X_pred_confirmed)[-1][0]\n            \n            data = data[(data.Fatalities_B1 != data.Fatalities) & (data.Fatalities_B2 != data.Fatalities)]\n            \n            X_train_fatalities = data[feature_Fatalities][train_period-1:-1]\n            y_train_fatalities = data['Fatalities'][train_period-1:-1]\n            \n            if (len(X_train_fatalities) < 1):\n                Fatalities_hat = 0\n            elif (len(X_train_fatalities) < train_period):\n                Fatalities_hat = X_train_fatalities['Fatalities'].values[-1:][0]\n            else:               \n                # Only train one time when have not train data to update                \n                #model.fit(X_train_fatalities,y_train_fatalities)\n                model.fit(X_train_fatalities, y_train_fatalities ,batch_size=BATCH_SIZE, epochs=EPOCHS, verbose = 0)\n                X_pred_fatalities = data[feature_Fatalities][-1:]\n                Fatalities_hat = model.predict(X_pred_fatalities)[-1][0]\n                \n            pred_data.append([testdate,country,province,forcast,ConfirmedCases_hat,Fatalities_hat])    \n            if (testdate > max_train_date):\n                # Update Train data\n                lat = df_test[(df_test['Country/Region'] == country) & (df_test['Province/State'] == province) & (df_test['ForecastId'] == forcast)]['Lat'].max()\n                long = df_test[(df_test['Country/Region'] == country) & (df_test['Province/State'] == province) & (df_test['ForecastId'] == forcast)]['Long'].max()\n                df_train.loc[len(df_train)] = [int(forcast),province,country,lat,long,testdate,float(ConfirmedCases_hat),float(Fatalities_hat)]                                                ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot and RMSLE only for Vietnam\nplotPrediction(pred_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Deep learning by separate country (range of confirm case)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Forecast base on num of day feature each country\nfeature_day = [1,20,50,100,200,500,1000]\ndef CreateInput(data):\n    feature = []\n    for day in feature_day:\n        #Get information in train data\n        data['Number day from ' + str(day) + ' case'] = 0\n        if (train[(train['Country/Region'] == country) & (train['Province/State'] == province) & (train['ConfirmedCases'] < day)]['Date'].count() > 0):\n            fromday = train[(train['Country/Region'] == country) & (train['Province/State'] == province) & (train['ConfirmedCases'] < day)]['Date'].max()        \n        else:\n            fromday = pd.Timestamp('2020-12-31')        \n        for i in range(0, len(data)):\n            if (data['Date'].iloc[i] > fromday):\n                day_denta = data['Date'].iloc[i] - fromday\n                data['Number day from ' + str(day) + ' case'].iloc[i] = day_denta.days \n        feature = feature + ['Number day from ' + str(day) + ' case']\n    \n    return data[feature]\n   \nimport tensorflow as tf\n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(64, activation='elu', input_shape=[len(feature_day)]),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Dense(32, activation='elu'),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Dense(1)\n  ])\n\noptimizer = \"rmsprop\"\nmodel.compile(loss='mse', optimizer=optimizer, metrics=['mse','mae'])\nEPOCHS = 10\nBATCH_SIZE = 1\n\npred_data = []\n#for country in train['Country/Region'].unique():\nfor country in ['Vietnam']:\n    for province in train[(train['Country/Region'] == country)]['Province/State'].unique():\n        df_train = train[(train['Country/Region'] == country) & (train['Province/State'] == province)]\n        df_test = test[(test['Country/Region'] == country) & (test['Province/State'] == province)]\n        X_train = CreateInput(df_train)\n        y_train_confirmed = df_train['ConfirmedCases']\n        y_train_fatalities = df_train['Fatalities']\n        X_pred = CreateInput(df_test)\n        # Check not change\n        if (y_train_confirmed[-5:].mean() == y_train_confirmed.iloc[-1]):            \n            y_hat_confirmed = np.repeat(y_train_confirmed.iloc[-1], len(X_pred))\n        else:\n            model.fit(X_train,y_train_confirmed,batch_size=BATCH_SIZE, epochs=EPOCHS, verbose = 0)\n            y_hat = model.predict(X_pred)\n            y_hat_confirmed = [item[0] for item in y_hat]            \n\n        if (y_train_fatalities[-5:].mean() == y_train_fatalities.iloc[-1]):            \n            y_hat_fatalities = np.repeat(y_train_fatalities.iloc[-1], len(X_pred))\n        else:\n            model.fit(X_train,y_train_fatalities,batch_size=BATCH_SIZE, epochs=EPOCHS, verbose = 0)\n            y_hat = model.predict(X_pred) \n            y_hat_fatalities = [item[0] for item in y_hat]            \n        \n        for i in range(0,len(y_hat_confirmed)):\n            pred_data.append([df_test['Date'].iloc[i],country,province,df_test['ForecastId'].iloc[i],y_hat_confirmed[i],y_hat_fatalities[i]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plot and RMSLE only for Vietnam\nplotPrediction(pred_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Deep learning by train all country"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Forecast base on num of day feature all country\ndef CreateInput(data):\n    feature_day = [5,20,50,100,200,500,1000]\n    feature_name = ['Lat','Long']\n    #feature_day = [1,20]\n    for day in feature_day:\n        #Get information in train data\n        data['Number day from ' + str(day) + ' case'] = 0\n        for country in data['Country/Region'].unique():\n            for province in data[data['Country/Region'] == country]['Province/State'].unique():\n                fromday = train[(train['Country/Region'] == country) & (train['Province/State'] == province) & (train['ConfirmedCases'] > day)]['Date'].min()\n                if (pd.isnull(fromday) == False):\n                    data.loc[(data['Country/Region'] == country) & (data['Province/State'] == province),'Number day from ' + str(day) + ' case'] = (data[(data['Country/Region'] == country) & (data['Province/State'] == province)]['Date'] - fromday).dt.days\n                #for date in data[(data['Country/Region'] == country) & (data['Province/State'] == province)]['Date'].unique():\n                    #data.loc[(data['Country/Region'] == country) & (data['Province/State'] == province) & (data['Date'] == date),'Number day from ' + str(day) + ' case'] = (pd.Timestamp(date) - fromday).days\n        data.loc[(data['Number day from ' + str(day) + ' case'] < 0),'Number day from ' + str(day) + ' case'] = 0\n        feature_name = feature_name + ['Number day from ' + str(day) + ' case']\n    return data[feature_name]\n    #return data\n\nimport tensorflow as tf\n\nX_train = CreateInput(train.copy())\ny_train = train[['ConfirmedCases','Fatalities']]\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(64, activation='relu', input_shape=[X_train.shape[1]]),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Dense(2)\n  ])\n\noptimizer = \"rmsprop\"\nmodel.compile(loss='mse', optimizer=optimizer, metrics=['mse','mae'])\nEPOCHS = 100\nBATCH_SIZE = 24\n#y_train = train[train['ConfirmedCases']>0]['ConfirmedCases']\nmodel.fit(X_train,y_train, batch_size=BATCH_SIZE, epochs=EPOCHS,verbose = 0)\nX_pred = CreateInput(test.copy())\ny_hat = model.predict(X_pred)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Write submission - update actual value in the past for scoring"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_forcast = pd.concat([test[['Date','ForecastId']],pd.DataFrame(y_hat)],axis = 1)\ndf_forcast.columns = ['Date','ForecastId','ConfirmedCases','Fatalities']\ndf_forcast.loc[df_forcast['Fatalities'] < 0,'Fatalities'] = 0\ndf_forcast.loc[df_forcast['ConfirmedCases'] < 0,'ConfirmedCases'] = 0\n\ndf_past = pd.merge(test,train,on = ['Province/State','Date','Country/Region','Lat','Long'], how = 'inner').drop(['Id','Lat','Long'],axis=1)\ndf_future = df_forcast[(df_forcast['Date'] > df_past['Date'].max())]\n\nsubmission = df_past.append(df_future, sort = True)\n#submission[['ForecastId','ConfirmedCases','Fatalities']].to_csv('submission.csv',index=False)\nsubmission[['ForecastId','ConfirmedCases','Fatalities']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot forcast (only for country have a province / state)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_val = pd.merge(test,df_forcast[['ForecastId','ConfirmedCases','Fatalities']], how='inner', on = 'ForecastId')\ndf_val = pd.merge(df_val,train,on=['Date','Country/Region','Province/State','Lat','Long'], how='left')\ndf_val = df_val.sort_values(by = ['Date','Country/Region'])\ndf = df_val[df_val['Country/Region'] == 'Vietnam']\n#df_val = pd.merge(df,train[['Date','Country/Region','Province/State','ConfirmedCases','Fatalities']],on=['Date','Country/Region','Province/State'], how='left')\nval_size = df_val[df_val['ConfirmedCases_y'].notnull() == True].shape[0]\n#RMSLE(df_val['ConfirmedCases_x'][0:val_size].values,df_val['ConfirmedCases_y'][0:val_size].values)\n\nfig, axes = plt.subplots(nrows=1,ncols=2,figsize=(20, 7))\naxes[0].plot(df['Date'], df['ConfirmedCases_x'], label = 'ConfirmedCase forcast ' + df['Date'].max().strftime('%Y-%m-%d'))\naxes[0].plot(df['Date'][0:val_size], df['ConfirmedCases_y'][0:val_size], label = 'ConfirmedCase ' + df[df['ConfirmedCases_y'].isnull() == False]['Date'].max().strftime('%Y-%m-%d'))\naxes[0].legend()\naxes[1].plot(df['Date'], df['Fatalities_x'], label = 'Fatalities forcast ' + df['Date'].max().strftime('%Y-%m-%d'))\naxes[1].plot(df['Date'][0:val_size], df['Fatalities_y'][0:val_size], label = 'Fatalities ' + df[df['Fatalities_y'].isnull() == False]['Date'].max().strftime('%Y-%m-%d'))\naxes[1].legend()\nfig.autofmt_xdate()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RMSLE(df_val['ConfirmedCases_x'][0:val_size].values,df_val['ConfirmedCases_y'][0:val_size].values)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}