{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Read dataset"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport datetime\nimport tensorflow as tf\nimport math\n\ntrain_df = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-1/train.csv')\ntest_df = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-1/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Explore dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df[train_df['Country/Region'] == 'Korea, South'].head(200)\n#test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.groupby(['Country/Region', 'Province/State'])['Id'].agg(['count']).reset_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocess dataset"},{"metadata":{},"cell_type":"markdown","source":"* Fill NaN values\n* Convert Date to Day count from the start date of major pandemic"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df.fillna({'Province/State': 'Unknown'})\ntest_df = test_df.fillna({'Province/State': 'Unknown'})\ntrain_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_datetime(dt):\n    return datetime.datetime.strptime(dt, '%Y-%m-%d')\n\ndef count_days(dt):\n    return (dt - datetime.datetime.strptime('2020-01-22', \"%Y-%m-%d\")).days\n\nplot_df = train_df[train_df['Country/Region'] == 'Iran']\nplot_df['Date'] = plot_df['Date'].map(to_datetime)\nplot_df['Day'] = plot_df['Date'].map(count_days)\nplt.plot(plot_df['Day'], plot_df['ConfirmedCases'].cumsum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Logtransform ConfirmedCases because the distribution is left-skewed"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['ConfirmedCases_log'] = train_df['ConfirmedCases'].map(math.log1p)\ntrain_df['ConfirmedCases_log'].hist(bins=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Country/Region'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['Date_dt'] = train_df['Date'].map(to_datetime)\ntrain_df['Day'] = train_df['Date_dt'].map(count_days)\ntest_df['Date_dt'] = test_df['Date'].map(to_datetime)\ntest_df['Day'] = test_df['Date_dt'].map(count_days)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"historical_steps = 30\n\n# todo: better split validate data\nval_df = train_df[train_df['Day'] > (train_df['Day'].max() - historical_steps)]\n#val_df = train_df[train_df['Country/Region'].isin(['China'])]\n#train_drop_df = train_df.drop(val_df.index)\nprint('# Train DF \\n {} \\n# Val DF \\n {} \\n# Test DF \\n {}'.format(train_df.head(), val_df.head(), test_df.head()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Selection"},{"metadata":{},"cell_type":"markdown","source":"# 1. LSTM Model (Initially Chosen)\n\n**Reshape dataset to sequences**\n\nInput data includes a series of historical responses from historical_steps to the given time wherareas targets only include last snapshot"},{"metadata":{"trusted":true},"cell_type":"code","source":"# historical_steps = 30\n# output_steps = 10\n\n# def make_sequential_input(df):\n    \n#     inputs, targets = [], []\n    \n#     for i in range(len(df) - historical_steps - 1):\n        \n#         if df.iloc[i]['Lat'] == df.iloc[i + historical_steps]['Lat'] and \\\n#             df.iloc[i]['Long'] == df.iloc[i + historical_steps]['Long']:\n            \n#             # iloc[a:b] startnig from index 'a' and ending before b\n#             inputs.append(np.array(df.iloc[i:i + historical_steps][['Day', 'Lat', 'Long', 'ConfirmedCases_log', 'Fatalities']]).tolist())\n#             targets.append(np.array(df.iloc[i + historical_steps][['ConfirmedCases_log']]).tolist())\n        \n#     return inputs, targets\n\n\n# # Make sequential input for training and validation\n# train_inputs, train_targets = make_sequential_input(train_df)\n# val_inputs, val_targets = make_sequential_input(val_df)\n# np.shape(train_inputs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Create LSTM layers**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# historical_steps = 30\n\n# input_feature_count = 5\n# output_feature_count = 1\n# hidden_node_count = 32\n\n# batch_size = 32\n# epochs = 20\n# lr = 0.001\n\n# model = tf.keras.Sequential()\n# model.add(tf.keras.layers.LSTM(hidden_node_count, batch_input_shape=[None, historical_steps, input_feature_count], return_sequences=True))\n# model.add(tf.keras.layers.LSTM(hidden_node_count))\n# model.add(tf.keras.layers.Dense(output_feature_count, activation='sigmoid'))\n\n# optimizer = tf.keras.optimizers.Adam(lr=lr)\n# model.compile(loss=\"mean_squared_error\", optimizer=optimizer)\n\n# early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='auto', patience=5)\n# history = model.fit(train_inputs, train_targets, \\\n#                     epochs=epochs, \\\n#                     batch_size=batch_size, \\\n#                     validation_data=(val_inputs, val_targets), \\\n#                     callbacks=[early_stopping])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Predict Next Day**"},{"metadata":{},"cell_type":"markdown","source":"Found that the predicted results are way inaccurate, and one of main reasons is due to that:\n* Depending on geograhy, ConfirmedCases & Fatalities data can show different degree in performance\n\nTo train all data in a model, random effects should beb computed for multiple countries and applied to the model.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# def _inverse_log(val):\n#     return math.expm1(val)\n\n# _inverse_log_v = np.vectorize(_inverse_log)\n\n# # For certain country,\n# df = train_df[(train_df['Country/Region'] == 'Korea, South') & (train_df['Province/State'] == 'Unknown') ]\n\n# # Get latest tail & Conver to array\n# inputs = np.array(df[['Day', 'Lat', 'Long', 'ConfirmedCases_log', 'Fatalities']][-tail_len:])\n\n# # Get next ConfirmedCases & Fatalities\n# _inverse_log_v(model.predict(np.array(inputs).reshape(1, historical_steps, input_feature_count)).reshape(-1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Linear Mixed Model (Finally Chosen)\n\nLinear Mixed Effects models are used for regression analyses involving dependent data. Such data arise when working with longitudinal and other study designs in which multiple observations are made on each subject. Some specific linear mixed effects models are\n\n* Random intercepts models, where all responses in a group are additively shifted by a value that is specific to the group.\n* Random slopes models, where the responses in a group follow a (conditional) mean trajectory that is linear in the observed covariates, with the slopes (and possibly intercepts) varying by group.\n* Variance components models, where the levels of one or more categorical covariates are associated with draws from distributions. These random terms additively determine the conditional mean of each observation based on its covariate values."},{"metadata":{},"cell_type":"markdown","source":"**Train the model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\n\nhistorical_steps = 7\ntrain_df['Geo'] = train_df['Province/State'].astype(str) + ',' +train_df['Country/Region'].astype(str)\ntrain_df['Fatalities_log'] = train_df['Fatalities'].map(math.log1p)\n\nx_arr, y_arr, y_inverse_arr, grp_arr, day_arr = [], [], [], [], []\nxf_arr, yf_arr, yf_inverse_arr = [], [], []\n\nfor i in range(len(train_df) - historical_steps -1):\n    if train_df.iloc[i]['Lat'] == train_df.iloc[i+historical_steps]['Lat'] and \\\n        train_df.iloc[i]['Long'] == train_df.iloc[i+historical_steps]['Long']: \n        \n        x_arr.append(np.array(train_df.iloc[i:i+historical_steps][['ConfirmedCases_log']]).reshape(-1).tolist())\n        y_arr.append(np.array(train_df.iloc[i+historical_steps][['ConfirmedCases_log']]).tolist())\n        y_inverse_arr.append(np.array(train_df.iloc[i+historical_steps][['ConfirmedCases']]).tolist())\n        \n        xf_arr.append(np.array(train_df.iloc[i:i+historical_steps][['Fatalities_log']]).reshape(-1).tolist())\n        yf_arr.append(np.array(train_df.iloc[i+historical_steps][['Fatalities_log']]).tolist())\n        yf_inverse_arr.append(np.array(train_df.iloc[i+historical_steps][['Fatalities']]).tolist())\n        \n        grp_arr.append(np.array(train_df.iloc[i+historical_steps][['Geo']]).tolist())\n        day_arr.append(np.array(train_df.iloc[i+historical_steps][['Day']]).tolist())\n\n\nlmm_df = pd.DataFrame(np.hstack((x_arr, xf_arr)), columns=['L1','L2','L3','L4','L5','L6','L7', 'F1','F2','F3','F4','F5','F6','F7'])\nlmm_df['ConfirmedCases_log'] = sum(y_arr,[])\nlmm_df['ConfirmedCases'] = sum(y_inverse_arr,[])\n\nlmm_df['Fatalities_log'] = sum(yf_arr,[])\nlmm_df['Fatalities'] = sum(yf_inverse_arr,[])\n\nlmm_df['Geo'] = sum(grp_arr,[])\nlmm_df['Day'] = sum(day_arr,[])\nlmm_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = sm.MixedLM(endog=lmm_df['ConfirmedCases_log'], exog=lmm_df[['L1', 'L2', 'L3', 'L4', 'L5', 'L6', 'L7']], exog_re=lmm_df[['L1', 'L2', 'L3', 'L4', 'L5', 'L6', 'L7']], groups=lmm_df['Geo'])\nmodel_fat = sm.MixedLM(endog=lmm_df['Fatalities_log'], exog=lmm_df[['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7']], exog_re=lmm_df[['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7']],groups=lmm_df['Geo'])\nfitted = model.fit()\nfitted_fat = model_fat.fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['Geo'] = test_df['Province/State'] + ',' + test_df['Country/Region']\ntest_lmm_df = test_df\n\n# For each row\nfor i in range(len(test_lmm_df)):\n    \n    day = test_lmm_df.iloc[i].Day\n    geo = test_lmm_df.iloc[i]['Geo']\n    confirmedCases = 0\n    fatalities = 0\n    \n    # Find previous day\n    prev_df = lmm_df[(lmm_df['Day'] == day-1) & (lmm_df['Geo'] == geo)]\n    \n    # Confirmed Cases \n    if len(prev_df) != 0:\n        \n        # Generate new time lags \n        temp_l_df = prev_df[['L1', 'L2', 'L3', 'L4', 'L5', 'L6', 'L7']].iloc[:,1:]        \n        temp_l_df.columns = ['L1', 'L2', 'L3', 'L4', 'L5', 'L6']\n        temp_l_df['L7'] = prev_df['ConfirmedCases_log']        \n        \n        # Compute new exog array & Predict\n        confirmedCases_log = fitted.predict(exog=np.array(temp_l_df).reshape(-1).tolist())[0]        \n        confirmedCases = math.expm1(confirmedCases_log)\n        \n    # Fatalities \n    if len(prev_df) != 0:\n        \n        # Generate new time lags \n        temp_f_df = prev_df[['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7']].iloc[:,1:]        \n        temp_f_df.columns = ['F1', 'F2', 'F3', 'F4', 'F5', 'F6']\n        temp_f_df['F7'] = prev_df['Fatalities_log']        \n        \n        # Compute new exog array & Predict\n        fatalities_log = fitted_fat.predict(exog=np.array(temp_f_df).reshape(-1).tolist())[0]        \n        fatalities = math.expm1(fatalities_log)\n    \n    current_df = lmm_df[(lmm_df['Day'] == day) & (lmm_df['Geo'] == geo)]\n    \n    if len(current_df) != 0:\n        lmm_df = lmm_df.drop(current_df.index.tolist())\n    lmm_df = lmm_df.append(pd.Series([temp_l_df['L1'].values[0], temp_l_df['L2'].values[0], temp_l_df['L3'].values[0], temp_l_df['L4'].values[0], temp_l_df['L5'].values[0], temp_l_df['L6'].values[0], temp_l_df['L7'].values[0], \\\n                                      temp_f_df['F1'].values[0], temp_f_df['F2'].values[0], temp_f_df['F3'].values[0], temp_f_df['F4'].values[0], temp_f_df['F5'].values[0], temp_f_df['F6'].values[0], temp_f_df['F7'].values[0], \\\n                                      confirmedCases_log, confirmedCases, fatalities_log, fatalities, geo, day], index=lmm_df.columns ), ignore_index=True)\n                                        \nlmm_df[(lmm_df['Geo'] == 'Unknown,Korea, South')].tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Prediction by Geography**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_df = lmm_df[(lmm_df['Geo'] == 'New South Wales,Australia')]\nplt.plot(plot_df['Day'], plot_df['ConfirmedCases'].cumsum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_df = lmm_df[(lmm_df['Geo'] == 'Hubei,China')]\nplt.plot(plot_df['Day'], plot_df['ConfirmedCases'].cumsum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_df = lmm_df[(lmm_df['Geo'] == 'Unknown,Korea, South')]\nplt.plot(plot_df['Day'], plot_df['ConfirmedCases'].cumsum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_df = lmm_df[(lmm_df['Geo'] == 'Unknown,Italy')]\nplt.plot(plot_df['Day'], plot_df['ConfirmedCases'].cumsum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_df = lmm_df[(lmm_df['Geo'] == 'Unknown,Iran')]\nplt.plot(plot_df['Day'], plot_df['ConfirmedCases'].cumsum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmedCases = []\nfatalities = [] \nfor i in range(len(test_df)):\n    \n    day = test_lmm_df.iloc[i].Day\n    geo = test_lmm_df.iloc[i]['Geo']    \n       \n    current_df = lmm_df[(lmm_df['Day'] == day) & (lmm_df['Geo'] == geo)]    \n    \n    if len(current_df) != 0:\n        confirmedCases.append(current_df['ConfirmedCases'].values[0])\n        fatalities.append(current_df['Fatalities'].values[0])        \n    else:\n        confirmedCases.append(0)\n        fatalities.append(0)    \n\ntest_df['ConfirmedCases'] = confirmedCases\ntest_df['Fatalities'] = fatalities\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df[['ForecastId', 'ConfirmedCases', 'Fatalities']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[(train_df['Country/Region'] == 'Korea, South') & (train_df['Province/State'] == 'Unknown')].tail(20) \ntest_df[(test_df['Country/Region'] == 'Korea, South') & (test_df['Province/State'] == 'Unknown') ].head(25)\nlmm_df[(lmm_df['Geo'] == 'Unknown,Korea, South')].tail(35)\ntrain_df[(train_df['Country/Region'] == 'Korea, South') & (train_df['Province/State'] == 'Unknown') & (train_df['Day'] == 88)].head()\ntest_df[(test_df['Country/Region'] == 'Korea, South') & (test_df['Province/State'] == 'Unknown') & (test_df['Day'] == 88)].head()\n\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}