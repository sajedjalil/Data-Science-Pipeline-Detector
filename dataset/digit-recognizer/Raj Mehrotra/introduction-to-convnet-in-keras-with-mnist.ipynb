{"cells":[{"metadata":{"colab_type":"text","id":"0BFH4V9FlmDr","_uuid":"f38e87d4f76a25e432de4fa7907a1cb0252cd941"},"cell_type":"markdown","source":"# MNIST DIGIT RECOGNIZER USING CNN KERAS [Val. Acc.: 99.57 ]"},{"metadata":{"colab_type":"text","id":"JE5wCNMElmDs","_uuid":"6c1c4d336f1660ea564534a69a3f4a92e534e84d"},"cell_type":"markdown","source":"## [Please upvote/star if u like it or find it helpful.]"},{"metadata":{"colab_type":"text","id":"d2kkEDgSlmDu","_uuid":"c2772f3657b687c403728b019db082e1ccefd2c4"},"cell_type":"markdown","source":"## CONTENTS::->"},{"metadata":{"colab_type":"text","id":"c6Mst4z0lmDv","_uuid":"dc25799eaa9696d17231fbc88088aa5a1dc8c124"},"cell_type":"markdown","source":"[ **1) Importing Variuos Modules**](#content1)"},{"metadata":{"colab_type":"text","id":"l7gcPBA_lmDx","_uuid":"154cd37c3c00902e4ee18c462fcbc6de6fb1efae"},"cell_type":"markdown","source":" [ **2) Loading the training and testing files**](#content2)"},{"metadata":{"colab_type":"text","id":"-WMLwJm5lmDz","_uuid":"21d26fcf3fcff142635ad2529445349576fa6d06"},"cell_type":"markdown","source":" [ **3) Preparing the Data**](#content3)"},{"metadata":{"colab_type":"text","id":"zimzfjTulmDz","_uuid":"1cd508005416f5d7fab1959ba3b154dc20e2494a"},"cell_type":"markdown","source":" [ **4) Modelling**](#content4)"},{"metadata":{"colab_type":"text","id":"KNfZ8Zc1lmD0","_uuid":"63c846d81a30789e9f803102faeb297ab13276b9"},"cell_type":"markdown","source":" [ **5) Making Predictions on the Validation Set**](#content5)"},{"metadata":{"colab_type":"text","id":"oauVQfxzlmD1","_uuid":"b02788639c55e6703ff6ab5de83a4fcd5686a13b"},"cell_type":"markdown","source":" [ **6) Evaluating the Model Performance**](#content6)"},{"metadata":{"colab_type":"text","id":"UrxgVb3llmD2","_uuid":"25b7ab55ba8e7eb5af93298352cade10ef3cc736"},"cell_type":"markdown","source":" [ **7 ) Making Submission to Kaggle**](#content7)"},{"metadata":{"colab_type":"text","id":"iMtTdnzulmD3","_uuid":"055623148fd245231f49ee9c6b26f25f34f7b4e1"},"cell_type":"markdown","source":"<a id=\"content1\"></a>\n## 1 ) Importing Various Modules"},{"metadata":{"colab":{},"colab_type":"code","id":"oHYM8dQ0lmD4","trusted":false,"_uuid":"57d58eb189b49f450e6d0e33bba4882dbf10fc93","collapsed":true},"cell_type":"code","source":"# Ignore  the warnings\nimport warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n\n# data visualisation and manipulation\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nimport seaborn as sns\nimport missingno as msno\n\n#configure\n# sets matplotlib to inline and displays graphs below the corressponding cell.\n%matplotlib inline  \nstyle.use('fivethirtyeight')\nsns.set(style='whitegrid',color_codes=True)\n\n#import the necessary modelling algos.\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\n#model selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score\nfrom sklearn.model_selection import GridSearchCV\n\nfrom imblearn.over_sampling import SMOTE\n\n#preprocess.\nfrom sklearn.preprocessing import MinMaxScaler,StandardScaler,Imputer,LabelEncoder,OneHotEncoder\nfrom keras.preprocessing.image import ImageDataGenerator\n\n#dl libraraies\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\nfrom keras.utils import to_categorical\n\n# specifically for cnn\nfrom keras.layers import Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n \n\nimport tensorflow as tf\nimport random as rn","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"Uujy_2LNlmD-","_uuid":"dd3c059fcab1965e9213f8de438b12489e2c635b"},"cell_type":"markdown","source":"<a id=\"content2\"></a>\n## 2 ) Loading the training and testing files"},{"metadata":{"colab":{},"colab_type":"code","id":"sUlWe-AdlmD_","trusted":false,"_uuid":"98ef947d8600f6ec7a64f1de3615bb04f815162a","collapsed":true},"cell_type":"code","source":"train=pd.read_csv(r'../input/train.csv')\ntest=pd.read_csv(r'../input/test.csv')\ndf=train.copy()\ndf_test=test.copy()","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"colab_type":"code","executionInfo":{"elapsed":1017,"status":"ok","timestamp":1534508053132,"user":{"displayName":"Raj Mehrotra","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116188724100341692953"},"user_tz":-330},"id":"E9v-Q-pVlmEn","outputId":"0bdbc56f-7534-460e-e6a1-5cf86436c921","trusted":false,"_uuid":"6af663b5762fb6cac7844ac400ddd30d9f7afc83","collapsed":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"RJegJNGUlmEr","_uuid":"b2828591ccbf80dc8caef08fdab4e807ccd7a6d3"},"cell_type":"markdown","source":"<a id=\"content3\"></a>\n## 3 ) Preparing the Data"},{"metadata":{"colab_type":"text","id":"qSjMEJtPlmEt","_uuid":"b6803069622eef7a269d74edf468d609f5059ae7"},"cell_type":"markdown","source":"## 3.1 ) Shape of Training/Testing Set"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":941,"status":"ok","timestamp":1534508054395,"user":{"displayName":"Raj Mehrotra","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116188724100341692953"},"user_tz":-330},"id":"HEZXohDLlmEt","outputId":"e3edcbba-b6cc-47d0-aea4-50a88312b7a3","trusted":false,"_uuid":"2bd2aa98109ef54a996ffa08e894ac6f67f79eca","collapsed":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"jIk1mHjhlmE3","_uuid":"566a278107137a6b6463cbe29f5de8a974fbe9af"},"cell_type":"markdown","source":"A training set of 42000 images. The images are of 28*28 pixels and one extra column is for the label of the digit (0 1 2... etc...)"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":911,"status":"ok","timestamp":1534508055685,"user":{"displayName":"Raj Mehrotra","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116188724100341692953"},"user_tz":-330},"id":"UlXCJBjQlmE5","outputId":"c044c94a-7acb-4159-8970-99ee9744ba08","trusted":false,"_uuid":"8b3b4ec214496258d081333e84fb9aa584200ad4","collapsed":true},"cell_type":"code","source":"df_test.shape ","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"GOpme5wvlmE9","_uuid":"d4f072ad4ec980370605b433e2c4e70cf5dc191d"},"cell_type":"markdown","source":"The test set contains 28000 images of 28*28 pixels each."},{"metadata":{"colab_type":"text","id":"hfDC739slmE-","_uuid":"31d633df24048f9bb9d28a92b5551f6e5a6b3574"},"cell_type":"markdown","source":"## 3.2 ) Visualizing Number of Images for each Digit "},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"colab_type":"code","executionInfo":{"elapsed":1340,"status":"ok","timestamp":1534508057472,"user":{"displayName":"Raj Mehrotra","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116188724100341692953"},"user_tz":-330},"id":"9THsMD59lmE_","outputId":"fe24d3c7-ca3e-453b-ab41-c2161bd49091","trusted":false,"_uuid":"e616d7f713ea0cc3aa005f2df5b0b3f7adc36a46","collapsed":true},"cell_type":"code","source":"df['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"colab_type":"code","executionInfo":{"elapsed":2653,"status":"ok","timestamp":1534508060314,"user":{"displayName":"Raj Mehrotra","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116188724100341692953"},"user_tz":-330},"id":"d5oOKd2LlmFF","outputId":"faac2d27-c4e9-4bad-efab-4a50df4638f9","trusted":false,"_uuid":"b14827e5f2ecce5893478a82ff2bf020fcbe1bcc","collapsed":true},"cell_type":"code","source":"sns.factorplot(data=df,kind='count',x='label',size=5,aspect=1.5)","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"d_90H011lmGP","_uuid":"9545ec42ca977484d474120263130919a81488b7"},"cell_type":"markdown","source":"Now we can randomly visualize some images from the training set by plottimg them. Lets do this for  the first ( say ) 10 or 20 images."},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":924},"colab_type":"code","executionInfo":{"elapsed":3552,"status":"ok","timestamp":1534508065212,"user":{"displayName":"Raj Mehrotra","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116188724100341692953"},"user_tz":-330},"id":"9k7moSXYlmGQ","outputId":"6738a1c5-a12b-4959-a9ac-c1a33e1b85af","trusted":false,"_uuid":"4653f5c0efc68596ab32a7a42f946c20332c4ef0","collapsed":true},"cell_type":"code","source":"fig,ax=plt.subplots(5,2)\nfig.set_size_inches(15,15)\ncount=0\nfor i in range(5):\n    for j in range (2):\n        ax[i,j].imshow(df.drop('label',axis=1).values[count].reshape(28,28),cmap='gray')\n        count+=1","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"-nxa3sIklmGU","_uuid":"ce7a4abf1462be09988bd8654f368ca9486a421d"},"cell_type":"markdown","source":"The countplot shows the number of images for each digit. For eg---> 1 has 4684 images and so on for other digits... ."},{"metadata":{"colab_type":"text","id":"mdQ0UndDlmGU","_uuid":"44cdd37f62ea9a31d0447164c43eb6432544f861"},"cell_type":"markdown","source":"## 3.3 ) Converting from Data Frame to Numpy Arrays"},{"metadata":{"colab_type":"text","id":"2KRRcR8plmGX","_uuid":"dd4652a999b255723eecbd3c576ebc6758b8ca34"},"cell_type":"markdown","source":"Note that to feed our data to a neural network or more specifically a ConvNet model in our case; we need to convert it to numpy arrays holding the respective pixel values. To do this we use the '.values' attribute on the data frame."},{"metadata":{"colab":{},"colab_type":"code","id":"Z5OxBfhClmGY","trusted":false,"_uuid":"b0e5969d9a32972af018c352a8152300f77521fc","collapsed":true},"cell_type":"code","source":"X=df.drop('label',axis=1).values\nY=df['label'].values","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136},"colab_type":"code","executionInfo":{"elapsed":1116,"status":"ok","timestamp":1534508067809,"user":{"displayName":"Raj Mehrotra","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116188724100341692953"},"user_tz":-330},"id":"flPGZyqQlmGb","outputId":"6a0bb972-07ae-4c32-8a39-d68e4b93b1f9","trusted":false,"_uuid":"d11e3789c6e7db40e5459e76996bb520f30bedae","collapsed":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"mH2Hi70IlmGg","_uuid":"84c24ae4cb81a58f823c81834c1288cc5d9f7d5d"},"cell_type":"markdown","source":"## 3.4 ) One Hot Encoding the Target"},{"metadata":{"colab_type":"text","id":"hotQ_vFqlmGh","_uuid":"64a683635065befd1a7c1200f52155590cfe4b44"},"cell_type":"markdown","source":"Note that there are two main things to watch out before feeding data into a neural network.\n\nThe first is that our data needs to be in the form of numpy arrays (ndarray) which we did in previous section.\n\nThe second that the target variable should be one hot encoded eg 2--> 0010 (assuming 0 based indexing) and so on.. In this way for a 'n' class classification problems our target variable will have n classes and hence after one hot encoding we shall have n labels with each label corressponding to a particular target class.\n\nHere we have 10 digits (or target classes) ie from 0--->9 and so we one hot encode the target using 10 classes."},{"metadata":{"colab":{},"colab_type":"code","id":"kRTfcz8jlmGj","trusted":false,"_uuid":"7c67358429bb7277f96399c143169b30942574d4","collapsed":true},"cell_type":"code","source":"Y=to_categorical(Y,10)  ","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"R0tRNYqZlmGl","_uuid":"18ef0218c1baba963ce9fa28da87e8fe1d5bc0ed"},"cell_type":"markdown","source":"## 3.5 ) Splitting into Training and Validation Sets.\n"},{"metadata":{"colab":{},"colab_type":"code","id":"FJCdGBPLlmGm","trusted":false,"_uuid":"4201e6c8b438176fe284b4ce2386bf915944b03b","collapsed":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.20,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"Q7McnmyMlmGp","_uuid":"2a31ed2271a6e27fc141a1a50a8e5b92d502ad13"},"cell_type":"markdown","source":"## 3.6 ) Normalizing the Features"},{"metadata":{"colab_type":"text","id":"ffx52wJDlmGp","_uuid":"d81cabf3b2b6b783a602729d62704aaac1e8d018"},"cell_type":"markdown","source":"Note that the neural networks are quite sensitive towards the scale of the features. Hence it is always good to perform feature scaling on the data before feeding it into a Neural Network.\n\nBelow I have scaled the pixel values by dividing by 255 since the max pixel value is 255 and minimum is zero.\n\nActually it is based on \n\nx=(x-min)/(max-min) ;where min=0 and max=255 for our case."},{"metadata":{"colab":{},"colab_type":"code","id":"LYfYA7o2lmGr","trusted":false,"_uuid":"1f269c50cc0099f12ced815f296ab88bbe03cefc","collapsed":true},"cell_type":"code","source":"x_train=x_train/255  \nx_test=x_test/255\nnum_test=df_test.values\nnum_test=num_test/255","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"9MFBnHoelmGu","_uuid":"4726fbf9d757c3280aec9cf06204be52685028e7"},"cell_type":"markdown","source":"## 3.7 ) Reshaping the Images"},{"metadata":{"colab_type":"text","id":"4ugAUhe9lmHQ","_uuid":"a8fb1e4e0db382461fddb8f14a16f0dfd18524d4"},"cell_type":"markdown","source":"Note that to feed our data to a ConvNet model we need to make its shape correct. \n\nSince we have 784 pixel values , we resize each images to 28*28 pixels. Also since it is a grayscale image it has only one channel(unlike a RGB image which has 3 channels; one corressponding to each color).\n\nNow we reshape our training , validation and test sets. The first dimension of each is the number of observations in the set. What follows is the dimensions of the image in \"channels_last\" order ie (no of obs., width,height,depth)."},{"metadata":{"colab":{},"colab_type":"code","id":"kKGLGyfblmHR","trusted":false,"_uuid":"9b14b759ed2b7519fbf5a2133e5adcd9c30c3da3","collapsed":true},"cell_type":"code","source":"x_train=x_train.reshape(x_train.shape[0],28,28,1)\nx_test=x_test.reshape(x_test.shape[0],28,28,1)\nnum_test=num_test.reshape(num_test.shape[0],28,28,1)","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":1075,"status":"ok","timestamp":1534508076315,"user":{"displayName":"Raj Mehrotra","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116188724100341692953"},"user_tz":-330},"id":"6KelQHqAlmHV","outputId":"6b624b5b-77d3-4f29-ab75-1919fe529f90","trusted":false,"_uuid":"8634e1a399bfe577ba5f99e4278fd7b661831349","collapsed":true},"cell_type":"code","source":"x_train.shape","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"ouOhrwoalmHa","_uuid":"a6794dac48d45446d2d8b7902b8e0d16d8eba8d9"},"cell_type":"markdown","source":"## 3.8 ) Setting the Random Seeds"},{"metadata":{"colab_type":"text","id":"a-5botj2lmHa","_uuid":"70559856a241c9f94802c93cd378ed815a409b67"},"cell_type":"markdown","source":"Setting the seeds for reproducibility."},{"metadata":{"colab":{},"colab_type":"code","id":"a3qX4tjAlmHc","trusted":false,"_uuid":"73e34d431ee05021bd7b5ca164e1ff4bcbcdc103","collapsed":true},"cell_type":"code","source":"np.random.seed(42)","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"R4O941CylmHe","trusted":false,"_uuid":"7c83facab9e254f6cf8558a6c35a38474cbdee23","collapsed":true},"cell_type":"code","source":"rn.seed(42)","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"2P5p34jFlmHk","trusted":false,"_uuid":"2efaf864dc1559dd0dd8243fc55c2a7730078556","collapsed":true},"cell_type":"code","source":"tf.set_random_seed(42)","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"me0vRNZ3lmHn","_uuid":"5dc31be92ac62a19f2e751791429f965bbd87c7d"},"cell_type":"markdown","source":"<a id=\"content4\"></a>\n## 4 ) Modelling "},{"metadata":{"colab_type":"text","id":"t9VOWe3clmHv","_uuid":"f6f9ca79586b4f4dec2650f08219f3c32cb769a6"},"cell_type":"markdown","source":"## 4.1 ) Building a Convolutional Neural Network using Keras"},{"metadata":{"colab":{},"colab_type":"code","id":"Dnc_Xv4klmHw","trusted":true,"_uuid":"bf64001382b74e1f0d6bf7062048e1895dfd5b0e"},"cell_type":"code","source":"# modelling starts using a CNN.\n\nmodel=Sequential()\nmodel.add(Conv2D(filters=32,kernel_size=(3,3),strides=1,padding='same',data_format=\"channels_last\",activation='relu',\n                 input_shape=(28,28,1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=32,kernel_size=(3,3),strides=1,padding='same',data_format=\"channels_last\",activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid', data_format=\"channels_last\"))\nmodel.add(Dropout(0.20))\n\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),strides=1,padding='same',data_format=\"channels_last\",activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),strides=1,padding='same',data_format=\"channels_last\",activation='relu'))\nmodel.add(BatchNormalization()) \nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid', data_format=\"channels_last\"))\nmodel.add(Dropout(0.20))\n\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),strides=1,padding='same',data_format=\"channels_last\",activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=64,kernel_size=(3,3),strides=1,padding='same',data_format=\"channels_last\",activation='relu'))\nmodel.add(BatchNormalization()) \nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid', data_format=\"channels_last\"))\nmodel.add(Dropout(0.20))\n\nmodel.add(Flatten())\nmodel.add(Dense(256,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.50))\nmodel.add(Dense(10, activation='softmax'))\n","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"ZAIQ1Dl0lmHz","_uuid":"fe1fa4d7fa98e5177a33c0c1dc69d75198ff273c"},"cell_type":"markdown","source":"#### BREAKING IT DOWN--\n\n1.) First we create a Keras Sequential model which is nothing but a stack of layers.\n\n2.) Next we have to add the convolutional and the pooling layers to our model. The number of convolutional layers as well as the number and position of a pooling layer is a hyperparameter which we need to decide. Also we have other hyperparameters such as the 'activation function','stride','padding','the number as well as the size of the filter' and etc... .\n\n  Note that in a ConvNet the convolution layer generally has the padding of zeros so that the spatial dimesnions of input volume and output volume are same. Hence we have used the 'padding='same'' arguement. Whereas in a pooling layer the padding is not applied in general.\n  \n  Also note that we have other types of pooling operations also but MaxPooling layer is known to perform better in most cases.\n\n3.) To further improve the model performance we can use the batch normalization. In our model I have used the batch normalization after each convolutonal layer but that depends on us.\n\n4.) In order to further prevent overfitting we can use the 'Dropout' technique. The dropout randomly drops nodes from the network and thus reduces the dependency on any one neuron. Because of this each neuron learns better and the whole network's performance is expected to get better. To use Dropout we need to set the 'DroputRate' which  is the fraction of the neurons to drop at random from each layer in the network. Note that Dropout is in general applied after the MaxPooling operation.\n\n5.) After this what follows is fully connected layers similar to what we would expect in the artificial neural network. Since it expects 1D input we add a Flatten layer to precede it.\n\n6.) Note that we can add as many fully connected layers as we want and can use Batch Normalization and Dropout here too.\n    The number of the units and the activation function('relu' used here) are the hyperparameters as usual.\n\n7.) Lastly what follows is the output layer. The output units in the output layer equals the number of categories in which we want to classify the target.The activation funtion used is 'softmax' since we have a multi-classification problem."},{"metadata":{"colab_type":"text","id":"Sf_u1HKLlmHz","_uuid":"0bd4d7972155937f6eb667df2d2855694b222b63"},"cell_type":"markdown","source":"## 4.2 ) Data Augmentation Using the Image Generator from Keras "},{"metadata":{"colab_type":"text","id":"qOlzZ3lRlmH0","_uuid":"7134b25cd4c9d5177a12d8cf1c7038107881a6c6"},"cell_type":"markdown","source":"Data augmentation is a really powerful technique. It helps in increasing the size of the training set by just making modifications to the images. In this way the size of the training set is increased and hence further reduces chances of overfitting.\n\nIn order to avoid overfitting problem, we need to expand artificially our handwritten digit dataset. We can make your existing dataset even larger. The idea is to alter the training data with small transformations to reproduce the variations occuring when someone is writing a digit.\n\nFor example, the number is not centered The scale is not the same (some who write with big/small numbers) The image is rotated...\n\nApproaches that alter the training data in ways that change the array representation while keeping the label the same are known as data augmentation techniques. Some popular augmentations people use are grayscales, horizontal flips, vertical flips, random crops, color jitters, translations, rotations, and much more.\n\nBy applying just a couple of these transformations to our training data, we can easily double or triple the number of training examples and create a very robust model.\n\nBelow I have used the ImageGenerator class from Keras I order to augment the data."},{"metadata":{"colab":{},"colab_type":"code","id":"nziSzDr3lmH1","trusted":false,"_uuid":"b54bdb625acdfd9156d146f0d69d6bd41d8a8590","collapsed":true},"cell_type":"code","source":"batch_size=64\nepochs=20\nfrom keras.callbacks import ReduceLROnPlateau\nred_lr= ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.1,min_lr=0.0001)","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"Z1bPSaDjlmIU","trusted":false,"_uuid":"0c44327dca818538c47ff331dbd73cab6d4065b6","collapsed":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(x_train)","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"58lLdeF2lmIW","_uuid":"d2e9429ecfada94b731bfd393ff8a6181b741466"},"cell_type":"markdown","source":"## 4.3 ) Compiling the Keras Model"},{"metadata":{"colab":{},"colab_type":"code","id":"sa0uHMYqlmIY","trusted":false,"_uuid":"00436404bd61025a29129193f996f147b86032c5","collapsed":true},"cell_type":"code","source":"model.compile(optimizer=RMSprop(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])  ","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"KyCRhm0BlmIj","_uuid":"302960d56a2aab3bdc782be4f7286bd6005df5f5"},"cell_type":"markdown","source":"#### BREAKING IT DOWN--\n\n1.) Now we need to compile the model. We have to specify the optimizer used by the model We have many choices like Adam,        RMSprop etc.. Refer to Keras doc for a comprehensive list of the optimizers available.\n\n2.) Next we need to specify the loss function for the neural network which we seek to minimize.\n\n   I have used the 'categorical_crossentropy' loss function since this is a mulit-class classification problem. For a binary    classification problems we may use the 'binary_crossentropy'.\n\n3.) Next we need to specify the metric to evaluate our models performance. Here I have used accuracy."},{"metadata":{"colab_type":"text","id":"a3ERd9UslmIk","_uuid":"586be7957b8814884545fe94761c7e69375b6ae2"},"cell_type":"markdown","source":"## 4.4 ) Summary of the Model"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":714},"colab_type":"code","executionInfo":{"elapsed":1063,"status":"ok","timestamp":1534508089519,"user":{"displayName":"Raj Mehrotra","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116188724100341692953"},"user_tz":-330},"id":"gFYjhtoMlmIl","outputId":"aa3af09f-cdb8-4c43-b32f-caa7c2aa8830","trusted":false,"_uuid":"6656d3caffccd61a21ec08e653f7049ed92519f1","collapsed":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"3EPXG010lmIo","_uuid":"b5a232bd32fce9014e06dce779522b9b6e1577ac"},"cell_type":"markdown","source":"Gives a detailed description of the model and various parameters."},{"metadata":{"colab_type":"text","id":"TcoMNaBWlmIp","_uuid":"5a53b4ef5c3c3cd64f8e8c30c3d9fff8d0fc2bc4"},"cell_type":"markdown","source":"## 4.5 ) Fitting the model on the training data and testing on the validation set"},{"metadata":{"colab_type":"text","id":"w-3soO0jlmIq","_uuid":"2a4517cf3a27df3d0296d6a64d1ab51f9757047e"},"cell_type":"markdown","source":"Finally we need to fit our model on the data or rather the 'augmented data'. We also need to specify the 'batch_size' ,'the number of epochs','the validation set' and some other parameters."},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":697},"colab_type":"code","executionInfo":{"elapsed":431785,"status":"ok","timestamp":1534508521583,"user":{"displayName":"Raj Mehrotra","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116188724100341692953"},"user_tz":-330},"id":"hTsapvzKlmIq","outputId":"909cb81b-5315-4680-e652-018753bdd063","trusted":false,"_uuid":"ea0e8b4b156a5c39b036db738ea5a8b36d272bf6","collapsed":true},"cell_type":"code","source":"History = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (x_test,y_test),\n                              verbose = 1, steps_per_epoch=x_train.shape[0] // batch_size,callbacks=[red_lr])","execution_count":null,"outputs":[]},{"metadata":{"colab":{},"colab_type":"code","id":"z9ql_NrOlmIu","trusted":false,"_uuid":"b0d19b814810eb4f7fffe170cbb3105bdf33ce1b","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"IevevDVylmIx","_uuid":"8db779053896332a48bd0cf76b5992ae2c61974d"},"cell_type":"markdown","source":"<a id=\"content5\"></a>\n## 5 ) Making Predictions on the Validation Set"},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":3214,"status":"ok","timestamp":1534508526117,"user":{"displayName":"Raj Mehrotra","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116188724100341692953"},"user_tz":-330},"id":"yDzAwZ40lmIy","outputId":"a6a1c08e-e083-47b8-d7fe-a9ba18554fa7","trusted":false,"_uuid":"3feb04ad6c1efcdcff041b0f90701576eea7b701","collapsed":true},"cell_type":"code","source":"pred=model.predict(x_test)\npred_digits=np.argmax(pred,axis=1)\nimage_id=[]\nfor i in range (len(pred_digits)):\n    image_id.append(i+1)\nlen(image_id)","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"colab_type":"code","executionInfo":{"elapsed":1185,"status":"ok","timestamp":1534508527403,"user":{"displayName":"Raj Mehrotra","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116188724100341692953"},"user_tz":-330},"id":"ig_lkd87lmI2","outputId":"70d43ecf-2fdd-454a-a3f0-ae3f20764670","trusted":false,"_uuid":"dbba769070b90e725406b5d50a8790705d42a6d7","collapsed":true},"cell_type":"code","source":"pred_digits","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"ep36mytrlmJA","_uuid":"98ff2ea0d5f6749dd2e1935133f62e0faeae3216"},"cell_type":"markdown","source":"<a id=\"content6\"></a>\n## 6 ) Evaluating the Model Performance"},{"metadata":{"colab_type":"text","id":"6OHxc_b-lmJA","_uuid":"7fa5173680f69e884d052fa857c109ba0ade5a53"},"cell_type":"markdown","source":"Let us plot the 'accuracy vs no of epcohs' and 'loss vs no of epochs' curves for a better insight."},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":51},"colab_type":"code","executionInfo":{"elapsed":2984,"status":"ok","timestamp":1534508530624,"user":{"displayName":"Raj Mehrotra","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116188724100341692953"},"user_tz":-330},"id":"78uuux8UlmJB","outputId":"532a61c3-3d0f-43a9-90c0-39256d9e9200","trusted":false,"_uuid":"bcedf9bb0f3c3549b9d1a18c21651e58076766d4","collapsed":true},"cell_type":"code","source":"model.evaluate(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":398},"colab_type":"code","executionInfo":{"elapsed":1474,"status":"ok","timestamp":1534508532429,"user":{"displayName":"Raj Mehrotra","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116188724100341692953"},"user_tz":-330},"id":"stk6AG55lmJE","outputId":"18e0845a-4895-4da5-9af0-894ec913a9f4","trusted":false,"_uuid":"46d065c6751c0d1578c8e6da00478fffa84d2594","collapsed":true},"cell_type":"code","source":"plt.plot(History.history['loss'])\nplt.plot(History.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":398},"colab_type":"code","executionInfo":{"elapsed":1823,"status":"ok","timestamp":1534508534398,"user":{"displayName":"Raj Mehrotra","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116188724100341692953"},"user_tz":-330},"id":"n0E3IKL_lmJJ","outputId":"a9e90f0b-eba9-445d-dc11-7f86651518f1","trusted":false,"_uuid":"ef73bb083adba4cb8ea8793f9238135b6eb2bf82","collapsed":true},"cell_type":"code","source":"plt.plot(History.history['acc'])\nplt.plot(History.history['val_acc'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend(['train', 'test'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"4emmfeoKlmJN","_uuid":"56f4792bb5374d131dc0165dbad7ec4241c83324"},"cell_type":"markdown","source":"Below I have displayed some correctly classified and misclassified images which just helps it visualize better."},{"metadata":{"colab":{},"colab_type":"code","id":"6KFJbnlmlmJO","trusted":false,"_uuid":"9b85f2614735a60821f689711a63fb7103885798","collapsed":true},"cell_type":"code","source":"i=0\nprop_class=[]\nmis_class=[]\n\nfor i in range(len(y_test)):\n    if(np.argmax(y_test[i])==pred_digits[i]):\n        prop_class.append(i)\n    if(len(prop_class)==6):\n        break\n\ni=0\nfor i in range(len(y_test)):\n    if(not np.argmax(y_test[i])==pred_digits[i]):\n        mis_class.append(i)\n    if(len(mis_class)==6):\n        break\n","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"wf8qR0kPlmJT","_uuid":"bdda61c4fd1c623351de69090ce9e987c6bc640e"},"cell_type":"markdown","source":"#### CORRECTLY CLASSIFIED IMAGES."},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":725},"colab_type":"code","executionInfo":{"elapsed":2722,"status":"ok","timestamp":1534508538709,"user":{"displayName":"Raj Mehrotra","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116188724100341692953"},"user_tz":-330},"id":"vtPIc_vblmJU","outputId":"82143cd6-68bf-488a-ce74-ae03d38b928e","trusted":false,"_uuid":"82f06f4a4fc255b7139b65e75e03a4f268a8671f","collapsed":true},"cell_type":"code","source":"count=0\nfig,ax=plt.subplots(3,2)\nfig.set_size_inches(10,10)\nfor i in range (3):\n    for j in range (2):\n        ax[i,j].imshow(x_test[prop_class[count]].reshape(28,28),cmap='gray')\n        ax[i,j].set_title(\"Predicted Label : \"+str(pred_digits[prop_class[count]])+\"\\n\"+\"Actual Label : \"+str(np.argmax(y_test[prop_class[count]])))\n        plt.tight_layout()\n        count+=1\n        ","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"azjQsIj2lmJW","_uuid":"4481b115d3a2553c1464f4a01ddafd070e3a689d"},"cell_type":"markdown","source":"#### MISCLASSIFIED IMAGES."},{"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":725},"colab_type":"code","executionInfo":{"elapsed":2890,"status":"ok","timestamp":1534508541815,"user":{"displayName":"Raj Mehrotra","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"116188724100341692953"},"user_tz":-330},"id":"2Ixl2twHlmJX","outputId":"7e1874bd-aa7b-46a7-8cfd-66af73d9cdc7","trusted":false,"_uuid":"f4461f79f991744d3a4c71adf78896b0d1bc441a","collapsed":true},"cell_type":"code","source":"count=0\nfig,ax=plt.subplots(3,2)\nfig.set_size_inches(10,10)\nfor i in range (3):\n    for j in range (2):\n        ax[i,j].imshow(x_test[mis_class[count]].reshape(28,28),cmap='gray')\n        ax[i,j].set_title(\"Predicted Label : \"+str(pred_digits[mis_class[count]])+\"\\n\"+\"Actual Label : \"+str(np.argmax(y_test[mis_class[count]])))\n        plt.tight_layout()\n        count+=1\n        ","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"183H69NOlmJh","_uuid":"6d8ba1670fe3ad0496a846f82e9c7620f0ecafab"},"cell_type":"markdown","source":"<a id=\"content7\"></a>\n## 7 ) Making Submission to KaggleÂ¶"},{"metadata":{"colab":{},"colab_type":"code","id":"yukFjZvVlmJi","trusted":false,"_uuid":"ff6b598259c117532c30e09214f3af9fe77f61b8","collapsed":true},"cell_type":"code","source":"pred_digits_test=np.argmax(model.predict(num_test),axis=1)\nimage_id_test=[]\nfor i in range (len(pred_digits_test)):\n    image_id_test.append(i+1)\nd={'ImageId':image_id_test,'Label':pred_digits_test}\nanswer=pd.DataFrame(d)\nanswer.to_csv('answer.csv',index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"colab_type":"text","id":"KKT6LaE8lmKA","_uuid":"a7e356618ea51ab3ddffdfcfa3b7a3baecd928aa"},"cell_type":"markdown","source":"# THE END."},{"metadata":{"colab_type":"text","id":"e89iRZVclmKC","_uuid":"409d4353061f5e6e4f80010ed65552b914bcc643"},"cell_type":"markdown","source":"## [Please star/upvote if u like it.]"},{"metadata":{"colab":{},"colab_type":"code","id":"6gjb7nFFlmKC","trusted":false,"_uuid":"c04cb61c9e7d6fcae4ee34cf0f03f3fd95d78075","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["RJegJNGUlmEr","me0vRNZ3lmHn","ZAIQ1Dl0lmHz","KyCRhm0BlmIj"],"name":"digit-recognizer-cnn.ipynb","provenance":[],"version":"0.3.2"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}