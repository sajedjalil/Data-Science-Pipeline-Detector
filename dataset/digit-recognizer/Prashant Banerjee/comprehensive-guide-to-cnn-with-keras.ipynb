{"cells":[{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0\"></a>\n# Comprehensive Guide to CNN with Keras\n\n\nHello friends,\n\n\nIn this kernel, I discuss **Convolutional Neural Network**. A convolutional neural network **(CNN or ConvNet)** for short, is a class of deep neural networks, most commonly applied to image classification and computer vision problems.\n\nAlso, I have built a simple CNN model with MNIST digits.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**I hope you find this kernel useful and your <font color=\"red\"><b>UPVOTES</b></font> would be very much appreciated**.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0.1\"></a>\n# Table of Contents\n\n\n1. [Introduction to Convolutional Neural Network](#1)\n1. [Basic terminology of CNN](#2)\n1. [What is Convolution](#3)\n1. [Building blocks of CNN](#4)\n1. [Elements of a CNN model](#5)\n1. [Basic CNN model](#6)\n1. [Training and evaluation of the model](#7)\n1. [Hyperparameters of the convolutional layer](#8)\n1. [Results and conclusion](#9)\n1. [References](#10)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 1. Introduction to Convolutional Neural Network (CNN) <a class=\"anchor\" id=\"1\"></a>\n\n[Back to Table of Contents](#0.1)\n\n\n- In deep learning, a **convolutional neural network (CNN or ConvNet)** is a class of deep neural networks.\n\n- CNNs, like neural networks, are made up of neurons with learnable weights and biases. Each neuron receives several inputs, takes a weighted sum over them, pass it through an activation function and responds with an output. \n\n- The whole network has a loss function and all the basics for neural networks will apply on CNNs as well.\n\n- A convolutional neural network (CNN) consists of an input and an output layer, as well as multiple hidden layers.\n\n- The hidden layers of a CNN typically consist of a series of convolutional layers that convolve with a multiplication or other dot product. \n\n- The activation function is commonly a RELU layer, and is subsequently followed by additional convolutions such as pooling layers, fully connected layers and normalization layers, referred to as hidden layers because their inputs and outputs are masked by the activation function and final convolution. \n\n- The final convolution, in turn, often involves backpropagation in order to more accurately weight the end product.\n\n- CNNs have wide variety of applications in image and video recognition, recommender systems and natural language processing. \n\n- For detailed discussion on CNN, please visit:\n\n[Convolutional Neural Network](https://en.wikipedia.org/wiki/Convolutional_neural_network)\n\n\n[CNN-Overview](http://cs231n.github.io/convolutional-networks/#overview)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## CNNs operate over images\n\n\n- Unlike neural networks, where the input is a vector, in CNNs the input is a multi-channeled image (3 channeled) as shown in the figure below:\n\n![Input tensor for CNN](https://miro.medium.com/max/261/1*C55kkMQHSE1x9p2LdMf-DQ.png)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 2. Basic terminology of CNN <a class=\"anchor\" id=\"2\"></a>\n\n\n[Back to Table of Contents](#0.1)\n\n- We should be aware of some basic terminology regarding CNN. These are as follows:-","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 2.1 Filters <a class=\"anchor\" id=\"2.1\"></a>\n\n- CNN’s make use of filters to detect what features, such as edges, are present throughout an image. \n\n- A **filter** is just a matrix of values, called weights, that are trained to detect specific features. \n\n- The filter moves over each part of the image to check if the feature it is meant to detect is present. \n\n- To provide a value representing how confident it is that a specific feature is present, the filter carries out a convolution operation, which is an element-wise product and sum between two matrices.\n\n- When the feature is present in part of an image, the convolution operation between the filter and that part of the image results in a real number with a high value. If the feature is not present, the resulting value is low.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 2.2 Convolutional <a class=\"anchor\" id=\"2.2\"></a>\n\n- When programming a CNN, each convolutional layer within a neural network should have the following attributes:\n\n  - Input is a tensor with shape (number of images) x (image width) x (image height) x (image depth).\n  \n  - Convolutional kernels whose width and height are hyper-parameters, and whose depth must be equal to that of the image. \n\n- Convolutional layers convolve the input and pass its result to the next layer.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 2.3 Pooling <a class=\"anchor\" id=\"2.3\"></a>\n\n- Convolutional networks may include local or global pooling layers to streamline the underlying computation. \n\n- Pooling layers reduce the dimensions of the data by combining the outputs of neuron clusters at one layer into a single neuron in the next layer. \n\n- Local pooling combines small clusters, typically 2 x 2. Global pooling acts on all the neurons of the convolutional layer. \n\n- In addition, pooling may compute a max or an average. Max pooling uses the maximum value from each of a cluster of neurons at the prior layer. Average pooling uses the average value from each of a cluster of neurons at the prior layer.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 2.4 Fully connected <a class=\"anchor\" id=\"2.4\"></a>\n\n- Fully connected layers connect every neuron in one layer to every neuron in another layer. \n\n- It is in principle the same as the traditional multi-layer perceptron neural network (MLP). \n\n- The flattened matrix goes through a fully connected layer to classify the images.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 2.5 Receptive field <a class=\"anchor\" id=\"2.5\"></a>\n\n- In neural networks, each neuron receives input from some number of locations in the previous layer. In a fully connected layer, each neuron receives input from every element of the previous layer. \n\n- In a convolutional layer, neurons receive input from only a restricted subarea of the previous layer. Typically the subarea is of a square shape (e.g., size 5 by 5). The input area of a neuron is called its **receptive field**. \n\n- So, in a fully connected layer, the receptive field is the entire previous layer. In a convolutional layer, the receptive area is smaller than the entire previous layer.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 2.6 Weights <a class=\"anchor\" id=\"2.6\"></a>\n\n- Each neuron in a neural network computes an output value by applying a specific function to the input values coming from the receptive field in the previous layer. \n\n- The function that is applied to the input values is determined by a vector of weights and a bias (typically real numbers). Learning, in a neural network, progresses by making iterative adjustments to these biases and weights.\n\n- The vector of weights and the bias are called filters and represent particular features of the input (e.g., a particular shape). \n\n- A distinguishing feature of CNNs is that many neurons can share the same filter. This reduces memory footprint because a single bias and a single vector of weights are used across all receptive fields sharing that filter, as opposed to each receptive field having its own bias and vector weighting.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## 2.7 Strides <a class=\"anchor\" id=\"2.7\"></a>\n\n- **Strides** is the number of pixels shifts over the input matrix. \n\n- When the stride is 1 then we move the filters to 1 pixel at a time. \n\n- When the stride is 2 then we move the filters to 2 pixels at a time and so on.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 2.8 Padding <a class=\"anchor\" id=\"2.8\"></a>\n\n- In CNNs, we can also apply a technique of filling zeros around the margin of the image to improve the sweep that is done with the sliding window. The parameter to define this technique is called “padding”\n\n- In CNNs, sometimes filter does not perfectly fit the input image. In this case, we have two options:\n\n  - We can apply a technique of filling zeros around the margin of the image so that it fits the input image perfectly. This is called **zero-padding** where we pad the gaps with zeros.\n  \n  - Another option is to drop the part of the image where the filter does not fit the image perfectly. This is called **valid padding** which keeps only valid part of the image.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 3. What is Convolution <a class=\"anchor\" id=\"3\"></a>\n\n[Back to Table of Contents](#0.1)\n\n\n- Convolutional neural networks are simple neural networks that use convolution in place of general matrix multiplication in at least one of their layers.\n\n- The name `convolutional neural network` indicates that the network employs a mathematical operation called convolution.\n\n- Convolution is a specialized kind of linear operation. In mathematics, convolution is a mathematical operation on two functions (f and g) that produces a third function expressing how the shape of one is modified by the other. \n\n- The term **convolution** refers to both the result function and to the process of computing it. It is defined as the integral of the product of the two functions after one is reversed and shifted.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- **Convolution** is explained visually as follows:","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![Filter with dimensions 5*5*3](https://miro.medium.com/max/390/1*FUEkm0JghT3ab8P7p9c5Qg.png)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- In the above plot, we take the 5x5x3 filter and slide it over the complete image and along the way take the dot product between the filter and chunks of the input image.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![Convolution Operation](https://miro.medium.com/max/811/1*3sfzVenrdS5MWGsmSCbx3A.png)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- For every dot product taken, the result is a scalar.\n\n- Now, we convolve the complete image with the filter as shown below.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![Convolution Operation](https://miro.medium.com/max/764/1*mcBbGiV8ne9NhF3SlpjAsA.png)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 4. Basic building blocks of CNN <a class=\"anchor\" id=\"4\"></a>\n\n[Back to Table of Contents](#0.1)\n\n\n- A simple CNN is a sequence of layers, and every layer of a CNN transforms one volume of activations to another through a differentiable function. \n\n- We use three main types of layers to build CNN architectures - **Convolutional Layer**, **Pooling Layer**, and **Fully-Connected Layer**. We will stack these layers to form a full CNN architecture.\n\n- There are two other layers - **ReLU Layer** and **Loss Layer** that are also used to build a CNN. These layers are described below:\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 4.1 Convolutional layer  <a class=\"anchor\" id=\"4.1\"></a>\n\n- The convolutional layer is the core building block of a CNN. The layer's parameters consist of a set of learnable filters (or kernels), which have a small receptive field, but extend through the full depth of the input volume. \n\n- During the forward pass, each filter is convolved across the width and height of the input volume, computing the dot product between the entries of the filter and the input and producing a 2-dimensional activation map of that filter. \n\n- As a result, the network learns filters that activate when it detects some specific type of feature at some spatial position in the input.\n\n- Stacking the activation maps for all filters along the depth dimension forms the full output volume of the convolution layer. \n\n- Every entry in the output volume can thus also be interpreted as an output of a neuron that looks at a small region in the input and shares parameters with neurons in the same activation map.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 4.2 Pooling layer <a class=\"anchor\" id=\"4.2\"></a>\n\n- Another important concept of CNNs is pooling, which is a form of non-linear down-sampling. There are several non-linear functions to implement pooling among which `max pooling` is the most common. It partitions the input image into a set of non-overlapping rectangles and for each such sub-region, outputs the maximum.\n\n- Intuitively, the exact location of a feature is less important than its rough location relative to other features. This is the idea behind the use of pooling in convolutional neural networks. \n\n- The pooling layer serves to progressively reduce the spatial size of the representation, to reduce the number of parameters, memory footprint and amount of computation in the network, and hence to also control overfitting. It is common to periodically insert a pooling layer between successive convolutional layers in a CNN architecture.\n\n- The pooling layer operates independently on every depth slice of the input and resizes it spatially. The most common form is a pooling layer with filters of size 2×2 applied with a stride of 2 downsamples at every depth slice in the input by 2 along both width and height, discarding 75% of the activations. In this case, every max operation is over 4 numbers. The depth dimension remains unchanged.\n\n- In addition to max pooling, pooling units can use other functions, such as average pooling or ℓ2-norm pooling.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 4.3 ReLU layer <a class=\"anchor\" id=\"4.3\"></a>\n\n\n- **ReLU** is the abbreviation of **Rectified Linear Unit**, which applies the non-saturating activation function.\n\n- It is given by the following formula f(x) = max(0,x).\n\n- It effectively removes negative values from an activation map by setting them to zero.\n\n- It increases the nonlinear properties of the decision function and of the overall network without affecting the receptive fields of the convolution layer.\n\n- ReLU is often preferred to other functions because it trains the neural network several times faster without a significant penalty to generalization accuracy.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 4.4 Fully connected layer <a class=\"anchor\" id=\"4.4\"></a>\n\n\n- Finally, after several convolutional and max pooling layers, the high-level reasoning in the neural network is done via fully connected layers. \n\n- Neurons in a fully connected layer have connections to all activations in the previous layer, as seen in regular (non-convolutional) artificial neural networks. \n\n- Their activations can thus be computed as an affine transformation, with matrix multiplication followed by a bias offset (vector addition of a learned or fixed bias term).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## 4.5 Loss layer <a class=\"anchor\" id=\"4.5\"></a>\n\n- The **loss layer** specifies how training penalizes the deviation between the predicted (output) and true labels and is normally the final layer of a neural network. Various loss functions are appropriate for different tasks may be used.\n\n- **Softmax loss** is used for predicting a single class of K mutually exclusive classes. \n\n- **Sigmoid cross-entropy loss** is used for predicting K independent probability values in [0,1]. \n\n- **Euclidean loss** is used for regressing to real-valued labels (-∞,∞).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 5. Elements of a CNN model <a class=\"anchor\" id=\"5\"></a>\n\n[Back to Table of Contents](#0.1)\n\n\n- Enough of theory, now its time to see CNN in action.\n\n- We will see how the convolutional neural network can be programmed with Keras using MNIST dataset.\n\n- There are several values to be specified in order to parameterize the convolution and pooling stages. \n\n- In this case, we will use a simplified model with a stride of 1 in each dimension (**stride** is the size of the step with which the window slides) and a padding of 0 (**padding** is the filling with zeros around the image). Both these hyperparameters will be presented below. \n\n- The **pooling operation** will be a max-pooling operation with a 2×2 window.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- So, our CNN model will consist of a convolution followed by a max-pooling. \n\n- In this case, we will have 32 filters using a 5×5 window for the convolutional layer and a 2×2 window for the pooling layer. \n\n- We will use the ReLU activation function. \n\n- In this case, we are configuring a convolutional neural network to process an input tensor of size (28, 28, 1), which is the size of the MNIST images (the third parameter is the color channel which in our case is depth 1), and we specify it by means of the value of the argument input_shape = (28, 28,1) in our first layer:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import layers\nfrom keras import models\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (5,5), activation = 'relu', input_shape= (28,28,1)))\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Description of parameters\n\n- The number of parameters of the conv2D layer corresponds to the weight matrix W of 5×5 and a b bias for each of the filters is 832 parameters (32 × (25 + 1)). \n\n- Max-pooling does not require parameters since it is a mathematical operation to find the maximum.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 6. Basic CNN model <a class=\"anchor\" id=\"6\"></a>\n\n[Back to Table of Contents](#0.1)\n\n\n- Now, we will build a basic CNN model. We will stack several layers to build the model.\n\n- We will create a second group of layers that will have 64 filters with a 5×5 window in the convolutional layer and a 2×2 window in the pooling layer. \n\n- In this case, the number of input channels will take the value of the 32 features that we have obtained from the previous layer.\n\n\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.Sequential()\nmodel.add(layers.Conv2D(32, (5,5), activation = 'relu', input_shape=(28,28,1)))\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.add(layers.Conv2D(64, (5,5), activation = 'relu'))\nmodel.add(layers.MaxPooling2D((2,2)))\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Description of parameters\n\n- In this case, the size of the resulting second convolution layer is 8×8 since we now start from an input space of 12×12×32 and a sliding window of 5×5, taking into account that it has a stride of 1. \n\n- The number of parameters 51,264 corresponds to the fact that the second layer will have 64 filters (as we have specified in the argument), with 801 parameters each (1 corresponds to the bias, and a W matrix of 5×5 for each of the 32 entries). That means ((5 × 5 × 32) +1) × 64 = 51264.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- The next step, now that we have 64 4x4 filters, is to add a densely connected layer, which will serve to feed a final layer of softmax activation function with the following code snippet:\n\n`model.add(layers.Dense(10, activation='softmax'))`","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- In this example, we have to adjust the tensors to the input of the dense layer like the softmax, which is a 1D tensor, while the output of the previous one is a 3D tensor. So, we will first flatten the 3D tensor to one of 1D. \n\n- Our output (4,4,64) must be flattened to a vector of (1024) before applying the Softmax with the following code snippet:\n\n`model.add(layers.Flatten())`\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- So, our final model becomes:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.Sequential()\n\nmodel.add(layers.Conv2D(32,(5,5),activation='relu', input_shape=(28,28,1)))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(64, (5, 5), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(10, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### View the model summary\n\n- We can view the summary of the model with the `summary()` method.\n\n- With the `summary()` method, we can see this information about the parameters of each layer and shape of the output tensors of each layer.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visual representation of the model\n\n- A visual representation of the above information is shown in the following figure, where we see a graphic representation of the shape of the tensors that are passed between layers and their connections.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"![Visual representation of the model](https://miro.medium.com/max/772/1*CKgnKTEITrPKaDiG_536Mg.png)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 7. Training and evaluation of the model <a class=\"anchor\" id=\"7\"></a>\n\n[Back to Table of Contents](#0.1)\n\n\n- Now that we have built our CNN model, its time to train it. \n\n- It means to adjust the parameters of all the convolutional layers.\n\n- Training can be done as follows:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.datasets import mnist\nfrom keras.utils import to_categorical\n\n\n(train_images, train_labels), (test_images, test_labels) = mnist.load_data()  \n                              \n    \ntrain_images = train_images.reshape((60000, 28, 28, 1))\ntrain_images = train_images.astype('float32') / 255\n\n\ntest_images = test_images.reshape((10000, 28, 28, 1))\ntest_images = test_images.astype('float32') / 255\n\n\ntrain_labels = to_categorical(train_labels)\ntest_labels = to_categorical(test_labels)\n\n\nbatch_size = 100\nepochs = 10\n\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='sgd',\n              metrics=['accuracy'])\n\n\n\nmodel.fit(train_images, train_labels,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Now, its time to evaluate the model. Model evaluation can be done as follows:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss, test_acc = model.evaluate(test_images, test_labels)\n\nprint('Test loss:', test_loss)\nprint('Test accuracy:', test_acc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 8. Hyperparameters of the convolution layer <a class=\"anchor\" id=\"8\"></a>\n\n\n[Back to Table of Contents](#0.1)\n\n\n- There are three main hyperparameters of the CNN model. These are as follows: \n\n  - the size and number of the filters window, \n  \n  - the padding, and \n  \n  - the stride.\n  \n  \n  \n - I will describe these hyperparameters below:","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Size and number of filters\n\n\n- The size of the window `(window_height × window_width)` that holds information from spatially close pixels is usually 3×3 or 5×5. The number of filters that tells us the number of characteristics that we want to handle (output_depth) is usually 32 or 64. \n\n- In the Conv2D layers of Keras, these hyperparameters are what we pass as arguments in this order:\n\n**Conv2D(output_depth, (window_height, window_width))**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Padding\n\n- Padding is the technique of filling zeros around the margin of the image to improve the sweep that is done with the sliding window. The parameter to define this technique is called `padding`.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Stride\n\n- **Strides** is the number of pixels shifts over the input matrix. \n\n- When the stride is 1 then we move the filters to 1 pixel at a time. \n\n- When the stride is 2 then we move the filters to 2 pixels at a time and so on.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 9. Results and conclusion <a class=\"anchor\" id=\"9\"></a>\n\n[Back to Table of Contents](#0.1)\n\n\n- We can see that in the convolutional layers, where more memory is required and, therefore, more computation to store the data is needed. \n\n- In contrast, in the densely connected layer of softmax, little memory space is needed. But, in comparison, the model requires numerous parameters which must be learned. \n\n- It is important to be aware of the sizes of the data and the parameters because, when we have models based on convolutional neural networks, they have many layers, and these values can shoot exponentially.\n\n- Our CNN model offers an accuracy of approximately 98%.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# 10. References <a class=\"anchor\" id=\"10\"></a>\n\n[Back to Table of Contents](#0.1)\n\n\nThe concepts and ideas are taken from the following books and websites:\n\n\n- [Convolutional Neural Network](https://en.wikipedia.org/wiki/Convolutional_neural_network)\n\n- [CNN Overview](http://cs231n.github.io/convolutional-networks/#overview)\n\n- Deep Learning with Python by Francois Chollet\n\n- Advanced Deep Learning with Keras by Rowel Atienza\n\n","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"markdown","source":"So, now we will come to the end of this kernel.\n \nI hope you find this kernel useful and enjoyable.\n\nThank you\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"[Go to Top](#0)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}