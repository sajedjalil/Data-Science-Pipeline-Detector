{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### This solution made without pretrained models and additional datasets","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nimport torchvision as thv\nimport random\nfrom tqdm.notebook import tqdm\nimport copy\nimport numpy as np\nimport pandas as pd\nimport collections\nimport matplotlib.pyplot as plt\nfrom IPython.display import FileLink","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we are fixing ALL of the randomnesses for each restart.","metadata":{}},{"cell_type":"code","source":"def setSeed(x):\n  random.seed(x)\n  np.random.seed(x)\n  torch.manual_seed(x)\n  torch.cuda.manual_seed(x)\n  torch.backends.cudnn.deterministic = True\n\nsetSeed(2)\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') # using gpu if available\ndevice","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Copying the .csv files to the `pandas.DataFrame`<br>\n<br>\nLinks: [`pandas.DataFrame`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)","metadata":{}},{"cell_type":"code","source":"mnist_test = pd.read_csv(\"../input/digit-recognizer/test.csv\")\nmnist_train = pd.read_csv(\"../input/digit-recognizer/train.csv\")\nmnist_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can implement `torch.utils.data.Dataset` with our data type, so we can use an automatic `DataLoader`.<br>\nIt's not necessary, because you can do a batch split manually, but still, it's good to use.<br>\n<br>\nLinks: [`unsqueeze`](https://pytorch.org/docs/stable/generated/torch.unsqueeze.html), [datasets and dataloader tutorial](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)","metadata":{}},{"cell_type":"code","source":"class Dataset(torch.utils.data.Dataset):\n  def __init__(self, images, targets, transforms=None):\n        self.targets = targets # This tensor contains numbers from 0 to 9, which are the answers\n        # We need to add a channel dimension for all of the images\n        # Also, we can normalize pixel values from 0..255 to 0..1. This will speed up the training process\n        self.images = images.unsqueeze(1) / 255\n        self.transforms = transforms # We will catch up this later\n\n  def __len__(self):\n        return len(self.targets)\n\n  def __getitem__(self, i):\n        # if the transforms are set up - use it\n        if self.transforms:\n            x = self.transforms(self.images[i])\n        else:\n            x = self.images[i]\n        return x, self.targets[i]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we need to extract the data from the `pandas.DataFrame` to the `torch.Tensor`.<br>\n`torch.utils.data.random_split` will return us two `torch.Subset`, which we will use for the train and validation.<br>\nYou need to understand, that the `subset.dataset` contains **whole** dataset as `pandas.DataFrame`.<br>\n`subset.dataset.iloc[subset.indices]` will return us a dataframe that will contain only wanted values.<br>\nIn this dataframe, the first row will be our target, and the others - pixel information.","metadata":{}},{"cell_type":"code","source":"def extractData(subset):\n    # extract subset\n    df = subset.dataset.iloc[subset.indices]\n    # extract pixel information and transform every image to 28x28 tensor (from 784 pixels in a row)\n    x = torch.from_numpy(df.values[:, 1:]).reshape(-1, 28, 28).to(torch.float)\n    # extract target and covert it to torch.long type tensor\n    y = torch.from_numpy(df.values[:, 0]).to(torch.long)\n    return x, y\n\ndef splitData(dataframe):\n    # 1/6 of all our data will be reserved for the validation\n    val_n = len(dataframe) // 6\n    mnist_train, mnist_val = torch.utils.data.random_split(dataframe, [len(dataframe) - val_n, val_n])\n    \n    return extractData(mnist_train), extractData(mnist_val)\n\n(x_train, y_train), (x_val, y_val) = splitData(mnist_train)\n# our test doesn't have answers, so the dataframe contains only pictures\nx_test = torch.Tensor(mnist_test.values).reshape(-1, 28, 28)\nprint(x_train.shape, y_train.shape)\nprint(x_val.shape, y_val.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's look at the first image and its target from the train subset<br>\n`.item()` returns a value of the tensor with one element","metadata":{}},{"cell_type":"code","source":"plt.imshow(x_train[0, :, :])\nplt.xlabel(y_train[0].item())\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"35000 images for the training are good, but we can do better. Let's do some *data augmentation*.<br>\nWe will use `torchvision.transforms` to do so. First, we will randomly rotate the image by -10..10 degrees.<br>\nAfter that, we will apply a tiny random blur to it.<br>\nThis will increase the overall amount of pictures that our net will see.<br>\n<br>\nLinks: [`torchvision.transforms`](https://pytorch.org/vision/stable/transforms.html)","metadata":{}},{"cell_type":"code","source":"transforms = torch.nn.Sequential(\n    # without this \"deprecated\" resample scripted_transforms crashes in this kernel. Should be removed in the newer versions\n    thv.transforms.RandomRotation(10, resample=0),\n    thv.transforms.GaussianBlur(3, sigma=(0.0001, 0.3)),\n)\n\n# This will speed up transformation\nscripted_transforms = torch.jit.script(transforms)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see what these transforms do.","metadata":{}},{"cell_type":"code","source":"plt.imshow(scripted_transforms(x_train)[0])\nplt.xlabel(y_train[0].item())\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creating train set and validation set","metadata":{}},{"cell_type":"code","source":"trainset = Dataset(x_train, y_train, scripted_transforms)\nvalset = Dataset(x_val, y_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creating data loaders with our datasets. Train loader will automatically give us shuffled batches.","metadata":{}},{"cell_type":"code","source":"# num workers used to paralell computations\ntrain_loader = DataLoader(trainset, batch_size=200, shuffle=True, num_workers=2)\nval_loader = DataLoader(valset, batch_size=200, shuffle=False, num_workers=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we need to create the model. I will use a convolutional neural network (CNN)<br>\nIt can be easily understood on the LeNet5 example (check links).<br>\nApart from that, we will use some more specific layers:\n* `nn.BatchNorm` will normalize the data from the previous layers. It will speed up our net.\n* `nn.Dropout(0.25)` will turn off each neuron from the previous layer with a 25% chance. It will help us with the overfitting.\n\nNotice that I don't use softmax at the end, because I don't need to have probabilities for each class. It will reduce unnecessary computations.<br>\n<br>\nLinks: [LeNet5](https://towardsdatascience.com/understanding-and-implementing-lenet-5-cnn-architecture-deep-learning-a2d531ebc342), [BatchNorm and Dropout explanation](https://towardsdatascience.com/batch-normalization-and-dropout-in-neural-networks-explained-with-pytorch-47d7a8459bcd), [BatchNorm docs](https://pytorch.org/docs/stable/nn.html#normalization-layers), [Dropout docs](https://pytorch.org/docs/stable/nn.html#dropout-layers)","metadata":{}},{"cell_type":"code","source":"class Net(torch.nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        \n        self.conv1 = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(num_features=64, eps=1e-05, momentum=0.1),\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(num_features=64, eps=1e-05, momentum=0.1),\n            nn.ReLU(),\n\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(num_features=64, eps=1e-05, momentum=0.1),\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(num_features=64, eps=1e-05, momentum=0.1),\n            nn.ReLU(),\n\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Dropout2d(0.25),\n        )\n       \n        self.conv2 = nn.Sequential(\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(num_features=64, eps=1e-05, momentum=0.1),\n            nn.ReLU(),\n\n            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(num_features=64, eps=1e-05, momentum=0.1),\n            nn.ReLU(),\n\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Dropout2d(0.25),\n        )\n        \n        self.fc1 = nn.Sequential(\n            nn.Dropout(0.25),\n            nn.Linear(7 * 7 * 64, 256),\n            nn.BatchNorm1d(num_features=256, eps=1e-05, momentum=0.1),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n        )\n        \n        self.fc2 = nn.Sequential(\n            nn.Dropout(0.25),\n            nn.Linear(256, 10),\n        )\n    \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        \n        # Flatten the 3 last dimensions (channels, width, height) to one\n        x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n        \n        x = self.fc1(x)\n        x = self.fc2(x)\n        \n        return x\n\n# move the net to gpu if available\nnet = Net().to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"`CrossEntropy` is a common lost function for the classification task.<br>\n`RMSprop` is not that easy to understand, so I'll just leave a link. But still, you can use other optimizers, maybe they will improve the quality.<br>\n`ReduceLROnPlateau` will reduce the optimizer's learning rate during the training process.<br>\nWhen the validation loss doesn't change for the `patience` amount of epochs, the learning rate multiplies by the `factor`. The `threshold` sets the needed delta between losses.<br>\n<br>\nLinks: [`CrossEntropy docs`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss), [`RMSprop explanation`](https://towardsdatascience.com/understanding-rmsprop-faster-neural-network-learning-62e116fcf29a), [`optimizators and schedulers in PyTorch docs`](https://pytorch.org/docs/stable/optim.html), ","metadata":{}},{"cell_type":"code","source":"loss = nn.CrossEntropyLoss()\noptimizer = torch.optim.RMSprop(net.parameters(), lr=1e-3, alpha=0.99)\n# verbose=True will print learning rate changes\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, threshold=0.0001, patience=3, verbose=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we need to create a training function, which will return us loss and accuracy histories. Also, it will return the final net, and the best loss and accuracy net.<br>\nWhen we do `net.eval()`, it will block dropout layers and fix batch normalization layers. It's very important, don't forget about it!","metadata":{}},{"cell_type":"code","source":"def train_model(net, loss, optimizer, scheduler, num_epochs):\n    \n    loss_hist = {'train': [], 'val': []}\n    acc_hist = {'train': [], 'val': []}\n    \n    for epoch in range(num_epochs):\n        for phase in ['train', 'val']:\n            # choose dataloader and net mode based on phase\n            if phase == 'train': \n                dataloader = train_loader\n                net.train()\n            else:\n                dataloader = val_loader \n                net.eval()\n\n            # this will accumulate loss and accuracy\n            running_loss = 0. \n            running_acc = 0.\n            \n            # this will accumulate loss and accuracy\n            best_loss = 100.\n            best_acc = 0.\n            \n            # this will contain the best nets\n            best_loss_net = None\n            best_acc_net = None\n\n            # tqdm provides the progress bar for the loop\n            with tqdm(dataloader, unit='batch') as tepoch:\n                # print the current epoch and phase\n                tepoch.set_description(f'Epoch {epoch + 1}/{num_epochs}, {phase:5} phase') # seems like tqdm.notebook.tqdm drops repeatable spaces :(\n                \n                # iterate the dataloader (one iteration - one batch, which is 200 items)\n                for images, targets in tepoch:\n                    # transfer all data to gpu if possible\n                    images, targets = images.to(device), targets.to(device)\n\n                    # PyTorch accumulates tensor's gradient. We need to set it to zero at every batch.\n                    optimizer.zero_grad()\n\n                    # We don't need to calculate gradients at the validation phase. It will give us a significant speed boost.\n                    with torch.set_grad_enabled(phase == 'train'):\n                        # making predictions\n                        preds = net(images)\n                        # calculate loss value\n                        loss_value = loss(preds, targets)\n                        # choose the class with maximum value for each image. It will be an answer.\n                        preds_class = preds.argmax(dim=1)\n                        if phase == 'train':\n                            # calculate gradients\n                            loss_value.backward()\n                            # make the optimizer's step\n                            optimizer.step()\n\n                    # accumulate loss and accuracy\n                    running_loss += loss_value.item()\n                    # all true predictions become 1, others - 0. Calculating mean of this tensor will give us the accuracy\n                    running_acc += (preds_class == targets.data).float().mean().item()\n                    \n                \n                # divide our accumulators by the amount of the batches\n                # so we receive the mean value of loss and accuracy\n                epoch_loss = running_loss / len(dataloader)\n                epoch_acc = running_acc / len(dataloader)\n                \n                # update out history\n                loss_hist[phase].append(epoch_loss)\n                acc_hist[phase].append(epoch_acc)\n                \n                if phase == 'val':\n                    # make a scheduler's step based on epoch's validation loss\n                    scheduler.step(epoch_loss)\n                    \n                    # remember best models\n                    if epoch_loss < best_loss:\n                        best_loss = epoch_loss\n                        # this will create us a copy of the network\n                        best_loss_net = copy.deepcopy(net)\n\n                    if epoch_acc > best_acc:\n                        best_acc = epoch_acc\n                        best_acc_net = copy.deepcopy(net)\n                        \n                # print epoch's accuracy and loss\n                tepoch.set_postfix(loss=f'{epoch_loss:.5f}', accuracy=f'{epoch_acc:.5f}')\n                \n    print(best_acc, best_loss)\n    return best_loss_net, best_acc_net, net, loss_hist, acc_hist","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_loss_net, best_acc_net, net, loss_hist, acc_hist = train_model(net, loss, optimizer, scheduler, 40)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's print loss and accuracy histories","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14, 7))\nfor phase in acc_hist.keys():\n    plt.plot(acc_hist[phase], label=phase)\nplt.legend(loc='upper left')\nplt.title('Accuracy')\nplt.xlabel('Epoch', fontsize=14)\nplt.grid()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (14, 7))\nfor phase in loss_hist.keys():\n    plt.plot(loss_hist[phase], label=phase)\nplt.legend(loc='upper left')\nplt.title('Loss')\nplt.xlabel('Epoch', fontsize=14)\nplt.grid()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see on the plots, we don't really face overfitting. But still, this net doesn't give us the best results.<br>\nYou can try different parameters, optimizers, schedulers, etc., which might improve accuracy.","metadata":{}},{"cell_type":"markdown","source":"Let's see which pictures this net recognizes incorrectly.","metadata":{}},{"cell_type":"code","source":"best_acc_net = best_loss_net.to(device)\nbest_acc_net.eval()\npreds_class = np.array([], dtype=int)\n\nwith torch.no_grad():\n    for images, _ in val_loader:\n        preds = best_acc_net(images.to(device))\n        preds = preds.cpu() # only cpu tensor can be converted to the numpy array\n        preds_class = np.append(preds_class, preds.argmax(dim=1))\n\n# this will return bool mask array\nerrors = (y_val.numpy() != preds_class)\n\ndef draw_errors(x_val, y_val, preds_class, errors):\n    # check only error's indicies\n    x_val, y_val, preds_class = x_val[errors], y_val[errors], preds_class[errors]\n    cols = 6\n    fig, ax = plt.subplots(1, cols, sharex=True)\n    fig.set_size_inches(20, 10)\n    for col in range(cols):\n        ax[col].imshow(x_val[col])\n        ax[col].set_title(f'Predicted  {preds_class[col]}\\nTrue: {y_val[col]}')\n\ndraw_errors(x_val, y_val, preds_class, errors)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we need to create dataloader for the test data. Same as for the train, but only with images.","metadata":{}},{"cell_type":"code","source":"class TestDataset(torch.utils.data.Dataset):\n  def __init__(self, images):\n        self.images = images.unsqueeze(1).to(device) / 255\n\n  def __len__(self):\n        return len(self.images)\n\n  def __getitem__(self, i):\n        return self.images[i]\n    \n    \ntestset = TestDataset(x_test)\ntest_loader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Calculating predictions on the best accuracy model","metadata":{}},{"cell_type":"code","source":"preds_class = np.array([], dtype=int)\n\nwith torch.no_grad():\n    for images in test_loader:\n        preds = best_acc_net(images.to(device)).cpu() # only cpu tensor can be converted to the numpy array\n        preds_class = np.append(preds_class, preds.argmax(dim=1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creating dataframe like sample_submission.csv","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame({\n    # notice that the sample submission iterates id's from 1\n    'ImageId': np.arange(1, len(preds_class) + 1),\n    'Label': preds_class\n})\n# set the ImageId row as an index\ndf = df.set_index('ImageId')\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we need to create the file and download it","metadata":{}},{"cell_type":"code","source":"# save dataframe to csv\ndf.to_csv('submission.csv')\n# generate download link\nFileLink(r'submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}