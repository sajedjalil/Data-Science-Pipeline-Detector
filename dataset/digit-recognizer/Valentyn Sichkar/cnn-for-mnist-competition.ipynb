{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ðŸ”¢ CNN for MNIST Competition","metadata":{}},{"cell_type":"markdown","source":"# ðŸŽ“ Related course for classification tasks","metadata":{}},{"cell_type":"markdown","source":"**Design**, **Train** & **Test** deep CNN for Image Classification.\n\n**Join** the course & enjoy new opportunities to get deep learning skills:\n\n\n[https://www.udemy.com/course/convolutional-neural-networks-for-image-classification/](https://www.udemy.com/course/convolutional-neural-networks-for-image-classification/?referralCode=12EE0D74A405BF4DDE9B)\n\n\n![](https://github.com/sichkar-valentyn/1-million-images-for-Traffic-Signs-Classification-tasks/blob/main/images/slideshow_classification.gif?raw=true)","metadata":{}},{"cell_type":"markdown","source":"# ðŸ“¥ Importing needed libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom math import sqrt, ceil\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, AvgPool2D, BatchNormalization, Reshape\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-14T17:54:50.504159Z","iopub.execute_input":"2021-06-14T17:54:50.504462Z","iopub.status.idle":"2021-06-14T17:54:50.512208Z","shell.execute_reply.started":"2021-06-14T17:54:50.504409Z","shell.execute_reply":"2021-06-14T17:54:50.511341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸ“‚ Loading data","metadata":{}},{"cell_type":"code","source":"# Loading training data\ndata_train = pd.read_csv(\"../input/train.csv\")\n\n# Showing some data\ndata_train.head()\n","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2021-06-14T17:54:52.970915Z","iopub.execute_input":"2021-06-14T17:54:52.971201Z","iopub.status.idle":"2021-06-14T17:54:56.786281Z","shell.execute_reply.started":"2021-06-14T17:54:52.971157Z","shell.execute_reply":"2021-06-14T17:54:56.785629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting first column with labels\ny_train = data_train['label']\n\n# Dropping column with labels\nx_train = data_train.drop(labels = [\"label\"], axis = 1)\n\n# Showing current shape of training data\nprint('Shape of whole data for training', data_train.shape)  # (42000, 785)\nprint('x_train:', x_train.shape)  # (42000, 784)\nprint('y_train:', y_train.shape)  # (42000,)\n\n# Showing some examples\n%matplotlib inline\n\n# Preparing function for ploting set of examples\n# As input it will take 4D tensor and convert it to the grid\n# Values will be scaled to the range [0, 255]\ndef convert_to_grid(x_input):\n    N, H, W = x_input.shape\n    grid_size = int(ceil(sqrt(N)))\n    grid_height = H * grid_size + 1 * (grid_size - 1)\n    grid_width = W * grid_size + 1 * (grid_size - 1)\n    grid = np.zeros((grid_height, grid_width)) + 255\n    next_idx = 0\n    y0, y1 = 0, H\n    for y in range(grid_size):\n        x0, x1 = 0, W\n        for x in range(grid_size):\n            if next_idx < N:\n                img = x_input[next_idx]\n                low, high = np.min(img), np.max(img)\n                grid[y0:y1, x0:x1] = 255.0 * (img - low) / (high - low)\n                next_idx += 1\n            x0 += W + 1\n            x1 += W + 1\n        y0 += H + 1\n        y1 += H + 1\n\n    return grid\n\n\n# Visualizing some examples of training data\nexamples = np.array(x_train.iloc[:81]).reshape(81, 28, 28)\nprint(examples.shape)  # (81, 28, 28)\n\n# Plotting\nfig = plt.figure()\ngrid = convert_to_grid(examples)\nplt.imshow(grid.astype('uint8'), cmap='gray')\nplt.axis('off')\nplt.gcf().set_size_inches(7, 7)\nplt.title('Some examples of training data', fontsize=24)\nplt.show()\nplt.close()\n\n# Saving plot\nfig.savefig('training_examples.png')\nplt.close()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:54:59.58353Z","iopub.execute_input":"2021-06-14T17:54:59.583848Z","iopub.status.idle":"2021-06-14T17:54:59.937316Z","shell.execute_reply.started":"2021-06-14T17:54:59.583794Z","shell.execute_reply":"2021-06-14T17:54:59.936728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading testing data\nx_test = pd.read_csv(\"../input/test.csv\")\n\n# Showing some data\nx_test.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:55:04.308092Z","iopub.execute_input":"2021-06-14T17:55:04.308398Z","iopub.status.idle":"2021-06-14T17:55:07.068239Z","shell.execute_reply.started":"2021-06-14T17:55:04.308348Z","shell.execute_reply":"2021-06-14T17:55:07.067563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualizing some examples of testing data\nexamples = np.array(x_test.iloc[:81]).reshape(81, 28, 28)\nprint(examples.shape)  # (81, 28, 28)\n\n# Plotting\nfig = plt.figure()\ngrid = convert_to_grid(examples)\nplt.imshow(grid.astype('uint8'), cmap='gray')\nplt.axis('off')\nplt.gcf().set_size_inches(7, 7)\nplt.title('Some examples of testing data', fontsize=24)\nplt.show()\nplt.close()\n\n# Saving plot\nfig.savefig('testing_examples.png')\nplt.close()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:55:09.610458Z","iopub.execute_input":"2021-06-14T17:55:09.61078Z","iopub.status.idle":"2021-06-14T17:55:09.745286Z","shell.execute_reply.started":"2021-06-14T17:55:09.610722Z","shell.execute_reply":"2021-06-14T17:55:09.744625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Making data as numpy array\n# Reshaping training and testing data\nx_train = np.array(x_train).reshape(-1, 28, 28, 1)\nx_test = np.array(x_test).reshape(-1, 28, 28, 1)\n\n# Showing current shape of training and testing data\nprint('x_train:', x_train.shape)  # (42000, 28, 28, 1)\nprint('x_test:', x_test.shape)  # (28000, 28, 28, 1)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:55:25.340529Z","iopub.execute_input":"2021-06-14T17:55:25.340837Z","iopub.status.idle":"2021-06-14T17:55:25.61995Z","shell.execute_reply.started":"2021-06-14T17:55:25.340784Z","shell.execute_reply":"2021-06-14T17:55:25.619252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# âž° Preprocessing data","metadata":{}},{"cell_type":"code","source":"# Preparing datasets for further using\n\n# Preparing function for preprocessing MNIST datasets for further use in classifier\ndef pre_process_mnist(x_train, y_train, x_test):\n    # Normalizing whole data by dividing /255.0\n    x_train = x_train / 255.0\n    x_test = x_test / 255.0  # Data for testing consists of 28000 examples from testing dataset\n\n    # Preparing data for training, validation and testing\n    # Data for validation is taken with 1000 examples from training dataset in range from 41000 to 42000\n    batch_mask = list(range(41000, 42000))\n    x_validation = x_train[batch_mask]  # (1000, 28, 28, 1)\n    y_validation = y_train[batch_mask]  # (1000,)\n    # Data for training is taken with first 41000 examples from training dataset\n    batch_mask = list(range(41000))\n    x_train = x_train[batch_mask]  # (41000, 28, 28, 1)\n    y_train = y_train[batch_mask]  # (41000,)\n\n    # Normalizing data by subtracting mean image and dividing by standard deviation\n    # Subtracting the dataset by mean image serves to center the data\n    # It helps for each feature to have a similar range and gradients don't go out of control\n    # Calculating mean image from training dataset along the rows by specifying 'axis=0'\n    mean_image = np.mean(x_train, axis=0)  # numpy.ndarray (28, 28, 1)\n\n    # Calculating standard deviation from training dataset along the rows by specifying 'axis=0'\n    std = np.std(x_train, axis=0)  # numpy.ndarray (28, 28, 1)\n    # Taking into account that a lot of values are 0, that is why we need to replace it to 1\n    # In order to avoid dividing by 0\n    for j in range(28):\n        for i in range(28):\n            if std[i, j, 0] == 0:\n                std[i, j, 0] = 1.0\n\n    # Subtracting calculated mean image from pre-processed datasets\n    x_train -= mean_image\n    x_validation -= mean_image\n    x_test -= mean_image\n\n    # Dividing then every dataset by standard deviation\n    x_train /= std\n    x_validation /= std\n    x_test /= std\n    \n    # Preparing y_train and y_validation for using in Keras\n    y_train = to_categorical(y_train, num_classes=10)\n    y_validation = to_categorical(y_validation, num_classes=10)\n\n    # Returning result as dictionary\n    d_processed = {'x_train': x_train, 'y_train': y_train,\n                   'x_validation': x_validation, 'y_validation': y_validation,\n                   'x_test': x_test}\n\n    # Returning dictionary\n    return d_processed\n\n\n# Preprocessing data\ndata = pre_process_mnist(x_train, y_train, x_test)\nfor i, j in data.items():\n    print(i + ':', j.shape)\n\n# x_train: (41000, 28, 28, 1)\n# y_train: (41000, 10)\n# x_validation: (1000, 28, 28, 1)\n# y_validation: (1000, 10)\n# x_test: (28000, 28, 28, 1)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:55:33.4709Z","iopub.execute_input":"2021-06-14T17:55:33.471189Z","iopub.status.idle":"2021-06-14T17:55:34.460103Z","shell.execute_reply.started":"2021-06-14T17:55:33.471138Z","shell.execute_reply":"2021-06-14T17:55:34.459418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸ—ï¸ Building model of CNN with Keras","metadata":{}},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(64, kernel_size=7, padding='same', activation='relu', input_shape=(28, 28, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size=9, strides=2, padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size=7, padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(128, kernel_size=5, padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, kernel_size=7, strides=2, padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(128, kernel_size=5, padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(256, kernel_size=3, padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256, kernel_size=5, strides=2, padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(256, kernel_size=3, padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\n\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:55:38.19848Z","iopub.execute_input":"2021-06-14T17:55:38.19881Z","iopub.status.idle":"2021-06-14T17:55:41.704306Z","shell.execute_reply.started":"2021-06-14T17:55:38.198759Z","shell.execute_reply":"2021-06-14T17:55:41.703522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# âž¿ Training the model","metadata":{}},{"cell_type":"code","source":"annealer = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** (x + 50))\nepochs = 25\n\nh = model.fit(data['x_train'], data['y_train'], batch_size=50, epochs = epochs,\n              validation_data = (data['x_validation'], data['y_validation']), callbacks=[annealer], verbose=1)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T17:56:19.24507Z","iopub.execute_input":"2021-06-14T17:56:19.24541Z","iopub.status.idle":"2021-06-14T18:05:37.800087Z","shell.execute_reply.started":"2021-06-14T17:56:19.24536Z","shell.execute_reply":"2021-06-14T18:05:37.799292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Epochs={0:d}, Train accuracy={1:.5f}, Validation accuracy={2:.5f}\".format(epochs, max(h.history['acc']), \n                                                                                 max(h.history['val_acc'])))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:05:41.705159Z","iopub.execute_input":"2021-06-14T18:05:41.705466Z","iopub.status.idle":"2021-06-14T18:05:41.713265Z","shell.execute_reply.started":"2021-06-14T18:05:41.705413Z","shell.execute_reply":"2021-06-14T18:05:41.712155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸ“ˆ Plotting model's accuracy","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\nplt.rcParams['figure.figsize'] = (15.0, 5.0) # Setting default size of plots\nplt.rcParams['image.interpolation'] = 'nearest'\nplt.rcParams['image.cmap'] = 'gray'\n\nfig = plt.figure()\nplt.plot(h.history['acc'], '-o')\nplt.plot(h.history['val_acc'], '-o')\nplt.title('Model accuracy')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.xlabel('Epoch', fontsize=15)\nplt.ylabel('Accuracy', fontsize=15)\nplt.ylim(0.98, 1)\nplt.show()\n\n# Saving plot\nfig.savefig('model_accuracy.png')\nplt.close()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:05:47.006197Z","iopub.execute_input":"2021-06-14T18:05:47.006489Z","iopub.status.idle":"2021-06-14T18:05:47.226919Z","shell.execute_reply.started":"2021-06-14T18:05:47.006438Z","shell.execute_reply":"2021-06-14T18:05:47.226161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸ’¾ Saving model","metadata":{}},{"cell_type":"code","source":"model.save('my_model.h5')","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:05:51.138091Z","iopub.execute_input":"2021-06-14T18:05:51.138392Z","iopub.status.idle":"2021-06-14T18:05:52.153133Z","shell.execute_reply.started":"2021-06-14T18:05:51.138338Z","shell.execute_reply":"2021-06-14T18:05:52.152413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Saving model locally without commiting\n# from IPython.display import FileLink\n\n# FileLink('my_model.h5')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸ”® Predicting with images from test dataset","metadata":{}},{"cell_type":"code","source":"results = model.predict(data['x_test'])\nresults = np.argmax(results, axis=1)\n\n# Loading sample template for submission and writing predicted labels into 'Label' column\nsubmission = pd.read_csv('../input/sample_submission.csv')\n\nsubmission['Label'] = results\nsubmission.to_csv('sample_submission.csv', index=None)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:05:55.191553Z","iopub.execute_input":"2021-06-14T18:05:55.19188Z","iopub.status.idle":"2021-06-14T18:06:01.115701Z","shell.execute_reply.started":"2021-06-14T18:05:55.191827Z","shell.execute_reply":"2021-06-14T18:06:01.114973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cheking\ns = pd.read_csv('sample_submission.csv')\ns.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:06:05.042875Z","iopub.execute_input":"2021-06-14T18:06:05.043163Z","iopub.status.idle":"2021-06-14T18:06:05.065302Z","shell.execute_reply.started":"2021-06-14T18:06:05.043114Z","shell.execute_reply":"2021-06-14T18:06:05.064702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Saving resulted data locally without commiting\n# from IPython.display import FileLink\n\n# FileLink('sample_submission.csv')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}