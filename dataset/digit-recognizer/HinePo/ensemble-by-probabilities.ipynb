{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# About this notebook\n\nIn this case of MNIST image classification, we cannot ensemble by taking the mean of predictions from different models, as we would do in a regression problem. This would make no sense, as this approach would, for example, take a predicted label (digit 6) from one model and a predicted label (digit 0) from other model and would output a 3, or even worse, output a float number (a class that does not exist).\n\nSo we have two options to ensemble models:\n- make predictions for several models and take the mode (most common predicted digit), just like a hard voting classifier with a majority rule; or\n- perform some calculation on the probabilities the models predicted for each class (like a soft voting classifier).\n\nIn this notebook I am ensembling only two models. So I will have to go with the second approach and I am taking a combination of the probabilities each model predicted for each sample to predict its class.\n\nFor that we will need:\n- Two Dataset classes (because the models used have different input shapes)\n- Two DataLoaders objects\n- Two Model classes\n- One inference function\n- Add data (two models): best custom model, best timm model\n- No training, only inference: just predict and ensemble.\n\nYou can find the models I am using on the links below, where they were trained:\n\n[Model 1: custom CNN model](https://www.kaggle.com/hinepo/pytorch-tutorial-cv-99-67-lb-99-26)\n\n[Model 2: ResNet50](https://www.kaggle.com/hinepo/transfer-learning-with-timm-models-and-pytorch)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"!pip install timm -q","metadata":{"execution":{"iopub.status.busy":"2022-01-01T23:37:09.338918Z","iopub.execute_input":"2022-01-01T23:37:09.339182Z","iopub.status.idle":"2022-01-01T23:37:16.680637Z","shell.execute_reply.started":"2022-01-01T23:37:09.339153Z","shell.execute_reply":"2022-01-01T23:37:16.679818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport time\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\n\nimport timm","metadata":{"execution":{"iopub.status.busy":"2022-01-01T23:37:16.68443Z","iopub.execute_input":"2022-01-01T23:37:16.684669Z","iopub.status.idle":"2022-01-01T23:37:16.689177Z","shell.execute_reply.started":"2022-01-01T23:37:16.684641Z","shell.execute_reply":"2022-01-01T23:37:16.688513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"# Load the data\nINPUT_PATH = '../input/digit-recognizer/'\nOUTPUT_PATH = './'\n\ntest = pd.read_csv(INPUT_PATH + \"test.csv\")\ntest","metadata":{"execution":{"iopub.status.busy":"2022-01-01T23:37:16.690666Z","iopub.execute_input":"2022-01-01T23:37:16.690982Z","iopub.status.idle":"2022-01-01T23:37:18.182192Z","shell.execute_reply.started":"2022-01-01T23:37:16.690945Z","shell.execute_reply":"2022-01-01T23:37:18.181394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# detect and define device \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T23:37:18.184128Z","iopub.execute_input":"2022-01-01T23:37:18.184589Z","iopub.status.idle":"2022-01-01T23:37:18.189548Z","shell.execute_reply.started":"2022-01-01T23:37:18.184547Z","shell.execute_reply":"2022-01-01T23:37:18.188718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CFG","metadata":{}},{"cell_type":"code","source":"class CFG:\n  N_CLASS = 10\n  BATCH_SIZE = 1024\n  model_name = 'resnet50'","metadata":{"execution":{"iopub.status.busy":"2022-01-01T23:37:18.190977Z","iopub.execute_input":"2022-01-01T23:37:18.191261Z","iopub.status.idle":"2022-01-01T23:37:18.199956Z","shell.execute_reply.started":"2022-01-01T23:37:18.191224Z","shell.execute_reply":"2022-01-01T23:37:18.199044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset class (for custom model)","metadata":{}},{"cell_type":"code","source":"class Digit_Inference_Dataset_Custom(Dataset):\n    def __init__(self, df, augmentations = None):\n        self.features = df.values/255 # scale (greyscale) features\n        self.augmentations = augmentations \n\n    def __len__(self):\n        return len(self.features)\n    \n    def __getitem__(self, idx):\n        image = self.features[idx].reshape((1, 28, 28))\n        return torch.FloatTensor(image)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T23:37:18.201394Z","iopub.execute_input":"2022-01-01T23:37:18.201844Z","iopub.status.idle":"2022-01-01T23:37:18.208649Z","shell.execute_reply.started":"2022-01-01T23:37:18.201809Z","shell.execute_reply":"2022-01-01T23:37:18.207982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset class (for ResNet)","metadata":{}},{"cell_type":"code","source":"class Digit_Inference_Dataset_ResNet(Dataset):\n    def __init__(self, df, augmentations = None):\n        self.df = df\n        self.features = df[:].values/255 # scale (greyscale) only features. do not scale target\n        self.augmentations = augmentations\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        image = self.features[idx].reshape((28, 28))\n        image = torch.from_numpy(image).float()\n        image = torch.stack([image, image, image], dim = 0) # images must have 3 channels to enter timm models\n        return image","metadata":{"execution":{"iopub.status.busy":"2022-01-01T23:37:18.209808Z","iopub.execute_input":"2022-01-01T23:37:18.210161Z","iopub.status.idle":"2022-01-01T23:37:18.218888Z","shell.execute_reply.started":"2022-01-01T23:37:18.210125Z","shell.execute_reply":"2022-01-01T23:37:18.218073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model class (custom model)","metadata":{}},{"cell_type":"code","source":"class Digit_Custom_Model(nn.Module):\n    def __init__(self):\n        super(Digit_Custom_Model, self).__init__()\n        \n        # Convolution to detect features and create feature maps: kernel = feature detector = filter\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(5,5), padding=0)\n        \n        # activation\n        self.actv = nn.LeakyReLU()\n\n        # Batch normalization 1\n        self.batchnorm1 = nn.BatchNorm2d(32)\n        \n        # Max pool: down sample the detected features in feature maps\n        self.maxpool = nn.MaxPool2d(kernel_size=(2,2))\n\n        # Dropout\n        self.dropout = nn.Dropout(0.25) \n     \n        # Convolution\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(5,5), padding=0)\n\n        # Batch normalization 2\n        self.batchnorm2 = nn.BatchNorm2d(64)        \n\n        # flatten the feature map: reduce dimensionality\n        self.flatten = nn.Flatten()\n\n        # Fully connected\n        self.fc1 = nn.Linear(64 * 4 * 4, 256)\n\n        # Batch normalization 3\n        self.batchnorm3 = nn.BatchNorm1d(256)  # 1 D because it is called after the flatten layer\n\n        # The last fully connected layer must output the number of classes\n        self.classifier = nn.Linear(256, CFG.N_CLASS)\n    \n    def forward(self, x):\n        # conv1 block\n        x = self.conv1(x)\n        x = self.actv(x)\n        x = self.batchnorm1(x)\n        x = self.maxpool(x)\n        # x = self.dropout(x)\n\n        # conv2 block\n        x = self.conv2(x)\n        x = self.actv(x)\n        x = self.batchnorm2(x)\n        x = self.maxpool(x)\n        # x = self.dropout(x)\n\n        # flatten\n        x = self.flatten(x)\n\n        # print(x.size())\n        \n        # Linear functions\n        x = self.fc1(x)\n        x = self.batchnorm3(x)\n        # x = self.dropout(x)\n        out = self.classifier(x)\n        \n        return out ","metadata":{"execution":{"iopub.status.busy":"2022-01-01T23:37:18.221774Z","iopub.execute_input":"2022-01-01T23:37:18.222252Z","iopub.status.idle":"2022-01-01T23:37:18.236292Z","shell.execute_reply.started":"2022-01-01T23:37:18.222217Z","shell.execute_reply":"2022-01-01T23:37:18.235584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model class (ResNet50)","metadata":{}},{"cell_type":"code","source":"class Digit_ResNet_Model(nn.Module):\n    def __init__(self, model_name = CFG.model_name, pretrained = True):\n        super().__init__()\n\n        self.model_name = model_name\n        self.cnn = timm.create_model(self.model_name, pretrained = pretrained, num_classes = CFG.N_CLASS)\n\n    def forward(self, x):\n        x = self.cnn(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-01-01T23:37:18.237603Z","iopub.execute_input":"2022-01-01T23:37:18.239406Z","iopub.status.idle":"2022-01-01T23:37:18.24772Z","shell.execute_reply.started":"2022-01-01T23:37:18.239376Z","shell.execute_reply":"2022-01-01T23:37:18.246971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference and Ensemble","metadata":{}},{"cell_type":"code","source":"def softmax(x):\n    return np.exp(x)/np.sum(np.exp(x), axis=1)[:, None]\n\ndef inference(test_loader_custom, test_loader_resnet):\n    start = time.time()\n\n    probs_custom = torch.Tensor()\n    probs_resnet = torch.Tensor()\n\n    ################################# model 1: custom model #################################\n    model_custom = Digit_Custom_Model() # instantiate custom model\n    model_custom.load_state_dict(torch.load(f\"../input/pytorch-tutorial-cv-99-67-lb-99-26/DigitModel_ep21.pth\")) # Load custom model\n    model_custom.eval() # eval mode\n    model_custom.to(device)\n\n    ################################# model 2: ResNet #################################\n    model_resnet = Digit_ResNet_Model() # instantiate ResNet model\n    model_resnet.load_state_dict(torch.load(f\"../input/transfer-learning-with-timm-models-and-pytorch/DigitModel_ep38.pth\")) # Load ResNet model\n    model_resnet.eval() # eval mode\n    model_resnet.to(device)\n\n    # disable gradients for inference\n    with torch.no_grad():\n      ################################# inference for custom model #################################      \n      for batch, X in enumerate(test_loader_custom):\n\n        X = X.to(device)\n\n        # compute predictions for custom model\n        pred_custom = model_custom(X)\n        y_pred_custom = softmax(pred_custom.detach().cpu().numpy()) # convert tensor to numpy to apply softmax\n\n        batch_probs_custom = torch.from_numpy(y_pred_custom) # convert np array back to torch tensor\n        probs_custom = torch.cat((probs_custom, batch_probs_custom), dim = 0) # concatenate softmax probabilities\n\n      ################################# inference for resnet #################################\n      for batch, X in enumerate(test_loader_resnet):\n\n        X = X.to(device)\n\n        # compute predictions for resnet model\n        pred_resnet = model_resnet(X)\n        y_pred_resnet = softmax(pred_resnet.detach().cpu().numpy()) # convert tensor to numpy to apply softmax\n\n        batch_probs_resnet = torch.from_numpy(y_pred_resnet) # convert np array back to torch tensor\n        probs_resnet = torch.cat((probs_resnet, batch_probs_resnet), dim = 0) # concatenate softmax probabilities\n\n    \n    # ensemble by probabilities: combination of the probabilities predicted by each model\n    ens = probs_custom * 0.6 + probs_resnet * 0.4\n    final_predictions = torch.argmax(ens, axis = 1) # indice of the highest probability in the ensemble (predicted digit/class)\n    \n    # log\n    end = time.time()\n    time_delta = np.round(end - start, 5)     \n    print('Elapsed time: ', time_delta, \"s\")\n\n    # return probs_custom, probs_resnet\n    return final_predictions","metadata":{"execution":{"iopub.status.busy":"2022-01-01T23:37:18.25048Z","iopub.execute_input":"2022-01-01T23:37:18.250746Z","iopub.status.idle":"2022-01-01T23:37:18.263879Z","shell.execute_reply.started":"2022-01-01T23:37:18.250711Z","shell.execute_reply":"2022-01-01T23:37:18.26294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# instantiate Inference Dataset class (create inference Dataset)\ninference_dataset_custom = Digit_Inference_Dataset_Custom(test, augmentations=None)\ninference_dataset_resnet = Digit_Inference_Dataset_ResNet(test, augmentations=None)\n\n# create Inference DataLoader object from Dataset class object (for custom model)\ninference_dataloader_custom = DataLoader(inference_dataset_custom,\n                                         batch_size = CFG.BATCH_SIZE,\n                                         shuffle = False)\n\n# create Inference DataLoader object from Dataset class object (for ResNet50 model)\ninference_dataloader_resnet = DataLoader(inference_dataset_resnet,\n                                         batch_size = CFG.BATCH_SIZE,\n                                         shuffle = False)","metadata":{"execution":{"iopub.status.busy":"2022-01-01T23:37:18.265128Z","iopub.execute_input":"2022-01-01T23:37:18.265567Z","iopub.status.idle":"2022-01-01T23:37:18.408914Z","shell.execute_reply.started":"2022-01-01T23:37:18.265477Z","shell.execute_reply":"2022-01-01T23:37:18.408175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# run inference\nfinal_predictions = inference(inference_dataloader_custom, inference_dataloader_resnet)\nfinal_predictions","metadata":{"execution":{"iopub.status.busy":"2022-01-01T23:37:18.410493Z","iopub.execute_input":"2022-01-01T23:37:18.411Z","iopub.status.idle":"2022-01-01T23:37:30.985377Z","shell.execute_reply.started":"2022-01-01T23:37:18.410957Z","shell.execute_reply":"2022-01-01T23:37:30.984394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv(INPUT_PATH + \"sample_submission.csv\")\nsubmission[\"Label\"] = final_predictions\n\nsubmission.to_csv(OUTPUT_PATH + 'submission.csv', index = False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-01T23:37:30.986813Z","iopub.execute_input":"2022-01-01T23:37:30.98712Z","iopub.status.idle":"2022-01-01T23:37:31.064831Z","shell.execute_reply.started":"2022-01-01T23:37:30.987076Z","shell.execute_reply":"2022-01-01T23:37:31.063963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check predictions","metadata":{}},{"cell_type":"code","source":"# check some predictions\n\nfig = plt.figure(figsize = (12, 12))\nfig.suptitle('Visualizing Predictions', fontsize = 24)\n\n# define a range of predictions to plot\nbegin = 0\nend = begin + 20\n\nfor i in range(begin, end):\n\n  img = np.array(test.iloc[i, :]).reshape(1, 1, 28, 28) # reshape to image dimensions\n  plt.subplot(4, 5, i + 1 - begin) # 4 rows and 5 columns plot \n  label = str(submission.loc[i, 'Label'])\n  plt.title(\"Predicted label: \" + label, color=\"red\") # write label in each image title\n  plt.imshow(np.squeeze(img), cmap='gray') # plot image\n  plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-01-01T23:37:31.066133Z","iopub.execute_input":"2022-01-01T23:37:31.066453Z","iopub.status.idle":"2022-01-01T23:37:31.846071Z","shell.execute_reply.started":"2022-01-01T23:37:31.066416Z","shell.execute_reply":"2022-01-01T23:37:31.843549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Upvote if you found value in this notebook! ðŸ˜€","metadata":{}}]}