{"cells":[{"metadata":{},"cell_type":"markdown","source":"* Auh...\n* Train 8 epochs and 0.99607 score\n* I enter this competion only for ... (you guess)\n* Notebook for beginners. Sorry for I forgot to save output.\n* I was so busy and lazy that I don't visualize data and train result in this notebook.But I assume you are a clever guy or you have already learn those from other notebooks.Please don't criticize me. HaHa\n* Hope this will help you."},{"metadata":{},"cell_type":"markdown","source":"**What you can do?**"},{"metadata":{},"cell_type":"markdown","source":"* You could try seresnext50, find more appropriate learning rate, use more data augumentation, train more epochs (if you have patience haha)...\n* Welcome to improve it and if you have better thought, let me know.\n* I bet you will get a higher score!"},{"metadata":{},"cell_type":"markdown","source":"By the way, you can download parameters from this site : https://www.kaggle.com/qiyuange/mnist-resnext50-weights-pytorch"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom albumentations import Compose, Resize, OneOf, RandomBrightness, RandomContrast, ShiftScaleRotate, Normalize \nfrom albumentations.pytorch import ToTensor\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport time\nimport copy\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 271\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class digitdataset(torch.utils.data.Dataset):\n    def __init__(self, csv_file, transform=None):\n        super(digitdataset, self).__init__()\n        self.df = pd.read_csv(csv_file)\n        self.transform = transform\n        \n    def __getitem__(self, idx):\n        image = self.df.iloc[idx][1:].to_numpy().reshape(28,28)\n        image = cv2.cvtColor(np.uint8(image), cv2.COLOR_GRAY2RGB)\n        label = self.df.iloc[idx][0]\n        if self.transform is not None:\n            image = self.transform(image=image)['image']\n        image = ToTensor()(image=image)['image']\n        label = torch.as_tensor(label)\n        \n        return image, label\n    \n    def __len__(self):\n        return len(self.df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Focal Loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"class FocalLoss(nn.Module):\n    def __init__(self, num_classes, alpha = None, gamma = 2, reduction = 'mean'):\n        super(FocalLoss, self).__init__()\n        if alpha == None:\n            self.alpha = torch.ones(num_classes, 1)\n        else:\n            self.alpha = torch.as_tensor(alpha)\n        self.gamma = gamma\n        self.reduction = reduction\n        \n    def forward(self, inputs, targets):\n        n = inputs.size(0)\n        c = inputs.size(1)\n        p = F.softmax(inputs, dim=1)\n        \n        class_mask = inputs.data.new(n, c).fill_(0)\n        ids = targets.view(-1, 1)\n        class_mask.scatter_(1, ids.data, 1.)\n        \n        probs = (p*class_mask).sum(1).view(-1,1)\n        log_probs = probs.log()\n        \n        alpha = self.alpha[ids.data.view(-1)]\n        if inputs.is_cuda:\n            alpha = alpha.cuda()\n        batch_loss = -alpha*(torch.pow((1-probs), self.gamma))*log_probs\n        \n        if self.reduction == 'mean':\n            loss = batch_loss.mean()\n        elif self.reduction == 'sum':\n            loss = batch_loss.sum()\n            \n        return loss  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def resnext50(num_classes = 10, pretrained=True):\n    model = torchvision.models.resnext50_32x4d(pretrained=pretrained)\n    num_features = model.fc.in_features\n    num_classes = num_classes\n    model.fc = nn.Linear(num_features, num_classes, bias=True)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_with_evaluate(model, criterion, optimizer, lr_scheduler, alpha=[1,1], num_epochs=20):\n    since = time.time()\n    train_loss = []\n    test_loss = []\n    train_acc = []\n    test_acc = []\n    \n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    print_freq = int(len(dataloader['train'])/20)\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        for phase in ['train','test']:\n            if phase == 'train':\n                model.train() \n            else:\n                model.eval() \n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for i, (inputs, labels) in enumerate(dataloader[phase]):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                optimizer.zero_grad()       \n\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = alpha[0]*criterion[0](outputs, labels) + alpha[1]*criterion[1](outputs, labels)\n\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                        lr_scheduler.step()\n\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n                num_dot = int(i/print_freq)\n                dots = '* ' * num_dot\n                print('\\r{0}[{1}/{2}]'.format(dots, i+1, len(dataloader[phase])), end='')\n \n            \n            epoch_loss = running_loss / dataset_size[phase]\n            epoch_acc = running_corrects.double() / dataset_size[phase]\n            print()\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n            \n            if phase == 'train':\n                train_loss.append(epoch_loss)\n                train_acc.append(epoch_acc)\n           \n            elif phase == 'test':\n                test_loss.append(epoch_loss)\n                test_acc.append(epoch_acc)\n\n            if phase == 'test' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print('Best test Acc: {:4f}'.format(best_acc))\n    print()\n\n    model.load_state_dict(best_model_wts)\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Augumentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"imgsize = 224\ntransform = {\n    'train': Compose([\n        Resize(imgsize,imgsize),\n        OneOf([RandomBrightness(limit=0.1, p=0.4), RandomContrast(limit=0.1, p=0.4)]),\n        ShiftScaleRotate(\n            shift_limit=0.2,\n            scale_limit=0.2,\n            rotate_limit=30,\n            interpolation=cv2.INTER_LINEAR,\n            border_mode=cv2.BORDER_REFLECT_101,\n            p=0.8),\n        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ]\n    ),\n    \n    'default': Compose([\n        Resize(imgsize,imgsize),                                                                 \n        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ]),\n    \n    'TTA': Compose([\n        Resize(imgsize,imgsize),            \n        ShiftScaleRotate(\n            shift_limit=0.1,\n            scale_limit=0.1,\n            rotate_limit=30,\n            interpolation=cv2.INTER_LINEAR,\n            border_mode=cv2.BORDER_REFLECT_101,\n            p=0.5),                                                                \n        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ]),\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 32\ntrain_csv = r'../input/digit-recognizer/train.csv'\n\ndataset = digitdataset(train_csv, transform=transform['train'])\ntrain_size = int(0.8 * len(dataset))\ntest_size = len(dataset) - train_size\n\ntrain_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n\nprint(\"length of train_dataset:\", len(train_dataset))\nprint(\"length of test_dataset:\", len(test_dataset))\n\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n\ndataloader = {'train' : train_dataloader, 'test' : test_dataloader}\ndataset_size = {'train' : len(train_dataset), 'test' : len(test_dataset)}\n\nmodel = resnext50()\nmodel.to(device)\n\ncriterion1 = nn.CrossEntropyLoss()\ncriterion2 = FocalLoss(num_classes = 10)\n\ncriterion = [criterion1, criterion2]\nstep_per_epoch = len(dataloader['train'])\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\nlr_scheduler=torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-4, epochs=10, steps_per_epoch=step_per_epoch)\nmodel = train_with_evaluate(model, criterion, optimizer, lr_scheduler, num_epochs=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"saved_path = 'mnist_resnext50.pth'\ntorch.save(model.state_dict(), saved_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class digit_test_dataset(torch.utils.data.Dataset):\n    def __init__(self, csv_file, transform=None):\n        super(digit_test_dataset, self).__init__()\n        self.df = pd.read_csv(csv_file)\n        self.transform = transform\n        \n    def __getitem__(self, idx):\n        image = self.df.iloc[idx][:].to_numpy().reshape(28,28)\n        image = cv2.cvtColor(np.uint8(image), cv2.COLOR_GRAY2RGB)\n        if self.transform is not None:\n            image = self.transform(image=image)['image']\n        image = ToTensor()(image=image)['image']\n        \n        return image\n    \n    def __len__(self):\n        return len(self.df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Test Time Augumentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_csv = r'../input/digit-recognizer/test.csv'\ntest_dataset = digit_test_dataset(test_csv, transform=transform['TTA'])\nmodel.eval()\nresult = []\nnum_TTA = 4\nfor i in range(len(test_dataset)):\n    sum_pred = 0\n    for n in range(num_TTA):\n        with torch.no_grad():\n            img = test_dataset[i]\n            pred = model(img.unsqueeze(0).to(device))\n            pred = nn.Softmax(dim=1)(pred)\n            sum_pred += pred\n            \n    avg_pred = sum_pred / num_TTA\n    _, pred = torch.max(avg_pred, 1)\n    pred = pred.item()\n    print('No.', i, '->', pred)\n    result.append(pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ndata = pd.DataFrame(result, index = list(range(1,len(result)+1,1)), columns = ['ImageId','label'])\ndata.to_csv('mnist.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}