{"cells":[{"metadata":{},"cell_type":"markdown","source":"# MNIST using Keras CNN Ensemble(0.996 accuracy)\nThis notebook covers CNN, ensemble and visualization process step-by-step.\nI hope you find this notebook useful!"},{"metadata":{},"cell_type":"markdown","source":"* [1. Import required libraries](#1)\n* [2. Data preparation](#2)\n    * [2.1 load dataset](#2.1)\n    * [2.2 Optimize data](#2.2)\n    * [2.3 Data Augmentation](#2.3)\n* [3. Build CNN](#3)\n    * [3.1 Define the model](#3.1)\n* [4. Training](#4)\n* [5. Evaluate the model](#5)\n    * [5.1 Predictions correlation matrix](#5.1)\n    * [5.2 Training and validation curves](#5.2)\n* [6. Create submission](#6)"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"1\"></a>\n<h1 style='background:navy; border:0; color:white'><center>1. Import required libraries</center></h1>"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2\"></a>\n<h1 style='background:navy; border:0; color:white'><center>2. Data preparation</center></h1>"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2.1\"></a>\n## 2.1 load dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\ntest = pd.read_csv('/kaggle/input/digit-recognizer/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2.2\"></a>\n## 2.2 Optimize data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# divide training data into features and labels\nX_train = train.iloc[:,1:]\ny_train = train.iloc[:,0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalize and reshape image\nX_train = X_train.values.reshape(-1, 28, 28, 1)/255.\ntest = test.values.reshape(-1, 28, 28, 1)/255.\n# One Hot encoding the label\ny_train = to_categorical(y_train, 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"2.3\"></a>\n## 2.3 Data Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n            rotation_range=15,\n            width_shift_range=0.1,\n            height_shift_range=0.1,\n            zoom_range=0.1,\n            shear_range=0.2\n            )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3\"></a>\n<h1 style='background:navy; border:0; color:white'><center>3. Build CNN</center></h1>"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"3.1\"></a>\n## 3.1 Define the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    model = Sequential()\n\n    model.add(Conv2D(32, (3,3), padding='same', input_shape=X_train.shape[1:], activation='relu'))\n    model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(2,2))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(2,2))\n    model.add(Dropout(0.2))\n\n    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n    model.add(Conv2D(128, (3,3), padding='same', activation='relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(2,2))\n    model.add(Dropout(0.2))\n    \n    model.add(Flatten())\n    model.add(Dense(256, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(10, activation='softmax'))\n    \n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"4\"></a>\n<h1 style='background:navy; border:0; color:white'><center>4. Training</center></h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 30\nBATCH_SIZE = 50\nENSEMBLES = 5 # number of models to ensemble\nresult_list = [] # store results for correlation matrix\nhistories = [] # store histories for training and validation curves\nresults = np.zeros((test.shape[0],10))\n\ncallback_list = [\n    ReduceLROnPlateau(monitor='val_loss', factor=0.25, patience=2),\n    EarlyStopping(monitor='val_loss', min_delta=0.0005, patience=4)\n]\n\nfor i in range(ENSEMBLES):\n    # split training and validation sets\n    X_train_tmp, X_val, y_train_tmp, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=i)\n    # create model\n    model = create_model()\n    # fit the model\n    print('training No.', i)\n    history = model.fit(datagen.flow(X_train_tmp, y_train_tmp, batch_size=BATCH_SIZE),\n                   verbose=0,\n                   epochs=EPOCHS,\n                   callbacks=callback_list,\n                   validation_data=(X_val, y_val),\n                   steps_per_epoch=X_train_tmp.shape[0] // BATCH_SIZE)\n    # save results\n    histories.append(history)\n    result = model.predict(test)\n    results += result\n    result_list.append(result)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5\"></a>\n<h1 style='background:navy; border:0; color:white'><center>5. Evaluate the model</center></h1>"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5.1\"></a>\n## 5.1 Predictions correlation matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"# check correlation of each predictions\ncorr_preds = pd.DataFrame([np.argmax(result, axis=1) for result in result_list]).T.corr()\nfig = sns.heatmap(corr_preds, annot=True, fmt='.3f', cmap='rainbow')\nfig.set_title('Predictions correlation matrix', fontsize=16, y=1.05)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"5.2\"></a>\n## 5.2 Training and validation curves"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2, 1, figsize=(12,6))\n\nfor e in range(ENSEMBLES):\n    loss = histories[e].history['loss']\n    val_loss = histories[e].history['val_loss']\n    acc = histories[e].history['accuracy']\n    val_acc = histories[e].history['val_accuracy']\n    ax[0].set_title('loss')\n    ax[0].plot(loss, 'b', linewidth=1)\n    ax[0].plot(val_loss, 'r', linewidth=1)\n    ax[0].grid(color='black', linestyle='-', linewidth=0.2)\n    ax[1].set_title('accuracy')\n    ax[1].plot(acc, 'b', linewidth=1)\n    ax[1].plot(val_acc, 'r', linewidth=1)\n    ax[1].grid(color='black', linestyle='-', linewidth=0.2)\n    \nax[0].legend(['Training loss', 'Validation loss'], shadow=True)     \nax[1].legend(['Training accuracy', 'Validation accuracy'], shadow=True)\n\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"6\"></a>\n<h1 style='background:navy; border:0; color:white'><center>6. Create submission</center></h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"results = np.argmax(results, axis=1)\nresults = pd.Series(results, name='Label')\nsubmission = pd.concat([pd.Series(range(1,28001), name='ImageID'), results], axis=1)\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}