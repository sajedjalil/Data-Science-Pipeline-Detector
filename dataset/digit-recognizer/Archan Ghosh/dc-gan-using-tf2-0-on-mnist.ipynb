{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"DC-GAN or Deep Convolution GANS, uses deep neural networks for Image generations.\n\nmore can be found [here](https://medium.com/@jonathan_hui/gan-dcgan-deep-convolutional-generative-adversarial-networks-df855c438f)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Importing the required libraries and packages**","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport imageio\nimport glob\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow.keras as keras\nimport os \nimport PIL\nimport time\nimport pandas as pd\n\nfrom keras.layers import Dense, BatchNormalization, LeakyReLU, Reshape, Conv2DTranspose, Conv2D, Dropout, Flatten\nfrom keras import Sequential\nfrom IPython import display\n\n%matplotlib inline\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Loading the Dataset and Processing it**","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\ntrain_images = (train_images - 127.5)/ 127.5\n\nBUFFER_SIZE = 60000\nBATCH_SIZE = 256\n\nX_train = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building the Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_generator():\n  model = Sequential()\n  model.add(Dense(7*7*256, use_bias = False, input_shape=(100,)))\n  model.add(BatchNormalization())\n  model.add(LeakyReLU())\n\n  model.add(Reshape((7, 7, 256)))\n  assert model.output_shape == (None, 7, 7, 256)\n\n  model.add(Conv2DTranspose(128, (5,5), strides=(1,1), padding='same', use_bias=False))\n  assert model.output_shape == (None, 7, 7, 128)\n  model.add(BatchNormalization())\n  model.add(LeakyReLU())\n\n  model.add(Conv2DTranspose(64, (5,5), strides=(2,2), padding='same', use_bias=False))\n  assert model.output_shape == (None, 14, 14, 64)\n  model.add(BatchNormalization())\n  model.add(LeakyReLU())\n\n  model.add(Conv2DTranspose(1, (5,5), strides=(2,2), padding='same', use_bias=False, activation='tanh' ))\n  assert model.output_shape ==(None, 28, 28, 1)\n\n  return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gen = build_generator()\n\nnoise = tf.random.normal([1,100])\ngenerated_image = gen(noise, training=False)\n\nplt.imshow(generated_image[0, :, :, 0], cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_discriminator():\n  model = Sequential()\n  model.add(Conv2D(64, (5, 5), strides=(2,2), padding='same', input_shape=[28,28,1]))\n\n  model.add(LeakyReLU())\n  model.add(Dropout(0.3))\n\n  model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n  model.add(LeakyReLU())\n  model.add(Dropout(0.3))\n\n  model.add(Flatten())\n  model.add(Dense(1))\n\n  return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"disc = build_discriminator()\ndecision = disc(generated_image)\n\nprint(decision)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating Loss function, optimizer and checkpoints","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"bce = keras.losses.BinaryCrossentropy(from_logits=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def discriminator_loss(real_output, fake_output):\n  real_loss = bce(tf.ones_like(real_output), real_output)\n  fake_loss = bce(tf.zeros_like(fake_output), fake_output)\n  total_loss = real_loss + fake_loss\n\n  return total_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generator_loss(fake_output):\n  return bce(tf.ones_like(fake_output), fake_output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gen_optimizer = keras.optimizers.Adam(1e-4)\ndis_optimizer = keras.optimizers.Adam(1e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint_dir = './training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\ncheckpoint = tf.train.Checkpoint(generator_optimizer = gen_optimizer,\n                                 discriminator_optimizer=dis_optimizer,\n                                 generator=gen,\n                                 discriminator=disc)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Defining hyper-parameters**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 250\n\nnoise_dim = 100\n\nto_gen = 16\n\nseed = tf.random.normal([to_gen, noise_dim])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating Train Function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"@tf.function\ndef train_step(images):\n  noise = tf.random.normal([BATCH_SIZE, noise_dim])\n\n  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n    generated_images = gen(noise, training=True)\n\n    real_output = disc(images, training=True)\n    fake_output = disc(generated_images, training=True)\n\n    gen_loss = generator_loss(fake_output)\n    dis_loss = discriminator_loss(real_output, fake_output)\n\n    gradients_of_generator = gen_tape.gradient(gen_loss, gen.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(dis_loss, disc.trainable_variables)\n\n    gen_optimizer.apply_gradients(zip(gradients_of_generator, gen.trainable_variables))\n    dis_optimizer.apply_gradients(zip(gradients_of_discriminator, disc.trainable_variables))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(dataset, epochs):\n  for epoch in range(epochs):\n    start = time.time()\n\n    for image_batch in dataset:\n      train_step(image_batch)\n\n    display.clear_output(wait=True)\n    generate_and_save_images(gen, epoch +1, seed)\n\n    if(epoch + 1) % 15 == 0:\n      checkpoint.save(file_prefix = checkpoint_prefix)\n\n    print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n\n  display.clear_output(wait=True)\n  generate_and_save_images(gen, epochs, seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_and_save_images(model, epoch, test_input):\n  \n  predictions = model(test_input, training=False)\n\n  fig = plt.figure(figsize=(4,4))\n\n  for i in range(predictions.shape[0]):\n      plt.subplot(4, 4, i+1)\n      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n      plt.axis('off')\n\n  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n  plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training the Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train(X_train, epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_image(epoch_no):\n  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_image(epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\n\nframes = []\nimgs = glob.glob(\"*.png\")\nimgs.sort()\nfor i in imgs:\n    new_frame = Image.open(i)\n    frames.append(new_frame)\n\n \n\nframes[0].save('training.gif', format='GIF',\n               append_images=frames[1:],\n               save_all=True,\n               duration=100, loop=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image \nImage(open('training.gif','rb').read())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gen_image = gen(noise, training=False)\n\nplt.imshow(gen_image[0, :, :, 0], cmap='gray')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}