{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. Import","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torch import optim, nn\nfrom torch.utils.data import TensorDataset, DataLoader\nimport pandas as pd\nimport numpy as np\nimport time\nimport copy\nimport os\nimport matplotlib.pyplot as plt\n\nimport warnings\n\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Data preparation\n\n##     Load Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/digit-recognizer/train.csv').sample(frac=1)  # load\n\ntrain_size = 37800\nprint(\"train_size: {}\".format(train_size))\n\nlabel = data['label']\ndel data['label']\n\ndata = torch.tensor(data.values)\nlabel = torch.tensor(label)\n\n# Normalization\ndata = data / 255.0\n\nprint(label.size())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split train and valid set. Create dataloaders","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"all_ds = TensorDataset(data, label)\n\n# Split\ntrain_ds, valid_ds = torch.utils.data.random_split(all_ds, [train_size, 42000-train_size])\n\n# Create dataloaders\nbatch_size = 1000\ntrain_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\nvalid_dl = DataLoader(valid_ds, batch_size=batch_size * 2)\n\nprint(train_ds[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Accelerating computing with GPU","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\nprint('Device: {}'.format(device))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. CNN\n\n##     Define your model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n\n            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n        )\n        self.linear = nn.Sequential(\n            nn.Linear(256 * 3 * 3, 256),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(256, 10)\n        )\n\n    def forward(self, x):\n        x = x.view(-1, 1, 28, 28).float()\n        x = self.conv(x)\n        x = x.view(x.size(0), -1)\n        x = self.linear(x)\n        return x\n\n\nnet = Net()\nnet.to(device)\n\n\n# Load your model\n# if os.path.exists(net_path):\n#     net.load_state_dict(torch.load(net_path))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Set optimizer and loss function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 0.0001\n\noptimizer = optim.RMSprop(net.parameters(), lr=lr, alpha=0.9)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)\nloss_fn = nn.CrossEntropyLoss()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Start training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy(out, y):\n    preds = torch.argmax(out, dim=1)\n    return (preds == y).float().mean().item(), len(y)\n\n\ndef loss_batch(net, x, y):\n    loss = loss_fn(net(x), y)\n    return loss.item(), len(x)\n\n\ndef train_model():\n    print('Train model')\n    best_model_wts = copy.deepcopy(net.state_dict())\n    best_acc = 0.0\n    loss_show = []\n    acc_show = []\n\n    for epoch in range(epochs):\n        epoch_since = time.time()\n        print(\"Epoch {}:\".format(epoch), end=' ')\n        net.train()\n        for step, (b_x, b_y) in enumerate(train_dl):\n            out = net(b_x.to(device))\n            loss = loss_fn(out, b_y.to(device))\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        net.eval()\n        with torch.no_grad():\n            losses, nums_loss = zip(\n                *[loss_batch(net, x.to(device), y.to(device)) for x, y in valid_dl]\n            )\n            acc, nums_acc = zip(\n                *[accuracy(net(x.to(device)), y.to(device)) for x, y in valid_dl]\n            )\n        val_loss = np.sum(np.multiply(losses, nums_loss)) / np.sum(nums_loss)\n        val_acc = np.sum(np.multiply(acc, nums_acc)) / np.sum(nums_acc)\n        epoch_time_elapsed = time.time() - epoch_since\n        print(\"time:{:.0f}s\".format(epoch_time_elapsed), \"loss:{:.10f}\".format(val_loss), \"accuracy:{:.10f}\".format(val_acc))\n        if val_acc > best_acc:\n            best_acc = val_acc\n            best_model_wts = copy.deepcopy(net.state_dict())\n        scheduler.step(val_loss)\n        loss_show.append(val_loss)\n        acc_show.append(val_acc)\n\n        if epoch % 10 == 9:\n            net.load_state_dict(best_model_wts)\n#             torch.save(net.state_dict(), net_path)\n    net.load_state_dict(best_model_wts)\n#     Save your model if you want\n#     torch.save(net.state_dict(), net_path)\n    plt.figure()\n    plt.plot(range(epochs), loss_show)\n    plt.figure()\n    plt.plot(range(epochs), acc_show)\n    plt.show()\n    \n\n\n# Set epoch to 30 to get 99.4% accuracy\nepochs = 10\ntrain_model()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Make predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def save():\n    test = pd.read_csv('../input/digit-recognizer/test.csv')\n    test = torch.tensor(test.values)\n    test = test / 255.0\n    test_ds = TensorDataset(test)\n    test_dl = DataLoader(test_ds, batch_size=2)\n    print(\"Save preds\")\n    preds = []\n    with torch.no_grad():\n        for x in test_dl:\n            x = x[0]\n            out = net(x.to(device))\n            a, b = out.split(1, 0)\n            pred = torch.argmax(a, dim=1).to('cpu')\n            preds.append(pred.numpy().tolist()[0])\n            pred = torch.argmax(b, dim=1).to('cpu')\n            preds.append(pred.numpy().tolist()[0])\n    dataframe = pd.DataFrame({\"ImageId\": range(1, 28001), \"Label\": preds})\n    dataframe.to_csv(csv_path, index=False)\n    print('Saved')\n    return preds\n\n\n\ncsv_path = 'post.csv'\n# save()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## View training results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"acc, nums_acc = zip(\n    *[accuracy(net(x.to(device)), y.to(device)) for x, y in valid_dl]\n)\nvalid_acc = np.sum(np.multiply(acc, nums_acc)) / np.sum(nums_acc)\nprint(\"valid :{:.10f}\".format(valid_acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thanks","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}