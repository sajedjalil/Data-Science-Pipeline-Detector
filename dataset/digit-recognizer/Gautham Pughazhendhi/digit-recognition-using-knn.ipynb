{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Digit Recognizer\n\nAlthough this is a computer vision problem, I created a simple model using **K-Nearest Neighbors** algorithm in this notebook to be a good starting point knowing that CNN would be a much better option. I used the **GridSearchCV** to fine tune the hyperparameters such as *\"n_neighbors\", and \"weights\"* and to perform cross-validation. Furthermore, I have used **Data Augmentation** or **Artificial Data Synthesis** technique in this notebook to boost the model's performance on the test set.\n\nPlease **upvote** if you like this notebook and share your valuable feedback.\n\nYou can find my other notebooks below:\n\n* [Disaster Tweets Classification](https://www.kaggle.com/gauthampughazh/disaster-or-not-plotly-use-tfidf-h2o-ai-automl)\n* [House Sales Price Prediction](https://www.kaggle.com/gauthampughazh/house-sales-price-prediction-svr)\n* [Titanic Survival Classification](https://www.kaggle.com/gauthampughazh/titanic-survival-prediction-pandas-plotly-keras)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # Linear algebra\nimport pandas as pd # For data manipulation\nimport json\nimport os\nimport matplotlib.pyplot as plt # For visualization\nfrom sklearn.neighbors import KNeighborsClassifier # For modelling\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold # For evaluation and hyperparameter tuning\nfrom sklearn.metrics import confusion_matrix, classification_report # For evaluation\nfrom scipy.ndimage import shift, rotate, zoom # For data augmentation\nfrom IPython.display import FileLink # For downloading the output file\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Peeking the data**"},{"metadata":{},"cell_type":"markdown","source":"Loading the datasets into dataframes"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")\nsubmission_df = pd.read_csv(\"/kaggle/input/digit-recognizer/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Knowing about the features in the datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Converting the train and test dataframes into numpy arrays"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train_df.iloc[:, 1:].values\ny_train = train_df.iloc[:, 0].values\nX_test = test_df.values\n\nprint(f\"X_train shape: {X_train.shape}\")\nprint(f\"y_train shape: {y_train.shape}\")\nprint(f\"X_test shape: {X_test.shape}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Visualizing a digit from the training data as a 28 X 28 image"},{"metadata":{"trusted":true},"cell_type":"code","source":"some_digit = X_train[40]\n\nsome_digit_image = some_digit.reshape(28, 28)\nprint(f\"Label: {y_train[40]}\")\nplt.imshow(some_digit_image, cmap=\"binary\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model Selection**"},{"metadata":{},"cell_type":"markdown","source":"Using **StratifiedKFold** to ensure that the test data represents samples from all classes (digits) and for cross-validating the model. Using the classification report and confusion matrix to understand the model's performance on each fold."},{"metadata":{"trusted":true},"cell_type":"code","source":"stratified_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, indices in enumerate(stratified_fold.split(X_train, y_train)):\n    # Creating datasets for training and testing the model \n    X_train_, y_train_ = X_train[indices[0]], y_train[indices[0]]\n    X_test_, y_test_ = X_train[indices[1]], y_train[indices[1]]\n    \n    estimator = KNeighborsClassifier()\n    estimator.fit(X_train_, y_train_)\n    predictions = estimator.predict(X_test_)\n    \n    print(f\"Classification report for Fold {fold + 1}:\")\n    print(classification_report(y_test_, predictions, digits=3), end=\"\\n\\n\")\n    \n    print(f\"Confusion Matrix for Fold {fold + 1}:\")\n    print(confusion_matrix(y_test_, predictions), end=\"\\n\\n\")\n    \n    del X_train_\n    del X_test_\n    del y_train_\n    del y_test_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fine-tuning the model by finding the best values for the hyperparameters (weights, n_neighbors) using GridSearchCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_params = {\n    \"weights\": ['uniform', 'distance'],\n    \"n_neighbors\": [3, 4, 5, 6, 8, 10]\n}\n\nestimator = KNeighborsClassifier()\ngrid_estimator = GridSearchCV(estimator, # Base estimator\n                              grid_params, # Parameters to tune\n                              cv=stratified_fold, # cross-validation stratergy\n                              verbose=2, # Verbosity of the logs\n                              n_jobs=-1) # Number of jobs to be run concurrently with -1 meaning all the processors\n\n\"\"\"\nCommenting this block to reduce the notebook execution time\n\"\"\"\n\n# Fitting the estimator with training data\n# grid_estimator.fit(X_train, y_train)\n\n# print(f\"Best Score: {grid_estimator.best_score_}\", end=\"\\n\\n\")\n# print(f\"Best Parameters: \\n{json.dumps(grid_estimator.best_params_, indent=4)}\",\n#       end=\"\\n\\n\")\n# print(\"Grid Search CV results:\")\n# results_df = pd.DataFrame(grid_estimator.cv_results_)\n# results_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Best parameter values found:** {n_neighbors: 4, weights: 'distance'}"},{"metadata":{},"cell_type":"markdown","source":"Fitting a new model with the found hyperparameter values to the training data and making predictions on the test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"estimator = KNeighborsClassifier(n_neighbors=4, weights='distance')\nestimator.fit(X_train, y_train)\npredictions = estimator.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Augmentation**"},{"metadata":{},"cell_type":"markdown","source":"Each image in the training set is \n\n* shifted down, up, left and right by one pixel\n* rotated clockwise and anti-clockwise \n* clipped and zoomed at two different ranges\n\ngenerating eight different images. The image is clipped before zooming to preserve the image size."},{"metadata":{"trusted":true},"cell_type":"code","source":"def shift_in_one_direction(image, direction):\n    \"\"\"\n    Shifts an image by one pixel in the specified direction\n    \"\"\"\n    if direction == \"DOWN\":\n        image = shift(image, [1, 0])\n    elif direction == \"UP\":\n        image = shift(image, [-1, 0])\n    elif direction == \"LEFT\":\n        image = shift(image, [0, -1])\n    else:\n        image = shift(image, [0, 1])\n\n    return image\n\n\ndef shift_in_all_directions(image):\n    \"\"\"\n    Shifts an image in all the directions by one pixel\n    \"\"\"\n    reshaped_image = image.reshape(28, 28)\n\n    down_shifted_image = shift_in_one_direction(reshaped_image, \"DOWN\")\n    up_shifted_image = shift_in_one_direction(reshaped_image, \"UP\")\n    left_shifted_image = shift_in_one_direction(reshaped_image, \"LEFT\")\n    right_shifted_image = shift_in_one_direction(reshaped_image, \"RIGHT\")\n\n    return (down_shifted_image, up_shifted_image,\n            left_shifted_image, right_shifted_image)\n\n\ndef rotate_in_all_directions(image, angle):\n    \"\"\"\n    Rotates an image clockwise and anti-clockwise\n    \"\"\"\n    reshaped_image = image.reshape(28, 28)\n    \n    rotated_images = (rotate(reshaped_image, angle, reshape=False),\n                      rotate(reshaped_image, -angle, reshape=False))\n    \n    return rotated_images\n\n\ndef clipped_zoom(image, zoom_ranges):\n    \"\"\"\n    Clips and zooms an image at the specified zooming ranges\n    \"\"\"\n    reshaped_image = image.reshape(28, 28)\n    \n    h, w = reshaped_image.shape\n    \n    zoomed_images = []\n    for zoom_range in zoom_ranges:\n        zh = int(np.round(h / zoom_range))\n        zw = int(np.round(w / zoom_range))\n        top = (h - zh) // 2\n        left = (w - zw) // 2\n        \n        zoomed_images.append(zoom(reshaped_image[top:top+zh, left:left+zw],\n                                  zoom_range))\n    \n    return zoomed_images\n\ndef alter_image(image):\n    \"\"\"\n    Alters an image by shifting, rotating, and zooming it\n    \"\"\"\n    shifted_images = shift_in_all_directions(image)\n    rotated_images = rotate_in_all_directions(image, 10)\n    zoomed_images = clipped_zoom(image, [1.1, 1.2])\n            \n    return np.r_[shifted_images, rotated_images, zoomed_images]\n\nX_train_add = np.apply_along_axis(alter_image, 1, X_train).reshape(-1, 784)\ny_train_add = np.repeat(y_train, 8)\n\nprint(f\"X_train_add shape: {X_train_add.shape}\")\nprint(f\"y_train_add shape: {y_train_add.shape}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Combining the synthesized data with the actual training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_combined = np.r_[X_train, X_train_add]\ny_train_combined = np.r_[y_train, y_train_add]\n\ndel X_train\ndel X_train_add\ndel y_train\ndel y_train_add\n\nprint(f\"X_train_combined shape: {X_train_combined.shape}\")\nprint(f\"y_train_combined shape: {y_train_combined.shape}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fitting a new model with the tuned hyperparameters to the combined dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"cdata_estimator = KNeighborsClassifier(n_neighbors=4, weights='distance')\ncdata_estimator.fit(X_train_combined, y_train_combined)\ncdata_estimator_predictions = cdata_estimator.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Generating the submission file"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df[\"Label\"] = predictions\nsubmission_df.to_csv('submission.csv', index=False)\nFileLink('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df[\"Label\"] = cdata_estimator_predictions\nsubmission_df.to_csv('cdata_submission.csv', index=False)\nFileLink('cdata_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Note:** With **Data Augmentation** the accuracy jumped from 97.185% to 98.128% on the test data."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}