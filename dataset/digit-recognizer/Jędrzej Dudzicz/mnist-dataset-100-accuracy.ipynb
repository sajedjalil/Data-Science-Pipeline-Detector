{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Experimenting on MNIST","metadata":{}},{"cell_type":"markdown","source":"### About MNIST Dataset","metadata":{}},{"cell_type":"markdown","source":" The **MNIST** database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems\n \n The **MNIST** database contains 60,000 training images and 10,000 testing images.\n Photo size: **28x28 p**.","metadata":{}},{"cell_type":"markdown","source":"### The Purpose of notebook","metadata":{}},{"cell_type":"markdown","source":"I will design and try two neural networks to get ~100% accuracy\n- MLP (Multilayer perceptron)\n\n- CNN (Convolutional neural network)","metadata":{}},{"cell_type":"markdown","source":"**Update:**\n- I made this notebook 7 months ago, and it is one of my first data science projects. During this time I learned a lot of interesting things and put these things in here.","metadata":{}},{"cell_type":"markdown","source":"### Importing libs","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nnp.random.seed(0) \nimport random\n\nimport tensorflow.keras as keras\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\nfrom keras.utils.vis_utils import plot_model\n\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  Reading data","metadata":{}},{"cell_type":"code","source":"# (X_train, y_train), (X_test, y_test) = mnist.load_data()\ntrain = pd.read_csv(\"../input/digit-recognizer/train.csv\")\ntest = pd.read_csv(\"../input/digit-recognizer/test.csv\")\n\n\nX_train = train.drop(labels = [\"label\"], axis = 1)\ny_train = train['label']\n\nX_test = test\n\nprint(X_train.shape, X_test.shape)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"X_train_plot = X_train.values.reshape(-1, 28, 28)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Show_example_digits(mono = 'gray'):\n    fig = plt.figure(figsize = (16, 16))\n    for idx in range(15):\n        plt.subplot(5, 5,idx+1)\n        plt.imshow(X_train_plot[idx], cmap = mono)\n        plt.title(\"Digit {}\".format(y_train[idx]))\n        \n    plt.tight_layout()\n    \nShow_example_digits()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function return digit in grayscale\ndef plot_digit(digit, dem = 28, font_size = 12):\n    max_ax = font_size * dem\n    \n    fig = plt.figure(figsize=(13, 13))\n    plt.xlim([0, max_ax])\n    plt.ylim([0, max_ax])\n    plt.axis('off')\n    black = '#000000'\n    \n    for idx in range(dem):\n        for jdx in range(dem):\n\n            t = plt.text(idx * font_size, max_ax - jdx*font_size, digit[jdx][idx], fontsize = font_size, color = black)\n            c = digit[jdx][idx] / 255.\n            t.set_bbox(dict(facecolor=(c, c, c), alpha = 0.5, edgecolor = 'black'))\n            \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rand_number = random.randint(0, len(y_train))\nprint(y_train[rand_number])\nplot_digit(X_train_plot[rand_number])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Chart of the number of digits in the data","metadata":{}},{"cell_type":"code","source":"digit_range = np.arange(10)\n\nval = y_train.value_counts().index\ncnt = y_train.value_counts().values\nmycolors = ['red', 'blue', 'green', 'orange', 'brown', 'grey', 'pink', 'olive', 'deeppink', 'steelblue']\n\nplt.figure(figsize = (15, 7))\nplt.title(\"The number of digits in the data\", fontsize = 20)\nplt.xticks(range(10))\nplt.bar(val, cnt, color = mycolors);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preparing","metadata":{}},{"cell_type":"code","source":"img_rows, img_cols = 28, 28\n\nnum_pixels = X_train.shape[1] \n\ninput_shape = (img_rows, img_cols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Normalization [0, 1]\nX_train /= 255\nX_test /= 255\n\n# one-hot encoding for target column\ny_train = to_categorical(y_train)\n\n# | [0, 1, 2, ... , 9] | = 10\nnum_classes = y_train.shape[1]\n\n# Number of objects, vector size (28 * 28)\nprint(X_train.shape, X_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Split data\n\nadded stratified folds","metadata":{}},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state = 2, stratify=y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## MLP ([Multilayer perceptron](https://en.wikipedia.org/wiki/Multilayer_perceptron))","metadata":{}},{"cell_type":"markdown","source":"### Structure","metadata":{}},{"cell_type":"markdown","source":"Firstly, let's think how the network should look like. It will have three layers:\n\n1 Input Layer\n\n2 Hidden Layer\n\n3 Output Layer\n","metadata":{}},{"cell_type":"markdown","source":"![MLP](https://miro.medium.com/max/700/1*-IPQlOd46dlsutIbUq1Zcw.png)","metadata":{}},{"cell_type":"markdown","source":"Input layer has 28 * 28 pixels reshape to vector\n\nHidden layer has a lot of neurons\n\nOutput layer has 10 neurons ","metadata":{}},{"cell_type":"markdown","source":"Design network with using keras \n\nThe metrics we use are f1_score","metadata":{}},{"cell_type":"code","source":"def f1(y_true, y_pred):\n    def recall(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives / (possible_positives + K.epsilon())\n        return recall\n\n    def precision(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n    \n    precision = precision(y_true, y_pred)\n    recall = recall(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Function to drawing learning curve history learning neural network\n\n","metadata":{}},{"cell_type":"code","source":"def draw_learning_curve(history, keys=['f1', 'loss']):\n    plt.figure(figsize=(20,8))\n    for i, key in enumerate(keys):\n        plt.subplot(1, 2, i + 1)\n        sns.lineplot(x = history.epoch, y = history.history[key])\n        sns.lineplot(x = history.epoch, y = history.history['val_' + key])\n        plt.title('Learning Curve')\n        plt.ylabel(key.title())\n        plt.xlabel('Epoch')\n#         plt.ylim(ylim)\n        plt.legend(['train', 'test'], loc='best')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Adding Callbacks\n- EarlyStopping (Stop training when a monitored metric has stopped improving)\n- ReduceLROnPlateau (Reduce learning rate when a metric has stopped improving)\n- ModelCheckpoint (Callback to save the Keras model or model weights at some frequency)","metadata":{}},{"cell_type":"code","source":"def callbacks(name): \n    return [ \n        EarlyStopping(monitor = 'loss', patience = 6), \n        ReduceLROnPlateau(monitor = 'loss', patience = 3), \n        ModelCheckpoint(f'../working/{name}.hdf5', save_best_only=True) # saving the best model\n    ]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Simple MLP with one hidden layer","metadata":{}},{"cell_type":"code","source":"def get_mlp():\n    \n    return Sequential([\n        #input layer is automatic generation by keras\n        \n        #hidden layer\n        Dense(512, input_dim = num_pixels, activation='relu'),\n        \n        #output layer\n        Dense(num_classes, activation='softmax')\n    ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_mlp()\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our network has 407,050 params (weights)","metadata":{}},{"cell_type":"markdown","source":"#### You can use **GPU** to accelerate training","metadata":{}},{"cell_type":"code","source":"learning_history = model.fit(X_train, y_train,\n          batch_size = 1024, epochs = 40, verbose = 2, callbacks = callbacks('simple_mlp'),\n          validation_data=(X_val, y_val));","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = model.evaluate(X_val, y_val, verbose = 0)\nprint('Test loss: {}%'.format(score[0] * 100))\nprint('Test score: {}%'.format(score[1] * 100))\n\nprint(\"MLP Error: %.2f%%\" % (100 - score[1] * 100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"draw_learning_curve(learning_history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Cool! I get ~98% accuracy with easy model MLP and i didn't work too much.\n\nAccording to Pareto principle 80/20 in this case 20% work generate ~80%~ 98% accuracy :)","metadata":{}},{"cell_type":"markdown","source":"#### Adding new layer and Dropout to avoid overfitting","metadata":{}},{"cell_type":"code","source":"def get_mlpv2():\n    \n    return Sequential([\n        Dense(512, input_dim=num_pixels, activation='relu'),\n        Dropout(0.3),\n        Dense(256, activation='relu'),\n        Dropout(0.2),\n        Dense(128, activation='relu'),\n        Dense(num_classes, activation='softmax')\n    ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_mlpv2()\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Run new model ","metadata":{}},{"cell_type":"code","source":"learning_history = model.fit(X_train, y_train,\n          batch_size = 1024, epochs = 40, verbose = 2, callbacks = callbacks('mlp_reg'),\n          validation_data=(X_val, y_val));","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"draw_learning_curve(learning_history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = model.evaluate(X_val, y_val, verbose = 0)\nprint('Test loss: {}%'.format(score[0] * 100))\nprint('Test score: {}%'.format(score[1] * 100))\n\nprint(\"MLP Error: %.2f%%\" % (100 - score[1] * 100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### I slightly improved the model, so we keep working.","metadata":{}},{"cell_type":"markdown","source":"## CNN ([Convolutional_neural_network](https://en.wikipedia.org/wiki/Convolutional_neural_network))","metadata":{}},{"cell_type":"markdown","source":"![CNN](https://miro.medium.com/max/1872/1*SGPGG7oeSvVlV5sOSQ2iZw.png)","metadata":{}},{"cell_type":"markdown","source":"CNN consists with:\n- convolution layer\n- in the past MLP","metadata":{}},{"cell_type":"markdown","source":"It will use 3 convolutional layers: (Conv2D, Conv2D, pool)","metadata":{}},{"cell_type":"markdown","source":"#### We need to reshape data.","metadata":{}},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = X_train.values.reshape(-1, 28, 28, 1)\nX_val = X_val.values.reshape(-1, 28, 28, 1)\nX_test = X_test.values.reshape(-1, 28, 28, 1)\ninput_shape = (28, 28, 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_cnn():\n    return Sequential([\n        Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape = input_shape),\n        Conv2D(32, kernel_size=(3, 3), activation='relu' ),\n        MaxPool2D(pool_size=(2, 2)),\n        Dropout(0.25),\n        \n        Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n        Conv2D(64, kernel_size=(3, 3), activation='relu' ),\n        MaxPool2D(pool_size=(2, 2)),\n        Dropout(0.25),\n        \n        Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same' ),\n        Conv2D(128, kernel_size=(3, 3), activation='relu' ),\n        MaxPool2D(pool_size=(2, 2)),\n        Dropout(0.25),\n        \n        \n        Flatten(),\n        \n        Dense(256, activation='relu'),\n        Dropout(0.5),\n        Dense(num_classes, activation = \"softmax\")\n        \n    ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_cnn()\nmodel.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=[f1])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_history = model.fit(X_train, y_train,\n          batch_size = 128,\n          epochs = 50,\n          verbose = 1,\n          callbacks = callbacks('cnn_v1'),\n          validation_data = (X_val, y_val))","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = model.evaluate(X_val, y_val, verbose=0)\nprint('Test loss:', score[0])\nprint('Test score:', score[1])\n\nprint(\"CNN Error: %.2f%%\" % (100-score[1]*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"draw_learning_curve(learning_history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's see in which cases the model is invalid.","metadata":{}},{"cell_type":"markdown","source":"#### Let's assign the values provided by the model","metadata":{}},{"cell_type":"code","source":"y_pred = model.predict(X_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### I made function to visual output","metadata":{}},{"cell_type":"code","source":"def draw_output(idx_nums):\n    plt.figure(figsize = (20, 20))\n    plt.xticks( range(10) )\n    x = np.ceil(np.sqrt(len(idx_nums)))\n    cnt = 1\n    for ph in idx_nums:\n        plt.subplot(x, x, cnt)\n        curr_photo = y_val[ph]\n        \n        plt.xlim(0, 10)\n        plt.title(\"Digit: {0}\\n idx: {1} \".format(np.argmax(y_val[ph]), ph), fontsize = 10) \n        plt.bar(range(10), y_pred[ph])\n        \n        cnt += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The number of errors for the each digit","metadata":{}},{"cell_type":"code","source":"cnt_error = []\nfor idx, (a, b) in enumerate(zip(y_val, y_pred)):\n    if np.argmax(a) == np.argmax(b): continue\n    cnt_error.append( (np.argmax(a)) )\n\ncnt_error = np.unique(cnt_error, return_counts = True)\nsns.set_style(\"darkgrid\")\nplt.figure(figsize = (15, 7))\nbar_plot = sns.barplot(cnt_error[0], cnt_error[1], palette=\"muted\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Let's see these photos (2, 9)","metadata":{}},{"cell_type":"code","source":"cnt_ind = 1\nlist_idx = []\nX_val_plot = X_val.reshape( X_val.shape[:-1] )\nfig = plt.figure(figsize=(14, 14))\n\nfor idx, (a, b) in enumerate(zip(y_val, y_pred)):\n    if np.argmax(a) == np.argmax(b): continue\n    if (np.argmax(a) == 2 or np.argmax(a) == 9):    \n        plt.subplot(5, 5, cnt_ind)\n        plt.imshow(X_val_plot[idx], cmap='gray', interpolation='none')\n        plt.title('y_true={0}\\ny_pred={1}\\n ind = {2}'.format(np.argmax(a), np.argmax(b), idx))\n        plt.tight_layout()\n        list_idx.append(idx)\n        cnt_ind += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Run the `draw_output` function to see the probability of each value occurring","metadata":{}},{"cell_type":"code","source":"draw_output(list_idx)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### As you can see, the model is wrong in cases where the common person would also have trouble finding the correct answer.","metadata":{}},{"cell_type":"markdown","source":"## Data Augmentation","metadata":{}},{"cell_type":"markdown","source":"#### I will try to improve the result by expanding the data. You have to be careful when rotating your photos not to misclassify numbers such as 9 and 6.\n\n#### Data augmentation:\n\nRandomly shift images horizontally by 10% of the width\n\nRandomly shift images vertically by 10% of the height\n\nRandomly rotate images by 10 degrees\n\nRandomly Zoom by 10% some images\n","metadata":{}},{"cell_type":"code","source":"train_aug = ImageDataGenerator(\n        featurewise_center = False,\n        samplewise_center = False,\n        featurewise_std_normalization = False, \n        samplewise_std_normalization = False,\n        zca_whitening = False,\n        horizontal_flip = False,\n        vertical_flip = False,\n        fill_mode = 'nearest',\n        rotation_range = 10,  \n        zoom_range = 0.1, \n        width_shift_range = 0.1, \n        height_shift_range = 0.1)\n        \n\ntrain_aug.fit(X_train)\ntrain_gen = train_aug.flow(X_train, y_train, batch_size=64)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Building new model and using batch normalization","metadata":{}},{"cell_type":"code","source":"def get_cnn_v2():\n    return Sequential([\n        Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape = input_shape),\n        Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n        BatchNormalization(),\n        MaxPool2D(pool_size=(2, 2)),\n        Dropout(0.25),\n        \n        Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n        Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same' ),\n        BatchNormalization(),\n        MaxPool2D(pool_size=(2, 2)),\n        Dropout(0.25),\n        \n        Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same' ),\n        Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same' ),\n        BatchNormalization(),\n        MaxPool2D(pool_size=(2, 2)),\n        Dropout(0.25),\n        \n        \n        Flatten(),\n          \n        Dense(512, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.5),\n        \n        Dense(256, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.4),\n        \n        Dense(64, activation='relu'),\n        BatchNormalization(),\n        Dropout(0.3),\n        \n        Dense(num_classes, activation = \"softmax\")\n        \n    ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_cnn_v2()\nmodel.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=[f1])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_history = model.fit_generator(train_gen, epochs = 100, \n                               steps_per_epoch = X_train.shape[0] // 64,\n                               validation_data = (X_val, y_val),\n                               callbacks = callbacks('best_cnn'),\n                             )","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Loading the best model","metadata":{}},{"cell_type":"code","source":"model = load_model('../working/best_cnn.hdf5', custom_objects={\"f1\": f1})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = model.evaluate(X_val, y_val, verbose=0)\nprint('Test loss:', score[0])\nprint('Test score:', score[1])\n\nprint(\"CNN Error: %.2f%%\" % (100-score[1]*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"draw_learning_curve(learning_history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### We achieved a great result of 99.6% accuracy","metadata":{}},{"cell_type":"markdown","source":"# Generate output","metadata":{}},{"cell_type":"code","source":"output = model.predict(X_test)\n\noutput = np.argmax(output, axis = 1)\n\noutput = pd.Series(output, name=\"Label\")\n\nsubmission = pd.concat([pd.Series(range(1,28001), name = \"ImageId\"), output], axis = 1)\n\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bonus","metadata":{}},{"cell_type":"markdown","source":"Let's see, using additional data, how this will affect the final result.","metadata":{}},{"cell_type":"code","source":"def load_data(path):\n    with np.load(path) as f:\n        x_train, y_train = f['x_train'], f['y_train']\n        x_test, y_test = f['x_test'], f['y_test']\n        return (x_train, y_train), (x_test, y_test)\n\n(x_train1, y_train1), (x_test1, y_test1) = load_data('../input/mnist-numpy/mnist.npz')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train1 = x_train1 / 255\nx_test1 = x_test1 / 255\n\nx_train1 = x_train1.reshape(-1, 28, 28, 1)\nx_test1 = x_test1.reshape(-1, 28, 28, 1)\n\ny_train1 = y_train1.reshape(y_train1.shape[0], 1)\ny_test1 = y_test1.reshape(y_test1.shape[0], 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Add_X = np.vstack((x_train1, x_test1))\n\nAdd_y = np.vstack((y_train1, y_test1))\n\nAdd_y = to_categorical(Add_y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/digit-recognizer/train.csv\")\n\nX_train = train.drop(labels = [\"label\"], axis = 1)\ny_train = train['label']\ny_train = to_categorical(y_train)\n\nX_train /= 255\nX_train = X_train.values.reshape(-1, 28, 28, 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"add_train_aug = ImageDataGenerator(\n        featurewise_center = False,\n        samplewise_center = False,\n        featurewise_std_normalization = False, \n        samplewise_std_normalization = False,\n        zca_whitening = False,\n        horizontal_flip = False,\n        vertical_flip = False,\n        fill_mode = 'nearest',\n        rotation_range = 10,  \n        zoom_range = 0.1, \n        width_shift_range = 0.1, \n        height_shift_range = 0.1)\n        \n\nadd_train_aug.fit(Add_X)\nadd_train_gen = add_train_aug.flow(Add_X, Add_y, batch_size=64)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_cnn_v2()\nmodel.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=[f1])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_history = model.fit_generator((add_train_gen), epochs = 100, \n                               steps_per_epoch = x_train1.shape[0] // 64,\n                               validation_data = (X_val, y_val),\n                               callbacks = callbacks('cnn_bonus'),\n                             )","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = load_model('cnn_bonus.hdf5', custom_objects={\"f1\": f1})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = model.evaluate(X_val, y_val, verbose=0)\nprint('Test loss:', score[0])\nprint('Test score:', score[1])\n\nprint(\"CNN Error: %.2f%%\" % (100-score[1]*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"draw_learning_curve(learning_history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### As you can see, even with such a large data set, we do not get 100% accuracy","metadata":{}},{"cell_type":"markdown","source":"## Visualize Model","metadata":{}},{"cell_type":"code","source":"plot_model(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Occlusion sensitivity","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"plt.imshow(X_train[0].reshape(28, 28), cmap='gray');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def apply_grey_patch(image, top_left_x, top_left_y, patch_size):\n    patched_image = np.array(image, copy=True)\n    patched_image[top_left_y:top_left_y + patch_size, top_left_x:top_left_x + patch_size, :] = 0\n\n    return patched_image\n\n\nimg = X_train[0]\n\nPATCH_SIZE = 4\nsensitivity_map = np.zeros((img.shape[0], img.shape[0]))\n\nfor top_left_x in range(0, img.shape[0], PATCH_SIZE):\n    for top_left_y in range(0, img.shape[1], PATCH_SIZE):\n        patched_image = apply_grey_patch(img, top_left_x, top_left_y, PATCH_SIZE)\n        \n        \n        predicted_classes = model.predict(np.array([patched_image]))[0]\n        confidence = predicted_classes[1]\n        \n        sensitivity_map[\n            top_left_y:top_left_y + PATCH_SIZE,\n            top_left_x:top_left_x + PATCH_SIZE,\n        ] = confidence\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(sensitivity_map, cmap='gray');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate bonus output","metadata":{}},{"cell_type":"code","source":"output = model.predict(X_test)\n\noutput = np.argmax(output, axis = 1)\n\noutput = pd.Series(output, name=\"Label\")\n\nsubmission = pd.concat([pd.Series(range(1,28001), name = \"ImageId\"), output], axis = 1)\n\nsubmission.to_csv(\"bonus_submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Final step: Conclusions\n\n#### I achieved the following results:\n- MLP: ~98% f1\n- CNN: ~100% f1\n\nI have created a model that recognizes handwritten numbers. You can try to get more data to make the model even better.\n\n\n#### This is my first notebook.\n\n#### I would love to know your comments and note about this.","metadata":{}},{"cell_type":"markdown","source":"<font size=\"3\">\n    <div style=\"text-align: right\"> <b> Author </b> </div>\n</font>\n<div style=\"text-align: right\"> JÄ™drzej </div>\n<div style=\"text-align: right\"> Dudzicz </div>","metadata":{}}]}