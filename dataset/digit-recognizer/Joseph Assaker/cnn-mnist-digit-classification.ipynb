{"cells":[{"metadata":{},"cell_type":"markdown","source":"# CNN MNIST Digit Classification ðŸ”¢\n\nIn this notebook we will implement an accurate **Handwritten Digit Classification** model. This model will be built using Tensorflow's Keras API."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Importing useful modules\n\nimport numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\n\nimport os\n\n\n# Printing out the available data\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Reading in the training data into 2 lists: X_train containg the images and Y the labels\n\nX_train = []\nY_train = []\n\nwith open('/kaggle/input/digit-recognizer/train.csv') as train_file:\n    for line in train_file.readlines()[1:]:\n        content = line.strip().split(',')\n        label, image_raw_data = content[0], content[1:]\n        image_np = np.array_split(np.array(image_raw_data), 28)\n        X_train.append(image_np)\n        Y_train.append(label)\n\nX_train = np.array(X_train).astype(float)\nX_train = np.expand_dims(X_train, axis=3)\nY_train = np.array(Y_train).astype(float)\n\nprint(X_train.shape)\nprint(Y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading in the testing data into 1 list: X_test containg the images\n\nX_test = []\n\nwith open('/kaggle/input/digit-recognizer/test.csv') as test_file:\n    for line in test_file.readlines()[1:]:\n        content = line.strip().split(',')\n        image_raw_data = content[:]\n        image_np = np.array_split(np.array(image_raw_data), 28)\n        X_test.append(image_np)\n\nX_test = np.array(X_test).astype(float)\nX_test = np.expand_dims(X_test, axis=3)\n\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Downloading fonts from Github\n\n\n!wget --recursive --no-parent 'https://github.com/google/fonts/raw/master/apache/opensans/OpenSans-Regular.ttf' -P /usr/local/lib/python3.6/dist-packages/matplotlib/mpl-data/fonts/ttf\n!wget --recursive --no-parent 'https://github.com/google/fonts/raw/master/apache/opensans/OpenSans-Light.ttf' -P /usr/local/lib/python3.6/dist-packages/matplotlib/mpl-data/fonts/ttf\n!wget --recursive --no-parent 'https://github.com/google/fonts/raw/master/apache/opensans/OpenSans-SemiBold.ttf' -P /usr/local/lib/python3.6/dist-packages/matplotlib/mpl-data/fonts/ttf\n!wget --recursive --no-parent 'https://github.com/google/fonts/raw/master/apache/opensans/OpenSans-Bold.ttf' -P /usr/local/lib/python3.6/dist-packages/matplotlib/mpl-data/fonts/ttf","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"# Plotting the output labels distribution\n\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n\n\nmpl.font_manager._rebuild()\n\nplt.rc('font', family='Open Sans')\n\nfig, ax = plt.subplots(figsize=(10, 5), dpi=240)\n\nbars = ax.bar(\n    x=np.unique(Y_train, return_counts=True)[0],\n    height=np.unique(Y_train, return_counts=True)[1],\n    tick_label=np.unique(Y_train, return_counts=True)[0].astype(int)\n)\n\nax.spines['top'].set_visible(False)\nax.spines['right'].set_visible(False)\nax.spines['left'].set_visible(False)\nax.spines['bottom'].set_color('#DDDDDD')\nax.tick_params(bottom=False, left=False)\nax.set_axisbelow(True)\nax.yaxis.grid(True, color='#EEEEEE')\nax.xaxis.grid(False)\n\nbar_color = bars[0].get_facecolor()\nfor bar in bars:\n    ax.text(\n        bar.get_x() + bar.get_width() / 2,\n        bar.get_height() + 50,\n        round(bar.get_height(), 1),\n        horizontalalignment='center',\n        color=bar_color,\n        weight='bold'\n    )\n\nax.set_xlabel('Label', labelpad=20, color='#333333', fontsize=12)\nax.set_ylabel('Number of Training Samples', labelpad=16, color='#333333', fontsize=12)\nax.set_title('Label Counts Distribution', pad=14, color='#333333', fontsize=18, weight='bold')\n\nxl, yl, xh, yh=np.array(ax.get_position()).ravel()\nw=xh-xl\nh=yh-yl\nsize=0.075\n\nfor i in range(10):\n    xp=xl+w*(0.06 + (0.106 * i))\n    ax1=fig.add_axes([xp-size*0.5, 0.075, size, size])\n    ax1.axison = False\n    imgplot = ax1.imshow(X_train[np.where(Y_train==i)[0][0]].reshape((28,28)),cmap='Blues', vmin=0, vmax=255)\n\nfig.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting 10 examples from each output class\n\nfrom collections import defaultdict\n\nf, axes = plt.subplots(10, 10, figsize=(16, 18))\n\ncounter = defaultdict(int)\n\nfor i in range(1000):\n    label = int(Y_train[i])\n    if counter[label] >= 10: continue\n    img = X_train[i].reshape((28,28))\n    axes[counter[label], label].imshow(img)\n    axes[counter[label], label].set_title(label)\n    counter[label] += 1\n        \n[ax.set_axis_off() for ax in axes.ravel()]\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining the model, compiling and fitting it to the data\n\nmodel = tf.keras.models.Sequential([\n    tf.keras.Input(shape=(28, 28, 1)),\n    tf.keras.layers.Dropout(0.25),\n    tf.keras.layers.Conv2D(32, (5,5), activation='relu', kernel_initializer = 'he_uniform', padding=\"SAME\"),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(32, (5,5), activation='relu', kernel_initializer = 'he_uniform', padding=\"SAME\"),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer = 'he_uniform', padding=\"SAME\"),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', kernel_initializer = 'he_uniform', padding=\"SAME\"),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer = 'he_uniform', padding=\"SAME\"),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu', kernel_initializer = 'he_uniform', padding=\"SAME\"),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512, activation='relu', kernel_initializer = 'he_uniform'),\n    tf.keras.layers.Dropout(rate=0.5),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(256, activation='relu', kernel_initializer = 'he_uniform'),\n    tf.keras.layers.Dropout(rate=0.5),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(128, activation='relu', kernel_initializer = 'he_uniform'),\n    tf.keras.layers.Dropout(rate=0.5),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(64, activation='relu', kernel_initializer = 'he_uniform'),\n    tf.keras.layers.Dropout(rate=0.5),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(10, activation='softmax')\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.summary()\n\nearly_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\", mode='max', patience=25)\n\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint('./best_model.hdf5', monitor='accuracy',\n                                                               mode='max', verbose=1, save_best_model=True)\n\nreduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy', mode='max', patience=15,\n                                                          verbose=1, factor=0.5, min_lr=0.0001)\n\nhistory = model.fit(\n    X_train / 255,\n    tf.keras.utils.to_categorical(Y_train, num_classes=10),\n    epochs=1000,\n    shuffle=True,\n    callbacks=[early_stopping_callback, model_checkpoint_callback,reduce_lr_callback]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the training and pseudo-validation accuracies\n\nacc = history.history['accuracy']\nloss = history.history['loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.title('Training Accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'b', label='Training Loss')\nplt.title('Training Loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predicting on the test set and saving it into a CSV submission file\n\npredictions = model.predict(X_test / 255)\ny_pred = np.argmax(predictions, axis=-1)\n\nsubmission_df = pd.DataFrame(data={\n    'ImageId': np.arange(1, X_test.shape[0] + 1),\n    'label': y_pred\n})\nsubmission_df.to_csv('submission.csv', index=False)\nsubmission_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting 100 prediction examples\n\nf, axes = plt.subplots(10, 10, figsize=(16, 18))\n\ncounter = defaultdict(int)\n\nfor i in range(100):\n    label = int(y_pred[i])\n    img = X_test[i].reshape((28,28))\n    axes[i % 10, i // 10].imshow(img)\n    axes[i % 10, i // 10].set_title(label)\n    counter[label] += 1\n        \n[ax.set_axis_off() for ax in axes.ravel()]\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}