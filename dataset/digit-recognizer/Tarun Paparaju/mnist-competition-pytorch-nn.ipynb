{"cells":[{"metadata":{},"cell_type":"markdown","source":"<center><img src=\"https://i.imgur.com/1qejfmD.png\" width=\"750px\"></center>\n\n\n# Introduction\n\nIn this tutorial, I will demonstrate how to build a simple MLP (Vanilla Neural Network) to recognize handwritten digits using PyTorch. These handwritten digit images are taken from the famous **MNIST database** which contains several thousands of (28 x 28) grayscale images representing the ten digits from 0 to 9. MNIST is the classic \"Hello World!\" of machine learning. It is a great place to get started with Deep Learning. The task is to take an image as input and predict which digit it is from 0 to 9 (classification).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Preparing the ground","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Import necessary libraries\n\n* Now, we import all the libraries we need.\n* **matplotlib, tqdm, and plotly** for visualization.\n* **numpy, pandas, keras, sklearn, and torch** for modelling.","execution_count":null},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import os\nimport gc\nimport time\nimport numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom keras.utils import to_categorical\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom torch.utils.data import Dataset, DataLoader","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Set random seeds\n\n* The next step is to set the random seed for NumPy and PyTorch.\n* Setting the random seed helps us keep training determinstic and ensure reproducible results.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(27)\ntorch.manual_seed(27)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load the training and testing data\n\n* Now we need to load the training and testing data.\n* These dataframes contain the pixel data required to make predictions.","execution_count":null},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('../input/digit-recognizer/test.csv')\ntrain_df = pd.read_csv('../input/digit-recognizer/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling\n\n* Next, we need to build a machine learning pipeline to recognize these handwritten digits.\n* I will use a classic Vanilla Neural Network (VNN) also known as a Multi-layer Perceptron (MLP).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Define PyTorch dataset\n\n* The first step is to build a PyTorch dataset to generate data for our model.\n* A PyTorch dataset has three fundamental functions: <code>init</code>, <code>len</code>, and <code>getitem</code>.\n* The <code>init</code> function initializes all the components required for data loading (image data and labels data)\n* The <code>len</code> function simply returns the length of the dataset. This indicates the number of retrievable samples.\n* The <code>getitem</code> function returns a data point at a given index <code>idx</code>. The actual logic is written in this function.\n* The <code>getitem</code> function does 2 things: gets the target and retrieves the 28 x 28 image at an <code>idx</code> (as a vector).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_tensor(data):\n    return [torch.FloatTensor(point) for point in data]\n\nclass MNISTDataset(Dataset):\n    def __init__(self, df, X_col, y_col):\n        self.features = df[X_col].values/255\n        self.targets = df[y_col].values.reshape((-1, 1))\n\n    def __len__(self):\n        return len(self.targets)\n    \n    def __getitem__(self, idx):\n        return to_tensor([self.features[idx], self.targets[idx]])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Split train/valid (80/20)\n\n* We now split the data into training and validation sets (train: 80%, valid: 20%).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_col = \"label\"\ntest_df[y_col] = [-1]*len(test_df)\n\nsplit = int(0.8*len(train_df))\nvalid_df = train_df[split:].reset_index(drop=True)\ntrain_df = train_df[:split].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define the PyTorch dataloaders\n\n* Now we create train and valid dataloaders to get data batches for the training and validation loops.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_col = list(train_df.columns[1:])\n\ntrain_set = MNISTDataset(train_df, X_col, y_col)\nvalid_set = MNISTDataset(valid_df, X_col, y_col)\n\nvalid_loader = DataLoader(valid_set, batch_size=1024, shuffle=True)\ntrain_loader = DataLoader(train_set, batch_size=1024, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define MLP model\n\n* Next, we define the actual model which we are going to train.\n* The MLP model includes an input layer (**784** neurons), and output layer (**10** neurons).\n* There are two hidden layers of **20** and **15** neurons each (between the input and output layers).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class MLP(nn.Module):\n    def __init__(self, i, u, v, o):\n        super(MLP, self).__init__()\n        self.relu_layer = nn.ReLU()\n        self.dense_1 = nn.Linear(i, u)\n        self.dense_2 = nn.Linear(u, v)\n        self.dense_output = nn.Linear(v, o)\n        \n    def forward(self, x):\n        x = self.relu_layer(self.dense_1(x))\n        x = self.relu_layer(self.dense_2(x))\n        logits = self.dense_output(x); return logits","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define model and optimizer","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda')\nnetwork = MLP(i=784, u=20, v=15, o=10).to(device)\noptimizer = Adam(params=network.parameters(), lr=0.01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(network)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define binary cross entropy and accuracy\n* Next, we define our loss function (binary cross entropy) and evaluation metric (accuracy).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def cel(y_true, y_pred):\n    y_true = y_true.long().squeeze()\n    return nn.CrossEntropyLoss()(y_pred, y_true)\n\ndef acc(y_true, y_pred):\n    y_true = y_true.long().squeeze()\n    y_pred = torch.argmax(y_pred, axis=1)\n    return (y_true == y_pred).float().sum()/len(y_true)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train the model on GPU\n\n* Now, we train the model on the NVIDIA Tesla P100 GPU provided by Kaggle.\n* First, we do a training loop, where we train the model with back-prop to adjust the parameters.\n* Second, we do a validation loop, to check the model's performance on unseen data after each epoch.\n* The training loop uses forward-prop and back-prop, while the validation loop uses only forward-prop.\n* We use the <code>torch.no_grad()</code> flag for the validation loop as no gradients are needed for forward-prop.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.time()\nprint(\"STARTING TRAINING ...\\n\")\n\ntrain_losses, valid_losses = [], []\ntrain_accuracies, valid_accuracies = [], []\n\nfor epoch in range(20):\n    network = network.train()\n    print(\"Epoch: {}\".format(epoch + 1))\n    batch_train_losses, batch_train_accuracies = [], []\n    \n    batch = 0\n    for train_batch in train_loader:\n        train_X, train_y = train_batch\n\n        train_X = train_X.to(device)\n        train_y = train_y.to(device)\n        train_preds = network.forward(train_X)\n        train_loss = cel(train_y, train_preds)\n        train_accuracy = acc(train_y, train_preds)\n        \n        optimizer.zero_grad()\n        train_loss.backward()\n        \n        optimizer.step()\n        train_loss = np.round(train_loss.item(), 3)\n        train_accuracy = np.round(train_accuracy.item(), 3)\n\n        end = time.time()\n        batch = batch + 1\n        log = batch % 10 == 0\n        time_delta = np.round(end - start, 3)\n        \n        batch_train_losses.append(train_loss)\n        batch_train_accuracies.append(train_accuracy)\n        logs = \"Batch: {} || Train Loss: {} || Train Acc: {} || Time: {} s\"\n        if log: print(logs.format(batch, train_loss, train_accuracy, time_delta))\n        \n    train_losses.append(np.mean(batch_train_losses))\n    train_accuracies.append(np.mean(batch_train_accuracies))\n    \n    total_valid_loss = 0\n    total_valid_points = 0\n    total_valid_accuracy = 0\n    \n    with torch.no_grad():\n        for valid_batch in valid_loader:\n            valid_X, valid_y = valid_batch\n            \n            valid_X = valid_X.to(device)\n            valid_y = valid_y.to(device)\n            valid_preds = network.forward(valid_X)\n            valid_loss = cel(valid_y, valid_preds)\n            valid_accuracy = acc(valid_y, valid_preds)\n            \n            total_valid_points += 1\n            total_valid_loss += valid_loss.item()\n            total_valid_accuracy += valid_accuracy.item()\n            \n    valid_loss = np.round(total_valid_loss/total_valid_points, 3)\n    valid_accuracy = np.round(total_valid_accuracy/total_valid_points, 3)\n    \n    valid_losses.append(valid_loss)\n    valid_accuracies.append(valid_accuracy)\n    \n    end = time.time()\n    time_delta = np.round(end - start, 3)\n    logs = \"Epoch: {} || Valid Loss: {} || Valid Acc: {} || Time: {} s\"\n    print(\"\\n\" + logs.format(epoch + 1, valid_loss, valid_accuracy, time_delta) + \"\\n\")\n    \nprint(\"ENDING TRAINING ...\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize metrics over time\n\n* Now, we visualize how the metrics (loss and accuracy) change over time.","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = go.Figure()\n\nfig.add_trace(go.Scatter(x=np.arange(1, len(valid_losses)),\n                         y=valid_losses, mode=\"lines+markers\", name=\"valid\",\n                         marker=dict(color=\"indianred\", line=dict(width=.5,\n                                                                  color='rgb(0, 0, 0)'))))\n\nfig.add_trace(go.Scatter(x=np.arange(1, len(train_losses)),\n                         y=train_losses, mode=\"lines+markers\", name=\"train\",\n                         marker=dict(color=\"darkorange\", line=dict(width=.5,\n                                                                   color='rgb(0, 0, 0)'))))\n\nfig.update_layout(xaxis_title=\"Epochs\", yaxis_title=\"Cross Entropy\",\n                  title_text=\"Cross Entropy vs. Epochs\", template=\"plotly_white\", paper_bgcolor=\"#f0f0f0\")\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The loss seems to converge over time towards a good value (0.18).","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig = go.Figure()\n\nfig.add_trace(go.Scatter(x=np.arange(1, len(valid_accuracies)),\n                         y=valid_accuracies, mode=\"lines+markers\", name=\"valid\",\n                         marker=dict(color=\"indianred\", line=dict(width=.5,\n                                                                  color='rgb(0, 0, 0)'))))\n\nfig.add_trace(go.Scatter(x=np.arange(1, len(train_accuracies)),\n                         y=train_accuracies, mode=\"lines+markers\", name=\"train\",\n                         marker=dict(color=\"darkorange\", line=dict(width=.5,\n                                                                   color='rgb(0, 0, 0)'))))\n\nfig.update_layout(xaxis_title=\"Epochs\", yaxis_title=\"Accuracy\",\n                  title_text=\"Accuracy vs. Epochs\", template=\"plotly_white\", paper_bgcolor=\"#f0f0f0\")\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The accuracy seems to converge over time towards a good value (0.95).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Run inference on the test data\n\n* The final step is to infer the model on the test data.\n* We create a test dataloader and iterate through it using a loop with <code>torch.no_grad()</code> enabled.\n* The generated predictions are passed through the <code>softmax</code> function to convert logits to probabilities.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def softmax(x):\n    return np.exp(x)/np.sum(np.exp(x), axis=1)[:, None]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set = MNISTDataset(test_df, X_col, y_col)\ntest_loader = tqdm(DataLoader(test_set, batch_size=1024, shuffle=False))\n\ntest_preds = []\nwith torch.no_grad():\n    for test_X, _ in test_loader:\n        test_X = test_X.to(device)\n        test_pred = network.forward(test_X)\n        test_preds.append(softmax(test_pred.detach().cpu().numpy()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prepare submission\n\n* Next, we find the indices of maximum probability using <code>np.argmax</code>.\n* These indices represent our final prediction from 0 to 9 (for the digit).","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(\"../input/digit-recognizer/sample_submission.csv\")\nsubmission[\"Label\"] = np.argmax(np.concatenate(test_preds, axis=0), axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize predictions\n\n* Now, we visualize some sample test predictions.\n* The red label above each image is the prediction made by the model.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"test_batch = next(iter(test_loader))[0]\ntest_X = test_batch.reshape(-1, 28, 28)[:36]\nfig, ax = plt.subplots(nrows=6, ncols=6, figsize=(15, 15))\n\nfor i, image in enumerate(test_X):\n    ax[i//6][i%6].axis('off'); ax[i//6][i%6].imshow(image, cmap='gray')\n    ax[i//6][i%6].set_title(np.argmax(test_preds[0][i], axis=0), fontsize=20, color=\"red\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The model is able to classify almost all images. But, it is getting confused in certain cases.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submit submission file\n\n* Finally, we convert our submission dataframe to a .csv file for submission.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Takeaways\n\n* The MLP model is able to predict handwritten digits with an accuracy of 94.7 %.\n* The performance can be improved by using Convolutional Neural Networks (CNNs).\n* CNNs are specialized architectures made for computer vision (built to understand spatial features).\n* Using a flattened 784D vector makes it difficult to capture spatial relationships. But, an MLP is a great start.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}