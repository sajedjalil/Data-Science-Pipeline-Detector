{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Digit Recognizer Using Convolutional Neural Networks With Keras\n\nConvolutional Neural Network(CNN) is a class of deep neural networks. This techniques most commonly applied to analyzing visual imagery. This models used for Image Classification, Segmentation, Object Detection and many other image processing tasks. \nIn this kernel, I will be covering a few famous CNN architectures. We are using keras library for the modeling.\nFew of the models covering this kernel,\n\n1. VGG Net (Visual Geometry Group)\n1. ResNet\n1. Dense Net\n1. Inception Net\n1. Xception Net\n\nWe will start with MNIST data, Digit Recognizer problem.\nhttps://www.kaggle.com/c/digit-recognizer/overview","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"##Load Data\nimport numpy as np\nimport pandas as pd\n\ninput_train = pd.read_csv(\"../input/digit-recognizer/train.csv\")\ninput_test = pd.read_csv(\"../input/digit-recognizer/test.csv\")\nprint(\"Train data Shape : \"+str(input_train.shape))\nprint(\"Test data Shape : \"+str(input_test.shape))\n#Check any missing data\nprint(\"Any missing data : \"+str(np.any(input_train.isnull().sum())))\ninput_train.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##Prepare\nY_train = input_train[\"label\"]\nX_train = input_train.drop(labels = [\"label\"],axis = 1) \n# Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\nX_train = X_train.values.reshape(-1,28,28,1)\nprint(\"Features Shape : \"+str(X_train.shape))\nprint(\"Labels Shape : \"+str(Y_train.shape))\ninput_train.groupby(\"label\",axis=0).size()\n\ndel input_train # free some space","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#View Sample\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.imshow(X_train[1][:,:,0])\nplt.title(\"Actual Value : \"+str(Y_train.iloc[1]))\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Normalize\nX_train = X_train / 255\nX_train  = X_train.round()\ninput_test = input_test / 255\ninput_test  = input_test.round()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### One hot encoding on labels\nWe can observe that labels are in the range of 0-9, but for clasification we will convert that into onehot encoding. Refer : https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nY_train = to_categorical(Y_train, num_classes = 10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cross Validation\nWe need to split our data set for validation. Read more about it : https://towardsdatascience.com/why-and-how-to-cross-validate-a-model-d6424b45261f\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nrandom_seed = 2\n# Split the train and the validation set for the fitting\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Augmentation\n<span>**Why** :  to create more images for training data set.<span>\n    \n<span>**How** : By modifing existing images. <span>\n\nhttps://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Deep Netural Network Modeling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"###Loading libraries\nfrom keras.models import Sequential, Model\nfrom keras.layers import Input,concatenate,DepthwiseConv2D,Activation, Dense, Dropout, Flatten, Conv2D, MaxPool2D, MaxPooling2D, BatchNormalization\nfrom keras.optimizers import RMSprop, SGD\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are planning to train our model iteratively. So, We need to save the best model and also if we find out accuracy is going to outof control we are reducing our lerning rate.\nI'm using keras callbacks for that.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate_model(model,X_train,Y_train,X_val,Y_val,saveModelName,epochs,batch_size):\n    filepath=saveModelName+\".hdf5\"\n    best_accuracy_model = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n    learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n    history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val),\n                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n                              , callbacks=[learning_rate_reduction,best_accuracy_model]) \n    model.load_weights(filepath)\n    return model,history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Plotting train and test accuracy/loss\ndef plot_results(history):\n    fig, ax = plt.subplots(2,1)\n    ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n    ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n    legend = ax[0].legend(loc='best', shadow=True)\n\n    ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n    ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n    legend = ax[1].legend(loc='best', shadow=True)\n    \n# Saving results\nresult_table_columns = ['CNN Model','Train Accuracy','Test Accuracy']\nresults = pd.DataFrame(columns=result_table_columns)\n\ndef add_result(name,history,results,row):\n    results.loc[row,'CNN Model'] = name\n    results.loc[row,'Train Accuracy'] = history.history['accuracy'][np.argmax(history.history['val_accuracy'])]\n    results.loc[row,'Test Accuracy'] = max(history.history['val_accuracy'])\n    return results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##First we try with simple model with no shape reformating\ndef singelHiddenLayer(pixelcount):\n    model = Sequential()\n    model.add(Dense(pixelcount, input_dim=pixelcount, kernel_initializer='normal', activation='relu'))\n    model.add(Dense(10, kernel_initializer='normal', activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    print(model.summary())\n    return model\n\nflat_X_train = X_train.reshape((X_train.shape[0],-1))\nmodel = singelHiddenLayer(flat_X_train.shape[1])\nmodel.fit(flat_X_train, Y_train,epochs=15, batch_size=200, verbose=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### VGG(Visual Geometry Group)\n\n![](https://neurohive.io/wp-content/uploads/2018/11/vgg16.png)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"##To get Idea start with simple CNN model\n#[[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n#Method decription\n# 2C = 2 Conv2D\n# M = MaxPool2D\n# Dr = Dropout\n# F = Flatten\n# D = Dense\ndef model_2CMDr_2CMDr_FDDr_D():\n    model = Sequential()\n    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'same', activation ='relu', input_shape = (28,28,1)))\n    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'same', activation ='relu'))\n    model.add(MaxPool2D(pool_size=(2,2)))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'same', activation ='relu'))\n    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'same', activation ='relu'))\n    model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(256, activation = \"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(10, activation = \"softmax\"))\n    print(model.summary())\n    optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n    model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 5 # Change this to 35 for best results\nmodel = model_2CMDr_2CMDr_FDDr_D()\nprint(\"Starting evaluation\")\nmodel,history = evaluate_model(model,X_train,Y_train,X_val,Y_val,\"model_2CMDr_2CMDr_FDDr_D.best\",epochs,64)\nplot_results(history)\n\nresults = add_result(\"2CMDr_2CMDr_FDDr_D\",history,results,0)\nresults","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def vgg_model(n_filters,n_conv):\n    visible = Input(shape=(28, 28, 1))\n    layers= visible\n    for _ in range(n_conv):\n        layers = Conv2D(n_filters, (3,3), padding='same', activation='relu')(layers)\n    #add max pooling layer\n    layers = MaxPooling2D((2,2), strides=(2,2))(layers)\n    layers = Flatten()(layers)\n    output = Dense(10,activation='softmax')(layers)\n    model = Model(inputs=visible, outputs=output)\n    print(model.summary())\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n\nmodel = vgg_model(64,4)\nprint(\"Starting evaluation\")\nmodel,history = evaluate_model(model,X_train,Y_train,X_val,Y_val,\"model_vgg_64_4.best\",epochs,64)\nplot_results(history)\nresults = add_result(\"vgg_64_4\",history,results,1)\nresults","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_vgg_batchNormalize():\n    model = Sequential()\n\n    model.add(Conv2D(32,kernel_size=3,activation='relu',input_shape=(28,28,1)))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32,kernel_size=3,activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32,kernel_size=3,activation='relu',padding='same'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(32,kernel_size=5,strides=2,padding='same',activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n\n    model.add(Conv2D(64,kernel_size=3,activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64,kernel_size=3,activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(64,kernel_size=5,strides=2,padding='same',activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n    \n    model.add(BatchNormalization())\n    model.add(Conv2D(256,kernel_size=3,activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(256,kernel_size=5,strides=2,padding='same',activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n    \n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.4))\n    model.add(Dense(10, activation='softmax'))\n    print(model.summary())\n    \n    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    return model\n\nmodel = model_vgg_batchNormalize()\nprint(\"Starting evaluation\")\nmodel,history = evaluate_model(model,X_train,Y_train,X_val,Y_val,\"model_vgg_batchNormalize.best\",epochs,64)\nplot_results(history)\nresults = add_result(\"vgg_batchNormalize\",history,results,2)\nresults","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Inception\n\n![](https://www.jeremyjordan.me/content/images/2018/04/inception-model.png)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_Inception():\n    input_img = Input(shape=(28, 28, 1))\n    # Layer 1\n    layer1_tower_0 = Conv2D(16, (1, 1), padding='same', activation='relu')(input_img)\n    layer1_tower_1 = Conv2D(16, (1, 1), padding='same', activation='relu')(input_img)\n    layer1_tower_1 = Conv2D(16, (3, 3), padding='same', activation='relu')(layer1_tower_1)\n    \n    layer1_tower_2 = Conv2D(16, (1, 1), padding='same', activation='relu')(input_img)\n    layer1_tower_2 = Conv2D(16, (5, 5), padding='same', activation='relu')(layer1_tower_2)\n\n    layer1_tower_3 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(input_img)\n    layer1_tower_3 = Conv2D(16, (1, 1), padding='same', activation='relu')(layer1_tower_3)\n\n    layer1_output = concatenate([layer1_tower_1, layer1_tower_2, layer1_tower_3, layer1_tower_0], axis=1)\n\n    # Layer 2\n    layer2_tower_0 = Conv2D(16, (1, 1), padding='same', activation='relu')(layer1_output)\n    layer2_tower_1 = Conv2D(16, (1, 1), padding='same', activation='relu')(layer1_output)\n    layer2_tower_1 = Conv2D(16, (3, 3), padding='same', activation='relu')(layer2_tower_1)\n\n    layer2_tower_2 = Conv2D(16, (1, 1), padding='same', activation='relu')(layer1_output)\n    layer2_tower_2 = Conv2D(16, (5, 5), padding='same', activation='relu')(layer2_tower_2)\n\n    layer2_tower_3 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(layer1_output)\n    layer2_tower_3 = Conv2D(16, (1, 1), padding='same', activation='relu')(layer2_tower_3)\n\n    layer2_output = concatenate([layer2_tower_1, layer2_tower_2, layer2_tower_3, layer2_tower_0], axis=1)\n\n    # Flatten & Dense\n    layer2_output = Flatten()(layer2_output)\n    output = Dense(10,activation='softmax')(layer2_output)\n    \n    inception_Model = Model(inputs=input_img,outputs=output)\n    \n    print(inception_Model.summary())\n    inception_Model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    return inception_Model\n\nmodel = model_Inception()\nprint(\"Starting evaluation\")\nmodel,history = evaluate_model(model,X_train,Y_train,X_val,Y_val,\"model_Inception.best\",epochs,64)\nplot_results(history)\nresults = add_result(\"Inception\",history,results,3)\nresults","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XCeption\n\n![](https://cdn-images-1.medium.com/max/1600/1*SRBSbojkg48DTUMcP5VVHg.jpeg)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_Xception():\n    inp = Input(shape = (28, 28, 1))\n    x = inp\n    x = Conv2D(32, (3, 3), strides = 2, padding = \"same\", activation = \"relu\")(x)\n    x = BatchNormalization(axis = 3)(x)\n    x = Dropout(0.4)(x)\n    x = Conv2D(64, (3, 3), strides = 1, padding = \"same\", activation = \"relu\")(x)\n    x = BatchNormalization(axis = 3)(x)\n    x = Dropout(0.4)(x)\n\n    x1 = DepthwiseConv2D((3, 3), (1, 1), padding = \"same\", activation = \"relu\")(x)\n    x = BatchNormalization(axis = 3)(x)\n    x = Dropout(0.4)(x)\n    x1 = DepthwiseConv2D((3, 3), (1, 1), padding = \"same\", activation = \"relu\")(x1)\n    x = BatchNormalization(axis = 3)(x)\n    x = Dropout(0.4)(x)\n    x1 = MaxPooling2D((2, 2), strides = 1)(x1)\n\n    x = concatenate([x1, Conv2D(64, (2, 2), strides = 1)(x)])\n\n    x1 = Activation(\"relu\")(x)\n    x1 = Conv2D(256, (3, 3), strides = 1, padding = \"same\", activation = \"relu\")(x1)\n    x = BatchNormalization(axis = 3)(x)\n    x = Dropout(0.4)(x)\n    x1 = DepthwiseConv2D((3, 3), strides = 1, padding = \"same\", activation = \"relu\")(x1)\n    x = BatchNormalization(axis = 3)(x)\n    x = Dropout(0.4)(x)\n    x1 = DepthwiseConv2D((3, 3), strides = 1, padding = \"same\")(x1)\n    x = BatchNormalization(axis = 3)(x)\n    x = Dropout(0.4)(x)\n    x1 = MaxPooling2D((2, 2), strides = 1)(x1)\n\n    x = concatenate([x1, Conv2D(256, (2, 2), strides = 1)(x)])\n\n    x = Activation(\"relu\")(x)\n    x = Conv2D(256, (3, 3), strides = 1, padding = \"same\", activation = \"relu\")(x)\n    x = BatchNormalization(axis = 3)(x)\n    x = Dropout(0.4)(x)\n    x = Conv2D(128, (3, 3), strides = 1, padding = \"same\", activation = \"relu\")(x)\n    x = BatchNormalization(axis = 3)(x)\n    x = Dropout(0.4)(x)\n    x = Flatten()(x)\n\n    x = Dense(10, activation = \"softmax\")(x)\n\n    xception = Model(inp, x)\n    print(xception.summary())\n    xception.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n    return xception\n\nmodel = model_Xception()\nprint(\"Starting evaluation\")\nmodel,history = evaluate_model(model,X_train,Y_train,X_val,Y_val,\"model_Xception.best\",epochs,64)\nplot_results(history)\nresults = add_result(\"Xception\",history,results,4)\nresults","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Select model and predict test data\nSelect the best model and best weights and use it to predict results.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"results","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Above results are just for 5 epochs, increasing epochs to 35,40 giving better results.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## predict results\n# model = model_2CMDr_2CMDr_FDDr_D()  #99.214%\n# model = vgg_model(64,4) #99.476%\nmodel = model_vgg_batchNormalize()  #99.73%\n# model = model_Inception()  #99.21%\n# model = model_Xception()  #99.57%\n\nmodel.load_weights(\"model_vgg_batchNormalize.best.hdf5\")\n\ntest_data = input_test.values.reshape(-1,28,28,1)\noutputs = model.predict(test_data)\n\n# select the index with the maximum probability\noutputs = np.argmax(outputs,axis = 1)\n\noutputs = pd.Series(outputs,name=\"Label\")\noutputs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Submission\nSelect your best model and create a submission","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),outputs],axis = 1)\n\n#submission.to_csv(\"submision_Inception.csv\",index=False)\nsubmission","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### You can increase epochs and tune parameters for better results.\n\nI've not included the therotical details of the models in this notebook. I hope you can read about those internet and learn.\n\nResNet and Dense Net models are in the pipeline... working on those.\n\n\n### Please upvote if you findout this notebook helpful. \nThank you.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}