{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Local Agent Evaluation Framework"},{"metadata":{},"cell_type":"markdown","source":"\nThis goal of this framework is to allow for easier evaluation of agents performance in different scenarios, enabling quicker feedback to iterate through your different strategies. \n\nThe framework provides reusable functions, and the flexibility to change different parameter inputs, scenarios, and configurations.\n\nGives the ability to test how well your agent's strategies are working in different scenarios against different agents. Tets to see if their is improvement in scenario performances as you update your agents, and identify any regression across different scenarios as well\n\n\n* [Install Setup](#install-setup)\n* [Imports](#imports)\n* [Viz Toll Setup](#viz-setup)\n* [Agents for Evaluation](#agents)\n* [Pool Play + Scoreboard Implementation](#pplay-scoreboard)\n* [Example 1 - Academy 3 vs 1 with Keeper](#example-1)\n    * [Pool Play Run](#pool-play-run-ex1)\n    * [Visualize Scenario Gameplay](#viz-gameplay-ex1)\n* [Example 2 - Kaggle 11 vs 11 Scenario](#example-2)\n* [Example 3 - Writing to files flag](#example-3)"},{"metadata":{},"cell_type":"markdown","source":"Credit to the following notebooks for open agents I used here for evaluation and visualizations for testing:\n* https://www.kaggle.com/kwabenantim/gfootball-academy\n* https://www.kaggle.com/eugenkeil/simple-baseline-bot\n* https://www.kaggle.com/yegorbiryukov/gfootball-with-memory-patterns\n* https://www.kaggle.com/mlconsult/best-open-rules-bot-score-1020-7\n* https://www.kaggle.com/jaronmichal/human-readable-visualization"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"install-setup\"></a>\n# Install Setup"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# Install:\n# Kaggle environments.\n!git clone https://github.com/Kaggle/kaggle-environments.git\n!cd kaggle-environments && pip install .\n\n# GFootball environment.\n!apt-get update -y\n!apt-get install -y libsdl2-gfx-dev libsdl2-ttf-dev\n\n# Make sure that the Branch in git clone and in wget call matches !!\n!git clone -b v2.6 https://github.com/google-research/football.git\n!mkdir -p football/third_party/gfootball_engine/lib\n\n!wget https://storage.googleapis.com/gfootball/prebuilt_gameplayfootball_v2.6.so -O football/third_party/gfootball_engine/lib/prebuilt_gameplayfootball.so\n!cd football && GFOOTBALL_USE_PREBUILT_SO=1 pip3 install .","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"imports\"></a>\n# Imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport datetime as dt\nimport os\nimport time\n\nfrom kaggle_environments import make\nfrom kaggle_environments.envs.football.helpers import *\nfrom IPython.display import HTML\n\npd.set_option(\"display.float_format\", lambda x: \"%.5f\" % x)\npd.options.display.max_rows = 150\npd.set_option('display.max_columns', 150)\nnp.set_printoptions(suppress=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"agents\"></a>\n# Agents for evaluation"},{"metadata":{},"cell_type":"markdown","source":"I included agents already written to python files which come from agents open sourced by others. They can be found in directory:  \n**../input/open-gfball-agents/** "},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/open-gfball-agents/","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here is writing another new agent implementation to a submission.py file. This included since a lot of other reference notebooks show the agent implementation when they write to submission.py within their kaggle notebooks. \n\nThis is the basic template bot from here: \nhttps://www.kaggle.com/piotrstanczyk/gfootball-template-bot/data"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%writefile template_bot_submission.py\nfrom kaggle_environments.envs.football.helpers import *\n\n@human_readable_agent\ndef agent(obs):\n    # Make sure player is running.\n    if Action.Sprint not in obs['sticky_actions']:\n        return Action.Sprint\n    # We always control left team (observations and actions\n    # are mirrored appropriately by the environment).\n    controlled_player_pos = obs['left_team'][obs['active']]\n    # Does the player we control have the ball?\n    if obs['ball_owned_player'] == obs['active'] and obs['ball_owned_team'] == 0:\n        # Shot if we are 'close' to the goal (based on 'x' coordinate).\n        if controlled_player_pos[0] > 0.5:\n            return Action.Shot\n        # Run towards the goal otherwise.\n        return Action.Right\n    else:\n        # Run towards the ball.\n        if obs['ball'][0] > controlled_player_pos[0] + 0.05:\n            return Action.Right\n        if obs['ball'][0] < controlled_player_pos[0] - 0.05:\n            return Action.Left\n        if obs['ball'][1] > controlled_player_pos[1] + 0.05:\n            return Action.Bottom\n        if obs['ball'][1] < controlled_player_pos[1] - 0.05:\n            return Action.Top\n        # Try to take over the ball if close to the ball.\n        return Action.Slide","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"viz-setup\"></a>\n# Viz. Tool Setup"},{"metadata":{},"cell_type":"markdown","source":"setup visualization tool script taken from [Human Readable Visualization](https://www.kaggle.com/jaronmichal/human-readable-visualization)."},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"%%writefile visualizer.py\n\nfrom matplotlib import animation, patches, rcParams\nfrom matplotlib import pyplot as plt\nfrom kaggle_environments.envs.football.helpers import *\n\nWIDTH = 110\nHEIGHT = 46.2\nPADDING = 10\n\n\ndef initFigure(figwidth=12):\n    figheight = figwidth * (HEIGHT + 2 * PADDING) / (WIDTH + 2 * PADDING)\n\n    fig = plt.figure(figsize=(figwidth, figheight))\n    ax = plt.axes(xlim=(-PADDING, WIDTH + PADDING), ylim=(-PADDING, HEIGHT + PADDING))\n    plt.axis(\"off\")\n    return fig, ax\n\n\ndef drawPitch(ax):\n    paint = \"white\"\n\n    # Grass around pitch\n    rect = patches.Rectangle((-PADDING / 2, -PADDING / 2), WIDTH + PADDING, HEIGHT + PADDING,\n                             lw=1, ec=\"black\", fc=\"#3f995b\", capstyle=\"round\")\n    ax.add_patch(rect)\n\n    # Pitch boundaries\n    rect = plt.Rectangle((0, 0), WIDTH, HEIGHT, ec=paint, fc=\"None\", lw=2)\n    ax.add_patch(rect)\n\n    # Middle line\n    plt.plot([WIDTH / 2, WIDTH / 2], [0, HEIGHT], color=paint, lw=2)\n\n    # Dots\n    dots_x = [11, WIDTH / 2, WIDTH - 11]\n    for x in dots_x:\n        plt.plot(x, HEIGHT / 2, \"o\", color=paint, lw=2)\n\n    # Penalty box\n    penalty_box_dim = [16.5, 40.3]\n    penalty_box_pos_y = (HEIGHT - penalty_box_dim[1]) / 2\n\n    rect = plt.Rectangle((0, penalty_box_pos_y),\n                         penalty_box_dim[0], penalty_box_dim[1], ec=paint, fc=\"None\", lw=2)\n    ax.add_patch(rect)\n    rect = plt.Rectangle((WIDTH, penalty_box_pos_y), -\n                         penalty_box_dim[0], penalty_box_dim[1], ec=paint, fc=\"None\", lw=2)\n    ax.add_patch(rect)\n\n    # Goal box\n    goal_box_dim = [5.5, penalty_box_dim[1] - 11 * 2]\n    goal_box_pos_y = (penalty_box_pos_y + 11)\n\n    rect = plt.Rectangle((0, goal_box_pos_y),\n                         goal_box_dim[0], goal_box_dim[1], ec=paint, fc=\"None\", lw=2)\n    ax.add_patch(rect)\n    rect = plt.Rectangle((WIDTH, goal_box_pos_y),\n                         -goal_box_dim[0], goal_box_dim[1], ec=paint, fc=\"None\", lw=2)\n    ax.add_patch(rect)\n\n    # Goals\n    goal_width = 0.044 / 0.42 * HEIGHT\n    goal_pos_y = (HEIGHT / 2 - goal_width / 2)\n    rect = plt.Rectangle((0, goal_pos_y), -2, goal_width,\n                         ec=paint, fc=paint, lw=2, alpha=0.3)\n    ax.add_patch(rect)\n    rect = plt.Rectangle((WIDTH, goal_pos_y), 2, goal_width,\n                         ec=paint, fc=paint, lw=2, alpha=0.3)\n    ax.add_patch(rect)\n\n    # Middle circle\n    mid_circle = plt.Circle([WIDTH / 2, HEIGHT / 2], 9.15, color=paint, fc=\"None\", lw=2)\n    ax.add_artist(mid_circle)\n\n    # Penalty box arcs\n    left = patches.Arc([11, HEIGHT / 2], 2 * 9.15, 2 * 9.15,\n                       color=paint, fc=\"None\", lw=2, angle=0, theta1=308, theta2=52)\n    ax.add_patch(left)\n    right = patches.Arc([WIDTH - 11, HEIGHT / 2], 2 * 9.15, 2 * 9.15,\n                        color=paint, fc=\"None\", lw=2, angle=180, theta1=308, theta2=52)\n    ax.add_patch(right)\n\n    # Arcs on corners\n    corners = [[0, 0], [WIDTH, 0], [WIDTH, HEIGHT], [0, HEIGHT]]\n    angle = 0\n    for x, y in corners:\n        c = patches.Arc([x, y], 2, 2,\n                        color=paint, fc=\"None\", lw=2, angle=angle, theta1=0, theta2=90)\n        ax.add_patch(c)\n        angle += 90\n\n\ndef scale_x(x):\n    return (x + 1) * (WIDTH / 2)\n\n\ndef scale_y(y):\n    return (y + 0.42) * (HEIGHT / 0.42 / 2)\n\n\ndef extract_data(raw_obs):\n    obs = raw_obs[0][\"observation\"][\"players_raw\"][0]\n    res = dict()\n    res[\"left_team\"] = [(scale_x(x), scale_y(y)) for x, y in obs[\"left_team\"]]\n    res[\"right_team\"] = [(scale_x(x), scale_y(y)) for x, y in obs[\"right_team\"]]\n\n    ball_x, ball_y, ball_z = obs[\"ball\"]\n    res[\"ball\"] = [scale_x(ball_x), scale_y(ball_y), ball_z]\n    res[\"score\"] = obs[\"score\"]\n    res[\"steps_left\"] = obs[\"steps_left\"]\n    res[\"ball_owned_team\"] = obs[\"ball_owned_team\"]\n\n    left_active = raw_obs[0][\"observation\"][\"players_raw\"][0][\"active\"]\n    res[\"left_player\"] = res[\"left_team\"][left_active]\n\n    right_active = raw_obs[1][\"observation\"][\"players_raw\"][0][\"active\"]\n    res[\"right_player\"] = res[\"right_team\"][right_active]\n\n    res[\"right_team_roles\"] = obs[\"right_team_roles\"]\n    res[\"left_team_roles\"] = obs[\"left_team_roles\"]\n    res[\"left_team_direction\"] = obs[\"left_team_direction\"]\n    res[\"right_team_direction\"] = obs[\"right_team_direction\"]\n    res[\"game_mode\"] = GameMode(obs[\"game_mode\"]).name\n    return res\n\n\ndef draw_team(obs, team, side):\n    x_coords, y_coords = zip(*obs[side])\n    team.set_data(x_coords, y_coords)\n\n\ndef draw_ball(obs, ball):\n    ball.set_markersize(8 + obs[\"ball\"][2])  # Scale size of ball based on height\n    ball.set_data(obs[\"ball\"][:2])\n\n\ndef draw_active_players(obs, left_player, right_player):\n    x1, y1 = obs[\"left_player\"]\n    left_player.set_data(x1, y1)\n\n    x2, y2 = obs[\"right_player\"]\n    right_player.set_data(x2, y2)\n\n    if obs[\"ball_owned_team\"] == 0:\n        left_player.set_markerfacecolor(\"yellow\")\n        left_player.set_markersize(20)\n        right_player.set_markerfacecolor(\"blue\")\n        right_player.set_markersize(18)\n    elif obs[\"ball_owned_team\"] == 1:\n        left_player.set_markerfacecolor(\"firebrick\")\n        left_player.set_markersize(18)\n        right_player.set_markerfacecolor(\"yellow\")\n        right_player.set_markersize(20)\n    else:\n        left_player.set_markerfacecolor(\"firebrick\")\n        left_player.set_markersize(18)\n        right_player.set_markerfacecolor(\"blue\")\n        right_player.set_markersize(18)\n\n\ndef draw_team_active(obs, team_left_active, team_right_active):\n    team_left_active.set_data(WIDTH / 2 - 7, -7)\n    team_right_active.set_data(WIDTH / 2 + 7, -7)\n\n    if obs[\"ball_owned_team\"] == 0:\n        team_left_active.set_markerfacecolor(\"indianred\")\n    else:\n        team_left_active.set_markerfacecolor(\"mistyrose\")\n\n    if obs[\"ball_owned_team\"] == 1:\n        team_right_active.set_markerfacecolor(\"royalblue\")\n    else:\n        team_right_active.set_markerfacecolor(\"lightcyan\")\n\n\ndef draw_players_directions(obs, directions, side):\n    index = 0\n    if \"right\" in side:\n        index = 11\n    for i, player_dir in enumerate(obs[f\"{side}_direction\"]):\n        x_dir, y_dir = player_dir\n        dist = (x_dir ** 2 + y_dir ** 2)**0.5 + 0.00001  # to prevent division by 0\n        x = obs[side][i][0]\n        y = obs[side][i][1]\n        directions[i + index].set_data([x, x + x_dir / dist], [y, y + y_dir / dist])\n\n\ndef player_actions(step, side):\n    if side == 0:\n        actions = {0: \"idle\", 1: \"←\", 2: \"↖\", 3: \"↑\", 4: \"↗\", 5: \"→\", 6: \"↘\", 7: \"↓\", 8: \"↙\",\n                   9: \"l_pass\", 10: \"h_pass\", 11: \"s_pass\", 12: \"shot\",\n                   13: \"sprint\", 14: \"rel_dir\", 15: \"rel_spr\",\n                   16: \"slide\", 17: \"dribble\", 18: \"stp_drb\"}\n    else:\n        actions = {0: \"idle\", 1: \"→\", 2: \"↘\", 3: \"↓\", 4: \"↙\", 5: \"←\", 6: \"↖\", 7: \"↑\", 8: \"↗\",\n                   9: \"l_pass\", 10: \"h_pass\", 11: \"s_pass\", 12: \"shot\",\n                   13: \"sprint\", 14: \"rel_dir\", 15: \"rel_spr\",\n                   16: \"slide\", 17: \"dribble\", 18: \"stp_drb\"}\n\n    obs = step[side][\"observation\"][\"players_raw\"][0]\n\n    if obs[\"sticky_actions\"][8]:\n        spr = \"+spr\"\n    else:\n        spr = \"-spr\"\n\n    if obs[\"sticky_actions\"][9]:\n        drb = \"+drb\"\n    else:\n        drb = \"-drb\"\n\n    if 1 in obs[\"sticky_actions\"][0:8]:\n        i = obs[\"sticky_actions\"][0:8].index(1) + 1\n        drn = actions[i]\n    else:\n        drn = \"|\"\n\n    if step[side][\"action\"]:\n        act = actions[step[side][\"action\"][0]]\n    else:\n        act = \"idle\"\n\n    return f\"{spr} {drb} {drn} [{act}]\".ljust(24, \" \")\n\n\nsteps = None\ndrawings = None\ndirections = None\nball = left_player = right_player = None\nteam_left = team_right = None\nteam_left_active = team_right_active = None\nteam_left_actions = team_right_actions = None\nteam_left_number = team_right_number = None\nteam_left_direction = team_right_direction = None\ntext_frame = game_mode = match_info = None\n\n\ndef init():\n    ball.set_data([], [])\n    left_player.set_data([], [])\n    right_player.set_data([], [])\n    team_left.set_data([], [])\n    team_right.set_data([], [])\n    team_left_active.set_data([], [])\n    team_right_active.set_data([], [])\n    return drawings\n\n\ndef animate(i):\n    obs = extract_data(steps[i])\n\n    # Draw info about ball possesion\n    draw_active_players(obs, left_player, right_player)\n    draw_team_active(obs, team_left_active, team_right_active)\n\n    # Draw players\n    draw_team(obs, team_left, \"left_team\")\n    draw_team(obs, team_right, \"right_team\")\n\n    draw_players_directions(obs, directions, \"left_team\")\n    draw_players_directions(obs, directions, \"right_team\")\n\n    draw_ball(obs, ball)\n\n    # Draw textual informations\n    text_frame.set_text(f\"Step {i}/{obs['steps_left'] + i - 1}\")\n    game_mode.set_text(f\"{obs['game_mode']} Mode\")\n\n    score_a, score_b = obs[\"score\"]\n    match_info.set_text(f\"{score_a} : {score_b}\")\n\n    team_left_actions.set_text(player_actions(steps[i], 0))\n    team_right_actions.set_text(player_actions(steps[i], 1))\n\n    team_left_number.set_text(str(steps[i][0][\"observation\"][\"players_raw\"][0][\"active\"]))\n    team_right_number.set_text(str(steps[i][1][\"observation\"][\"players_raw\"][0][\"active\"]))\n\n    return drawings\n\n\ndef visualize(trace):\n    global steps\n    global drawings\n    global directions\n    global ball, left_player, right_player\n    global team_left, team_right\n    global team_left_active, team_right_active\n    global text_frame, game_mode, match_info\n    global team_left_actions, team_right_actions\n    global team_left_number, team_right_number\n    global team_left_direction, team_right_direction\n\n    rcParams['font.family'] = 'monospace'\n    rcParams['font.size'] = 12\n\n    steps = trace\n\n    fig, ax = initFigure()\n    drawPitch(ax)\n    ax.invert_yaxis()\n\n    left_player, = ax.plot([], [], \"o\", ms=18, mfc=\"firebrick\", mew=0, alpha=0.5)\n    right_player, = ax.plot([], [], \"o\", ms=18, mfc=\"blue\", mew=0, alpha=0.5)\n    team_left, = ax.plot([], [], \"o\", ms=12, mfc=\"firebrick\", mew=1, mec=\"white\")\n    team_right, = ax.plot([], [], \"o\", ms=12, mfc=\"blue\", mew=1, mec=\"white\")\n    ball, = ax.plot([], [], \"o\", ms=8, mfc=\"wheat\", mew=1, mec=\"black\")\n\n    team_left_active, = ax.plot([], [], \"o\", ms=16, mfc=\"mistyrose\", mec=\"None\")\n    team_right_active, = ax.plot([], [], \"o\", ms=16, mfc=\"lightcyan\", mec=\"None\")\n\n    textheight = -6\n    text_frame = ax.text(-5, textheight, \"\", ha=\"left\")\n    match_info = ax.text(WIDTH / 2, textheight, \"\", ha=\"center\", fontweight=\"bold\")\n    game_mode = ax.text(WIDTH + 5, textheight, \"\", ha=\"right\")\n\n    team_left_actions = ax.text(WIDTH / 4 + 2, textheight, \"\", ha=\"center\")\n    team_right_actions = ax.text(3 * WIDTH / 4 + 2, textheight, \"\", ha=\"center\")\n\n    team_left_number = ax.text(WIDTH / 2 - 7, -6.3, \"\", ha=\"center\", fontsize=10)\n    team_right_number = ax.text(WIDTH / 2 + 7, -6.3, \"\", ha=\"center\", fontsize=10)\n\n    # Drawing of directions definitely can be done in a better way\n    directions = []\n    for _ in range(22):\n        direction, = ax.plot([], [], color=\"yellow\", lw=1.5)\n        directions.append(direction)\n\n    drawings = [team_left_active, team_right_active, left_player, right_player,\n                team_left, team_right, ball, text_frame, match_info,\n                game_mode, team_left_actions, team_right_actions, team_left_number, team_right_number]\n\n    fig.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=None, hspace=None)\n    anim = animation.FuncAnimation(fig, animate, init_func=init, blit=True,\n                                   interval=100, frames=len(steps), repeat=True)\n    return anim\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"pplay-scoreboard\"></a>\n# Pool + and Scoreboard Implementation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_pool_play(scenario_name, episode_steps, num_rounds, agents, export_dir, write_file=False):\n    print('run pool play scenario: {0}'.format(scenario_name))\n    start_time = time.time()\n    \n    agents_dirs = agents\n    \n    env_config = {\n        \"save_video\": False,\n        \"scenario_name\": scenario_name,\n        \"running_in_notebook\": True,\n        \"episodeSteps\": episode_steps\n    }\n    \n    env = make(\"football\", configuration=env_config, debug=False)\n    \n    \n    df_list = []\n\n    for pool_play_round in range(num_rounds):\n        for agent1 in agents_dirs:\n            for agent2 in agents_dirs:\n                print(agent1, agent2)\n                env.reset()\n                output = env.run([agent1, agent2])\n\n                final_output = output[-1]\n                left_agent_foutput = final_output[0]\n                right_agent_foutput = final_output[1]\n                left_reward = left_agent_foutput['reward']\n                right_reward = right_agent_foutput['reward']\n                left_status = left_agent_foutput['status']\n                right_status = right_agent_foutput['status']\n\n                left_score = output[-1][0]['observation']['players_raw'][0]['score'][0]\n                right_score = output[-1][0]['observation']['players_raw'][0]['score'][1]\n\n                adf = pd.DataFrame()\n                adf['scenario'] = [scenario_name]\n                adf['round'] = [pool_play_round]\n                adf['left_agent'] = [agent1]\n                adf['right_agent'] = [agent2]\n                adf['left_score'] = [left_score]\n                adf['right_score'] = [right_score]\n                adf['left_reward'] = [left_reward]\n                adf['right_reward'] = [right_reward]\n                adf['left_status'] = [left_status]\n                adf['right_status'] = [right_status]\n\n                df_list.append(adf)\n\n        pool_play_round +=1\n        \n    #final dataframe with results    \n    fdf = pd.concat(df_list)\n    \n    # write out results to file if flag set\n    if write_file:\n        # if export_dir does not exist then create it\n        if export_dir not in os.listdir('.'):\n            print('{0} directory does not exist, creating'.format(export_dir) )\n            os.mkdir(export_dir)\n        \n        # make export directory w/ timestamp of runs\n        curr_datetime = dt.datetime.now()\n        curr_time = curr_datetime.strftime('%m-%d-%Y-%H-%M-%S')\n        export_fdir = export_dir + curr_time\n        os.mkdir(export_fdir)\n\n        # write out results\n        export_result_file = export_fdir + '/results.csv'\n        fdf.to_csv(export_result_file, index=False)\n        print('results written out to {0}'.format(export_result_file))\n\n        # write out config\n        config_df = pd.DataFrame(env_config.items())\n        config_df = config_df.append([['num_rounds', num_rounds]])\n        config_df.to_csv(export_fdir + '/config.csv', index=False)\n\n        end_time = round((time.time() - start_time), 2)\n        print(\"complete: --- %s seconds ---\" % end_time)\n    \n    # get scoreboard result dataframe\n    score_df = get_scoreboard(fdf)\n    # add some final columns\n    score_df['scenario_name'] = scenario_name\n    score_df = score_df[['scenario_name','agent', 'games_played', 'num_wins', 'num_losses', 'num_ties',\n       'goals_for', 'goals_against', 'num_points']]\n    \n    return fdf,score_df\n\n\ndef get_scoreboard_from_file(result_file):\n    rdf = pd.read_csv(result_file)\n    score_df = get_scoreboard(rdf)\n    return score_df\n\n\ndef get_scoreboard(rdf):\n    # get only cases where valid statuses\n    rdf = rdf[rdf['right_status'] == 'DONE']\n    rdf = rdf[rdf['left_status'] == 'DONE']\n\n    agents = list(set(list(rdf.left_agent.unique()) + list(rdf.right_agent.unique())))\n    \n    result_list = []\n\n    for agent in agents:\n        left_df = rdf[rdf.left_agent == agent].reset_index(drop=True)\n\n        # calculate num_wins, num_losses, num_ties\n        left_df['num_wins'] = np.where(left_df['left_score'] > left_df['right_score'], 1, 0)\n        left_df['num_losses'] = np.where(left_df['left_score'] < left_df['right_score'], 1, 0)\n        left_df['num_ties'] = np.where(left_df['left_score'] == left_df['right_score'], 1, 0)\n\n        games_played = len(left_df)\n        goals_for = left_df.left_score.sum()\n        goals_against = left_df.right_score.sum()\n        num_wins = left_df.num_wins.sum()\n        num_losses = left_df.num_losses.sum()\n        num_ties = left_df.num_ties.sum()\n\n        right_df = rdf[rdf.right_agent == agent].reset_index(drop=True)\n\n        # calculate num_wins, num_losses, num_ties\n        right_df['num_wins'] = np.where(right_df['right_score'] > right_df['left_score'], 1, 0)\n        right_df['num_losses'] = np.where(right_df['right_score'] < right_df['left_score'], 1, 0)\n        right_df['num_ties'] = np.where(right_df['right_score'] == right_df['left_score'], 1, 0)\n\n        games_played = games_played + len(right_df)\n        goals_for = goals_for + right_df.right_score.sum()\n        goals_against = goals_against + right_df.left_score.sum()\n        num_wins = num_wins + right_df.num_wins.sum()\n        num_losses = num_losses + right_df.num_losses.sum()\n        num_ties = num_ties + right_df.num_ties.sum()\n\n        result_list.append([agent, games_played, num_wins, num_losses, num_ties, goals_for, goals_against])\n\n    fdf = pd.DataFrame(result_list, columns = ['agent', 'games_played', 'num_wins', 'num_losses', 'num_ties',\n                                               'goals_for', 'goals_against'])\n\n    fdf['num_points'] = fdf['num_wins']*3 + fdf['num_ties']*1\n\n    fdf = fdf.sort_values('num_points', ascending=False)\n    \n    return fdf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"example-1\"></a>\n# Example 1 - Academy 3 vs 1 with Keeper"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"pool-play-run-ex1\"></a>\n### Pool Play Run"},{"metadata":{"trusted":true},"cell_type":"code","source":"#AGENTS_DIR = '../input/open-gfball-agents/' # where the agents submission.py files are located\nEXPORT_DIR = 'pool_play_results/' # optional flag to store results of pool play to files\nNUM_ROUNDS = 3 # number of time to repeat playing every agent in pool\n\nAGENTS = [\n    '../input/open-gfball-agents/best_open_rules_bot_1020_v2.py',\n    '../input/open-gfball-agents/tunable_baseline_bot.py',\n    '../input/open-gfball-agents/gfball_pattern_v15_submission.py',\n    'template_bot_submission.py'\n]\n\nEPISODE_STEPS = 400 # lets do shorter than default 3000 to speed up runs\n\nSCENARIO_NAME = 'academy_3_vs_1_with_keeper'","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"result_df, score_df = run_pool_play(SCENARIO_NAME, EPISODE_STEPS, NUM_ROUNDS, AGENTS, \n                                    EXPORT_DIR, write_file=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The score_df has the aggregated results of the different scenario runs of agents against each other.\n\nSince this is a academy scenario the way you interpet the metrics are not as intuitive vs the typical 11v11_kaggle scenario (which you can see in the next section)\n\nFor example lets take agent **gfball_pattern_v15_submission** below:\n* 18 total games played is because the number of rounds = 3 for the input and there are 3 agents played against including itself. 3x3 = 9 for being on offense for the scenario, and 9 for being on defense for the scenario.\n* From the goals for you can see that 3/9 matches on offense the agent was able to score, and 2/9 times on defense agent let in a goal.  so 6/9 times on offense wasnt able to score, and 7/9 times on defense didnt allow a goal. 6+7 = 13 ties."},{"metadata":{"trusted":true},"cell_type":"code","source":"score_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"If you want to Look at the results of each match, see result_df"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 48 total matches played, 4 teams playing each other including itself x 4 teams total = 16 x 3 rounds = 48\nprint(result_df.shape) \nresult_df.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"viz-gameplay-ex1\"></a>\n### Visualize Scenario Gameplay"},{"metadata":{"_kg_hide-output":true},"cell_type":"markdown","source":"So lets say our agent is tunable_baseline_bot, and we want to understand why the agents performance is not great for this academy 3 vs 1 scenario, lets run and visualize a bit"},{"metadata":{"trusted":true},"cell_type":"code","source":"def agent_run(left_agent, right_agent, debug, config):\n    env = make(\"football\", debug=debug, configuration=config)\n         \n    output = env.run([left_agent, right_agent])\n    print('SCENARIO TYPE: {0}'.format(config['scenario_name']))\n    print(left_agent + ' vs '+ right_agent)\n    scores = output[-1][0][\n        \"observation\"][\"players_raw\"][0][\"score\"]\n    print(\"Scores  {0} : {1}\".format(*scores))\n    print(\"Rewards {0} : {1}\".format(output[-1][0][\"reward\"], output[-1][1][\"reward\"]))\n    print('number of steps: {0}'.format(len(output)))\n    return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CONFIG={\n    \"save_video\": False, \n    \"scenario_name\": \"academy_3_vs_1_with_keeper\", \n    \"running_in_notebook\": True\n}\n\nDEBUG = False\n\nLEFT_AGENT = \"../input/open-gfball-agents/tunable_baseline_bot.py\"\nRIGHT_AGENT = \"../input/open-gfball-agents/best_open_rules_bot_1020_v2.py\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\noutput = agent_run(LEFT_AGENT, RIGHT_AGENT, DEBUG, CONFIG)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from visualizer import visualize\nviz = visualize(output)\nHTML(viz.to_html5_video())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see above that tunable-baseline-bot needs to improve offense strategy to score in this type of scenario,\n\nso just make changes to your agent, and now you can rerun evaluations with the methods as described above to check if your agent is improveing!"},{"metadata":{},"cell_type":"markdown","source":"Hmm, what about the gfootball agent offense vs tunable baseline defense for this academy 3 vs 1 scenario?"},{"metadata":{"trusted":true},"cell_type":"code","source":"LEFT_AGENT = \"../input/open-gfball-agents/gfball_pattern_v15_submission.py\"\nRIGHT_AGENT = \"../input/open-gfball-agents/tunable_baseline_bot.py\"\noutput = agent_run(LEFT_AGENT, RIGHT_AGENT, DEBUG, CONFIG)\nviz = visualize(output)\nHTML(viz.to_html5_video())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like gfootball pattern agent can improve in its shooting direction"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"example-2\"></a>\n# Example 2 - Kaggle 11 vs 11 scenario"},{"metadata":{},"cell_type":"markdown","source":"Now we want to run kaggle 11 vs 11 full scenario pool player. We limit to only 3 teams here and 2 rounds, and set episode_steps to only half of normal game at 1500 in order to speed up these runs for this kernel.\n\nWith my local setup I can kick off a full run with all my agents and multiple rounds overnight and all the results will be done in the morning."},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"AGENTS_DIR = '../input/open-gfball-agents/' # where the agents submission.py files are located\nEXPORT_DIR = 'pool_play_results/' # optional flag to store results of pool play to files\nNUM_ROUNDS = 2 # number of time to repeat playing every agent in pool\n\nAGENTS = [\n    '../input/open-gfball-agents/best_open_rules_bot_1020_v2.py',\n    '../input/open-gfball-agents/tunable_baseline_bot.py',\n    '../input/open-gfball-agents/gfball_pattern_v15_submission.py',\n]\n\nEPISODE_STEPS = 1500 # lets do shorter than default 3000 to speed up runs\n\nSCENARIO_NAME = '11_vs_11_kaggle'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**This can take 5-10 minutes to run**"},{"metadata":{"trusted":true,"_kg_hide-output":true,"collapsed":true},"cell_type":"code","source":"%%time\nresult_df2, score_df2 = run_pool_play(SCENARIO_NAME, EPISODE_STEPS, NUM_ROUNDS, AGENTS,\n                                    EXPORT_DIR, write_file=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The score dataframe has the results of running each agent against each other twice, (including against itself).\n\nthe number of points is based on 3 points for a win, 1 point for tie, 0 for loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"score_df2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(result_df2.shape) # 3 agents in pool each play each other including self, (3x3) = 9 x 2 rounds = 18 matches\nresult_df2.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"example-3\"></a>\n# Example 3 - Writing to files flag"},{"metadata":{},"cell_type":"markdown","source":"In the case you want to store your different run results to file to keep track of, you can just set the write_file flag to True"},{"metadata":{"trusted":true},"cell_type":"code","source":"EXPORT_DIR = 'pool_play_results/' # optional flag to store results of pool play to files\nNUM_ROUNDS = 3 # number of time to repeat playing every agent in pool\n\nAGENTS = [\n    '../input/open-gfball-agents/best_open_rules_bot_1020_v2.py',\n    '../input/open-gfball-agents/tunable_baseline_bot.py',\n    '../input/open-gfball-agents/gfball_pattern_v15_submission.py',\n    'template_bot_submission.py'\n]\n\nEPISODE_STEPS = 400 # lets do shorter than default 3000 to speed up runs\n\nSCENARIO_NAME = 'academy_3_vs_1_with_keeper'","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"collapsed":true},"cell_type":"code","source":"result_df, score_df = run_pool_play(SCENARIO_NAME, EPISODE_STEPS, NUM_ROUNDS, AGENTS,\n                                    EXPORT_DIR, write_file=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Results are written to a dynamically created directory based on timestamp of run"},{"metadata":{"trusted":true},"cell_type":"code","source":"tdir = os.listdir('pool_play_results/')[0]\ntdir","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('pool_play_results/' + tdir)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A config file is written in the directory which has the configs that were run with"},{"metadata":{"trusted":true},"cell_type":"code","source":"config_df = pd.read_csv('pool_play_results/' + tdir + '/config.csv')\nconfig_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"the results are stored in a results.csv file in the directory"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('pool_play_results/' + tdir + '/results.csv')\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You can generate a scorecard from a results.csv file"},{"metadata":{"trusted":true},"cell_type":"code","source":"score_df = get_scoreboard_from_file('pool_play_results/' + tdir + '/results.csv')\nscore_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Or you can generate a scorecard from a result dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"score_df = get_scoreboard(test_df)\nscore_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}