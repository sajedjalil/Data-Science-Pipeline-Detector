{"cells":[{"metadata":{},"cell_type":"markdown","source":"Using rogbas great episode scraper notebook https://www.kaggle.com/robga/google-football-episode-scraper we can use LightGBM to predict the top players actions.\n\nI have an a couple agents nearly identical to this notebook that have scores over 940.\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Install:\n# Kaggle environments.\n!git clone https://github.com/Kaggle/kaggle-environments.git\n!cd kaggle-environments && pip install .\n\n# GFootball environment.\n!apt-get update -y\n!apt-get install -y libsdl2-gfx-dev libsdl2-ttf-dev\n\n# Make sure that the Branch in git clone and in wget call matches !!\n!git clone -b v2.7 https://github.com/google-research/football.git\n!mkdir -p football/third_party/gfootball_engine/lib\n\n!wget https://storage.googleapis.com/gfootball/prebuilt_gameplayfootball_v2.7.so -O football/third_party/gfootball_engine/lib/prebuilt_gameplayfootball.so\n!cd football && GFOOTBALL_USE_PREBUILT_SO=1 pip3 install .","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport requests\nimport json\nimport datetime\nimport time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MIN_FINAL_RATING = 1200 # top submission in a match must have reached this score\nnum_api_calls_today = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_files = []\nfor root, dirs, files in os.walk('./', topdown=False):\n    all_files.extend(files)\nseen_episodes = [int(f.split('.')[0]) for f in all_files \n                      if '.' in f and f.split('.')[0].isdigit() and f.split('.')[1] == 'json']\nprint('{} games in existing library'.format(len(seen_episodes)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_TEAMS = 3\nEPISODES = 90 \n\nBUFFER = 1\n\nbase_url = \"https://www.kaggle.com/requests/EpisodeService/\"\nget_url = base_url + \"GetEpisodeReplay\"\nlist_url = base_url + \"ListEpisodes\"\n# inital team list\n\nr = requests.post(list_url, json = {\"teamId\":  5696217}) # arbitrary ID, change to leading ID during challenge\n\nrj = r.json()\n\nteams_df = pd.DataFrame(rj['result']['teams'])\nteams_df.sort_values('publicLeaderboardRank', inplace = True)\nteams_df.head(6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getTeamEpisodes(team_id):\n    r = requests.post(list_url, json = {\"teamId\":  int(team_id)})\n    rj = r.json()\n\n    # update teams list\n    global teams_df\n    teams_df_new = pd.DataFrame(rj['result']['teams'])\n    \n    if len(teams_df.columns) == len(teams_df_new.columns) and (teams_df.columns == teams_df_new.columns).all():\n        teams_df = pd.concat( (teams_df, teams_df_new.loc[[c for c in teams_df_new.index if c not in teams_df.index]] ) )\n        teams_df.sort_values('publicLeaderboardRank', inplace = True)\n    else:\n        print('teams dataframe did not match')\n    \n    # make df\n    team_episodes = pd.DataFrame(rj['result']['episodes'])\n    team_episodes['avg_score'] = -1;\n    \n    for i in range(len(team_episodes)):\n        agents = team_episodes['agents'].loc[i]\n        agent_scores = [a['updatedScore'] for a in agents if a['updatedScore'] is not None]\n        team_episodes.loc[i, 'submissionId'] = [a['submissionId'] for a in agents if a['submission']['teamId'] == team_id][0]\n        team_episodes.loc[i, 'updatedScore'] = [a['updatedScore'] for a in agents if a['submission']['teamId'] == team_id][0]\n        \n        if len(agent_scores) > 0:\n            team_episodes.loc[i, 'avg_score'] = np.mean(agent_scores)\n\n    for sub_id in team_episodes['submissionId'].unique():\n        sub_rows = team_episodes[ team_episodes['submissionId'] == sub_id ]\n        max_time = max( [r['seconds'] for r in sub_rows['endTime']] )\n        final_score = max( [r['updatedScore'] for r_idx, (r_index, r) in enumerate(sub_rows.iterrows())\n                                if r['endTime']['seconds'] == max_time] )\n\n        team_episodes.loc[sub_rows.index, 'final_score'] = final_score\n        \n    team_episodes.sort_values('avg_score', ascending = False, inplace=True)\n    return rj, team_episodes\ndef saveEpisode(epid, rj):\n    # request\n    re = requests.post(get_url, json = {\"EpisodeId\": int(epid)})\n        \n    # save replay\n    with open('{}.json'.format(epid), 'w') as f:\n        f.write(re.json()['result']['replay'])\n\n    # save episode info\n    with open('{}_info.json'.format(epid), 'w') as f:\n        json.dump([r for r in rj['result']['episodes'] if r['id']==epid][0], f)\nglobal num_api_calls_today\n\npulled_teams = {}\npulled_episodes = []\nstart_time = datetime.datetime.now()\nr = BUFFER;\n\nwhile num_api_calls_today < EPISODES:\n    # pull team\n    top_teams = [i for i in teams_df.id if i not in pulled_teams]\n    if len(top_teams) > 0:\n        team_id = top_teams[0]\n    else:\n        break;\n        \n    # get team data\n    team_json, team_df = getTeamEpisodes(team_id); r+=1;\n    num_api_calls_today+=1\n    print('{} games for {}'.format(len(team_df), teams_df.loc[teams_df.id == team_id].iloc[0].teamName))\n\n    \n    team_df = team_df[  (MIN_FINAL_RATING is None or (team_df.final_score > MIN_FINAL_RATING))]\n    \n    print('   {} in score range from {} submissions'.format(len(team_df), len(team_df.submissionId.unique() ) ) )\n    \n    team_df = team_df[~team_df.id.isin(pulled_episodes + seen_episodes)]        \n    print('      {} remain to be downloaded\\n'.format(len(team_df)))\n        \n    # pull games\n    target_team_games = int(np.ceil(EPISODES / NUM_TEAMS))\n    if target_team_games + len(pulled_episodes) > EPISODES:\n        target_team_games = EPISODES - len(pulled_episodes)\n     \n    pulled_teams[team_id] = 0\n    \n    i = 0\n    while i < len(team_df) and pulled_teams[team_id] < target_team_games:\n        epid = team_df.id.iloc[i]\n        if not (epid in pulled_episodes or epid in seen_episodes):\n            try:\n                saveEpisode(epid, team_json); r+=1;\n                num_api_calls_today+=1\n            except:\n                time.sleep(20)\n                i+=1;\n                continue;\n                \n            pulled_episodes.append(epid)\n            pulled_teams[team_id] += 1\n            try:\n                size = os.path.getsize('{}.json'.format(epid)) / 1e6\n                print(str(num_api_calls_today) + ': Saved Episode #{} @ {:.1f}MB'.format(epid, size))\n            except:\n                print('  file {}.json did not seem to save'.format(epid))    \n            if r > (datetime.datetime.now() - start_time).seconds:\n                time.sleep( r - (datetime.datetime.now() - start_time).seconds)\n                \n\n        i+=1;\n    print(); print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport json\nimport os\nfrom tqdm import tqdm, notebook","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_observation(observation, fixed_positions=False):\n\n    def do_flatten(obj):\n        if type(obj) == list:\n            return np.array(obj).flatten()\n        return obj.flatten()\n\n    final_obs = []\n    \n    for obs in observation:\n        \n\n        o = []\n        if fixed_positions:\n            for i, name in enumerate(['left_team', 'left_team_direction',\n                                    'right_team', 'right_team_direction']):\n                o.extend(do_flatten(obs[name]))\n            # If there were less than 11vs11 players we backfill missing values\n            # with -1.\n            if len(o) < (i + 1) * 22:\n                o.extend([-1] * ((i + 1) * 22 - len(o)))\n        else:\n            o.extend(do_flatten(obs['left_team']))\n            o.extend(do_flatten(obs['left_team_direction']))\n            o.extend(do_flatten(obs['right_team']))\n            o.extend(do_flatten(obs['right_team_direction']))\n\n        # If there were less than 11vs11 players we backfill missing values with\n        # -1.\n        # 88 = 11 (players) * 2 (teams) * 2 (positions & directions) * 2 (x & y)\n        if len(o) < 88:\n            o.extend([-1] * (88 - len(o)))\n\n        # ball position\n        o.extend(obs['ball'])\n        # ball direction\n        o.extend(obs['ball_direction'])\n        # one hot encoding of which team owns the ball\n        if obs['ball_owned_team'] == -1:\n            o.extend([1, 0, 0])\n        if obs['ball_owned_team'] == 0:\n            o.extend([0, 1, 0])\n        if obs['ball_owned_team'] == 1:\n            o.extend([0, 0, 1])\n\n        active = [0] * 11\n        if obs['active'] != -1:\n            active[obs['active']] = 1\n        o.extend(active)\n\n        game_mode = [0] * 7\n        game_mode[obs['game_mode']] = 1\n        o.extend(game_mode)\n        final_obs.append(o)\n\n        return np.array(final_obs, dtype=np.float32).flatten()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=[]\nx=[]\nfilenames = [p for p in os.listdir('.') if 'info' not in p and 'json' in p]\n\nfor f in notebook.tqdm(filenames):\n    filename = \"./\" + f\n\n    try:\n        with open(filename) as json_file:\n            data = json.load(json_file)\n    except:\n        continue\n        \n    counter=0\n\n\n    for team in [0,1]:\n        final_score = data['steps'][-2][team]['observation']['players_raw'][0]['score'][0]\n\n        goal=False\n\n        for i in range(2,len(data['steps'])-2,):\n\n            action=data['steps'][i][team]['action']\n            y.append(action[0])\n            \n            obs=data['steps'][i][team]['observation']['players_raw'][0]\n            x.append(convert_observation([obs]))\n                ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.metrics import accuracy_score\ndef evaluate_model(model,X_test,Y_test):\n    preds = model.predict(X_test)\n    best_preds = np.asarray([np.argmax(line) for line in preds])\n\n    print(\"Accuracy = {}\".format(accuracy_score(Y_test, best_preds)))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_train = lgb.Dataset(np.array(x).reshape((-1,115)), label=y)\nparams = {}\nparams['objective'] = 'multiclass'\nparams['num_classes'] = 19\n\n\nmod = lgb.train(params, d_train, 100,)\n\nmod.save_model('model.txt')    \nevaluate_model(mod,x[:1000],y[:1000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tree_agent(obs):\n    try:\n        obs1=obs['observation']['players_raw'][0]\n    except:\n        obs1=obs['players_raw'][0]\n\n    obs1=convert_observation([obs1])\n\n#     action=np.random.choice(np.arange(19),p=(mod.predict([obs1])).flatten())\n    action=np.argmax(mod.predict([obs1]).flatten())\n    return [int(action)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle_environments import make\n\nenv = make(\"football\", configuration={\"save_video\": True, \"scenario_name\": \"11_vs_11_kaggle\", \"running_in_notebook\": True})\noutput = env.run([tree_agent,tree_agent])\nprint('Left player: reward = %s, status = %s, info = %s' % (output[-1][0]['reward'],\n                                                            output[-1][0]['status'], output[-1][0]['info']))\nenv.render(mode='human',width=800, height=600)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}