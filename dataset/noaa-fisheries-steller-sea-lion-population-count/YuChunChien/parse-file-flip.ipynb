{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"ad424a07-b13f-6ccd-8613-7f708fa846e8"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8a693a54-a317-3e08-9b33-ce37d860424e"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport skimage.feature\n#%matplotlib inline\n\n#from subprocess import check_output\n#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"},{"cell_type":"markdown","metadata":{"_cell_guid":"d0f85775-fd8f-0566-ccdc-f49254a72cec"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3e98f15b-256a-78aa-caa6-d83300228098"},"outputs":[],"source":"import sys\narg = sys.argv[1:]\n\nif('-f' in arg):\n    arg = ['Basic', '32', 'Whole', 'Train']\nelse:\n    new_arg = []\n    if('Basic' in arg):\n        idx = arg.index('Basic')\n        new_arg.append('Basic')\n        new_arg.append(arg[idx+1])\n    elif('Advance' in arg):\n        idx = arg.index('Advance')\n        new_arg.append('Advance')\n        new_arg.append(arg[idx+1])\n    else:\n        print(\"Please enter \\\"Basic\\\" or \\\"Advance\\\".\")\n    \n    if('Whole' in arg):\n        new_arg.append('Whole')\n    elif('Black' in arg):\n        new_arg.append('Black')\n    else:\n        print(\"Please enter \\\"Whole\\\" or \\\"Black\\\".\")\n    \n    if('Test' in arg):\n        new_arg.append('Test')\n    elif('Train' in arg):\n        new_arg.append('Train')\n    else:\n        print(\"Please enter \\\"Test\\\" or \\\"Train\\\".\")\n        \n    arg = new_arg"},{"cell_type":"markdown","metadata":{"_cell_guid":"91613296-7690-0d93-85ce-01e1b69118ec"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"42878286-0f19-141a-f806-5e276b10ed4c"},"outputs":[],"source":"Path_Type = \"{0}/{1}_{2}_{3}\".format(arg[3], arg[0], arg[1], arg[2])\nPath_Type"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4fa8675b-30be-53ac-215d-44ffb6232e01"},"outputs":[],"source":"Path_Sealion = \"./\" # \"/home/paperspace/Project/Sealion/{0}/\".format(Path_Type) # \nPath_Train   = \"../input/Train/\" # \"/home/paperspace/Project/Sealion/TrainSmall2/Train/\"  # \nPath_Dotted  = \"../input/TrainDotted/\" # \"/home/paperspace/Project/Sealion/TrainSmall2/TrainDotted/\"  # \nfile_names = os.listdir(Path_Train)\nfile_names = sorted(file_names, key=lambda \n                    item: (int(item.partition('.')[0]) if item[0].isdigit() else float('inf'), item))\n\nfile_names = file_names[1:2]\nprint(file_names)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"21c9b3b5-a82e-9979-a792-02db783bfba0"},"outputs":[],"source":"\"\"\"\nif not os.path.exists(\"/home/paperspace/Project/Sealion/{0}/Augment\".format(Path_Type)):\n    os.makedirs(\"/home/paperspace/Project/Sealion/{0}/Augment\".format(Path_Type))\nif not os.path.exists(\"/home/paperspace/Project/Sealion/{0}/Augment/Flip\".format(Path_Type)):\n    os.makedirs(\"/home/paperspace/Project/Sealion/{0}/Augment/Flip\".format(Path_Type))\nif not os.path.exists(\"/home/paperspace/Project/Sealion/{0}/Augment/Flip/JPEGImages\".format(Path_Type)):\n    os.makedirs(\"/home/paperspace/Project/Sealion/{0}/Augment/Flip/JPEGImages\".format(Path_Type))\nif not os.path.exists(\"/home/paperspace/Project/Sealion/{0}/Augment/Flip/labels\".format(Path_Type)):\n    os.makedirs(\"/home/paperspace/Project/Sealion/{0}/Augment/Flip/labels\".format(Path_Type))\n\"\"\""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0448db77-e32e-3c3b-cf12-6c22c6c14cdb"},"outputs":[],"source":"if not os.path.exists(\"./Augment\"):\n    os.makedirs(\"./Augment\")     \nif not os.path.exists(\"./Augment/Flip\"):\n    os.makedirs(\"./Augment/Flip\") \nif not os.path.exists(\"./Augment/Flip/JPEGImages\"):\n    os.makedirs(\"./Augment/Flip/JPEGImages\")  \nif not os.path.exists(\"./Augment/Flip/DotImages\"):\n    os.makedirs(\"./Augment/Flip/DotImages\")  \nif not os.path.exists(\"./Augment/Flip/labels\"):\n    os.makedirs(\"./Augment/Flip/labels\")"},{"cell_type":"markdown","metadata":{"_cell_guid":"4d31b44c-9193-b6e5-4633-3f87abb75b94"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fb2a89e4-6383-d47e-d152-2f4c61be1185"},"outputs":[],"source":"Sub_Im_Size = (416,416)\n\nimage_tmp = cv2.imread(Path_Train + file_names[0])\nimage_tmp = image_tmp[:Sub_Im_Size[1],:Sub_Im_Size[0],:]\nimage_tmp = cv2.absdiff(image_tmp,image_tmp)\n\nplt.imshow(cv2.cvtColor(image_tmp, cv2.COLOR_BGR2RGB))\ncv2.imwrite('sub_im_template.jpg',image_tmp)"},{"cell_type":"markdown","metadata":{"_cell_guid":"cd0aa91a-5acb-a165-761a-3342d0638d3b"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"78d17983-7b97-45fe-40aa-3e2e6aedad19"},"outputs":[],"source":"def get_blobs(filename):\n    # read the Train and Train Dotted images\n    image_1 = cv2.imread(Path_Dotted + filename)\n    image_2 = cv2.imread(Path_Train + filename)\n    \n    # absolute difference between Train and Train Dotted\n    image_3 = cv2.absdiff(image_1,image_2)\n    \n    # mask out blackened regions from Train Dotted\n    mask_1 = cv2.cvtColor(image_1, cv2.COLOR_BGR2GRAY)\n    mask_1[mask_1 < 20] = 0\n    mask_1[mask_1 > 0] = 255\n    \n    mask_2 = cv2.cvtColor(image_2, cv2.COLOR_BGR2GRAY)\n    mask_2[mask_2 < 20] = 0\n    mask_2[mask_2 > 0] = 255\n    \n    image_3 = cv2.bitwise_or(image_3, image_3, mask=mask_1)\n    image_3 = cv2.bitwise_or(image_3, image_3, mask=mask_2) \n    \n    # convert to grayscale to be accepted by skimage.feature.blob_log\n    image_3 = cv2.cvtColor(image_3, cv2.COLOR_BGR2GRAY)\n    \n    # detect blobs\n    blobs = skimage.feature.blob_log(image_3, min_sigma=3, max_sigma=4, num_sigma=1, threshold=0.02)\n    \n    return blobs"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"0a5ee6cb-7143-6fa1-f41d-1b8b908c9ac3"},"outputs":[],"source":"# classes = [\"adult_males\", \"subadult_males\", \"pups\", \"juveniles\", \"adult_females\"]\n\ndef get_species(r,g,b):    \n    if r > 200 and g < 50 and b < 50: # RED\n        return 0        \n    elif r > 200 and g > 200 and b < 50: # MAGENTA\n        return 1         \n    elif r < 100 and g < 100 and 150 < b < 200: # GREEN\n        return 2\n    elif r < 100 and  100 < g and b < 100: # BLUE\n        return 3\n    elif r < 150 and g < 50 and b < 100:  # BROWN\n        return 4\n    else:\n        return -1"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"69c11e92-605f-84bb-d372-b7c5351a7bbe"},"outputs":[],"source":"def get_xy_range_basic(x, y, x_max, y_max, size):\n    ### x_left, x_right, y_up, y_down\n    x_left  = min(size, x)\n    x_right = min(size, x_max-x-1)\n    y_up    = min(size, y)\n    y_down  = min(size, y_max-y-1)\n    return (x_left, x_right, y_up, y_down)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f2c0e524-c43d-88a8-75a1-ee306e9be785"},"outputs":[],"source":"def get_dict_range_basic(filename, blobs):\n    Dict_range = {}\n    ori_image = cv2.imread(Path_Train + filename)\n    \n    for blob in blobs:\n        # get the coordinates for each blob\n        y, x, s = blob\n        \n        # get basic xy_range\n        xy_range = get_xy_range_basic(x=x, y=y, x_max=ori_image.shape[1], y_max=ori_image.shape[0], size=int(arg[1])/2)\n        \n        # save range info    \n        Dict_range[(x,y)] = xy_range\n        \n    return Dict_range"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3a8fd1ef-3d33-9c4b-a24c-ee135f16763c"},"outputs":[],"source":"MAX_SUB_IM_HALF_LEN = 48\n\ndef get_dict_range_advance(filename, blobs):\n    Dict_range = {}\n    ori_image = cv2.imread(Path_Train + filename)\n    dot_image = cv2.imread(Path_Dotted + filename)\n    s_size = int(arg[1])/8\n    \n    for blob in blobs:\n        # get the coordinates for each blob\n        y, x, s = blob\n        \n        # get species\n        g,b,r = dot_image[int(y)][int(x)][:]\n        species = get_species(r,g,b)\n         \n        # get basic xy_range\n        xy_range = get_xy_range_basic(x=x, y=y, x_max=ori_image.shape[1], y_max=ori_image.shape[0], size=int(arg[1])/2)\n        x_left  = xy_range[0] \n        x_right = xy_range[1]\n        y_up    = xy_range[2]\n        y_down  = xy_range[3]\n        \n        # set augmenting threshold for sea_lion\n        level = 45\n        \n        # augment xy_range\n        if(species != 2):\n            mid_im = ori_image[int(y-s_size):int(y+s_size), int(x-s_size):int(x+s_size), :]\n            mid_abs = np.linalg.norm(np.mean(mid_im, axis=(0,1)))\n            \n            # augment left side\n            while(x_left != x and x_left != MAX_SUB_IM_HALF_LEN):\n                # get three sub_sub_image on left\n                left_mid_im  = ori_image[  int(y-s_size):int(y+s_size), int(x-x_left):int(x-x_left+2*s_size), :]\n                left_up_im   = ori_image[int(y-3*s_size):int(y-s_size), int(x-x_left):int(x-x_left+2*s_size), :]\n                left_down_im = ori_image[int(y+s_size):int(y+3*s_size), int(x-x_left):int(x-x_left+2*s_size), :]\n                \n                # calculate distance\n                left_mid_abs  = np.linalg.norm(np.mean(  left_mid_im, axis=(0,1)))\n                left_up_abs   = np.linalg.norm(np.mean(   left_up_im, axis=(0,1)))\n                left_down_abs = np.linalg.norm(np.mean( left_down_im, axis=(0,1)))\n                \n                # augment if proper\n                if(abs(mid_abs-left_mid_abs) < level or abs(mid_abs-left_up_abs) < level or abs(mid_abs-left_down_abs) < level):  \n                    x_left = min(x_left+s_size, MAX_SUB_IM_HALF_LEN, x)\n                    #print(\"Augment x_left {0},{1}\".format(x,y))\n                else:\n                    break\n\n            # augment right side\n            while(x_right != ori_image.shape[1]-x and x_right != MAX_SUB_IM_HALF_LEN):\n                # get three sub_sub_image on right\n                right_mid_im  = ori_image[  int(y-s_size):int(y+s_size), int(x+x_right-2*s_size):int(x+x_right), :]\n                right_up_im   = ori_image[int(y-3*s_size):int(y-s_size), int(x+x_right-2*s_size):int(x+x_right), :]\n                right_down_im = ori_image[int(y+s_size):int(y+3*s_size), int(x+x_right-2*s_size):int(x+x_right), :]\n                \n                # calculate distance\n                right_mid_abs  = np.linalg.norm(np.mean(  right_mid_im, axis=(0,1)))\n                right_up_abs   = np.linalg.norm(np.mean(   right_up_im, axis=(0,1)))\n                right_down_abs = np.linalg.norm(np.mean( right_down_im, axis=(0,1)))\n                \n                # augment if proper\n                if(abs(mid_abs-right_mid_abs) < level or abs(mid_abs-right_up_abs) < level or abs(mid_abs-right_down_abs) < level):\n                    x_right = min(x_right+s_size, MAX_SUB_IM_HALF_LEN, ori_image.shape[1]-x)\n                    #print(\"Augment x_right {0},{1}\".format(x,y))\n                else:\n                    break\n            \n            # augment up side\n            while(y_up != y and y_up != MAX_SUB_IM_HALF_LEN):\n                # get three sub_sub_image on up\n                up_mid_im   = ori_image[int(y-y_up):int(y-y_up+2*s_size),   int(x-s_size):int(x+s_size), :]\n                up_left_im  = ori_image[int(y-y_up):int(y-y_up+2*s_size), int(x-3*s_size):int(x-s_size), :]\n                up_right_im = ori_image[int(y-y_up):int(y-y_up+2*s_size), int(x+s_size):int(x+3*s_size), :]\n                \n                # calculate distance\n                up_mid_abs   = np.linalg.norm(np.mean(   up_mid_im, axis=(0,1)))\n                up_left_abs  = np.linalg.norm(np.mean(  up_left_im, axis=(0,1)))\n                up_right_abs = np.linalg.norm(np.mean( up_right_im, axis=(0,1)))\n            \n                # augment if proper\n                if(abs(mid_abs-up_mid_abs) < level or abs(mid_abs-up_left_abs) < level or abs(mid_abs-up_right_abs) < level):\n                    y_up = min(y_up+s_size, MAX_SUB_IM_HALF_LEN, y)\n                    #print(\"Augment y_up {0},{1}\".format(x,y))\n                else:\n                    break\n            \n            # augment down side\n            while(y_down != ori_image.shape[0]-y and y_down != MAX_SUB_IM_HALF_LEN):\n                # get three sub_sub_image on down\n                down_mid_im   = ori_image[int(y+y_down-2*s_size):int(y+y_down),   int(x-s_size):int(x+s_size), :]\n                down_left_im  = ori_image[int(y+y_down-2*s_size):int(y+y_down), int(x-3*s_size):int(x-s_size), :]\n                down_right_im = ori_image[int(y+y_down-2*s_size):int(y+y_down), int(x+s_size):int(x+3*s_size), :]\n                \n                # calculate distance\n                down_mid_abs   = np.linalg.norm(np.mean(   down_mid_im, axis=(0,1)))\n                down_left_abs  = np.linalg.norm(np.mean(  down_left_im, axis=(0,1)))\n                down_right_abs = np.linalg.norm(np.mean( down_right_im, axis=(0,1)))\n                \n                # augment if proper\n                if(abs(mid_abs-down_mid_abs) < level or abs(mid_abs-down_left_abs) < level or abs(mid_abs-down_right_abs) < level):\n                    y_down = min(y_down+s_size, MAX_SUB_IM_HALF_LEN, ori_image.shape[0]-y)\n                    #print(\"Augment y_down {0},{1}\".format(x,y))\n                else:\n                    break\n                    \n        # save range info    \n        Dict_range[(x,y)] = (x_left, x_right, y_up, y_down)\n    \n    return Dict_range"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5b30fe15-9c70-4046-3622-c5ed5267abab"},"outputs":[],"source":"def parse_image_black(filename):\n    ## open sub_image_names file\n    sub_image_names = open(Path_Sealion + \"Augment/Flip/Train.txt\", 'a')\n    \n    ### get original image\n    ori_image = cv2.imread(Path_Train + filename)\n    dot_image = cv2.imread(Path_Dotted + filename)\n    cnt = 0\n    \n    ### flip origin image\n    ori_image = ori_image[::-1]\n    dot_image = dot_image[::-1]\n    \n    ### get coordinate of all sea lions\n    Dict_range = {}\n    blobs = get_blobs(filename)\n    \n    ### get xy_range info for all sea_lion\n    if(arg[0] == 'Basic'):\n        Dict_range = get_dict_range_basic(filename, blobs)\n    elif(arg[0] == 'Advance'):\n        Dict_range = get_dict_range_advance(filename, blobs)\n    \n    ### output sub_image and annotation file for each blob\n    Delete_Key_List = []\n    for key in list(Dict_range.keys()):       \n        if(key in Dict_range):\n            # add cnt for new sub_image name\n            cnt += 1\n            \n            # get x, y, xy_range in original image\n            main_x = int(key[0])\n            main_y = int(key[1])\n            xy_range = Dict_range[key]\n            \n            ### get basic sub_image\n            sub_image = cv2.imread('sub_im_template.jpg')            \n            sub_x_center = int(sub_image.shape[1]/2)\n            sub_y_center = int(sub_image.shape[0]/2)\n            sub_image[int(sub_y_center-xy_range[2]):int(sub_y_center+xy_range[3]), int(sub_x_center-xy_range[0]):int(sub_x_center+xy_range[1]), :] = ori_image[int(main_y-xy_range[2]):int(main_y+xy_range[3]), int(main_x-xy_range[0]):int(main_x+xy_range[1]), :]\n            del Dict_range[key]\n                    \n            ### get species\n            g,b,r = dot_image[int(main_y)][int(main_x)][:]\n            species = get_species(r,g,b)\n            if(species == -1):\n                continue\n            \n            # get pos info for annotation file\n            x_pos = float(sub_x_center)/float(Sub_Im_Size[0])\n            y_pos = float(sub_y_center)/float(Sub_Im_Size[0])\n            x_len = float(xy_range[0]+xy_range[1])/float(Sub_Im_Size[0])\n            y_len = float(xy_range[2]+xy_range[3])/float(Sub_Im_Size[0])\n            element = [x_pos, y_pos, x_len, y_len]\n            \n            # save species info in annotation file\n            ant_file = open(Path_Sealion + 'Augment/Flip/labels/{0}_{1}.txt'.format(filename[:-4], cnt), 'w')\n            ant_file.write(str(species) + \" \" + \" \".join([str(x) for x in element]) + '\\n')\n            \n            \n            ### include other sea lion\n            # max min coordinate for including image based on origin image\n            x_min = max(main_x - sub_image.shape[1]/2 + 1, 0)\n            x_max = min(main_x + sub_image.shape[1]/2 - 1, ori_image.shape[1])\n            y_min = max(main_y - sub_image.shape[0]/2 + 1, 0)\n            y_max = min(main_y + sub_image.shape[0]/2 - 1, ori_image.shape[0])\n            \n            for ex_key in list(Dict_range.keys()):\n                if(ex_key[0] > x_min and ex_key[0] < x_max and ex_key[1] > y_min and ex_key[1] < y_max):\n                    ### coordinate of ex_sea_lion in origin image\n                    ex_range = Dict_range[ex_key]\n                    ex_left  = int(ex_key[0] - ex_range[0])\n                    ex_right = int(ex_key[0] + ex_range[1])\n                    ex_up    = int(ex_key[1] - ex_range[2])\n                    ex_down  = int(ex_key[1] + ex_range[3])\n                    if(ex_left > x_min and ex_right < x_max and ex_up > y_min and ex_down < y_max):\n                        ### sub_image's coordinate where ex_sea_lion put  \n                        in_up    = int(sub_y_center - main_y + ex_key[1] - ex_range[2])\n                        in_down  = int(sub_y_center - main_y + ex_key[1] + ex_range[3])\n                        in_left  = int(sub_x_center - main_x + ex_key[0] - ex_range[0])\n                        in_right = int(sub_x_center - main_x + ex_key[0] + ex_range[1])\n                        sub_image[ in_up:in_down, in_left:in_right, :] = ori_image[ex_up:ex_down, ex_left:ex_right, :]\n                        del Dict_range[ex_key]\n                        \n                        ### get species for include sea_lion\n                        g,b,r = dot_image[int(ex_key[1])][int(ex_key[0])][:]\n                        species = get_species(r,g,b)\n            \n                        # get pos info for annotation file\n                        x_pos = float(sub_x_center - main_x + ex_key[0])/float(Sub_Im_Size[0])\n                        y_pos = float(sub_y_center - main_y + ex_key[1])/float(Sub_Im_Size[0])\n                        x_len = float(ex_range[0]+ex_range[1])/float(Sub_Im_Size[0])\n                        y_len = float(ex_range[2]+ex_range[3])/float(Sub_Im_Size[0])\n                        element = [x_pos, y_pos, x_len, y_len]\n            \n                        # save species info in annotation file\n                        ant_file.write(str(species) + \" \" + \" \".join([str(x) for x in element]) + '\\n')                          \n            \n            cv2.imwrite(Path_Sealion + 'Augment/Flip/JPEGImages/{0}_{1}.jpg'.format(filename[:-4], cnt),sub_image)\n            #cv2.imwrite('{0}_{1}.png'.format(filename[:-4], cnt),sub_image)\n            sub_image_names.write(Path_Sealion + 'Augment/Flip/JPEGImages/{0}_{1}.jpg'.format(filename[:-4], cnt))\n            sub_image_names.write(\"\\n\")\n            ant_file.close()\n    sub_image_names.close()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"fa3bcc1a-645f-855e-e11a-513dabbdf6f7"},"outputs":[],"source":"def parse_image_whole(filename):\n    ## open sub_image_names file\n    sub_image_names = open(Path_Sealion + \"Augment/Flip/Train.txt\", 'a')\n    \n    ### get original image\n    ori_image = cv2.imread(Path_Train + filename)\n    dot_image = cv2.imread(Path_Dotted + filename)\n    cnt = 0\n    \n    ### flip origin image\n    #ori_image = ori_image[::-1]\n    #dot_image = dot_image[::-1]\n    \n    ### get coordinate of all sea lions\n    blobs = get_blobs(filename)\n    \n    ### get xy_range info for all sea_lion\n    if(arg[0] == 'Basic'):\n        Dict_range = get_dict_range_basic(filename, blobs)\n    elif(arg[0] == 'Advance'):\n        Dict_range = get_dict_range_advance(filename, blobs)\n    \n    ### output sub_image and annotation file for each blob\n    Used_Key_Set = set()\n    for key in Dict_range.keys():       \n        if(key not in Used_Key_Set):\n            # add cnt for new sub_image name\n            cnt += 1\n            \n            # get x, y, xy_range in original image\n            main_x = int(key[0])\n            main_y = int(key[1])\n            xy_range = Dict_range[key]\n            \n            # adjust main_x main_y if sea_lion close to boundary\n            if(main_x - Sub_Im_Size[0]/2 < 0):\n                main_x = Sub_Im_Size[0]/2\n            if(main_x + Sub_Im_Size[0]/2 > ori_image.shape[1]):\n                main_x = ori_image.shape[1] - Sub_Im_Size[0]/2\n            if(main_y - Sub_Im_Size[1]/2 < 0):\n                main_y = Sub_Im_Size[1]/2\n            if(main_y + Sub_Im_Size[1]/2 > ori_image.shape[0]):\n                main_y = ori_image.shape[0] - Sub_Im_Size[1]/2\n            \n            # get_sub_image\n            sub_image     = ori_image[int(main_y - Sub_Im_Size[1]/2) : int(main_y + Sub_Im_Size[1]/2), int(main_x - Sub_Im_Size[0]/2) : int(main_x + Sub_Im_Size[0]/2), :]\n            sub_image_dot = dot_image[int(main_y - Sub_Im_Size[1]/2) : int(main_y + Sub_Im_Size[1]/2), int(main_x - Sub_Im_Size[0]/2) : int(main_x + Sub_Im_Size[0]/2), :]\n            \n            # record key as used_key\n            Used_Key_Set.add(key)\n            \n            ### get species\n            g,b,r = dot_image[int(key[1])][int(key[0])][:]\n            species = get_species(r,g,b)\n            if(species == -1):\n                continue\n\n            # get pos info for annotation file\n            x_pos = float(key[0]-(main_x-Sub_Im_Size[0]/2))/float(Sub_Im_Size[0])\n            y_pos = float(key[1]-(main_y-Sub_Im_Size[1]/2))/float(Sub_Im_Size[1])\n            x_len = float(xy_range[0]+xy_range[1])/float(Sub_Im_Size[0])\n            y_len = float(xy_range[2]+xy_range[3])/float(Sub_Im_Size[1])\n            element = [x_pos, y_pos, x_len, y_len]\n            \n            # save species info in annotation file\n            ant_file = open(Path_Sealion + 'Augment/Flip/labels/{0}_{1}.txt'.format(filename[:-4], cnt), 'w')\n            ant_file.write(str(species) + \" \" + \" \".join([str(x) for x in element]) + '\\n')\n            \n            \n            ### include other sea lion\n            # max min coordinate for including image based on origin image\n            x_min = max(main_x - sub_image.shape[1]/2 + 1, 0)\n            x_max = min(main_x + sub_image.shape[1]/2 - 1, ori_image.shape[1])\n            y_min = max(main_y - sub_image.shape[0]/2 + 1, 0)\n            y_max = min(main_y + sub_image.shape[0]/2 - 1, ori_image.shape[0])\n            \n            for ex_key in Dict_range.keys():\n                if(ex_key != key and ex_key[0] > x_min and ex_key[0] < x_max and ex_key[1] > y_min and ex_key[1] < y_max):\n                    ### coordinate of ex_sea_lion in origin image\n                    ex_range = Dict_range[ex_key]\n                    ex_left  = int(ex_key[0] - ex_range[0])\n                    ex_right = int(ex_key[0] + ex_range[1])\n                    ex_up    = int(ex_key[1] - ex_range[2])\n                    ex_down  = int(ex_key[1] + ex_range[3])\n                    \n                    ### sub_image's coordinate where ex_sea_lion put  \n                    Used_Key_Set.add(ex_key)\n\n                    ### get species for include sea_lion\n                    g,b,r = dot_image[int(ex_key[1])][int(ex_key[0])][:]\n                    species = get_species(r,g,b)\n            \n                    # get pos info for annotation file\n                    x_pos = float(ex_key[0]-(main_x-Sub_Im_Size[0]/2))/float(Sub_Im_Size[0])\n                    y_pos = float(ex_key[1]-(main_y-Sub_Im_Size[1]/2))/float(Sub_Im_Size[1])\n                    \n                    # adjust real size of include sea_lion due to be close to boarder\n                    ex_left_size  = min(ex_range[0], ex_key[0]-(main_x-Sub_Im_Size[0]/2))\n                    ex_right_size = min(ex_range[1], (main_x+Sub_Im_Size[0]/2)-ex_key[0])\n                    ex_up_size    = min(ex_range[2], ex_key[1]-(main_y-Sub_Im_Size[1]/2))\n                    ex_down_size  = min(ex_range[3], (main_y+Sub_Im_Size[1]/2)-ex_key[1])\n                    \n                    x_len = float(ex_left_size+ex_right_size)/float(Sub_Im_Size[0])\n                    y_len = float(ex_up_size+ex_down_size)/float(Sub_Im_Size[1])\n                    element = [x_pos, y_pos, x_len, y_len]\n            \n                    # save species info in annotation file\n                    ant_file.write(str(species) + \" \" + \" \".join([str(x) for x in element]) + '\\n')                          \n            \n            cv2.imwrite(Path_Sealion + 'Augment/Flip/JPEGImages/{0}_{1}.jpg'.format(filename[:-4], cnt), sub_image)\n            cv2.imwrite(Path_Sealion +  'Augment/Flip/DotImages/{0}_{1}.jpg'.format(filename[:-4], cnt), sub_image_dot)\n            #cv2.imwrite('{0}_{1}.png'.format(filename[:-4], cnt),sub_image)\n            sub_image_names.write(Path_Sealion + 'Augment/Flip/JPEGImages/{0}_{1}.jpg'.format(filename[:-4], cnt))\n            sub_image_names.write(\"\\n\")\n            ant_file.close()\n    sub_image_names.close()"},{"cell_type":"markdown","metadata":{"_cell_guid":"12d461e3-a244-f33a-cd97-e0daa849076d"},"source":""},{"cell_type":"markdown","metadata":{"_cell_guid":"9e3bccea-03ab-d77f-71f8-6de686515f21"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3054debf-59eb-b779-61a7-584cc797caaa"},"outputs":[],"source":"if os.path.exists(Path_Sealion + \"Augment/Flip/Train.txt\"):\n    os.remove(Path_Sealion + \"Augment/Flip/Train.txt\")\n\nfor filename in file_names:\n    if filename[-3:] == 'jpg':\n        parse_image_whole(filename)\n        \n        \"\"\"\n        print(\"Parsing {0}\".format(filename))\n        if(arg[2] == 'Black'):\n            parse_image_black(filename)\n        elif(arg[2] == 'Whole'):\n            parse_image_whole(filename)\n        else:\n            print(\"Wrong in argument\")\n        \"\"\""},{"cell_type":"markdown","metadata":{"_cell_guid":"8b5a797f-ad00-f818-30e8-a34cb7abc7a2"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c3668d36-2b4f-68bb-04d5-a0ce41185dfd"},"outputs":[],"source":"os.remove('sub_im_template.jpg')"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}