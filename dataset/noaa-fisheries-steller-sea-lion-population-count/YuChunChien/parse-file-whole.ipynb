{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"403f378b-67ea-d118-3d07-0a68c299ce60"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9255110f-aba2-d482-886c-c4dea3c87287"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport skimage.feature\n#%matplotlib inline\n\n#from subprocess import check_output\n#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ef7a38d3-302f-753b-abb0-91dae1ebcf05"},"outputs":[],"source":"import sys\narg = sys.argv[1:]"},{"cell_type":"markdown","metadata":{"_cell_guid":"12530618-ea0f-5a1e-a39a-327e89f46e4e"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"23a7340a-059b-d70c-27eb-7c6c45d14130"},"outputs":[],"source":"if(arg[0] == '-b'):\n    Path_Type = \"Basic_{0}\".format(arg[1])\nelif(arg[0] == '-a'):\n    Path_Type = \"Advance_{0}\".format(arg[1])\nelse:\n    Path_Type = \"Basic_32\""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8c49195f-e583-8330-e88b-85d8b8b90aac"},"outputs":[],"source":"Path_Sealion = \"./\" # \"/home/paperspace/Project/Sealion/{0}/\".format(Path_Type) # \nPath_Train  = \"../input/Train/\" # \"/home/paperspace/Project/Sealion/TrainSmall2/Train/\"  # \nPath_Dotted = \"../input/TrainDotted/\" # \"/home/paperspace/Project/Sealion/TrainSmall2/TrainDotted/\"  # \nfile_names = os.listdir(Path_Train)\nfile_names = sorted(file_names, key=lambda \n                    item: (int(item.partition('.')[0]) if item[0].isdigit() else float('inf'), item))\n\nfile_names = file_names[1:2]\nprint(file_names)\n# select a subset of files to run on\n#file_names = file_names[0:1]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"166ca57d-ee59-5ece-ed9f-49adeac103c3"},"outputs":[],"source":"\"\"\"\nif not os.path.exists(\"/home/paperspace/Project/Sealion/{0}\".format(Path_Type)):\n    os.makedirs(\"/home/paperspace/Project/Sealion/{0}\".format(Path_Type))\nif not os.path.exists(\"/home/paperspace/Project/Sealion/{0}/labels\".format(Path_Type)):\n    os.makedirs(\"/home/paperspace/Project/Sealion/{0}/labels\".format(Path_Type))\nif not os.path.exists(\"/home/paperspace/Project/Sealion/{0}/JPEGImages\".format(Path_Type)):\n    os.makedirs(\"/home/paperspace/Project/Sealion/{0}/JPEGImages\".format(Path_Type))\n\"\"\""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7f1f5602-6e67-bf06-8169-01974d852b35"},"outputs":[],"source":"\nif not os.path.exists(\"./labels\"):\n    os.makedirs(\"./labels\")\nif not os.path.exists(\"./JPEGImages\"):\n    os.makedirs(\"./JPEGImages\")\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"0d10df83-caea-1c64-81a0-dd9c9353559a"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5c6f6c1d-d2a2-5cc4-b940-395db9951604"},"outputs":[],"source":"Sub_Im_Size = (416,416)\n\nimage_tmp = cv2.imread(Path_Train + file_names[0])\nimage_tmp = image_tmp[:Sub_Im_Size[1],:Sub_Im_Size[0],:]\nimage_tmp = cv2.absdiff(image_tmp,image_tmp)\n\nplt.imshow(cv2.cvtColor(image_tmp, cv2.COLOR_BGR2RGB))\ncv2.imwrite('sub_im_template.jpg',image_tmp)"},{"cell_type":"markdown","metadata":{"_cell_guid":"804cb60e-e351-319e-6c9b-89bde2e84853"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c811677b-00b2-0b7f-6a44-012f242d8ea9"},"outputs":[],"source":"def get_blobs(filename):\n    # read the Train and Train Dotted images\n    image_1 = cv2.imread(Path_Dotted + filename)\n    image_2 = cv2.imread(Path_Train + filename)\n    \n    # absolute difference between Train and Train Dotted\n    image_3 = cv2.absdiff(image_1,image_2)\n    \n    # mask out blackened regions from Train Dotted\n    mask_1 = cv2.cvtColor(image_1, cv2.COLOR_BGR2GRAY)\n    mask_1[mask_1 < 20] = 0\n    mask_1[mask_1 > 0] = 255\n    \n    mask_2 = cv2.cvtColor(image_2, cv2.COLOR_BGR2GRAY)\n    mask_2[mask_2 < 20] = 0\n    mask_2[mask_2 > 0] = 255\n    \n    image_3 = cv2.bitwise_or(image_3, image_3, mask=mask_1)\n    image_3 = cv2.bitwise_or(image_3, image_3, mask=mask_2) \n    \n    # convert to grayscale to be accepted by skimage.feature.blob_log\n    image_3 = cv2.cvtColor(image_3, cv2.COLOR_BGR2GRAY)\n    \n    # detect blobs\n    blobs = skimage.feature.blob_log(image_3, min_sigma=3, max_sigma=4, num_sigma=1, threshold=0.02)\n    \n    return blobs"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4308b650-6a18-a860-d5d8-f39a264a1097"},"outputs":[],"source":"def get_xy_range_basic(x, y, x_max, y_max, size):\n    ### x_left, x_right, y_up, y_down\n    x_left  = min(size, x)\n    x_right = min(size, x_max-x-1)\n    y_up    = min(size, y)\n    y_down  = min(size, y_max-y-1)\n    return (x_left, x_right, y_up, y_down)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"210857f1-f27c-050c-633e-53885ff84a6a"},"outputs":[],"source":"# classes = [\"adult_males\", \"subadult_males\", \"adult_females\", \"juveniles\", \"pups\"]\n\ndef get_species(r,g,b):    \n    if r > 200 and g < 50 and b < 50: # RED\n        return 0        \n    elif r > 200 and g > 200 and b < 50: # MAGENTA\n        return 1         \n    elif r < 100 and g < 100 and 150 < b < 200: # GREEN\n        return 2\n    elif r < 100 and  100 < g and b < 100: # BLUE\n        return 3\n    elif r < 150 and g < 50 and b < 100:  # BROWN\n        return 4"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f0eedce5-a2e6-5001-0dbe-d68876499af1"},"outputs":[],"source":"def parse_image_black(filename):\n    ## open sub_image_names file\n    sub_image_names = open(Path_Sealion + \"Train.txt\", 'a')\n    \n    ### get original image\n    ori_image = cv2.imread(Path_Train + filename)\n    dot_image = cv2.imread(Path_Dotted + filename)\n    cnt = 0\n    \n    ### get coordinate of all sea lions\n    Dict_range = {}\n    blobs = get_blobs(filename)\n    \n    for blob in blobs:\n        # get the coordinates for each blob\n        y, x, s = blob\n        \n        # decide get_xy_range method\n        if(arg[0] == '-b' and arg[1]):\n            xy_range = get_xy_range_basic(x=x, y=y, x_max=ori_image.shape[1], y_max=ori_image.shape[0], size=int(arg[1])/2)\n        elif(arg[0] == '-a' and arg[1]):\n            xy_range = get_xy_range_advance()\n        else:\n            xy_range = get_xy_range_basic(x=x, y=y, x_max=ori_image.shape[1], y_max=ori_image.shape[0], size=16)\n            \n        # save range info    \n        Dict_range[(x,y)] = xy_range\n    \n    ### output sub_image and annotation file for each blob\n    Delete_Key_List = []\n    for key in list(Dict_range.keys()):       \n        if(key in Dict_range):\n            # add cnt for new sub_image name\n            cnt += 1\n            \n            # get x, y, xy_range in original image\n            main_x = int(key[0])\n            main_y = int(key[1])\n            xy_range = Dict_range[key]\n            \n            ### get basic sub_image\n            sub_image = cv2.imread('sub_im_template.jpg')            \n            sub_x_center = int(sub_image.shape[1]/2)\n            sub_y_center = int(sub_image.shape[0]/2)\n            sub_image[int(sub_y_center-xy_range[2]):int(sub_y_center+xy_range[3]), int(sub_x_center-xy_range[0]):int(sub_x_center+xy_range[1]), :] = ori_image[int(main_y-xy_range[2]):int(main_y+xy_range[3]), int(main_x-xy_range[0]):int(main_x+xy_range[1]), :]\n            del Dict_range[key]\n                    \n            ### get species\n            g,b,r = dot_image[int(main_y)][int(main_x)][:]\n            species = get_species(r,g,b)\n            \n            # get pos info for annotation file\n            x_pos = float(sub_x_center)/float(Sub_Im_Size[0])\n            y_pos = float(sub_y_center)/float(Sub_Im_Size[0])\n            x_len = float(xy_range[0]+xy_range[1])/float(Sub_Im_Size[0])\n            y_len = float(xy_range[2]+xy_range[3])/float(Sub_Im_Size[0])\n            element = [x_pos, y_pos, x_len, y_len]\n            \n            # save species info in annotation file\n            ant_file = open(Path_Sealion + 'labels/{0}_{1}.txt'.format(filename[:-4], cnt), 'w')\n            ant_file.write(str(species) + \" \" + \" \".join([str(x) for x in element]) + '\\n')\n            \n            \n            ### include other sea lion\n            # max min coordinate for including image based on origin image\n            x_min = max(main_x - sub_image.shape[1]/2 + 1, 0)\n            x_max = min(main_x + sub_image.shape[1]/2 - 1, ori_image.shape[1])\n            y_min = max(main_y - sub_image.shape[0]/2 + 1, 0)\n            y_max = min(main_y + sub_image.shape[0]/2 - 1, ori_image.shape[0])\n            \n            for ex_key in list(Dict_range.keys()):\n                if(ex_key[0] > x_min and ex_key[0] < x_max and ex_key[1] > y_min and ex_key[1] < y_max):\n                    ### coordinate of ex_sea_lion in origin image\n                    ex_range = Dict_range[ex_key]\n                    ex_left  = int(ex_key[0] - ex_range[0])\n                    ex_right = int(ex_key[0] + ex_range[1])\n                    ex_up    = int(ex_key[1] - ex_range[2])\n                    ex_down  = int(ex_key[1] + ex_range[3])\n                    if(ex_left > x_min and ex_right < x_max and ex_up > y_min and ex_down < y_max):\n                        ### sub_image's coordinate where ex_sea_lion put  \n                        in_up    = int(sub_y_center - main_y + ex_key[1] - ex_range[2])\n                        in_down  = int(sub_y_center - main_y + ex_key[1] + ex_range[3])\n                        in_left  = int(sub_x_center - main_x + ex_key[0] - ex_range[0])\n                        in_right = int(sub_x_center - main_x + ex_key[0] + ex_range[1])\n                        sub_image[ in_up:in_down, in_left:in_right, :] = ori_image[ex_up:ex_down, ex_left:ex_right, :]\n                        del Dict_range[ex_key]\n                        \n                        ### get species for include sea_lion\n                        g,b,r = dot_image[int(ex_key[1])][int(ex_key[0])][:]\n                        species = get_species(r,g,b)\n            \n                        # get pos info for annotation file\n                        x_pos = float(sub_x_center - main_x + ex_key[0])/float(Sub_Im_Size[0])\n                        y_pos = float(sub_y_center - main_y + ex_key[1])/float(Sub_Im_Size[0])\n                        x_len = float(ex_range[0]+ex_range[1])/float(Sub_Im_Size[0])\n                        y_len = float(ex_range[2]+ex_range[3])/float(Sub_Im_Size[0])\n                        element = [x_pos, y_pos, x_len, y_len]\n            \n                        # save species info in annotation file\n                        ant_file.write(str(species) + \" \" + \" \".join([str(x) for x in element]) + '\\n')                          \n            \n            cv2.imwrite(Path_Sealion + 'JPEGImages/{0}_{1}.jpg'.format(filename[:-4], cnt),sub_image)\n            #cv2.imwrite('{0}_{1}.png'.format(filename[:-4], cnt),sub_image)\n            sub_image_names.write(Path_Sealion + 'JPEGImages/{0}_{1}.jpg'.format(filename[:-4], cnt))\n            sub_image_names.write(\"\\n\")\n            ant_file.close()\n    sub_image_names.close()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"90d1fef6-0929-b4c0-1a44-2585079f9a2a"},"outputs":[],"source":"def parse_image_whole(filename):\n    ## open sub_image_names file\n    sub_image_names = open(Path_Sealion + \"Train.txt\", 'a')\n    \n    ### get original image\n    ori_image = cv2.imread(Path_Train + filename)\n    dot_image = cv2.imread(Path_Dotted + filename)\n    cnt = 0\n    \n    ### get coordinate of all sea lions\n    Dict_range = {}\n    blobs = get_blobs(filename)\n    \n    for blob in blobs:\n        # get the coordinates for each blob\n        y, x, s = blob\n        \n        # decide get_xy_range method\n        if(arg[0] == '-b' and arg[1]):\n            xy_range = get_xy_range_basic(x=x, y=y, x_max=ori_image.shape[1], y_max=ori_image.shape[0], size=int(arg[1])/2)\n        elif(arg[0] == '-a' and arg[1]):\n            xy_range = get_xy_range_advance()\n        else:\n            xy_range = get_xy_range_basic(x=x, y=y, x_max=ori_image.shape[1], y_max=ori_image.shape[0], size=16)\n            \n        # save range info    \n        Dict_range[(x,y)] = xy_range\n    \n    ### output sub_image and annotation file for each blob\n    Used_Key_Set = set()\n    for key in Dict_range.keys():       \n        if(key not in Used_Key_Set):\n            # add cnt for new sub_image name\n            cnt += 1\n            \n            # get x, y, xy_range in original image\n            main_x = int(key[0])\n            main_y = int(key[1])\n            xy_range = Dict_range[key]\n            \n            # adjust main_x main_y if sea_lion close to boundary\n            if(main_x - Sub_Im_Size[0]/2 < 0):\n                main_x = Sub_Im_Size[0]/2\n            if(main_x + Sub_Im_Size[0]/2 > ori_image.shape[1]):\n                main_x = ori_image.shape[1] - Sub_Im_Size[0]/2\n            if(main_y - Sub_Im_Size[1]/2 < 0):\n                main_y = Sub_Im_Size[1]/2\n            if(main_y + Sub_Im_Size[1]/2 > ori_image.shape[0]):\n                main_x = ori_image.shape[0] - Sub_Im_Size[1]/2\n            \n            # get_sub_image\n            sub_image = ori_image[int(main_y - Sub_Im_Size[1]/2) : int(main_y + Sub_Im_Size[1]/2), int(main_x - Sub_Im_Size[0]/2) : int(main_x + Sub_Im_Size[0]/2), :]\n            \n            # record key as used_key\n            Used_Key_Set.add(key)\n           \n            ### get species\n            g,b,r = dot_image[int(key[1])][int(key[0])][:]\n            species = get_species(r,g,b)\n    \n            # get pos info for annotation file\n            x_pos = float(key[0]-(main_x-Sub_Im_Size[0]/2))/float(Sub_Im_Size[0])\n            y_pos = float(key[1]-(main_y-Sub_Im_Size[1]/2))/float(Sub_Im_Size[1])\n            x_len = float(xy_range[0]+xy_range[1])/float(Sub_Im_Size[0])\n            y_len = float(xy_range[2]+xy_range[3])/float(Sub_Im_Size[1])\n            element = [x_pos, y_pos, x_len, y_len]\n            \n            # save species info in annotation file\n            ant_file = open(Path_Sealion + 'labels/{0}_{1}.txt'.format(filename[:-4], cnt), 'w')\n            ant_file.write(str(species) + \" \" + \" \".join([str(x) for x in element]) + '\\n')\n            \n            \n            ### include other sea lion\n            # max min coordinate for including image based on origin image\n            x_min = max(main_x - sub_image.shape[1]/2 + 1, 0)\n            x_max = min(main_x + sub_image.shape[1]/2 - 1, ori_image.shape[1])\n            y_min = max(main_y - sub_image.shape[0]/2 + 1, 0)\n            y_max = min(main_y + sub_image.shape[0]/2 - 1, ori_image.shape[0])\n          \n            for ex_key in Dict_range.keys():\n                if(ex_key != key and ex_key[0] > x_min and ex_key[0] < x_max and ex_key[1] > y_min and ex_key[1] < y_max):\n                    ### coordinate of ex_sea_lion in origin image\n                    ex_range = Dict_range[ex_key]\n                    ex_left  = int(ex_key[0] - ex_range[0])\n                    ex_right = int(ex_key[0] + ex_range[1])\n                    ex_up    = int(ex_key[1] - ex_range[2])\n                    ex_down  = int(ex_key[1] + ex_range[3])\n                    if(ex_left > x_min and ex_right < x_max and ex_up > y_min and ex_down < y_max):\n                        ### sub_image's coordinate where ex_sea_lion put  \n                        Used_Key_Set.add(ex_key)\n                       \n                        ### get species for include sea_lion\n                        g,b,r = dot_image[int(ex_key[1])][int(ex_key[0])][:]\n                        species = get_species(r,g,b)\n            \n                        # get pos info for annotation file\n                        x_pos = float(ex_key[0]-(main_x-Sub_Im_Size[0]/2))/float(Sub_Im_Size[0])\n                        y_pos = float(ex_key[1]-(main_y-Sub_Im_Size[1]/2))/float(Sub_Im_Size[1])\n                        x_len = float(ex_range[0]+ex_range[1])/float(Sub_Im_Size[0])\n                        y_len = float(ex_range[2]+ex_range[3])/float(Sub_Im_Size[1])\n                        element = [x_pos, y_pos, x_len, y_len]\n            \n                        # save species info in annotation file\n                        ant_file.write(str(species) + \" \" + \" \".join([str(x) for x in element]) + '\\n')                          \n           \n            cv2.imwrite(Path_Sealion + 'JPEGImages/{0}_{1}.jpg'.format(filename[:-4], cnt), sub_image)\n            #cv2.imwrite('{0}_{1}.png'.format(filename[:-4], cnt),sub_image)\n            sub_image_names.write(Path_Sealion + 'JPEGImages/{0}_{1}.jpg'.format(filename[:-4], cnt))\n            sub_image_names.write(\"\\n\")\n            ant_file.close()\n    sub_image_names.close()\n    "},{"cell_type":"markdown","metadata":{"_cell_guid":"bd42b615-576f-b8e9-9bdb-7b5937fccec2"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a1fd4cd0-2c0c-3177-c29f-3565b2f6be0c"},"outputs":[],"source":"### remove Train.txt if exist\nif os.path.exists(Path_Sealion + \"Train.txt\"):\n    os.remove(Path_Sealion + \"Train.txt\")\n\nfor filename in file_names:\n    if filename[-3:] == 'jpg':\n        parse_image_whole(filename)\n        \n        \"\"\"\n        if(len(arg) >= 3 and arg[2] == '-b'):\n            parse_image_black(filename)\n        elif(len(arg) >= 3 and arg[2] == '-w'):\n            parse_image_whole(filename)\n        else:\n            print(\"Please enter \\\"black\\\" or \\\"whole\\\".\")\n        \"\"\""},{"cell_type":"markdown","metadata":{"_cell_guid":"e4b20f5c-8ccc-1358-8923-ba3c3c477543"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b8c63156-ed8f-407d-ddeb-ea5e9b3eafd9"},"outputs":[],"source":"os.remove('sub_im_template.jpg')"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}