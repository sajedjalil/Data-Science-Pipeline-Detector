{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"97e436b7-8a2c-2005-4561-0168486842f6"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport skimage.feature\n#%matplotlib inline\n\n#from subprocess import check_output\n#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"},{"cell_type":"markdown","metadata":{"_cell_guid":"50b64479-c001-27c3-2adb-c3d119a9a5a9"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aac98a74-9643-f60a-8c74-08d3868bcc79"},"outputs":[],"source":"import sys\narg = sys.argv[1:]\n\nif('-f' in arg):\n    arg = ['Advance', '32', 'Black', 'Train']\nelse:\n    new_arg = []\n    if('Basic' in arg):\n        idx = arg.index('Basic')\n        new_arg.append('Basic')\n        new_arg.append(arg[idx+1])\n    elif('Advance' in arg):\n        idx = arg.index('Advance')\n        new_arg.append('Advance')\n        new_arg.append(arg[idx+1])\n    else:\n        print(\"Please enter \\\"Basic\\\" or \\\"Advance\\\".\")\n    \n    if('Whole' in arg):\n        new_arg.append('Whole')\n    elif('Black' in arg):\n        new_arg.append('Black')\n    else:\n        print(\"Please enter \\\"Whole\\\" or \\\"Black\\\".\")\n    \n    if('Test' in arg):\n        new_arg.append('Test')\n    elif('Train' in arg):\n        new_arg.append('Train')\n    else:\n        print(\"Please enter \\\"Test\\\" or \\\"Train\\\".\")\n        \n    arg = new_arg"},{"cell_type":"markdown","metadata":{"_cell_guid":"c1d6e45d-0644-2ed3-a639-f5d42e3762c3"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"67306e91-e43d-c5d4-0ac5-f30d17c9a894"},"outputs":[],"source":"Path_Type = \"{0}/{1}_{2}_{3}\".format(arg[3], arg[0], arg[1], arg[2])\nPath_Type"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6776ed96-a915-7cc2-e643-6aea309bb615"},"outputs":[],"source":"Path_Sealion = \"./\" # \"/home/paperspace/Project/Sealion/{0}/\".format(Path_Type) # \nPath_Train   = \"../input/Train/\" # \"/home/paperspace/Project/Sealion/TrainSmall2/Train/\"  # \nPath_Dotted  = \"../input/TrainDotted/\" # \"/home/paperspace/Project/Sealion/TrainSmall2/TrainDotted/\"  # \nfile_names = os.listdir(Path_Train)\nfile_names = sorted(file_names, key=lambda \n                    item: (int(item.partition('.')[0]) if item[0].isdigit() else float('inf'), item))\n\nfile_names = file_names[0:1]\nprint(file_names)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1e369db0-98d6-11bb-2474-7b75c14d220c"},"outputs":[],"source":"\"\"\"\nif not os.path.exists(\"/home/paperspace/Project/Sealion/{0}\".format(Path_Type)):\n    os.makedirs(\"/home/paperspace/Project/Sealion/{0}\".format(Path_Type))\nif not os.path.exists(\"/home/paperspace/Project/Sealion/{0}/labels\".format(Path_Type)):\n    os.makedirs(\"/home/paperspace/Project/Sealion/{0}/labels\".format(Path_Type))\nif not os.path.exists(\"/home/paperspace/Project/Sealion/{0}/JPEGImages\".format(Path_Type)):\n    os.makedirs(\"/home/paperspace/Project/Sealion/{0}/JPEGImages\".format(Path_Type))\n\"\"\""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9f9fca50-f5d7-1b95-7f24-c74a42b1d25c"},"outputs":[],"source":"\nif not os.path.exists(\"./labels\"):\n    os.makedirs(\"./labels\")\nif not os.path.exists(\"./JPEGImages\"):\n    os.makedirs(\"./JPEGImages\")\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"376e95e9-4b42-b8cf-5834-a0881b40ea9c"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"881ab8c8-e6a6-ef8a-29c2-57b921587ebc"},"outputs":[],"source":"Sub_Im_Size = (416,416)\n\nimage_tmp = cv2.imread(Path_Train + file_names[0])\nimage_tmp = image_tmp[:Sub_Im_Size[1],:Sub_Im_Size[0],:]\nimage_tmp = cv2.absdiff(image_tmp,image_tmp)\n\nplt.imshow(cv2.cvtColor(image_tmp, cv2.COLOR_BGR2RGB))\ncv2.imwrite('sub_im_template.jpg',image_tmp)"},{"cell_type":"markdown","metadata":{"_cell_guid":"6f23766f-4856-9eb2-4240-10d8910248ee"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"03dd9090-3674-0246-5a70-ddfcd55cc107"},"outputs":[],"source":"def get_blobs(filename):\n    # read the Train and Train Dotted images\n    image_1 = cv2.imread(Path_Dotted + filename)\n    image_2 = cv2.imread(Path_Train + filename)\n    \n    # absolute difference between Train and Train Dotted\n    image_3 = cv2.absdiff(image_1,image_2)\n    \n    # mask out blackened regions from Train Dotted\n    mask_1 = cv2.cvtColor(image_1, cv2.COLOR_BGR2GRAY)\n    mask_1[mask_1 < 20] = 0\n    mask_1[mask_1 > 0] = 255\n    \n    mask_2 = cv2.cvtColor(image_2, cv2.COLOR_BGR2GRAY)\n    mask_2[mask_2 < 20] = 0\n    mask_2[mask_2 > 0] = 255\n    \n    image_3 = cv2.bitwise_or(image_3, image_3, mask=mask_1)\n    image_3 = cv2.bitwise_or(image_3, image_3, mask=mask_2) \n    \n    # convert to grayscale to be accepted by skimage.feature.blob_log\n    image_3 = cv2.cvtColor(image_3, cv2.COLOR_BGR2GRAY)\n    \n    # detect blobs\n    blobs = skimage.feature.blob_log(image_3, min_sigma=3, max_sigma=4, num_sigma=1, threshold=0.02)\n    \n    return blobs"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"adeae652-7b2c-1129-3a2d-4d522bd6616a"},"outputs":[],"source":"# classes = [\"adult_males\", \"subadult_males\", \"pups\", \"juveniles\", \"adult_females\"]\n\ndef get_species(r,g,b):    \n    if r > 200 and g < 50 and b < 50: # RED\n        return 0        \n    elif r > 200 and g > 200 and b < 50: # MAGENTA\n        return 1         \n    elif r < 100 and g < 100 and 150 < b < 200: # GREEN\n        return 2\n    elif r < 100 and  100 < g and b < 100: # BLUE\n        return 3\n    elif r < 150 and g < 50 and b < 100:  # BROWN\n        return 4"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4384ea34-1a59-35c4-8b89-18053029c183"},"outputs":[],"source":"def get_xy_range_basic(x, y, x_max, y_max, size):\n    ### x_left, x_right, y_up, y_down\n    x_left  = min(size, x)\n    x_right = min(size, x_max-x-1)\n    y_up    = min(size, y)\n    y_down  = min(size, y_max-y-1)\n    return (x_left, x_right, y_up, y_down)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"70d94ac7-5b85-8a97-e9a3-086aece172fb"},"outputs":[],"source":"def get_dict_range_basic(filename, blobs):\n    Dict_range = {}\n    ori_image = cv2.imread(Path_Train + filename)\n    \n    for blob in blobs:\n        # get the coordinates for each blob\n        y, x, s = blob\n        \n        # get basic xy_range\n        xy_range = get_xy_range_basic(x=x, y=y, x_max=ori_image.shape[1], y_max=ori_image.shape[0], size=int(arg[1])/2)\n        \n        # save range info    \n        Dict_range[(x,y)] = xy_range\n        \n    return Dict_range"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c5cec56e-53a8-55dc-5cef-da8ba004ce9e"},"outputs":[],"source":"def get_dict_range_advance(filename, blobs):\n    level = 40\n    Dict_range = {}\n    ori_image = cv2.imread(Path_Train + filename)\n    dot_image = cv2.imread(Path_Dotted + filename)\n    s_size = int(arg[1])/8\n    \n    for blob in blobs:\n        # get the coordinates for each blob\n        y, x, s = blob\n        \n        # get species\n        g,b,r = dot_image[int(y)][int(x)][:]\n        species = get_species(r,g,b)\n         \n        # get basic xy_range\n        xy_range = get_xy_range_basic(x=x, y=y, x_max=ori_image.shape[1], y_max=ori_image.shape[0], size=int(arg[1])/2)\n        x_left  = xy_range[0] \n        x_right = xy_range[1]\n        y_up    = xy_range[2]\n        y_down  = xy_range[3]\n        \n        # augment xy_range\n        if(species != 2):\n            mid_im = ori_image[int(y-s_size):int(y+s_size), int(x-s_size):int(x+s_size), :]\n            mid_abs = np.linalg.norm(np.mean(mid_im, axis=(0,1)))\n            \n            # augment left side\n            while(True):\n                # get three sub_sub_image on left\n                left_mid_im  = ori_image[  int(y-s_size):int(y+s_size), int(x-x_left):int(x-x_left+2*s_size), :]\n                left_up_im   = ori_image[int(y-3*s_size):int(y-s_size), int(x-x_left):int(x-x_left+2*s_size), :]\n                left_down_im = ori_image[int(y+s_size):int(y+3*s_size), int(x-x_left):int(x-x_left+2*s_size), :]\n                \n                # calculate distance\n                left_mid_abs  = np.linalg.norm(np.mean(  left_mid_im, axis=(0,1)))\n                left_up_abs   = np.linalg.norm(np.mean(   left_up_im, axis=(0,1)))\n                left_down_abs = np.linalg.norm(np.mean( left_down_im, axis=(0,1)))\n                \n                # augment if proper\n                if(abs(mid_abs-left_mid_abs) < level or abs(mid_abs-left_up_abs) < level or abs(mid_abs-left_down_abs) < level):  \n                    x_left = min(x_left+s_size, x)\n                    if(x_left == x):\n                        break\n                    print(\"Augment x_left {0},{1}\".format(x,y))\n                else:\n                    break\n\n            # augment right side\n            while(True):\n                # get three sub_sub_image on right\n                right_mid_im  = ori_image[  int(y-s_size):int(y+s_size), int(x+x_right-2*s_size):int(x+x_right), :]\n                right_up_im   = ori_image[int(y-3*s_size):int(y-s_size), int(x+x_right-2*s_size):int(x+x_right), :]\n                right_down_im = ori_image[int(y+s_size):int(y+3*s_size), int(x+x_right-2*s_size):int(x+x_right), :]\n                \n                # calculate distance\n                right_mid_abs  = np.linalg.norm(np.mean(  right_mid_im, axis=(0,1)))\n                right_up_abs   = np.linalg.norm(np.mean(   right_up_im, axis=(0,1)))\n                right_down_abs = np.linalg.norm(np.mean( right_down_im, axis=(0,1)))\n                \n                # augment if proper\n                if(abs(mid_abs-right_mid_abs) < level or abs(mid_abs-right_up_abs) < level or abs(mid_abs-right_down_abs) < level):\n                    x_right = min(x_right+s_size, ori_image.shape[1]-x)\n                    if(x_right == ori_image.shape[1]-x):\n                        break\n                    print(\"Augment x_right {0},{1}\".format(x,y))\n                else:\n                    break\n            \n            # augment up side\n            while(True):\n                # get three sub_sub_image on up\n                up_mid_im   = ori_image[int(y-y_up):int(y-y_up+2*s_size),   int(x-s_size):int(x+s_size), :]\n                up_left_im  = ori_image[int(y-y_up):int(y-y_up+2*s_size), int(x-3*s_size):int(x-s_size), :]\n                up_right_im = ori_image[int(y-y_up):int(y-y_up+2*s_size), int(x+s_size):int(x+3*s_size), :]\n                \n                # calculate distance\n                up_mid_abs   = np.linalg.norm(np.mean(   up_mid_im, axis=(0,1)))\n                up_left_abs  = np.linalg.norm(np.mean(  up_left_im, axis=(0,1)))\n                up_right_abs = np.linalg.norm(np.mean( up_right_im, axis=(0,1)))\n            \n                # augment if proper\n                if(abs(mid_abs-up_mid_abs) < level or abs(mid_abs-up_left_abs) < level or abs(mid_abs-up_right_abs) < level):\n                    y_up = min(y_up+s_size, y)\n                    if(y_up == y):\n                        break\n                    print(\"Augment y_up {0},{1}\".format(x,y))\n                else:\n                    break\n            \n            # augment down side\n            while(True):\n                # get three sub_sub_image on down\n                down_mid_im   = ori_image[int(y+y_down-2*s_size):int(y+y_down),   int(x-s_size):int(x+s_size), :]\n                down_left_im  = ori_image[int(y+y_down-2*s_size):int(y+y_down), int(x-3*s_size):int(x-s_size), :]\n                down_right_im = ori_image[int(y+y_down-2*s_size):int(y+y_down), int(x+s_size):int(x+3*s_size), :]\n                \n                # calculate distance\n                down_mid_abs   = np.linalg.norm(np.mean(   down_mid_im, axis=(0,1)))\n                down_left_abs  = np.linalg.norm(np.mean(  down_left_im, axis=(0,1)))\n                down_right_abs = np.linalg.norm(np.mean( down_right_im, axis=(0,1)))\n                \n                # augment if proper\n                if(abs(mid_abs-down_mid_abs) < level or abs(mid_abs-down_left_abs) < level or abs(mid_abs-down_right_abs) < level):\n                    y_down = min(y_down+s_size, ori_image.shape[0]-y)\n                    if(y_down == ori_image.shape[0]-y):\n                        break\n                    print(\"Augment y_down {0},{1}\".format(x,y))\n                else:\n                    break\n                    \n        # save range info    \n        Dict_range[(x,y)] = (x_left, x_right, y_up, y_down)\n    \n    return Dict_range"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"58bdd509-ffdb-ef05-a396-2490994a5bc0"},"outputs":[],"source":"def parse_image_black(filename):\n    ## open sub_image_names file\n    sub_image_names = open(Path_Sealion + \"Train.txt\", 'a')\n    \n    ### get original image\n    ori_image = cv2.imread(Path_Dotted + filename)\n    dot_image = cv2.imread(Path_Dotted + filename)\n    cnt = 0\n    \n    ### get coordinate of all sea lions\n    Dict_range = {}\n    blobs = get_blobs(filename)\n    \n    ### get xy_range info for all sea_lion\n    if(arg[0] == 'Basic'):\n        Dict_range = get_dict_range_basic(filename, blobs)\n    elif(arg[0] == 'Advance'):\n        Dict_range = get_dict_range_advance(filename, blobs)\n    \n    ### output sub_image and annotation file for each blob\n    Delete_Key_List = []\n    for key in list(Dict_range.keys()):       \n        if(key in Dict_range):\n            # add cnt for new sub_image name\n            cnt += 1\n            \n            # get x, y, xy_range in original image\n            main_x = int(key[0])\n            main_y = int(key[1])\n            xy_range = Dict_range[key]\n            \n            ### get basic sub_image\n            sub_image = cv2.imread('sub_im_template.jpg')            \n            sub_x_center = int(sub_image.shape[1]/2)\n            sub_y_center = int(sub_image.shape[0]/2)\n            sub_image[int(sub_y_center-xy_range[2]):int(sub_y_center+xy_range[3]), int(sub_x_center-xy_range[0]):int(sub_x_center+xy_range[1]), :] = ori_image[int(main_y-xy_range[2]):int(main_y+xy_range[3]), int(main_x-xy_range[0]):int(main_x+xy_range[1]), :]\n            del Dict_range[key]\n                    \n            ### get species\n            g,b,r = dot_image[int(main_y)][int(main_x)][:]\n            species = get_species(r,g,b)\n            \n            # get pos info for annotation file\n            x_pos = float(sub_x_center)/float(Sub_Im_Size[0])\n            y_pos = float(sub_y_center)/float(Sub_Im_Size[0])\n            x_len = float(xy_range[0]+xy_range[1])/float(Sub_Im_Size[0])\n            y_len = float(xy_range[2]+xy_range[3])/float(Sub_Im_Size[0])\n            element = [x_pos, y_pos, x_len, y_len]\n            \n            # save species info in annotation file\n            ant_file = open(Path_Sealion + 'labels/{0}_{1}.txt'.format(filename[:-4], cnt), 'w')\n            ant_file.write(str(species) + \" \" + \" \".join([str(x) for x in element]) + '\\n')\n            \n            \n            ### include other sea lion\n            # max min coordinate for including image based on origin image\n            x_min = max(main_x - sub_image.shape[1]/2 + 1, 0)\n            x_max = min(main_x + sub_image.shape[1]/2 - 1, ori_image.shape[1])\n            y_min = max(main_y - sub_image.shape[0]/2 + 1, 0)\n            y_max = min(main_y + sub_image.shape[0]/2 - 1, ori_image.shape[0])\n            \n            for ex_key in list(Dict_range.keys()):\n                if(ex_key[0] > x_min and ex_key[0] < x_max and ex_key[1] > y_min and ex_key[1] < y_max):\n                    ### coordinate of ex_sea_lion in origin image\n                    ex_range = Dict_range[ex_key]\n                    ex_left  = int(ex_key[0] - ex_range[0])\n                    ex_right = int(ex_key[0] + ex_range[1])\n                    ex_up    = int(ex_key[1] - ex_range[2])\n                    ex_down  = int(ex_key[1] + ex_range[3])\n                    if(ex_left > x_min and ex_right < x_max and ex_up > y_min and ex_down < y_max):\n                        ### sub_image's coordinate where ex_sea_lion put  \n                        in_up    = int(sub_y_center - main_y + ex_key[1] - ex_range[2])\n                        in_down  = int(sub_y_center - main_y + ex_key[1] + ex_range[3])\n                        in_left  = int(sub_x_center - main_x + ex_key[0] - ex_range[0])\n                        in_right = int(sub_x_center - main_x + ex_key[0] + ex_range[1])\n                        sub_image[ in_up:in_down, in_left:in_right, :] = ori_image[ex_up:ex_down, ex_left:ex_right, :]\n                        del Dict_range[ex_key]\n                        \n                        ### get species for include sea_lion\n                        g,b,r = dot_image[int(ex_key[1])][int(ex_key[0])][:]\n                        species = get_species(r,g,b)\n            \n                        # get pos info for annotation file\n                        x_pos = float(sub_x_center - main_x + ex_key[0])/float(Sub_Im_Size[0])\n                        y_pos = float(sub_y_center - main_y + ex_key[1])/float(Sub_Im_Size[0])\n                        x_len = float(ex_range[0]+ex_range[1])/float(Sub_Im_Size[0])\n                        y_len = float(ex_range[2]+ex_range[3])/float(Sub_Im_Size[0])\n                        element = [x_pos, y_pos, x_len, y_len]\n            \n                        # save species info in annotation file\n                        ant_file.write(str(species) + \" \" + \" \".join([str(x) for x in element]) + '\\n')                          \n            \n            cv2.imwrite(Path_Sealion + 'JPEGImages/{0}_{1}.jpg'.format(filename[:-4], cnt),sub_image)\n            #cv2.imwrite('{0}_{1}.png'.format(filename[:-4], cnt),sub_image)\n            sub_image_names.write(Path_Sealion + 'JPEGImages/{0}_{1}.jpg'.format(filename[:-4], cnt))\n            sub_image_names.write(\"\\n\")\n            ant_file.close()\n    sub_image_names.close()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a26f8ff8-53ff-1d9e-4e0b-df0fdae613ad"},"outputs":[],"source":"def parse_image_whole(filename):\n    ## open sub_image_names file\n    sub_image_names = open(Path_Sealion + \"Train.txt\", 'a')\n    \n    ### get original image\n    ori_image = cv2.imread(Path_Train + filename)\n    dot_image = cv2.imread(Path_Dotted + filename)\n    cnt = 0\n    \n    ### get coordinate of all sea lions\n    blobs = get_blobs(filename)\n    \n    ### get xy_range info for all sea_lion\n    if(arg[0] == 'Basic'):\n        Dict_range = get_dict_range_basic(filename, blobs)\n    elif(arg[0] == 'Advance'):\n        Dict_range = get_dict_range_advance(filename, blobs)\n    \n    ### output sub_image and annotation file for each blob\n    Used_Key_Set = set()\n    for key in Dict_range.keys():       \n        if(key not in Used_Key_Set):\n            # add cnt for new sub_image name\n            cnt += 1\n            \n            # get x, y, xy_range in original image\n            main_x = int(key[0])\n            main_y = int(key[1])\n            xy_range = Dict_range[key]\n            \n            # adjust main_x main_y if sea_lion close to boundary\n            if(main_x - Sub_Im_Size[0]/2 < 0):\n                main_x = Sub_Im_Size[0]/2\n            if(main_x + Sub_Im_Size[0]/2 > ori_image.shape[1]):\n                main_x = ori_image.shape[1] - Sub_Im_Size[0]/2\n            if(main_y - Sub_Im_Size[1]/2 < 0):\n                main_y = Sub_Im_Size[1]/2\n            if(main_y + Sub_Im_Size[1]/2 > ori_image.shape[0]):\n                main_y = ori_image.shape[0] - Sub_Im_Size[1]/2\n            \n            # get_sub_image\n            sub_image = ori_image[int(main_y - Sub_Im_Size[1]/2) : int(main_y + Sub_Im_Size[1]/2), int(main_x - Sub_Im_Size[0]/2) : int(main_x + Sub_Im_Size[0]/2), :]\n            \n            # record key as used_key\n            Used_Key_Set.add(key)\n            \n            ### get species\n            g,b,r = dot_image[int(key[1])][int(key[0])][:]\n            species = get_species(r,g,b)\n\n            # get pos info for annotation file\n            x_pos = float(key[0]-(main_x-Sub_Im_Size[0]/2))/float(Sub_Im_Size[0])\n            y_pos = float(key[1]-(main_y-Sub_Im_Size[1]/2))/float(Sub_Im_Size[1])\n            x_len = float(xy_range[0]+xy_range[1])/float(Sub_Im_Size[0])\n            y_len = float(xy_range[2]+xy_range[3])/float(Sub_Im_Size[1])\n            element = [x_pos, y_pos, x_len, y_len]\n            \n            # save species info in annotation file\n            ant_file = open(Path_Sealion + 'labels/{0}_{1}.txt'.format(filename[:-4], cnt), 'w')\n            ant_file.write(str(species) + \" \" + \" \".join([str(x) for x in element]) + '\\n')\n            \n            \n            ### include other sea lion\n            # max min coordinate for including image based on origin image\n            x_min = max(main_x - sub_image.shape[1]/2 + 1, 0)\n            x_max = min(main_x + sub_image.shape[1]/2 - 1, ori_image.shape[1])\n            y_min = max(main_y - sub_image.shape[0]/2 + 1, 0)\n            y_max = min(main_y + sub_image.shape[0]/2 - 1, ori_image.shape[0])\n            \n            for ex_key in Dict_range.keys():\n                if(ex_key != key and ex_key[0] > x_min and ex_key[0] < x_max and ex_key[1] > y_min and ex_key[1] < y_max):\n                    ### coordinate of ex_sea_lion in origin image\n                    ex_range = Dict_range[ex_key]\n                    ex_left  = int(ex_key[0] - ex_range[0])\n                    ex_right = int(ex_key[0] + ex_range[1])\n                    ex_up    = int(ex_key[1] - ex_range[2])\n                    ex_down  = int(ex_key[1] + ex_range[3])\n                    \n                    ### sub_image's coordinate where ex_sea_lion put  \n                    Used_Key_Set.add(ex_key)\n\n                    ### get species for include sea_lion\n                    g,b,r = dot_image[int(ex_key[1])][int(ex_key[0])][:]\n                    species = get_species(r,g,b)\n            \n                    # get pos info for annotation file\n                    x_pos = float(ex_key[0]-(main_x-Sub_Im_Size[0]/2))/float(Sub_Im_Size[0])\n                    y_pos = float(ex_key[1]-(main_y-Sub_Im_Size[1]/2))/float(Sub_Im_Size[1])\n                    \n                    # adjust real size of include sea_lion due to be close to boarder\n                    ex_left_size  = min(ex_range[0], ex_key[0]-(main_x-Sub_Im_Size[0]/2))\n                    ex_right_size = min(ex_range[1], (main_x+Sub_Im_Size[0]/2)-ex_key[0])\n                    ex_up_size    = min(ex_range[2], ex_key[1]-(main_y-Sub_Im_Size[1]/2))\n                    ex_down_size  = min(ex_range[3], (main_y+Sub_Im_Size[1]/2)-ex_key[1])\n                    \n                    x_len = float(ex_left_size+ex_right_size)/float(Sub_Im_Size[0])\n                    y_len = float(ex_up_size+ex_down_size)/float(Sub_Im_Size[1])\n                    element = [x_pos, y_pos, x_len, y_len]\n            \n                    # save species info in annotation file\n                    ant_file.write(str(species) + \" \" + \" \".join([str(x) for x in element]) + '\\n')                          \n            \n            cv2.imwrite(Path_Sealion + 'JPEGImages/{0}_{1}.jpg'.format(filename[:-4], cnt), sub_image)\n            #cv2.imwrite('{0}_{1}.png'.format(filename[:-4], cnt),sub_image)\n            sub_image_names.write(Path_Sealion + 'JPEGImages/{0}_{1}.jpg'.format(filename[:-4], cnt))\n            sub_image_names.write(\"\\n\")\n            ant_file.close()\n    sub_image_names.close()"},{"cell_type":"markdown","metadata":{"_cell_guid":"45636c54-41bd-865b-906b-f1fc40bf18fa"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cab6b1ed-e39b-6dcf-5f83-bee0ac80f720"},"outputs":[],"source":"### remove Train.txt if exist\nif os.path.exists(Path_Sealion + \"Train.txt\"):\n    os.remove(Path_Sealion + \"Train.txt\")\n\nfor filename in file_names:\n    if filename[-3:] == 'jpg':\n        parse_image_black(filename)\n        \n        \"\"\"\n        if(arg[2] == 'Black'):\n            parse_image_black(filename)\n        elif(arg[2] == 'Whole'):\n            parse_image_whole(filename)\n        else:\n            print(\"Wrong in argument\")\n        \"\"\""},{"cell_type":"markdown","metadata":{"_cell_guid":"917bbfc5-0c4f-5841-061e-46cb0606b558"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8c41fa4b-621a-8352-92bd-edc6d9f12a31","collapsed":true},"outputs":[],"source":""},{"cell_type":"markdown","metadata":{"_cell_guid":"a2da0704-7327-dd60-8369-53a42265fa14"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a512918b-aa00-70bc-50d6-e7dd30332f96","collapsed":true},"outputs":[],"source":""},{"cell_type":"markdown","metadata":{"_cell_guid":"66bc69f1-0aff-cf49-a9d4-a1955d6bbe17"},"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}