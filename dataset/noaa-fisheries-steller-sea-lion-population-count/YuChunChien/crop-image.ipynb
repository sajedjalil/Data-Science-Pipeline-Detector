{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"ad4c0146-f261-25de-be01-5d0451f7d5f9"},"source":"# Define environment"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d9b20c33-9c6e-ebcd-e1e1-79f733b87a30"},"outputs":[],"source":"SYSTEM = \"Kaggle\" # \"Paperspace\" # "},{"cell_type":"markdown","metadata":{"_cell_guid":"5939a853-75be-149b-6f85-90179d7c9fa1"},"source":"# import module"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"74f7c7f1-0171-02c9-5ab6-98910c086728"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt"},{"cell_type":"markdown","metadata":{"_cell_guid":"b7b0fbbe-e273-dc8f-d936-017807950a86"},"source":"# Get Argument"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"de076964-e894-3951-4bbd-fb1918549fd8"},"outputs":[],"source":"if SYSTEM == \"Kaggle\":\n    Image_Path = \"../input/Train/\"\n    Crop_Path  = \"./TestLargeCrop/JPEGImages/\"\nelse:\n    Image_Path = \"/home/paperspace/Project/Sealion/TestLargeRaw/\"\n    Crop_Path  = \"/home/paperspace/Project/Sealion/TestLargeCrop/JPEGImages/\""},{"cell_type":"markdown","metadata":{"_cell_guid":"662e1b3e-ccd6-8bad-2422-f802b1346952"},"source":"# Define Cropped Image Size"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c8d39244-a119-c6f7-8e92-073bf9d67a0b"},"outputs":[],"source":"Crop_Size = (416,416)"},{"cell_type":"markdown","metadata":{"_cell_guid":"e3ed975a-9912-b47f-fe96-eb941a87027d"},"source":"# Get Original Images"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ee4578fa-0235-5176-71a2-0f0d34469f10"},"outputs":[],"source":"file_names = os.listdir(Image_Path)\nfile_names = sorted(file_names, key=lambda \n                    item: (int(item.partition('.')[0]) if item[0].isdigit() else float('inf'), item))\nfile_names = file_names[:1]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7340496c-6104-7422-f1bb-9b4815fa4a8c"},"outputs":[],"source":"print(file_names)"},{"cell_type":"markdown","metadata":{"_cell_guid":"cce802f6-843c-e4b6-dab6-cc590ed68774"},"source":"# Crop Images"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"761aeefb-90ac-321f-e55e-2eb4d5d7e681"},"outputs":[],"source":"def ceil_devide(Big, Small):\n    result = int(Big/Small)\n    if(Big%Small != 0):\n        result += 1\n    return result"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"704b2217-66b4-a2d3-771d-811099cd63b5"},"outputs":[],"source":"def create_crop_template(filename):\n    ### remove existing template\n    if os.path.exists(Image_Path + 'crop_template.jpg'):\n        os.remove(Image_Path + 'crop_template.jpg')\n        \n    image = cv2.imread(Image_Path + filename)\n    image = image[:Crop_Size[1],:Crop_Size[0],:]\n    image = cv2.absdiff(image,image)\n\n    cv2.imwrite(Image_Path + 'crop_template.jpg',image)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"308d4ade-4a43-bb51-9402-b1200f0f8fb0"},"outputs":[],"source":"def delete_crop_template():\n    os.remove(Image_Path + 'crop_template.jpg')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"71b6cbbe-456e-35ff-940b-92801a20dc01"},"outputs":[],"source":"def create_crop_file():\n    if(SYSTEM == \"Kaggle\"):\n        if not os.path.exists(\"./TestLargeCrop/\"):\n            os.makedirs(\"./TestLargeCrop/\")\n        if not os.path.exists(\"./TestLargeCrop/JPEGImages/\"):\n            os.makedirs(\"./TestLargeCrop/JPEGImages/\")        \n    else:\n        if not os.path.exists(\"/home/paperspace/Project/Sealion/TestLargeCrop/\"):\n            os.makedirs(\"/home/paperspace/Project/Sealion/TestLargeCrop/\")\n        if not os.path.exists(\"/home/paperspace/Project/Sealion/TestLargeCrop/JPEGImages/\"):\n            os.makedirs(\"/home/paperspace/Project/Sealion/TestLargeCrop/JPEGImages/\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"af4e236f-56bc-ce6f-702d-af8b362d8759"},"outputs":[],"source":"create_crop_template(file_names[0])\ncreate_crop_file()\n\nfor filename in file_names:\n    ### skip if file is not image\n    if(filename[-3:] != 'jpg'):\n        continue\n        \n    ### read origin image\n    ori_image = cv2.imread(Image_Path + filename)\n    Shape = ori_image.shape\n    X_Len = Shape[1]\n    Y_Len = Shape[0]\n    \n    X_Amt = ceil_devide(X_Len, Crop_Size[0])\n    Y_Amt = ceil_devide(Y_Len, Crop_Size[1])\n    \n    cnt = 0\n    for j in range(Y_Amt):\n        for i in range(X_Amt):\n            # counting\n            cnt += 1\n            \n            # create crop image\n            crop_image = cv2.imread(Image_Path + 'crop_template.jpg')\n            crop_image = ori_image[j*Crop_Size[1]:(j+1)*Crop_Size[1], i*Crop_Size[0]:(i+1)*Crop_Size[0], :]\n            \n            # save crop image\n            Name = Crop_Path + filename.split('.')[0] + '_' + str(cnt) + '.jpg'\n            cv2.imwrite(Name, crop_image) \n    \ndelete_crop_template()"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}