{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"04d8ac0f-e429-3675-d0ee-e5915e9c0fea"},"source":"# Import Library"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"22d2997b-b24f-d2b2-2d19-a79bdfc71ec9"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport skimage.feature\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer\n%matplotlib inline\n\n#from subprocess import check_output\n#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"},{"cell_type":"markdown","metadata":{"_cell_guid":"ede9db49-9980-1d57-1b1c-aa32936509cb"},"source":"# File Extract & Sort"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c62086dd-32e4-5919-34ac-63dd40caac44"},"outputs":[],"source":"file_names = os.listdir(\"../input/Train/\")\nfile_names = sorted(file_names, key=lambda \n                    item: (int(item.partition('.')[0]) if item[0].isdigit() else float('inf'), item))\n\n# select a subset of files to run on\nfile_names = file_names[0:1]"},{"cell_type":"markdown","metadata":{"_cell_guid":"73e38688-f743-d5e0-6c7f-eb0a87a50993"},"source":"#  Extract Coordinate of Dotted SeaLion"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c33faf2b-b5df-5f38-00ab-ddffee3eeaa7"},"outputs":[],"source":"# dataframe to store coordinate results in\nclasses = [\"adult_males\", \"subadult_males\", \"adult_females\", \"juveniles\", \"pups\"]\ncoordinates_df = pd.DataFrame(index=file_names, columns=classes)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"01e9decf-d8e7-5cc0-7131-4ac152a756ca"},"outputs":[],"source":"def get_coordinate(filename):\n    \n    # read the Train and Train Dotted images\n    image_1 = cv2.imread(\"../input/TrainDotted/\" + filename)\n    image_2 = cv2.imread(\"../input/Train/\" + filename)\n    \n    # absolute difference between Train and Train Dotted\n    image_3 = cv2.absdiff(image_1,image_2)\n    \n    # mask out blackened regions from Train Dotted\n    mask_1 = cv2.cvtColor(image_1, cv2.COLOR_BGR2GRAY)\n    mask_1[mask_1 < 20] = 0\n    mask_1[mask_1 > 0] = 255\n    \n    mask_2 = cv2.cvtColor(image_2, cv2.COLOR_BGR2GRAY)\n    mask_2[mask_2 < 20] = 0\n    mask_2[mask_2 > 0] = 255\n    \n    image_3 = cv2.bitwise_or(image_3, image_3, mask=mask_1)\n    image_3 = cv2.bitwise_or(image_3, image_3, mask=mask_2) \n    \n    # convert to grayscale to be accepted by skimage.feature.blob_log\n    image_3 = cv2.cvtColor(image_3, cv2.COLOR_BGR2GRAY)\n    \n    # detect blobs\n    blobs = skimage.feature.blob_log(image_3, min_sigma=3, max_sigma=4, num_sigma=1, threshold=0.02)\n    \n    adult_males = []\n    subadult_males = []\n    pups = []\n    juveniles = []\n    adult_females = [] \n    \n    for blob in blobs:\n        # get the coordinates for each blob\n        y, x, s = blob\n        # get the color of the pixel from Train Dotted in the center of the blob\n        g,b,r = image_1[int(y)][int(x)][:]\n        \n        # decision tree to pick the class of the blob by looking at the color in Train Dotted\n        if r > 200 and g < 50 and b < 50: # RED\n            adult_males.append((int(x),int(y)))        \n        elif r > 200 and g > 200 and b < 50: # MAGENTA\n            subadult_males.append((int(x),int(y)))         \n        elif r < 100 and g < 100 and 150 < b < 200: # GREEN\n            pups.append((int(x),int(y)))\n        elif r < 100 and  100 < g and b < 100: # BLUE\n            juveniles.append((int(x),int(y))) \n        elif r < 150 and g < 50 and b < 100:  # BROWN\n            adult_females.append((int(x),int(y)))\n            \n    coordinates_df[\"adult_males\"][filename] = adult_males\n    coordinates_df[\"subadult_males\"][filename] = subadult_males\n    coordinates_df[\"adult_females\"][filename] = adult_females\n    coordinates_df[\"juveniles\"][filename] = juveniles\n    coordinates_df[\"pups\"][filename] = pups\n    \n    return coordinates_df"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c57e7a2d-9a72-c4fe-db70-54f390af5787"},"outputs":[],"source":"def get_blobs(filename):\n    # read the Train and Train Dotted images\n    image_1 = cv2.imread(\"../input/TrainDotted/\" + filename)\n    image_2 = cv2.imread(\"../input/Train/\" + filename)\n    \n    # absolute difference between Train and Train Dotted\n    image_3 = cv2.absdiff(image_1,image_2)\n    \n    # mask out blackened regions from Train Dotted\n    mask_1 = cv2.cvtColor(image_1, cv2.COLOR_BGR2GRAY)\n    mask_1[mask_1 < 20] = 0\n    mask_1[mask_1 > 0] = 255\n    \n    mask_2 = cv2.cvtColor(image_2, cv2.COLOR_BGR2GRAY)\n    mask_2[mask_2 < 20] = 0\n    mask_2[mask_2 > 0] = 255\n    \n    image_3 = cv2.bitwise_or(image_3, image_3, mask=mask_1)\n    image_3 = cv2.bitwise_or(image_3, image_3, mask=mask_2) \n    \n    # convert to grayscale to be accepted by skimage.feature.blob_log\n    image_3 = cv2.cvtColor(image_3, cv2.COLOR_BGR2GRAY)\n    \n    # detect blobs\n    blobs = skimage.feature.blob_log(image_3, min_sigma=3, max_sigma=4, num_sigma=1, threshold=0.02)\n    \n    return blobs"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"46beb729-1967-b63f-4638-215e0ed96b66"},"outputs":[],"source":"def get_xy_range_basic(size):\n    ### return (x_left, x_right, y_up, y_down)\n    return (size,size,size,size) "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d08a6bf8-edd1-0532-0e20-0a1cb455e56f"},"outputs":[],"source":"def parse_image(filename):\n    ### get coordinate of all sea lions\n    Dict_range = {}\n    blobs = get_blobs(filename)\n    \n    for blob in blobs:\n        # get the coordinates for each blob\n        y, x, s = blob\n        \n        xy_range = get_xy_range_basic(size=16)\n        Dict_range[(x,y)] = xy_range\n    \n    ### output sub_image and annotation file for each blob\n    for key in Dict_range.keys():\n        if(key in Dict_range):\n            main_x = key[0]\n            main_y = key[1]\n            xy_range = Dict_range[key]\n            x_min = main_x - xy_range[0]\n            x_max = main_x + xy_range[1]\n            y_min = main_y - xy_range[2]\n            y_max = main_y + xy_range[3]\n            \n            ### get basic sub_image\n            \n            \n            if()\n        \n        "},{"cell_type":"markdown","metadata":{"_cell_guid":"82df1e28-2ebd-d3ea-e7ba-d70a33ea2e96"},"source":"# Display Extracted Fixed Size Square Image "},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e3299f44-9672-3d8c-c9b2-925e879abb8d"},"outputs":[],"source":"#HALF_SQUARE_SIZE = 16\nx = []\ny = []\n\nfor filename in file_names:\n    coordinates_df = get_coordinate(filename)\n    image = cv2.imread(\"../input/Train/\" + filename)\n    for lion_class in classes:\n        for coordinates in coordinates_df[lion_class][filename]:\n            thumb = image[coordinates[1]-16:coordinates[1]+16,coordinates[0]-16:coordinates[0]+16,:]\n            if np.shape(thumb) == (32, 32, 3):\n                x.append(thumb)\n                y.append(lion_class)\nx = np.array(x)\ny = np.array(y)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5d3c9fff-24e6-7fde-85e0-898a42f39fed"},"outputs":[],"source":"for lion_class in classes:\n    f, ax = plt.subplots(1,10,figsize=(12,1.5))\n    f.suptitle(lion_class)\n    axes = ax.flatten()\n    j = 0\n    for a in axes:\n        a.set_xticks([])\n        a.set_yticks([])\n        for i in range(j,len(x)):\n            if y[i] == lion_class:\n                j = i+1\n                a.imshow(cv2.cvtColor(x[i], cv2.COLOR_BGR2RGB))\n                break"},{"cell_type":"markdown","metadata":{"_cell_guid":"d7e6b699-e432-4647-21fb-55224fa25728"},"source":"Thanks to Radu Stoicescu's kernel - \"Use keras to classify Sea Lions: 0.91 accuracy\"\nhttps://www.kaggle.com/radustoicescu/noaa-fisheries-steller-sea-lion-population-count/use-keras-to-classify-sea-lions-0-91-accuracy"},{"cell_type":"markdown","metadata":{"_cell_guid":"8a16ee5d-3284-5aed-3495-ffb43eaf7222"},"source":"# Output annotation file"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6b574c94-9306-02d5-a5d1-eafb2f72cb3b"},"outputs":[],"source":"# class_id  x_pos/image_x_width  y_pos/image_y_height  x_len/image_x_width  y_len/image_y_height\ndef output_annotation(filename):\n    coordinates_df = get_coordinate(filename)\n    print(coordinates_df)\n    txt_outfile = open(\"{0}_anno.txt\".format(filename), \"w\")  #./annotations/\n    \n    image = cv2.imread(\"../input/Train/\" + filename)\n    image_W = float(image.shape[1])\n    image_H = float(image.shape[0])    \n    \n    for idx in range(len(classes)):\n        for coordinates in coordinates_df[classes[idx]][filename]:\n            Width = 32   # int\n            Height = 32  # int\n            \n            x_pos = float(coordinates[0])/image_W\n            y_pos = float(coordinates[1])/image_H\n            x_len = float(Width)/image_W\n            y_len = float(Height)/image_H\n            element = [x_pos, y_pos, x_len, y_len]\n                       \n            txt_outfile.write(str(idx) + \" \" + \" \".join([str(x) for x in element]) + '\\n')\n     \n    txt_outfile.close()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8918aa32-dac2-99d2-f787-f3cc08f0ff36"},"outputs":[],"source":"output_annotation(file_names[0])"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"45a35bf3-a5e1-81db-9072-51751bf470ba"},"outputs":[],"source":"image = cv2.imread(\"../input/Train/\" + file_names[0])\nimage.shape"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c18d1863-5a34-887c-748d-2b357b9cf1e6"},"outputs":[],"source":"plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"301f9a32-d4b4-a973-8fd1-55f8430a16a2"},"outputs":[],"source":"File = open(\"{0}_anno.txt\".format(file_names[0]), \"r\")\nFile.read()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"9ced1bf1-2418-6029-f38f-629dd8c0c5de"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"12b690b1-bd78-b6c9-f990-9f1635e9c52d"},"outputs":[],"source":"file_names"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}