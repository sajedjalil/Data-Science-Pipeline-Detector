{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"25d17686-e4bf-2dc1-f21e-4e80e57bd25e"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b785edd6-0658-2101-e6a7-9c7c0818f9a4"},"outputs":[],"source":"SYSTEM = \"Kaggle\" # \"Paperspace\" # "},{"cell_type":"markdown","metadata":{"_cell_guid":"c6865a83-6bf4-fa63-9c3c-4b1f4a289491"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4aced642-d9c4-33b2-a281-790671c41599"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt"},{"cell_type":"markdown","metadata":{"_cell_guid":"9d080440-4645-4e7c-eae8-608a8e7fe3db"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"afe42213-2583-5806-d071-b3f4e04aad4a"},"outputs":[],"source":"if SYSTEM == \"Kaggle\":\n    Image_Path = \"../input/Train/\"\n    Crop_Path  = \"./TestLargeCrop/JPEGImages/\"\nelse:\n    Image_Path = \"/home/paperspace/Project/Sealion/TestLargeRaw/\"\n    Crop_Path  = \"/home/paperspace/Project/Sealion/TestLargeCrop/JPEGImages/\""},{"cell_type":"markdown","metadata":{"_cell_guid":"72989e0d-7d99-0b6f-517c-e5d6e907ac6d"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"07fa5aa6-e7e6-dde8-829b-2433c491f24b"},"outputs":[],"source":"Crop_Size = (416,416)"},{"cell_type":"markdown","metadata":{"_cell_guid":"76129c2b-6054-ad7c-99ae-d49c3b070025"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e0c072dd-f587-2c90-097c-deabbf338e94"},"outputs":[],"source":"file_names = os.listdir(Image_Path)\nfile_names = sorted(file_names, key=lambda \n                    item: (int(item.partition('.')[0]) if item[0].isdigit() else float('inf'), item))\nfile_names = file_names[:1]"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3ce846ab-cfe8-cf08-e922-2e226ca595f0"},"outputs":[],"source":"print(file_names)"},{"cell_type":"markdown","metadata":{"_cell_guid":"9c006320-7935-ac31-8f4a-c3382413e919"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f7309f06-96f4-7cd9-e5fa-9444594c9875"},"outputs":[],"source":"def ceil_devide(Big, Small):\n    result = int(Big/Small)\n    if(Big%Small != 0):\n        result += 1\n    return result"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"62028c39-54bb-d041-8fb8-edb2c48c1916"},"outputs":[],"source":"def create_crop_template(filename):\n    ### remove existing template\n    if os.path.exists('crop_template.jpg'):\n        os.remove('crop_template.jpg')\n        \n    image = cv2.imread(Image_Path + filename)\n    image = image[:Crop_Size[1],:Crop_Size[0],:]\n    image = cv2.absdiff(image,image)\n\n    cv2.imwrite('crop_template.jpg',image)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d485cf0c-b296-d2b2-d23d-7f9a3e161e61"},"outputs":[],"source":"def delete_crop_template():\n    os.remove('crop_template.jpg')"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"48fe0ee0-1ebb-9d2a-36d9-36d390e5b241"},"outputs":[],"source":"def create_crop_file():\n    if(SYSTEM == \"Kaggle\"):\n        if not os.path.exists(\"./TestLargeCrop/\"):\n            os.makedirs(\"./TestLargeCrop/\")\n        if not os.path.exists(\"./TestLargeCrop/JPEGImages/\"):\n            os.makedirs(\"./TestLargeCrop/JPEGImages/\")        \n    else:\n        if not os.path.exists(\"/home/paperspace/Project/Sealion/TestLargeCrop/\"):\n            os.makedirs(\"/home/paperspace/Project/Sealion/TestLargeCrop/\")\n        if not os.path.exists(\"/home/paperspace/Project/Sealion/TestLargeCrop/JPEGImages/\"):\n            os.makedirs(\"/home/paperspace/Project/Sealion/TestLargeCrop/JPEGImages/\")"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2b661da7-c3c4-184f-90d9-a6d0f261e0f8"},"outputs":[],"source":"create_crop_template(file_names[0])\ncreate_crop_file()\n\nfor filename in file_names:\n    ### skip if file is not image\n    if(filename[-3:] != 'jpg'):\n        continue\n        \n    ### read origin image\n    ori_image = cv2.imread(Image_Path + filename)\n    Shape = ori_image.shape\n    X_Len = Shape[1]\n    Y_Len = Shape[0]\n    \n    X_Amt = ceil_devide(X_Len, Crop_Size[0])\n    Y_Amt = ceil_devide(Y_Len, Crop_Size[1])\n    \n    cnt = 0\n    for j in range(Y_Amt):\n        for i in range(X_Amt):\n            # counting\n            cnt += 1\n            \n            # create crop image\n            crop_image = cv2.imread('crop_template.jpg')\n            tmp_image  = ori_image[j*Crop_Size[1]:(j+1)*Crop_Size[1], i*Crop_Size[0]:(i+1)*Crop_Size[0], :]\n            crop_image[:tmp_image.shape[0], :tmp_image.shape[1], :] = tmp_image\n            \n            # save crop image\n            Name = Crop_Path + filename.split('.')[0] + '_' + str(cnt) + '.jpg'\n            cv2.imwrite(Name, crop_image) \n    \ndelete_crop_template()"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}