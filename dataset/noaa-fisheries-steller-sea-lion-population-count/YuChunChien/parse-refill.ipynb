{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"6d54342a-13b1-ad25-cee1-43e94078d6b3"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"5a38fa1b-ae30-73b5-cca2-e507c2dc02b7"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport skimage.feature\n#%matplotlib inline\n\n#from subprocess import check_output\n#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"},{"cell_type":"markdown","metadata":{"_cell_guid":"71574317-458c-c11a-fd43-f5f4c98c2657"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"50b0df70-3bf8-fd52-6be7-9dfaa64a55c6"},"outputs":[],"source":"import sys\narg = sys.argv[1:]\n\nif('-f' in arg):\n    arg = ['Advance', '32', 'Black', 'Train']\nelse:\n    new_arg = []\n    if('Basic' in arg):\n        idx = arg.index('Basic')\n        new_arg.append('Basic')\n        new_arg.append(arg[idx+1])\n    elif('Advance' in arg):\n        idx = arg.index('Advance')\n        new_arg.append('Advance')\n        new_arg.append(arg[idx+1])\n    else:\n        print(\"Please enter \\\"Basic\\\" or \\\"Advance\\\".\")\n    \n    if('Whole' in arg):\n        new_arg.append('Whole')\n    elif('Black' in arg):\n        new_arg.append('Black')\n    else:\n        print(\"Please enter \\\"Whole\\\" or \\\"Black\\\".\")\n    \n    if('Test' in arg):\n        new_arg.append('Test')\n    elif('Train' in arg):\n        new_arg.append('Train')\n    else:\n        print(\"Please enter \\\"Test\\\" or \\\"Train\\\".\")\n        \n    arg = new_arg"},{"cell_type":"markdown","metadata":{"_cell_guid":"14d71e8a-e34f-f821-cdf5-546f9aa69875"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d2e3a3e3-c80b-57b1-79da-55f86797db83"},"outputs":[],"source":"Path_Type = \"{0}/{1}_{2}_{3}\".format(arg[3], arg[0], arg[1], arg[2])\nPath_Type"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8bd7a311-381b-0276-cae4-f9bd788c0fa8"},"outputs":[],"source":"Path_Sealion = \"./\" # \"/home/paperspace/Project/Sealion/{0}/\".format(Path_Type) # \nPath_Train   = \"../input/Train/\" # \"/home/paperspace/Project/Sealion/TrainSmall2/Train/\"  # \nPath_Dotted  = \"../input/TrainDotted/\" # \"/home/paperspace/Project/Sealion/TrainSmall2/TrainDotted/\"  # \nfile_names = os.listdir(Path_Train)\nfile_names = sorted(file_names, key=lambda \n                    item: (int(item.partition('.')[0]) if item[0].isdigit() else float('inf'), item))\n\nfile_names = file_names[1:2]\nprint(file_names)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"607745eb-f2ab-378d-44d1-11d2a0df291b"},"outputs":[],"source":"\"\"\"\nif not os.path.exists(\"/home/paperspace/Project/Sealion/{0}\".format(Path_Type)):\n    os.makedirs(\"/home/paperspace/Project/Sealion/{0}\".format(Path_Type))\nif not os.path.exists(\"/home/paperspace/Project/Sealion/{0}/labels\".format(Path_Type)):\n    os.makedirs(\"/home/paperspace/Project/Sealion/{0}/labels\".format(Path_Type))\nif not os.path.exists(\"/home/paperspace/Project/Sealion/{0}/JPEGImages\".format(Path_Type)):\n    os.makedirs(\"/home/paperspace/Project/Sealion/{0}/JPEGImages\".format(Path_Type))\n\"\"\""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3bdc3c59-6a8e-e44a-f04d-8dfcf58e1467"},"outputs":[],"source":"\nif not os.path.exists(\"./labels\"):\n    os.makedirs(\"./labels\")\nif not os.path.exists(\"./JPEGImages\"):\n    os.makedirs(\"./JPEGImages\")\n"},{"cell_type":"markdown","metadata":{"_cell_guid":"e883ae1d-94cd-83bd-5a18-9bb2810bfa1d"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"17d6c268-379c-abdf-6229-71e370675ca3"},"outputs":[],"source":"Sub_Im_Size = (416,416)\n\nimage_tmp = cv2.imread(Path_Train + file_names[0])\nimage_tmp = image_tmp[:Sub_Im_Size[1],:Sub_Im_Size[0],:]\nimage_tmp = cv2.absdiff(image_tmp,image_tmp)\n\nplt.imshow(cv2.cvtColor(image_tmp, cv2.COLOR_BGR2RGB))\ncv2.imwrite('sub_im_template.jpg',image_tmp)"},{"cell_type":"markdown","metadata":{"_cell_guid":"c13ce656-30b8-5601-3cfe-acd4dc0d7dde"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"a7b9b7da-9484-f7e6-e8bd-07cea47850fb"},"outputs":[],"source":"def get_blobs(filename):\n    # read the Train and Train Dotted images\n    image_1 = cv2.imread(Path_Dotted + filename)\n    image_2 = cv2.imread(Path_Train + filename)\n    \n    # absolute difference between Train and Train Dotted\n    image_3 = cv2.absdiff(image_1,image_2)\n    \n    # mask out blackened regions from Train Dotted\n    mask_1 = cv2.cvtColor(image_1, cv2.COLOR_BGR2GRAY)\n    mask_1[mask_1 < 20] = 0\n    mask_1[mask_1 > 0] = 255\n    \n    mask_2 = cv2.cvtColor(image_2, cv2.COLOR_BGR2GRAY)\n    mask_2[mask_2 < 20] = 0\n    mask_2[mask_2 > 0] = 255\n    \n    image_3 = cv2.bitwise_or(image_3, image_3, mask=mask_1)\n    image_3 = cv2.bitwise_or(image_3, image_3, mask=mask_2) \n    \n    # convert to grayscale to be accepted by skimage.feature.blob_log\n    image_3 = cv2.cvtColor(image_3, cv2.COLOR_BGR2GRAY)\n    \n    # detect blobs\n    blobs = skimage.feature.blob_log(image_3, min_sigma=3, max_sigma=4, num_sigma=1, threshold=0.02)\n    \n    return blobs"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"32a8777f-4b7b-06ad-624c-a68a9983472b"},"outputs":[],"source":"# classes = [\"adult_males\", \"subadult_males\", \"pups\", \"juveniles\", \"adult_females\"]\n\ndef get_species(r,g,b):    \n    if r > 200 and g < 50 and b < 50: # RED\n        return 0        \n    elif r > 200 and g > 200 and b < 50: # MAGENTA\n        return 1         \n    elif r < 100 and g < 100 and 150 < b < 200: # GREEN\n        return 2\n    elif r < 100 and  100 < g and b < 100: # BLUE\n        return 3\n    elif r < 150 and g < 50 and b < 100:  # BROWN\n        return 4"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f2b4332e-ede0-5e4b-3129-4b7274a8ef51"},"outputs":[],"source":"def get_xy_range_basic(x, y, x_max, y_max, size):\n    ### x_left, x_right, y_up, y_down\n    x_left  = min(size, x)\n    x_right = min(size, x_max-x-1)\n    y_up    = min(size, y)\n    y_down  = min(size, y_max-y-1)\n    return (x_left, x_right, y_up, y_down)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2498d69b-799b-9e83-ba2c-7366f4e69094"},"outputs":[],"source":"def get_dict_range_basic(filename, blobs):\n    Dict_range = {}\n    ori_image = cv2.imread(Path_Train + filename)\n    \n    for blob in blobs:\n        # get the coordinates for each blob\n        y, x, s = blob\n        \n        # get basic xy_range\n        xy_range = get_xy_range_basic(x=x, y=y, x_max=ori_image.shape[1], y_max=ori_image.shape[0], size=int(arg[1])/2)\n        \n        # save range info    \n        Dict_range[(x,y)] = xy_range\n        \n    return Dict_range"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"698772fa-95b0-3f1f-6345-02c286ce9cb8"},"outputs":[],"source":"def get_dict_range_advance(filename, blobs):\n    level = 30\n    Dict_range = {}\n    ori_image = cv2.imread(Path_Train + filename)\n    dot_image = cv2.imread(Path_Dotted + filename)\n    s_size = int(arg[1])/8\n    \n    for blob in blobs:\n        # get the coordinates for each blob\n        y, x, s = blob\n        \n        # get species\n        g,b,r = dot_image[int(y)][int(x)][:]\n        species = get_species(r,g,b)\n         \n        # get basic xy_range\n        xy_range = get_xy_range_basic(x=x, y=y, x_max=ori_image.shape[1], y_max=ori_image.shape[0], size=int(arg[1])/2)\n        x_left  = xy_range[0] \n        x_right = xy_range[1]\n        y_up    = xy_range[2]\n        y_down  = xy_range[3]\n        \n        # augment xy_range\n        if(species != 2):\n            mid_im = ori_image[int(y-s_size):int(y+s_size), int(x-s_size):int(x+s_size), :]\n            mid_abs = np.linalg.norm(np.mean(mid_im, axis=(0,1)))\n            \n            # augment left side\n            while(True):\n                # get three sub_sub_image on left\n                left_mid_im  = ori_image[  int(y-s_size):int(y+s_size), int(x-x_left):int(x-x_left+2*s_size), :]\n                left_up_im   = ori_image[int(y-3*s_size):int(y-s_size), int(x-x_left):int(x-x_left+2*s_size), :]\n                left_down_im = ori_image[int(y+s_size):int(y+3*s_size), int(x-x_left):int(x-x_left+2*s_size), :]\n                \n                # calculate distance\n                left_mid_abs  = np.linalg.norm(np.mean(  left_mid_im, axis=(0,1)))\n                left_up_abs   = np.linalg.norm(np.mean(   left_up_im, axis=(0,1)))\n                left_down_abs = np.linalg.norm(np.mean( left_down_im, axis=(0,1)))\n                \n                # augment if proper\n                if(abs(mid_abs-left_mid_abs) < level or abs(mid_abs-left_up_abs) < level or abs(mid_abs-left_down_abs) < level):  \n                    x_left = min(x_left+s_size, x)\n                    if(x_left == x):\n                        break\n                    print(\"Augment x_left {0},{1}\".format(x,y))\n                else:\n                    break\n\n            # augment right side\n            while(True):\n                # get three sub_sub_image on right\n                right_mid_im  = ori_image[  int(y-s_size):int(y+s_size), int(x+x_right-2*s_size):int(x+x_right), :]\n                right_up_im   = ori_image[int(y-3*s_size):int(y-s_size), int(x+x_right-2*s_size):int(x+x_right), :]\n                right_down_im = ori_image[int(y+s_size):int(y+3*s_size), int(x+x_right-2*s_size):int(x+x_right), :]\n                \n                # calculate distance\n                right_mid_abs  = np.linalg.norm(np.mean(  right_mid_im, axis=(0,1)))\n                right_up_abs   = np.linalg.norm(np.mean(   right_up_im, axis=(0,1)))\n                right_down_abs = np.linalg.norm(np.mean( right_down_im, axis=(0,1)))\n                \n                # augment if proper\n                if(abs(mid_abs-right_mid_abs) < level or abs(mid_abs-right_up_abs) < level or abs(mid_abs-right_down_abs) < level):\n                    x_right = min(x_right+s_size, ori_image.shape[1]-x)\n                    if(x_right == ori_image.shape[1]-x):\n                        break\n                    print(\"Augment x_right {0},{1}\".format(x,y))\n                else:\n                    break\n            \n            # augment up side\n            while(True):\n                # get three sub_sub_image on up\n                up_mid_im   = ori_image[int(y-y_up):int(y-y_up+2*s_size),   int(x-s_size):int(x+s_size), :]\n                up_left_im  = ori_image[int(y-y_up):int(y-y_up+2*s_size), int(x-3*s_size):int(x-s_size), :]\n                up_right_im = ori_image[int(y-y_up):int(y-y_up+2*s_size), int(x+s_size):int(x+3*s_size), :]\n                \n                # calculate distance\n                up_mid_abs   = np.linalg.norm(np.mean(   up_mid_im, axis=(0,1)))\n                up_left_abs  = np.linalg.norm(np.mean(  up_left_im, axis=(0,1)))\n                up_right_abs = np.linalg.norm(np.mean( up_right_im, axis=(0,1)))\n            \n                # augment if proper\n                if(abs(mid_abs-up_mid_abs) < level or abs(mid_abs-up_left_abs) < level or abs(mid_abs-up_right_abs) < level):\n                    y_up = min(y_up+s_size, y)\n                    if(y_up == y):\n                        break\n                    print(\"Augment y_up {0},{1}\".format(x,y))\n                else:\n                    break\n            \n            # augment down side\n            while(True):\n                # get three sub_sub_image on down\n                down_mid_im   = ori_image[int(y+y_down-2*s_size):int(y+y_down),   int(x-s_size):int(x+s_size), :]\n                down_left_im  = ori_image[int(y+y_down-2*s_size):int(y+y_down), int(x-3*s_size):int(x-s_size), :]\n                down_right_im = ori_image[int(y+y_down-2*s_size):int(y+y_down), int(x+s_size):int(x+3*s_size), :]\n                \n                # calculate distance\n                down_mid_abs   = np.linalg.norm(np.mean(   down_mid_im, axis=(0,1)))\n                down_left_abs  = np.linalg.norm(np.mean(  down_left_im, axis=(0,1)))\n                down_right_abs = np.linalg.norm(np.mean( down_right_im, axis=(0,1)))\n                \n                # augment if proper\n                if(abs(mid_abs-down_mid_abs) < level or abs(mid_abs-down_left_abs) < level or abs(mid_abs-down_right_abs) < level):\n                    y_down = min(y_down+s_size, ori_image.shape[0]-y)\n                    if(y_down == ori_image.shape[0]-y):\n                        break\n                    print(\"Augment y_down {0},{1}\".format(x,y))\n                else:\n                    break\n                    \n        # save range info    \n        Dict_range[(x,y)] = (x_left, x_right, y_up, y_down)\n    \n    return Dict_range"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"6f18d44b-d4fc-0eed-a377-c19a284b69a2"},"outputs":[],"source":"def parse_image_black(filename):\n    ## open sub_image_names file\n    sub_image_names = open(Path_Sealion + \"Train.txt\", 'a')\n    \n    ### get original image\n    ori_image = cv2.imread(Path_Train + filename)\n    dot_image = cv2.imread(Path_Dotted + filename)\n    cnt = 0\n    \n    ### get coordinate of all sea lions\n    Dict_range = {}\n    blobs = get_blobs(filename)\n    \n    ### get xy_range info for all sea_lion\n    if(arg[0] == 'Basic'):\n        Dict_range = get_dict_range_basic(filename, blobs)\n    elif(arg[0] == 'Advance'):\n        Dict_range = get_dict_range_advance(filename, blobs)\n    \n    ### output sub_image and annotation file for each blob\n    Delete_Key_List = []\n    for key in list(Dict_range.keys()):       \n        if(key in Dict_range):\n            # add cnt for new sub_image name\n            cnt += 1\n            \n            # get x, y, xy_range in original image\n            main_x = int(key[0])\n            main_y = int(key[1])\n            xy_range = Dict_range[key]\n            \n            ### get basic sub_image\n            sub_image = cv2.imread('sub_im_template.jpg')            \n            sub_x_center = int(sub_image.shape[1]/2)\n            sub_y_center = int(sub_image.shape[0]/2)\n            sub_image[int(sub_y_center-xy_range[2]):int(sub_y_center+xy_range[3]), int(sub_x_center-xy_range[0]):int(sub_x_center+xy_range[1]), :] = ori_image[int(main_y-xy_range[2]):int(main_y+xy_range[3]), int(main_x-xy_range[0]):int(main_x+xy_range[1]), :]\n            del Dict_range[key]\n                    \n            ### get species\n            g,b,r = dot_image[int(main_y)][int(main_x)][:]\n            species = get_species(r,g,b)\n            \n            # get pos info for annotation file\n            x_pos = float(sub_x_center)/float(Sub_Im_Size[0])\n            y_pos = float(sub_y_center)/float(Sub_Im_Size[0])\n            x_len = float(xy_range[0]+xy_range[1])/float(Sub_Im_Size[0])\n            y_len = float(xy_range[2]+xy_range[3])/float(Sub_Im_Size[0])\n            element = [x_pos, y_pos, x_len, y_len]\n            \n            # save species info in annotation file\n            ant_file = open(Path_Sealion + 'labels/{0}_{1}.txt'.format(filename[:-4], cnt), 'w')\n            ant_file.write(str(species) + \" \" + \" \".join([str(x) for x in element]) + '\\n')\n            \n            \n            ### include other sea lion\n            # max min coordinate for including image based on origin image\n            x_min = max(main_x - sub_image.shape[1]/2 + 1, 0)\n            x_max = min(main_x + sub_image.shape[1]/2 - 1, ori_image.shape[1])\n            y_min = max(main_y - sub_image.shape[0]/2 + 1, 0)\n            y_max = min(main_y + sub_image.shape[0]/2 - 1, ori_image.shape[0])\n            \n            for ex_key in list(Dict_range.keys()):\n                if(ex_key[0] > x_min and ex_key[0] < x_max and ex_key[1] > y_min and ex_key[1] < y_max):\n                    ### coordinate of ex_sea_lion in origin image\n                    ex_range = Dict_range[ex_key]\n                    ex_left  = int(ex_key[0] - ex_range[0])\n                    ex_right = int(ex_key[0] + ex_range[1])\n                    ex_up    = int(ex_key[1] - ex_range[2])\n                    ex_down  = int(ex_key[1] + ex_range[3])\n                    if(ex_left > x_min and ex_right < x_max and ex_up > y_min and ex_down < y_max):\n                        ### sub_image's coordinate where ex_sea_lion put  \n                        in_up    = int(sub_y_center - main_y + ex_key[1] - ex_range[2])\n                        in_down  = int(sub_y_center - main_y + ex_key[1] + ex_range[3])\n                        in_left  = int(sub_x_center - main_x + ex_key[0] - ex_range[0])\n                        in_right = int(sub_x_center - main_x + ex_key[0] + ex_range[1])\n                        sub_image[ in_up:in_down, in_left:in_right, :] = ori_image[ex_up:ex_down, ex_left:ex_right, :]\n                        del Dict_range[ex_key]\n                        \n                        ### get species for include sea_lion\n                        g,b,r = dot_image[int(ex_key[1])][int(ex_key[0])][:]\n                        species = get_species(r,g,b)\n            \n                        # get pos info for annotation file\n                        x_pos = float(sub_x_center - main_x + ex_key[0])/float(Sub_Im_Size[0])\n                        y_pos = float(sub_y_center - main_y + ex_key[1])/float(Sub_Im_Size[0])\n                        x_len = float(ex_range[0]+ex_range[1])/float(Sub_Im_Size[0])\n                        y_len = float(ex_range[2]+ex_range[3])/float(Sub_Im_Size[0])\n                        element = [x_pos, y_pos, x_len, y_len]\n            \n                        # save species info in annotation file\n                        ant_file.write(str(species) + \" \" + \" \".join([str(x) for x in element]) + '\\n')                          \n            \n            cv2.imwrite(Path_Sealion + 'JPEGImages/{0}_{1}.jpg'.format(filename[:-4], cnt),sub_image)\n            #cv2.imwrite('{0}_{1}.png'.format(filename[:-4], cnt),sub_image)\n            sub_image_names.write(Path_Sealion + 'JPEGImages/{0}_{1}.jpg'.format(filename[:-4], cnt))\n            sub_image_names.write(\"\\n\")\n            ant_file.close()\n    sub_image_names.close()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"57f36e9d-2d5b-d30d-200e-ac612fcf4c8f"},"outputs":[],"source":"def parse_image_whole(filename):\n    ## open sub_image_names file\n    sub_image_names = open(Path_Sealion + \"Train.txt\", 'a')\n    \n    ### get original image\n    ori_image = cv2.imread(Path_Train + filename)\n    dot_image = cv2.imread(Path_Dotted + filename)\n    cnt = 0\n    \n    ### get coordinate of all sea lions\n    blobs = get_blobs(filename)\n    \n    ### get xy_range info for all sea_lion\n    if(arg[0] == 'Basic'):\n        Dict_range = get_dict_range_basic(filename, blobs)\n    elif(arg[0] == 'Advance'):\n        Dict_range = get_dict_range_advance(filename, blobs)\n    \n    ### output sub_image and annotation file for each blob\n    Used_Key_Set = set()\n    for key in Dict_range.keys():       \n        if(key not in Used_Key_Set):\n            # add cnt for new sub_image name\n            cnt += 1\n            \n            # get x, y, xy_range in original image\n            main_x = int(key[0])\n            main_y = int(key[1])\n            xy_range = Dict_range[key]\n            \n            # adjust main_x main_y if sea_lion close to boundary\n            if(main_x - Sub_Im_Size[0]/2 < 0):\n                main_x = Sub_Im_Size[0]/2\n            if(main_x + Sub_Im_Size[0]/2 > ori_image.shape[1]):\n                main_x = ori_image.shape[1] - Sub_Im_Size[0]/2\n            if(main_y - Sub_Im_Size[1]/2 < 0):\n                main_y = Sub_Im_Size[1]/2\n            if(main_y + Sub_Im_Size[1]/2 > ori_image.shape[0]):\n                main_y = ori_image.shape[0] - Sub_Im_Size[1]/2\n            \n            # get_sub_image\n            sub_image = ori_image[int(main_y - Sub_Im_Size[1]/2) : int(main_y + Sub_Im_Size[1]/2), int(main_x - Sub_Im_Size[0]/2) : int(main_x + Sub_Im_Size[0]/2), :]\n            \n            # record key as used_key\n            Used_Key_Set.add(key)\n            \n            ### get species\n            g,b,r = dot_image[int(key[1])][int(key[0])][:]\n            species = get_species(r,g,b)\n\n            # get pos info for annotation file\n            x_pos = float(key[0]-(main_x-Sub_Im_Size[0]/2))/float(Sub_Im_Size[0])\n            y_pos = float(key[1]-(main_y-Sub_Im_Size[1]/2))/float(Sub_Im_Size[1])\n            x_len = float(xy_range[0]+xy_range[1])/float(Sub_Im_Size[0])\n            y_len = float(xy_range[2]+xy_range[3])/float(Sub_Im_Size[1])\n            element = [x_pos, y_pos, x_len, y_len]\n            \n            # save species info in annotation file\n            ant_file = open(Path_Sealion + 'labels/{0}_{1}.txt'.format(filename[:-4], cnt), 'w')\n            ant_file.write(str(species) + \" \" + \" \".join([str(x) for x in element]) + '\\n')\n            \n            \n            ### include other sea lion\n            # max min coordinate for including image based on origin image\n            x_min = max(main_x - sub_image.shape[1]/2 + 1, 0)\n            x_max = min(main_x + sub_image.shape[1]/2 - 1, ori_image.shape[1])\n            y_min = max(main_y - sub_image.shape[0]/2 + 1, 0)\n            y_max = min(main_y + sub_image.shape[0]/2 - 1, ori_image.shape[0])\n            \n            for ex_key in Dict_range.keys():\n                if(ex_key != key and ex_key[0] > x_min and ex_key[0] < x_max and ex_key[1] > y_min and ex_key[1] < y_max):\n                    ### coordinate of ex_sea_lion in origin image\n                    ex_range = Dict_range[ex_key]\n                    ex_left  = int(ex_key[0] - ex_range[0])\n                    ex_right = int(ex_key[0] + ex_range[1])\n                    ex_up    = int(ex_key[1] - ex_range[2])\n                    ex_down  = int(ex_key[1] + ex_range[3])\n                    \n                    ### sub_image's coordinate where ex_sea_lion put  \n                    Used_Key_Set.add(ex_key)\n\n                    ### get species for include sea_lion\n                    g,b,r = dot_image[int(ex_key[1])][int(ex_key[0])][:]\n                    species = get_species(r,g,b)\n            \n                    # get pos info for annotation file\n                    x_pos = float(ex_key[0]-(main_x-Sub_Im_Size[0]/2))/float(Sub_Im_Size[0])\n                    y_pos = float(ex_key[1]-(main_y-Sub_Im_Size[1]/2))/float(Sub_Im_Size[1])\n                    \n                    # adjust real size of include sea_lion due to be close to boarder\n                    ex_left_size  = min(ex_range[0], ex_key[0]-(main_x-Sub_Im_Size[0]/2))\n                    ex_right_size = min(ex_range[1], (main_x+Sub_Im_Size[0]/2)-ex_key[0])\n                    ex_up_size    = min(ex_range[2], ex_key[1]-(main_y-Sub_Im_Size[1]/2))\n                    ex_down_size  = min(ex_range[3], (main_y+Sub_Im_Size[1]/2)-ex_key[1])\n                    \n                    x_len = float(ex_left_size+ex_right_size)/float(Sub_Im_Size[0])\n                    y_len = float(ex_up_size+ex_down_size)/float(Sub_Im_Size[1])\n                    element = [x_pos, y_pos, x_len, y_len]\n            \n                    # save species info in annotation file\n                    ant_file.write(str(species) + \" \" + \" \".join([str(x) for x in element]) + '\\n')                          \n            \n            cv2.imwrite(Path_Sealion + 'JPEGImages/{0}_{1}.jpg'.format(filename[:-4], cnt), sub_image)\n            #cv2.imwrite('{0}_{1}.png'.format(filename[:-4], cnt),sub_image)\n            sub_image_names.write(Path_Sealion + 'JPEGImages/{0}_{1}.jpg'.format(filename[:-4], cnt))\n            sub_image_names.write(\"\\n\")\n            ant_file.close()\n    sub_image_names.close()"},{"cell_type":"markdown","metadata":{"_cell_guid":"94c7c283-6ea9-3b3d-43c7-982d5ec32ad8"},"source":""},{"cell_type":"markdown","metadata":{"_cell_guid":"5872d525-5d3b-1833-af2f-99029a642d5a"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3e8cab80-d055-7ab7-7dcc-c3f5076b4a30"},"outputs":[],"source":"if os.path.exists(Path_Sealion + \"Train.txt\"):\n    os.remove(Path_Sealion + \"Train.txt\")\n\nfor filename in file_names:\n    if filename[-3:] == 'jpg':\n        parse_image_black(filename)\n        \n        \"\"\"\n        if(arg[2] == 'Black'):\n            parse_image_black(filename)\n        elif(arg[2] == 'Whole'):\n            parse_image_whole(filename)\n        else:\n            print(\"Wrong in argument\")\n        \"\"\""},{"cell_type":"markdown","metadata":{"_cell_guid":"42f98c53-b001-a9f0-24f4-c0bdf55c3d83"},"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"96c268cb-13b9-4b0e-1e61-716027c7cbf0","collapsed":true},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}