{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Visualizing each variable vs a normally distributed."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pylab as plt\nimport seaborn as sns\nfrom tqdm import tqdm\n\ntrain_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Number of times the unique variable appears vs `np.random.normal` ..."},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"for var in ['var_{}'.format(x) for x in range(0, 200)]:\n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 4))\n    train_df.groupby(var)['target'].agg(['count','mean']).sort_values('count') \\\n        .plot(kind='scatter', x='mean', y='count', ax=ax1, alpha=0.1, title='Train Data')\n    train_df['random_{}'.format(var)] = np.random.normal(train_df[var].mean(), train_df[var].std(), 200000).round(4)\n    train_df.groupby('random_{}'.format(var))['target'].agg(['count','mean']).sort_values('count') \\\n        .plot(kind='scatter', x='mean', y='count', ax=ax2, alpha=0.1, title='Simulated Data')\n    # Both together\n    train_df.groupby(var)['target'].agg(['count','mean']).sort_values('count') \\\n        .plot(kind='scatter', x='mean', y='count', ax=ax3, alpha=0.1)\n    train_df.groupby('random_{}'.format(var))['target'].agg(['count','mean']).sort_values('count') \\\n        .plot(kind='scatter', x='mean', y='count', ax=ax3, alpha=0.1, color='orange', title='Both')\n    ax1.set_xlabel('average target')\n    ax2.set_xlabel('average target')\n    ax3.set_xlabel('average target')\n    ax1.set_ylabel('count of unique value')\n    ax2.set_ylabel('count of unique value')\n    ax3.set_ylabel('count of unique value')\n    fig.suptitle(var)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Interactive Version of the Plot for var_12\nVar 12 looks strange so I wanted to interact with the points that don't appear in the simulated data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import bokeh\nfrom bokeh.io import show, output_notebook\nfrom bokeh.plotting import figure, ColumnDataSource\nfrom bokeh.models import HoverTool\nfrom collections import OrderedDict\n\noutput_notebook()\n\nvar = 'var_126'\ntrain_df['random_{}'.format(var)] = np.random.normal(train_df[var].mean(), train_df[var].std(), 200000).round(4)\n\nTOOLS=\"crosshair,pan,wheel_zoom,box_zoom,reset,hover,previewsave\"\np = figure(tools=TOOLS, title=var)\nsource = ColumnDataSource(data=dict(x=train_df.groupby(var)['target'].mean(),\n                 y=train_df.groupby(var)['target'].count(),\n                 size=(train_df.groupby(var)['target'].mean().index / 2),\n                 label=train_df.groupby(var)['target'].mean().index * 10000))\n\nsource2 = ColumnDataSource(data=dict(x=train_df.groupby('random_{}'.format(var))['target'].mean(),\n                 y=train_df.groupby('random_{}'.format(var))['target'].count(),\n                 size=(train_df.groupby('random_{}'.format(var))['target'].mean().index / 2),\n                 label=train_df.groupby('random_{}'.format(var))['target'].mean().index))\n\np.circle(x='x', y='y', size='size', source=source)\np.circle(x='x', y='y', size='size', source=source2, color='orange')\n\nhover =p.select(dict(type=HoverTool))\nhover.tooltips = OrderedDict([\n    (\"index\", \"$index\"),\n    (\"(xx,yy)\", \"(@x, @y)\"),\n    (\"label\", \"@label\"),\n])\nshow(p)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Feature that is the difference in unique counts vs normal distribution unique counts"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reload Train and Test\ntrain_df = pd.read_csv('../input/train.csv')\ntest_df = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def transform(df, var='var_12'):\n    df['random_{}'.format(var)] = np.random.normal(df[var].mean(), df[var].std(), 200000).round(4)\n    var_counts = pd.DataFrame(df.groupby(var)['ID_code'].count()).reset_index()\n    var_counts_random = pd.DataFrame(df.groupby('random_{}'.format(var))['ID_code'].count()).reset_index()\n    merged_counts = pd.merge(var_counts, var_counts_random, left_on=var, right_on='random_{}'.format(var))\n    merged_counts['diff'] = merged_counts['ID_code_x'] - merged_counts['ID_code_y']\n    df['{}_diff_normal_dist'.format(var)] = df.merge(merged_counts[[var,'diff']], how='left')['diff']\n    df = df.drop('random_{}'.format(var), axis=1)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loop and add features\nfor var in tqdm(['var_{}'.format(x) for x in range(0, 200)]):\n    train_df = transform(train_df, var=var)\n    test_df = transform(test_df, var=var)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nimport lightgbm as lgb\n\nrandom_state = 42\nparams = {\n    \"objective\" : \"binary\", \"metric\" : \"auc\", \"boosting\": 'gbdt', \"max_depth\" : -1, \"num_leaves\" : 13,\n    \"learning_rate\" : 0.01, \"bagging_freq\": 5, \"bagging_fraction\" : 0.4, \"feature_fraction\" : 0.05,\n    \"min_data_in_leaf\": 80, \"min_sum_heassian_in_leaf\": 10, \"tree_learner\": \"serial\", \"boost_from_average\": \"false\",\n    \"bagging_seed\" : random_state, \"verbosity\" : 1, \"seed\": random_state\n}\n\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\noof = train_df[['ID_code', 'target']].copy()\noof['predict'] = 0\npredictions = test_df[['ID_code']].copy()\nval_aucs = []\n\nfeatures = [col for col in train_df.columns if col not in ['target', 'ID_code']]\nX_test = test_df[features].values\n\nfor fold, (trn_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n    X_train, y_train = train_df.iloc[trn_idx][features], train_df.iloc[trn_idx]['target']\n    X_valid, y_valid = train_df.iloc[val_idx][features], train_df.iloc[val_idx]['target']\n    \n    N = 3\n    p_valid,yp = 0,0\n    trn_data = lgb.Dataset(X_train, label=y_train)\n    val_data = lgb.Dataset(X_valid, label=y_valid)\n    evals_result = {}\n    lgb_clf = lgb.train(params,\n                        trn_data,\n                        100000,\n                        valid_sets = [trn_data, val_data],\n                        early_stopping_rounds=1000,\n                        verbose_eval = 500,\n                        evals_result=evals_result)\n    p_valid += lgb_clf.predict(X_valid)\n    yp += lgb_clf.predict(X_test)\n\n    oof['predict'][val_idx] = p_valid\n    val_score = roc_auc_score(y_valid, p_valid)\n    val_aucs.append(val_score)\n    predictions['fold{}'.format(fold+1)] = yp\n    \nmean_auc = np.mean(val_aucs)\nstd_auc = np.std(val_aucs)\nall_auc = roc_auc_score(oof['target'], oof['predict'])\nprint(\"Mean auc: %.9f, std: %.9f. All auc: %.9f.\" % (mean_auc, std_auc, all_auc))\n\npredictions['target'] = np.mean(predictions[[col for col in predictions.columns if col not in ['ID_code', 'target']]].values, axis=1)\nsubmission = pd.DataFrame({\"ID_code\":test_df[\"ID_code\"].values})\nsubmission[\"target\"] = predictions['target']\nsubmission.to_csv(\"lgb_submission2.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}