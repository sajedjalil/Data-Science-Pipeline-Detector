{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"../input\"))\nimport seaborn as sns\nimport time\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this kernel, I implement vectorized PDF caculation (without for loop) to get their correlation matrix. This is helpful to study feature grouping.\ncredits to @sibmike https://www.kaggle.com/sibmike/are-vars-mixed-up-time-intervals"},{"metadata":{},"cell_type":"markdown","source":"**Functions**"},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"def logloss(y,yp):\n    yp = np.clip(yp,1e-5,1-1e-5)\n    return -y*np.log(yp)-(1-y)*np.log(1-yp)\n    \ndef reverse(tr,te):\n    reverse_list = [0,1,2,3,4,5,6,7,8,11,15,16,18,19,\n                22,24,25,26,27,41,29,\n                32,35,37,40,48,49,47,\n                55,51,52,53,60,61,62,103,65,66,67,69,\n                70,71,74,78,79,\n                82,84,89,90,91,94,95,96,97,99,\n                105,106,110,111,112,118,119,125,128,\n                130,133,134,135,137,\n                140,144,145,147,151,155,157,159,\n                161,162,163,164,167,168,\n                170,171,173,175,176,179,\n                180,181,184,185,187,189,\n                190,191,195,196,199]\n    reverse_list = ['var_%d'%i for i in reverse_list]\n    for col in tr.columns:\n        colx = '_'.join(col.split('_')[:2])\n        if colx in reverse_list and 'count' not in col: \n            tr[col] = tr[col]*(-1)\n            te[col] = te[col]*(-1)\n    return tr,te\n\ndef scale(tr,te):\n    for col in tr.columns:\n        if col.startswith('var_') and 'count' not in col:\n            mean,std = tr[col].mean(),tr[col].std()\n            tr[col] = (tr[col]-mean)/std\n            if col in te.columns:\n                te[col] = (te[col]-mean)/std\n    return tr,te\n\ndef getp_vec_sum(x,x_sort,y,std,c=0.5):\n    # x is sorted\n    left = x - std/c\n    right = x + std/c\n    p_left = np.searchsorted(x_sort,left)\n    p_right = np.searchsorted(x_sort,right)\n    p_right[p_right>=y.shape[0]] = y.shape[0]-1\n    p_left[p_left>=y.shape[0]] = y.shape[0]-1\n    return (y[p_right]-y[p_left])\n\ndef get_prob(tr,col,x_query=None,smooth=3,silent=1):\n    std = tr[col].std()\n    N = tr.shape[0]\n    tr = tr.dropna(subset=[col])\n    if silent==0:\n        print(\"null ratio %.4f\"%(tr.shape[0]/N))\n    df = tr.groupby(col).agg({'target':['sum','count']})\n    cols = ['sum_y','count_y']\n    df.columns = cols\n    df = df.reset_index()\n    df = df.sort_values(col)\n    y,c = cols\n    \n    df[y] = df[y].cumsum()\n    df[c] = df[c].cumsum()\n    \n    if x_query is None:\n        rmin,rmax,res = -5.0, 5.0, 501\n        x_query = np.linspace(rmin,rmax,res)\n    \n    dg = pd.DataFrame()\n    tm = getp_vec_sum(x_query,df[col].values,df[y].values,std,c=smooth)\n    cm = getp_vec_sum(x_query,df[col].values,df[c].values,std,c=smooth)+1\n    dg['res'] = tm/cm\n    dg.loc[cm<500,'res'] = 0.1\n    return dg['res'].values\n\ndef get_probs(tr):\n    y = []\n    for i in range(200):\n        name = 'var_%d'%i\n        res = get_prob(tr,name)\n        y.append(res)\n    return np.vstack(y)\n\ndef split(tr):\n    split = pickle.load(open('cache/kfolds.pkl','rb'))\n    for trx,tex in split:\n        break\n    trx,vax = tr.iloc[trx],tr.iloc[tex]\n    return trx,vax\n\n\ndef plot_pdf(tr,name):\n    name1 = '%s_no_noise'%name\n    name2 = '%s_no_noise2'%name\n    rmin,rmax,res = -5.0, 5.0, 501\n    x_query = np.linspace(rmin,rmax,res)\n    plt.figure(figsize=(10,5))\n    prob1 = get_prob(tr,name,x_query=x_query)\n    prob2 = get_prob(tr,name1,x_query=x_query)\n    prob3 = get_prob(tr,name2,x_query=x_query)\n    plt.grid()\n    plt.plot(x_query,prob1,color='b',label=name)\n    plt.plot(x_query,prob2,color='r',label=name1)\n    plt.plot(x_query,prob3,color='g',label=name2)\n    plt.legend(loc='upper right')\n    plt.title('PDF of '+name)\n    \ndef plot_pdfs(tr):\n    rmin,rmax,res = -5.0, 5.0, 501\n    x_query = np.linspace(rmin,rmax,res)\n    cols = [i for i in tr.columns if i.startswith('var')]\n    for i in range(50):\n        plt.figure(figsize=(18,10))\n        print('plot var %d to var %d'%(i*4,i*4+4))\n        for j in range(4):\n            cx = i*4+j\n            name = 'var_%d'%cx\n            name1 = '%s_no_noise'%name\n            name2 = '%s_no_noise2'%name\n            plt.subplot(2,2,j+1)\n            prob1 = get_prob(tr,name,x_query=x_query)\n            prob2 = get_prob(tr,name1,x_query=x_query)\n            prob3 = get_prob(tr,name2,x_query=x_query)\n            plt.grid()\n            plt.plot(x_query,prob1,color='b',label=name)\n            plt.plot(x_query,prob2,color='r',label=name1)\n            plt.plot(x_query,prob3,color='g',label=name2)\n            plt.legend(loc='upper right')\n            plt.title('PDF of '+name)\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_magic():\n    tr_path,te_path = '../input/train.csv','../input/test.csv'\n\n    tr = pd.read_csv(tr_path)#.drop([IDCOL,YCOL],axis=1)\n    te = pd.read_csv(te_path)#.drop([IDCOL],axis=1)\n    cols = [i for i in tr.columns if i.startswith('var_')]\n    N = tr.shape[0]\n    tr['real'] = 1\n    te0 = te.copy()\n    for col in cols:\n        te[col] = te[col].map(te[col].value_counts())\n    a = te[cols].min(axis=1)\n    te0['real'] = (a == 1).astype('int')\n\n    tr = tr.append(te0).reset_index(drop=True)\n    for col in cols:\n        tr[col+'_count'] = tr[col].map(tr.loc[tr.real==1,col].value_counts())\n    for col in cols:\n        tr.loc[tr[col+'_count']>1,col+'_no_noise'] = tr.loc[tr[col+'_count']>1,col]\n        tr.loc[tr[col+'_count']>2,col+'_no_noise2'] = tr.loc[tr[col+'_count']>2,col]\n    return tr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**load data & group vars**"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntr = build_magic()\nte = tr[tr.target.isnull()]\ntr = tr[tr.target.isnull()==0]\nprint(tr.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntr,te = reverse(tr,te)\ntr,te = scale(tr,te)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nplot_pdfs(tr)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}