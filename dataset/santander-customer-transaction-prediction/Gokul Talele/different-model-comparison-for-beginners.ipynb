{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Imports for Modeling\n\n#from sklearn.preprocessing import Imputer, MinMaxScaler\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.metrics import roc_curve, roc_auc_score, auc, confusion_matrix, classification_report\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nimport lightgbm as lgb\nfrom mlxtend.classifier import StackingClassifier\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is my first attempt to write the notebook from scratch. I have been playing around with exisitng kernels for competition until now. Comments, suggestions, recommendations are all very welcomed.\n\nI will be modeling using the following algorithms -\n\nModified Naive Bayes\nDecision Tree Classifier\nRandom Forest Classifier\nLight Gradient Boosting Method\nLet's start by importing necessary packages -"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"\ntrain = pd.read_csv('../input/train.csv')\ntrain0 = train[ train['target']==0 ].copy()\ntrain1 = train[ train['target']==1 ].copy()\ntrain.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# CALCULATE MEANS AND STANDARD DEVIATIONS\ns = [0]*200\nm = [0]*200\nfor i in range(200):\n    s[i] = np.std(train['var_'+str(i)])\n    m[i] = np.mean(train['var_'+str(i)])\n    \n# CALCULATE PROB(TARGET=1 | X)\ndef getp(i,x):\n    c = 3 #smoothing factor\n    a = len( train1[ (train1['var_'+str(i)]>x-s[i]/c)&(train1['var_'+str(i)]<x+s[i]/c) ] ) \n    b = len( train0[ (train0['var_'+str(i)]>x-s[i]/c)&(train0['var_'+str(i)]<x+s[i]/c) ] )\n    if a+b<500: return 0.1 #smoothing factor\n    # RETURN PROBABILITY\n    return a / (a+b)\n    # ALTERNATIVELY RETURN ODDS\n    # return a / b\n    \n# SMOOTH A DISCRETE FUNCTION\ndef smooth(x,st=1):\n    for j in range(st):\n        x2 = np.ones(len(x)) * 0.1\n        for i in range(len(x)-2):\n            x2[i+1] = 0.25*x[i]+0.5*x[i+1]+0.25*x[i+2]\n        x = x2.copy()\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nPicture = True #draw plots\nrmin=-5; rmax=5; res=501\npr = 0.1 * np.ones((200,res))\npr2 = pr.copy()\nxr = np.zeros((200,res))\nxr2 = xr.copy()\nct2 = 0\nfor j in range(50):\n    if Picture: plt.figure(figsize=(15,8))\n    for v in range(4):\n        ct = 0\n        # CALCULATE PROBABILITY FUNCTION FOR VAR\n        for i in np.linspace(rmin,rmax,res):\n            pr[v+4*j,ct] = getp(v+4*j,m[v+4*j]+i*s[v+4*j])\n            xr[v+4*j,ct] = m[v+4*j]+i*s[v+4*j]\n            xr2[v+4*j,ct] = i\n            ct += 1\n        # SMOOTH FUNCTION FOR PRETTIER DISPLAY\n        # BUT USE UNSMOOTHED FUNCTION FOR PREDICTION\n        pr2[v+4*j,:] = smooth(pr[v+4*j,:],50)\n        if Picture:\n            # DISPLAY PROBABILITY FUNCTION\n            plt.subplot(2, 4, ct2%4+5)\n            plt.plot(xr[v+4*j,:],pr2[v+4*j,:],'-')\n            plt.title('P( t=1 | var_'+str(v+4*j)+' )')\n            xx = plt.xlim()\n            # DISPLAY TARGET DENSITIES\n            plt.subplot(2, 4, ct2%4+1)            \n            sns.distplot(train0['var_'+str(v+4*j)], label = 't=0')\n            sns.distplot(train1['var_'+str(v+4*j)], label = 't=1')\n            plt.title('var_'+str(v+4*j))\n            plt.legend()\n            plt.xlim(xx)\n            plt.xlabel('')\n        if (ct2%8==0): print('Showing vars',ct2,'to',ct2+7,'...')\n        ct2 += 1\n    if Picture: plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getp2(i,x):\n    z = (x-m[i])/s[i]\n    ss = (rmax-rmin)/(res-1)\n    idx = min( (res+1)//2 + (z-ss/2)//ss, res-1)\n    idx = max(idx,0)\n    return pr[i,int(idx)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nprint('Calculating 200000 predictions and displaying a few examples...')\npred = [0]*200000; ct = 0\nfor r in train.index:\n    p = 0.1\n    for i in range(200):\n        p *= 10*getp2(i,train.iloc[r,2+i])\n    if ct%25000==0: print('train',r,'has target =',train.iloc[r,1],'and prediction =',p)\n    pred[ct]=p; ct += 1\nprint('###############')\nprint('Validation AUC =',roc_auc_score(train['target'], pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/test.csv')\nprint('Calculating 200000 predictions and displaying a few examples...')\npred = [0]*200000; ct = 0\nfor r in test.index:\n    p = 0.1\n    for i in range(200):\n        p *= 10*getp2(i,test.iloc[r,1+i])\n    if ct%25000==0: print('test',r,'has prediction =',p)\n    pred[ct]=p\n    ct += 1\nsub = pd.read_csv('../input/sample_submission.csv')\nsub['target'] = pred\nsub.to_csv('submission.csv',index=False)\nprint('###############')\nprint('Finished. Wrote predictions to submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.loc[ sub['target']>1 , 'target'] = 1\nb = plt.hist(sub['target'], bins=200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Target variable from the Training Set\nTarget = train['target']\n\n# Input dataset for Train and Test \ntrain_inp = train.drop(columns = ['target', 'ID_code'])\ntest_inp = test.drop(columns = ['ID_code'])\n\n# List of feature names\nfeatures = list(train_inp.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the Train Dataset into training and validation sets for model building. \n# The training set now has 140K records and validation set has 60K records\n\nX_train, X_test, Y_train, Y_test = train_test_split(train_inp, Target, \n                                                    test_size= 0.3, random_state = 2078)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the split of train and validation\nprint('Train:',X_train.shape)\nprint('Test:',X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Performance Function\n\nSince we will be building multiple models, it is advisable to create a function that can be called with different outputs of each model. This is a simple function which takes in the Predicted Validation Target and Actual Validation Target. It then gives out classification summary like confusion matrix and AUC score"},{"metadata":{"trusted":true},"cell_type":"code","source":"def performance(Y_test, logist_pred):\n    logist_pred_var = [0 if i < 0.5 else 1 for i in logist_pred]\n    print('Confusion Matrix:')\n    print(confusion_matrix(Y_test, logist_pred_var)) \n      \n    #print(classification_report(Y_test, logist_pred)) \n\n    fpr, tpr, thresholds = roc_curve(Y_test, logist_pred, pos_label=1)\n    print('AUC:')\n    print(auc(fpr, tpr))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Decision Trees  \n\nMoving on to a slightly advanced algorithm, decision trees. Again, the parameters here are class_weight to deal with unbalanced target variable, random_state for reproducability of same trees. The feature max_features and min_sample_leaf are used to prune the tree and avoid overfitting to the training data.\n\nMax_features defines what proportion of available input features will be used to create tree.\n\nMin_sample_leaf restricts the minimum number of samples in a leaf node, making sure none of the leaf nodes has less than 80 samples in it. If leaf nodes have less samples it implies we have grown the tree too much and trying to predict each sample very precisely, thus leading to overfitting."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create Decision Tree Classifier object with few parameters\ntree_clf = DecisionTreeClassifier(class_weight='balanced', random_state = 2019, \n                                  max_features = 0.7, min_samples_leaf = 80)\n\n# Fit the object on training data\ntree_clf.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Decision Tree Results:\n\nBasic decision tree is giving us 0.651 AUC score on the validation set and 0.650 AUC score on the test set submitted on public leaderboard"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict for validation set and check the performance\ntree_preds = tree_clf.predict_proba(X_test)[:, 1]\nperformance(Y_test, tree_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Submission dataframe\ntree_pred_test = tree_clf.predict_proba(test_inp)[:, 1]\n\n# Create the Submission File using Decision tree model\nsub = pd.read_csv('../input/sample_submission.csv')\nsub['target'] = tree_pred_test\nsub.to_csv('Decision_Tree.csv',index=False)\nsubmitTree.to_csv('Decision_Tree.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract feature importances\nfeature_importance_values = tree_clf.feature_importances_\nfeature_importances = pd.DataFrame({'feature': features, 'importance': feature_importance_values})\nfeature_importances.sort_values(by='importance', ascending=False).head(n=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,8))\nsns.boxplot(data=train[['var_81', 'var_139', 'var_12', 'var_26', 'var_146', 'var_110',\n                        'var_109', 'var_53', 'var_6', 'var_166']])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ensemble Learning\n\n[Ensemble Learning](https://en.wikipedia.org/wiki/Ensemble_learning) refers to the algorithms that created using ensembles of variour learning algorithms. So, to give you an example, random forests are ensembles of many decision tree estimators.\n\nThere are 2 types of ensemble learning algorithms - 1. Bagging Algorithms: Bagging involves having each model in the ensemble vote with equal weight for the final output. In order to promote model variance, bagging trains each model in the ensemble using a randomly drawn subset of the training set 2. Boosting Algorithms: As Wikipedia defines, boosting involves incrementally building an ensemble by training each new model instance to emphasize the training instances that previous models mis-classified.\n\nRandom Forest\n\nLet's start with building a random forest, with parameters like class_weight, random_state, and hyperparameters like max_features and min_sample_leaf as earlier. We have also defined the n_estimators which is a compulsory parameter. This defines the number of decision trees that will be present in the forest."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create random Forest Object using the mentioned parameters\nrandom_forest = RandomForestClassifier(n_estimators=100, random_state=2019, verbose=1,\n                                      class_weight='balanced', max_features = 0.5, \n                                       min_samples_leaf = 100)\n\n# Fit the object on training set \nrandom_forest.fit(X_train, Y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest Results:\nBasic random forest is giving us 0.787 AUC score on the validation set and 0.789 AUC score on the test set submitted on public leaderboard"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict the validation set target and check the performance\nforest_preds = random_forest.predict_proba(X_test)[:, 1]\nperformance(Y_test, forest_preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Submission dataframe\nforest_pred_test = random_forest.predict_proba(test_inp)[:, 1]\n\n# Create the Submission File using Random_Forest model\nsub = pd.read_csv('../input/sample_submission.csv')\nsub['target'] = forest_pred_test\nsub.to_csv('Random_Forest.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The feature importance we get from random forest is very similar to the list we got from decision trees"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract feature importances\nfeature_importance_values = random_forest.feature_importances_\nfeature_importances = pd.DataFrame({'feature': features, 'importance': feature_importance_values})\nfeature_importances.sort_values(by='importance', ascending=False).head(n=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Light Gradient Boosting Method\nWHAT IS IT?\n\nLight GBM is a gradient boosting framework that uses tree based learning algorithm. It grows tree vertically while other algorithm grows trees horizontally meaning that Light GBM grows tree leaf-wise while other algorithm grows level-wise. Leaf-wise algorithm can reduce more loss than a level-wise algorithm.\n\nWHY USE LGB?\n\nIt is ‘Light’ because of its high speed. It can handle large data, requires low memory to run and focuses on accuracy of results. Also supports GPU learning and thus data scientists/ Kagglers are widely using LGBM for data science application development.\n\nTIPS & TRICKS\n\nThe algorithm easily overfits and thus, should not be used with small (< 10K rows) datasets.\nDeal with overfitting using these parameters:\nSmall Maximum Depth\nLarge Minimum Data in a Leaf\nSmall Feature and Bagging Fraction\nImprove the training speed\nSmall Bagging Fraction\nEarly Stopping Round\nUse small learning_rate with large num_iterations for better accuracy\nIdeally, the value of num_leaves should be less than or equal to 2^(max_depth). Value more than this will result in overfitting\nIf you have a big enough dataset, use this algorithm at least once. It’s accuracy has challenged other boosting algorithms"},{"metadata":{"trusted":true},"cell_type":"code","source":"#custom function to build the LightGBM model.\ndef run_lgb(X_train, Y_train, X_test, Y_test, test_inp):\n    params = {\n        \"objective\" : \"binary\",\n        \"metric\" : \"auc\",\n        \"num_leaves\" : 1000,\n        \"learning_rate\" : 0.01,\n        \"bagging_fraction\" : 0.8,\n        \"feature_fraction\" : 0.8,\n        \"bagging_freq\" : 5,\n        \"reg_alpha\" : 1.728910519108444,\n        \"reg_lambda\" : 4.9847051755586085,\n        \"random_state\" : 42,\n        \"bagging_seed\" : 2019,\n        \"verbosity\" : -1,\n        \"max_depth\": 18,\n        \"min_child_samples\":100\n       # ,\"boosting\":\"rf\"\n    }\n    \n    lgtrain = lgb.Dataset(X_train, label=Y_train)\n    lgval = lgb.Dataset(X_test, label=Y_test)\n    evals_result = {}\n    model = lgb.train(params, lgtrain, 2500, valid_sets=[lgval], \n                      early_stopping_rounds=50, verbose_eval=50, evals_result=evals_result)\n    \n    pred_test_y = model.predict(test_inp, num_iteration=model.best_iteration)\n    return pred_test_y, model, evals_result\n\n# Training the model #\npred_test, model, evals_result = run_lgb(X_train, Y_train, X_test, Y_test, test_inp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Light GBM Results:\nThe AUC Score drastically improves from 0.650 in our Decision Tree model to an AUC score of 0.89 in our ensemble of trees, Light GBM model. The public leaderboard scores after submitting the test predictions come out to be 0.891\n\nThe feature importance though, it has some variables similar to those we saw in the tree models but majority of them are new in the top 10 most important variable list"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extract feature importances\nfeature_importance_values = model.feature_importance()\nfeature_importances = pd.DataFrame({'feature': features, 'importance': feature_importance_values})\nfeature_importances.sort_values(by='importance', ascending=False).head(n=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Submission dataframe\npred_test[pred_test>1] = 1\npred_test[pred_test<0] = 0\n\n# Create the Submission File using Light GBM\nsub = pd.read_csv('../input/sample_submission.csv')\nsub['target'] = pred_test\nsub.to_csv('LightGBM.csv', index = False)\n\n#sig_clf3 = CalibratedClassifierCV(clf3, method=\"sigmoid\")\nsubmitLGB.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}