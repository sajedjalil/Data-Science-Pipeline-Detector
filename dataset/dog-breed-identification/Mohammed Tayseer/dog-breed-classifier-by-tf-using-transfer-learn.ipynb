{"cells":[{"metadata":{"id":"U-Cw_mo61ml6"},"cell_type":"markdown","source":"# Introduction","execution_count":null},{"metadata":{"id":"uyP8PpxU68xW"},"cell_type":"markdown","source":"In this project I going to be using deep learning to help us identify 120 breeds of dogs. \nI will load the data from Kaggle competition ( [Kaggle dog breed identification competition](https://www.kaggle.com/c/dog-breed-identification/overview)). \nIn this project, a pre-trainded model form tensorflow hud used to predict a 120 differents breeds of dogs. This is call Multi-classs classification. For speed the training and validation processes I will use GPU as processor.\nEnabling a GPU to your Kernel results in a 12.5X speedup during training of a deep learning model.\n\n","execution_count":null},{"metadata":{"id":"TCouUe091ezu"},"cell_type":"markdown","source":"# Setup Workplace","execution_count":null},{"metadata":{"id":"beM5o0tcATAJ","trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n\nfrom sklearn.model_selection import train_test_split\n\nimport random\nfrom random import randint\nimport re\n\nfrom keras.utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical #convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout,BatchNormalization\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import EarlyStopping\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"68qqOBltAdOg"},"cell_type":"markdown","source":"## Enabling and testing the GPU\n","execution_count":null},{"metadata":{"id":"t6GB6JDeAd3t","trusted":true},"cell_type":"code","source":"\n\n#%tensorflow_version 2.x\nimport tensorflow as tf\n\ndevice_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))\n\nprint(\"GPU\", \"available (YESS!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To create data dirctories","execution_count":null},{"metadata":{"id":"JD4sdB-dB61x","trusted":true},"cell_type":"code","source":"# creat data dirctories, we my use it later\n\nDATA_DIR = '../input/dog-breed-identification'\n\n\nTRAIN_DIR = DATA_DIR + '/train'                           \nTEST_DIR = DATA_DIR + '/test'                             \n\nTRAIN_CSV = DATA_DIR + '/labels.csv'                     \nTEST_CSV = DATA_DIR + '/sample_submission.csv' ","execution_count":null,"outputs":[]},{"metadata":{"id":"03AKScL4CUEw"},"cell_type":"markdown","source":"# Exlporatory Data Analysis (EDA)","execution_count":null},{"metadata":{"id":"r_ijHFCVB77O","trusted":true},"cell_type":"code","source":"# Checkout the labels of our data\nimport pandas as pd\nlabels_df= pd.read_csv(TRAIN_CSV)\nlabels_df.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"ICvxmusqCYVr","trusted":true},"cell_type":"code","source":"labels_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"id":"L72qWwv1CjuE"},"cell_type":"markdown","source":"labels.csv file contains all Images ID and labels. Every entry contains ID image and its assosciated dog breed","execution_count":null},{"metadata":{"id":"m9U77lLICbKT","trusted":true},"cell_type":"code","source":"labels = labels_df[\"breed\"].to_numpy() # convert labels column to NumPy array\nlabels[:15] ","execution_count":null,"outputs":[]},{"metadata":{"id":"q0n8J-XvCmpo","trusted":true},"cell_type":"code","source":"num_images = len(labels_df[\"id\"])\nprint('Number of images in Training file:', num_images)\nno_labels=len(labels)\nprint('Number of dog breeds in Training file:', no_labels)","execution_count":null,"outputs":[]},{"metadata":{"id":"VAOtixBqCpAI","trusted":true},"cell_type":"code","source":"# Make bar chart\n\nbar = labels_df[\"breed\"].value_counts(ascending=True).plot.barh(figsize = (30,120))\nplt.title(\"Distribution of the Dog Breeds\", fontsize = 20)\nbar.tick_params(labelsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"H9jlQfJdDR61","trusted":true},"cell_type":"code","source":"# Create pathnames from image ID's\nfilenames = [TRAIN_DIR + \"/\" + fname + \".jpg\" for fname in labels_df[\"id\"]]\nfilenames[:10]","execution_count":null,"outputs":[]},{"metadata":{"id":"M_VS-IESC1ih","trusted":true},"cell_type":"code","source":"# display some dogs with their labels\nfig, axes = plt.subplots(nrows=5, ncols=5, figsize=(25, 25),\n                          subplot_kw={'xticks': [], 'yticks': []})\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(filenames[i]))\n    ax.set_title(labels_df.breed[i])\nplt.tight_layout()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"id":"pXT8K08zGERe","trusted":true},"cell_type":"code","source":"# check image size\nfrom matplotlib.pyplot import imread\nimage = imread(filenames[42]) # read in an image\nimage.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"ApoOXC7oE9YE"},"cell_type":"markdown","source":"**We cansee that:**\n*   All images are of differnt sizes.\n*   The backgrounsd vary- some have humans, and other things.\n*   Some images are not vertical\n","execution_count":null},{"metadata":{"id":"qxHVxPI1Eq3Z","trusted":true},"cell_type":"code","source":"# See if number of labels matches the number of filenames\nif len(labels) == len(filenames):\n  print(\"Number of labels matches number of filenames!\")\nelse:\n  print(\"Number of labels does not match number of filenames, check data directories.\")","execution_count":null,"outputs":[]},{"metadata":{"id":"OpE7dBbRFMDp"},"cell_type":"markdown","source":"# Input data and pre-processing ","execution_count":null},{"metadata":{"id":"pI_uvSunFjvz"},"cell_type":"markdown","source":"## Oen-hot encoding","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Since the output of our predictor for each input is a vector of probabilities for each class we must convert out label dataset to be the same format. That is for each input a row vector of length num_classes with a 1 at the index of the label and 0's everywhere else.","execution_count":null},{"metadata":{"id":"-NjI_x7uFAwK","trusted":true},"cell_type":"code","source":"# Find the unique label values\nunique_breeds = np.unique(labels)\nlen(unique_breeds)","execution_count":null,"outputs":[]},{"metadata":{"id":"hIrqtemoFm2w","trusted":true},"cell_type":"code","source":"one_hot_labels = [label == np.array(unique_breeds) for label in labels]\none_hot_labels[0] ","execution_count":null,"outputs":[]},{"metadata":{"id":"NQtxLOT7FpJB","trusted":true},"cell_type":"code","source":"# Setup X & y variables\nX = filenames\ny = one_hot_labels","execution_count":null,"outputs":[]},{"metadata":{"id":"PzTZ67iNGXZo"},"cell_type":"markdown","source":"## Image processing ","execution_count":null},{"metadata":{"id":"c3S5bbMjFvF4","trusted":true},"cell_type":"code","source":"# Define image size\nIMAGE_SIZE = 331\n\n\n\ndef process_image(image_path):\n  \"\"\"\n  Takes an image file path and turns it into a Tensor.\n  \"\"\"\n  # Read in image file\n  image = tf.io.read_file(image_path)\n  \n  # Turn the jpeg image into numerical Tensor with 3 colour channels (Red, Green, Blue)\n  image = tf.image.decode_jpeg(image, channels=3)\n  \n\n  # Convert the colour channel values from 0-225 values to 0-1 values\n  image = tf.image.convert_image_dtype(image, tf.float32)\n  \n  # Resize the image to our desired size \n  image = tf.image.resize(image, size=[IMAGE_SIZE, IMAGE_SIZE])\n\n  return image\n","execution_count":null,"outputs":[]},{"metadata":{"id":"RbSdRbPrJ3Oo","trusted":true},"cell_type":"code","source":"#Display one dog\n#plt.imshow(process_image(filenames[0]))\n#plt.title(labels_df.breed[0])\n\none_image=process_image(filenames[0])\none_image\n#print(one_image.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"fMRJUlijI3kJ","trusted":true},"cell_type":"code","source":"#diplay dogs after processing\n\nfig, axes = plt.subplots(nrows=5, ncols=5, figsize=(25, 25),\n                        subplot_kw={'xticks': [], 'yticks': []})\n\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(process_image(filenames[i]))\n    ax.set_title(labels_df.breed[i])\nplt.tight_layout()\nplt.show()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data agumentation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_agumentation(image=process_image):\n    image=tf.image.random_flip_up_down(image)\n    image=tf.image.random_flip_left_right(image)\n    return image\n\n\n\n\n#not used..low accuraccy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Spilt data for experimenting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split them into training and validation using NUM_IMAGES \nX_train, X_val, y_train, y_val = train_test_split(X[:1000],\n                                                  y[:1000], \n                                                  test_size=0.15,\n                                                  random_state=42)\n\nlen(X_train), len(y_train), len(X_val), len(y_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating data batches","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a simple function to return a tuple (image, label)\ndef get_image_label(image_path, label):\n  \"\"\"\n  Takes an image file path name and the associated label,\n  processes the image and returns a tuple of (image, label).\n  \"\"\"\n  image = process_image(image_path)\n  return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the batch size, 32 is a good default\nBATCH_SIZE = 32\n\n# Create a function to turn data into batches\ndef create_data_batches(x, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n  \"\"\"\n  Creates batches of data out of image (x) and label (y) pairs.\n  Shuffles the data if it's training data but doesn't shuffle it if it's validation data.\n  Also accepts test data as input (no labels).\n  \"\"\"\n  # If the data is a test dataset, we probably don't have labels\n  if test_data:\n    print(\"Creating test data batches...\")\n    data = tf.data.Dataset.from_tensor_slices((tf.constant(x))) # only filepaths\n    data_batch = data.map(process_image).batch(batch_size)\n    return data_batch\n  \n  # If the data if a valid dataset, we don't need to shuffle it\n  elif valid_data:\n    print(\"Creating validation data batches...\")\n    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n                                               tf.constant(y))) # labels\n    data_batch = data.map(get_image_label).batch(batch_size)\n    return data_batch\n\n  else:\n    # If the data is a training dataset, we shuffle it\n    print(\"Creating training data batches...\")\n    # Turn filepaths and labels into Tensors\n    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n                                              tf.constant(y))) # labels\n    \n    # Shuffling pathnames and labels before mapping image processor function is faster than shuffling images\n    #data = data.shuffle(buffer_size=len(x))\n\n    # Create (image, label) tuples (this also turns the image path into a preprocessed image)\n    data = data.map(get_image_label)\n\n    # Turn the data into batches\n    data_batch = data.batch(BATCH_SIZE)\n  return data_batch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create training and validation data batches\ntrain_data = create_data_batches(X_train, y_train)\nval_data = create_data_batches(X_val, y_val, valid_data=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualizing data batches","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a function for viewing images in a data batch\ndef show_25_images(images, labels):\n  \"\"\"\n  Displays 25 images from a data batch.\n  \"\"\"\n  # Setup the figure\n  plt.figure(figsize=(10, 10))\n  # Loop through 25 (for displaying 25 images)\n  for i in range(25):\n    # Create subplots (5 rows, 5 columns)\n    ax = plt.subplot(5, 5, i+1)\n    # Display an image\n    plt.imshow(images[i])\n    # Add the image label as the title\n    plt.title(unique_breeds[labels[i].argmax()])\n    # Turn gird lines off\n    plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize training images from the training data batch\ntrain_images, train_labels = next(train_data.as_numpy_iterator())\nshow_25_images(train_images, train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualize validation images from the validation data batch\nval_images, val_labels = next(val_data.as_numpy_iterator())\nshow_25_images(val_images, val_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating and training a model","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Create model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setup input shape to the model\nINPUT_SHAPE = [None, IMAGE_SIZE, IMAGE_SIZE, 3] # batch, height, width, colour channels\n\n# Setup output shape of the model\nOUTPUT_SHAPE = len(unique_breeds) # number of unique labels\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create model\n\ndef create_model():\n    pretrained_model = tf.keras.applications.InceptionV3(input_shape=(IMAGE_SIZE,IMAGE_SIZE, 3), include_top=False)\n    pretrained_model.trainable = True\n    model = tf.keras.Sequential([\n        pretrained_model,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(OUTPUT_SHAPE, activation='softmax')\n      ])\n    \n    #Define the optimizer\n    optimizer=RMSprop(lr=0.0001, rho=0.9, epsilon=1e-08, decay=0.0)\n\n\n\n\n    model.compile(\n        optimizer=optimizer,\n        loss = tf.keras.losses.CategoricalCrossentropy(),\n        metrics=['accuracy']\n  )\n    \n  # Build the model\n    model.build(INPUT_SHAPE) # Let the model know what kind of inputs it'll be getting\n    return model  \n  \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Create a model and check its details\nmodel = create_model()\nmodel.summary() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating callbacks","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create early stopping (once our model stops improving, stop training)\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n                                                  patience=3) # stops after 3 rounds of no improvements","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set a learning rate annealer\nlearning_rate_redcuing=ReduceLROnPlateau(monitor='val_accuracy', \n                                         patience=3,\n                                         verbose=1,\n                                         factor=0.5,\n                                         min_lr=0.00001)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training a model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# How many rounds should we get the model to look through the data?\nNUM_EPOCHS = 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build a function to train and return a trained model\ndef train_model(NUM_EPOCHS, model):\n    \"\"\"\n    Trains a given model and returns the trained version.\n    \"\"\"\n\n    # Fit the model to the data passing it the callbacks we created\n    history=model.fit(x=train_data,\n                epochs=NUM_EPOCHS,\n                validation_data=val_data,\n                steps_per_epoch=len(X_train) // BATCH_SIZE,\n                validation_freq=1, # check validation metrics every epoch\n                callbacks=[learning_rate_redcuing, early_stopping])\n    return history\n  \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fit the model to the data\nhistory = train_model(NUM_EPOCHS,model)\n\nfinal_accuracy = history.history[\"val_accuracy\"][-5:]\nprint(\"FINAL ACCURACY MEAN-5: \", np.mean(final_accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_training_curves(training, validation, title, subplot):\n  ax = plt.subplot(subplot)\n  ax.plot(training)\n  ax.plot(validation)\n  ax.set_title('Model '+ title)\n  ax.set_ylabel(title)\n  ax.set_xlabel('Epoch')\n  ax.legend(['Training', 'Validation'])\n\nplt.subplots(figsize=(10,10))\nplt.tight_layout()\ndisplay_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'accuracy', 211)\ndisplay_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 212)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Making and evaluating predictions using a trained model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make predictions on the validation data (not used to train on)\npredictions = model.predict(val_data, verbose=1) # verbose shows us how long there is to go\npredictions\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the shape of predictions\npredictions.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# First prediction\nprint(predictions[0])\nprint(f\"Max value (probability of prediction): {np.max(predictions[0])}\") # the max probability value predicted by the model\nprint(f\"Sum: {np.sum(predictions[0])}\") # because we used softmax activation in our model, this will be close to 1\nprint(f\"Max index: {np.argmax(predictions[0])}\") # the index of where the max value in predictions[0] occurs\nprint(f\"Predicted label: {unique_breeds[np.argmax(predictions[0])]}\") # the predicted label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a function to unbatch a batched dataset\ndef unbatchify(data):\n  \"\"\"\n  Takes a batched dataset of (image, label) Tensors and returns separate arrays\n  of images and labels.\n  \"\"\"\n  images = []\n  labels = []\n  # Loop through unbatched data\n  for image, label in data.unbatch().as_numpy_iterator():\n    images.append(image)\n    labels.append(unique_breeds[np.argmax(label)])\n  return images, labels\n\n# Unbatchify the validation data\nval_images, val_labels = unbatchify(val_data)\nval_images[0], val_labels[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Turn prediction probabilities into their respective label (easier to understand)\ndef get_pred_label(prediction_probabilities):\n  \"\"\"\n  Turns an array of prediction probabilities into a label.\n  \"\"\"\n  return unique_breeds[np.argmax(prediction_probabilities)]\n\n# Get a predicted label based on an array of prediction probabilities\npred_label = get_pred_label(predictions[0])\npred_label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_pred(prediction_probabilities, labels, images, n=1):\n  \"\"\"\n  View the prediction, ground truth label and image for sample n.\n  \"\"\"\n  pred_prob, true_label, image = prediction_probabilities[n], labels[n], images[n]\n  \n  # Get the pred label\n  pred_label = get_pred_label(pred_prob)\n  \n  # Plot image & remove ticks\n  plt.imshow(image)\n  plt.xticks([])\n  plt.yticks([])\n\n  # Change the color of the title depending on if the prediction is right or wrong\n  if pred_label == true_label:\n    color = \"green\"\n  else:\n    color = \"red\"\n\n  plt.title(\"Predicted label :{} ({:2.0f}%) \\n True label :{}\".format(pred_label,\n                                      np.max(pred_prob)*100,\n                                      true_label),\n                                      color=color)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# View an example prediction, original image and truth label\nplot_pred(prediction_probabilities=predictions, n=0,\n          labels=val_labels,\n          images=val_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_pred_conf(prediction_probabilities, labels, n=1):\n    \"\"\"\n    Plots the top 10 highest prediction confidences along with\n    the truth label for sample n.\n    \"\"\"\n    pred_prob, true_label = prediction_probabilities[n], labels[n]\n\n    # Get the predicted label\n    pred_label = get_pred_label(pred_prob)\n\n    # Find the top 10 prediction confidence indexes\n    top_10_pred_indexes = pred_prob.argsort()[-10:][::-1]\n    \n    # Find the top 10 prediction confidence values\n    top_10_pred_values = pred_prob[top_10_pred_indexes]\n    \n    # Find the top 10 prediction labels\n    top_10_pred_labels = unique_breeds[top_10_pred_indexes]\n\n    # Setup plot\n    top_plot = plt.bar(np.arange(len(top_10_pred_labels)), \n                     top_10_pred_values, color=\"gray\")\n        \n    plt.xticks(np.arange(len(top_10_pred_labels)),\n             labels=top_10_pred_labels, rotation=\"vertical\")\n    \n     # Change color of true label\n    #if np.isin(true_label, top_10_pred_labels):\n    top_plot[np.argmax(top_10_pred_labels == true_label)].set_color(\"green\")\n \n    \n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_pred_conf(prediction_probabilities=predictions,\n               labels=val_labels,\n               n=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's check a few predictions and their different values\ni_multiplier = 0\nnum_rows = 3\nnum_cols = 2\nnum_images = num_rows*num_cols\nplt.figure(figsize=(5*2*num_cols, 5*num_rows))\nfor i in range(num_images):\n  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n  plot_pred(prediction_probabilities=predictions,\n            labels=val_labels,\n            images=val_images,\n            n=i+i_multiplier)\n  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n  plot_pred_conf(prediction_probabilities=predictions,\n                labels=val_labels,\n                n=i+i_multiplier)\nplt.tight_layout(h_pad=1.0)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Saving and reloading a model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime\nimport shutil\n\n#shutil.rmtree(\"./models\")\n\n#Make directory\nshutil.os.mkdir(\"./models\")\n\n\ndef save_model(model, suffix=None):\n    \"\"\"\n    Saves a given model in a models directory and appends a suffix (str)\n    for clarity and reuse.\n    \"\"\"\n    # Create model directory with current time\n    modeldir = os.path.join(\"models\",\n                          datetime.datetime.now().strftime(\"%Y%m%d-%H%M%s\"))\n    model_path = modeldir + \"-\" + suffix + \".h5\" # save format of model\n    print(f\"Saving model to: {model_path}...\")\n    model.save(model_path)\n    return model_path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_model(model_path):\n  \"\"\"\n  Loads a saved model from a specified path.\n  \"\"\"\n  print(f\"Loading saved model from: {model_path}\")\n  model = tf.keras.models.load_model(model_path)\n                                     \n  return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save our model trained on 1000 images\nsave_model(model, suffix=\"1000 images model\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load our model trained on 1000 images\n#model_1000_images = load_model('models/20200815-22211597530072-1000 images model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate the pre-saved model\nmodel.evaluate(val_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate the loaded model\n#model_1000_images.evaluate(val_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Making predictions on the test dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test_filenames = [TEST_DIR +\"/\"+ fname for fname in os.listdir(TEST_DIR)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create test data batch\ntest_data = create_data_batches(test_filenames, test_data=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#take one hour to complete\n\n# Make predictions on test data batch using the loaded full model\ntest_predictions = model.predict(test_data, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check out the test predictions\ntest_predictions[:10]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}