{"nbformat":4,"nbformat_minor":1,"cells":[{"cell_type":"markdown","source":"Please be indulgent with me! It's late when I write this lines so a lot of comments are missing in my code.  I will update this notebook regularly to bring more details :)","metadata":{"_cell_guid":"c7cd2341-230e-4c3e-8d45-4634f0c6cc4c","_uuid":"1fc9e7e4e761de55ed74443f6a080521d3e9baf8","collapsed":true}},{"cell_type":"markdown","source":"You will find below a code to upload the image from the zip file and manipulate them directly.","metadata":{"_cell_guid":"964da2be-24c7-4ea1-87b4-7b8d77e9170c","_uuid":"1cb34b88591bd2ad44e5f83d644251ceda2f3626"}},{"cell_type":"markdown","source":"Step 1 - Import packages\n\nWe import the package which will be used to upload and 'plot' the image.","metadata":{"_cell_guid":"3761ebf7-0190-4412-a259-8c2c0bed7c93","_uuid":"f2779d193aa4cd1200bc362ccf632be5efca3679"}},{"cell_type":"code","outputs":[],"source":"%matplotlib inline\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.misc\nfrom zipfile import ZipFile\nfrom io import BytesIO\n\n# Image manipulation.\nimport PIL.Image\nfrom IPython.display import display","execution_count":null,"metadata":{"_cell_guid":"e7f32b1d-9ffc-424b-82af-80795846527e","_uuid":"719fbe488120ada3f6ec50e1919fc09f50092fa7","_kg_hide-input":false,"collapsed":true,"_kg_hide-output":false}},{"cell_type":"markdown","source":"Step 2 - This is some functions to upload an image from zip file and to resize it.\n\nIndeed, you will see that all the images in the zip file do not have the same dimensions. It could be helpful to resize all the image to the same dimension for our study.","metadata":{"_cell_guid":"731d4ee7-3036-4ab6-a4d0-f3fd2b4201ee","_uuid":"437a6ea3c232cb00f52588c8b96b88ec9df05861"}},{"cell_type":"markdown","source":"- Function to load the image in black and white.\n    I choose to change all the photo in black and white to make it easier (it decrease the number of parameters so that I can run a convolutional neural network on my outdated computer). Of course, you can change it in order to keep the colors.","metadata":{"_cell_guid":"80acb16e-e76b-40fe-a83e-2cc20c24cc8e","_uuid":"f9383a5d8d4cf9b2ced0689067c185a8f5a455d8"}},{"cell_type":"code","outputs":[],"source":"def load_image_blackandwhite(filename):\n    #image = PIL.Image.open(filename)\n\n    image = PIL.Image.open(filename) # open colour image\n    image = image.convert('L') # convert image to black and white\n    image = np.array(image)\n    \n    return np.float32(image)","execution_count":null,"metadata":{"_cell_guid":"9625303f-8bcb-4c8b-b278-c9fa13f55227","_uuid":"e186b7c9ab8d8ae12fab875c06958c2bf39b37d6","collapsed":true}},{"cell_type":"markdown","source":"- Function to plot the image.\nYou will se that I change the value of the pixel. I want them to be between 0 and 1 (you will see later why). You can keep the initial value of each pixel by removing the line \"image = np.clip(image/255.0, 0.0, 1.0)\" and change the line \"plt.imshow(image, interpolation='lanczos')\" by \"plt.imshow(image, cmd='binary')\"","metadata":{"_cell_guid":"528d778e-5455-4ee8-81ba-d9d2d344afa5","_uuid":"4d3bb87560e65feb4979808b567cf8cca81904d8"}},{"cell_type":"code","outputs":[],"source":"def plot_image(image):\n    # Assume the pixel-values are scaled between 0 and 255.\n    \n    # Convert the pixel-values to the range between 0.0 and 1.0\n    image = np.clip(image/255.0, 0.0, 1.0)\n        \n    # Plot using matplotlib.\n    plt.imshow(image, interpolation='lanczos')\n    plt.show()","execution_count":null,"metadata":{"_cell_guid":"8358b6b2-9ec5-4206-8be6-ba34b907791c","_uuid":"9907aa265e601a3b1eab60eca9e13c9fbe83887e","collapsed":true}},{"cell_type":"markdown","source":"- Function to reshape the image","metadata":{"_cell_guid":"f0321032-95f3-4968-a9ff-2b8e46917e3d","_uuid":"624b72ac4648eb24bff047a7a0e86c73710ec539"}},{"cell_type":"code","outputs":[],"source":"def reshape_image(image_file, new_wigth, new_height):\n    \n    ############\n    # Reduce Size of Image\n    ############\n    \n    olddim = np.shape(image_file)\n    img = np.zeros((new_wigth,new_height))\n    newdim = np.shape(img)\n        \n    for r in range(newdim[0]):\n        if (newdim[0] <= olddim[0]):\n            centerx=(r)/newdim[0]*olddim[0]\n            lowerx=max(0,int(round(centerx-olddim[0]/newdim[0]/2,0)))\n            upperx=min(olddim[0],int(round(centerx+olddim[0]/newdim[0]/2,0))+1)\n        else:\n            lowerx=max(0,int(r*olddim[0]/newdim[0]))\n            upperx=min(lowerx+1,olddim[0]-1)+1\n            \n        for c in range(newdim[1]):  \n            if (newdim[1] <= olddim[1]):\n                centery=(c)/newdim[1]*olddim[1]\n                lowery=max(0,int(round(centery-olddim[1]/newdim[1]/2,0)))\n                uppery=min(olddim[1],int(round(centery+olddim[1]/newdim[1]/2,0))+1)\n            else:\n                lowery=max(0,int(c*olddim[1]/newdim[1]))\n                uppery=min(lowery+1,olddim[1]-1)+1\n            img[r,c] = np.mean(image_file[ lowerx:upperx, lowery:uppery ])\n\n                \n    return img","execution_count":null,"metadata":{"_cell_guid":"6e07adcd-f297-4dbf-84a5-9b8bce716d9b","_uuid":"d3a13efb7dc0c039a5c4e224ecb928f02233a864","collapsed":true}},{"cell_type":"markdown","source":"Step 3 - Upload all the images from the zip file","metadata":{"_cell_guid":"8c03891a-d5c6-40fb-995b-42f580cfaaef","_uuid":"238fa55a9287ccdbf7192a8f556928599a613565"}},{"cell_type":"code","outputs":[],"source":"archive = ZipFile(\"../input/train.zip\", 'r')\narchive.namelist()[0:5]","execution_count":null,"metadata":{"_cell_guid":"1075393d-4f5f-4dc1-882c-16866179ba72","_uuid":"4ffc78e4ba46384ac9417949c98ac3c3235b63f1","collapsed":true}},{"cell_type":"markdown","source":"You will obtain the following result:","metadata":{"_cell_guid":"2d518c05-788f-4556-a8ac-6bfb1ed2a127","_uuid":"9405d26f10d78cbc1c3a78a9cb6a60663665fedd"}},{"cell_type":"code","outputs":[],"source":"['train/',\n 'train/000bec180eb18c7604dcecc8fe0dba07.jpg',\n 'train/001513dfcb2ffafc82cccf4d8bbaba97.jpg',\n 'train/001cdf01b096e06d78e9e5112d419397.jpg',\n 'train/00214f311d5d2247d5dfe4fe24b2303d.jpg']","execution_count":null,"metadata":{"_cell_guid":"3fa04064-89b5-4a80-93c7-92307c5a251d","_uuid":"01f916b56a87433e4388acc74f963bbc88f72f7e","collapsed":true}},{"cell_type":"markdown","source":"Let's load and show the image number 150.","metadata":{"_cell_guid":"296b8fea-7547-4140-9b58-76b6d0e9953c","_uuid":"88ab733af152c2b9acbd25597dc899d654a0cbfe"}},{"cell_type":"code","outputs":[],"source":"image = load_image_blackandwhite(filename=BytesIO(archive.read(archive.namelist()[150])))\nimage.shape","execution_count":null,"metadata":{"_cell_guid":"82c306eb-784c-4d50-8f9a-40b67dd7c1e0","_uuid":"7dcb3030459c6f1bfd2b5ba0927526b9d48a44c4","collapsed":true}},{"cell_type":"code","outputs":[],"source":"(500, 333)","execution_count":null,"metadata":{"_cell_guid":"988f2e2c-1b94-4f08-9151-f73b3e99267f","_uuid":"5c1d46ff98cedb3a4fcbbad8a7e67c16c3f56661","collapsed":true}},{"cell_type":"code","outputs":[],"source":"The shape of the image is 500 pixels x 333 pixels. If you try another image, you will see that the shape might change.","execution_count":null,"metadata":{"_cell_guid":"2d19d576-92bf-444e-9a63-a0dd5647c2a2","_uuid":"e5f4ecae4e1d78edacb9465072d82bf1b3594ac4","collapsed":true}},{"cell_type":"code","outputs":[],"source":"plot_image(image)","execution_count":null,"metadata":{"_cell_guid":"f9778117-ab7f-4d31-a8ac-5bcbb5e54b49","_uuid":"ee06037b776eb665621921f8c5b3a3537abfa870","collapsed":true}},{"cell_type":"markdown","source":"You should normally see the image.\nNow let's reshape to a 100 x 100 pixels image. It might be useful if we want to apply it to all the images (so that they can have the same dimension)","metadata":{"_cell_guid":"760eefa4-bf20-4fc4-832a-cdf36ee05bc8","_uuid":"fddb763e20fe5d2d2ca515e04dba0f6b9043eaba"}},{"cell_type":"code","outputs":[],"source":"image_reshaped = reshape_image(image_file=image, new_wigth = 100, new_height = 100)\nplot_image(image_reshaped)","execution_count":null,"metadata":{"_cell_guid":"b7fd33c1-68a3-4306-88d4-5c4a805b5f8c","_uuid":"3189e3c65be24b664db31226e83940e80d352bd3","collapsed":true}},{"cell_type":"markdown","source":"You should now see that the image is now smaller.","metadata":{"_cell_guid":"c1068f31-78a1-4d33-8bb6-11da9f9687eb","_uuid":"5e9bc69625c232ed659d868939ce4a21adbff5c0"}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","pygments_lexer":"ipython3","codemirror_mode":{"version":3,"name":"ipython"},"nbconvert_exporter":"python","file_extension":".py","version":"3.6.3","name":"python"}}}