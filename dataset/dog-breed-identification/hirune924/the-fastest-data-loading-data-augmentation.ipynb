{"cells":[{"metadata":{},"cell_type":"markdown","source":"# OpenCV + Albumentation","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import time\nfrom tqdm.notebook import tqdm\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport cv2\nimport albumentations as A\n\n\nclass DogDataset(Dataset):\n    def __init__(self, transform=None):\n        self.img_list = pd.read_csv('../input/dog-breed-identification/labels.csv')\n        self.transform = transform\n        \n        breeds=list(self.img_list['breed'].unique())\n        self.breed2idx = {b: i for i, b in enumerate(breeds)}\n\n    def __len__(self):\n        return len(self.img_list)\n\n    def __getitem__(self, idx):\n        img_row = self.img_list.iloc[idx]\n        image = cv2.imread('../input/dog-breed-identification/train/' + img_row['id'] + '.jpg')\n        label = self.breed2idx[img_row['breed']]\n\n        if self.transform is not None:\n            image = self.transform(image=image)\n        image = torch.from_numpy(image['image'].transpose(2, 0, 1))\n        return image, label\n\ntransform = A.Compose([A.RandomResizedCrop(height=224, width=224, p=1),\n                       A.HorizontalFlip(p=0.5),\n                       A.VerticalFlip(p=0.5),\n                       A.MotionBlur(blur_limit=3, p=1),\n                       A.Rotate(limit=45, p=1),\n                       A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), max_pixel_value=255.0, always_apply=True, p=1.0)])\n\ndata_loader = DataLoader(DogDataset(transform=transform), batch_size=64, shuffle=True, num_workers=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%timeit -r 2 -n 5\nopencv_alb_times = []\nstart_time = time.time()\nfor image, label in data_loader:\n    image = image.cuda()\n    label = label.cuda()\n    pass\nopencv_alb_time = time.time() - start_time\nopencv_alb_times.append(opencv_alb_time)\nprint(str(opencv_alb_time) + ' sec')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# jpeg4py + Albumentations","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!apt-get install libturbojpeg\n!pip install jpeg4py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nfrom tqdm.notebook import tqdm\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport cv2\nimport albumentations as A\nimport jpeg4py as jpeg\n\n\nclass DogDataset(Dataset):\n    def __init__(self, transform=None):\n        self.img_list = pd.read_csv('../input/dog-breed-identification/labels.csv')\n        self.transform = transform\n        \n        breeds=list(self.img_list['breed'].unique())\n        self.breed2idx = {b: i for i, b in enumerate(breeds)}\n\n    def __len__(self):\n        return len(self.img_list)\n\n    def __getitem__(self, idx):\n        img_row = self.img_list.iloc[idx]\n        image = jpeg.JPEG('../input/dog-breed-identification/train/' + img_row['id'] + '.jpg').decode()\n        label = self.breed2idx[img_row['breed']]\n\n        if self.transform is not None:\n            image = self.transform(image=image)\n        image = torch.from_numpy(image['image'].transpose(2, 0, 1))\n        return image, label\n\ntransform = A.Compose([A.RandomResizedCrop(height=224, width=224, p=1),\n                       A.HorizontalFlip(p=0.5),\n                       A.VerticalFlip(p=0.5),\n                       A.MotionBlur(blur_limit=3, p=1),\n                       A.Rotate(limit=45, p=1),\n                       A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), max_pixel_value=255.0, always_apply=True, p=1.0)])\n\ndata_loader = DataLoader(DogDataset(transform=transform), batch_size=64, shuffle=True, num_workers=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%timeit -r 2 -n 5\njpeg4py_alb_times = []\nstart_time = time.time()\nfor image, label in data_loader:\n    image = image.cuda()\n    label = label.cuda()\n    pass\njpeg4py_alb_time = time.time() - start_time\njpeg4py_alb_times.append(jpeg4py_alb_time)\nprint(str(jpeg4py_alb_time) + ' sec')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# jpeg4py + Kornia","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nfrom tqdm.notebook import tqdm\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport jpeg4py as jpeg\n\nimport albumentations as A\nimport kornia.augmentation as K\nimport torch.nn as nn\n\n\nclass DogDataset(Dataset):\n    def __init__(self, transform=None):\n        self.img_list = pd.read_csv('../input/dog-breed-identification/labels.csv')\n        self.transform = transform\n        \n        breeds=list(self.img_list['breed'].unique())\n        self.breed2idx = {b: i for i, b in enumerate(breeds)}\n\n    def __len__(self):\n        return len(self.img_list)\n\n    def __getitem__(self, idx):\n        img_row = self.img_list.iloc[idx]\n        image = jpeg.JPEG('../input/dog-breed-identification/train/' + img_row['id'] + '.jpg').decode()\n        label = self.breed2idx[img_row['breed']]\n\n        if self.transform is not None:\n            image = self.transform(image=image)\n        image = torch.from_numpy(image['image'].transpose(2, 0, 1).astype(np.float32))\n        return image, label\n\nalb_transform = A.Compose([A.RandomResizedCrop(height=224, width=224, p=1)])\n\nmean_std = torch.Tensor([0.5, 0.5, 0.5])*255\nkornia_transform = nn.Sequential(\n    K.RandomHorizontalFlip(),\n    K.RandomVerticalFlip(),\n    K.RandomMotionBlur(3, 35., 0.5),\n    K.RandomRotation(degrees=45.0),\n    K.Normalize(mean=mean_std,std=mean_std)\n)\n\ndata_loader = DataLoader(DogDataset(transform=alb_transform), batch_size=64, shuffle=True, num_workers=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%timeit -r 2 -n 5\njpeg4py_kornia_times = []\nstart_time = time.time()\nfor image, label in data_loader:\n    image = kornia_transform(image.cuda())\n    label = label.cuda()\n    pass\njpeg4py_kornia_time = time.time() - start_time\njpeg4py_kornia_times.append(jpeg4py_kornia_time)\nprint(str(jpeg4py_kornia_time) + ' sec')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# NVIDIA DALI + Kornia","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!pip install --extra-index-url https://developer.download.nvidia.com/compute/redist nvidia-dali-cuda100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nfrom tqdm.notebook import tqdm\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\n\nimport kornia.augmentation as K\nimport torch.nn as nn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nvidia.dali.pipeline import Pipeline\nfrom nvidia.dali.plugin.pytorch import DALIGenericIterator\nimport nvidia.dali.ops as ops\nimport nvidia.dali.types as types","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DALIPipeline(Pipeline):\n    def __init__(self, batch_size, num_threads, device_id):\n        super(DALIPipeline, self).__init__(batch_size, num_threads, device_id)\n        self.img_list = pd.read_csv('../input/dog-breed-identification/labels.csv')\n\n        breeds=list(self.img_list['breed'].unique())\n        self.breed2idx = {b: i for i, b in enumerate(breeds)}\n        \n        self.img_list['label'] = self.img_list['breed'].map(self.breed2idx)\n        self.img_list['data'] = '../input/dog-breed-identification/train/' + self.img_list['id'] + '.jpg'\n        \n        self.img_list[['data', 'label']].to_csv('dali.txt', header=False, index=False, sep=' ')\n        \n        self.input = ops.FileReader(file_root='.', file_list='dali.txt')\n        self.decode = ops.ImageDecoder(device = \"mixed\", output_type = types.DALIImageType.RGB)\n        #self.decode = ops.ImageDecoderRandomCrop(device = \"mixed\", output_type = types.DALIImageType.RGB)\n        self.resize = ops.RandomResizedCrop(device = \"gpu\", size=(224, 224))\n        self.transpose = ops.Transpose(device='gpu', perm = [2, 0, 1])\n        self.cast = ops.Cast(device='gpu', dtype=types.DALIDataType.FLOAT)\n\n    def define_graph(self):\n        images, labels = self.input(name=\"Reader\")\n        images = self.decode(images)\n        images = self.resize(images)\n        images = self.cast(images)\n        output = self.transpose(images)\n        return (output, labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def DALIDataLoader(batch_size):\n    num_gpus = 1\n    pipes = [DALIPipeline(batch_size=batch_size, num_threads=2, device_id=device_id) for device_id in range(num_gpus)]\n\n    pipes[0].build()\n    dali_iter = DALIGenericIterator(pipelines=pipes, output_map=['data', 'label'], \n                                    size=pipes[0].epoch_size(\"Reader\"), reader_name=None, \n                                    auto_reset=True, fill_last_batch=True, dynamic_shape=False, \n                                    last_batch_padded=True)\n    return dali_iter\n\ndata_loader = DALIDataLoader(batch_size=64)\n\nmean_std = torch.Tensor([0.5, 0.5, 0.5])*255\nkornia_transform = nn.Sequential(\n    K.RandomHorizontalFlip(),\n    K.RandomVerticalFlip(),\n    K.RandomMotionBlur(3, 35., 0.5),\n    K.RandomRotation(degrees=45.0),\n    K.Normalize(mean=mean_std,std=mean_std)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%timeit -r 2 -n 5\ndali_kornia_times = []\nstart_time = time.time()\nfor feed in data_loader:\n    # image is already on GPU\n    image = kornia_transform(feed[0]['data'])\n    label = feed[0]['label'].cuda()\n    pass\ndali_kornia_time = time.time() - start_time\ndali_kornia_times.append(dali_kornia_time)\nprint(str(dali_kornia_time) + ' sec')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n \nleft = np.array([1, 2, 3, 4])\nheight = np.array([71, 41.5, 26.2, 8.1])\nlabel = [\"OpenCV\\n+\\nAlbumentations\", \"jpeg4py\\n+\\nAlbumentations\", \"jpeg4py\\n+\\nKornia\", \"NVIDIA DALI\\n+\\nKornia\"]\nplt.bar(left, height, tick_label=label, align=\"center\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}