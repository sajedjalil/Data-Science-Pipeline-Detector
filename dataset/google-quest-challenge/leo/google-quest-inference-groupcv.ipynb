{"cells":[{"metadata":{},"cell_type":"markdown","source":"## using group multilabel stratified kfold CV"},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python ../input/gq-inf-scripts-gmkf/tf_bert_large_inf.py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python ../input/gq-inf-scripts-gmkf/tf_bert_base_inf.py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python ../input/gq-inf-scripts-gmkf/pytorch_feat_inf.py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !python ../input/gq-inf-scripts/pytorch_albert_inf.py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !python ../input/gq-inf-scripts/pytorch_bert_inf.py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy.stats import spearmanr, rankdata\nfrom scipy.optimize import minimize\nfrom collections import defaultdict\n\nkf = np.load(\"../input/split-dataset/GroupMultilabelStratifiedKfold.npy\", allow_pickle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/google-quest-challenge/train.csv')\nsub_df = pd.read_csv('../input/google-quest-challenge/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model_names = [\"albert\", \"bert_base\", \"tf_bert_large\", \"feat_multi\", \"feat_nn\",\n#                \"tf_bert_base_epoch1\", \"tf_bert_base_epoch2\", \"tf_bert_base_epoch3\"]\nmodel_names = [\"feat_multi\", \"feat_nn\", \"tf_bert_large\",\n               \"tf_bert_base_epoch1\", \"tf_bert_base_epoch2\", \"tf_bert_base_epoch3\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_spearmanr(trues, preds):\n    rhos = []\n    for col_true, col_pred in zip(trues.T, preds.T):\n        rhos.append(spearmanr(col_true, col_pred + np.random.normal(0, 1e-7, col_pred.shape[0])).correlation)\n    return np.mean(rhos)\n\n# def compute_spearmanr(trues, preds, columns=None):\n#     rhos = []\n#     for i, (col_true, col_pred) in enumerate(zip(trues.T, preds.T)):\n#         if i == 0:\n#             # qa_id\n#             continue\n#         r = spearmanr(col_true, col_pred).correlation\n#         if columns:\n#             print(\"{:.3f}\\t{}\".format(r, columns[i]))\n#         rhos.append(r)\n#     return np.mean(rhos)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_columns = list(sub_df.columns)\n\nresults = []\nfor fold_i in range(1, 6):\n    result_df = pd.DataFrame(index=model_names, columns=target_columns[-30:] + [\"ave\"])\n    for model_name in model_names:\n        for target in target_columns[-30:]:\n            true = train_df[target_columns].iloc[kf[fold_i-1][1]].reset_index(drop=True)\n            oof = pd.read_csv(model_name + f\"/oof{fold_i}.csv\")\n            r = spearmanr(true[target].values, oof[target].values + np.random.normal(0, 1e-7, oof.shape[0])).correlation\n            result_df.loc[model_name, target] = r\n        result_df.loc[model_name, \"ave\"] = np.mean(result_df.loc[model_name, target_columns[-30:]].values)\n    results.append(result_df)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# optimize model weight\n\ndef norm_with_rankdata(df):\n    for col_name in target_columns[-30:]:\n        df[col_name] = rankdata(df[col_name].values) / len(df)\n    return df\n\nkfold = 5\nmodel_number = len(model_names)\n\ntrue_dfs = []\nfor i in range(5):\n    oof = train_df.iloc[kf[i][1]]\n    true_dfs.append(oof[target_columns])\n\nmodel_df = defaultdict(lambda: [])\nfor model_name in model_names:\n    print(model_name)\n\n    scores = []\n    pred_dfs = []\n\n    for i in range(5):\n        pred = pd.read_csv(f\"{model_name}/oof{i+1}.csv\")\n        pred = norm_with_rankdata(pred)\n        model_df[model_name].append(pred)\n        true = true_dfs[i]\n        rho = compute_spearmanr(true.values, pred.values)\n        scores.append(rho)\n        pred_dfs.append(pred.copy())\n    print([f\"fold{i+1}: {scores[i]:.4}\" for i in range(5)])\n    \nscores = [{} for _ in range(kfold)]\nall_coeffs = []\n\nfor col_num, col_name in enumerate(target_columns[-30:]):\n    coefficients = np.zeros((kfold, model_number))\n    print(col_name, \"\\n\")\n    for fold_num, (_, vld_idx) in enumerate(kf): \n        print(\"\\n\"+\"-\"*50+'\\n[Fold {}/{}]'.format(fold_num + 1, kfold))\n        # optimize function\n        def function_spearmanr(x):\n            true = true_dfs[fold_num].loc[:, col_name].values\n            pred = np.zeros(len(true))\n            for k, (model_name, df) in enumerate(model_df.items()):\n                pred += x[k] * df[fold_num].loc[:, col_name].values\n            return -spearmanr(true, pred).correlation\n\n        # initial weights\n        x0 = [1 for _ in range(model_number)]\n        # optimize\n        res = minimize(function_spearmanr, x0, method='nelder-mead', options={'xtol': 1e-4, 'disp': True})\n        # normalize sum(weights) = 1.0\n        coeffs = [max(val, 0) for val in res.x]\n        coefficients[fold_num,:] = coeffs / np.sum(coeffs)\n        print('\\nfinal vector: {}'.format(coefficients[fold_num,:]))\n\n        y_true = true_dfs[fold_num].loc[:, col_name].values\n        y_pred = np.zeros(len(y_true))\n        for k, (model_name, df) in enumerate(model_df.items()):\n            y_pred += coefficients[fold_num, k] * df[fold_num].loc[:, col_name].values\n\n        score = spearmanr(y_true, y_pred).correlation\n        scores[fold_num][col_name] = score\n        print(f\"valid's spearmanr: {score:<7.4f} \\n\")\n    all_coeffs.append(coefficients)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.mean(np.array([list(s.values()) for s in scores]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ensamble\nsub_df = pd.read_csv(\"../input/google-quest-challenge/sample_submission.csv\")\nsubmission = np.zeros((len(sub_df), 30)).T\n\n# load each submission.csv\nFOLD_NUM = 5\ninf_sub = []\nfor fold_num in range(FOLD_NUM):\n    l = []\n    for model_num, model_name in enumerate(model_names):\n        sub_ = pd.read_csv(f\"{model_name}/submission{fold_num+1}.csv\")\n        sub_ = norm_with_rankdata(sub_)\n        l.append(sub_.copy())\n    inf_sub.append(l.copy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col_num, col_name in enumerate(target_columns[-30:]):\n    for fold_num in range(FOLD_NUM): \n        for model_num in range(len(model_names)):\n            coef = all_coeffs[col_num][fold_num][model_num]\n            submission[col_num] += coef / FOLD_NUM * inf_sub[fold_num][model_num][col_name].values\n\nsub_df.iloc[:, -30:] = submission.T\nsub_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.max(sub_df.iloc[:, -30:].values), np.min(sub_df.iloc[:, -30:].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def norm_sub(df):\n    for col_name in df.columns[-30:]:\n        tmp_df = df[col_name].values\n        v_max = np.max(tmp_df) + 0.01\n        v_min = np.min(tmp_df) - 0.01\n        df[col_name] = df[col_name].apply(lambda x: (x - v_min) / (v_max - v_min))\n        df[col_name] = df[col_name].values + np.random.normal(0, 1e-7, len(df))\n    return df\nsub_df = norm_sub(sub_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.max(sub_df.iloc[:, -30:].values), np.min(sub_df.iloc[:, -30:].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # check bug\n# debug_sub_files = [\"submission_230.csv\", \"submission_253.csv\", \"submission_288.csv\", \"submission_301.csv\", \n#                    \"submission_305.csv\", \"submission_335.csv\", \"submission_342.csv\", \"submission_350.csv\"]\n# for model_num, model_name in enumerate(model_names):\n#     try:\n#         for i in range(1, 6):\n#             tmp = pd.read_csv(f\"{model_name}/oof{i}.csv\")\n#             tmp = pd.read_csv(f\"{model_name}/submission{i}.csv\")\n#     except:\n#         debug_sub = pd.read_csv(f\"../input/gq-debug/{debug_sub_files[model_num]}\")\n#         sub_df = pd.merge(sub_df[\"qa_id\"], debug_sub, on=\"qa_id\", how='outer')\n#         sub_df = sub_df.fillna(0)\n#         sub_df = norm_sub(sub_df)\n#         break\n# sub_df.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport scipy as sp\nfrom collections import defaultdict\nfrom functools import partial\n\ndef compute_actual_spearmanr(trues, preds):\n    rhos = []\n    for col_true, col_pred in zip(trues.T, preds.T):\n        rhos.append(spearmanr(col_true, col_pred).correlation)\n    return np.mean(rhos)\n\nclass OptimizedRounder(object):\n    # inputs are between 0 to 1\n    # n is number of annotator + 1\n    def __init__(self, n):\n        self.coef_ = 0\n        self.n = n\n\n    def _kappa_loss(self, coef, X, y):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n                continue\n            for i in range(self.n-2):\n                if coef[i] <= pred and pred < coef[i+1]:\n                    X_p[i] = (i + 1) / (self.n - 1)\n                    break\n            else:\n                X_p[i] = 1\n\n        ll = spearmanr(y, X_p).correlation\n        return -ll\n\n    def fit(self, X, y, init_coef=None):\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        if init_coef == None:\n            initial_coef = [1/self.n * (x+1) for x in range(self.n-1)]\n        else:\n            initial_coef = init_coef\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n\n    def predict(self, X, coef):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n                continue\n            for i in range(self.n-2):\n                if coef[i] <= pred and pred < coef[i+1]:\n                    X_p[i] = (i + 1) / (self.n - 1)\n            else:\n                X_p[i] = 1\n        return X_p\n\n    def coefficients(self):\n        return self.coef_['x']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class color:\n   PURPLE = '\\033[95m'\n   CYAN = '\\033[96m'\n   DARKCYAN = '\\033[36m'\n   BLUE = '\\033[94m'\n   GREEN = '\\033[92m'\n   YELLOW = '\\033[93m'\n   RED = '\\033[91m'\n   BOLD = '\\033[1m'\n   UNDERLINE = '\\033[4m'\n   END = '\\033[0m'\n\ndef compute_spearmanr(trues, preds, columns=None):\n    rhos = []\n    for i, (col_true, col_pred) in enumerate(zip(trues.T, preds.T)):\n        if i == 0:\n            # qa_id\n            continue\n        r = spearmanr(col_true, col_pred).correlation\n        if columns:\n            print(\"{:.3f}\\t{}\".format(r, columns[i-1]))\n        rhos.append(r)\n    return np.mean(rhos)\n\ndef compare_spearmanr(trues, preds, pp_preds, columns=None):\n    rhos = []\n    pp_rhos = []\n    for i, (col_true, col_pred, col_pp_pred) in enumerate(zip(trues.T, preds.T, pp_preds.T)):\n        if i == 0:\n            # qa_id\n            continue\n        r = spearmanr(col_true, col_pred).correlation\n        pp_r = spearmanr(col_true, col_pp_pred).correlation\n        if columns:\n            if r < pp_r:\n                print(\"{:.3f} ->\".format(r) + color.BOLD +  \" {:.3f}\".format(pp_r) + color.END + \" \\t{}\".format(columns[i-1]))\n            elif (r - pp_r) < 10**(-6):\n                print(\"{:.3f} ->\".format(r) + \" {:.3f}\".format(pp_r) +  \" \\t{}\".format(columns[i-1]))\n            else:\n                print(\"{:.3f} ->\".format(r) + color.RED +  \" {:.3f}\".format(pp_r) + color.END + \" \\t{}\".format(columns[i-1]))\n\n        rhos.append(r)\n        pp_rhos.append(pp_r)\n    whole_base = np.mean(rhos)\n    whole_pp = np.mean(pp_rhos)\n    print(\"Whole Score\")\n    if whole_base < whole_pp:\n        print(\"{:.3f} ->\".format(whole_base) + color.BOLD +  \" {:.3f}\".format(whole_pp) + color.END + \" +{}\".format(abs(whole_pp - whole_base)))\n    elif (whole_base - whole_pp ) < 10**(-6):\n        print(\"{:.3f} ->\".format(whole_base) + \" {:.3f}\".format(whole_pp))\n    else:\n        print(\"{:.3f} ->\".format(whole_base) + color.RED +  \" {:.3f}\".format(whole_pp) + color.END + \" -{}\".format(abs(whole_pp - whole_base)))\n    return whole_base, whole_pp\n\ndef inf_numbert_of_annotators(v):\n    s = set(v)\n    d = 10\n\n    for v in s:\n        for u in s:\n            if v != u:\n                d = min(abs(v - u), d)\n    for i in range(100):\n        if d * i >= 1 - 10**(-3):\n            return i\n\ndef zero_one_scale(v):\n    max_x = np.max(v)\n    min_x = np.min(v)\n    return (v - min_x) / (max_x - min_x)\n\n\n# check postprocess score with oof\noofs = []\nfor fold_num in range(FOLD_NUM):\n    oof_ = np.zeros((len(model_df[model_names[0]][fold_num]), 30)).T\n    for col_num, col_name in enumerate(target_columns[-30:]):\n        for model_num, model_name in enumerate(model_names):\n            coef = all_coeffs[col_num][fold_num][model_num]\n            oof_[col_num] += coef * model_df[model_name][fold_num][col_name].values\n    oofs.append(oof_.T)\n\ngold_label_df = train_df[target_columns]\npred_label_df = gold_label_df.copy()\n\nfor fold_num in range(5):\n    pred_label_df.loc[kf[fold_num][1], target_columns[1:]] = oofs[fold_num]\npred_label_df = norm_with_rankdata(pred_label_df)\n\n\ndef post_process(train_df, train, pred_df):\n    # print(len(train), len(pred_df))\n    df = pred_df.copy()\n\n    df.loc[(train[\"host\"] != \"english.stackexchange.com\") & (train[\"host\"] != \"ell.stackexchange.com\"), \"question_type_spelling\"] = 0\n\n    df = norm_with_rankdata(df)\n\n    # question_type_spelling not english or ell\n\n    # 0-1 scalingã€€\n    for col_name in target_columns[1:]:\n        d = defaultdict(int)\n        for v in gold_label_df[col_name].values:\n            d[v] += 1\n        d = sorted(d.items())\n        data_length = len(gold_label_df)\n\n        coefs = []\n        for i, (_, v) in enumerate(d[:-1]):\n            v_ = v / data_length\n            if i > 0:\n                v_ += coefs[i-1]\n            coefs.append(v_)\n\n        n = inf_numbert_of_annotators(train_df[col_name].values)\n        gold = gold_label_df[col_name].values\n        pred = pred_label_df[col_name].values\n        base_score = spearmanr(gold, pred).correlation\n\n        optR = OptimizedRounder(len(d))\n        optR.fit(pred, gold, coefs)\n        opt_v = optR.predict(pred, optR.coefficients())\n        opt_score = spearmanr(gold, opt_v).correlation\n        if base_score < opt_score and n < 10:\n            df[col_name] = optR.predict(df[col_name].values, coefs)\n\n        if len(set(df[col_name].values)) == 1:\n            df[col_name] = pred_df[col_name].values\n\n    df.loc[((train[\"host\"] == \"english.stackexchange.com\") | (train[\"host\"] == \"ell.stackexchange.com\")), \"question_type_spelling\"] += 0.1\n\n    df[\"question_type_spelling\"] = zero_one_scale(df[\"question_type_spelling\"].values)\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/google-quest-challenge/train.csv')\ntest_df = pd.read_csv('../input/google-quest-challenge/test.csv')\n\nsub_df = post_process(train_df, test_df, sub_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_score = 0\n\nfor fold_num in range(FOLD_NUM):\n    fold_base = model_df[model_names[0]][fold_num].copy()\n    fold_base.iloc[:, -30:] = oofs[fold_num]\n    r = compute_spearmanr(true_dfs[fold_num].iloc[:, -30:].values, fold_base.iloc[:, -30:].values)\n    cv_score += r / FOLD_NUM\nprint(cv_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_score = 0\nfor fold_num in range(FOLD_NUM):\n    fold_base = model_df[model_names[0]][fold_num].copy()\n    fold_base.iloc[:, -30:] = oofs[fold_num]\n    fold_base = post_process(train_df, train_df.iloc[kf[fold_num][1]].reset_index(drop=True), fold_base)\n    r = compute_actual_spearmanr(true_dfs[fold_num].iloc[:, -30:].values, fold_base.iloc[:, -30:].values)\n    cv_score += r / FOLD_NUM\nprint(cv_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df[sub_df[\"question_type_spelling\"] > 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.max(sub_df.iloc[:, -30:].values), np.min(sub_df.iloc[:, -30:].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}