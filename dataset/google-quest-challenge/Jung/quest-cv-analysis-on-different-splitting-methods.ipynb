{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. This notebook is about \"Splitting and CV\"\nGood day everybody! In this competition, one important aspect is that **\"Public LB is based on 13% of total test data, which is only 476 examples\"**. So it is intuitively clear that our own CV score is more reliable than public LB, e.g. if we do 5-folds split, we will have 20% of training data, around 1200 examples. Moreover, we can average over 5-folds and get even more reliable number, right? It seems to me that in this *imbalance-multi-label* problem (explained below), splitting is not easy. So in this notebook, we will investigate and compare 3 splitting approaches which I know of:\n\n- `KFold`\n- `GroupKFold`\n- `MultilabelStratifiedKFold`\n\nThe goal of this notebook is to compare CV from these methods among themselves, and also to Public LB. Since this notebook is not about optimizing LB, we will save time by using a very fast model training from [@abhishek's kernel](https://www.kaggle.com/abhishek/distilbert-use-features-oof) which in turn originated from [@abazdyrev's kernel](https://www.kaggle.com/abazdyrev/use-features-oof). \n\n**We will see that this same model will have different CV behaviors depending on splitting methods. Therefore, when talking about CV vs. LB, it's important to understand this different behaviors. In particular, when teaming up with other people, be sure that different CV calculation (if any) will not mislead your team.**\n\nNote that this is all I know about splitting. At the end of the article, if anybody know a better method, or have better insights, and would like to share in the comment section, it will be very much appreciate!!\n"},{"metadata":{},"cell_type":"markdown","source":"## 1.1 Should we simply do K-folds split?\nSo we should just use `sklearn.model_selection.KFold` and that's all? Unfortunately, in this problem, they are at least two subtleties which we have to be careful!\n\n### Problem A. There can be leakage between train and validation\nThis [nice EDA kernel](https://www.kaggle.com/sediment/a-gentle-introduction-eda-tfidf-word2vec) shows that there are some questions that appear many times (with different answers each time). For example the most frequent question is\n\n> What is the best introductory Bayesian statistics?\n\nwhich appears 12 times in the training set. Therefore, this means that **if we split the data naively, this same question can be in both train and valid sets, and since many labels are related to \"questions\", there will be leakage between train and valid sets**.\n\n> So naive `KFold` can give you an over-estimated CV\n\n## 1.2 GroupKFold\n\nIn contrast, this [top kernel](https://www.kaggle.com/akensert/bert-base-tf2-0-minimalistic) from my friend @akensert smartly avoid this problem by using `sklearn.model_selection.GroupKFold` instead! By using `GroupKFold` it is possible to guarantee that *all data with the same question, will always stay in the same fold*. Therefore, the above leakage will not happen, and CV is more likely to be more accurate compared to `KFold`.\n\nSo does `GroupKFold` solve the problem? In my understanding, unfortunately, we will face the other issue instead. As we can see from his kernel (Version 5), that in some fold, we cannot get the CV score! (`nan`). Why does this happen ??\n\n### Problem B. Some labels having very few non-zero values, possibly causes `spearmanr = nan`\nConcretely, if you take a look at the label `question_type_spelling`, there will be only 11 / 6079 non-zero values!!! That's are very few! And if we are not careful it will make CV score `nan` (explained below)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\ndf_train = pd.read_csv(\"../input/google-quest-challenge/train.csv\").fillna(\"none\")\nspell = df_train['question_type_spelling'].values\nprint('There is only %d from %d examples!!!' % (np.sum(spell > 0), len(spell)))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Moreover, if we print these 11 examples out we can see that they come from only 8 questions. Therefore, when we use`GroupKFold`, there can be some fold which have no example of positive value on `question_type_spelling` label at all. Note that in this multi-label problem, there are other labels having (less extreme) this kind of imbalance distribution too."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[spell > 0]['question_title'].sort_values().values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The problem is, if some fold has only 0-value of `question_type_spelling`, the calculation of spearman correlation will results in `nan`. Informally speaking, a correlation is related to a **slope** of 'best linear regression' between true values and predict values. Therefore, if either true or predict sets contains only one value, the slope is not well-defined."},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import spearmanr\nprint(spearmanr([1,2,3],[-0.00005,-0.00005,0]).correlation)\nprint(spearmanr([1,2,3],[-5,-5,-5]).correlation)\nprint(spearmanr([1,1,1],[-5,-4,-3]).correlation)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Therefore, \n\n> `GroupKFold` has higher chance than `KFold` to get `nan` especially when increasing the `NUM_FOLDS` number\n\nAnd we have to be careful, when we *average* the `GroupKFold` performance, not to include the nan fold, (You will see later that `np.nanmean()` will not help too).\n\n## 1.3 Multi-label Stratified-KFold\nUnlike the above two methods, `MultilabelStratifiedKFold` is designed directly for multi-labels problem. It will try to make *each fold have similar number of examples for each label*. Therefore, `MultilabelStratifiedKFold` is a method with the least chance to have  `nan` problem. Also, it should give the most stable estimation since the label distributions are similar (less biased toward extreme) to all folds.\n\nHowever,it still have a leakage problem. So we still have a possibly over-estimated CV value. Here is [a very good slide](https://www.slideshare.net/tsoumakas/on-the-stratification-of-multilabel-data) explaining how it work.\n\nIn order to use `MultilabelStratifiedKFold` offline, you can use this script which copied from the [original repo](https://github.com/trent-b/iterative-stratification)\n\n- https://www.kaggle.com/ratthachat/ml-stratifiers (In your notebook/kernel --> **go to File, and select \"Adding utility script\"**). Please upvote it if you find it useful :)\n"},{"metadata":{},"cell_type":"markdown","source":"# 2. Take-away message \n\n## 2.1 CV vs. LB\nFor anybody who doesn't want to bother with the detailed experiments below, I summarize the main finding here. This summary is based on the fact that the baseline got 0.36x LB (after removing Elastic Network).\n\n(1) For small number of folds e.g. `NUM_FOLDS=4` both `KFold` and `MultilabelStratifiedKFold` give similar CV results. I found CV is consistently around 0.02x more than LB possibly due to the leakage problem mentioned above. (If you choose an unlucky SEED, `KFold` can also give `nan` in some fold) \n\nIn contrast, `GroupKFold` has much more chance to have a `nan` CV, and this is true with the default `SEED=42`. If we ignore the nan-fold, we will get a smaller gap of 0.01x between CV and LB. This should be because `GroupKFold` doesn't have the mentioned leakage problem. However, I also note that using `np.nanmean()` to average the results can lead to over-estimated CV. Therefore, do not use `np.nanmean()`.\n\n(2) When `NUM_FOLDS=10`, `GroupKFold` will inevitably has at least two nan-folds due to its definition. In `SEED=42`, `KFold` will also face `nan`. Only `MultilabelStratifiedKFold` will not have a nan fold. Moreover, `MultilabelStratifiedKFold` should give the most stable estimation since the label distributions are similar (less biased toward extreme) to all folds.\n\n## 2.2 Be careful, when teaming up !\nDoes not mean to discourage about teaming up, but I think we should make sure that all people in the same team use the same CV methodology, since if one person gets over-estimated CV, and another person gets less-over-estimated CV, it can mislead the team's best combination.\n\nAnother issue is that this problem is quite small, so one person alone can train many models. But there is a 2-hours running-time limitation, so the team should handle number of inference models for each member carefully.\n\n### My personal note\n- I would like to avoid `nan` completely, so I personally go to `MultilabelStratifiedKFold`. Therefore, my own CV will always be a bit over-score (gap around 0.02x). But still LB and CV are very consistent. Whenever CV increase, I always observe LB increases in similar magnitudes."},{"metadata":{},"cell_type":"markdown","source":"# 3. Experiments Outline\n\nAs mentioned, we will compare different CVs of [@abhishek's kernel](https://www.kaggle.com/abhishek/distilbert-use-features-oof) which got LB 0.36x (removing Elastic Network to speed up). We will run the following 6 experiments.\n\n### 4-fold splitting for the 3 methods. \nHere, you will see that \n- both `KFold` and `MultilabelStratifiedKFold` have the leakage problem, so CVs are around 0.38x. But they will not have `nan` problem. Therefore, there are around 0.02x gap for these methods.\n- `GroupKFold` will have `nan` in one fold. In this case, if we ignore the `nan` fold, we will get CV 0.37x which is closer to LB. Therefore, ignoring `nan`,  there are around 0.01x gap for this method. This observation consistent with [@akensert's kernel](https://www.kaggle.com/akensert/bert-base-tf2-0-minimalistic) where he got average CV around 0.39x with LB 0.382 (Version 9).\n- I tried to use `np.nanmean()` to average over the nan-fold, but the result is misleading. It usually lead to 0.4x to even 0.5 CV. And I don't yet understand why this happen.\n\n### 10-fold splitting for the 3 methods.\nHere, when we increase the number of folds to 10, you will see that \n- both `KFold` and `GroupKFold` will have `nan` problem. But there will be 3-4 `nan` folds for `GroupKFold`.\n- `MultilabelStratifiedKFold` will have no `nan`, but still have a bit over-estimated CV (around 0.02x gap)."},{"metadata":{},"cell_type":"markdown","source":"## 3.1 Here's we begin the main code\nSince the main code is very similar to the original kernel, I hide most of the cells."},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install ../input/sacremoses/sacremoses-master/ > /dev/null\n\nimport os\nimport sys\nimport glob\nimport torch\n\nsys.path.insert(0, \"../input/transformers/transformers-master/\")\nimport transformers\nimport math","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is how we import the 3 splitting methods"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"from ml_stratifiers import MultilabelStratifiedShuffleSplit, MultilabelStratifiedKFold\nfrom sklearn.model_selection import StratifiedKFold, KFold, GroupKFold\nSEED = 42\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def chunks(l, n):\n    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n    for i in range(0, len(l), n):\n        yield l[i:i + n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def fetch_vectors(string_list, batch_size=64):\n    # inspired by https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/\n    DEVICE = torch.device(\"cuda\")\n    tokenizer = transformers.DistilBertTokenizer.from_pretrained(\"../input/distilbertbaseuncased/\")\n    model = transformers.DistilBertModel.from_pretrained(\"../input/distilbertbaseuncased/\")\n    model.to(DEVICE)\n\n    fin_features = []\n    for data in chunks(string_list, batch_size):\n        tokenized = []\n        for x in data:\n            x = \" \".join(x.strip().split()[:300])\n            tok = tokenizer.encode(x, add_special_tokens=True)\n            tokenized.append(tok[:512])\n\n        max_len = 512\n        padded = np.array([i + [0] * (max_len - len(i)) for i in tokenized])\n        attention_mask = np.where(padded != 0, 1, 0)\n        input_ids = torch.tensor(padded).to(DEVICE)\n        attention_mask = torch.tensor(attention_mask).to(DEVICE)\n\n        with torch.no_grad():\n            last_hidden_states = model(input_ids, attention_mask=attention_mask)\n\n        features = last_hidden_states[0][:, 0, :].cpu().numpy()\n        fin_features.append(features)\n\n    fin_features = np.vstack(fin_features)\n    return fin_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(\"../input/google-quest-challenge/train.csv\").fillna(\"none\")\ndf_test = pd.read_csv(\"../input/google-quest-challenge/test.csv\").fillna(\"none\")\n\nsample = pd.read_csv(\"../input/google-quest-challenge/sample_submission.csv\")\ntarget_cols = list(sample.drop(\"qa_id\", axis=1).columns)\n\ntrain_question_body_dense = fetch_vectors(df_train.question_body.values)\ntrain_answer_dense = fetch_vectors(df_train.answer.values)\n\ntest_question_body_dense = fetch_vectors(df_test.question_body.values)\ntest_answer_dense = fetch_vectors(df_test.answer.values)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import os\nimport re\nimport gc\nimport pickle  \nimport random\nimport keras\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport keras.backend as K\n\nfrom keras.models import Model\nfrom keras.layers import Dense, Input, Dropout, Lambda\nfrom keras.optimizers import Adam\nfrom keras.callbacks import Callback\nfrom scipy.stats import spearmanr, rankdata\nfrom os.path import join as path_join\nfrom numpy.random import seed\nfrom urllib.parse import urlparse\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import MultiTaskElasticNet\n\nseed(42)\ntf.random.set_seed(42)\nrandom.seed(42)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data_dir = '../input/google-quest-challenge/'\ntrain = pd.read_csv(path_join(data_dir, 'train.csv'))\ntest = pd.read_csv(path_join(data_dir, 'test.csv'))\nprint(train.shape, test.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"targets = [\n        'question_asker_intent_understanding',\n        'question_body_critical',\n        'question_conversational',\n        'question_expect_short_answer',\n        'question_fact_seeking',\n        'question_has_commonly_accepted_answer',\n        'question_interestingness_others',\n        'question_interestingness_self',\n        'question_multi_intent',\n        'question_not_really_a_question',\n        'question_opinion_seeking',\n        'question_type_choice',\n        'question_type_compare',\n        'question_type_consequence',\n        'question_type_definition',\n        'question_type_entity',\n        'question_type_instructions',\n        'question_type_procedure',\n        'question_type_reason_explanation',\n        'question_type_spelling',\n        'question_well_written',\n        'answer_helpful',\n        'answer_level_of_information',\n        'answer_plausible',\n        'answer_relevance',\n        'answer_satisfaction',\n        'answer_type_instructions',\n        'answer_type_procedure',\n        'answer_type_reason_explanation',\n        'answer_well_written'    \n    ]\n\ninput_columns = ['question_title', 'question_body', 'answer']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Features"},{"metadata":{},"cell_type":"markdown","source":"Here we construct features from **Universal Sentence Encoder** and some smart extra features credited to original authors mentioned above."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"find = re.compile(r\"^[^.]*\")\n\ntrain['netloc'] = train['url'].apply(lambda x: re.findall(find, urlparse(x).netloc)[0])\ntest['netloc'] = test['url'].apply(lambda x: re.findall(find, urlparse(x).netloc)[0])\n\nfeatures = ['netloc', 'category']\nmerged = pd.concat([train[features], test[features]])\nohe = OneHotEncoder()\nohe.fit(merged)\n\nfeatures_train = ohe.transform(train[features]).toarray()\nfeatures_test = ohe.transform(test[features]).toarray()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"module_url = \"../input/universalsentenceencoderlarge4/\"\nembed = hub.load(module_url)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"embeddings_train = {}\nembeddings_test = {}\nfor text in input_columns:\n    print(text)\n    train_text = train[text].str.replace('?', '.').str.replace('!', '.').tolist()\n    test_text = test[text].str.replace('?', '.').str.replace('!', '.').tolist()\n    \n    curr_train_emb = []\n    curr_test_emb = []\n    batch_size = 4\n    ind = 0\n    while ind*batch_size < len(train_text):\n        curr_train_emb.append(embed(train_text[ind*batch_size: (ind + 1)*batch_size])[\"outputs\"].numpy())\n        ind += 1\n        \n    ind = 0\n    while ind*batch_size < len(test_text):\n        curr_test_emb.append(embed(test_text[ind*batch_size: (ind + 1)*batch_size])[\"outputs\"].numpy())\n        ind += 1    \n        \n    embeddings_train[text + '_embedding'] = np.vstack(curr_train_emb)\n    embeddings_test[text + '_embedding'] = np.vstack(curr_test_emb)\n    \ndel embed\nK.clear_session()\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"l2_dist = lambda x, y: np.power(x - y, 2).sum(axis=1)\n\ncos_dist = lambda x, y: (x*y).sum(axis=1)\n\ndist_features_train = np.array([\n    l2_dist(embeddings_train['question_title_embedding'], embeddings_train['answer_embedding']),\n    l2_dist(embeddings_train['question_body_embedding'], embeddings_train['answer_embedding']),\n    l2_dist(embeddings_train['question_body_embedding'], embeddings_train['question_title_embedding']),\n    cos_dist(embeddings_train['question_title_embedding'], embeddings_train['answer_embedding']),\n    cos_dist(embeddings_train['question_body_embedding'], embeddings_train['answer_embedding']),\n    cos_dist(embeddings_train['question_body_embedding'], embeddings_train['question_title_embedding'])\n]).T\n\ndist_features_test = np.array([\n    l2_dist(embeddings_test['question_title_embedding'], embeddings_test['answer_embedding']),\n    l2_dist(embeddings_test['question_body_embedding'], embeddings_test['answer_embedding']),\n    l2_dist(embeddings_test['question_body_embedding'], embeddings_test['question_title_embedding']),\n    cos_dist(embeddings_test['question_title_embedding'], embeddings_test['answer_embedding']),\n    cos_dist(embeddings_test['question_body_embedding'], embeddings_test['answer_embedding']),\n    cos_dist(embeddings_test['question_body_embedding'], embeddings_test['question_title_embedding'])\n]).T\n\nX_train = np.hstack([item for k, item in embeddings_train.items()] + [features_train, dist_features_train])\nX_test = np.hstack([item for k, item in embeddings_test.items()] + [features_test, dist_features_test])\ny_train = train[targets].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.hstack((X_train, train_question_body_dense, train_answer_dense))\nX_test = np.hstack((X_test, test_question_body_dense, test_answer_dense))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modeling"},{"metadata":{},"cell_type":"markdown","source":"I modify a little on Spearman Callback, and remove the use of Elastic network since it consumes a lot of time."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"'''Here, I modify a little\n(1) recount bad_epoch every time new best_weight is founded\n(2) save and load best model\n(3) I use pure spearman correlation, no random noise added\n'''\n\nclass SpearmanRhoCallback(Callback):\n    def __init__(self, training_data, validation_data, patience, model_name):\n        self.x = training_data[0]\n        self.y = training_data[1]\n        self.x_val = validation_data[0]\n        self.y_val = validation_data[1]\n        \n        self.patience = patience\n        self.value = -1\n        self.bad_epochs = 0\n        self.model_name = model_name\n\n    def on_train_begin(self, logs={}):\n        return\n\n    def on_train_end(self, logs={}):\n        return\n\n    def on_epoch_begin(self, epoch, logs={}):\n        return\n    \n    def on_epoch_end(self, epoch, logs={}):\n        y_pred_val = self.model.predict(self.x_val)\n#         rho_val = np.mean([spearmanr(self.y_val[:, ind], y_pred_val[:, ind] + np.random.normal(0, 1e-7, y_pred_val.shape[0])).correlation for ind in range(y_pred_val.shape[1])])\n        rho_val = np.mean([ spearmanr(self.y_val[:, ind], y_pred_val[:, ind]).correlation for ind in range(y_pred_val.shape[1]) ])\n        if rho_val >= self.value:\n            self.value = rho_val\n            self.bad_epochs = 0\n            print('\\nsave best weights\\n')\n            self.model.save_weights(self.model_name)\n        else:\n            self.bad_epochs += 1\n            print('bad epochs = ',self.bad_epochs)\n        if self.bad_epochs >= self.patience:\n            print(\"Epoch %05d: early stopping Threshold -- load best weights\" % epoch)\n            try:\n                self.model.load_weights(self.model_name)\n            except:\n                print('could not load a model')\n            self.model.stop_training = True\n            \n#             \n        print('\\rval_spearman-rho: %s' % (str(round(rho_val, 4))), end=100*' '+'\\n')\n        return rho_val\n\n    def on_batch_begin(self, batch, logs={}):\n        return\n\n    def on_batch_end(self, batch, logs={}):\n        return","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def create_model():\n    inps = Input(shape=(X_train.shape[1],))\n    x = Dense(512, activation='elu')(inps)\n    x = Dropout(0.2)(x)\n    x = Dense(y_train.shape[1], activation='sigmoid')(x)\n    model = Model(inputs=inps, outputs=x)\n    model.compile(\n        optimizer=Adam(lr=1e-4),\n        loss=['binary_crossentropy']\n    )\n    model.summary()\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Experiments with NUM_FOLDS = 4\n\nIf the number of folds is small, e.g. `NUM_FOLDS=4`. We will see that `KFold` usually works fine like `MultilabelStratifiedKFold` (but there's no guaranteed if we change splitting SEED (default=42) ). In the experiment, I run the 4-fold training and record all CVs.\n\nOnly `GroupKFold` will have `nan` with this SEED . So, either we have to change SEED or we have to carefully ignore `nan`. **Important note is that we should not use `np.nanmean` since it will give us dramatically high CV for that nan-fold, so that we will have an over-estimated CV instead. See details in `GroupKFold` experiment below **\n\nTo summarize empirical results which you can see below, `KFold` and `MultilabelStratifiedKFold` will give us average CV around 0.38x with standard deviation in a 3rd decimal. While `GroupKFold` if ignoring `nan` properly usually give us average CV around 0.37x which is closer to 0.36x LB. However, as noted above, if we use `np.nanmean` in the nan-fold, we will have strangely-high CV, and CV standard deviation becomes 2nd decimal indicating unreliability.\n\n## Plain KFold - 4 folds"},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_FOLDS=4\nkf = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"all_predictions = []\nrho_kfolds = []\n\nfor ind, (tr, val) in enumerate(kf.split(X_train)):\n    X_tr = X_train[tr]\n    y_tr = y_train[tr]\n    X_vl = X_train[val]\n    y_vl = y_train[val]\n    \n    model = create_model()\n    model.fit(\n        X_tr, y_tr, epochs=100, batch_size=32, validation_data=(X_vl, y_vl), verbose=True, \n        callbacks=[SpearmanRhoCallback(training_data=(X_tr, y_tr), validation_data=(X_vl, y_vl),\n                                       patience=15, model_name=f'best_model_batch{ind}.h5')]\n    )\n    all_predictions.append(model.predict(X_test))\n\n    y_pred_val = model.predict(X_vl)\n    rho_list = [ spearmanr(y_vl[:, ind], y_pred_val[:, ind]).correlation for ind in range(y_pred_val.shape[1]) ]\n    rho_kfolds.append(rho_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Each fold : ', np.mean(rho_kfolds,axis=1))\nprint('Using nanmean, each fold : ', np.nanmean(rho_kfolds,axis=1))\nprint('Average performance : %.4f +/- %.4f'% ( np.mean(rho_kfolds), np.std(np.mean(rho_kfolds,axis=1)) ) )\n\nprint('Each label : ')\nspearman_avg_per_label = np.mean(rho_kfolds,axis=0) # metric for each label -- use print line-by-line for better illustration\nspearman_std_per_label = np.std(rho_kfolds,axis=0)\nfor ii in range(len(target_cols)):\n    print('%d - %.3f +/- %.3f - %s' % (ii+1,spearman_avg_per_label[ii],spearman_std_per_label[ii],\n                                       target_cols[ii] ))\n    \nrho_kfolds_plain = np.array(rho_kfolds) # saving for later use","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Multi-label Stratified-KFold - 4 folds"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"all_predictions = []\n\nrho_kfolds = []\n\nkf = MultilabelStratifiedKFold(n_splits = NUM_FOLDS, random_state = SEED)\nfor ind, (tr, val) in enumerate(kf.split(X_train,y_train)):\n    X_tr = X_train[tr]\n    y_tr = y_train[tr]\n    X_vl = X_train[val]\n    y_vl = y_train[val]\n    \n    model = create_model()\n    model.fit(\n        X_tr, y_tr, epochs=100, batch_size=32, validation_data=(X_vl, y_vl), verbose=True, \n        callbacks=[SpearmanRhoCallback(training_data=(X_tr, y_tr), validation_data=(X_vl, y_vl),\n                                       patience=15, model_name=f'best_model_batch{ind}.h5')]\n    )\n    all_predictions.append(model.predict(X_test))\n\n    y_pred_val = model.predict(X_vl)\n    rho_list = [ spearmanr(y_vl[:, ind], y_pred_val[:, ind]).correlation for ind in range(y_pred_val.shape[1]) ]\n    rho_kfolds.append(rho_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Each fold : ', np.mean(rho_kfolds,axis=1))\nprint('Using nanmean, each fold : ', np.nanmean(rho_kfolds,axis=1))\nprint('Average performance : %.4f +/- %.4f'% ( np.mean(rho_kfolds), np.std(np.mean(rho_kfolds,axis=1)) ) )\n\n'''I hide details for read-ability. You can comment out to see per-label details'''\n# print('Each label : ')\n# spearman_avg_per_label = np.mean(rho_kfolds,axis=0) # metric for each label -- use print line-by-line for better illustration\n# spearman_std_per_label = np.std(rho_kfolds,axis=0)\n# for ii in range(len(target_cols)):\n#     print('%d - %.3f +/- %.3f - %s' % (ii+1,spearman_avg_per_label[ii],spearman_std_per_label[ii],\n#                                        target_cols[ii] ))\n    \nrho_kfolds_multi = np.array(rho_kfolds) # saving for later use","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## GroupKFold - 4 folds"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"all_predictions = []\n\nrho_kfolds = []\n\nkf = GroupKFold(n_splits=NUM_FOLDS).split(X=df_train.question_body, groups=df_train.question_body)\nfor ind, (tr, val) in enumerate(kf):\n    X_tr = X_train[tr]\n    y_tr = y_train[tr]\n    X_vl = X_train[val]\n    y_vl = y_train[val]\n    \n    model = create_model()\n    model.fit(\n        X_tr, y_tr, epochs=100, batch_size=32, validation_data=(X_vl, y_vl), verbose=True, \n        callbacks=[SpearmanRhoCallback(training_data=(X_tr, y_tr), validation_data=(X_vl, y_vl),\n                                       patience=15, model_name=f'best_model_batch{ind}.h5')]\n    )\n    all_predictions.append(model.predict(X_test))\n\n    y_pred_val = model.predict(X_vl)\n    rho_list = [ spearmanr(y_vl[:, ind], y_pred_val[:, ind]).correlation for ind in range(y_pred_val.shape[1]) ]\n    rho_kfolds.append(rho_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, we got `nan` in the last fold, so we have to fix it. **NOTE the absurdly high CV for `np.nanmean` in the last fold! So don't use it**. If we exclude the nan-fold properly, see `rho_kfolds_group_nonan`, we will get a good CV in this case."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Each fold : ', np.mean(rho_kfolds,axis=1))\nprint('**NOTE** Using nanmean, each fold : ', np.nanmean(rho_kfolds,axis=1))\nprint('Average performance : %.4f +/- %.4f'% ( np.mean(rho_kfolds), np.std(np.mean(rho_kfolds,axis=1)) ) )\n\nprint('Each label : ')\nspearman_avg_per_label = np.mean(rho_kfolds,axis=0) # metric for each label -- use print line-by-line for better illustration\nspearman_std_per_label = np.std(rho_kfolds,axis=0)\nfor ii in range(len(target_cols)):\n    print('%d - %.3f +/- %.3f - %s' % (ii+1,spearman_avg_per_label[ii],spearman_std_per_label[ii],\n                                       target_cols[ii] ))\n    \nrho_kfolds_group = np.array(rho_kfolds) # saving for later use\n\nrho_kfolds_group_nonan = [] \nmm = np.mean(rho_kfolds,axis=1)\nfor ii in range(len(mm)):    \n    if np.isnan(mm[ii]) == False:\n        rho_kfolds_group_nonan.append(rho_kfolds[ii])\n        \nprint('Average performance with ignoring nan : %.4f +/- %.4f'% ( np.mean(rho_kfolds_group_nonan), np.std(np.mean(rho_kfolds_group_nonan,axis=1)) ) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Summary for 4 folds"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('precision',4)\npd.set_option('display.precision',4)\npd.set_option('display.float_format','{:.4f}'.format)\n\ndf = pd.DataFrame(columns=['label','plain','multi','group_nanmean','group_nonan'])\ndf['label'] = df_train.columns[11:]\ndf['plain'] = np.nanmean(rho_kfolds_plain,axis=0)\ndf['multi'] = np.nanmean(rho_kfolds_multi,axis=0)\ndf['group_nanmean'] = np.nanmean(rho_kfolds_group,axis=0)\ndf['group_nonan'] = np.mean(rho_kfolds_group_nonan,axis=0)\n\ndf2 = pd.DataFrame([['average',np.mean(rho_kfolds_plain), \n                     np.mean(rho_kfolds_multi), \n                     np.nanmean(rho_kfolds_group),\n                     np.mean(rho_kfolds_group_nonan),\n                    ]],\n                     columns=df.columns)\ndf2 = df.append(df2)\n\ndf2.head(35)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Experiments with NUM_FOLDS = 10\n\n## Plain KFold - 10 folds\nWhen we step up to 10 folds, now KFold will also face `nan` problem by chance. Note that some SEED may not produce `nan`, but the current SEED=42 which usually a default number in public kernel will have `nan` in 2 folds. So now in order to calculate average CV, we have to ignore the nan fold."},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_FOLDS=10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"all_predictions = []\nrho_kfolds = []\n\nkf = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\nfor ind, (tr, val) in enumerate(kf.split(X_train)):\n    X_tr = X_train[tr]\n    y_tr = y_train[tr]\n    X_vl = X_train[val]\n    y_vl = y_train[val]\n    \n    model = create_model()\n    model.fit(\n        X_tr, y_tr, epochs=100, batch_size=32, validation_data=(X_vl, y_vl), verbose=True, \n        callbacks=[SpearmanRhoCallback(training_data=(X_tr, y_tr), validation_data=(X_vl, y_vl),\n                                       patience=15, model_name=f'best_model_batch{ind}.h5')]\n    )\n    all_predictions.append(model.predict(X_test))\n\n    y_pred_val = model.predict(X_vl)\n    rho_list = [ spearmanr(y_vl[:, ind], y_pred_val[:, ind]).correlation for ind in range(y_pred_val.shape[1]) ]\n    rho_kfolds.append(rho_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Each fold : ', np.mean(rho_kfolds,axis=1))\nprint('Using nanmean, each fold : ', np.nanmean(rho_kfolds,axis=1))\nprint('Average performance : %.4f +/- %.4f'% ( np.mean(rho_kfolds), np.std(np.mean(rho_kfolds,axis=1)) ) )\n\nprint('Each label : ')\nspearman_avg_per_label = np.mean(rho_kfolds,axis=0) # metric for each label -- use print line-by-line for better illustration\nspearman_std_per_label = np.std(rho_kfolds,axis=0)\nfor ii in range(len(target_cols)):\n    print('%d - %.3f +/- %.3f - %s' % (ii+1,spearman_avg_per_label[ii],spearman_std_per_label[ii],\n                                       target_cols[ii] ))\n    \nrho_kfolds_plain = np.array(rho_kfolds) # saving for later use\n\nrho_kfolds_plain_nonan = [] \nmm = np.mean(rho_kfolds,axis=1)\nfor ii in range(len(mm)):    \n    if np.isnan(mm[ii]) == False:\n        rho_kfolds_plain_nonan.append(rho_kfolds[ii])\n        \nprint('Average performance with ignoring nan : %.4f +/- %.4f'% ( np.mean(rho_kfolds_plain_nonan), np.std(np.mean(rho_kfolds_plain_nonan,axis=1)) ) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Multi-label StratifiedKFold  - 10 folds\nUsing this method, even 10 fold, we will not have `nan` problem."},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"all_predictions = []\n\nrho_kfolds = []\n\nkf = MultilabelStratifiedKFold(n_splits = NUM_FOLDS, random_state = SEED)\nfor ind, (tr, val) in enumerate(kf.split(X_train,y_train)):\n    X_tr = X_train[tr]\n    y_tr = y_train[tr]\n    X_vl = X_train[val]\n    y_vl = y_train[val]\n    \n    model = create_model()\n    model.fit(\n        X_tr, y_tr, epochs=100, batch_size=32, validation_data=(X_vl, y_vl), verbose=True, \n        callbacks=[SpearmanRhoCallback(training_data=(X_tr, y_tr), validation_data=(X_vl, y_vl),\n                                       patience=15, model_name=f'best_model_batch{ind}.h5')]\n    )\n    all_predictions.append(model.predict(X_test))\n\n    y_pred_val = model.predict(X_vl)\n    rho_list = [ spearmanr(y_vl[:, ind], y_pred_val[:, ind]).correlation for ind in range(y_pred_val.shape[1]) ]\n    rho_kfolds.append(rho_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Each fold : ', np.mean(rho_kfolds,axis=1))\nprint('Using nanmean, each fold : ', np.nanmean(rho_kfolds,axis=1))\nprint('Average performance : %.4f +/- %.4f'% ( np.mean(rho_kfolds), np.std(np.mean(rho_kfolds,axis=1)) ) )\n\n'''I hide details for read-ability. You can comment out to see per-label details'''\n# print('Each label : ')\n# spearman_avg_per_label = np.mean(rho_kfolds,axis=0) # metric for each label -- use print line-by-line for better illustration\n# spearman_std_per_label = np.std(rho_kfolds,axis=0)\n# for ii in range(len(target_cols)):\n#     print('%d - %.3f +/- %.3f - %s' % (ii+1,spearman_avg_per_label[ii],spearman_std_per_label[ii],\n#                                        target_cols[ii] ))\n    \nrho_kfolds_multi = np.array(rho_kfolds) # saving for later use","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## GroupKFolds - 10 folds\nNow we will have 3-4 `nan` (both by chance and by definition) since only 8-`nan`-questions have to be divided randomly into 10 folds."},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"all_predictions = []\n\nrho_kfolds = []\n\nkf = GroupKFold(n_splits=NUM_FOLDS).split(X=df_train.question_body, groups=df_train.question_body)\nfor ind, (tr, val) in enumerate(kf):\n    X_tr = X_train[tr]\n    y_tr = y_train[tr]\n    X_vl = X_train[val]\n    y_vl = y_train[val]\n    \n    model = create_model()\n    model.fit(\n        X_tr, y_tr, epochs=100, batch_size=32, validation_data=(X_vl, y_vl), verbose=True, \n        callbacks=[SpearmanRhoCallback(training_data=(X_tr, y_tr), validation_data=(X_vl, y_vl),\n                                       patience=15, model_name=f'best_model_batch{ind}.h5')]\n    )\n    all_predictions.append(model.predict(X_test))\n\n    y_pred_val = model.predict(X_vl)\n    rho_list = [ spearmanr(y_vl[:, ind], y_pred_val[:, ind]).correlation for ind in range(y_pred_val.shape[1]) ]\n    rho_kfolds.append(rho_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Each fold : ', np.mean(rho_kfolds,axis=1))\nprint('Using nanmean, each fold : ', np.nanmean(rho_kfolds,axis=1))\nprint('Average performance : %.4f +/- %.4f'% ( np.mean(rho_kfolds), np.std(np.mean(rho_kfolds,axis=1)) ) )\n\nprint('Each label : ')\nspearman_avg_per_label = np.mean(rho_kfolds,axis=0) # metric for each label -- use print line-by-line for better illustration\nspearman_std_per_label = np.std(rho_kfolds,axis=0)\nfor ii in range(len(target_cols)):\n    print('%d - %.3f +/- %.3f - %s' % (ii+1,spearman_avg_per_label[ii],spearman_std_per_label[ii],\n                                       target_cols[ii] ))\n    \nrho_kfolds_group = np.array(rho_kfolds) # saving for later use\nrho_kfolds_group_nonan = [] \nmm = np.mean(rho_kfolds,axis=1)\nfor ii in range(len(mm)):    \n    if np.isnan(mm[ii]) == False:\n        rho_kfolds_group_nonan.append(rho_kfolds[ii])\n        \nprint('Average performance with ignoring nan : %.4f +/- %.4f'% ( np.mean(rho_kfolds_group_nonan), np.std(np.mean(rho_kfolds_group_nonan,axis=1)) ) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Summary for 10 folds\n\nNote that `GroupKFold` can give us most accurate average CV if ignoring nan, but can come with high standard deviation of 2nd-decimal point."},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('precision',4)\npd.set_option('display.precision',4)\npd.set_option('display.float_format','{:.4f}'.format)\n\ndf = pd.DataFrame(columns=['label','plain_nonan','multi','group_nanmean','group_nonan'])\ndf['label'] = df_train.columns[11:]\ndf['plain_nonan'] = np.mean(rho_kfolds_plain_nonan,axis=0)\ndf['multi'] = np.mean(rho_kfolds_multi,axis=0)\ndf['group_nanmean'] = np.nanmean(rho_kfolds_group,axis=0)\ndf['group_nonan'] = np.mean(rho_kfolds_group_nonan,axis=0)\n\ndf2 = pd.DataFrame([['average',np.mean(rho_kfolds_plain_nonan), \n                     np.mean(rho_kfolds_multi), \n                     np.nanmean(rho_kfolds_group),\n                     np.mean(rho_kfolds_group_nonan),\n                    ]],\n                     columns=df.columns)\ndf2 = df.append(df2)\n\ndf2.head(35)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}