{"cells":[{"metadata":{},"cell_type":"markdown","source":"This is a QUEST version of the following Jigsaw Toxic Comments kernel: https://www.kaggle.com/tunguz/logistic-regression-with-words-and-char-n-grams\n\nWhich in turn was forked from the followiong kernel: https://www.kaggle.com/thousandvoices/logistic-regression-with-words-and-char-n-grams"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom scipy.sparse import hstack\nfrom sklearn.metrics import roc_auc_score, accuracy_score, log_loss\nfrom tqdm import tqdm_notebook, tqdm\nfrom scipy import stats\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport gc\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def spearman_corr(y_true, y_pred):\n        if np.ndim(y_pred) == 2:\n            corr = np.mean([stats.spearmanr(y_true[:, i], y_pred[:, i])[0] for i in range(y_true.shape[1])])\n        else:\n            corr = stats.spearmanr(y_true, y_pred)[0]\n        return corr","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/google-quest-challenge/train.csv').fillna(' ')\ntest = pd.read_csv('../input/google-quest-challenge/test.csv').fillna(' ')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.unique(train['category'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_text_1 = train['question_body']\ntest_text_1 = test['question_body']\nall_text_1 = pd.concat([train_text_1, test_text_1])\n\ntrain_text_2 = train['answer']\ntest_text_2 = test['answer']\nall_text_2 = pd.concat([train_text_2, test_text_2])\n\ntrain_text_3 = train['question_title']\ntest_text_3 = test['question_title']\nall_text_3 = pd.concat([train_text_3, test_text_3])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv('../input/google-quest-challenge/sample_submission.csv').fillna(' ')\nsample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names = list(sample_submission.columns[1:])\nclass_names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names_q = class_names[:21]\nclass_names_a = class_names[21:]\nclass_names_a","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_names_2 = [class_name+'_2' for class_name in class_names]\nfor class_name in class_names:\n    train[class_name+'_2'] = (train[class_name].values >= 0.5)*1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nword_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='word',\n    token_pattern=r'\\w{1,}',\n    stop_words='english',\n    ngram_range=(1, 2),\n    max_features=20000)\nword_vectorizer.fit(all_text_1)\ntrain_word_features_1 = word_vectorizer.transform(train_text_1)\ntest_word_features_1 = word_vectorizer.transform(test_text_1)\n\nword_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='word',\n    token_pattern=r'\\w{1,}',\n    stop_words='english',\n    ngram_range=(1, 2),\n    max_features=20000)\nword_vectorizer.fit(all_text_2)\ntrain_word_features_2 = word_vectorizer.transform(train_text_2)\ntest_word_features_2 = word_vectorizer.transform(test_text_2)\n\nword_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='word',\n    token_pattern=r'\\w{1,}',\n    stop_words='english',\n    ngram_range=(1, 2),\n    max_features=20000)\nword_vectorizer.fit(all_text_3)\ntrain_word_features_3 = word_vectorizer.transform(train_text_3)\ntest_word_features_3 = word_vectorizer.transform(test_text_3)\n\nchar_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='char',\n    stop_words='english',\n    ngram_range=(1, 4),\n    max_features=50000)\nchar_vectorizer.fit(all_text_1)\ntrain_char_features_1 = char_vectorizer.transform(train_text_1)\ntest_char_features_1 = char_vectorizer.transform(test_text_1)\n\nchar_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='char',\n    stop_words='english',\n    ngram_range=(1, 4),\n    max_features=50000)\nchar_vectorizer.fit(all_text_2)\ntrain_char_features_2 = char_vectorizer.transform(train_text_2)\ntest_char_features_2 = char_vectorizer.transform(test_text_2)\n\nchar_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='char',\n    stop_words='english',\n    ngram_range=(1, 4),\n    max_features=50000)\nchar_vectorizer.fit(all_text_3)\ntrain_char_features_3 = char_vectorizer.transform(train_text_3)\ntest_char_features_3 = char_vectorizer.transform(test_text_3)\n\ntrain_features_1 = hstack([train_char_features_1, train_word_features_1, train_char_features_3, train_word_features_3])\ntest_features_1 = hstack([test_char_features_1, test_word_features_1, test_char_features_3, test_word_features_3])\ntrain_features_2 = hstack([train_char_features_2, train_word_features_2])\ntest_features_2 = hstack([test_char_features_2, test_word_features_2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features_1= train_features_1.tocsr()\ntrain_features_2= train_features_2.tocsr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nsubmission = pd.DataFrame.from_dict({'qa_id': test['qa_id']})\n\ntrain_preds = []\ntest_preds = []\nscores = []\nspearman_scores = []\n\nfor class_name in tqdm_notebook(class_names_q):\n    print(class_name)\n    Y = train[class_name+'_2']\n    \n    n_splits = 3\n    kf = KFold(n_splits=n_splits, random_state=47)\n\n    train_oof_1 = np.zeros((train_features_1.shape[0], ))\n    test_preds_1 = 0\n    \n    score = 0\n\n    for jj, (train_index, val_index) in enumerate(kf.split(train_features_1)):\n        #print(\"Fitting fold\", jj+1)\n        train_features = train_features_1[train_index]\n        train_target = Y[train_index]\n\n        val_features = train_features_1[val_index]\n        val_target = Y[val_index]\n\n        model = LogisticRegression(C= .3, solver='lbfgs')\n        model.fit(train_features, train_target)\n        val_pred = model.predict_proba(val_features)[:,1]\n        train_oof_1[val_index] = val_pred\n        #print(\"Fold auc:\", roc_auc_score(val_target, val_pred))\n        #spearman_corr\n        #score += roc_auc_score(val_target, val_pred)/n_splits\n\n        test_preds_1 += model.predict_proba(test_features_1)[:,1]/n_splits\n        del train_features, train_target, val_features, val_target\n        gc.collect()\n        \n    model = LogisticRegression(C= .3, solver='lbfgs')\n    model.fit(train_features_1, Y)\n    submission[class_name] = model.predict_proba(test_features_1)[:, 1]\n    spearman_score = spearman_corr(train[class_name], train_oof_1)\n    print(\"spearman_corr:\", spearman_score) \n    spearman_scores.append(spearman_score)\n    score = roc_auc_score(Y, train_oof_1)    \n    print(\"auc:\", score, \"\\n\")\n    train_preds.append(train_oof_1)\n    test_preds.append(test_preds_1)\n    scores.append(score)\n    \n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nfor class_name in tqdm_notebook(class_names_a):\n    print(class_name+'_2')\n    Y = train[class_name+'_2']\n    \n    n_splits = 3\n    kf = KFold(n_splits=n_splits, random_state=47)\n\n    train_oof_2 = np.zeros((train_features_2.shape[0], ))\n    test_preds_2 = 0\n    \n    score = 0\n\n    for jj, (train_index, val_index) in enumerate(kf.split(train_features_1)):\n        #print(\"Fitting fold\", jj+1)\n        train_features = train_features_2[train_index]\n        train_target = Y[train_index]\n\n        val_features = train_features_2[val_index]\n        val_target = Y[val_index]\n\n        model = LogisticRegression(solver='lbfgs')\n        model.fit(train_features, train_target)\n        val_pred = model.predict_proba(val_features)[:,1]\n        train_oof_2[val_index] = val_pred\n        #print(\"Fold auc:\", roc_auc_score(val_target, val_pred))\n        #score += roc_auc_score(val_target, val_pred)/n_splits\n\n        test_preds_2 += model.predict_proba(test_features_2)[:,1]/n_splits\n        del train_features, train_target, val_features, val_target\n        gc.collect()\n        \n    model = LogisticRegression(C= .3, solver='lbfgs')\n    model.fit(train_features_2, Y)\n    submission[class_name] = model.predict_proba(test_features_2)[:, 1]\n        \n    score = roc_auc_score(Y, train_oof_2)\n    \n    \n    spearman_score = spearman_corr(train[class_name], train_oof_2)\n    print(\"spearman_corr:\", spearman_score)\n    print(\"auc:\", score, \"\\n\")\n    spearman_scores.append(spearman_score)\n    \n    train_preds.append(train_oof_2)\n    test_preds.append(test_preds_2)\n    scores.append(score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Mean auc:\", np.mean(scores))\nprint(\"Mean spearman_scores\", np.mean(spearman_scores))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}