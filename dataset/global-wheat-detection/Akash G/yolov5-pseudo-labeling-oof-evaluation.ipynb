{"cells":[{"metadata":{},"cell_type":"markdown","source":"## YoloV5 Pseudo Labeling + OOF Evaluation\n\nThis notebook is a clean up of [Yolov5 Pseudo Labeling](https://www.kaggle.com/nvnnghia/yolov5-pseudo-labeling), with OOF-evaluation to search the best `score_threshold` for final prediction.  \nMy pretrained checkpoint gives worse results compared to the original notebook, but to my surprise adding OOF-evaluation gives me a large boost about 1% LB.   \nYou can try your pretrained model on this notebook.\n\nupdate: fixed a bug in `calculate_final_score`, boxes should be sorted with discending conf score.\n\nReferences:  \nAwesome original Pseudo Labeling notebook: https://www.kaggle.com/nvnnghia/yolov5-pseudo-labeling  \nEvaluation Script: https://www.kaggle.com/pestipeti/competition-metric-details-script  \nOOF-Evaluation: https://www.kaggle.com/shonenkov/oof-evaluation-mixup-efficientdet  \nBayesian Optimization (though failed to improve my results): https://www.kaggle.com/shonenkov/bayesian-optimization-wbf-efficientdet  \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom tqdm.auto import tqdm\nimport shutil as sh\nimport torch\nimport sys\nimport glob\nimport random\n\n!cp -r ../input/yolov5train/* .\n#sys.path.insert(0, \"../input/yolov5tta/\")\nsys.path.insert(0, \"../input/weightedboxesfusion\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"NMS_IOU_THR = 0.6\nNMS_CONF_THR = 0.25\n\n# WBF\nbest_iou_thr = 0.6\nbest_skip_box_thr = 0.43\n\n# Box conf threshold\nbest_final_score = 0\nbest_score_threshold = 0\n\nSEED = 42\n\nEPO = 15\n\nWEIGHTS = '../input/yolov5-files/yolov5_weights/yolov5_models/yolov5s.pt'\n\nCONFIG = '../input/wheatyolov5/yolov5x.yaml'\n\nDATA = '../input/configyolo5/wheat0.yaml'\n\nis_TEST = len(os.listdir('../input/global-wheat-detection/test/'))>11\n\nis_AUG = True\nis_ROT = True\n\nVALIDATE = True\n\nPSEUDO = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def set_seed(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)  # type: ignore\n    torch.backends.cudnn.deterministic = True  # type: ignore\n    torch.backends.cudnn.benchmark = True  # type: ignore\n    \nset_seed(SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For OOF evaluation\nmarking = pd.read_csv('../input/global-wheat-detection/train.csv')\n\nbboxs = np.stack(marking['bbox'].apply(lambda x: np.fromstring(x[1:-1], sep=',')))\nfor i, column in enumerate(['x', 'y', 'w', 'h']):\n    marking[column] = bboxs[:,i]\nmarking.drop(columns=['bbox'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convertTrainLabel():\n    df = pd.read_csv('../input/global-wheat-detection/train.csv')\n    bboxs = np.stack(df['bbox'].apply(lambda x: np.fromstring(x[1:-1], sep=',')))\n    for i, column in enumerate(['x', 'y', 'w', 'h']):\n        df[column] = bboxs[:,i]\n    df.drop(columns=['bbox'], inplace=True)\n    df['x_center'] = df['x'] + df['w']/2\n    df['y_center'] = df['y'] + df['h']/2\n    df['classes'] = 0\n    from tqdm.auto import tqdm\n    import shutil as sh\n    df = df[['image_id','x', 'y', 'w', 'h','x_center','y_center','classes']]\n    \n    index = list(set(df.image_id))\n    \n    source = 'train'\n    if True:\n        for fold in [0]:\n            val_index = index[len(index)*fold//5:len(index)*(fold+1)//5]\n            for name, mini in tqdm(df.groupby('image_id')):\n                path2save = 'val2017/' if name in val_index else 'train2017/'\n                os.makedirs('convertor/fold{}/labels/'.format(fold)+path2save, exist_ok=True)\n                with open('convertor/fold{}/labels/'.format(fold)+path2save+name+\".txt\", 'w+') as f:\n                    row = mini[['classes','x_center','y_center','w','h']].astype(float).values\n                    row = row/1024\n                    row = row.astype(str)\n                    for j in range(len(row)):\n                        text = ' '.join(row[j])\n                        f.write(text)\n                        f.write(\"\\n\")\n                os.makedirs('convertor/fold{}/images/{}'.format(fold,path2save), exist_ok=True)\n                sh.copy(\"../input/global-wheat-detection/{}/{}.jpg\".format(source,name),'convertor/fold{}/images/{}/{}.jpg'.format(fold,path2save,name))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from ensemble_boxes import *\n\ndef run_wbf(boxes, scores, image_size=1024, iou_thr=0.5, skip_box_thr=0.7, weights=None):\n    labels = [np.zeros(score.shape[0]) for score in scores]\n    boxes = [box/(image_size) for box in boxes]\n    boxes, scores, labels = weighted_boxes_fusion(boxes, scores, labels, weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n    boxes = boxes*(image_size)\n    return boxes, scores, labels\n\ndef TTAImage(image, index):\n    image1 = image.copy()\n    if index==0: \n        rotated_image = cv2.rotate(image1, cv2.ROTATE_90_CLOCKWISE)\n        return rotated_image\n    elif index==1:\n        rotated_image2 = cv2.rotate(image1, cv2.ROTATE_90_CLOCKWISE)\n        rotated_image2 = cv2.rotate(rotated_image2, cv2.ROTATE_90_CLOCKWISE)\n        return rotated_image2\n    elif index==2:\n        rotated_image3 = cv2.rotate(image1, cv2.ROTATE_90_CLOCKWISE)\n        rotated_image3 = cv2.rotate(rotated_image3, cv2.ROTATE_90_CLOCKWISE)\n        rotated_image3 = cv2.rotate(rotated_image3, cv2.ROTATE_90_CLOCKWISE)\n        return rotated_image3\n    elif index == 3:\n        return image1\n    \ndef rotBoxes90(boxes, im_w, im_h):\n    ret_boxes =[]\n    for box in boxes:\n        x1, y1, x2, y2 = box\n        x1, y1, x2, y2 = x1-im_w//2, im_h//2 - y1, x2-im_w//2, im_h//2 - y2\n        x1, y1, x2, y2 = y1, -x1, y2, -x2\n        x1, y1, x2, y2 = int(x1+im_w//2), int(im_h//2 - y1), int(x2+im_w//2), int(im_h//2 - y2)\n        x1a, y1a, x2a, y2a = min(x1, x2), min(y1, y2), max(x1, x2), max(y1, y2)\n        ret_boxes.append([x1a, y1a, x2a, y2a])\n    return np.array(ret_boxes)\n\ndef detect1Image(img, img0, model, device, aug):\n    img = img.transpose(2,0,1)\n    img = torch.from_numpy(img).to(device)\n    img =  img.float()  # uint8 to fp16/32\n    img /= 255.0\n    if img.ndimension() == 3:\n        img = img.unsqueeze(0)\n    \n    # Inference\n    pred = model(img, augment=aug)[0]\n    \n    # Apply NMS\n    pred = non_max_suppression(pred, NMS_CONF_THR, NMS_IOU_THR, merge=True, classes=None, agnostic=False)\n    \n    boxes = []\n    scores = []\n    for i, det in enumerate(pred):  # detections per image\n        # save_path = 'draw/' + image_id + '.jpg'\n        if det is not None and len(det):\n            # Rescale boxes from img_size to im0 size\n            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], img0.shape).round()\n\n            # Write results\n            for *xyxy, conf, cls in det:\n                boxes.append([int(xyxy[0]), int(xyxy[1]), int(xyxy[2]), int(xyxy[3])])\n                scores.append(conf)\n\n    return np.array(boxes), np.array(scores) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# validate\n\nimport pandas as pd\nimport numpy as np\nimport numba\nimport re\nimport cv2\nimport ast\nimport matplotlib.pyplot as plt\n\nfrom numba import jit\nfrom typing import List, Union, Tuple\n\n\n@jit(nopython=True)\ndef calculate_iou(gt, pr, form='pascal_voc') -> float:\n    \"\"\"Calculates the Intersection over Union.\n\n    Args:\n        gt: (np.ndarray[Union[int, float]]) coordinates of the ground-truth box\n        pr: (np.ndarray[Union[int, float]]) coordinates of the prdected box\n        form: (str) gt/pred coordinates format\n            - pascal_voc: [xmin, ymin, xmax, ymax]\n            - coco: [xmin, ymin, w, h]\n    Returns:\n        (float) Intersection over union (0.0 <= iou <= 1.0)\n    \"\"\"\n    if form == 'coco':\n        gt = gt.copy()\n        pr = pr.copy()\n\n        gt[2] = gt[0] + gt[2]\n        gt[3] = gt[1] + gt[3]\n        pr[2] = pr[0] + pr[2]\n        pr[3] = pr[1] + pr[3]\n\n    # Calculate overlap area\n    dx = min(gt[2], pr[2]) - max(gt[0], pr[0]) + 1\n    \n    if dx < 0:\n        return 0.0\n    \n    dy = min(gt[3], pr[3]) - max(gt[1], pr[1]) + 1\n\n    if dy < 0:\n        return 0.0\n\n    overlap_area = dx * dy\n\n    # Calculate union area\n    union_area = (\n            (gt[2] - gt[0] + 1) * (gt[3] - gt[1] + 1) +\n            (pr[2] - pr[0] + 1) * (pr[3] - pr[1] + 1) -\n            overlap_area\n    )\n\n    return overlap_area / union_area\n\n\n@jit(nopython=True)\ndef find_best_match(gts, pred, pred_idx, threshold = 0.5, form = 'pascal_voc', ious=None) -> int:\n    \"\"\"Returns the index of the 'best match' between the\n    ground-truth boxes and the prediction. The 'best match'\n    is the highest IoU. (0.0 IoUs are ignored).\n\n    Args:\n        gts: (List[List[Union[int, float]]]) Coordinates of the available ground-truth boxes\n        pred: (List[Union[int, float]]) Coordinates of the predicted box\n        pred_idx: (int) Index of the current predicted box\n        threshold: (float) Threshold\n        form: (str) Format of the coordinates\n        ious: (np.ndarray) len(gts) x len(preds) matrix for storing calculated ious.\n\n    Return:\n        (int) Index of the best match GT box (-1 if no match above threshold)\n    \"\"\"\n    best_match_iou = -np.inf\n    best_match_idx = -1\n\n    for gt_idx in range(len(gts)):\n        \n        if gts[gt_idx][0] < 0:\n            # Already matched GT-box\n            continue\n        \n        iou = -1 if ious is None else ious[gt_idx][pred_idx]\n\n        if iou < 0:\n            iou = calculate_iou(gts[gt_idx], pred, form=form)\n            \n            if ious is not None:\n                ious[gt_idx][pred_idx] = iou\n\n        if iou < threshold:\n            continue\n\n        if iou > best_match_iou:\n            best_match_iou = iou\n            best_match_idx = gt_idx\n\n    return best_match_idx\n\n@jit(nopython=True)\ndef calculate_precision(gts, preds, threshold = 0.5, form = 'coco', ious=None) -> float:\n    \"\"\"Calculates precision for GT - prediction pairs at one threshold.\n\n    Args:\n        gts: (List[List[Union[int, float]]]) Coordinates of the available ground-truth boxes\n        preds: (List[List[Union[int, float]]]) Coordinates of the predicted boxes,\n               sorted by confidence value (descending)\n        threshold: (float) Threshold\n        form: (str) Format of the coordinates\n        ious: (np.ndarray) len(gts) x len(preds) matrix for storing calculated ious.\n\n    Return:\n        (float) Precision\n    \"\"\"\n    n = len(preds)\n    tp = 0\n    fp = 0\n    \n    # for pred_idx, pred in enumerate(preds_sorted):\n    for pred_idx in range(n):\n\n        best_match_gt_idx = find_best_match(gts, preds[pred_idx], pred_idx,\n                                            threshold=threshold, form=form, ious=ious)\n\n        if best_match_gt_idx >= 0:\n            # True positive: The predicted box matches a gt box with an IoU above the threshold.\n            tp += 1\n            # Remove the matched GT box\n            gts[best_match_gt_idx] = -1\n\n        else:\n            # No match\n            # False positive: indicates a predicted box had no associated gt box.\n            fp += 1\n\n    # False negative: indicates a gt box had no associated predicted box.\n    fn = (gts.sum(axis=1) > 0).sum()\n\n    return tp / (tp + fp + fn)\n\n\n@jit(nopython=True)\ndef calculate_image_precision(gts, preds, thresholds = (0.5, ), form = 'coco') -> float:\n    \"\"\"Calculates image precision.\n\n    Args:\n        gts: (List[List[Union[int, float]]]) Coordinates of the available ground-truth boxes\n        preds: (List[List[Union[int, float]]]) Coordinates of the predicted boxes,\n               sorted by confidence value (descending)\n        thresholds: (float) Different thresholds\n        form: (str) Format of the coordinates\n\n    Return:\n        (float) Precision\n    \"\"\"\n    n_threshold = len(thresholds)\n    image_precision = 0.0\n    \n    ious = np.ones((len(gts), len(preds))) * -1\n    # ious = None\n\n    for threshold in thresholds:\n        precision_at_threshold = calculate_precision(gts.copy(), preds, threshold=threshold,\n                                                     form=form, ious=ious)\n        image_precision += precision_at_threshold / n_threshold\n\n    return image_precision\n\n    \n# Numba typed list!\niou_thresholds = numba.typed.List()\n\nfor x in [0.5, 0.55, 0.6, 0.65, 0.7, 0.75]:\n    iou_thresholds.append(x)\n    \ndef validate():\n    source = 'convertor/fold0/images/val2017'\n    \n    weights = 'weights/best.pt'\n    if not os.path.exists(weights):\n        weights = WEIGHTS\n    \n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n    # Load model\n    model = torch.load(weights, map_location=device)['model'].float()  # load to FP32\n    model.to(device).eval()\n    \n    dataset = LoadImages(source, img_size=1024)\n\n    results = []\n    \n    for path, img, img0, vid_cap in dataset:\n            \n        image_id = os.path.basename(path).split('.')[0]\n        img = img.transpose(1,2,0) # [H, W, 3]\n        \n        enboxes = []\n        enscores = []\n        \n        # only rot, no flip\n        if is_ROT:    \n            for i in range(4):\n                img1 = TTAImage(img, i)\n                boxes, scores = detect1Image(img1, img0, model, device, aug=False)\n                for _ in range(3-i):\n                    boxes = rotBoxes90(boxes, *img.shape[:2])            \n                enboxes.append(boxes)\n                enscores.append(scores) \n        \n        # flip\n        boxes, scores = detect1Image(img, img0, model, device, aug=is_AUG)\n        enboxes.append(boxes)\n        enscores.append(scores) \n            \n        #boxes, scores, labels = run_wbf(enboxes, enscores, image_size=1024, iou_thr=WBF_IOU_THR, skip_box_thr=WBF_CONF_THR)    \n        #boxes = boxes.astype(np.int32).clip(min=0, max=1024)\n        #boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n        #boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n        \n        #boxes = boxes[scores >= 0.05].astype(np.int32)\n        #scores = scores[scores >= float(0.05)]\n        \n        records = marking[marking['image_id'] == image_id]\n        gtboxes = records[['x', 'y', 'w', 'h']].values\n        gtboxes = gtboxes.astype(np.int32).clip(min=0, max=1024)\n        gtboxes[:, 2] = gtboxes[:, 0] + gtboxes[:, 2]\n        gtboxes[:, 3] = gtboxes[:, 1] + gtboxes[:, 3]\n        \n            \n        result = {\n            'image_id': image_id,\n            'pred_enboxes': enboxes, # xyhw\n            'pred_enscores': enscores,\n            'gt_boxes': gtboxes, # xyhw\n        }\n\n        results.append(result)\n        \n    return results\n\ndef calculate_final_score(all_predictions, iou_thr, skip_box_thr, score_threshold):\n    final_scores = []\n    for i in range(len(all_predictions)):\n        gt_boxes = all_predictions[i]['gt_boxes'].copy()\n        enboxes = all_predictions[i]['pred_enboxes'].copy()\n        enscores = all_predictions[i]['pred_enscores'].copy()\n        image_id = all_predictions[i]['image_id']\n        \n        pred_boxes, scores, labels = run_wbf(enboxes, enscores, image_size=1024, iou_thr=iou_thr, skip_box_thr=skip_box_thr)    \n        pred_boxes = pred_boxes.astype(np.int32).clip(min=0, max=1024)\n\n        indexes = np.where(scores>score_threshold)\n        pred_boxes = pred_boxes[indexes]\n        scores = scores[indexes]\n        \n        # descending conf\n        rank = np.argsort(scores)[::-1]\n        pred_boxes = pred_boxes[rank]\n        scores = scores[rank]\n\n        image_precision = calculate_image_precision(gt_boxes, pred_boxes,thresholds=iou_thresholds,form='pascal_voc')\n        final_scores.append(image_precision)\n\n    return np.mean(final_scores)\n\ndef show_result(sample_id, preds, gt_boxes):\n    sample = cv2.imread(f'../input/global-wheat-detection/train/{sample_id}.jpg', cv2.IMREAD_COLOR)\n    sample = cv2.cvtColor(sample, cv2.COLOR_BGR2RGB)\n\n    fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n\n    for pred_box in preds:\n        cv2.rectangle(\n            sample,\n            (pred_box[0], pred_box[1]),\n            (pred_box[2], pred_box[3]),\n            (220, 0, 0), 2\n        )\n\n    for gt_box in gt_boxes:    \n        cv2.rectangle(\n            sample,\n            (gt_box[0], gt_box[1]),\n            (gt_box[2], gt_box[3]),\n            (0, 0, 220), 2\n        )\n\n    ax.set_axis_off()\n    ax.imshow(sample)\n    ax.set_title(\"RED: Predicted | BLUE - Ground-truth\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bayesian Optimize\n\nfrom skopt import gp_minimize, forest_minimize\nfrom skopt.utils import use_named_args\nfrom skopt.plots import plot_objective, plot_evaluations, plot_convergence, plot_regret\nfrom skopt.space import Categorical, Integer, Real\n\ndef log(text):\n    print(text)\n\ndef optimize(space, all_predictions, n_calls=10):\n    @use_named_args(space)\n    def score(**params):\n        log('-'*10)\n        log(params)\n        final_score = calculate_final_score(all_predictions, **params)\n        log(f'final_score = {final_score}')\n        log('-'*10)\n        return -final_score\n\n    return gp_minimize(func=score, dimensions=space, n_calls=n_calls)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from utils.datasets import *\nfrom utils.utils import *\n\ndef makePseudolabel():\n    source = '../input/global-wheat-detection/test/'\n    weights = WEIGHTS\n    \n    imagenames =  os.listdir(source)\n    \n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n    # Load model\n    model = torch.load(weights, map_location=device)['model'].float()  # load to FP32\n    model.to(device).eval()\n    \n    dataset = LoadImages(source, img_size=1024)\n\n    path2save = 'train2017/'\n    \n    if not os.path.exists('convertor/fold0/labels/'+path2save):\n        os.makedirs('convertor/fold0/labels/'+path2save)\n    if not os.path.exists('convertor/fold0/images/{}'.format(path2save)):\n        os.makedirs('convertor/fold0/images/{}'.format(path2save))\n    \n    for path, img, img0, vid_cap in dataset:\n        image_id = os.path.basename(path).split('.')[0]\n        img = img.transpose(1,2,0) # [H, W, 3]\n        \n        enboxes = []\n        enscores = []\n        \n        # only rot, no flip\n        if is_ROT:    \n            for i in range(4):\n                img1 = TTAImage(img, i)\n                boxes, scores = detect1Image(img1, img0, model, device, aug=False)\n                for _ in range(3-i):\n                    boxes = rotBoxes90(boxes, *img.shape[:2])            \n                enboxes.append(boxes)\n                enscores.append(scores) \n        \n        # flip\n        boxes, scores = detect1Image(img, img0, model, device, aug=is_AUG)\n        enboxes.append(boxes)\n        enscores.append(scores) \n            \n        boxes, scores, labels = run_wbf(enboxes, enscores, image_size=1024, iou_thr=best_iou_thr, skip_box_thr=best_skip_box_thr)\n        boxes = boxes.astype(np.int32).clip(min=0, max=1024)\n        \n        boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n        boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n        \n        indices = scores >= best_score_threshold\n        boxes = boxes[indices]\n        scores = scores[indices]\n        \n        lineo = ''\n        for box in boxes:\n            x1, y1, w, h = box\n            xc, yc, w, h = (x1+w/2)/1024, (y1+h/2)/1024, w/1024, h/1024\n            lineo += '0 %f %f %f %f\\n'%(xc, yc, w, h)\n            \n        fileo = open('convertor/fold0/labels/'+path2save+image_id+\".txt\", 'w+')\n        fileo.write(lineo)\n        fileo.close()\n        sh.copy(\"../input/global-wheat-detection/test/{}.jpg\".format(image_id),'convertor/fold0/images/{}/{}.jpg'.format(path2save,image_id))\n            \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if PSEUDO or VALIDATE:\n    convertTrainLabel()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if PSEUDO:\n    # this gives worse results\n    '''\n    if VALIDATE and is_TEST:\n        all_predictions = validate()\n        for score_threshold in tqdm(np.arange(0, 1, 0.01), total=np.arange(0, 1, 0.01).shape[0]):\n            final_score = calculate_final_score(all_predictions, score_threshold)\n            if final_score > best_final_score:\n                best_final_score = final_score\n                best_score_threshold = score_threshold\n\n        print('-'*30)\n        print(f'[Best Score Threshold]: {best_score_threshold}')\n        print(f'[OOF Score]: {best_final_score:.4f}')\n        print('-'*30)\n    ''' \n    makePseudolabel()\n    \n    if is_TEST:\n        !python train.py --weights {WEIGHTS} --img 1024 --batch 2 --epochs {EPO} --data {DATA} --cfg {CONFIG}\n    else:\n        pass\n        #!python train.py --weights {WEIGHTS} --img 1024 --batch 2 --epochs 1 --data {DATA} --cfg {CONFIG}\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if VALIDATE and is_TEST:\n    all_predictions = validate()\n    \n    # Bayesian Optimization: worse results.\n    '''\n    space = [\n        Real(0, 1, name='iou_thr'),\n        Real(0.25, 1, name='skip_box_thr'),\n        Real(0, 1, name='score_threshold'),\n    ]\n\n    opt_result = optimize(\n        space, \n        all_predictions,\n        n_calls=50,\n    )\n    \n    best_final_score = -opt_result.fun\n    best_iou_thr = opt_result.x[0]\n    best_skip_box_thr = opt_result.x[1]\n    best_score_threshold = opt_result.x[2]\n\n\n    print('-'*13 + 'WBF' + '-'*14)\n    print(\"[Baseline score]\", calculate_final_score(all_predictions, 0.6, 0.43, 0))\n    print(f'[Best Iou Thr]: {best_iou_thr:.3f}')\n    print(f'[Best Skip Box Thr]: {best_skip_box_thr:.3f}')\n    print(f'[Best Score Thr]: {best_score_threshold:.3f}')\n    print(f'[Best Score]: {best_final_score:.4f}')\n    print('-'*30)\n    \n    '''\n    \n    for score_threshold in tqdm(np.arange(0, 1, 0.01), total=np.arange(0, 1, 0.01).shape[0]):\n        final_score = calculate_final_score(all_predictions, best_iou_thr, best_skip_box_thr, score_threshold)\n        if final_score > best_final_score:\n            best_final_score = final_score\n            best_score_threshold = score_threshold\n\n    print('-'*30)\n    print(f'[Best Score Threshold]: {best_score_threshold}')\n    print(f'[OOF Score]: {best_final_score:.4f}')\n    print('-'*30)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def format_prediction_string(boxes, scores):\n    pred_strings = []\n    for j in zip(scores, boxes):\n        pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(j[0], j[1][0], j[1][1], j[1][2], j[1][3]))\n\n    return \" \".join(pred_strings)\n\ndef detect():\n    source = '../input/global-wheat-detection/test/'\n    weights = 'weights/best.pt'\n    if not os.path.exists(weights):\n        weights = WEIGHTS\n    \n    imagenames =  os.listdir(source)\n    \n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n    # Load model\n    model = torch.load(weights, map_location=device)['model'].float()  # load to FP32\n    model.to(device).eval()\n    \n    dataset = LoadImages(source, img_size=1024)\n\n    results = []\n    fig, ax = plt.subplots(5, 2, figsize=(30, 70))\n    count = 0\n    \n    for path, img, img0, vid_cap in dataset:\n        image_id = os.path.basename(path).split('.')[0]\n        img = img.transpose(1,2,0) # [H, W, 3]\n        \n        enboxes = []\n        enscores = []\n        \n        # only rot, no flip\n        if is_ROT:    \n            for i in range(4):\n                img1 = TTAImage(img, i)\n                boxes, scores = detect1Image(img1, img0, model, device, aug=False)\n                for _ in range(3-i):\n                    boxes = rotBoxes90(boxes, *img.shape[:2])            \n                enboxes.append(boxes)\n                enscores.append(scores) \n        \n        # flip\n        boxes, scores = detect1Image(img, img0, model, device, aug=is_AUG)\n        enboxes.append(boxes)\n        enscores.append(scores) \n            \n        boxes, scores, labels = run_wbf(enboxes, enscores, image_size=1024, iou_thr=best_iou_thr, skip_box_thr=best_skip_box_thr)    \n        boxes = boxes.astype(np.int32).clip(min=0, max=1024)\n        boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n        boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n        \n        indices = scores >= best_score_threshold\n        boxes = boxes[indices]\n        scores = scores[indices]\n        \n        if count<10:\n            img_ = cv2.imread(path)  # BGR\n            for box, score in zip(boxes,scores):\n                cv2.rectangle(img_, (box[0], box[1]), (box[2]+box[0], box[3]+box[1]), (220, 0, 0), 2)\n                cv2.putText(img_, '%.2f'%(score), (box[0], box[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA)\n            ax[count%5][count//5].imshow(img_)\n            count+=1\n            \n        result = {\n            'image_id': image_id,\n            'PredictionString': format_prediction_string(boxes, scores)\n        }\n\n        results.append(result)\n    return results","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = detect()\ntest_df = pd.DataFrame(results, columns=['image_id', 'PredictionString'])\ntest_df.to_csv('submission.csv', index=False)\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -rf convertor","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}