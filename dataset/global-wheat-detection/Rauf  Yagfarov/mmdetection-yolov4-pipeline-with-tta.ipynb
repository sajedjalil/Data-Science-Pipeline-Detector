{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np \nimport cv2\nimport glob\nimport os\nimport sys\n\nfrom tqdm import tqdm\nfrom itertools import product\nimport torch\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nfrom IPython.display import clear_output","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Install mmdetection and dependencies","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp -r /kaggle/input/mmdetection/mmdetection-master/ /mmdetection\n!cp -r /kaggle/input/detectors/DetectoRS-mmdetv2/ /detectors\n!cp -r /kaggle/input/cocoapi/cocoapi-master/ /cocoapi\n!cp -r /kaggle/input/mmcv-lib/mmcv-0.6.2/ /mmcv\n!cp -r /kaggle/input/terminaltables/terminaltables-master/ /terminaltables\n!cp -r /kaggle/input/addict/addict-master/ /addict\n!cp -r /kaggle/input/weightedbf/Weighted-Boxes-Fusion-master/ /wbf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install /wbf\n!cd /cocoapi/PythonAPI/ && pip install -e .\nsys.path.append('/cocoapi/PythonAPI/')\n!pip install /addict\n!pip install /mmcv\n!pip install /terminaltables\n!pip install -v -e /mmdetection\nsys.path.append('/mmdetection')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp -r ../input/pytorchyolov4/pytorch-YOLOv4-master/tool .\nfrom tool.utils import *\nfrom tool.torch_utils import *\nfrom tool.darknet2pytorch import Darknet\nfrom ensemble_boxes import weighted_boxes_fusion","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Main pipeline","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## YOLO part","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"yolo_iou_threshold = 0.6\nyolo_score_threshold = 0.25\n\nyolov4_cfgfile = '../input/yolov4weights/yolov4-wheat.cfg'\nyolov4_weightfile = '../input/yolov4weights/yolov4-wheat_40000.weights'\n\nyolo_m = Darknet(yolov4_cfgfile)\nyolo_m.load_weights(yolov4_weightfile)\nyolo_m.cuda()\nyolo_num_classes = yolo_m.num_classes\n\nyolo_models = [yolo_m]\n\nyolo_transform = A.Compose([\n            A.Resize(height=1024, width=1024, p=1.0),\n            ToTensorV2(p=1.0),\n        ], p=1.0)\n\ndef convert_image_to_yolo(img):\n    image = img.copy()\n    image = cv2.resize(image, (1024, 1024))\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    sample = {'image': image}\n    sample = yolo_transform(**sample)\n    image = sample['image']\n    return (image,)\n\nclass BaseWheatTTA:\n    \"\"\" author: @shonenkov \"\"\"\n    image_size = 1024\n\n    def augment(self, image):\n        raise NotImplementedError\n    \n    def batch_augment(self, images):\n        raise NotImplementedError\n    \n    def deaugment_boxes(self, boxes):\n        raise NotImplementedError\n\nclass TTAHorizontalFlip(BaseWheatTTA):\n    \"\"\" author: @shonenkov \"\"\"\n\n    def augment(self, image):\n        return image.flip(1)\n    \n    def batch_augment(self, images):\n        return images.flip(2)\n    \n    def deaugment_boxes(self, boxes):\n        boxes[:, [1,3]] = self.image_size - boxes[:, [3,1]]\n        return boxes\n\nclass TTAVerticalFlip(BaseWheatTTA):\n    \"\"\" author: @shonenkov \"\"\"\n    \n    def augment(self, image):\n        return image.flip(2)\n    \n    def batch_augment(self, images):\n        return images.flip(3)\n    \n    def deaugment_boxes(self, boxes):\n        boxes[:, [0,2]] = self.image_size - boxes[:, [2,0]]\n        return boxes\n    \nclass TTARotate90(BaseWheatTTA):\n    \"\"\" author: @shonenkov \"\"\"\n    \n    def augment(self, image):\n        return torch.rot90(image, 1, (1, 2))\n\n    def batch_augment(self, images):\n        return torch.rot90(images, 1, (2, 3))\n    \n    def deaugment_boxes(self, boxes):\n        res_boxes = boxes.copy()\n        res_boxes[:, [0,2]] = self.image_size - boxes[:, [1,3]]\n        res_boxes[:, [1,3]] = boxes[:, [2,0]]\n        return res_boxes\n\n    \nclass TTACompose(BaseWheatTTA):\n    \"\"\" author: @shonenkov \"\"\"\n    def __init__(self, transforms):\n        self.transforms = transforms\n        \n    def augment(self, image):\n        for transform in self.transforms:\n            image = transform.augment(image)\n        return image\n    \n    def batch_augment(self, images):\n        for transform in self.transforms:\n            images = transform.batch_augment(images)\n        return images\n    \n    def prepare_boxes(self, boxes):\n        result_boxes = boxes.copy()\n        result_boxes[:,0] = np.min(boxes[:, [0,2]], axis=1)\n        result_boxes[:,2] = np.max(boxes[:, [0,2]], axis=1)\n        result_boxes[:,1] = np.min(boxes[:, [1,3]], axis=1)\n        result_boxes[:,3] = np.max(boxes[:, [1,3]], axis=1)\n        return result_boxes\n    \n    def deaugment_boxes(self, boxes):\n        for transform in self.transforms[::-1]:\n            boxes = transform.deaugment_boxes(boxes)\n        return self.prepare_boxes(boxes)\n\ndef process_det(index, det, score_threshold=0.25):\n    scores = det[index][:, 5].copy()\n    det = det[index][:, :4].copy()\n    bboxes = np.zeros((det.shape))\n    multiplier = 1024\n    bboxes[:, 0] = ((det[:, 0]) * multiplier).astype(int)\n    bboxes[:, 1] = ((det[:, 1]) * multiplier).astype(int)\n    bboxes[:, 2] = (det[:, 0] + (det[:, 2] * multiplier)).astype(int)\n    bboxes[:, 3] = (det[:, 1] + (det[:, 3] * multiplier)).astype(int)\n    bboxes = (bboxes).clip(min = 0, max = multiplier-1).astype(int)\n    \n    indexes = np.where(scores>score_threshold)\n    bboxes = bboxes[indexes]\n    scores = scores[indexes]\n    return bboxes, scores\n\n\ndef make_tta_predictions(yolo_model, image, score_threshold=0.25, iou_th=0.6):\n    predictions = np.array([])\n    with torch.no_grad():\n        images = torch.stack(image).float().cuda()\n\n        for tta_transform in yolo_tta_transforms:\n            input_img = tta_transform.batch_augment(images.clone()).permute(0,2,3,1).cpu().numpy()\n            det = do_detect(yolo_model, input_img, 0.0001, iou_th)\n            det_new = []\n            for i_i in det:\n                if i_i is not None:\n                    det_new.append(np.array(i_i))\n                else:\n                    det_new.append(np.array([]))\n            det = det_new\n            \n            if det[0].size !=0:\n                boxes, scores = process_det(0, det)\n                if len(boxes) > 0:\n                    boxes = tta_transform.deaugment_boxes(boxes.copy())\n                    boxes = (boxes).round().astype(np.int32).clip(min=0, max=1023)\n                    if len(boxes) > 0:\n                        predictions_curr = np.zeros((len(boxes), 5))\n                        predictions_curr[:,:4] = boxes\n                        predictions_curr[:,4] = scores\n                        if predictions.size==0:\n                            predictions = predictions_curr\n                        else:\n                            predictions = np.concatenate((predictions, predictions_curr), axis=0)\n                            \n    return predictions\n\nyolo_tta_transforms = []\nfor tta_combination in product([TTAHorizontalFlip(), None], \n                               [TTAVerticalFlip(), None],\n                               [TTARotate90(), None]):\n    yolo_tta_transforms.append(TTACompose([tta_transform for tta_transform in tta_combination if tta_transform]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## MMdetection part","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def format_prediction_string(boxes, scores):\n    pred_strings = []\n    for sc, bbox in zip(scores, boxes):\n        pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(sc, bbox[0], bbox[1], bbox[2], bbox[3]))\n\n    return \" \".join(pred_strings)\n\ndef predict(models, \n            test_files, \n            confidence_thresh=0.5, \n            nms_thresh = 0.5, \n            pseudolabelling_thresh = 0.8, \n            with_tta=False, \n            multiscale=False, \n            with_wbf=False, \n            wbf_weights=None, \n            clip_val=None,\n            with_yolo=True):\n\n    results = []\n    pseudo_labels = []\n\n    for img_path in test_files:\n        models_results = []\n        img = cv2.imread(img_path)\n        \n        im_w, im_h = img.shape[:2]\n        if multiscale:\n            resize_scales = [0.8, 0.7]\n            resized_imgs = []\n            for resize_scale in resize_scales:\n                img_resized = cv2.resize(img, (int(resize_scale*im_h), int(resize_scale*im_w)), cv2.INTER_AREA)\n                img_resized = cv2.resize(img_resized, (im_h, im_w), cv2.INTER_CUBIC)\n                resized_imgs.append(img_resized)\n        \n        if with_yolo:\n            image_yolo = convert_image_to_yolo(img)\n            for yolo_model in yolo_models:\n                yolo_predictions = make_tta_predictions(yolo_model, image_yolo, score_threshold=yolo_score_threshold, iou_th=yolo_iou_threshold)\n                if yolo_predictions.size!=0:\n                    models_results.append(yolo_predictions)\n                clear_output(wait=True)\n                    \n        for model_i, model in enumerate(models):\n            if with_tta:\n                wheat_result_i = detect_tta(model, img)\n                if multiscale:\n                    for resized_img in resized_imgs:\n                        wheat_result_j = detect_tta(model, resized_img)\n                        wheat_result_i = np.concatenate((wheat_result_i, wheat_result_j), axis=0)\n            else:\n                res_values = inference_detector(model, img) \n                wheat_result_i = res_values[0]\n            if model_i==0:\n                wheat_result = wheat_result_i\n            else:\n                wheat_result = np.concatenate((wheat_result, wheat_result_i), axis=0)\n            models_results.append(wheat_result_i)\n        \n        if with_wbf:\n            from ensemble_boxes import weighted_boxes_fusion\n            wbf_weights = [1] * len(models_results)\n            bboxes_wbf = [model_result[:,:4]/1024 for model_result in models_results]\n            scores_wbf = [model_result[:,4] for model_result in models_results]\n            labels_wbf = [np.zeros_like(score_wbf) for score_wbf in scores_wbf]\n            wheat_bboxes, wheat_scores, _ = weighted_boxes_fusion(bboxes_wbf, scores_wbf, labels_wbf, weights=wbf_weights, iou_thr=nms_thresh, skip_box_thr=confidence_thresh, allows_overflow=False)    \n            wheat_bboxes *= 1024\n        else:\n            wheat_bboxes, wheat_scores = nms(wheat_result[:,:4], wheat_result[:,4], nms_thresh)\n\n        res_scores = []\n        res_bboxes = []\n\n        image_id = img_path.split('/')[-1].replace('.jpg','')\n\n        for bbox, score in zip(wheat_bboxes, wheat_scores):\n            if score>=confidence_thresh:\n                if clip_val:\n                    if score>clip_val:\n                        score = clip_val\n                res_scores.append(score)\n                bbx_int = [int(bbx) for bbx in bbox]\n                bbx_int[2] = bbx_int[2] - bbx_int[0]\n                bbx_int[3] = bbx_int[3] - bbx_int[1]\n                res_bboxes.append(bbx_int)\n\n                if score>=pseudolabelling_thresh:\n                    pseudo_labels.append([image_id, 1024, 1024, f'[{bbx_int[0]}, {bbx_int[1]}, {bbx_int[2]}, {bbx_int[3]}]', 'nvnn'])\n\n\n        result = {\n                    'image_id': image_id,\n                    'PredictionString': format_prediction_string(res_bboxes, res_scores)\n                }\n\n\n        results.append(result)\n        \n    return results, pseudo_labels\n\ndef rot_bboxes_90(boxes, im_w, im_h):\n    ret_boxes =[]\n    for box in boxes:\n        x1, y1, x2, y2 = box\n        x1, y1, x2, y2 = x1-im_w//2, im_h//2 - y1, x2-im_w//2, im_h//2 - y2\n        x1, y1, x2, y2 = y1, -x1, y2, -x2\n        x1, y1, x2, y2 = int(x1+im_w//2), int(im_h//2 - y1), int(x2+im_w//2), int(im_h//2 - y2)\n        x1a, y1a, x2a, y2a = min(x1, x2), min(y1, y2), max(x1, x2), max(y1, y2)\n        ret_boxes.append([x1a, y1a, x2a, y2a])\n    return np.array(ret_boxes)\n\ndef rot_bboxes_90_n(boxes, im_w, im_h, n=1):\n    for _ in range(n):\n        boxes = rot_bboxes_90(boxes, im_w, im_h)\n    return boxes\n    \ndef flip_bboxes_lr(boxes, im_w, im_h):\n    ret_boxes =[]\n    for box in boxes:\n        x1, y1, x2, y2 = box\n        x1a, y1a, x2a, y2a = im_w-x2, y1, im_w-x1, y2\n        ret_boxes.append([x1a, y1a, x2a, y2a])\n    return np.array(ret_boxes)\n\ndef flip_bboxes_ud(boxes, im_w, im_h):\n    ret_boxes =[]\n    for box in boxes:\n        x1, y1, x2, y2 = box\n        x1a, y1a, x2a, y2a = x1, im_h - y2, x2, im_h - y1\n        ret_boxes.append([x1a, y1a, x2a, y2a])\n    return np.array(ret_boxes)\n\ndef detect_tta(model, image):\n    \n    # Original image\n    res_values = inference_detector(model, image)\n    all_results = res_values[0]\n\n    \n    # Flip lr\n    image1 = image.copy()\n    im_w, im_h = image.shape[:2]\n    fliplr_image = cv2.flip(image1, 1)\n    res_values = inference_detector(model, fliplr_image)\n    bboxes_scores = res_values[0]\n    if bboxes_scores.size!=0:\n        boxes = bboxes_scores[:,:4]\n        boxes = flip_bboxes_lr(boxes, im_w, im_h)\n        bboxes_scores[:,:4] = boxes\n        all_results = np.concatenate((all_results, bboxes_scores), axis=0)\n    \n    # Flip ud\n    image1 = image.copy()\n    im_w, im_h = image.shape[:2]\n    flipud_image = cv2.flip(image1, 0)\n    res_values = inference_detector(model, flipud_image)\n    bboxes_scores = res_values[0]\n    if bboxes_scores.size!=0:\n        boxes = bboxes_scores[:,:4]\n        boxes = flip_bboxes_ud(boxes, im_w, im_h)\n        bboxes_scores[:,:4] = boxes\n        all_results = np.concatenate((all_results, bboxes_scores), axis=0)\n    \n    # Flip lr + ud\n    image1 = image.copy()\n    im_w, im_h = image.shape[:2]\n    fliplr_image = cv2.flip(image1, 1)\n    flipud_image = cv2.flip(fliplr_image, 0)\n    res_values = inference_detector(model, flipud_image)\n    bboxes_scores = res_values[0]\n    if bboxes_scores.size!=0:\n        boxes = bboxes_scores[:,:4]\n        boxes = flip_bboxes_ud(boxes, im_w, im_h)\n        boxes = flip_bboxes_lr(boxes, im_w, im_h)\n        bboxes_scores[:,:4] = boxes\n        all_results = np.concatenate((all_results, bboxes_scores), axis=0)\n    \n    # Rotate 90\n    image1 = image.copy()\n    im_w, im_h = image.shape[:2]\n    rotated_image = cv2.rotate(image1, cv2.ROTATE_90_CLOCKWISE)\n    res_values = inference_detector(model, rotated_image)\n    bboxes_scores = res_values[0]\n    if bboxes_scores.size!=0:\n        boxes = bboxes_scores[:,:4]\n        boxes = rot_bboxes_90_n(boxes, im_w, im_h, n=3)\n        bboxes_scores[:,:4] = boxes\n        all_results = np.concatenate((all_results, bboxes_scores), axis=0)\n    \n    # Rotate -90\n    image1 = image.copy()\n    im_w, im_h = image.shape[:2]\n    rotated_image = cv2.rotate(image1, cv2.ROTATE_90_COUNTERCLOCKWISE)\n    res_values = inference_detector(model, rotated_image)\n    bboxes_scores = res_values[0]\n    if bboxes_scores.size!=0:\n        boxes = bboxes_scores[:,:4]\n        boxes = rot_bboxes_90_n(boxes, im_w, im_h, n=1)\n        bboxes_scores[:,:4] = boxes\n        all_results = np.concatenate((all_results, bboxes_scores), axis=0)\n    \n    # Rotate 90 + Flip ud\n    image1 = image.copy()\n    im_w, im_h = image.shape[:2]\n    rotated_image = cv2.rotate(image1, cv2.ROTATE_90_CLOCKWISE)\n    rot_flip_ud_image = cv2.flip(rotated_image, 0)\n    res_values = inference_detector(model, rot_flip_ud_image)\n    bboxes_scores = res_values[0]\n    if bboxes_scores.size!=0:\n        boxes = bboxes_scores[:,:4]\n        boxes = flip_bboxes_ud(boxes, im_w, im_h)\n        boxes = rot_bboxes_90_n(boxes, im_w, im_h, n=3)\n        bboxes_scores[:,:4] = boxes\n        all_results = np.concatenate((all_results, bboxes_scores), axis=0)\n    \n    # Rotate -90 + Flip ud\n    image1 = image.copy()\n    im_w, im_h = image.shape[:2]\n    rotated_image = cv2.rotate(image1, cv2.ROTATE_90_COUNTERCLOCKWISE)\n    rot_flip_ud_image = cv2.flip(rotated_image, 0)\n    res_values = inference_detector(model, rot_flip_ud_image)\n    bboxes_scores = res_values[0]\n    if bboxes_scores.size!=0:\n        boxes = bboxes_scores[:,:4]\n        boxes = flip_bboxes_ud(boxes, im_w, im_h)\n        boxes = rot_bboxes_90_n(boxes, im_w, im_h, n=1)\n        bboxes_scores[:,:4] = boxes\n        all_results = np.concatenate((all_results, bboxes_scores), axis=0)\n        \n    \n    del image1\n    \n    return all_results","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## YOLOv4 part","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Inference","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from mmdet.apis import init_detector, inference_detector\nimport mmcv \n\nMMDETECTION_PATH = '/mmdetection/'\nTEST_IMAGES_DIR = '/kaggle/input/global-wheat-detection/test/'\n# TEST_IMAGES_DIR = '/kaggle/input/global-wheat-detection/train/'\ntest_files=glob.glob(f'{TEST_IMAGES_DIR}*.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CONFIGS_PATHS = ['/kaggle/input/glf-configs/',\n                 '/kaggle/input/glf-configs/',\n#                  '/kaggle/input/detectors-configs/',\n                 '/kaggle/input/glf-configs/']\n\nWEIGHTS_PATHS = ['/kaggle/input/glf-weights/',\n                 '/kaggle/input/glf-weights/',\n#                  '/kaggle/input/detectors-weights/',\n                 '/kaggle/input/glf-weights/']\n\nWEIGHTS_NAMES = ['m1_s2_epoch_24.pth',\n                 'm2_s7_epoch_30_multiscale.pth',\n#                  'epoch_24.pth',\n                 'm2_s3_epoch_24.pth']\n\nMODEL_NAMES = ['gfl_x101',\n               'gfl_x101',\n#                'detecto_rs_model',\n               'gfl_x101']\n\n\nmodels = []\n\nfor CONFIGS_PATH, WEIGHTS_PATH, WEIGHTS_NAME, MODEL_NAME in zip(CONFIGS_PATHS, WEIGHTS_PATHS, WEIGHTS_NAMES, MODEL_NAMES):\n    config_file = os.path.join(CONFIGS_PATH, MODEL_NAME + '.py')\n    checkpoint_file = os.path.join(WEIGHTS_PATH,WEIGHTS_NAME)\n    models.append(init_detector(config_file, checkpoint_file, device='cuda:0'))\n\nif len(models)==1:\n    wbf_weights = None\nelse:\n    wbf_weights = [1] * (len(models)+1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Params","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"confidence_thresh = 0.4\nnms_thresh = 0.5\npseudolabelling_thresh = 0.4\nwith_tta = True\nwith_yolo = True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Visualize single image","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"file_name = test_files[9]\nimage = cv2.imread(file_name)\n\nmodels_results = []\nif with_yolo:\n    image_yolo = convert_image_to_yolo(image)\n    yolo_predictions = make_tta_predictions(image_yolo, score_threshold=yolo_score_threshold, iou_th=yolo_iou_threshold)\n    models_results.append(yolo_predictions)\n    \nfor model_i, model in enumerate(models):\n    if with_tta:\n        wheat_result_i = detect_tta(model, image)\n    else:\n        res_values = inference_detector(model, image) \n        wheat_result_i = res_values[0]\n    models_results.append(wheat_result_i)\nbboxes_wbf = [model_result[:,:4]/1024 for model_result in models_results]\nscores_wbf = [model_result[:,4] for model_result in models_results]\nlabels_wbf = [np.zeros_like(score_wbf) for score_wbf in scores_wbf]\n\n# wbf_weights = [2,1]\nwheat_bboxes, wheat_scores, _ = weighted_boxes_fusion(bboxes_wbf, scores_wbf, labels_wbf, weights=wbf_weights, iou_thr=nms_thresh, skip_box_thr=confidence_thresh)\n\nprint('Before WBF')\nprint(f'scores: {scores_wbf}')\nprint('After WBF')\nprint(f'scores: {wheat_scores}')\n\nwheat_bboxes *= 1024\n            \nprint(f'Before wbf {sum([len(model_result) for model_result in models_results])}')\nprint(f'After wbf {len(wheat_bboxes)}')\n\nnum_bboxes = 0\nprint(f'Before confidence thresholding {len(wheat_bboxes)}')\nfor bbox, score in zip(wheat_bboxes, wheat_scores):\n    if score>=confidence_thresh:\n        bbx_int = [int(bbx) for bbx in bbox]\n        cv2.rectangle(image, (bbx_int[0],bbx_int[1]), (bbx_int[2],bbx_int[3]), (255,0,0), 2)\n        num_bboxes+=1\nprint(f'After confidence thresholding {num_bboxes}')\n\nfig=plt.figure(figsize=(18, 16))\nplt.imshow(image)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Inference on all test data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"results, pseudo_labels = predict(models, \n                                 test_files, \n                                 confidence_thresh=confidence_thresh, \n                                 nms_thresh = nms_thresh, \n                                 pseudolabelling_thresh = pseudolabelling_thresh, \n                                 with_tta=with_tta, \n                                 with_wbf=True, \n                                 wbf_weights=wbf_weights,\n                                 with_yolo=with_yolo)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pseudolabelling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"PSEUDOLABEL = False\n# if len(os.listdir('../input/global-wheat-detection/test/'))>11:\n#      PSEUDOLABEL = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if PSEUDOLABEL:\n    !mkdir -p /pseudo/images\n    !cp /kaggle/input/global-wheat-detection/train/* /pseudo/images\n    !cp /kaggle/input/global-wheat-detection/test/* /pseudo/images\n    !ls -l /pseudo/images | wc -l\n    \n    train_df = pd.read_csv('/kaggle/input/global-wheat-detection/train.csv')\n    pseudolabels_file_name = '/pseudo/train_with_pseudo.csv'\n    pseudolabels_df = pd.DataFrame(pseudo_labels, columns =['image_id', 'width', 'height', 'bbox', 'source'])\n\n    total_df = pd.concat([pseudolabels_df,train_df], ignore_index=True)\n    total_df.to_csv(pseudolabels_file_name, index=False)\n    total_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Train with pseudolabels","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"if PSEUDOLABEL:\n    os.chdir('/mmdetection')\n    !python tools/train.py /kaggle/input/glf-configs/gfl_x101.py --work-dir /pseudo/model1/ --no-validate --resume-from /kaggle/input/glf-weights/m2_s7_epoch_30_multiscale.pth\n#     !python tools/train.py /kaggle/input/glf-configs/gfl_x101.py --work-dir /pseudo/model1/ --no-validate --resume-from /kaggle/input/glf-weights/m1_s2_epoch_24.pth\n#     !python tools/train.py /kaggle/input/glf-configs/gfl_x101.py --work-dir /pseudo/model2/ --no-validate --resume-from /kaggle/input/glf-weights/m2_s3_epoch_24.pth\n    os.chdir('/kaggle/working')\n    \n#     CONFIGS_PATHS = ['/kaggle/input/glf-configs/',\n#                      '/kaggle/input/glf-configs/']\n#     MODEL_NAMES = ['gfl_x101',\n#                    'gfl_x101']\n#     WEIGHTS_PATHS = ['/pseudo/model1/epoch_26.pth',\n#                      '/pseudo/model2/epoch_26.pth']\n    CONFIGS_PATHS = ['/kaggle/input/glf-configs/']\n    MODEL_NAMES = ['gfl_x101']\n    WEIGHTS_PATHS = ['/pseudo/model1/epoch_32.pth']\n    models_with_pseudo = []\n    for CONFIGS_PATH, WEIGHTS_PATH, MODEL_NAME in zip(CONFIGS_PATHS, WEIGHTS_PATHS, MODEL_NAMES):\n        config_file = os.path.join(CONFIGS_PATH, MODEL_NAME + '.py')\n        models_with_pseudo.append(init_detector(config_file, WEIGHTS_PATH, device='cuda:0'))\n    \n    confidence_thresh = 0.4\n    nms_thresh = 0.5\n    results, pseudo_labels = predict(models_with_pseudo, \n                                     test_files, \n                                     confidence_thresh=confidence_thresh, \n                                     nms_thresh = nms_thresh, \n                                     pseudolabelling_thresh = 0.4, \n                                     with_tta=True, \n                                     with_wbf=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls /pseudo/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.DataFrame(results, columns=['image_id', 'PredictionString'])\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.to_csv('/kaggle/working/submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !rm -r /pseudo","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}