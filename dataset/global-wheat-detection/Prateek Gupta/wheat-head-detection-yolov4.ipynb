{"cells":[{"metadata":{},"cell_type":"markdown","source":"1. TTA with WBF is not working with my YOLOv4.In this version I will use model trained on 1024x1024 resolution.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Framework used for the training: Darknet**\n**[https://github.com/AlexeyAB/darknet](http://)**\n\n**License of the above framework:**\n**[https://github.com/AlexeyAB/darknet/blob/master/LICENSE](http://)**\n\n**++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++**\n\n**Repository used for converting YOLOv4 weights into keras/TF2:**\n**[https://github.com/david8862/keras-YOLOv3-model-set](http://)**\n\n**License of the above repository:**\n**[https://github.com/david8862/keras-YOLOv3-model-set/blob/master/LICENSE](http://)**\n\n**++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++**\n\n**Training Details:**\n* I prepared the annotation files as per required for AlexeyAB/darknet's YOLOv4 from below kernel\n**[https://www.kaggle.com/pabloberhauser/creating-label-files-for-use-in-yolov4](http://)**\n \n* I followed following steps for the training:\n**[https://github.com/AlexeyAB/darknet#how-to-train-to-detect-your-custom-objects](http://)**\n\n* After lots of trial with different parameters in configuration I achieved best mAP score in training-\n\nwithout iou_thresh=0.05, mAP=0.931018\n\nwith iou_thresh=0.05, mAP=0.974559\n\n* I performed the training in my local system with following configurations-\nWindows 10, Core i7, GeForce GTX 1660 Ti, 16 GB RAM, CUDA 10.1, cuDNN 7.6.5\n\n* The final training took around 36 hours in completion\n\n**+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++**\n\n**Preparing Submission File:**\n\nI have made required changes and added my logic in following file '../input/yolo2keras/keras-YOLOv3-model-set/tools/evaluation/validate_yolo.py'\n\n**+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++**\n\n**Problem Faced:**\n\n* Could not train the model with the higher resolution image in my system due to memory error.\n\n* Could not able to use the original darknet command '.\\darknet.exe detector test..' command to test the detection on new images. Since internet is not allowed and when I uploaded the compiled Darknet repo then I was getting permission denied error due to kaggl's input directory policy.\n\n* Could not use OpenCV-Python DNN module with YOLOv4 since current version of OpenCV does not support it.\n\n* Due to above issues, I converted the YOLOv4 weights into keras/TF2 and then make inference out of it. Making the submission file was not easy with this.\n\n* Faced 'Submission csv not found' error many times while submitting the csv file.\n**+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++**\n\n**Experiments**\n\n* with iou_threshold=0.4, score=0.6626\n* with iou_threshold=0.05, score decreased to 0.6426\n* with WBF code, score=0.6815\n* with TTA and WBF, score=0.6135\n* with improved TTA and WBF, score=0.6352\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## YOLOv4 Training Result -","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# training chart showing mAP score and iteration details\nfrom IPython.display import Image\nImage(\"../input/wheat-yolov4-training-results/chart_wheat_608.png\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# console output of the detection with default iou threshold\nImage(\"../input/wheat-yolov4-training-results/detect_map_wheat.JPG\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# console output of the detection with custom iou threshold\nImage(\"../input/wheat-yolov4-training-results/detect_map_wheat_thres.JPG\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Testing Result-","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Image(\"../input/wheat-yolov4-training-results/2fd875eaa.jpg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Image(\"../input/wheat-yolov4-training-results/348a992bb.jpg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Image(\"../input/wheat-yolov4-training-results/51b3e36ab.jpg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Image(\"../input/wheat-yolov4-training-results/51f1be19e.jpg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Image(\"../input/wheat-yolov4-training-results/53f253011.jpg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Image(\"../input/wheat-yolov4-training-results/796707dd7.jpg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Image(\"../input/wheat-yolov4-training-results/aac893a91.jpg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Image(\"../input/wheat-yolov4-training-results/cb8d261a3.jpg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Image(\"../input/wheat-yolov4-training-results/cc3532ff6.jpg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Image(\"../input/wheat-yolov4-training-results/f5a1f0358.jpg\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/working/'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# import required libraries\nimport io\nimport time\nimport math\nimport cv2, colorsys\nfrom PIL import Image, ImageEnhance, ImageFilter\nimport imgaug.augmenters as iaa\nfrom matplotlib.colors import rgb_to_hsv, hsv_to_rgb\n\nfrom functools import wraps, reduce\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.lite.python import interpreter as interpreter_wrapper\nfrom tensorflow.keras.layers import Conv2D, DepthwiseConv2D, Concatenate, MaxPooling2D, BatchNormalization, Activation, UpSampling2D, ZeroPadding2D\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.regularizers import l2\n\nprint(\"TensorFlow version is: {}\".format(tf.__version__))\nprint(\"Eager execution is: {}\".format(tf.executing_eagerly()))\nprint(\"Keras version is: {}\".format(tf.keras.__version__))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Below script will run on test images and then generate the submission file**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"!python ../input/yolo2keraswbf/keras-YOLOv3-model-set/tools/evaluation/validate_yolo.py --model_path=../input/yolo2keraswbf/keras-YOLOv3-model-set/weights/wheat_yolov4.h5 --image_file=../input/global-wheat-detection/test/ --anchors_path=../input/yolo2keraswbf/keras-YOLOv3-model-set/configs/yolo4_anchors.txt --classes_path=../input/yolo2kerastta/keras-YOLOv3-model-set/configs/wheat_classes.txt --model_image_size=1024x1024","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"+++++++++++++++++++++++++++++++++ Completed +++++++++++++++++++++++++++++++++++++++++++\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**In this notebook I have taken care of licensing rule.**\n\n**The repositories I am using in this notebook have licenses as required for this challenge.**\n\n**My this notebook also demonstrates how can we use Darknet's YOLOv4 with Keras and TensorFlow.**\n\n**We can also use OpenCV with YOLOv4 but current version of OpenCV does not support some new changes in YOLOv4.**\n\n**We can run this notebook with or without GPU**","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}