{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Global Wheat Detection\n#### Can you help identify wheat heads using image analysis?\n\nThe roadmap we intend to follow:\n1. Draw out some of the images and try to make some inferences via naked eye.\n2. Then we will merge and prepapre the data for images and mark them with the labelled data from the CSV file.\n3. Then we will approach MODELLING for our prepared dataset!.\n4. We would like to try out few of the things mentioned below and will not be dissapointe few of the things don't work out:\n    1. Use Pretrained CNN Model to share the weights and prevent training from scratch.\n    2. Try to see out if we can apply Transfer Learning for better results.\n    3. Playing with Image Scaling, Number of Channels. My though process is that we should be processing the images in BLACK and WHITE channel as the riped crop will be having features like large size and larger height than the others. So we need to try this out!.","execution_count":null},{"metadata":{"_uuid":"03a2e4e4-7acb-41eb-82a8-e0134bbbb109","_cell_guid":"293b8fed-255a-4e71-a524-9c1c1ebfb560","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom PIL import Image\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"31aa8764-cf68-4213-9555-0c49a99a20de","_cell_guid":"b295c70b-50ed-4b96-8f94-508f00f8ff0d","trusted":true},"cell_type":"code","source":"# We will use 2 images: -> 86b661ae0 and dc8b73725. First we will try to print the original images and then we'll print the same in B&W.\n\n# We need to find the status of these 2 Images, what is the Target Value?\n\ntraining_data = pd.read_csv('/kaggle/input/global-wheat-detection/train.csv')\nunique_id=training_data['image_id'].value_counts()\nsource_86b661ae0 = training_data.loc[training_data['image_id'] == '86b661ae0']\nsource_dc8b73725 = training_data.loc[training_data['image_id'] == 'dc8b73725']\nprint(source_86b661ae0.source.value_counts())\nprint(source_dc8b73725.source.value_counts())\nprint(training_data.head())\nunique_id","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pathlib\nimport imageio\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nplt.figure(figsize=(16,16))\nplt.subplot(1,2,1)\nimg_array = np.array(Image.open('../input/global-wheat-detection/train/86b661ae0.jpg'))\nindex=np.where(training_data['image_id'] == '86b661ae0')\nplt.title('arvalis_1');\nplt.imshow(img_array);\nplt.subplot(1,2,2)\nimg = Image.open('../input/global-wheat-detection/train/86b661ae0.jpg')\nimg.thumbnail((120, 120), Image.ANTIALIAS)\nplt.title('arvalis_1');\nimgplot = plt.imshow(img);\n#plt.imshow(img_array);\nprint(index)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,16))\nplt.subplot(1,2,1)\nimg_array = np.array(Image.open('../input/global-wheat-detection/train/dc8b73725.jpg'))\nplt.title('arvalis_1');\nplt.imshow(img_array);\nplt.subplot(1,2,2)\nimg = Image.open('../input/global-wheat-detection/train/dc8b73725.jpg')\nimg.thumbnail((120, 120), Image.ANTIALIAS)\nplt.title('arvalis_1');\nimgplot = plt.imshow(img);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's print the same images in B&W color!\nplt.figure(figsize=(18,18))\nplt.subplot(1,2,1)\nimages = ['../input/global-wheat-detection/train/dc8b73725.jpg','../input/global-wheat-detection/train/86b661ae0.jpg']\nimage_file = Image.open(images[0]) # open colour image\nimage_file = image_file.convert('1') # convert image to black and white\nimgplot = plt.imshow(image_file);\nplt.subplot(1,2,2)\nimage_file = Image.open(images[1]) # open colour image\nimage_file = image_file.convert('1') # convert image to black and white\nimgplot = plt.imshow(image_file);\n\n# We will be trying some more experiments, like checking out the resolution before getting into Modelling and try to print the features for these 2 images as sample!.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import ast \nimport cv2\n#print(training_data.iloc[index[0][0]])\nplt.figure(figsize=(18,18))\nimg=cv2.imread(images[1])\nfor i in range(0,len(index[0])):\n    string=training_data.iloc[index[0][i]]['bbox']\n    #image=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    #image=cv2.resize(image,(120,120))\n    array=ast.literal_eval(string)\n    pt1=(array[0],array[1])\n    pt2=(array[0]+array[2],array[1]+array[3])\n    #print(array)\n    img=cv2.rectangle(img,pt1,pt2,(255,0,0),10)\nplt.imshow(img,cmap='gray');\n#plt.savefig()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image=Image.open(images[0])\nimage1=Image.open(images[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"histogram = image.histogram()\n# Take only the Red counts\nl1 = histogram[0:256]\n# Take only the Blue counts\nl2 = histogram[256:512]\n# Take only the Green counts\nl3 = histogram[512:768]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getRed(redVal):\n    return '#%02x%02x%02x' % (redVal, 0, 0)\ndef getGreen(greenVal):\n    return '#%02x%02x%02x' % (0, greenVal, 0)\ndef getBlue(blueVal):\n    return '#%02x%02x%02x' % (0, 0, blueVal)\nplt.figure(0)\n# R histogram\n\nfor i in range(0, 256):\n    plt.bar(i, l1[i], color = getRed(i), edgecolor=getRed(i), alpha=0.3)\n\n# G histogram\nplt.figure(1)\nfor i in range(0, 256):\n    plt.bar(i, l2[i], color = getGreen(i), edgecolor=getGreen(i),alpha=0.3)\n\n# B histogram\nplt.figure(2)\nfor i in range(0, 256):\n    plt.bar(i, l3[i], color = getBlue(i), edgecolor=getBlue(i),alpha=0.3)\nplt.figure(3)\nplt.imshow(image)\n\n\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"histogram = image1.histogram()\n# Take only the Red counts\nl1 = histogram[0:256]\n# Take only the Blue counts\nl2 = histogram[256:512]\n# Take only the Green counts\nl3 = histogram[512:768]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.figure(0,figsize=(6,3))\n# R histogram\n\nfor i in range(0, 256):\n    \n    plt.bar(i, l1[i], color = getRed(i), edgecolor=getRed(i), alpha=0.3)\n\n# G histogram\n\nplt.figure(1,figsize=(6,3))\nfor i in range(0, 256):\n    \n    plt.bar(i, l2[i], color = getGreen(i), edgecolor=getGreen(i),alpha=0.3)\n\n# B histogram\n\nplt.figure(2,figsize=(6,3))\nfor i in range(0, 256):\n    \n    plt.bar(i, l3[i], color = getBlue(i), edgecolor=getBlue(i),alpha=0.3)\n\nplt.figure(3,figsize=(6,3))\n\nplt.imshow(image1)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.mkdir(\"/kaggle/working/bboximages/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tempdir='/kaggle/input/global-wheat-detection/train'\ntraining_data = pd.read_csv('/kaggle/input/global-wheat-detection/train.csv')\nfile=os.listdir(tempdir)\nlen(file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import ast\nimport cv2\nfrom skimage.io import imsave\nfor i in range(0,len(file)):\n    img=cv2.imread(os.path.join(tempdir,file[i]))\n    text=file[i].split('.')[0]\n    source= training_data.loc[training_data['image_id'] ==text]\n    ind=np.where(training_data['image_id'] ==text)\n    for j in range(0,len(ind[0])):\n        string=training_data.iloc[ind[0][j]]['bbox']\n        #image=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n        #image=cv2.resize(image,(120,120))\n        array=ast.literal_eval(string)\n        pt1=(int(array[0]),int(array[1]))\n        pt2=(int(array[0]+array[2]),int(array[1]+array[3]))\n        #print(array)\n        target_img=cv2.rectangle(img,pt1,pt2,(255,0,0),10)\n    imsave('/kaggle/working/bboximages/target_{}.jpg'.format(text),target_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tempdir1='/kaggle/working/bboximages'\n\nfile1=os.listdir(tempdir1)\nlen(file1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, i'll explain what we have done!\n1. We have tried to Finalise the Channel for our Modelling and we figure out that **RED** to be the channel for modelling as pixel intensity is uniform across most of the images.\n2. Then we plotted out the *bboxes* over the images as part of EDA.\n3. Then we are saving the **images**of the booxes images which will be used for Modelling!.\n4. Next, we'll just plot some 2 random images and then start working for preparing the data for Modelling!\n5. Finally, we can see that the number of images are matching with the CSV Count.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#3248-45\n# pritning two random images!\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(15,18))\nimage1 = file[10]\nimage2 = file1[2809]\nplt.subplot(1,2,1)\nprint('Image: ',image1)\nimg_array_1 = np.array(Image.open(tempdir+'/' + image1))\nplt.imshow(img_array_1);\nplt.subplot(1,2,2)\nprint('Target: ',image2)\nimg_array_2 = np.array(Image.open(tempdir1+'/' + image2))\nplt.imshow(img_array_2);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.shape(img_array_2 )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wow, everything looks fine!. Guess Next What?\nLet's Start out Modelling process!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x=np.zeros((len(file),256,256,3))\ny=np.zeros((len(file),256,256,3))\nfor i in range(0,len(file)):\n    for j in range(0,len(file1)):\n        if file[i]==file1[j][7:]:\n            img=cv2.imread(os.path.join(tempdir,file[i]))\n            image=cv2.resize(img,(256,256))\n            tar=cv2.imread(os.path.join(tempdir1,file1[j]))\n            target=cv2.resize(tar,(256,256))\n            break\n    x[i,:,:,:]=image\n    y[i,:,:,:]=target\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num=100\nplt.figure(figsize=(15,18))\nplt.subplot(1,2,1)\nplt.imshow(x[num]/255)\nplt.subplot(1,2,2)\nplt.imshow(y[num]/255)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}