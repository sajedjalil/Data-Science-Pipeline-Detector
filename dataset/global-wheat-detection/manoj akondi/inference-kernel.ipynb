{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ../input/efficientnet","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import cv2, os\nimport numpy as np \nimport tensorflow as tf\nfrom keras.utils import Sequence\nfrom imgaug import augmenters as iaa\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n\nfrom PIL import Image\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model,load_model\nimport pandas as pd\n\nimport tensorflow.keras.backend as K\nfrom matplotlib import pyplot as plt\nfrom efficientnet import tfkeras as efn","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define the network","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"###\ncategory_n=1\noutput_layer_n=category_n+4\nstride = 2\n##########MODEL#############\ndef build_fpn(features,num_channels,wbifpn,kernel_size=2):\n    p4,p5,p6,p7 = features\n    #column1\n    p6 = Conv2D(num_channels,(3,3),kernel_initializer='glorot_uniform',activation='relu',padding='same')(p6)\n    p5 = Conv2D(num_channels,(3,3),kernel_initializer='glorot_uniform',activation='relu',padding='same')(p5)\n    p4 = Conv2D(num_channels,(3,3),kernel_initializer='glorot_uniform',activation='relu',padding='same')(p4)\n    \n    p7 = Conv2D(num_channels,(3,3),kernel_initializer='glorot_uniform',activation='relu',padding='same')(p7)\n    p7_resize = BatchNormalization()(p7)\n    p7_resize = MaxPool2D((kernel_size,kernel_size))(p7_resize)\n    if wbifpn:\n        p6_td = Fuse()([p6,p7_resize])\n    else:\n        p6_td = Add()([p6,p7_resize])\n    p6_td = Conv2D(num_channels,(3,3),kernel_initializer = 'glorot_uniform',activation='relu',padding='same')(p6_td)\n    p6_td = BatchNormalization()(p6_td)\n    p6_td = MaxPool2D((2,2),padding = 'same',strides = 1)(p6_td)\n    p6_td_resize = Conv2D(num_channels,(3,3),kernel_initializer='glorot_uniform',activation='relu',padding='same')(p6_td)\n    p6_td_resize = BatchNormalization()(p6_td_resize)\n    \n    p6_td_resize = MaxPool2D((kernel_size,kernel_size))(p6_td_resize) \n    if wbifpn:\n        p5_td = Fuse()([p5,p6_td_resize])\n    else:\n        p5_td = Add()([p5,p6_td_resize])\n    p5_td = Conv2D(num_channels,(3,3),kernel_initializer='glorot_uniform',activation='relu',padding='same')(p5_td)\n    p5_td = BatchNormalization()(p5_td)\n    p5_td = MaxPool2D((2,2),padding='same',strides = 1)(p5_td)\n    p5_td_resize = Conv2D(num_channels,(3,3),kernel_initializer='glorot_uniform',activation='relu',padding='same')(p5_td)\n    p5_td_resize = BatchNormalization()(p5_td_resize)\n    p5_td_resize = MaxPooling2D((kernel_size,kernel_size))(p5_td_resize)\n    if wbifpn:\n        p4_td = Fuse()([p4,p5_td_resize])\n    else:\n        p4_td = Add()([p4,p5_td_resize])\n    p4_td = Conv2D(num_channels,(3,3),kernel_initializer='glorot_uniform',activation='relu',padding='same')(p4_td)\n    p4_td = MaxPool2D((2,2),padding='same',strides = 1)(p4_td)\n    '''\n    p4_td_resize = Conv2D(num_channels,(3,3),kernel_initializer='glorot_uniform',activation='relu',apdding='same')(p4_td)\n    p4_td_resize = BatchNormalization()(p4_td_resize)\n    p4_td_resize = MaxPooling2D((kernel_size,kernel_size))(p4_td_resize)\n    p3_td = Add()([p3,p5_td_resize])\n    p3_td = Conv2D(num_channels,(3,3),kernel_initializer='glorot_uniform',activation='relu',padding='same')(p3_td)\n    p3_td = BatchNormalization()(p3_td)\n    p3_td = MaxPooling2D((3,3),padding='same')(p3_td)\n    '''\n    #column2\n    '''\n    p3_td = Conv2D(num_channels,(3,3),kernel_initializer='glorot_uniform',activation='relu',padding='same')(p3_td)\n    p3_td = BatchNormalization()(p3_td)\n    p4_U = UpSampling((kernel_size,kernel_size))(p3_td)\n    p4_U = Add()([p4,p4_td,p4_U])'''\n    p4_U = Conv2D(num_channels,(3,3),kernel_initializer='glorot_uniform',activation='relu',padding='same')(p4_td)\n    p4_U = BatchNormalization()(p4_U)\n    p5_U = UpSampling2D((kernel_size,kernel_size))(p4_U)\n    if wbifpn:\n        p5_U = Fuse()([p5,p5_td,p5_U])\n    else:\n        p5_U = Add()([p5,p5_td,p5_U])\n    p5_U = Conv2D(num_channels,(3,3),kernel_initializer='glorot_uniform',activation='relu',padding='same')(p5_U)\n    p5_U = BatchNormalization()(p5_U)\n    p6_U = UpSampling2D((kernel_size,kernel_size))(p5_U)\n    if wbifpn:\n        p6_U = Fuse()([p6,p6_td,p6_U])\n    else:\n        p6_U = Add()([p6,p6_td,p6_U])\n    p6_U = Conv2D(num_channels,(3,3),kernel_initializer='glorot_uniform',activation='relu',padding='same')(p6_U)\n    p6_U = BatchNormalization()(p6_U)\n    p7_U = UpSampling2D((kernel_size,kernel_size))(p6_U)\n    if wbifpn:\n        p7_U = Fuse()([p7,p7_U])\n    else:\n        p7_U = Add()([p7,p7_U])\n    p7_U = Conv2D(num_channels,(3,3),kernel_initializer='glorot_uniform',activation='relu',padding='same')(p7_U)\n    p7_U = BatchNormalization()(p7_U)\n    return (p4_U,p5_U,p6_U,p7_U)\n\ndef aggregation_block(x_shallow, x_deep, deep_ch, out_ch):\n    x_deep= Conv2DTranspose(deep_ch, kernel_size=2, strides=2, padding='same', use_bias=False)(x_deep)\n    x_deep = BatchNormalization()(x_deep)   \n    x_deep = LeakyReLU(alpha=0.1)(x_deep)\n    x = Concatenate()([x_shallow, x_deep])\n    x=Conv2D(out_ch, kernel_size=1, strides=1, padding=\"same\")(x)\n    x = BatchNormalization()(x)   \n    x = LeakyReLU(alpha=0.1)(x)\n    return x\n\ndef cbr(x, out_layer, kernel, stride,name = False):\n    if name:\n        x=Conv2D(out_layer, kernel_size=kernel, strides=stride, padding=\"same\",name='final')(x)\n    else:\n        x=Conv2D(out_layer, kernel_size=kernel, strides=stride, padding=\"same\")(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.1)(x)\n    return x\n\ndef resblock(x_in,layer_n):\n    x=cbr(x_in,layer_n,3,1)\n    x=cbr(x,layer_n,3,1)\n    x=Add()([x,x_in])\n    return x  \n\nclass Fuse(tf.keras.layers.Layer):\n    def __init__(self, epsilon=1e-4, **kwargs):\n        super(Fuse, self).__init__(**kwargs)\n        self.epsilon = epsilon\n\n    def build(self, input_shape):\n        num_in = len(input_shape)\n        self.w = self.add_weight(name=self.name,\n                                 shape=(num_in,),\n                                 initializer=tf.keras.initializers.constant(1 / num_in),\n                                 trainable=True,\n                                 dtype=tf.float32)\n\n    def call(self, inputs, **kwargs):\n        w = tf.keras.activations.relu(self.w)\n        x = tf.reduce_sum([w[i] * inputs[i] for i in range(len(inputs))], axis=0)\n        x = x / (tf.reduce_sum(w) + self.epsilon)\n        return x\n    def compute_output_shape(self, input_shape):\n        return input_shape[0]\n\n    def get_config(self):\n        config = super(Fuse, self).get_config()\n        config.update({\n            'epsilon': self.epsilon\n        })\n        return config\n    \ndef create_model(input_shape ,wbifpn=False):\n    effnet = efn.EfficientNetB4(input_shape=input_shape,weights=None,include_top = False)\n    p4 = effnet.get_layer('block2a_activation').output\n    p5 = effnet.get_layer('block3a_activation').output\n    p6 = effnet.get_layer('block4a_activation').output\n    p7 = effnet.get_layer('block7a_activation').output\n    features = (p7,p6,p5,p4)\n    features = build_fpn(features,16,wbifpn)\n    features = build_fpn(features,32,wbifpn)\n    features = build_fpn(features,64,wbifpn)\n    features = build_fpn(features,81,wbifpn)\n    features = list(features)\n\n    for i in range(1,4):\n        feature_curr = features[i]\n        feature_past = features[i-1]\n        feature_past_up = UpSampling2D((2,2))(feature_past)\n        feature_past_up = Conv2D(81,(3,3),padding='same',activation='relu',kernel_initializer='glorot_uniform')(feature_past_up)\n        if wbifpn:\n            feature_final = Fuse(name='final{}'.format(str(i)))([feature_curr,feature_past_up])\n        else:\n            feature_final = Add(name='final{}'.format(str(i)))([feature_curr,feature_past_up])\n        features[i] = feature_final\n    if stride == 2:\n        features[-1] = UpSampling2D((2,2))(features[-1])\n        features[-1] = Conv2D(128,(3,3),activation='relu',padding='same',kernel_initializer='glorot_uniform')(features[-1])\n    out = Conv2D(5,(3,3),activation='sigmoid',kernel_initializer='glorot_uniform',padding='same')(features[-1])\n    zeros = tf.expand_dims(tf.zeros_like(out[...,0]),axis=-1)\n    out_concat = tf.concat([zeros,out],axis = -1)\n    prediction_model=tf.keras.models.Model(inputs=[effnet.input],outputs=out)\n    #model = Model(inputs = [effnet.input],outputs = out_concat)\n    return prediction_model\n'''\n#I use the same network at CenterNet\ndef create_model(input_shape, aggregation=True):\n    input_layer = Input(input_shape)\n    \n    #resized input\n    input_layer_1=AveragePooling2D(2)(input_layer)\n    input_layer_2=AveragePooling2D(2)(input_layer_1)\n\n    #### ENCODER ####\n\n    x_0= cbr(input_layer, 16, 3, 2)#512->256\n    concat_1 = Concatenate()([x_0, input_layer_1])\n\n    x_1= cbr(concat_1, 32, 3, 2)#256->128\n    concat_2 = Concatenate()([x_1, input_layer_2])\n\n    x_2= cbr(concat_2, 64, 3, 2)#128->64\n    \n    x=cbr(x_2,64,3,1)\n    x=resblock(x,64)\n    x=resblock(x,64)\n    \n    x_3= cbr(x, 128, 3, 2)#64->32\n    x= cbr(x_3, 128, 3, 1)\n    x=resblock(x,128)\n    x=resblock(x,128)\n    x=resblock(x,128)\n    \n    x_4= cbr(x, 256, 3, 2)#32->16\n    x= cbr(x_4, 256, 3, 1)\n    x=resblock(x,256)\n    x=resblock(x,256)\n    x=resblock(x,256)\n    x=resblock(x,256)\n    x=resblock(x,256)\n \n    x_5= cbr(x, 512, 3, 2)#16->8\n    x= cbr(x_5, 512, 3, 1)\n    \n    x=resblock(x,512)\n    x=resblock(x,512)\n    x=resblock(x,512)\n    \n    #### DECODER ####\n    x_1= cbr(x_1, output_layer_n, 1, 1,name='final')\n    x_1 = aggregation_block(x_1, x_2, output_layer_n, output_layer_n)\n    x_2= cbr(x_2, output_layer_n, 1, 1)\n    x_2 = aggregation_block(x_2, x_3, output_layer_n, output_layer_n)\n    x_1 = aggregation_block(x_1, x_2, output_layer_n, output_layer_n)\n    x_3= cbr(x_3, output_layer_n, 1, 1)\n    x_3 = aggregation_block(x_3, x_4, output_layer_n, output_layer_n) \n    x_2 = aggregation_block(x_2, x_3, output_layer_n, output_layer_n)\n    x_1 = aggregation_block(x_1, x_2, output_layer_n, output_layer_n)\n\n    x_4= cbr(x_4, output_layer_n, 1, 1)\n\n    x=cbr(x, output_layer_n, 1, 1)\n    x= UpSampling2D(size=(2, 2))(x)#8->16 \n\n    x = Concatenate()([x, x_4])\n    x=cbr(x, output_layer_n, 3, 1)\n    x= UpSampling2D(size=(2, 2))(x)#16->32\n\n    x = Concatenate()([x, x_3])\n    x=cbr(x, output_layer_n, 3, 1)\n    x= UpSampling2D(size=(2, 2))(x)#32->64 \n\n    x = Concatenate()([x, x_2])\n    x=cbr(x, output_layer_n, 3, 1)\n    x= UpSampling2D(size=(2, 2))(x)#64->128 \n\n    x = Concatenate()([x, x_1])\n    x=Conv2D(output_layer_n, kernel_size=3, strides=1, padding=\"same\")(x)\n    out = Activation(\"sigmoid\")(x)\n    zeros = tf.expand_dims(tf.zeros_like(out[...,0]),axis=-1)\n    out_concat = tf.concat([zeros,out],axis = -1)\n    prediction_model=tf.keras.models.Model(inputs=[input_layer],outputs=out)\n    model = tf.keras.models.Model(inputs=[input_layer],outputs=out_concat)\n    return model,prediction_model\n'''\nmodel = create_model(input_shape=(512,512,3))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Function for post processing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def _ctdet_decode(hm, reg, wh, k=20, output_stride=2):\n    bboxes = []\n    scores = []\n    hm = K.eval(_nms(tf.cast(hm,tf.float32)))\n    hm = hm[0,:,:,0]\n    w = hm.shape[0]\n    hm_ = np.zeros_like(hm)\n    hm_flat = hm.reshape(-1)\n    for i in range(k):\n        m = np.argmax(hm_flat)\n        hm_[m//w][m%w] = hm_flat[m]\n        hm_flat[m] = -1\n    points = np.argwhere(hm_[:,:]!=0)\n    \n    #print(points.shape)\n    for (y,x) in points:\n        #print(type(y),type(x))\n        score = hm_[y,x]\n        offy = reg[0,y,x,0]\n        offx = reg[0,y,x,1]\n        height = wh[0,y,x,0]*OUTPUT_SIZE\n        width = wh[0,y,x,1]*OUTPUT_SIZE\n        xc = x+offx\n        yc = y+offy\n        xmin = int((xc-(width/2)))\n        ymin = int((yc-(height/2)))\n        xmax = int((xc+(width/2)))\n        ymax = int((yc+(height/2)))\n        bboxes.append([xmin,ymin,xmax,ymax])\n        scores.append(score)\n    return scores,bboxes\ndef _nms(heat, kernel=10):\n    hmax = K.pool2d(heat, (kernel, kernel), padding='same', pool_mode='max')\n    #hmax2 = K.pool2d(heat, (kernel[1], kernel[1]), padding='same', pool_mode='max')\n    #hmax3 = K.pool2d(heat, (kernel[2], kernel[2]), padding='same', pool_mode='max')\n    #hmax = (hmax1+hmax2+hmax3)/3\n    keep = K.cast(K.equal(hmax, heat), K.floatx())\n    return heat * keep\ndef NMS_all(predicts,category_n, pred_out_h, pred_out_w, score_thresh,iou_thresh):\n    y_c=predicts[...,category_n]+np.arange(pred_out_h).reshape(-1,1)\n    x_c=predicts[...,category_n+1]+np.arange(pred_out_w).reshape(1,-1)\n    height=predicts[...,category_n+2]*pred_out_h\n    width=predicts[...,category_n+3]*pred_out_w\n\n    count=0\n    for category in range(category_n):\n        predict=predicts[...,category]\n        mask=(predict>score_thresh)\n        #print(\"box_num\",np.sum(mask))\n        if mask.all==False:\n            continue\n        box_and_score=NMS(predict[mask],y_c[mask],x_c[mask],height[mask],width[mask],iou_thresh,pred_out_h, pred_out_w)\n        box_and_score=np.insert(box_and_score,0,category,axis=1)#category,score,top,left,bottom,right\n        if count==0:\n            box_and_score_all=box_and_score\n        else:\n            box_and_score_all=np.concatenate((box_and_score_all,box_and_score),axis=0)\n        count+=1\n    score_sort=np.argsort(box_and_score_all[:,1])[::-1]\n    box_and_score_all=box_and_score_all[score_sort]\n    #print(box_and_score_all)\n\n    _,unique_idx=np.unique(box_and_score_all[:,2],return_index=True)\n    #print(unique_idx)\n    return box_and_score_all[sorted(unique_idx)]\n  \ndef NMS(score,y_c,x_c,height,width,iou_thresh,pred_out_h, pred_out_w,merge_mode=False):\n    if merge_mode:\n        score=score\n        top=y_c\n        left=x_c\n        bottom=height\n        right=width\n    else:\n        #flatten\n        score=score.reshape(-1)\n        y_c=y_c.reshape(-1)\n        x_c=x_c.reshape(-1)\n        height=height.reshape(-1)\n        width=width.reshape(-1)\n        size=height*width\n\n\n        top=y_c-height/2\n        left=x_c-width/2\n        bottom=y_c+height/2\n        right=x_c+width/2\n\n        inside_pic=(top>0)*(left>0)*(bottom<pred_out_h)*(right<pred_out_w)\n        outside_pic=len(inside_pic)-np.sum(inside_pic)\n        #if outside_pic>0:\n        #  print(\"{} boxes are out of picture\".format(outside_pic))\n        normal_size=(size<(np.mean(size)*20))*(size>(np.mean(size)/20))\n        score=score[inside_pic*normal_size]\n        top=top[inside_pic*normal_size]\n        left=left[inside_pic*normal_size]\n        bottom=bottom[inside_pic*normal_size]\n        right=right[inside_pic*normal_size]\n  \n\n    \n\n  #sort  \n    score_sort=np.argsort(score)[::-1]\n    score=score[score_sort]  \n    top=top[score_sort]\n    left=left[score_sort]\n    bottom=bottom[score_sort]\n    right=right[score_sort]\n\n    area=((bottom-top)*(right-left))\n\n    boxes=np.concatenate((score.reshape(-1,1),top.reshape(-1,1),left.reshape(-1,1),bottom.reshape(-1,1),right.reshape(-1,1)),axis=1)\n\n    box_idx=np.arange(len(top))\n    alive_box=[]\n    while len(box_idx)>0:\n  \n        alive_box.append(box_idx[0])\n\n        y1=np.maximum(top[0],top)\n        x1=np.maximum(left[0],left)\n        y2=np.minimum(bottom[0],bottom)\n        x2=np.minimum(right[0],right)\n\n        cross_h=np.maximum(0,y2-y1)\n        cross_w=np.maximum(0,x2-x1)\n        still_alive=(((cross_h*cross_w)/area[0])<iou_thresh)\n        if np.sum(still_alive)==len(box_idx):\n            print(\"error\")\n            print(np.max((cross_h*cross_w)),area[0])\n        top=top[still_alive]\n        left=left[still_alive]\n        bottom=bottom[still_alive]\n        right=right[still_alive]\n        area=area[still_alive]\n        box_idx=box_idx[still_alive]\n    return boxes[alive_box]#score,top,left,bottom,right\n\ndef visualize(box_and_score,img):\n    boxes = []\n    scores = []\n    colors= [(0,0,255), (255,0,0), (0,255,255), (0,127,127), (127,255,127), (255,255,0)]\n    classes = [\"car\", \"motor\", \"person\", \"bus\", \"truck\", \"bike\"]\n    number_of_rect=np.minimum(500,len(box_and_score))\n\n    for i in reversed(list(range(number_of_rect))):\n        predicted_class, score, top, left, bottom, right = box_and_score[i,:]\n\n\n        top = np.floor(top + 0.5).astype('int32')\n        left = np.floor(left + 0.5).astype('int32')\n        bottom = np.floor(bottom + 0.5).astype('int32')\n        right = np.floor(right + 0.5).astype('int32')\n\n        predicted_class = int(predicted_class)\n\n        label = '{:.2f}'.format(score)\n        #print(label)\n        #print(top, left, right, bottom)\n        cv2.rectangle(img, (left, top), (right, bottom), colors[predicted_class], 3)\n        cv2.putText(img, label, (left, top), cv2.FONT_HERSHEY_SIMPLEX ,  \n                       0.5, (255,255,255), 2, cv2.LINE_AA) \n        boxes.append([left, top, right-left, bottom-top])\n        scores.append(score)\n    \n    return np.array(boxes), np.array(scores)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Convert to submission format\nBorrowed from [here](https://www.kaggle.com/pestipeti/pytorch-starter-fasterrcnn-train)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def format_prediction_string(boxes, scores):\n    pred_strings = []\n    for j in zip(scores, boxes):\n        pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(j[0], j[1][0], j[1][1], j[1][2], j[1][3]))\n\n    return \" \".join(pred_strings)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DIR_INPUT = '/kaggle/input/global-wheat-detection'\nDIR_TRAIN = f'{DIR_INPUT}/train'\nDIR_TEST = f'{DIR_INPUT}/test'\n\n\nimagenames = os.listdir(DIR_TEST)\n\n#def predict_image(imagenames,input_size=320, weights_file=''):\ninput_size = 512\n\npred_out_h=int(input_size/stride)\npred_out_w=int(input_size/stride)\n\nmodel=create_model(input_shape=(input_size,input_size,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imagenames","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Inference","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"weights_list = []\nfor weight in os.listdir('../input/centrenettrained'):\n    weights_list.append('../input/centrenettrained/'+weight)\nweights_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nINPUT_SIZE = 512\nOUTPUT_SIZE = INPUT_SIZE//4\nresults = []\nmodel = create_model((INPUT_SIZE,INPUT_SIZE,3))\n\nfor test_image in os.listdir(DIR_TEST):\n    ids = test_image.split('.')[0] \n    imagecv = cv2.imread(DIR_TEST+'/'+test_image)\n    w,h = imagecv.shape[0],imagecv.shape[1]\n    image = cv2.resize(imagecv,(INPUT_SIZE,INPUT_SIZE))\n    output = np.zeros((OUTPUT_SIZE,OUTPUT_SIZE,5))\n    for i,weight in enumerate(weights_list):\n        #print('predicting...{}'.format(i))\n        model.load_weights(weight)\n        output = output + model.predict(image.reshape(-1,INPUT_SIZE,INPUT_SIZE,3)/255)\n    output = output/(i+1)\n    hm = output[:,:,:,0].reshape((1,OUTPUT_SIZE,OUTPUT_SIZE,1))\n    reg = output[:,:,:,1:3]\n    wh = output[:,:,:,3:]\n    scores,detections = _ctdet_decode(hm, reg, wh, k=30, output_stride=4)\n    fig,ax = plt.subplots(1,2,figsize=(10,10))\n    ax[0].imshow(imagecv)\n    for i in range(len(detections)):\n        #print(i)\n        #score = scores[i]\n        detection = detections[i]\n        xmin = detection[0]*(w/OUTPUT_SIZE)\n        #print(xmin)\n        xmin = int(int(xmin>0)*xmin)\n        if xmin>w:\n            xmin = w\n        ymin = detection[1]*(h/OUTPUT_SIZE)\n        ymin = int(ymin*int(ymin>0))\n        if ymin>h:\n            ymin = h\n        xmax = detection[2]*(w/OUTPUT_SIZE)\n        xmax = int(xmax*int(xmax>0))\n        if xmax>w:\n            xmax = w\n        ymax = detection[3]*(h/OUTPUT_SIZE)\n        ymax = int(ymax*int(ymax>0))\n        if ymax>h:\n            ymax = h\n        #print(xmin,ymin,xmax,ymax)\n        #print(type(imagecv))\n        cv2.rectangle(imagecv,(xmin,ymin),(xmax,ymax),(0,0,255),3)\n        #cv2.putText(imagecv, score, (xmin, ymin), cv2.FONT_HERSHEY_SIMPLEX ,  \n        #               0.5, (255,255,255), 2, cv2.LINE_AA)\n        detections[i] = [xmin,ymin,xmax,ymax] \n        \n    #print(i)\n    ax[1].imshow(imagecv)\n    result = {\n                'image_id': ids,\n                'PredictionString': format_prediction_string(detections, scores)\n            }\n    results.append(result)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = []\nfig, axes = plt.subplots(10, 1,figsize=(160,80))\nfor count, name in enumerate(imagenames):\n    ids = name.split('.')[0] \n    imagepath = '%s/%s.jpg'%(DIR_TEST,ids)\n    imgcv = cv2.imread(imagepath)\n    img = cv2.resize(imgcv, (input_size, input_size))\n    predict0 = np.zeros((pred_out_h,pred_out_w,5))\n    for i,weight in enumerate(weights_list):\n        model.load_weights(weight)\n        predict0 = predict0+ model.predict((img[np.newaxis])/255).reshape(pred_out_h,pred_out_w,5)\n    predict0  = predict0/(i+1)\n    #print(img.shape)\n    print_h, print_w = imgcv.shape[:2]\n    #print(predict.shape)\n\n    \n    box_and_score=NMS_all(predict0,category_n, pred_out_h, pred_out_w, score_thresh=0.25,iou_thresh=0.5)\n    if len(box_and_score)==0:\n        print('no boxes found!!')\n        #return\n        result = {\n                'image_id': ids,\n                'PredictionString': ''\n            }\n\n        results.append(result)\n    else:\n\n        #heatmap=predict[:,:,2]\n\n        box_and_score=box_and_score*[1,1,print_h/pred_out_h,print_w/pred_out_w,print_h/pred_out_h,print_w/pred_out_w]\n        # img=draw_rectangle(box_and_score[:,2:],img,\"red\")\n        # img=draw_rectangle(true_boxes,img,\"blue\")\n        preds, scores = visualize(box_and_score,imgcv)\n\n        result = {\n                'image_id': ids,\n                'PredictionString': format_prediction_string(preds, scores)\n            }\n\n        results.append(result)\n    \n\n    \n    # #axes[0].set_axis_off()\n    if count <10:\n        axes[count].imshow(imgcv)\n    # #axes[1].set_axis_off()\n    # axes[1].imshow(heatmap)#, cmap='gray')\n    # #axes[2].set_axis_off()\n    # #axes[2].imshow(heatmap_1)#, cmap='gray')\nplt.show()\n    #break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.DataFrame(results, columns=['image_id', 'PredictionString'])\ntest_df.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}