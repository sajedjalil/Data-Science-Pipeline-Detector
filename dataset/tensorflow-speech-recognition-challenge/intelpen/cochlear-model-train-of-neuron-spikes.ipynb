{"nbformat_minor":1,"cells":[{"cell_type":"code","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n"},{"cell_type":"code","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"source":"# Any results you write to the current directory are saved as output.\n\nimport cochlea\nfrom scipy.io import wavfile\n\nimport numpy as np\nimport scipy\nimport pandas as pd\n#import os\n#import multiprocessing\n\ndef accumulate(spike_trains, ignore=None, keep=None):\n    \"\"\"Concatenate spike trains with the same meta data. Trains will\n    be sorted by the metadata.\n    \"\"\"\n\n    assert None in (ignore, keep)\n\n    keys = spike_trains.columns.tolist()\n\n    if ignore is not None:\n        for k in ignore:\n            keys.remove(k)\n\n    if keep is not None:\n        keys = keep\n\n    if 'duration' not in keys:\n        keys.append('duration')\n\n    if 'spikes' in keys:\n        keys.remove('spikes')\n\n\n    groups = spike_trains.groupby(keys, as_index=False)\n\n    acc = []\n    for name,group in groups:\n        if not isinstance(name, tuple):\n            name = (name,)\n        spikes = np.concatenate(tuple(group['spikes']))\n        acc.append(name + (spikes,))\n\n    columns = list(keys)\n    columns.append('spikes')\n\n    acc = pd.DataFrame(acc, columns=columns)\n\n    return acc\n\n\n\ndef extractSpikes(filename , channelsNo = 128 , colsNo = 512):\n  fs, samples = wavfile.read(filename)\n  norm = (500.0)/np.max(np.abs(samples))\n  samples = norm*samples  \n  samples = cochlea.set_dbspl(samples,50)\n  fs100kHz = 100e3\n  down = fs*100/fs100kHz \n  samples100kHz =scipy.signal.resample_poly(samples,up = 100, down = down)\n  samples100kHz = cochlea.set_dbspl(samples100kHz,50)\n  anf_trains = cochlea.run_zilany2014(sound= samples100kHz, fs = fs100kHz, anf_num = (0,0,50), cf= (125,10e3,channelsNo) ,seed = 0,\n                                    powerlaw=\"approximate\",  species = 'human' )\n  anf_trains= accumulate(anf_trains)\n  spikes = anf_trains[\"spikes\"].as_matrix()\n  spikesImage = np.zeros(shape = [channelsNo, colsNo])\n  maxTime=np.concatenate(spikes).max()\n  for index in range(spikes.shape[0]):\n    spikesNorm = (colsNo-1)*spikes[index]/maxTime\n    spikesInt = spikesNorm.astype(dtype = np.int)\n    spikesImage[index, spikesInt] = 1 \n  #plt.figure()\n  #plt.imshow(spikesImage)\n  #plt.show()\n  return spikesImage\ndef extractSpikesParallel(arguments):\n  try :\n    filenameIn, filenameOut = arguments\n    print(filenameIn)\n    print(filenameOut)\n    spikesTrain = extractSpikes(filenameIn, channelsNo = 128 , colsNo = 512)\n    np.savetxt(fname =filenameOut, X =spikesTrain,fmt=\"%d\", delimiter = \";\")  \n    print(\"finished\"+filenameOut)\n  except :\n    print(\"There was an error here\")\n  return 1"},{"cell_type":"code","outputs":[],"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"7c95595c-35ca-45d8-b0ac-a201057d842f","_uuid":"b9ca9538381a03bdc8e0fd25ce2c7c5f94a78e66"},"source":"\n\n\nfrom scipy import misc\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.python.framework import ops\nfrom tf_utils import load_dataset, random_mini_batchesT, convert_to_one_hot\nimport sys\n#np.random.seed(1)\nimport time\n\nlabelsList = [\"_silence_\",\"_unknown_\",\"yes\",\"no\",\"up\",\"down\",\"left\",\"right\",\"on\",\"off\",\"stop\",\"go\"]\nnoClasses = len(labelsList)\n#%%\nclass Params:\n  imageWidth = 512\n  imageHeight = 128\n  def __init__(self, imageWidth = 512, imageHeight = 128):\n    self.imageWidth = imageWidth\n    self.imageHeight = imageHeight\n\n\ndef load_dataset(rootDir, labelsList):\n  print(rootDir)\n  X = []\n  Y = []  \n  for label in os.listdir(rootDir):\n    \n    dirLabel = rootDir + \"//\" + label\n    print('Found directory: %s' % dirLabel)\n    index = 0\n    for filename in os.listdir(dirLabel):\n       if index % 1 == 0 :\n          #print('\\t%s' % fname)\n          filename = dirLabel+\"//\"+ filename\n          image= np.zeros(shape = [128,512], dtype = np.uint8)\n          img = pd.read_csv(filename, sep=\";\").as_matrix()\n          image[0:127,:] = img\n          \n          X.append(image)\n          yL = np.zeros(shape = [noClasses])\n          yL[labelsList.index(label)]=1\n          Y.append(yL)\n          \n          #if index > 500:\n          #  break\n       index = index +1\n  X = np.array(X)\n  Y= np.array(Y)\n  \n  print(X.shape)\n  print(Y.shape)\n  \n  permutation = list(np.random.permutation(X.shape[0]))\n  X = X[permutation,:]\n  Y = Y[permutation,:]\n  \n  no_examples =X.shape[0] \n  X_Train= X[0:int(0.90*no_examples),:]\n  Y_Train =Y[0:int(0.90*no_examples),:] \n  X_Test = X[int(0.90*no_examples):int(1*no_examples),:]\n  Y_Test = Y[int(0.90*no_examples):int(1*no_examples),:]\n  classes = labelsList\n  return X_Train, Y_Train, X_Test, Y_Test, classes\n\ndef deepnn(x):\n  noClasses=12\n  \"\"\"deepnn builds the graph for a deep net for classifying digits.  Args:\n    x: an input tensor with the dimensions (N_examples, 3*92*46), where 784 is the\n    number of pixels in a standard MNIST image.\n  Returns:\n    A tuple (y, keep_prob). y is a tensor of shape (N_examples, noClasses), with values equal to the logits of classifying the imagesinto one of 2 classes .\n    keep_prob is a scalar placeholder for the probability of     dropout.\n  \"\"\"\n  # Reshape to use within a convolutional neural net.   # Last dimension - it would be 3 for an RGB image, 4 for RGBA, etc.\n  XFloat = tf.cast(x, dtype = tf.float32)\n  #XNorm = tf.scalar_mul(1.0/255.0, XFloat)\n  \n  with tf.name_scope('reshape'):\n    x_image = tf.reshape(XFloat, [-1, 128, 512, 1]) #was 28 28, 28, 1\n  # First convolutional layer - maps one grayscale image to 32 feature maps.\n  with tf.name_scope('conv1'):\n    W_conv1 = weight_variable([5, 5, 1, 16]) #W_conv1 = weight_variable([5, 5, 1, 32]) try fatter features\n    b_conv1 = bias_variable([16])\n    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n\n  # Pooling layer - downsamples by 2X.\n  with tf.name_scope('pool1'):\n    #h_pool1= tf.sqrt(tf.nn.avg_pool(tf.square(h_conv1),ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1], padding='SAME'))\n    h_pool1 = max_pool_2x2(h_conv1)\n\n  # Second convolutional layer -- maps 32 feature maps to 64.\n  with tf.name_scope('conv2'):\n    W_conv2 = weight_variable([8, 8, 16, 32]) #W_conv2 = weight_variable([5, 5, 32, 64])\n    b_conv2 = bias_variable([32])\n    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n\n  # Second pooling layer.\n  with tf.name_scope('pool2'):\n    #h_pool2= tf.sqrt(tf.nn.avg_pool(tf.square(h_conv2),ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1], padding='SAME'))\n    h_pool2 = max_pool_2x2(h_conv2)\n\n\n# third convolutional layer -- maps 32 feature maps to 64.\n  with tf.name_scope('conv3'):\n    W_conv3 = weight_variable([5, 5, 32, 64]) #W_conv2 = weight_variable([5, 5, 32, 64])\n    b_conv3 = bias_variable([64])\n    h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n\n  # Second pooling layer.\n  with tf.name_scope('pool3'):\n    #h_pool2= tf.sqrt(tf.nn.avg_pool(tf.square(h_conv2),ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1], padding='SAME'))\n    h_pool3 = max_pool_2x2(h_conv3)\n\n\n  # Fully connected layer 1 -- after 2 round of downsampling, our 128x512 image\n  # is down to 16x64x64 feature maps -- maps this to 1024 features.\n  with tf.name_scope('fc1'):\n    W_fc1 = weight_variable([16*64*64, 512])\n    b_fc1 = bias_variable([512])\n\n    h_pool2_flat = tf.reshape(h_pool3, [-1,16*64*64])\n    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n\n  # Dropout - controls the complexity of the model, prevents co-adaptation of\n  # features.\n  with tf.name_scope('dropout'):\n    keep_prob = tf.placeholder(tf.float32, name = \"keep_prob\")\n    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n\n  # Map the 1024 features to 10 classes, one for each digit\n  with tf.name_scope('fc2'):\n    W_fc2 = weight_variable([512, noClasses])\n    b_fc2 = bias_variable([noClasses])\n    y_conv = tf.add(tf.matmul(h_fc1_drop, W_fc2),b_fc2, name = \"Y_Conv\")\n  return y_conv, keep_prob\ndef conv2d(x, W):\n  \"\"\"conv2d returns a 2d convolution layer with full stride.\"\"\"\n  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\ndef max_pool_2x2(x):\n  \"\"\"max_pool_2x2 downsamples a feature map by 2X.\"\"\"\n  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n                        strides=[1, 2, 2, 1], padding='SAME')\ndef max_pool_4x4(x):\n  \"\"\"max_pool_2x2 downsamples a feature map by 2X.\"\"\"\n  return tf.nn.max_pool(x, ksize=[1, 4, 4, 1],\n                        strides=[1, 4, 4, 1], padding='SAME')\n  \ndef weight_variable(shape):\n  \"\"\"weight_variable generates a weight variable of a given shape.\"\"\"\n  initial = tf.truncated_normal(shape, stddev=0.1)\n  return tf.Variable(initial)\ndef bias_variable(shape):\n  \"\"\"bias_variable generates a bias variable of a given shape.\"\"\"\n  initial = tf.constant(0.1, shape=shape)\n  return tf.Variable(initial)\n#%%\n  \n\ndef initParameters():\n  global PARAMS\n  PARAMS = Params()\n  PARAMS.imageHeight = 128\n  PARAMS.imageWidth = 512\n\ndef one_hot_matrix(labels, C):\n  \"\"\" Creates a matrix where the i-th row corresponds to the ith class number and the jth column  corresponds to the jth training example. So if example j had a label i. Then entry (i,j)  will be 1. \n  Arguments:\n  labels -- vector containing the labels \n  C -- number of classes, the depth of the one hot dimension\n  Returns: \n  one_hot -- one hot matrix\n  \"\"\"\n  C = tf.constant(C, name = \"C\")\n  # Use tf.one_hot, be careful with the axis \n  one_hot_matrix = tf.one_hot( labels, depth = C, axis = 0 ) #you can receive variables without a placeholder ... probably if used once\n  sess = tf.Session()\n  one_hot = sess.run(one_hot_matrix )\n  sess.close()\n  return one_hot\n\ndef ones(shape):\n  \"\"\"\n  Creates an array of ones of dimension shape\n  Arguments:\n  shape -- shape of the array you want to create\n  Returns: \n  ones -- array containing only ones\n  \"\"\"\n  ones = tf.ones(shape)\n  sess = tf.Session()\n  ones = sess.run(ones)\n  sess.close()\n  return ones\n\ndef create_placeholders( n_y):\n  \"\"\"  Creates the placeholders for the tensorflow session.\n  Arguments:\n  n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n  n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n  Returns:\n  X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n  Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n  Tips:     - \" None\" let's us be flexible on the number of examples you will for the placeholders.  In fact, the number of examples during test/train is different.\n  \"\"\"\n  X = tf.placeholder(dtype = tf.uint8, shape=(None,128,512), name = \"X\")\n  Y = tf.placeholder(dtype = tf.float32, shape=(None,n_y), name = \"Y\")\n  return X, Y\n\ndef compute_cost(Y_conv, Y):\n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Y_conv, labels = Y))\n    return cost\n\ndef model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001, num_epochs = 1500, minibatch_size = 32, print_cost = True, tfModelSavePath =\"\"):\n    \"\"\"     Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n    Arguments:\n    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n    learning_rate -- learning rate of the optimization\n    num_epochs -- number of epochs of the optimization loop\n    minibatch_size -- size of a minibatch\n    print_cost -- True to print the cost every 100 epochs\n    Returns:\n    parameters -- parameters learnt by the model. They can then be used to predict.\n    \"\"\"\n    tf.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n    tf.set_random_seed(1)                             # to keep consistent results\n    seed = 3                                          # to keep consistent results\n    m,n_y = Y_train.shape                            # n_y : output size\n    costs = []                                        # To keep track of the cost\n    train_accuracys = []                                        # To keep track of the cost\n    test_accuracys = []                                        # To keep track of the cost\n    # Create Placeholders of shape (n_x, n_y)    \n    X, Y = create_placeholders(n_y)\n    # Forward propagation: Build the forward propagation in the tensorflow graph\n    y_conv, keep_prob = deepnn(X)\n    # Cost function: Add cost function to tensorflow graph\n    cost = compute_cost(y_conv,Y) \n    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n    #optimizer =  tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n    optimizer =  tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n    # Initialize all the variables\n    init = tf.global_variables_initializer()\n    # Start the session to compute the tensorflow graph\n    correct_prediction = tf.equal(tf.argmax(y_conv, axis =1), tf.argmax(Y, axis = 1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n        \n    with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n        saver = tf.train.Saver() #SAVE\n        # Run the initialization\n        sess.run(init)\n        curr_time = time.time()\n        # Do the training loop\n        for epoch in range(num_epochs):\n            epoch_cost = 0.                       # Defines a cost related to an epoch\n            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n            seed = seed + 1\n            minibatches = random_mini_batchesT(X_train, Y_train, minibatch_size, seed)\n            for minibatch in minibatches:\n                # Select a minibatch\n                (minibatch_X, minibatch_Y) = minibatch\n                # IMPORTANT: The line that runs the graph on a minibatch. Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n                _ , minibatch_cost = sess.run([optimizer,cost], feed_dict = {X:minibatch_X, Y:minibatch_Y , keep_prob : 0.2 })\n                epoch_cost += minibatch_cost / num_minibatches\n            # Print the cost every epoch\n            if print_cost == True and epoch % 2 == 0:\n                new_time = time.time()\n                print(\"Time/epoch:\"+str((new_time-curr_time)/2))\n                curr_time=new_time\n                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n            if print_cost == True and epoch % 5 == 0:\n                costs.append(epoch_cost)\n                (minibatch_X, minibatch_Y) = minibatches[0]\n                train_accuracys.append(accuracy.eval({X: minibatch_X, Y: minibatch_Y, keep_prob : 1}))\n                test_accuracys.append(accuracy.eval({X: X_test[0:128,:], Y: Y_test[0:128  ,:], keep_prob : 1}))\n                plotAccuracys(train_accuracys,test_accuracys,learning_rate)\n                plotCosts(costs,learning_rate)\n        saver.save(sess, tfModelSavePath)\n        tf.train.write_graph(sess.graph_def, tfModelSavePath , \"ModelTFPerson.pb\", as_text=True)\n        #plot the cost\n        plotCosts(costs,learning_rate)\n        \n        print (\"Parameters have been trained!\")\n        #print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test, keep_prob : 1}))\n        \ndef predictOnly(X_test ):\n  \n  tf.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n  \n  tf.set_random_seed(1)                             # to keep consistent results\n  seed = 3                                          # to keep consistent results\n  (m,n_x) = X_test.shape                          # (n_x: input size, m : number of examples in the train set)\n  costs = []                                        # To keep track of the cost\n  # Create Placeholders of shape (n_x, n_y)    \n  X = tf.placeholder(dtype = tf.uint8, shape=(None, n_x))\n  # Forward propagation: Build the forward propagation in the tensorflow graph\n  y_conv, keep_prob = deepnn(X)\n  init = tf.global_variables_initializer()\n  # Start the session to compute the tensorflow graph\n  with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n      sess.run(init)\n      tfModelSavePath = \"D:\\\\Dev\\\\ML\\\\PersonDetection\\\\NeuralNet3LTensorFlow\\\\TFSavedModels\"\n      saver = tf.train.Saver()\n      saver = tf.train.import_meta_graph(tfModelSavePath +\"\\\\.meta\")   # Load :  Important\n      saver.restore(sess, tfModelSavePath + \"\\\\\" ) # Load :  Important\n      start_time = time.time()\n      for i in range (100):\n        yOut =  sess.run([y_conv], feed_dict = {X:X_test, keep_prob : 1 })\n      end_time = time.time()\n      print(\"Elapsed\"+str(end_time-start_time))\n  return yOut\n\n        \ndef plotCosts(costs, learning_rate):\n  plt.plot(np.squeeze(costs))\n  plt.ylabel('Cost')\n  plt.xlabel('iterations (per tens)')\n  plt.title(\"Learning rate =\" + str(learning_rate))\n  plt.show()\n\ndef plotAccuracys(train_accuracys,test_accuracys,learning_rate):\n  plt.plot(np.squeeze(train_accuracys))\n  plt.plot(np.squeeze(test_accuracys))\n  plt.ylabel('Accuracy')\n  plt.xlabel('iterations (per tens)')\n  plt.title(\"Learning rate =\" + str(learning_rate))\n  plt.show()\n\ndef printOutput(X, Y , Y_True): \n  \n  for i in range(X.shape[0]):\n    if Y[i]!=Y_True[i]:\n      plt.imshow(np.reshape(X[i], newshape=[92,46,3]))\n      plt.show()\n      im=np.reshape(X[i], newshape=[92,46,3])\n      print(\"Y_pred=\"+str(Y[i])+ \"Y_true\"+str(Y_True[i]))\n      misc.imsave(\"D://data//ML//ImageSegmentation//out//True\"+str(Y_True[i])+\"//Pred\"+str(Y[i])+\"_\" +str(i)+\".jpg\",im)\n  \n#%%\n#%%\n# Loading the dataset\n\nrootDir = \"E://data//kaggle//TFSpeechRC//train//spikes128x512\"  \nif not('X_train_orig' in locals()):\n  X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset(rootDir, labelsList)\n# Change the index below and run the cell to visualize some examples in the dataset.\n\n#%%\n\n\n# Flatten the training and test images\nX_train = X_train_orig #/255.\nX_test = X_test_orig #/255.\nY_train = Y_train_orig\nY_test = Y_test_orig\nprint (\"number of training examples = \" + str(X_train.shape[0]))\nprint (\"number of test examples = \" + str(X_test.shape[0]))\nprint (\"X_train shape: \" + str(X_train.shape))\nprint (\"Y_train shape: \" + str(Y_train.shape))\nprint (\"X_test shape: \" + str(X_test.shape))\nprint (\"Y_test shape: \" + str(Y_test.shape))\n\n#%%\n# Example of a picture\nindex = 300\nplt.imshow(X_train_orig[index])\nplt.show()\nprint (\"y = \" + str(Y_train_orig[index])+labelsList[np.argmax(Y_train_orig[index])] )\n\nindex = 100\nplt.imshow(X_train_orig[index])\nplt.show()\nprint (\"y = \" + str(Y_train_orig[index])+labelsList[np.argmax(Y_train_orig[index])] )\n\n\nindex = 15\nplt.imshow(X_train_orig[index])\nplt.show()\nprint (\"y = \" + str(Y_train_orig[index])+labelsList[np.argmax(Y_train_orig[index])] )\n\n\n\nindex = 4\nplt.imshow(X_test[index])\nplt.show()\nprint (\"y = \" + str(Y_test[index])+labelsList[np.argmax(Y_test[index])] )\n\n#%% def trainAndSave():\ntfModelSavePath = \"E://science//info//Competitions//Kaggle//TFSpeechRC//SavedModel//\"\nmodel(X_train, Y_train, X_test, Y_test,learning_rate = 1e-3,num_epochs = 50, minibatch_size = 64, print_cost = True,tfModelSavePath =tfModelSavePath )\n"},{"cell_type":"code","outputs":[],"execution_count":null,"metadata":{"collapsed":true},"source":"labelsList = [\"silence\",\"unknown\",\"yes\",\"no\",\"up\",\"down\",\"left\",\"right\",\"on\",\"off\",\"stop\",\"go\"]\n#%%\ndef main():\n  \n  audioFilesDir = \"E://data//kaggle//TFSpeechRC//test//audio//\"\n  spikesFilesDir = \"E://data//kaggle//TFSpeechRC//test//spikes128x512//\"\n  #spikesFilesDir = \"E://data//kaggle//TFSpeechRC//train//spikes128x512//off//\"\n  index = 0\n  \n  tf.reset_default_graph()   \n  sess= tf.Session() \n  #model is restored here\n  tfModelSavePath = \"E://science//info//Competitions//Kaggle//TFSpeechRC//SavedModel\"\n  saver = tf.train.import_meta_graph(\"E://science//info//Competitions//Kaggle//TFSpeechRC//SavedModel//.meta\")   # Load :  Important\n  saver.restore(sess, tfModelSavePath + \"\\\\\" ) # Load :  Important\n  graph = tf.get_default_graph() # Load :  Important\n  x = graph.get_tensor_by_name(\"X:0\") # Load :  Important\n  keep = graph.get_tensor_by_name(\"dropout/keep_prob:0\") # Load :  Important\n  Y_conv = graph.get_tensor_by_name(\"fc2/Y_Conv:0\") \n  \n  \n  outL = []\n  fileList = os.listdir(spikesFilesDir)\n  \n  for file in fileList:\n    index = index +1 \n    if index % 1 == 0 :\n      \n      if (index%1000==0):\n        print(\"Index\" + str(index) +\" : \"+str(file))\n      image= np.zeros(shape = [1,128,512], dtype = np.uint8)\n      img = pd.read_csv(spikesFilesDir + file, sep=\";\").as_matrix()\n      image[0,0:127,:] = img\n      \n      #plt.imshow(image[0])\n      #plt.show()\n      \n     \n      feed_dict ={x:image,keep:1.0 }  \n      # Feed the audio data as input to the graph.    #   predictions  will contain a two-dimensional array, where one         #   dimension represents the input image count, and the other has     #   predictions per class\n      YConv = sess.run(Y_conv, feed_dict)\n      # Sort to show labels in order of confidence\n      top_k = np.argmax(YConv)\n      #print(YConv)\n      human_string = labelsList[top_k]\n      outL.append([file[0:-4],human_string])\n      #print(file[0:-4] + human_string)\n  df = pd.DataFrame(outL,index =None, columns = [\"fname\",\"label\"])\n  #print(df)\n  df.to_csv(\"my_sample_submission3.csv\",index = False)\n\n      \n        \nif __name__ == '__main__':\n  main()"}],"nbformat":4,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","mimetype":"text/x-python","pygments_lexer":"ipython3","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.4","nbconvert_exporter":"python"}}}