{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1D Inception Model Approach (KOR)\n## Origin: https://www.kaggle.com/ivallesp/wavception-v1-a-1-d-inception-approach-lb-0-76\n### Translated by siryuon","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\nimport numpy as np \nimport pandas as pd \nimport os\nimport shutil\nimport glob\nimport random\nfrom tqdm import tqdm\nfrom collections import Counter\nfrom sklearn.preprocessing import LabelEncoder\nimport IPython\nfrom numpy.fft import rfft, irfft\nimport numpy as np\nimport random\nimport itertools\n\nfrom scipy.io import wavfile\nimport IPython.display as ipd\nimport matplotlib.pyplot as plt\nimport scipy as sp\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2021-09-25T11:57:07.987078Z","iopub.execute_input":"2021-09-25T11:57:07.987355Z","iopub.status.idle":"2021-09-25T11:57:07.998984Z","shell.execute_reply.started":"2021-09-25T11:57:07.987325Z","shell.execute_reply":"2021-09-25T11:57:07.998154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 노이즈를 만들어 주는 함수들  \n출처: https://github.com/python-acoustics/python-acoustics/blob/master/acoustics/generator.py\n\n\n|Color|Power|Power Density|\n|------|:--------:|:---:|\n|White|+3 dB|0 dB|\n|Pink|0 dB|-3 dB|\n|Blue|+6 dB|+3 dB|\n|Brown|-3 dB|-6 dB|\n|Violet|+9 dB|+6 dB|","metadata":{}},{"cell_type":"code","source":"#Mean Squared\ndef ms(x):\n    return (np.abs(x)**2.0).mean()\n\ndef normalize(y, x=None):\n    if x is not None:\n        x = ms(x)\n    else:\n        x = 1.0\n    return y * np.sqrt( x / ms(y) )\n\ndef white_noise(N, state=None):\n    state = np.random.RandomState() if state is None else state\n    return state.randn(N)\n\ndef pink_noise(N, state=None):\n    state = np.random.RandomState() if state is None else state\n    uneven = N%2\n    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n    S = np.sqrt(np.arange(len(X))+1.) # +1 to avoid divide by zero\n    y = (irfft(X/S)).real\n    if uneven:\n        y = y[:-1]\n    return normalize(y)\n\ndef blue_noise(N, state=None):\n    state = np.random.RandomState() if state is None else state\n    uneven = N%2\n    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n    S = np.sqrt(np.arange(len(X)))# Filter\n    y = (irfft(X*S)).real\n    if uneven:\n        y = y[:-1]\n    return normalize(y)\n\ndef brown_noise(N, state=None):\n    state = np.random.RandomState() if state is None else state\n    uneven = N%2\n    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n    S = (np.arange(len(X))+1)# Filter\n    y = (irfft(X/S)).real\n    if uneven:\n        y = y[:-1]\n    return normalize(y)\n\ndef violet_noise(N, state=None):\n    state = np.random.RandomState() if state is None else state\n    uneven = N%2\n    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n    S = (np.arange(len(X)))# Filter\n    y = (irfft(X*S)).real\n    if uneven:\n        y = y[:-1]\n    return normalize(y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tensorflow 기본 동작 수행을 위한 함수들","metadata":{}},{"cell_type":"code","source":"#사용할 GPU와 프로세스가 사용할 수 있는 메모리 양을 선택하는 함수\ndef get_tensorflow_configuration(device=\"0\", memory_fraction=1):\n    device = str(device)\n    config = tf.ConfigProto()\n    config.allow_soft_placement = True\n    config.gpu_options.per_process_gpu_memory_fraction = memory_fraction\n    config.gpu_options.visible_device_list = device\n    return(config)\n\n#사용할 GPU 장치와 사전 할당될 메모리 비율을 처리하는 TF 세션을 시작하는 함수\ndef start_tensorflow_session(device=\"0\", memory_fraction=1):\n    return(tf.Session(config=get_tensorflow_configuration(device=device, memory_fraction=memory_fraction)))\n\n#리포팅 함수(기록)\ndef get_summary_writer(session, logs_path, project_id, version_id):\n    path = os.path.join(logs_path,\"{}_{}\".format(project_id, version_id)) \n    if os.path.exists(path):\n        shutil.rmtree(path)\n    summary_writer = tf.summary.FileWriter(path, graph_def=session.graph_def)\n    return(summary_writer)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 데이터 Path와 관련된 함수들","metadata":{}},{"cell_type":"code","source":"#경로 검색 기능의 출력을 정규화하는 데 사용하기 위한 데코레이터 함수. 슬래시/백슬래시 창의 경우를 수정하는 데 유용.\ndef _norm_path(path):\n    def normalize_path(*args, **kwargs):\n        return os.path.normpath(path(*args, **kwargs))\n    return normalize_path\n\n#경로 검색 기능의 출력이 있는지 확인하기 위한 데코레이터 함수. 슬래시/백슬래시 창의 경우를 수정하는 데 유용.\ndef _assure_path_exists(path):\n    def assure_exists(*args, **kwargs):\n        p=path(*args, **kwargs)\n        assert os.path.exists(p), \"the following path does not exist: '{}'\".format(p)\n        return p\n    return assure_exists\n\n#출력 경로 검색 기능의 출력에 적용되는 기능을 그룹화하기 위한 데코레이터 함수\ndef _is_output_path(path):\n    @_norm_path\n    @_assure_path_exists\n    def check_existence_or_create_it(*args, **kwargs):\n        if not os.path.exists(path(*args, **kwargs)):\n            \"Path does not exist... creating it: {}\".format(path(*args, **kwargs))\n            os.makedirs(path(*args, **kwargs))\n        return path(*args, **kwargs)\n    return check_existence_or_create_it\n\n#입력 경로 검색 기능의 출력에 적용되는 기능을 그룹화하기 위한 데코레이터 함수\ndef _is_input_path(path):\n    @_norm_path\n    @_assure_path_exists\n    def check_existence(*args, **kwargs):\n        return path(*args, **kwargs)\n    return check_existence\n\n@_is_input_path\ndef get_train_path():\n    path = \"../input/train\"\n    return path\n\n@_is_input_path\ndef get_test_path():\n    path = \"../input/test\"\n    return path\n\n@_is_input_path\ndef get_train_audio_path():\n    path = os.path.join(get_train_path(), \"audio\")\n    return path\n\n@_is_input_path\ndef get_scoring_audio_path():\n    path = os.path.join(get_test_path(), \"audio\")\n    return path\n\n@_is_output_path\ndef get_submissions_path():\n    path = \"../working/output\"\n    return path\n\n@_is_output_path\ndef get_silence_path():\n    path = \"../working/silence\"\n    return path","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Handling Tools","metadata":{}},{"cell_type":"code","source":"flatten = lambda l: [item for sublist in l for item in sublist]\n\ndef batching(iterable, n=1):\n    l = len(iterable)\n    for ndx in range(0, l, n):\n        yield iterable[ndx:min(ndx + n, l)]\n\n#wav 파일의 파일 경로가 주어지면 이 함수는 파일을 읽고 정규화하고 패딩하여 16k 샘플이 있는지 확인함.\ndef read_wav(filepath, pad=True):\n    sample_rate, x = wavfile.read(filepath)\n    target = os.path.split(os.path.split(filepath)[0])[1]\n    assert sample_rate==16000\n    if pad:\n        return np.pad(x, (0, 16000-len(x)), mode=\"constant\")/32768, target\n    else:\n        return x/32768, target\n    \n#배치 목록이 주어지면 Batch Generator를 빌드\ndef get_batcher(list_of_paths, batch_size, label_encoder=None, scoring=False):\n    for filepaths in batching(list_of_paths, batch_size):\n        wavs, targets = zip(*list(map(read_wav, filepaths)))\n        if scoring:\n            yield np.expand_dims(np.row_stack(wavs), 2), filepaths\n        else:\n            if label_encoder is None:\n                yield np.expand_dims(np.row_stack(wavs), 2), np.row_stack(targets)\n            else:\n                yield np.expand_dims(np.row_stack(wavs), 2), np.expand_dims(label_encoder.transform(np.squeeze(targets)),1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Block을 만드는 함수 (1D Inception)\n#### 기존 CNN보다 향상된 성능을 보인다.","metadata":{}},{"cell_type":"code","source":"#BatchNormalization (밑의 inception_1d의 normalization function parameter로 사용될 예정)\nclass BatchNorm(object):\n    def __init__(self, epsilon=1e-5, momentum=0.999, name=\"batch_norm\"):\n        with tf.variable_scope(name):\n            self.epsilon = epsilon\n            self.momentum = momentum\n            self.name = name\n\n    def __call__(self, x, train=True):\n        return tf.contrib.layers.batch_norm(x,\n                                            decay=self.momentum,\n                                            updates_collections=None,\n                                            epsilon=self.epsilon,\n                                            scale=True,\n                                            is_training=train,\n                                            scope=self.name)\n    \n    \n#구조: CONV1D(64,1x1) -> CONV1D(128,3x3) -> CONV1D(128, 5x5) -> CONV1D(128, 7x7) -> MAXPOOL(16, 3x3) + CONV1D(16, 1x1)\n#-> MAXPOOL(16,5x5) + CONV1D(16,1x1) -> AVGPOOL(16,3x3) + CONV1D(16,1x1) -> AVGPOOL(16,5x5) + CONV1D(16,1x1)\ndef inception_1d(x, is_train, depth, norm_function, activ_function, name):\n    with tf.variable_scope(name):\n        x_norm = norm_function(name=\"norm_input\")(x, train=is_train)\n\n        # Branch 1: 64 x conv 1x1 \n        branch_conv_1_1 = tf.layers.conv1d(inputs=x_norm, filters=16*depth, kernel_size=1,\n                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n                                           padding=\"same\", name=\"conv_1_1\")\n        branch_conv_1_1 = norm_function(name=\"norm_conv_1_1\")(branch_conv_1_1, train=is_train)\n        branch_conv_1_1 = activ_function(branch_conv_1_1, \"activation_1_1\")\n\n        # Branch 2: 128 x conv 3x3 \n        branch_conv_3_3 = tf.layers.conv1d(inputs=x_norm, filters=16, kernel_size=1, \n                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n                                           padding=\"same\", name=\"conv_3_3_1\")\n        branch_conv_3_3 = norm_function(name=\"norm_conv_3_3_1\")(branch_conv_3_3, train=is_train)\n        branch_conv_3_3 = activ_function(branch_conv_3_3, \"activation_3_3_1\")\n\n        branch_conv_3_3 = tf.layers.conv1d(inputs=branch_conv_3_3, filters=32*depth, kernel_size=3, \n                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n                                           padding=\"same\", name=\"conv_3_3_2\")\n        branch_conv_3_3 = norm_function(name=\"norm_conv_3_3_2\")(branch_conv_3_3, train=is_train)\n        branch_conv_3_3 = activ_function(branch_conv_3_3, \"activation_3_3_2\")\n\n        # Branch 3: 128 x conv 5x5 \n        branch_conv_5_5 = tf.layers.conv1d(inputs=x_norm, filters=16, kernel_size=1, \n                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n                                           padding=\"same\", name=\"conv_5_5_1\")\n        branch_conv_5_5 = norm_function(name=\"norm_conv_5_5_1\")(branch_conv_5_5, train=is_train)\n        branch_conv_5_5 = activ_function(branch_conv_5_5, \"activation_5_5_1\")\n\n        branch_conv_5_5 = tf.layers.conv1d(inputs=branch_conv_5_5, filters=32*depth, kernel_size=5, \n                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n                                           padding=\"same\", name=\"conv_5_5_2\")\n        branch_conv_5_5 = norm_function(name=\"norm_conv_5_5_2\")(branch_conv_5_5, train=is_train)\n        branch_conv_5_5 = activ_function(branch_conv_5_5, \"activation_5_5_2\")\n\n        # Branch 4: 128 x conv 7x7\n        branch_conv_7_7 = tf.layers.conv1d(inputs=x_norm, filters=16, kernel_size=1, \n                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n                                           padding=\"same\", name=\"conv_7_7_1\")\n        branch_conv_7_7 = norm_function(name=\"norm_conv_7_7_1\")(branch_conv_7_7, train=is_train)\n        branch_conv_7_7 = activ_function(branch_conv_7_7, \"activation_7_7_1\")\n\n        branch_conv_7_7 = tf.layers.conv1d(inputs=branch_conv_7_7, filters=32*depth, kernel_size=5, \n                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n                                           padding=\"same\", name=\"conv_7_7_2\")\n        branch_conv_7_7 = norm_function(name=\"norm_conv_7_7_2\")(branch_conv_7_7, train=is_train)\n        branch_conv_7_7 = activ_function(branch_conv_7_7, \"activation_7_7_2\")\n\n        # Branch 5: 16 x (max_pool 3x3 + conv 1x1)\n        branch_maxpool_3_3 = tf.layers.max_pooling1d(inputs=x_norm, pool_size=3, strides=1, padding=\"same\", name=\"maxpool_3\")\n        branch_maxpool_3_3 = norm_function(name=\"norm_maxpool_3_3\")(branch_maxpool_3_3, train=is_train)\n        branch_maxpool_3_3 = tf.layers.conv1d(inputs=branch_maxpool_3_3, filters=16, kernel_size=1, \n                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n                                              padding=\"same\", name=\"conv_maxpool_3\")\n\n        # Branch 6: 16 x (max_pool 5x5 + conv 1x1)\n        branch_maxpool_5_5 = tf.layers.max_pooling1d(inputs=x_norm, pool_size=5, strides=1, padding=\"same\", name=\"maxpool_5\")\n        branch_maxpool_5_5 = norm_function(name=\"norm_maxpool_5_5\")(branch_maxpool_5_5, train=is_train)\n        branch_maxpool_5_5 = tf.layers.conv1d(inputs=branch_maxpool_5_5, filters=16, kernel_size=1, \n                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n                                              padding=\"same\", name=\"conv_maxpool_5\")\n\n        # Branch 7: 16 x (avg_pool 3x3 + conv 1x1)\n        branch_avgpool_3_3 = tf.layers.average_pooling1d(inputs=x_norm, pool_size=3, strides=1, padding=\"same\", name=\"avgpool_3\")\n        branch_avgpool_3_3 = norm_function(name=\"norm_avgpool_3_3\")(branch_avgpool_3_3, train=is_train)\n        branch_avgpool_3_3 = tf.layers.conv1d(inputs=branch_avgpool_3_3, filters=16, kernel_size=1,\n                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n                                              padding=\"same\", name=\"conv_avgpool_3\")\n\n        # Branch 8: 16 x (avg_pool 5x5 + conv 1x1)\n        branch_avgpool_5_5 = tf.layers.average_pooling1d(inputs=x_norm, pool_size=5, strides=1, padding=\"same\", name=\"avgpool_5\")\n        branch_avgpool_5_5 = norm_function(name=\"norm_avgpool_5_5\")(branch_avgpool_5_5, train=is_train)\n        branch_avgpool_5_5 = tf.layers.conv1d(inputs=branch_avgpool_5_5, filters=16, kernel_size=1, \n                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n                                              padding=\"same\", name=\"conv_avgpool_5\")\n\n        #합치기\n        output = tf.concat([branch_conv_1_1, branch_conv_3_3, branch_conv_5_5, branch_conv_7_7, branch_maxpool_3_3, \n                           branch_maxpool_5_5, branch_avgpool_3_3, branch_avgpool_5_5], axis=-1)\n        return output","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 데이터 로드 및 준비","metadata":{}},{"cell_type":"code","source":"# 합성한 노이즈와 원래 노이즈 데이터 셋 합치기\nfilepaths_noise = glob.glob(os.path.join(get_train_audio_path(), \"_background_noise_\", \"*.wav\"))\n\nnoise = np.concatenate(list(map(lambda x: read_wav(x, False)[0], filepaths_noise)))\nnoise = np.concatenate([noise, noise[::-1]])\nsynthetic_noise = np.concatenate([white_noise(N=16000*30, state=np.random.RandomState(655321)), \n                                  blue_noise(N=16000*30, state=np.random.RandomState(655321)),\n                                  pink_noise(N=16000*30, state=np.random.RandomState(655321)),\n                                  brown_noise(N=16000*30, state=np.random.RandomState(655321)),\n                                  violet_noise(N=16000*30, state=np.random.RandomState(655321)),\n                                  np.zeros(16000*60)])\nsynthetic_noise /= np.max(np.abs(synthetic_noise))\nsynthetic_noise = np.concatenate([synthetic_noise, (synthetic_noise+synthetic_noise[::-1])/2])\nall_noise = np.concatenate([noise, synthetic_noise])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(655321)\nrandom.seed(655321)\n\npath = get_silence_path()\n\nif not os.path.exists(path):\n    os.makedirs(path) # It fails in kaggle kernel due to the read-only filesystem\n\nfor noise_clip_no in tqdm(range(8000)):\n    if noise_clip_no<=4000:\n        idx = np.random.randint(0, len(noise)-16000)\n        clip = noise[idx:(idx+16000)]\n    else:\n        idx = np.random.randint(0, len(synthetic_noise)-16000)\n        clip = synthetic_noise[idx:(idx+16000)]\n    wavfile.write(os.path.join(path, \"{0:04d}.wav\".format(noise_clip_no)), 16000, \n                               ((32767*clip/np.max(np.abs(clip))).astype(np.int16)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filepaths = glob.glob(os.path.join(get_train_audio_path(), \"**/*.wav\"), recursive=True)\nfilepaths += glob.glob(os.path.join(get_silence_path(), \"**/*.wav\"), recursive=True)\nfilepaths = list(filter(lambda fp: \"_background_noise_\" not in fp, filepaths))\nvalidation_list = open(os.path.join(get_train_path(), \"validation_list.txt\")).readlines()\ntest_list = open(os.path.join(get_train_path(), \"testing_list.txt\")).readlines()\nvalidation_list = list(map(lambda fn: os.path.join(get_train_audio_path(), fn.strip()), validation_list))\ntesting_list = list(map(lambda fn: os.path.join(get_train_audio_path(), fn.strip()), test_list))\ntraining_list = np.setdiff1d(filepaths, validation_list+testing_list).tolist()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.seed(655321)\nrandom.shuffle(filepaths)\nrandom.shuffle(validation_list)\nrandom.shuffle(testing_list)\nrandom.shuffle(training_list)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 제대로 수행되었는지 확인하는 assert문들\nassert all(map(lambda fp: os.path.splitext(fp)[1]==\".wav\", filepaths))\nassert len(filepaths)==64727 - 6 + 8000\nassert len(training_list) == len(filepaths) - 6798 - 6835 \nassert len(validation_list) == 6798\nassert len(testing_list) == 6835\n\nassert all(map(lambda fn: os.path.exists(os.path.join(fn)), validation_list))\nassert all(map(lambda fn: os.path.exists(os.path.join(fn)), testing_list))\nassert all(map(lambda fn: os.path.exists(os.path.join(fn)), training_list))\nassert set(validation_list + testing_list + training_list) == set(filepaths)\n\nassert len(np.intersect1d(validation_list, testing_list))==0\nassert len(np.intersect1d(training_list, testing_list))==0\nassert len(np.intersect1d(training_list, validation_list))==0","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 클래스 처리\ncardinal_classes = list(set(map(lambda fp:os.path.split(os.path.split(fp)[0])[1], filepaths)))\nle_classes = LabelEncoder().fit(cardinal_classes)\nCounter(map(lambda fp:os.path.split(os.path.split(fp)[0])[1], filepaths))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_gen_test = get_batcher(filepaths, 1000)\nbatch_a_wav, batch_a_target = next(_gen_test)\nbatch_b_wav, batch_b_target = next(_gen_test)\n_gen_test_le = get_batcher(filepaths, 1000, label_encoder=le_classes)\nbatch_le_wav, batch_le_target = next(_gen_test_le)\n\nassert batch_a_wav.shape == (1000, 16000, 1)\nassert batch_le_wav.shape == (1000, 16000, 1)\nassert batch_a_wav.shape == batch_b_wav.shape == batch_le_wav.shape\n\nassert np.sum(np.abs(batch_a_wav-batch_b_wav)) != 0\nassert len(batch_a_target) == len(batch_b_target) == len(batch_le_target)\nassert any(batch_a_target != batch_b_target)\n\nassert all(batch_le_target == np.expand_dims(le_classes.transform(np.squeeze(batch_a_target)),1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 구조 디자인","metadata":{}},{"cell_type":"code","source":"class NameSpacer:\n    def __init__(self, **kwargs):\n        self.__dict__.update(kwargs)\n\nclass Architecture:\n    def __init__(self, class_cardinality, seq_len=16000, name=\"architecture\"):\n        self.seq_len = seq_len\n        self.class_cardinality = class_cardinality\n        self.optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n        self.name=name\n        self.define_computation_graph()\n        \n        #Aliases\n        self.ph = self.placeholders\n        self.op = self.optimizers\n        self.summ = self.summaries\n\n    def define_computation_graph(self):\n        # Reset graph\n        tf.reset_default_graph()\n        self.placeholders = NameSpacer(**self.define_placeholders())\n        self.core_model = NameSpacer(**self.define_core_model())\n        self.losses = NameSpacer(**self.define_losses())\n        self.optimizers = NameSpacer(**self.define_optimizers())\n        self.summaries = NameSpacer(**self.define_summaries())\n\n    def define_placeholders(self):\n        with tf.variable_scope(\"Placeholders\"):\n            wav_in = tf.placeholder(dtype=tf.float32, shape=(None, self.seq_len, 1), name=\"wav_in\")\n            is_train = tf.placeholder(dtype=tf.bool, shape=None, name=\"is_train\")\n            target = tf.placeholder(dtype=tf.int32, shape=(None, 1), name=\"target\")\n            acc_dev = tf.placeholder(dtype=tf.float32, shape=None, name=\"acc_dev\")\n            loss_dev = tf.placeholder(dtype=tf.float32, shape=None, name=\"loss_dev\")\n            return({\"wav_in\": wav_in, \"target\": target, \"is_train\": is_train, \"acc_dev\": \n                    acc_dev, \"loss_dev\": loss_dev})\n        \n    def define_core_model(self):\n        with tf.variable_scope(\"Core_Model\"):\n            x = inception_1d(x=self.placeholders.wav_in, is_train=self.placeholders.is_train, \n                             norm_function=BatchNorm, activ_function=tf.nn.relu, depth=1,\n                             name=\"Inception_1_1\")\n            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n                             activ_function=tf.nn.relu, depth=1, name=\"Inception_1_2\")\n            x = tf.layers.max_pooling1d(x, 2, 2, name=\"maxpool_1\")\n            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n                             activ_function=tf.nn.relu, depth=1, name=\"Inception_2_1\")\n            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n                             activ_function=tf.nn.relu, depth=1, name=\"Inception_2_3\")\n            x = tf.layers.max_pooling1d(x, 2, 2, name=\"maxpool_2\")\n            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n                             activ_function=tf.nn.relu, depth=2, name=\"Inception_3_1\")\n            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n                             activ_function=tf.nn.relu, depth=2, name=\"Inception_3_2\")\n            x = tf.layers.max_pooling1d(x, 2, 2, name=\"maxpool_3\")\n            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n                             activ_function=tf.nn.relu, depth=2, name=\"Inception_4_1\")\n            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n                             activ_function=tf.nn.relu, depth=2, name=\"Inception_4_2\")\n            x = tf.layers.max_pooling1d(x, 2, 2, name=\"maxpool_4\")\n            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n                             activ_function=tf.nn.relu, depth=3, name=\"Inception_5_1\")\n            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n                             activ_function=tf.nn.relu, depth=3, name=\"Inception_5_2\")\n            x = tf.layers.max_pooling1d(x, 2, 2, name=\"maxpool_5\")\n            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n                             activ_function=tf.nn.relu, depth=3, name=\"Inception_6_1\")\n            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n                             activ_function=tf.nn.relu, depth=3, name=\"Inception_6_2\")\n            x = tf.layers.max_pooling1d(x, 2, 2, name=\"maxpool_6\")\n            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n                             activ_function=tf.nn.relu, depth=4, name=\"Inception_7_1\")\n            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n                             activ_function=tf.nn.relu, depth=4, name=\"Inception_7_2\")\n            x = tf.layers.max_pooling1d(x, 2, 2, name=\"maxpool_7\")\n            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n                             activ_function=tf.nn.relu, depth=4, name=\"Inception_8_1\")\n            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n                             activ_function=tf.nn.relu, depth=4, name=\"Inception_8_2\")\n            x = tf.layers.max_pooling1d(x, 2, 2, name=\"maxpool_8\")\n            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n                             activ_function=tf.nn.relu, depth=4, name=\"Inception_9_1\")\n            x = inception_1d(x=x, is_train=self.placeholders.is_train, norm_function=BatchNorm, \n                             activ_function=tf.nn.relu, depth=4, name=\"Inception_9_2\")\n            x = tf.layers.max_pooling1d(x, 2, 2, name=\"maxpool_9\")\n            x = tf.contrib.layers.flatten(x)\n            x = tf.layers.dense(BatchNorm(name=\"bn_dense_1\")(x,train=self.placeholders.is_train),\n                                128, activation=tf.nn.relu, kernel_initializer=tf.contrib.layers.xavier_initializer(),\n                                name=\"dense_1\")\n            output = tf.layers.dense(BatchNorm(name=\"bn_dense_2\")(x,train=self.placeholders.is_train),\n                                self.class_cardinality, activation=None, kernel_initializer=tf.contrib.layers.xavier_initializer(),\n                                name=\"output\")\n            return({\"output\": output})\n        \n    def define_losses(self):\n        with tf.variable_scope(\"Losses\"):\n            softmax_ce = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=tf.squeeze(self.placeholders.target), \n                                                                        logits=self.core_model.output,\n                                                                        name=\"softmax\")\n            return({\"softmax\": softmax_ce})\n\n    def define_optimizers(self):\n        with tf.variable_scope(\"Optimization\"):\n            op = self.optimizer.minimize(self.losses.softmax)\n            return({\"op\": op})\n\n    def define_summaries(self):\n        with tf.variable_scope(\"Summaries\"):\n            ind_max = tf.squeeze(tf.cast(tf.argmax(self.core_model.output, axis=1), tf.int32))\n            target = tf.squeeze(self.placeholders.target)\n            acc= tf.reduce_mean(tf.cast(tf.equal(ind_max, target), tf.float32))\n            loss = tf.reduce_mean(self.losses.softmax)\n            train_scalar_probes = {\"accuracy\": acc, \n                                   \"loss\": loss}\n            train_performance_scalar = [tf.summary.scalar(k, tf.reduce_mean(v), family=self.name) \n                                        for k, v in train_scalar_probes.items()]\n            train_performance_scalar = tf.summary.merge(train_performance_scalar)\n\n            dev_scalar_probes = {\"acc_dev\": self.placeholders.acc_dev, \n                                 \"loss_dev\": self.placeholders.loss_dev}\n            dev_performance_scalar = [tf.summary.scalar(k, v, family=self.name) for k, v in dev_scalar_probes.items()]\n            dev_performance_scalar = tf.summary.merge(dev_performance_scalar)\n            return({\"accuracy\": acc, \"loss\": loss, \"s_tr\": train_performance_scalar, \"s_de\": dev_performance_scalar})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 모델 실행","metadata":{}},{"cell_type":"code","source":"net = Architecture(class_cardinality=len(cardinal_classes), name=\"wavception\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sess = start_tensorflow_session(device=\"1\")\nsw = get_summary_writer(sess, \"~/.logs_tensorboard/\", \"wavception\", \"V1\") # Adjust your tensorboard logs path here\nc=0","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sess.run(tf.global_variables_initializer())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(655321)\nrandom.seed(655321)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(50000):\n    random.shuffle(training_list)\n    batcher = get_batcher(training_list, 16, le_classes)\n    for i, (batch_x, batch_y) in enumerate(batcher):\n        _, loss, acc, s = sess.run([net.op.op, net.losses.softmax, net.summ.accuracy, net.summ.s_tr],\n                                 feed_dict={net.ph.wav_in: batch_x, net.ph.target: batch_y, \n                                            net.ph.is_train: True})\n        print(\"[{0:04d}|{1:04d}] Accuracy train: {2:.2f}%\".format(epoch, i, acc*100))\n        sw.add_summary(s, c)\n        \n        if c%1000==0: # Validation\n            accuracies_dev=[]\n            losses_dev=[]\n            batcher = get_batcher(validation_list, 16, le_classes)\n            for i, (batch_x, batch_y) in enumerate(batcher):\n                acc, loss= sess.run([net.summ.accuracy, net.summ.loss], \n                               feed_dict={net.ph.wav_in: batch_x, net.ph.target: batch_y, \n                                          net.ph.is_train: False})\n                accuracies_dev.append(acc)\n                losses_dev.append(loss)\n            s = sess.run(net.summ.s_de, feed_dict={net.ph.acc_dev: np.mean(accuracies_dev),\n                                                        net.ph.loss_dev: np.mean(losses_dev)})\n            sw.add_summary(s, c)\n        c += 1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"테스트","metadata":{}},{"cell_type":"code","source":"accuracies=[]\nbatcher = get_batcher(testing_list, 64, le_classes)\nfor i, (batch_x, batch_y) in tqdm(enumerate(batcher)):\n    acc= sess.run(net.summ.accuracy, feed_dict={net.ph.wav_in: batch_x, net.ph.target: batch_y, \n                                                     net.ph.is_train: False})\n    accuracies.append(acc)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 예측 및 제출 파일 생성","metadata":{}},{"cell_type":"code","source":"scoring_list = glob.glob(os.path.join(get_scoring_audio_path(), \"*.wav\"), recursive=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batcher = get_batcher(scoring_list, 80, le_classes, scoring=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fns = []\nprds = []\nfor i, (batch_x, filepaths) in tqdm(enumerate(batcher)):\n    pred = sess.run(net.core_model.output, feed_dict={net.ph.wav_in: batch_x, net.ph.is_train: False})\n    fns.extend(map(lambda f:os.path.split(f)[1], filepaths))\n    prds.extend(map(lambda f:np.argmax(pred, axis=1).tolist(), pred))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.DataFrame({\"fname\":fns, \"label\": prds})\ndf.label = le_classes.inverse_transform(df.label)\ndf.loc[~df.label.isin([\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\", \"silence\"]), \"label\"]=\"unknown\"\ndf.to_csv(os.path.join(get_submissions_path(), \"submission.csv\"), index=False)","metadata":{},"execution_count":null,"outputs":[]}]}