{"cells":[{"outputs":[],"metadata":{"_uuid":"6e5f850f028ed6067d925e9b0bc5631afb2568be","_cell_guid":"d2a8577a-5d33-4543-a2d6-eac36ddb9f80"},"cell_type":"code","source":"import os\nimport numpy as np\nfrom scipy.fftpack import fft\nfrom scipy.io import wavfile\nfrom scipy import signal\nfrom glob import glob\nimport re\nimport pandas as pd\nimport gc\nfrom scipy.io import wavfile\n\nfrom keras import optimizers, losses, activations, models\nfrom keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization\nfrom sklearn.model_selection import train_test_split\nimport keras","execution_count":null},{"outputs":[],"metadata":{"_uuid":"9e143662405f843852435607ee056c3e284a7605","_cell_guid":"9de944c8-21c8-42b1-a343-fb3e472100be"},"cell_type":"code","source":"##################\nL = 16000\nlegal_labels = 'yes no up down left right on off stop go silence unknown'.split()\n\n#src folders\nroot_path = r'..'\nout_path = r'.'\nmodel_path = r'.'\ntrain_data_path = os.path.join(root_path, 'input', 'train', 'audio')\ntest_data_path = os.path.join(root_path, 'input', 'test', 'audio')\n\n\n##############\n\ndef custom_fft(y, fs):\n    T = 1.0 / fs\n    N = y.shape[0]\n    yf = fft(y)\n    xf = np.linspace(0.0, 1.0/(2.0*T), N//2)\n    # FFT is simmetrical, so we take just the first half\n    # FFT is also complex, to we take just the real part (abs)\n    vals = 2.0/N * np.abs(yf[0:N//2])\n    return xf, vals\n\ndef log_specgram(audio, sample_rate, window_size=20,\n                 step_size=10, eps=1e-10):\n    nperseg = int(round(window_size * sample_rate / 1e3))\n    noverlap = int(round(step_size * sample_rate / 1e3))\n    freqs, times, spec = signal.spectrogram(audio,\n                                    fs=sample_rate,\n                                    window='hann',\n                                    nperseg=nperseg,\n                                    noverlap=noverlap,\n                                    detrend=False)\n    return freqs, times, np.log(spec.T.astype(np.float32) + eps)\n\n#######\ndef list_wavs_fname(dirpath, ext='wav'):\n    print(dirpath)\n    fpaths = glob(os.path.join(dirpath, r'*/*' + ext))\n    pat = r'.+/(\\w+)/\\w+\\.' + ext + '$'\n    labels = []\n    for fpath in fpaths:\n        r = re.match(pat, fpath)\n        if r:\n            labels.append(r.group(1))\n    pat = r'.+/(\\w+\\.' + ext + ')$'\n    fnames = []\n    for fpath in fpaths:\n        r = re.match(pat, fpath)\n        if r:\n            fnames.append(r.group(1))\n    return labels, fnames\n\n#########\n    \ndef pad_audio(samples):\n    if len(samples) >= L: return samples\n    else: return np.pad(samples, pad_width=(L - len(samples), 0), mode='constant', constant_values=(0, 0))\n\ndef chop_audio(samples, L=16000, num=20):\n    for i in range(num):\n        beg = np.random.randint(0, len(samples) - L)\n        yield samples[beg: beg + L]\n\ndef label_transform(labels):\n    nlabels = []\n    for label in labels:\n        if label == '_background_noise_':\n            nlabels.append('silence')\n        elif label not in legal_labels:\n            nlabels.append('unknown')\n        else:\n            nlabels.append(label)\n    return pd.get_dummies(pd.Series(nlabels))\n\n#########\n    \n\nlabels, fnames = list_wavs_fname(train_data_path)\n\nnew_sample_rate = 8000\ny_train = []\nx_train = []\n\nfor label, fname in zip(labels, fnames):\n    sample_rate, samples = wavfile.read(os.path.join(train_data_path, label, fname))\n    samples = pad_audio(samples)\n    if len(samples) > 16000:\n        n_samples = chop_audio(samples)\n    else: n_samples = [samples]\n    for samples in n_samples:\n        resampled = signal.resample(samples, int(new_sample_rate / sample_rate * samples.shape[0]))\n        _, _, specgram = log_specgram(resampled, sample_rate=new_sample_rate)\n        y_train.append(label)\n        x_train.append(specgram)\nx_train = np.array(x_train)\nx_train = x_train.reshape(tuple(list(x_train.shape) + [1]))\ny_train = label_transform(y_train)\nlabel_index = y_train.columns.values\ny_train = y_train.values\ny_train = np.array(y_train)\ndel labels, fnames\ngc.collect()\n\n\n\n###############\n\ninput_shape = (99, 81, 1)\nnclass = 12\ninp = Input(shape=input_shape)\nnorm_inp = BatchNormalization()(inp)\nimg_1 = Convolution2D(8, kernel_size=2, activation=activations.relu)(norm_inp)\nimg_1 = Convolution2D(8, kernel_size=2, activation=activations.relu)(img_1)\nimg_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\nimg_1 = Dropout(rate=0.2)(img_1)\nimg_1 = Convolution2D(16, kernel_size=3, activation=activations.relu)(img_1)\nimg_1 = Convolution2D(16, kernel_size=3, activation=activations.relu)(img_1)\nimg_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\nimg_1 = Dropout(rate=0.2)(img_1)\nimg_1 = Convolution2D(32, kernel_size=3, activation=activations.relu)(img_1)\nimg_1 = MaxPooling2D(pool_size=(2, 2))(img_1)\nimg_1 = Dropout(rate=0.2)(img_1)\nimg_1 = Flatten()(img_1)\n\ndense_1 = BatchNormalization()(Dense(128, activation=activations.relu)(img_1))\ndense_1 = BatchNormalization()(Dense(128, activation=activations.relu)(dense_1))\ndense_1 = Dense(nclass, activation=activations.softmax)(dense_1)\n\nmodel = models.Model(inputs=inp, outputs=dense_1)\nopt = optimizers.Adam()\n\nmodel.compile(optimizer=opt, loss=losses.binary_crossentropy)\nmodel.summary()\n\nx_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1, random_state=2017)\nmodel.fit(x_train, y_train, batch_size=16, validation_data=(x_valid, y_valid), epochs=3, shuffle=True, verbose=2)\n\nmodel.save(os.path.join(model_path, 'cnn.model'))","execution_count":null},{"outputs":[],"metadata":{"_uuid":"d323ca45ebf84b503ce0a2b19681ed979af07f50","collapsed":true,"_cell_guid":"fd5487ae-4fb0-4fe0-b485-03077368e250"},"cell_type":"code","source":"\ndef test_data_generator(batch=16):\n    imgs = []\n    fnames = []\n    fpaths = glob(os.path.join(test_data_path, '*wav'))\n    i = 0\n    for path in fpaths:\n        if i == 0:\n            imgs = []\n            fnames = []\n        i += 1\n        rate, samples = wavfile.read(path)\n        samples = pad_audio(samples)\n        resampled = signal.resample(samples, int(new_sample_rate / rate * samples.shape[0]))\n        _, _, specgram = log_specgram(resampled, sample_rate=new_sample_rate)\n        imgs.append(specgram)\n        fnames.append(path.split('\\\\')[-1])\n        if i == batch:\n            i = 0\n            imgs = np.array(imgs)\n            imgs = imgs.reshape(tuple(list(imgs.shape) + [1]))\n            yield fnames, imgs\n    if i < batch:\n        imgs = np.array(imgs)\n        imgs = imgs.reshape(tuple(list(imgs.shape) + [1]))\n        yield fnames, imgs\n    raise StopIteration()\n    \n\n\ndel x_train, y_train\ngc.collect()\n\nindex = []\nresults = []\nfor fnames, imgs in test_data_generator(batch=32):\n    predicts = model.predict(imgs)\n    predicts = np.argmax(predicts, axis=1)\n    predicts = [label_index[p] for p in predicts]\n    index.extend(fnames)\n    results.extend(predicts)\n\ndf = pd.DataFrame(columns=['fname', 'label'])\ndf['fname'] = index\ndf['label'] = results\ndf.to_csv(os.path.join(out_path, 'sub.csv'), index=False)","execution_count":null},{"outputs":[],"metadata":{"_uuid":"fa1d07fb9f2924f4ba0b00832f9d4703641bc3a6","collapsed":true,"_cell_guid":"ba806a64-be68-480a-a153-2b8262873bb4"},"cell_type":"code","source":"","execution_count":null}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"nbconvert_exporter":"python","version":"3.6.4","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","name":"python","file_extension":".py","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}