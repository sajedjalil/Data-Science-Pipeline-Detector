{"cells":[{"metadata":{},"cell_type":"markdown","source":"GAN architecture from https://github.com/eriklindernoren/Keras-GAN/blob/master/bigan/bigan.py"},{"metadata":{"trusted":true},"cell_type":"code","source":" ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom __future__ import print_function, division\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport os\nfrom tqdm import tqdm, tqdm_notebook\nfrom keras.preprocessing.image import load_img\nfrom keras.applications.densenet import preprocess_input\nfrom keras.preprocessing.image import img_to_array\nfrom keras.preprocessing.image import array_to_img\nfrom keras.preprocessing import image\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n\n\n\nimg_size = 64\nbatch_size = 128\n\n\n\ndef resize_to_square(im):\n    # new_size should be in (width, height) format\n    im = cv2.resize(im, (img_size, img_size))\n    return im\n\ndef load_image2(file):\n    image = cv2.imread(file)\n    new_image = resize_to_square(image)\n    #ew_image = preprocess_input(new_image)\n    return new_image\n\ndef load_image(file):\n    new_image = load_img(file, target_size=(img_size, img_size))\n    new_image = (img_to_array(new_image))\n    #new_image = resize_to_square(img_to_array(new_image))\n    #ew_image = preprocess_input(new_image)\n    return new_image\n    \nif not os.path.exists('../output_images'):\n    os.mkdir('../output_images')\n    \n\n\nfrom keras.datasets import mnist\nfrom keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GaussianNoise\nfrom keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\nfrom keras.layers import MaxPooling2D, concatenate\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.layers.convolutional import UpSampling2D, Conv2D\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import Adam\nfrom keras import losses\nfrom keras.utils import to_categorical\nimport keras.backend as K\n\nimport matplotlib.pyplot as plt\n\nimport numpy as np\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_file=os.listdir(\"../input/all-dogs/all-dogs/\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator()\n\ntrain_generator = train_datagen.flow_from_directory(\n        '../input/all-dogs/',\n        target_size=(64, 64),\n        batch_size=batch_size)\n\ntrain_datagen_augment = ImageDataGenerator( featurewise_center=True,\n        featurewise_std_normalization=True,\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        horizontal_flip=True,\n        shear_range=0.2)\n\n\ntrain_generator_augment = train_datagen_augment.flow_from_directory(\n        '../input/all-dogs/',\n        target_size=(64, 64),\n        batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(image.array_to_img(train_generator[1][0][0]))\nplt.show()\n\nplt.imshow(image.array_to_img(train_generator_augment[1][0][0]))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the dataset\n#all_file=os.listdir(\"../input/all-dogs/all-dogs/\")\n\n#x_train_data = np.zeros((len(all_file),img_size,img_size,3))\n#for i in range(len(all_file)-1):\n#    file=all_file[i]\n#    path=\"../input/all-dogs/all-dogs/\"+file\n#    x_train_data[i] = load_image2(path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclass BIGAN():\n    def __init__(self):\n        self.img_rows = 64\n        self.img_cols = 64\n        self.channels = 3\n        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n        self.img_shape2 = (64, 64, self.channels)\n        self.latent_dim = 100\n\n        optimizer = Adam(0.001, 0.5)\n\n        # Build and compile the discriminator\n        self.discriminator = self.build_discriminator()\n        self.discriminator.compile(loss=['binary_crossentropy'],\n            optimizer=optimizer,\n            metrics=['accuracy'])\n\n        # Build the generator\n        self.generator = self.build_generator()\n\n        # Build the encoder\n        self.encoder = self.build_encoder()\n\n        # The part of the bigan that trains the discriminator and encoder\n        self.discriminator.trainable = False\n\n        # Generate image from sampled noise\n        z = Input(shape=(self.latent_dim, ))\n        img_ = self.generator(z)\n\n        # Encode image\n        img = Input(shape=self.img_shape)\n        z_ = self.encoder(img)\n\n        # Latent -> img is fake, and img -> latent is valid\n        fake = self.discriminator([z, img_])\n        valid = self.discriminator([z_, img])\n\n        # Set up and compile the combined model\n        # Trains generator to fool the discriminator\n        self.bigan_generator = Model([z, img], [fake, valid])\n        self.bigan_generator.compile(loss=['binary_crossentropy', 'binary_crossentropy'],\n            optimizer=optimizer)\n\n\n    def build_encoder(self):\n        model = Sequential()\n\n        model.add(Flatten(input_shape=self.img_shape))\n        model.add(Dense(512))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(512))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(self.latent_dim))\n\n        model.summary()\n\n        img = Input(shape=self.img_shape)\n        z = model(img)\n\n        return Model(img, z)\n\n    def build_generator(self):\n        model = Sequential()\n\n        model.add(Dense(512, input_dim=self.latent_dim))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(512))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n        model.add(Reshape(self.img_shape))\n\n        model.summary()\n\n        z = Input(shape=(self.latent_dim,))\n        gen_img = model(z)\n\n        return Model(z, gen_img)\n\n    def build_discriminator(self):\n\n        z = Input(shape=(self.latent_dim, ))\n        img = Input(shape=self.img_shape)\n        d_in = concatenate([z, Flatten()(img)])\n\n        model = Dense(1024)(d_in)\n        model = LeakyReLU(alpha=0.2)(model)\n        model = Dropout(0.5)(model)\n        model = Dense(1024)(model)\n        model = LeakyReLU(alpha=0.2)(model)\n        model = Dropout(0.5)(model)\n        model = Dense(1024)(model)\n        model = LeakyReLU(alpha=0.2)(model)\n        model = Dropout(0.5)(model)\n        validity = Dense(1, activation=\"sigmoid\")(model)\n\n        return Model([z, img], validity)\n\n    def train(self, epochs, batch_size=128, sample_interval=50):\n\n\n\n        \n        for epoch in range(epochs):\n            for ii in tqdm(range(len(train_generator)), total=len(train_generator)):\n                \n                # Adversarial ground truths\n                valid = np.ones((len(train_generator[ii][0]), 1))\n                fake = np.zeros((len(train_generator[ii][0]), 1))\n        \n                z = np.random.normal(size=(len(train_generator[ii][0]), self.latent_dim))\n                imgs_ = self.generator.predict(z)\n                imgs = train_generator[ii][0]\n                imgs = (imgs - 127.5) / 127.5\n                \n                z_ = self.encoder.predict(imgs)\n\n                # Train the discriminator (img -> z is valid, z -> img is fake)\n                d_loss_real = self.discriminator.train_on_batch([z_, imgs], valid)\n                d_loss_fake = self.discriminator.train_on_batch([z, imgs_], fake)\n                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n                # ---------------------\n                #  Train Generator\n                # ---------------------\n\n                # Train the generator (z -> img is valid and img -> z is is invalid)\n                g_loss = self.bigan_generator.train_on_batch([z, imgs], [valid, fake])\n\n                # Plot the progress\n                if (ii+1) % (len(train_generator)//2) == 0:\n                    print (\"%d [D loss: %f, acc: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss[0]))\n        \n                if (ii+1) % (len(train_generator)//2) == 0:\n                    self.sample_interval(epoch)\n                   \n        for i in range(int(500)):\n    \n            z = np.random.normal(size=(20, self.latent_dim))\n            gen_imgs = self.generator.predict(z)\n            gen_imgs = 0.5 * gen_imgs + 0.5\n    \n            for j in range(20):\n                img = image.array_to_img((gen_imgs[j, :,:,:]))\n                img.save(os.path.join('../output_images/','generated_dog' + str(i) + '_'+ str(j) +'.png')) \n        plt.imshow(image.array_to_img(gen_imgs[3]))\n        plt.show()\n        plt.imshow(image.array_to_img(gen_imgs[15]))\n        plt.show()\n        plt.imshow(image.array_to_img(gen_imgs[5]))\n        plt.show()\n\n    def sample_interval(self, epoch):\n        r, c = 5, 5\n        z = np.random.normal(size=(25, self.latent_dim))\n        gen_imgs = self.generator.predict(z)\n\n        gen_imgs = 0.5 * gen_imgs + 0.5\n\n        fig, axs = plt.subplots(r, c)\n        cnt = 0\n        for i in range(r):\n            for j in range(c):\n                axs[i,j].imshow(gen_imgs[cnt, :,:,])\n                axs[i,j].axis('off')\n                cnt += 1\n        #fig.savefig(\"../output_images/dog_%d.png\" % epoch)\n        plt.show()\n        plt.close()\n    \n           \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imgs = train_generator[30][0]\nimgs_augment =train_generator_augment[30][0]\nprint(imgs.shape)\nprint(imgs_augment.shape)\nimgs=np.concatenate((imgs,imgs_augment), axis=0)\nprint(imgs.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if __name__ == '__main__':\n    bigan = BIGAN()\n    bigan.train(epochs=50, batch_size=batch_size, sample_interval=500)\n\n    \nimport shutil\nshutil.make_archive('images', 'zip', '../output_images')\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}