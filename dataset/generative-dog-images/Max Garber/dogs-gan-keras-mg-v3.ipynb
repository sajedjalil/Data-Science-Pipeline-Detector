{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport xml.etree.ElementTree as ET \nimport matplotlib.pyplot as plt, zipfile \nfrom PIL import Image \n\nfrom tqdm import tqdm\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Model\nfrom keras.initializers import RandomNormal, Constant\nfrom keras import initializers\nfrom keras.layers import Input, Dense, Dropout, Flatten, Reshape , LeakyReLU , Lambda, PReLU, Concatenate\nfrom keras.layers import Conv2D, MaxPooling2D,AveragePooling2D, UpSampling2D, Conv2DTranspose,BatchNormalization\nfrom keras import regularizers\nfrom keras.optimizers import SGD, Adam\n\nfrom keras import backend as K\nfrom keras.engine import *\nfrom keras.utils import conv_utils\n\nfrom IPython.display import FileLink, FileLinks\n\nimport time\nstart_time = time.time()\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"PATH = '../input/all-dogs/all-dogs/'\nimageNames = os.listdir(PATH)\n#print(images)\nimg = plt.imread(PATH + imageNames[np.random.randint(0,len(imageNames))])\nplt.imshow(img)\nprint(img.size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH_ANNO = '../input/annotation/Annotation/'\nbreeds = os.listdir(PATH_ANNO)\nimagesInput = np.zeros((len(imageNames)*2,64,64,3))\nimages_breed = []\ni = 0\nprint(imagesInput.shape)\nfor breed in breeds:\n    for dog in os.listdir(PATH_ANNO+breed):\n        tree = ET.parse(PATH_ANNO + breed + '/' + dog)\n        root = tree.getroot()\n        try: img = Image.open(PATH + root.find('filename').text +'.jpg')\n        except: continue\n        for obj in root.findall('object'):\n            bndbox = obj.find('bndbox')\n            xmin = int(bndbox.find('xmin').text)\n            ymin = int(bndbox.find('ymin').text)\n            xmax = int(bndbox.find('xmax').text)\n            ymax = int(bndbox.find('ymax').text)\n            img_crop = img.crop((xmin, ymin, xmax, ymax))\n            w = img_crop.size[0]; h = img_crop.size[1];\n            a=0; b=0\n            if w<h:\n                w2 = 64; h2 = int((64/w)*h)\n                #b = np.random.randint(0,(h2-64)) if (h2-64 > 0) else 0\n            else:\n                h2 = 64; w2 = int((64/h)*w)\n                #a = np.random.randint(0,(w2-64)) if (w2-64 > 0) else 0\n            img_crop = img_crop.resize((w2,h2), Image.ANTIALIAS)\n            img_crop = img_crop.crop((0+a, 0+b, 64+a, 64+b))\n            imagesInput[i,:,:,:] = np.asarray(img_crop)\n            images_breed.append(obj.find('name').text)\n            i += 1\nimagesInput = imagesInput[:i,:,:,:]        \nflip_imagesInput = np.flip(imagesInput,2)\nimagesInput = np.vstack((imagesInput,flip_imagesInput))\nflip_imagesInput = None\nimages_breed = images_breed + images_breed\nimagesInput = imagesInput / (255 / 2) - 1\nprint(imagesInput.shape,len(images_breed))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rnd = np.random.randint(0,imagesInput.shape[0])\nplt.imshow(imagesInput[rnd]/2 + .5)\nprint(imagesInput[0].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_img_full():    \n    images = np.zeros((len(imageNames),64,64,3))\n    i = 0\n    for i, dog in enumerate(imageNames):\n        img = Image.open(PATH + dog)\n        w = img.size[0]; h = img.size[1];\n        a=0; b=0\n        if w<h:\n            w2 = 64; h2 = int((64/w)*h)\n            b = np.random.randint(0,(h2-64)) if (h2-64 > 0) else 0\n        else:\n            h2 = 64; w2 = int((64/h)*w)\n            a = np.random.randint(0,(w2-64)) if (w2-64 > 0) else 0\n        img = img.resize((w2,h2), Image.ANTIALIAS)\n        img = img.crop((0+a, 0+b, 64+a, 64+b))\n        images[i,:,:,:] = np.asarray(img)\n    images = images / (255 / 2) - 1\n    print(images.shape)\n    return images\nimagesInput = np.vstack((imagesInput,load_img_full()))\nprint(imagesInput.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**[Spectral Normalization](https://github.com/IShengFang/SpectralNormalizationKeras/blob/master/SpectralNormalizationKeras.py)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ConvSN2D(Conv2D):\n\n    def build(self, input_shape):\n        if self.data_format == 'channels_first':\n            channel_axis = 1\n        else:\n            channel_axis = -1\n        if input_shape[channel_axis] is None:\n            raise ValueError('The channel dimension of the inputs '\n                             'should be defined. Found `None`.')\n        input_dim = input_shape[channel_axis]\n        kernel_shape = self.kernel_size + (input_dim, self.filters)\n\n        self.kernel = self.add_weight(shape=kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      name='kernel',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.filters,),\n                                        initializer=self.bias_initializer,\n                                        name='bias',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n            \n        self.u = self.add_weight(shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n                         initializer=initializers.RandomNormal(0, 1),\n                         name='sn',\n                         trainable=False)\n        \n        # Set input spec.\n        self.input_spec = InputSpec(ndim=self.rank + 2,\n                                    axes={channel_axis: input_dim})\n        self.built = True\n    def call(self, inputs, training=None):\n        def _l2normalize(v, eps=1e-12):\n            return v / (K.sum(v ** 2) ** 0.5 + eps)\n        def power_iteration(W, u):\n            #Accroding the paper, we only need to do power iteration one time.\n            _u = u\n            _v = _l2normalize(K.dot(_u, K.transpose(W)))\n            _u = _l2normalize(K.dot(_v, W))\n            return _u, _v\n        #Spectral Normalization\n        W_shape = self.kernel.shape.as_list()\n        #Flatten the Tensor\n        W_reshaped = K.reshape(self.kernel, [-1, W_shape[-1]])\n        _u, _v = power_iteration(W_reshaped, self.u)\n        #Calculate Sigma\n        sigma=K.dot(_v, W_reshaped)\n        sigma=K.dot(sigma, K.transpose(_u))\n        #normalize it\n        W_bar = W_reshaped / sigma\n        #reshape weight tensor\n        if training in {0, False}:\n            W_bar = K.reshape(W_bar, W_shape)\n        else:\n            with tf.control_dependencies([self.u.assign(_u)]):\n                W_bar = K.reshape(W_bar, W_shape)\n                \n        outputs = K.conv2d(\n                inputs,\n                W_bar,\n                strides=self.strides,\n                padding=self.padding,\n                data_format=self.data_format,\n                dilation_rate=self.dilation_rate)\n        if self.use_bias:\n            outputs = K.bias_add(\n                outputs,\n                self.bias,\n                data_format=self.data_format)\n        if self.activation is not None:\n            return self.activation(outputs)\n        return outputs\n\n\nclass ConvSN2DTranspose(Conv2DTranspose):\n\n    def build(self, input_shape):\n        if len(input_shape) != 4:\n            raise ValueError('Inputs should have rank ' +\n                             str(4) +\n                             '; Received input shape:', str(input_shape))\n        if self.data_format == 'channels_first':\n            channel_axis = 1\n        else:\n            channel_axis = -1\n        if input_shape[channel_axis] is None:\n            raise ValueError('The channel dimension of the inputs '\n                             'should be defined. Found `None`.')\n        input_dim = input_shape[channel_axis]\n        kernel_shape = self.kernel_size + (self.filters, input_dim)\n\n        self.kernel = self.add_weight(shape=kernel_shape,\n                                      initializer=self.kernel_initializer,\n                                      name='kernel',\n                                      regularizer=self.kernel_regularizer,\n                                      constraint=self.kernel_constraint)\n        if self.use_bias:\n            self.bias = self.add_weight(shape=(self.filters,),\n                                        initializer=self.bias_initializer,\n                                        name='bias',\n                                        regularizer=self.bias_regularizer,\n                                        constraint=self.bias_constraint)\n        else:\n            self.bias = None\n            \n        self.u = self.add_weight(shape=tuple([1, self.kernel.shape.as_list()[-1]]),\n                         initializer=initializers.RandomNormal(0, 1),\n                         name='sn',\n                         trainable=False)\n        \n        # Set input spec.\n        self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})\n        self.built = True  \n    \n    def call(self, inputs):\n        input_shape = K.shape(inputs)\n        batch_size = input_shape[0]\n        if self.data_format == 'channels_first':\n            h_axis, w_axis = 2, 3\n        else:\n            h_axis, w_axis = 1, 2\n\n        height, width = input_shape[h_axis], input_shape[w_axis]\n        kernel_h, kernel_w = self.kernel_size\n        stride_h, stride_w = self.strides\n        if self.output_padding is None:\n            out_pad_h = out_pad_w = None\n        else:\n            out_pad_h, out_pad_w = self.output_padding\n\n        # Infer the dynamic output shape:\n        out_height = conv_utils.deconv_length(height,\n                                              stride_h, kernel_h,\n                                              self.padding,\n                                              out_pad_h)\n        out_width = conv_utils.deconv_length(width,\n                                             stride_w, kernel_w,\n                                             self.padding,\n                                             out_pad_w)\n        if self.data_format == 'channels_first':\n            output_shape = (batch_size, self.filters, out_height, out_width)\n        else:\n            output_shape = (batch_size, out_height, out_width, self.filters)\n            \n        #Spectral Normalization    \n        def _l2normalize(v, eps=1e-12):\n            return v / (K.sum(v ** 2) ** 0.5 + eps)\n        def power_iteration(W, u):\n            #Accroding the paper, we only need to do power iteration one time.\n            _u = u\n            _v = _l2normalize(K.dot(_u, K.transpose(W)))\n            _u = _l2normalize(K.dot(_v, W))\n            return _u, _v\n        W_shape = self.kernel.shape.as_list()\n        #Flatten the Tensor\n        W_reshaped = K.reshape(self.kernel, [-1, W_shape[-1]])\n        _u, _v = power_iteration(W_reshaped, self.u)\n        #Calculate Sigma\n        sigma=K.dot(_v, W_reshaped)\n        sigma=K.dot(sigma, K.transpose(_u))\n        #normalize it\n        W_bar = W_reshaped / sigma\n        #reshape weight tensor\n        if training in {0, False}:\n            W_bar = K.reshape(W_bar, W_shape)\n        else:\n            with tf.control_dependencies([self.u.assign(_u)]):\n                W_bar = K.reshape(W_bar, W_shape)\n        self.kernel = W_bar\n        \n        outputs = K.conv2d_transpose(\n            inputs,\n            self.kernel,\n            output_shape,\n            self.strides,\n            padding=self.padding,\n            data_format=self.data_format)\n\n        if self.use_bias:\n            outputs = K.bias_add(\n                outputs,\n                self.bias,\n                data_format=self.data_format)\n\n        if self.activation is not None:\n            return self.activation(outputs)\n        return outputs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"[**Self Attention**](https://stackoverflow.com/questions/50819931/self-attention-gan-in-keras)   \n[More](https://sthalles.github.io/advanced_gans/)"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Attention(Layer):\n    def __init__(self, ch, **kwargs):\n        super(Attention, self).__init__(**kwargs)\n        self.channels = ch\n        self.filters_f_g = self.channels // 8\n        self.filters_h = self.channels\n\n    def build(self, input_shape):\n        kernel_shape_f_g = (1, 1) + (self.channels, self.filters_f_g)\n        print(kernel_shape_f_g)\n        kernel_shape_h = (1, 1) + (self.channels, self.filters_h)\n\n        # Create a trainable weight variable for this layer:\n        self.gamma = self.add_weight(name='gamma', shape=[1], initializer='zeros', trainable=True)\n        self.kernel_f = self.add_weight(shape=kernel_shape_f_g,\n                                        initializer='glorot_uniform',\n                                        name='kernel_f')\n        self.kernel_g = self.add_weight(shape=kernel_shape_f_g,\n                                        initializer='glorot_uniform',\n                                        name='kernel_g')\n        self.kernel_h = self.add_weight(shape=kernel_shape_h,\n                                        initializer='glorot_uniform',\n                                        name='kernel_h')\n        self.bias_f = self.add_weight(shape=(self.filters_f_g,),\n                                      initializer='zeros',\n                                      name='bias_F')\n        self.bias_g = self.add_weight(shape=(self.filters_f_g,),\n                                      initializer='zeros',\n                                      name='bias_g')\n        self.bias_h = self.add_weight(shape=(self.filters_h,),\n                                      initializer='zeros',\n                                      name='bias_h')\n        super(Attention, self).build(input_shape)\n        # Set input spec.\n        self.input_spec = InputSpec(ndim=4,\n                                    axes={3: input_shape[-1]})\n        self.built = True\n\n\n    def call(self, x):\n        def hw_flatten(x):\n            return K.reshape(x, shape=[K.shape(x)[0], K.shape(x)[1]*K.shape(x)[2], K.shape(x)[-1]])\n\n        f = K.conv2d(x,\n                     kernel=self.kernel_f,\n                     strides=(1, 1), padding='same')  # [bs, h, w, c']\n        f = K.bias_add(f, self.bias_f)\n        g = K.conv2d(x,\n                     kernel=self.kernel_g,\n                     strides=(1, 1), padding='same')  # [bs, h, w, c']\n        g = K.bias_add(g, self.bias_g)\n        h = K.conv2d(x,\n                     kernel=self.kernel_h,\n                     strides=(1, 1), padding='same')  # [bs, h, w, c]\n        h = K.bias_add(h, self.bias_h)\n\n        s = tf.matmul(hw_flatten(g), hw_flatten(f), transpose_b=True)  # # [bs, N, N]  // Why matmul vs K.batch_dot\n\n        beta = K.softmax(s, axis=-1)  # attention map\n\n        o = K.batch_dot(beta, hw_flatten(h))  # [bs, N, C]\n\n        o = K.reshape(o, shape=K.shape(x))  # [bs, h, w, C]\n        x = self.gamma * o + x\n\n        return x\n\n    def compute_output_shape(self, input_shape):\n        return input_shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def PixelwiseNorm(x):\n    alpha=1e-8\n    y = x ** 2\n    y = K.mean(y, axis=-1, keepdims=True)\n    y = y + alpha\n    y = K.sqrt(y)\n    y = x / y  # normalize the input x volume\n    return y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Generator**"},{"metadata":{"trusted":true},"cell_type":"code","source":"drop = 0.1\ninit = RandomNormal(mean=0.0, stddev=0.02) #'glorot_uniform'#\ngen_input = Input(shape=(100,))\n\nx = Dense(1024, activation='relu',)(gen_input)\nx = BatchNormalization(momentum=0.8)(x)\nx = Reshape((4,4,64))(x)\n\nx3 = ConvSN2DTranspose(256, (3, 3),strides=(1, 1),padding='same',kernel_initializer=init)(x)\nx5 = ConvSN2DTranspose(128, (5, 5),strides=(1, 1),padding='same',kernel_initializer=init)(x)\nx = Concatenate(axis=-1)([x3,x5])\nx = Lambda(PixelwiseNorm)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x, training=True)\n\n\nx3 = ConvSN2DTranspose(128, (3, 3),strides=(2, 2),padding='same',kernel_initializer=init)(x)\nx5 = ConvSN2DTranspose(64, (5, 5),strides=(2, 2),padding='same',kernel_initializer=init)(x)\nx = Concatenate(axis=-1)([x3,x5])\nx = Lambda(PixelwiseNorm)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x, training=True)\n\nx3 = ConvSN2DTranspose(64, (3, 3),strides=(2, 2),padding='same',kernel_initializer=init)(x)\nx5 = ConvSN2DTranspose(32, (5, 5),strides=(2, 2),padding='same',kernel_initializer=init)(x)\nx = Concatenate(axis=-1)([x3,x5])\nx = Lambda(PixelwiseNorm)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x, training=True)\n\nx3 = ConvSN2DTranspose(32, (3, 3), strides=(2, 2), padding='same',kernel_initializer=init)(x)\nx5 = ConvSN2DTranspose(16, (5, 5),strides=(2, 2),padding='same',kernel_initializer=init)(x)\nx = Concatenate(axis=-1)([x3,x5])\nx = Lambda(PixelwiseNorm)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x, training=True)\n\nx = Attention(32+16)(x)\n\nx3 = ConvSN2DTranspose(32, (3, 3), strides=(2, 2), padding='same',kernel_initializer=init)(x)\nx5 = ConvSN2DTranspose(16, (5, 5),strides=(2, 2),padding='same',kernel_initializer=init)(x)\nx = Concatenate(axis=-1)([x3,x5])\nx = Lambda(PixelwiseNorm)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x, training=True)\n\n\n#x = AveragePooling2D(pool_size=(2, 2),strides=(1, 1),padding='same')(x)\n\nx = ConvSN2D(3, (5, 5), activation='tanh', padding='same',kernel_initializer=init)(x)\n\ngenerator = Model(gen_input, x)\ngenerator.compile(optimizer=Adam(lr=0.0002, beta_1=0.5), loss='binary_crossentropy')\ngenerator.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inpt = np.random.random(100*2).reshape(2,100)\nimg = generator.predict(inpt)\nprint(img.shape)\nplt.imshow(img[0]/2+.5)\nplt.imshow(img[1]/2+.5)\n#print(img[1]/2+.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Discriminator**"},{"metadata":{"trusted":true},"cell_type":"code","source":"init = RandomNormal(mean=0.0, stddev=0.02)\ndrop = 0.0\ndis_input = Input(shape=(64,64,3,))\nx = ConvSN2D(32, (5, 5), padding='same',kernel_initializer=init)(dis_input)\nx = BatchNormalization(momentum=0.8)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x)\n\n#x = MaxPooling2D(pool_size=(2, 2),strides=(2, 2))(x)\nx = ConvSN2D(64, (5, 5), padding='same',strides=(2, 2),kernel_initializer=init)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = BatchNormalization(momentum=0.8)(x)\nx = Dropout(drop)(x)\n\n#x = MaxPooling2D(pool_size=(2, 2),strides=(2, 2))(x)\nx = ConvSN2D(64, (3, 3), padding='same',strides=(2, 2),kernel_initializer=init)(x)\nx = BatchNormalization(momentum=0.8)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x)\n\n#x = MaxPooling2D(pool_size=(2, 2),strides=(2, 2))(x)\nx = ConvSN2D(128, (3, 3), padding='same',strides=(2, 2),kernel_initializer=init)(x)\nx = BatchNormalization(momentum=0.8)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x)\n\n#x = MaxPooling2D(pool_size=(2, 2),strides=(2, 2))(x)\nx = ConvSN2D(256, (3, 3), padding='same',strides=(2, 2),kernel_initializer=init)(x)\nx = BatchNormalization(momentum=0.8)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x)\n\n#x = Conv2D(64, (3, 3), padding='valid',strides=(1, 1),kernel_initializer=init)(x)\n#x = LeakyReLU()(x)\n#x = BatchNormalization()(x)\n#x = Dropout(drop)(x)\n\nx = ConvSN2D(512, (3, 3), padding='same',strides=(1, 1),kernel_initializer=init)(x)\nx = BatchNormalization(momentum=0.8)(x)\nx = PReLU(alpha_initializer=Constant(value=0.3))(x)\nx = Dropout(drop)(x)\n\n#x = AveragePooling2D(pool_size=(2, 2),strides=(1, 1),padding='same')(x)\n\nx = Flatten()(x)\nx = Dense(1 , activation = \"sigmoid\")(x)\ndiscriminator = Model(dis_input, x)\ndiscriminator.compile(optimizer=Adam(lr=0.0002, beta_1=0.5), loss='binary_crossentropy')\ndiscriminator.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gan_input = Input(shape=(100,))\ndiscriminator.trainable=False\nx = generator(gan_input)\nx = discriminator(x)\ngan = Model(gan_input, x)\ngan.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\ngan.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gen_noise(batch_size=128):\n    noise = np.random.randn(batch_size,100)\n    #noise = np.random.normal(size = 100 * batch_size).reshape(batch_size,100)\n    # noise =  np.random.random(100 * batch_size).reshape(batch_size,100)\n    return noise ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"--- %s seconds ---\" % (time.time() - start_time))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Training**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def training(epochs=3, batch_size=128):\n    imagesProgress = np.zeros((epochs,64,64,3))\n    progress_noise = gen_noise(1)\n        \n    min_learning_rate = 0.00005\n    max_learning_rate = K.eval(gan.optimizer.lr)\n    cycle_length = batch_size * 1200\n    mult_factor=2\n    batch_since_restart = 0\n    global learning_rate_log\n    learning_rate_log = []\n    \n    for e in range(1,epochs+1):\n        #print(imagesInput.shape[0]//batch_size)\n        #print('Epoch:', e)\n        np.random.shuffle(imagesInput)\n        for b in tqdm(range(imagesInput.shape[0]//batch_size)):\n            noise = gen_noise(batch_size)\n            gen_imgs = generator.predict(noise)\n            real_imgs = imagesInput[b*batch_size:(b+1)*batch_size]\n            #X = np.concatenate([real_imgs, gen_imgs])\n            #y_dis = np.zeros(2*batch_size) \n            #y_dis[:batch_size] = .8 +  np.random.normal(loc=0, scale=.050)\n            \n            y_dis = np.ones(batch_size) - np.abs(np.random.normal(loc=.2, scale=.1))\n            #y_dis = 1 - y_dis if np.random.random() <= .05 else y_dis\n            discriminator.trainable=True\n            discriminator.train_on_batch(real_imgs,y_dis)\n            \n            y_dis.fill(0.0)\n            y_dis += np.abs(np.random.normal(loc=.2, scale=.1))\n            #y_dis = 1 - y_dis if np.random.random() <= .05 else y_dis\n            discriminator.trainable=True\n            discriminator.train_on_batch(gen_imgs,y_dis)\n                        \n            noise = gen_noise(batch_size//2)\n            #noise[:,np.random.randint(100)] += 1\n            y_gen = np.ones(batch_size//2) - .1\n            \n            discriminator.trainable=False\n            gan.train_on_batch(noise, y_gen)\n            #inpt = np.random.random(100).reshape(1,100)\n                        \n            learning_rate = min_learning_rate + 0.5 * (max_learning_rate - min_learning_rate) * (1 + np.cos(np.pi * batch_since_restart/cycle_length))\n            if learning_rate < min_learning_rate:\n                learning_rate = min_learning_rate\n            if batch_since_restart >= cycle_length:\n                batch_since_restart = 0\n                learning_rate = max_learning_rate\n                cycle_length = cycle_length * mult_factor\n            batch_since_restart += 1\n            K.set_value(gan.optimizer.lr, learning_rate)\n            learning_rate_log.append(learning_rate)\n          \n        inpt = gen_noise(1)\n        i = np.random.randint(0,real_imgs.shape[0])\n        print('Epoch: ', e,\n        ' || Gen: ' , discriminator.predict(generator.predict(inpt))[0,0],\n        ' || Dog: ' , discriminator.predict(real_imgs[i:i+1])[0,0])\n        #print(np.average(y_dis))\n        imagesProgress[e-1,:,:,:] = generator.predict(progress_noise)[0]\n        os.system(f'echo \\\"{e}\\\"')\n        if (time.time() - start_time) > 31800:\n            imagesProgress = imagesProgress[:e-1,:,:,:]\n            break\n    return imagesProgress\ntry: imagesProgress\nexcept NameError: imagesProgress = np.zeros((0,64,64,3))\nimagesProgress = np.vstack((imagesProgress,training(epochs=600,batch_size=128)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(learning_rate_log)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Epochs: ' , imagesProgress.shape[0])\ncolumns = 6 ; rows = min(6,(imagesProgress.shape[0] // columns) + 1);\nfig=plt.figure(figsize=(32, 5 * rows))\nj=0\nfor i in range(0 , min(36,imagesProgress.shape[0])):\n    fig.add_subplot(rows,columns,i+1)\n    plt.imshow(imagesProgress[int(j)]/2+.5)\n    j += max(1,imagesProgress.shape[0] / 36)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = 6 ; rows = 4;\ninpt = gen_noise(columns * rows)\n#inpt[:,np.random.randint(100)] += 1\nimg = generator.predict(inpt)\n#print(discriminator.predict(imagesInput[:10]))\n#print(discriminator.predict(img))\n#print(img[0,0,:10])\nfig=plt.figure(figsize=(32, 5 * rows))\nfor i in range(0 , columns * rows):\n    fig.add_subplot(rows,columns,i+1)\n    plt.imshow(img[i]/2+.5)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"z = zipfile.PyZipFile('images.zip', mode='w')\ninpt = gen_noise(10000)\nimgs = generator.predict(inpt) \nimgs = imgs + 1\nimgs = imgs / 2\nprint(imgs.shape)\nfor k in range(10000):\n    f = str(k)+'.png'\n    img = imgs[k,:,:,:]#.numpy()\n    tf.keras.preprocessing.image.save_img(\n        f,\n        img,\n        scale=True\n    )\n    z.write(f); os.remove(f)\nz.close()\nFileLinks('.')\n#!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#inpt = gen_noise(10000)\n#img = generator.predict(inpt) \n#img = img + 1\n#img = img * (255 / 2)\n#np.array(img).min(), np.array(img).max()\n#if not os.path.exists('../tmp'):\n#    os.mkdir('../tmp')\n#for i in range(0,img.shape[0]):\n#    plt.imsave('../tmp/dog_'+ str (i)+'.png' , img[i].astype(np.uint8))\n#import shutil\n#shutil.make_archive('images', 'zip', '../tmp')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(img[9].astype(np.uint8))\n#im = Image.fromarray(img[0].astype(np.uint8))\n#plt.imshow(im)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"--- %s seconds ---\" % (time.time() - start_time))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}