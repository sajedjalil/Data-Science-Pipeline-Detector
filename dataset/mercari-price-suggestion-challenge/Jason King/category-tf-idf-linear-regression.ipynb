{"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"nbconvert_exporter":"python","pygments_lexer":"ipython3","mimetype":"text/x-python","file_extension":".py","version":"3.6.3","name":"python","codemirror_mode":{"version":3,"name":"ipython"}}},"nbformat_minor":1,"nbformat":4,"cells":[{"metadata":{"_cell_guid":"d8f10ebd-b92a-4540-bf72-bfbbecd374aa","_uuid":"1d9bbe803d5addd64fb8f6817598d3ec7421cd46"},"source":"11/29/2017: TF-IDF on name + item_description fed into a Linear Regression. Log transformed price to improve performance.\n\nI'm a huge proponent of the fact that simple regressors (linear or logistic) run the world. I wanted to put together a linear model that uses the category_name field to demonstrate that a linear regression is a nice baseline.","cell_type":"markdown"},{"metadata":{"collapsed":true,"_cell_guid":"90809387-d62c-4d62-819c-2c8226ac7a9b","_uuid":"338519d51f8e60ed92184e0bec21a1241ff201f3"},"outputs":[],"source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn.pipeline import Pipeline\n\nimport pandas as pd\nimport numpy as np\nimport time\nimport re\n\nseed = 101","cell_type":"code","execution_count":1},{"metadata":{"collapsed":true,"_cell_guid":"d379a07e-5cda-4355-9a28-2c9ba69da885","_uuid":"ee3c6cb68229ff8c447fab87bcf6440446cc5f8b"},"outputs":[],"source":"def tokenizer(text):\n    if text:\n        result = re.findall('[a-z]{2,}', text.lower())\n    else:\n        result = []\n    return result","cell_type":"code","execution_count":2},{"metadata":{"_cell_guid":"0d6c758c-c481-49fd-92c3-14f8b851adff","_uuid":"2d1ea007bc610fc619cb14b684625fbebbc81cc4"},"outputs":[],"source":"df = pd.read_csv('../input/train.tsv', sep='\\t')\ndf.head()","cell_type":"code","execution_count":3},{"metadata":{"_cell_guid":"c5e14c88-ea91-4f38-8589-a6432def3a4b","_uuid":"3d32cc3d53f075eff74810c30f76a21b72c51590"},"source":"Now let's train a simple tfidf vectorizer on the combination of the item name and description.","cell_type":"markdown"},{"metadata":{"collapsed":true,"_cell_guid":"1bed2c0a-d8f6-45de-a64e-be91755d113e","_uuid":"dd22fcd87d58bec7ae796850925f29b53222c554"},"outputs":[],"source":"df['item_description'].fillna(value='Missing', inplace=True)\nX = (df['name'] + ' ' + df['item_description']).values\ny = np.log1p(df['price'].values)\n\nX_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.3, random_state=seed)","cell_type":"code","execution_count":4},{"metadata":{"_cell_guid":"8b617cab-259c-47a9-a0a8-db949cea3e26","_uuid":"2115d7cde7a048c771a78755ad2e684da4d315cb"},"outputs":[],"source":"vect = TfidfVectorizer(tokenizer=tokenizer, stop_words='english')\nstart = time.time()\nX_train_vect = vect.fit_transform(X_train)\nend = time.time()\nprint('Time to train vectorizer and transform training text: %0.2fs' % (end - start))","cell_type":"code","execution_count":5},{"metadata":{"_cell_guid":"27539ead-5d35-4b5e-a02c-63d310c9513d","_uuid":"174cf9a77a2596a827d2e63a63725738ce00a279"},"source":"Now let's train a linear regression model.","cell_type":"markdown"},{"metadata":{"_cell_guid":"f3f289c3-84c1-4382-9012-949ca5dc3def","_uuid":"62a2a24a93d57576c8aa982823a68b8756ee49cb","scrolled":true},"outputs":[],"source":"# I was using a LinearRegression previously, but with the wider vocab it's too slow. \n# Let's use the SGDRegressor with ordinary least squares.\n# Also, using mean squared error as the eval metric, since negative values crash mean squared log error.\n\nmodel = SGDRegressor(loss='squared_loss', penalty='l2', random_state=seed, max_iter=5)\nparams = {'penalty':['none','l2','l1'],\n          'alpha':[1e-4, 2e-4, 5e-4, 1e-3, 2e-3, 5e-3, 1e-2, 2e-2, 5e-2, 0.1]}\ngs = GridSearchCV(estimator=model,\n                  param_grid=params,\n                  scoring='neg_mean_squared_error',\n                  n_jobs=1,\n                  cv=5,\n                  verbose=3)\nstart = time.time()\ngs.fit(X_train_vect, y_train)\nend = time.time()\nprint('Time to train model: %0.2fs' % (end -start))","cell_type":"code","execution_count":6},{"metadata":{"_cell_guid":"5e92c474-d9ad-4528-afb4-83106dcdfb97","_uuid":"c22a251a5233490932edd78577046804ac0c9f59"},"outputs":[],"source":"model = gs.best_estimator_\nprint(gs.best_params_)\nprint(gs.best_score_)","cell_type":"code","execution_count":7},{"metadata":{"_cell_guid":"3ea9beab-4b06-4b22-9ed4-99a103a4308e","_uuid":"344f0b9270ca14f2c0d97b595ae7a0ea3657dd53"},"source":"Now let's package everything up nicely in a pipeline and run it over the test set to check the performance.","cell_type":"markdown"},{"metadata":{"_cell_guid":"5bd26628-3881-46f5-9280-d7493f45a58f","_uuid":"0ce0f5b5ddae0294655c05798a7e8665970de23f"},"outputs":[],"source":"pipe = Pipeline([('vect',vect),('model',model)])\nstart = time.time()\ny_pred = pipe.predict(X_test)\nend = time.time()\nprint('Time to generate predictions on test set: %0.2fs' % (end - start))","cell_type":"code","execution_count":8},{"metadata":{"_cell_guid":"506e5658-1da4-42f4-a6a9-8e41ec1472ab","_uuid":"7e1ba629a30976584d6204b1c4ff0a6bb8998803"},"outputs":[],"source":"# Replace negative values with zero for the time being.\nprint(np.sqrt(mean_squared_log_error(np.exp(y_test)-1, np.exp(y_pred)-1)))","cell_type":"code","execution_count":12},{"metadata":{"_cell_guid":"14a1fa1f-0ede-495a-94f4-44b4c6730230","_uuid":"969db0e4af320178ce69f491b4eea7ec01e6ef5b"},"source":"Okay, now let's read in the test data and generate our submission file.","cell_type":"markdown"},{"metadata":{"_cell_guid":"3ac5e29b-192d-4e29-abac-f4eff0a18861","_uuid":"810bfc2601cef34d512ca0adf77ea93a9db18418"},"outputs":[],"source":"df_test = pd.read_csv('../input/test.tsv', sep='\\t')\ndf_test.head()","cell_type":"code","execution_count":13},{"metadata":{"_cell_guid":"7bfeba4b-a8dd-4fa9-85db-12b0c7d1626e","_uuid":"4b1f965ff8f86293e36380446d455824c44d051d"},"outputs":[],"source":"df_test['item_description'].fillna('Missing', inplace=True)\ndf_test['price'] = np.exp(pipe.predict((df_test['name'] + ' ' + df_test['item_description']).values))-1\ndf_test.head()","cell_type":"code","execution_count":14},{"metadata":{"collapsed":true,"_cell_guid":"75c3c83a-ad1e-4bea-98a9-0c377af0b1c7","_uuid":"f37d62ba2d7ec386847c9f29e3ad3eaa844112a3"},"outputs":[],"source":"df_test[['test_id','price']].to_csv('output.csv', index=False)","cell_type":"code","execution_count":null},{"metadata":{"collapsed":true},"outputs":[],"source":"","cell_type":"code","execution_count":null}]}