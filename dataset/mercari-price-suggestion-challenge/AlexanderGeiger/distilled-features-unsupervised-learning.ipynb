{"nbformat_minor":1,"cells":[{"cell_type":"markdown","metadata":{"_uuid":"39dcd6c0f6382ae4d276a98f19009755aba5271e","_cell_guid":"fa3b40a0-8037-44d9-85c1-89cf5d742100"},"source":"# **Introduction**\nThe following kernal demostraits how to derive  distilled features, then further condense your feature space via unsuperived learning. I have a lot to add to the code, let me know what you think! I just started the kernel Febuary 4th, If you have any questions or constructive feedback please email me directly:\n\nemail: **ajg1444@rit.edu**\n\n\n\n-- Alex G.\n\n***Distilling Features:***\n\nThe first step is to distill the *name, category_name, item_description*. To uderstand what distill means let me walk you through how to distill the *category_name*. \n\nWe begin by breaking each row element of the dataframe apart such that each element in the new list is an\n* Individual lower case word\n* Has no numbers or special characters"},{"source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom collections import Counter\nimport re\nimport time as tmi\nfrom collections import Counter\nfrom functools import reduce\nimport matplotlib.pyplot as plt\nimport pprint as pretty\nfrom IPython.display import display","cell_type":"code","metadata":{"_kg_hide-input":true,"collapsed":true,"_uuid":"242de81ad35bab6b2ed1265348a1bb4af98c3537","_cell_guid":"0da9d29b-853c-47f6-a9b7-4d474407d997","_kg_hide-output":true},"outputs":[],"execution_count":null},{"source":"\ntrain = pd.read_csv('../input/train.tsv', sep='\\t')\ntest = pd.read_csv('../input/test.tsv', sep='\\t')\ntrain.head(2)","cell_type":"code","metadata":{"_kg_hide-input":true,"scrolled":true,"_cell_guid":"4327e62a-61a8-4627-beda-1848d0870591","collapsed":true,"_uuid":"234e4a78821c0fbd697d0a277324ad87dc7b6e6b","_kg_hide-output":false},"outputs":[],"execution_count":null},{"source":"# clean list data:\ncategory_names = list(map(lambda x: x.lower(), list(map(str, train['category_name'].tolist()))))\ntrain_id = train['train_id'].tolist()\n\n# clean up category strings:\nfor i in range(len(category_names)):\n    category_names[i] = str(category_names[i].split('/')).split()\n    category_names[i] = map(lambda x: re.sub('[^a-z]+', '',x), category_names[i])\n    category_names[i] = list(Counter(list(filter(None, map(str.strip, category_names[i])))).keys())\n","cell_type":"code","metadata":{"collapsed":true,"_uuid":"b2839e75aa462ed52f75d605eb45f25ee1c6df0e","_cell_guid":"53a13ecc-9499-4997-a8a4-a6826cda0462"},"outputs":[],"execution_count":null},{"source":"pd.set_option('max_colwidth', 60)\ntemp_frame = pd.DataFrame({\"category_names\":[category_names[0],category_names[1]]})\ntemp_frame.head()","cell_type":"code","metadata":{"_kg_hide-input":true,"collapsed":true,"_uuid":"1cc9d7734d221f5f244449a2ae425926776f4f51","_cell_guid":"67e6c4fc-0042-428c-9aa3-200cd3762aaf"},"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{"_uuid":"5a720444b5df9684cd46179283646ed70a5233fb","_cell_guid":"f536cfb5-faaa-4218-a359-fde8cf092f1c"},"source":"Now since every word is lowercase and special characters have been removed we may now create a dictionary which allows us to look up all records (or train_ids) which has the key word in it's distilled catigory list. \n\nFor example\n1. if we wish to search for 'men' the search will return, [0, .... ]\n2. if we wish to search for 'electronics' the search will return [1, .... ]\n"},{"source":"\ncat_hashmap ={}\nfor i in range(len(train_id)):\n    for cat in category_names[i]:\n        if not cat in cat_hashmap:\n            cat_hashmap.update({cat:[train_id[i]]})\n        else:\n            cat_hashmap[cat].append(train_id[i])","cell_type":"code","metadata":{"collapsed":true,"_uuid":"b4e0052112a636ee6f07949b9a22cde6ef327df7","_cell_guid":"ba2f4a07-840b-4935-a9ab-d65549b46a2a"},"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{"_uuid":"4cb993791ce2373894b33677bee17e9f786af9e7","_cell_guid":"a8093d03-a23f-4c48-8e0d-499e4f1d8bb4"},"source":"Great! we have compiled the dictionary now let us put it to the test. Before we do let us set our data frame index to train_id. After let us pull all train_id which have the keyword 'tops' in the distilled category names."},{"source":"train = train.set_index('train_id')","cell_type":"code","metadata":{"collapsed":true,"_uuid":"2948b7863063083ff308facd6073b09481951f1a","_cell_guid":"9c98ba59-dde9-4eb2-8963-61df83cf73bf"},"outputs":[],"execution_count":null},{"source":"view_1 = \"tops\"\nview_1 = cat_hashmap[view_1]\npd.DataFrame({\"train_id_with_word_tops\":view_1,\"category_name\": train[\"category_name\"].loc[view_1].values}).head(5)","cell_type":"code","metadata":{"collapsed":true,"_uuid":"ce15eeee7b57779da908d4dde313a687e067a2c6","_cell_guid":"a1e542aa-31d6-4ef9-aa31-3c93577a257c"},"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{"_uuid":"682b3e31fed82acd650bb865340c5b9ca5c4b8c1","_cell_guid":"0fb33287-3a9e-4568-9cbc-9abb5b326be4"},"source":"Before we further distill the words let us first analize how we may apply our distilled feature by using set theory. Let us analize the price difference between women and men's sports wear. To do this we must analize when \n\n(men and sports intersect) and (woman and sports intersect)  \n\nNote the results have been filtered such that all results with a standard diviation of 3 have been excluded from the finding"},{"source":"# set train id as the primary key\nname = \"price\"       # value which you are  analizing\nview_1 = \"men\"       # subset_1\nview_2 = \"women\"     # subset_2\nintersect = \"sports\" # intersection of both subset_1 and subset_2\n\nview_1  = cat_hashmap[view_1]\nview_2  = cat_hashmap[view_2]\nintersect = cat_hashmap[intersect]\n\n# obtain intersection of view 1 and 2 & the compare list\nview_1 = list(set(view_1) & set(intersect))\nview_2 = list(set(view_2) & set(intersect))\n\n# exctract data\nplot_1 = train[name].loc[view_1].values\nplot_2 = train[name].loc[view_2].values","cell_type":"code","metadata":{"collapsed":true,"_uuid":"68b8e9f95cce9b7573d7100781e92e8c036a7a28","_cell_guid":"ae5eb3f0-978a-4916-a020-3d87fa2167d1"},"outputs":[],"execution_count":null},{"source":"# exctract data\nZ_Thresh = 3\n\nplot_1 = plot_1[abs(np.mean(plot_1)-plot_1)/np.std(plot_1) < Z_Thresh]\nplot_2 = plot_2[abs(np.mean(plot_2)-plot_2)/np.std(plot_2) < Z_Thresh]\n","cell_type":"code","metadata":{"collapsed":true,"_uuid":"8a5a0ceb8e0a54c4bae22a9d5e9eff6013736e01","_cell_guid":"25546ee3-c6ba-4b53-b226-45b91db95b96"},"outputs":[],"execution_count":null},{"source":"# pull training data\nBins  = 20\nviews = list([view_1,view_2])\n\n\nfig=plt.figure(figsize=(18, 6), dpi= 80, facecolor='w', edgecolor='k')\nplt.hist(plot_1, alpha=0.5, normed=True, bins=Bins,label='men')\nplt.hist(plot_2, normed=True,bins=Bins, alpha=0.5,label='women')\nplt.ylabel('Probability',fontsize=15);\nplt.xlabel('price',fontsize=15);\nplt.legend(loc='upper right',fontsize=15)\nplt.show();\n","cell_type":"code","metadata":{"_kg_hide-input":true,"collapsed":true,"_uuid":"e11b204db24af95f82895f9480e32b5aa423a7b6","_cell_guid":"8de572ef-b788-4e1c-98f9-fdb5cdf8465d"},"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{"_uuid":"7ef3899ded7bb18f5f9c2e5194e4ff29558e67f0","_cell_guid":"49b9d33b-5b28-4f0b-93e2-077d90c9d810"},"source":"Seems there is no difference between the pricing of men's and women's sports attare here. Not the best example but I hope you get the picture. \n\nTo further distill our category names we may throw low freqency names out of our universe. To do this let us create a data frame with two columns category_name & frequency. Roughly 581 words of our 1,008 have a freqency of occured less than 581 times out of our 1,482,535 records thats less than 0.03 percent!"},{"source":"Data = dict(Counter(map(lambda x: re.sub('[^a-z]+', '',x),(str(category_names)).split())))\ncategory_df = pd.DataFrame({\"category_name\":list(Data.keys()),\"frequency\":list(Data.values())})\ncategory_df = category_df.sort_values(\"frequency\",ascending=False)","cell_type":"code","metadata":{"collapsed":true,"_uuid":"2a8ed2984953399401e27b0b2e14e8fa5a00e527","_cell_guid":"bfac020e-1730-4831-856f-9b66e5a73914"},"outputs":[],"execution_count":null},{"source":"fig=plt.figure(figsize=(18, 5), dpi= 80, facecolor='w', edgecolor='k')\nplot_1 = category_df[\"frequency\"].values\nplot_1 = plot_1[plot_1  < 500]\nplt.hist(plot_1, alpha=0.5, normed=False, bins=10,label='men')\nplt.ylabel('Frequency',fontsize=15);\nplt.xlabel('Category Name Frequency',fontsize=15);\nplt.show();","cell_type":"code","metadata":{"_kg_hide-input":true,"collapsed":true,"_uuid":"d31a037fbeac5369d83777ba470acfd8367214a6","_cell_guid":"1d4940f5-1cf2-4fe2-9287-c07983f41e49"},"outputs":[],"execution_count":null},{"cell_type":"markdown","metadata":{"_uuid":"492283c8d928c3f8c1885c4ffea5eea6c41dadb1","_cell_guid":"8b763424-0588-4cae-9130-abce00ce689d"},"source":"The next step is to use unsuperviced learning to first transform the problem into a multiclass problem, then use the results aid in building your model."}],"metadata":{"language_info":{"file_extension":".py","mimetype":"text/x-python","version":"3.6.4","nbconvert_exporter":"python","pygments_lexer":"ipython3","codemirror_mode":{"version":3,"name":"ipython"},"name":"python"},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"nbformat":4}