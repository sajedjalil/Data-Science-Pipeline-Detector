{"nbformat":4,"metadata":{"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","mimetype":"text/x-python","version":"3.6.3","file_extension":".py"},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"nbformat_minor":1,"cells":[{"source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\nfrom sklearn.cross_validation import train_test_split\n\nimport matplotlib.pyplot as plt\n%matplotlib inline \n\nimport math\n\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\ndef rmsle(y, y_pred):\n    assert len(y) == len(y_pred)\n    to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n    return (sum(to_sum) * (1.0/len(y))) ** 0.5\n#Source: https://www.kaggle.com/marknagelberg/rmsle-function\n\n#LOAD DATA\nprint(\"Loading data...\")\ntrain = pd.read_table(\"../input/train.tsv\")\ntest = pd.read_table(\"../input/test.tsv\")\nprint(train.shape)\nprint(test.shape)\n\n#HANDLE MISSING VALUES\nprint(\"Handling missing values...\")\ndef handle_missing(dataset):\n    dataset.category_name.fillna(value=\"missing\", inplace=True)\n    dataset.brand_name.fillna(value=\"missing\", inplace=True)\n    dataset.item_description.fillna(value=\"missing\", inplace=True)\n    return (dataset)\n\ntrain = handle_missing(train)\ntest = handle_missing(test)\nprint(train.shape)\nprint(test.shape)\n\ntrain.head(3)\n\n#PROCESS CATEGORICAL DATA\nprint(\"Handling categorical variables...\")\nle = LabelEncoder()\n\nle.fit(np.hstack([train.category_name, test.category_name]))\ntrain.category_name = le.transform(train.category_name)\ntest.category_name = le.transform(test.category_name)\n\nle.fit(np.hstack([train.brand_name, test.brand_name]))\ntrain.brand_name = le.transform(train.brand_name)\ntest.brand_name = le.transform(test.brand_name)\ndel le\n\ntrain.head(3)\n\n#PROCESS TEXT: RAW\nprint(\"Text to seq process...\")\nfrom keras.preprocessing.text import Tokenizer\nraw_text = np.hstack([train.item_description.str.lower(), train.name.str.lower()])\n\nprint(\"   Fitting tokenizer...\")\ntok_raw = Tokenizer()\ntok_raw.fit_on_texts(raw_text)\nprint(\"   Transforming text to seq...\")\n\ntrain[\"seq_item_description\"] = tok_raw.texts_to_sequences(train.item_description.str.lower())\ntest[\"seq_item_description\"] = tok_raw.texts_to_sequences(test.item_description.str.lower())\ntrain[\"seq_name\"] = tok_raw.texts_to_sequences(train.name.str.lower())\ntest[\"seq_name\"] = tok_raw.texts_to_sequences(test.name.str.lower())\ntrain.head(3)\n\n#SEQUENCES VARIABLES ANALYSIS\nmax_name_seq = np.max([np.max(train.seq_name.apply(lambda x: len(x))), np.max(test.seq_name.apply(lambda x: len(x)))])\nmax_seq_item_description = np.max([np.max(train.seq_item_description.apply(lambda x: len(x)))\n                                   , np.max(test.seq_item_description.apply(lambda x: len(x)))])\nprint(\"max name seq \"+str(max_name_seq))\nprint(\"max item desc seq \"+str(max_seq_item_description))\n\ntrain.seq_name.apply(lambda x: len(x)).hist()\n\ntrain.seq_item_description.apply(lambda x: len(x)).hist()\n\n#EMBEDDINGS MAX VALUE\n#Base on the histograms, we select the next lengths\nMAX_NAME_SEQ = 10\nMAX_ITEM_DESC_SEQ = 75\nMAX_TEXT = np.max([np.max(train.seq_name.max())\n                   , np.max(test.seq_name.max())\n                  , np.max(train.seq_item_description.max())\n                  , np.max(test.seq_item_description.max())])+2\nMAX_CATEGORY = np.max([train.category_name.max(), test.category_name.max()])+1\nMAX_BRAND = np.max([train.brand_name.max(), test.brand_name.max()])+1\nMAX_CONDITION = np.max([train.item_condition_id.max(), test.item_condition_id.max()])+1\n\n#SCALE target variable\ntrain[\"target\"] = np.log(train.price+1)\ntarget_scaler = MinMaxScaler(feature_range=(-1, 1))\ntrain[\"target\"] = target_scaler.fit_transform(train.target.reshape(-1,1))\npd.DataFrame(train.target).hist()\n\n#EXTRACT DEVELOPTMENT TEST\ndtrain, dvalid = train_test_split(train, random_state=123, train_size=0.99)\nprint(dtrain.shape)\nprint(dvalid.shape)\n\n\n#KERAS DATA DEFINITION\nfrom keras.preprocessing.sequence import pad_sequences\n\ndef get_keras_data(dataset):\n    X = {\n        'name': pad_sequences(dataset.seq_name, maxlen=MAX_NAME_SEQ)\n        ,'item_desc': pad_sequences(dataset.seq_item_description, maxlen=MAX_ITEM_DESC_SEQ)\n        ,'brand_name': np.array(dataset.brand_name)\n        ,'category_name': np.array(dataset.category_name)\n        ,'item_condition': np.array(dataset.item_condition_id)\n        ,'num_vars': np.array(dataset[[\"shipping\"]])\n    }\n    return X\n\nX_train = get_keras_data(dtrain)\nX_valid = get_keras_data(dvalid)\nX_test = get_keras_data(test)\n\n#KERAS MODEL DEFINITION\nfrom keras.layers import Input, Dropout, Dense, BatchNormalization, Activation, concatenate, GRU, Embedding, Flatten, BatchNormalization\nfrom keras.models import Model\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\nfrom keras import backend as K\n\ndef get_callbacks(filepath, patience=2):\n    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n    msave = ModelCheckpoint(filepath, save_best_only=True)\n    return [es, msave]\n\ndef rmsle_cust(y_true, y_pred):\n    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n    return K.sqrt(K.mean(K.square(first_log - second_log), axis=-1))\n\ndef get_model():\n    #params\n    dr_r = 0.1\n    \n    #Inputs\n    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n    brand_name = Input(shape=[1], name=\"brand_name\")\n    category_name = Input(shape=[1], name=\"category_name\")\n    item_condition = Input(shape=[1], name=\"item_condition\")\n    num_vars = Input(shape=[X_train[\"num_vars\"].shape[1]], name=\"num_vars\")\n    \n    #Embeddings layers\n    emb_name = Embedding(MAX_TEXT, 50)(name)\n    emb_item_desc = Embedding(MAX_TEXT, 50)(item_desc)\n    emb_brand_name = Embedding(MAX_BRAND, 10)(brand_name)\n    emb_category_name = Embedding(MAX_CATEGORY, 10)(category_name)\n    emb_item_condition = Embedding(MAX_CONDITION, 5)(item_condition)\n    \n    #rnn layer\n    rnn_layer1 = GRU(16) (emb_item_desc)\n    rnn_layer2 = GRU(8) (emb_name)\n    \n    #main layer\n    main_l = concatenate([\n        Flatten() (emb_brand_name)\n        , Flatten() (emb_category_name)\n        , Flatten() (emb_item_condition)\n        , rnn_layer1\n        , rnn_layer2\n        , num_vars\n    ])\n    main_l = Dropout(dr_r) (Dense(128) (main_l))\n    main_l = Dropout(dr_r) (Dense(64) (main_l))\n    \n    #output\n    output = Dense(1, activation=\"linear\") (main_l)\n    \n    #model\n    model = Model([name, item_desc, brand_name\n                   , category_name, item_condition, num_vars], output)\n    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\", rmsle_cust])\n    \n    return model\n\n    \nmodel = get_model()\nmodel.summary()\n\n#FITTING THE MODEL\nBATCH_SIZE = 20000\nepochs = 5\n\nmodel = get_model()\nmodel.fit(X_train, dtrain.target, epochs=epochs, batch_size=BATCH_SIZE\n          , validation_data=(X_valid, dvalid.target)\n          , verbose=1)\n\n#EVLUEATE THE MODEL ON DEV TEST: What is it doing?\nval_preds = model.predict(X_valid)\nval_preds = target_scaler.inverse_transform(val_preds)\nval_preds = np.exp(val_preds)+1\n\n#mean_absolute_error, mean_squared_log_error\ny_true = np.array(dvalid.price.values)\ny_pred = val_preds[:,0]\nv_rmsle = rmsle(y_true, y_pred)\nprint(\" RMSLE error on dev test: \"+str(v_rmsle))\n\n#CREATE PREDICTIONS\npreds = model.predict(X_test, batch_size=BATCH_SIZE)\npreds = target_scaler.inverse_transform(preds)\npreds = np.exp(preds)-1\n\nsubmission = test[[\"test_id\"]]\nsubmission[\"price\"] = preds\n\nsubmission.to_csv(\"./NNsubmission.csv\", index=False)\nsubmission.price.hist()\n\n","outputs":[],"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"collapsed":true,"_cell_guid":"d820bc31-5850-4a70-a8e7-653b6b902168","_uuid":"ecc3e5b45f8ac3687cab6887f981b1b7eb1df1c3"},"cell_type":"code","execution_count":null}]}