{"nbformat_minor":1,"nbformat":4,"metadata":{"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py","mimetype":"text/x-python","name":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.3"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"cells":[{"execution_count":null,"outputs":[],"metadata":{"_uuid":"c20c67f2226b24051e2d64a63555059d96969829","_cell_guid":"37070448-9c94-480d-8ad4-55d84b7349b0","collapsed":true},"cell_type":"code","source":"#required libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport csv\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport re\n# Evalaluation\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.preprocessing import LabelBinarizer\nimport scipy\nimport lightgbm as lgb\nfrom sklearn.linear_model import Ridge\nimport time\nimport gc\nfrom scipy.sparse import csr_matrix, hstack"},{"metadata":{"_uuid":"a2348f9930d43043468acba9966cafa05f7864d4","_cell_guid":"406b37d4-0de2-4ce0-92f3-c633dc48df4e"},"cell_type":"markdown","source":"**It's always a good practice to specify the dtypes**"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"bcfc222d3594290f1e193be174a186425c4dec9a","_cell_guid":"a52ff5a1-c462-4688-9c9b-11e61649847a","collapsed":true},"cell_type":"code","source":"types_dict_train = {'train_id': 'int64',\n             'item_condition_id': 'int64',\n             'price': 'float64',\n             'shipping': 'int64'}\ntypes_dict_test = {'test_id': 'int64',\n             'item_condition_id': 'int64',\n             'shipping': 'int64'}"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"621c94f04f2d4da6ee1234adf9cc4db7173630a1","_cell_guid":"13acc905-7816-4194-8f8a-4f115224cbd1","collapsed":true},"cell_type":"code","source":"#read the datasets\ntrain = pd.read_csv('../input/train.tsv', sep='\\t', encoding='utf-8', dtype=types_dict_train)\ntest=pd.read_csv('../input/test.tsv', sep='\\t', encoding='utf-8', dtype=types_dict_train)"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"522ebae3c614166548cf9ee8196b88b62f81a79e","_cell_guid":"3b6e60ca-64f4-4403-90b9-d860ba5d18f2","collapsed":true},"cell_type":"code","source":"#shape of the datasets\nprint(train.shape)\nprint(test.shape)"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"32fd34a81140c7f44614f9866a78599d769c85e7","_cell_guid":"2bc4542d-66d7-482e-a827-f99b3f032e00","collapsed":true},"cell_type":"code","source":"#check the datatype of training dataset\nprint(train.dtypes)\n"},{"metadata":{"_uuid":"fc33c1ff8e68ea214530a91b94946181b3886916","_cell_guid":"3d3d3a2f-628e-41fa-870a-b99499e9e78b"},"cell_type":"markdown","source":"**The training dataset has two types of data-\nStrings:name,category_name,brand_name,item_description\nNumeric:train_id,item_condition_id,shipping,price**"},{"metadata":{"_uuid":"f3b3106339a426a79ea14411bf249db001f59eaa","_cell_guid":"626ffc2b-ca14-4f96-9760-af04d2897987"},"cell_type":"markdown","source":"**Here all categorical variables are stored as 'object' data type.\nSo I am going to convert them into Pandas Category**"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"029c6d3e90219811fb9726933e16818da10b1817","_cell_guid":"1851ea7f-0c22-49a4-9afa-d20f9b40658a","collapsed":true},"cell_type":"code","source":"train.category_name = train.category_name.astype('category')\ntrain.item_description = train.item_description.astype('category')\n\ntrain.name = train.name.astype('category')\ntrain.brand_name = train.brand_name.astype('category')\n\ntest.category_name = test.category_name.astype('category')\ntest.item_description = test.item_description.astype('category')\n\ntest.name = test.name.astype('category')\ntest.brand_name = test.brand_name.astype('category')"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"1e7b55d05e644be7a57618d129d734213fb4093f","_cell_guid":"2032c17b-6cec-4884-aa8c-128be85d566d","collapsed":true},"cell_type":"code","source":"#let's find out the count of distinct values in each column using Pandas\nprint(\"count of distinct values in train dataset:\")\ntrain.apply(lambda x: x.nunique())"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"a4042fca7754630e5e2a1080ce047c538778ffd6","_cell_guid":"c96a70c9-1454-4d40-9112-60f71c10a749","collapsed":true},"cell_type":"code","source":"#let's find out the count of distinct values in each column using Pandas\nprint(\"count of distinct values in test dataset:\")\ntest.apply(lambda x: x.nunique())"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"39442bd2d2ab98bc6e40fa776d1bf8f17663df79","_cell_guid":"423bdcb7-aca6-4718-a672-5ca8c068c033","collapsed":true},"cell_type":"code","source":"#let's find out the missing values\ntrain.isnull().sum(),train.isnull().sum()/train.shape[0]"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"2f8b3b164510f3931c0a1447ae5a83bddd560805","_cell_guid":"2a77b078-e305-4659-abc0-d5cddfe04303","collapsed":true},"cell_type":"code","source":"#let's find out the missing values\ntest.isnull().sum(),test.isnull().sum()/test.shape[0]"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"6207e49f0e069f99f105ede4707526f248cbb545","_cell_guid":"c4ac2d03-f2c4-4f34-860c-7e4dbfa3d29c","collapsed":true},"cell_type":"code","source":"#peek of the training dataset\ntrain.head()"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"6cf17f0391c47f7906bb8580e3a58127eb44e82a","_cell_guid":"2c227b7a-4600-4312-b011-9c1776b40011","collapsed":true},"cell_type":"code","source":"#peek of the test dataset\ntest.head()"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"108c15df51dcb506c23d374ae82d91895f5da0ae","_cell_guid":"e6c7ef4d-6d74-4adb-ba1e-622a3a77df01","collapsed":true},"cell_type":"code","source":"#changing train_id/test_id as id column\ntrain = train.rename(columns = {'train_id':'id'})\ntest = test.rename(columns = {'test_id':'id'})"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"4c6945a4ddd470423d1ff91a51400c6215e8a2ea","_cell_guid":"199621a2-5874-4c51-825c-2e583e769f54","collapsed":true},"cell_type":"code","source":"train.head()"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"8e1e2cb665a1414adf222250b69da69ead452fe7","_cell_guid":"275b2bfd-29e6-4a61-98ae-42e19cead8a7","collapsed":true},"cell_type":"code","source":"train['is_train'] = 1\ntest['is_train'] = 0"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"f2a6e0574d6d26f8f75bf92de0ba7705ec4fbe71","_cell_guid":"9b18b68e-ccc8-41bd-90ee-4a1104dc7946","collapsed":true},"cell_type":"code","source":"test.head()"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"5e9744e1756d0ea8d11348f140a7bbe2cf1afc72","_cell_guid":"3110f83e-3c75-4d02-a8ed-85dbbf5d9f07","collapsed":true},"cell_type":"code","source":"#seperate the target variable and combine the dataset\ntrain_test_combine = pd.concat([train.drop(['price'],axis =1),test],axis = 0)\ntrain_test_combine.category_name = train_test_combine.category_name.astype('category')\ntrain_test_combine.item_description = train_test_combine.item_description.astype('category')\ntrain_test_combine.name = train_test_combine.name.astype('category')\ntrain_test_combine.brand_name = train_test_combine.brand_name.astype('category')"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"8b495e350743c4a8b0d35f8237c082585b8912d9","_cell_guid":"eb65da05-83ff-4852-b022-3a37ee01b820","collapsed":true},"cell_type":"code","source":"#droping item description since I don't know about NLP and deep learning\ntrain_test_combine = train_test_combine.drop(['item_description'],axis = 1)"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"c6208ec9cce53359bb45ca210ef4f43267c76ec7","_cell_guid":"56699f98-d540-4b90-a606-fdc6aa165842","collapsed":true},"cell_type":"code","source":"#get numeric from categorical variables\ntrain_test_combine.name = train_test_combine.name.cat.codes\ntrain_test_combine.category_name = train_test_combine.category_name.cat.codes\ntrain_test_combine.brand_name = train_test_combine.brand_name.cat.codes"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"d6f3fca61d437fe4fe7243882c459456bf434222","_cell_guid":"b76fd4ed-56e0-4bdd-a4b2-684da4e2a7b7","collapsed":true},"cell_type":"code","source":"train_test_combine.head()"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"e39dfb9c494f077529687c26b050a683be796e3a","_cell_guid":"2c28eb75-a1c5-4c5c-8751-e301f520f947","collapsed":true},"cell_type":"code","source":"train_test_combine.dtypes"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"98b00a75a2e8788b749acd03ab828239a3f1081d","_cell_guid":"24586a1e-3b10-4424-8219-5a2d2244f7b0","collapsed":true},"cell_type":"code","source":"df_test = train_test_combine.loc[train_test_combine['is_train']==0]\ndf_train = train_test_combine.loc[train_test_combine['is_train']==1]"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"f169c9b9e804ded976e809ded6e9bc3d52544f39","_cell_guid":"f2e0c056-9eba-4b01-88b4-9224c3d2737d","collapsed":true},"cell_type":"code","source":"df_test = df_test.drop(['is_train'],axis=1)"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"97904bb8e2e5abcda5717ea4afa96783fa277015","_cell_guid":"ccba0271-57cf-4fc3-80f8-0e13a5c1e406","collapsed":true},"cell_type":"code","source":"df_train = df_train.drop(['is_train'],axis=1)"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"d892d0d4dd944ba22e90178810873b538bc710cc","_cell_guid":"03082ffd-f601-48f7-a70d-e471b6c52fc8","collapsed":true},"cell_type":"code","source":"#save the target variable from train dataframe\ndf_train['price'] = train.price"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"3b6f455458e6b4c52074e0b3aa2deb1ab8821b8a","_cell_guid":"f738a6de-8021-4fcb-8869-db7c515b3d23","collapsed":true},"cell_type":"code","source":"#taking the log of price\ndf_train['price'] = df_train['price'].apply(lambda x: np.log(x) if x>0 else x)"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"7a66f14bcecc9583bb2cb11e76a3b721e4db80ea","_cell_guid":"fc1fe3f8-caff-4a82-9ad3-51ae20f84e64","collapsed":true},"cell_type":"code","source":"x_train,y_train = df_train.drop(['price'],axis =1),df_train.price"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"a86e9a43f14f775896a4ef24f96414ed830ba7af","_cell_guid":"3662af93-71f9-49ff-9248-226e4566c59a","collapsed":true},"cell_type":"code","source":"#modeling the problem\nrandomfr = RandomForestRegressor(n_jobs=-1,min_samples_leaf=3,n_estimators=200)\nrandomfr.fit(x_train, y_train)\nrandomfr.score(x_train,y_train)"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"7b082d7d9ea8d54bb26a58e6b81d2ca893fc3cfb","_cell_guid":"493f8783-2222-43e6-962e-3b8c25e0ea49","collapsed":true},"cell_type":"code","source":"preds = randomfr.predict(df_test)"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"b5ee1e007f764cffb81ab8229a20811d907f1934","_cell_guid":"51199bde-8ef3-4f62-a963-38db68314617","collapsed":true},"cell_type":"code","source":"preds = pd.Series(np.exp(preds))"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"9b90ac0c04152c8ce8c206639b4474d4099398e9","_cell_guid":"908c9129-e7cb-4e8c-b4f7-3b8a6dab1b2d","collapsed":true},"cell_type":"code","source":"submit = pd.concat([df_test.id,preds],axis=1)\nsubmit.columns = ['test_id','price']\nsubmit.to_csv(\"./firstoutput.csv\", index=False)"},{"metadata":{"_uuid":"0496a5c128226254efe0428fdffb05e5a042b05d","_cell_guid":"55c0b0b0-3f48-46b8-b5e0-2638b49dc0c8"},"cell_type":"markdown","source":"**From the RandomForest I got a score of 0.53854**\n**Let's try to improve the score by applying light GBM**"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"b2d567d9f9e1867f8ea410fca1f1382bddf16c70","_cell_guid":"688f9629-9108-44ca-9be4-75ed709200e8","collapsed":true},"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.linear_model import Ridge, LogisticRegression\nparams = {\n    'learning_rate': 0.75,\n    'application': 'regression',\n    'max_depth': 3,\n    'num_leaves': 100,\n    'verbosity': -1,\n    'metric': 'RMSE',\n}\ntrain_X, valid_X, train_y, valid_y = train_test_split(x_train, y_train, test_size = 0.1, random_state = 144) \nd_train = lgb.Dataset(train_X, label=train_y, max_bin=8192)\nd_valid = lgb.Dataset(valid_X, label=valid_y, max_bin=8192)\nwatchlist = [d_train, d_valid]\n\nmodel = lgb.train(params, train_set=d_train, num_boost_round=2200, valid_sets=watchlist, \\\nearly_stopping_rounds=50, verbose_eval=100) \npreds = model.predict(df_test)\n\nmodel = Ridge(solver = \"lsqr\", fit_intercept=False)\n\nprint(\"Fitting Model\")\nmodel.fit(x_train, y_train)\n\n#preds += model.predict(df_test)\n#preds /= 2\n#preds = np.expm1(preds)\npreds = pd.Series(np.exp(preds))\nsubmit = pd.concat([df_test.id,preds],axis=1)\nsubmit.columns = ['test_id','price']\nsubmit.to_csv(\"./submissionusinglgb.csv\", index=False)"},{"metadata":{"_uuid":"4585810349afb324e3e6dbfca84e4298063227f1","_cell_guid":"ee5232df-01c1-4a69-b065-667db16a582d"},"cell_type":"markdown","source":"**The Light GBM algorithm improves my score from 0.53854 to 0.53284 which improves my rank 6 places up**"},{"metadata":{"_uuid":"68d65f3391eb87f75a465866c8177dbf2feb0f39","_cell_guid":"1d9a29d5-03ff-4ca0-94a1-70092d6386ac"},"cell_type":"markdown","source":"**For improving the model I need to work on the categorical variables more, so let's try new approach**"},{"metadata":{"_uuid":"bea405fafc7022bb4da5ded1983ea9fc70389144","_cell_guid":"412335f7-46e1-43ee-bede-020c992dcc13"},"cell_type":"markdown","source":"\"\"\"Reference:https://www.kaggle.com/tunguz/more-effective-ridge-lgbm-script-lb-0-44944\"\"\""},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"503ff70b3b2ebc5b014a1d610d7a71e663170588","_cell_guid":"0b85f754-f8a2-4639-b9c1-baa4cf6814e1","collapsed":true},"cell_type":"code","source":"NUM_BRANDS = 4000\nNUM_CATEGORIES = 1000\nNAME_MIN_DF = 10\nMAX_FEATURES_ITEM_DESCRIPTION = 50000"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"f8c11def62bb51ba20ca81707051d58d5626479c","_cell_guid":"5dfe01e4-1640-4b5a-ab31-f8e281f74583","collapsed":true},"cell_type":"code","source":"def handle_missing_inplace(dataset):\n    dataset['category_name'].fillna(value='missing', inplace=True)\n    dataset['brand_name'].fillna(value='missing', inplace=True)\n    dataset['item_description'].fillna(value='missing', inplace=True)"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"9b5733e51c300542bb9da8e45f069e35a8dcc33d","_cell_guid":"365cc6c8-a6c9-4234-bd74-5f5578ced253","collapsed":true},"cell_type":"code","source":"#dealing with missing values in categorical variables\ndef cutting(dataset):\n    pop_brand = dataset['brand_name'].value_counts().loc[lambda x: x.index != 'missing'].index[:NUM_BRANDS]\n    dataset.loc[~dataset['brand_name'].isin(pop_brand), 'brand_name'] = 'missing'\n    pop_category = dataset['category_name'].value_counts().loc[lambda x: x.index != 'missing'].index[:NUM_BRANDS]\n    dataset.loc[~dataset['category_name'].isin(pop_category), 'category_name'] = 'missing'\n\ndef to_categorical(dataset):\n    dataset['category_name'] = dataset['category_name'].astype('category')\n    dataset['brand_name'] = dataset['brand_name'].astype('category')\n    dataset['item_condition_id'] = dataset['item_condition_id'].astype('category')"},{"execution_count":null,"outputs":[],"metadata":{"_uuid":"98b1661bba1d9f9e6a6b0658ca5f89916ec69dfa","_cell_guid":"285c8d30-c9c5-4634-a562-764a60b5d9f5"},"cell_type":"code","source":"def main():\n    start_time = time.time()\n\n    train = pd.read_table('../input/train.tsv', engine='c')\n    test = pd.read_table('../input/test.tsv', engine='c')\n    print('[{}] Finished to load data'.format(time.time() - start_time))\n    print('Train shape: ', train.shape)\n    print('Test shape: ', test.shape)\n\n    nrow_train = train.shape[0]\n    y = np.log1p(train[\"price\"])\n    merge: pd.DataFrame = pd.concat([train, test])\n    submission: pd.DataFrame = test[['test_id']]\n\n    del train\n    del test\n    gc.collect()\n\n    handle_missing_inplace(merge)\n    print('[{}] Finished to handle missing'.format(time.time() - start_time))\n\n    cutting(merge)\n    print('[{}] Finished to cut'.format(time.time() - start_time))\n\n    to_categorical(merge)\n    print('[{}] Finished to convert categorical'.format(time.time() - start_time))\n\n    cv = CountVectorizer(min_df=NAME_MIN_DF)\n    X_name = cv.fit_transform(merge['name'])\n    print('[{}] Finished count vectorize `name`'.format(time.time() - start_time))\n\n    cv = CountVectorizer()\n    X_category = cv.fit_transform(merge['category_name'])\n    print('[{}] Finished count vectorize `category_name`'.format(time.time() - start_time))\n\n    tv = TfidfVectorizer(max_features=MAX_FEATURES_ITEM_DESCRIPTION,\n                         ngram_range=(1, 3),\n                         stop_words='english')\n    X_description = tv.fit_transform(merge['item_description'])\n    print('[{}] Finished TFIDF vectorize `item_description`'.format(time.time() - start_time))\n\n    lb = LabelBinarizer(sparse_output=True)\n    X_brand = lb.fit_transform(merge['brand_name'])\n    print('[{}] Finished label binarize `brand_name`'.format(time.time() - start_time))\n\n    X_dummies = csr_matrix(pd.get_dummies(merge[['item_condition_id', 'shipping']],\n                                          sparse=True).values)\n    print('[{}] Finished to get dummies on `item_condition_id` and `shipping`'.format(time.time() - start_time))\n\n    sparse_merge = hstack((X_dummies, X_description, X_brand, X_category, X_name)).tocsr()\n    print('[{}] Finished to create sparse merge'.format(time.time() - start_time))\n\n    X = sparse_merge[:nrow_train]\n    X_test = sparse_merge[nrow_train:]\n    \n    d_train = lgb.Dataset(X, label=y, max_bin=8192)\n    \n    params = {\n        'learning_rate': 0.75,\n        'application': 'regression',\n        'max_depth': 3,\n        'num_leaves': 100,\n        'verbosity': -1,\n        'metric': 'RMSE',\n    }\n    \n    model = lgb.train(params, train_set=d_train, num_boost_round=3200,  \\\n    verbose_eval=100) \n    preds = 0.6*model.predict(X_test)\n\n    model = Ridge(solver=\"sag\", fit_intercept=True, random_state=205)\n    model.fit(X, y)\n    print('[{}] Finished to train ridge'.format(time.time() - start_time))\n    preds += 0.4*model.predict(X=X_test)\n    print('[{}] Finished to predict ridge'.format(time.time() - start_time))\n\n    submission['price'] = np.expm1(preds)\n    submission.to_csv(\"Thirdsubmission_lgbm_ridge.csv\", index=False)\n\nif __name__ == '__main__':\n    main()"}]}