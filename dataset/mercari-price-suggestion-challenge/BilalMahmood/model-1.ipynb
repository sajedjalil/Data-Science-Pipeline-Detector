{"nbformat_minor":1,"nbformat":4,"cells":[{"cell_type":"code","metadata":{"_cell_guid":"194e0cb9-9f2d-4c45-90ae-9dd83521af5e","_uuid":"328691ddba1b47bbf34306fdb83c65d610f5f3d5"},"outputs":[],"execution_count":null,"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.externals import joblib # load trained model\nimport scipy\nfrom sklearn.feature_extraction.text import  TfidfVectorizer\nfrom sklearn.base import TransformerMixin, BaseEstimator\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"cell_type":"code","metadata":{"_cell_guid":"d22ccd73-4cd4-486d-95fa-9baae5e954f2","collapsed":true,"_uuid":"e55d759a3da6f259bd5feca51f43c7edcab414df"},"outputs":[],"execution_count":null,"source":"## Reading test data\ndf_test = pd.read_csv(\"../input/mercari-price-suggestion-challenge/test.tsv\",sep = \"\\t\")\n\n## Dealing with missing values\ndf_test = df_test.fillna('unavailable')\n"},{"cell_type":"code","metadata":{"_cell_guid":"ce8d0ef7-9afd-49c7-85ea-ee7e8f8ca7cf","collapsed":true,"_uuid":"7641f7470165014711d5c845e6ff91278140b402"},"outputs":[],"execution_count":null,"source":"class CustomVectorizer(BaseEstimator, TransformerMixin):\n    \"\"\" This is a custom transformer that joins text(product name + description) \n        with non text variables(product category, brand, condition & shipment)\n        and is used in pipeline to tune and make predictions.\n        \n        name + description ---> DTM \n        category_name --->  OneHotEncoding\n        brand name --->  OneHotEncoding\n        item_condition --> Number\n        shipping ---> Number\n       \n        \n    Parameters\n    ----------\n    min_df = look at sklearn's tfidf vectorizer for its meaning,\n    ngram_range = look at sklearn's tfidf vectorizer for its meaning\n    stop_words = list of english words that do not convey vital information\n    \n    \"\"\"\n    def __init__(self, min_df = 10, ngram_range = (1,1), stop_words = None):\n        ## Hyper parameters for the text part \n        self.min_df = min_df\n        self.ngram_range = ngram_range\n        self.stop_words = stop_words\n        \n        \n    def fit(self, df, y=None):\n        \"\"\"Fits separate transformers on text and categorical data.\n        Parameters\n        ----------\n        df : dataframe with text and non text variables\n        y : None\n            There is no need of a target in a transformer, yet the pipeline API\n            requires this parameter, thus it is there\n        Returns\n        -------\n        self : object\n            Returns self.\n        \"\"\"\n\n        ## Fitting Text\n        self.text_vect_  = TfidfVectorizer(stop_words = self.stop_words, \n                                          ngram_range = self.ngram_range,\n                                          min_df = self.min_df)\n        text = (df[\"name\"] + \" | \" + df[\"item_description\"]).values        \n        self.text_vect_.fit(text)\n        \n        ## Fitting Categories\n        self.label_cat_enc_  = LabelEncoder()\n        self.hot_cat_enc_  = OneHotEncoder()\n        categories = df[\"category_name\"].values\n        self.hot_cat_enc_.fit(self.label_cat_enc_.fit_transform(categories).reshape(-1, 1))\n        \n        self.cat_classes_dict = {i:0 for i in self.label_cat_enc_.classes_}\n        print(\"Number of categories {}\".format(len(self.cat_classes_dict)))\n        \n        ## Fitting Brand names\n        self.label_brand_enc_  = LabelEncoder()\n        self.hot_brand_enc_  = OneHotEncoder()\n        brands = df[\"brand_name\"].values\n        self.hot_brand_enc_.fit(self.label_brand_enc_.fit_transform(brands).reshape(-1, 1))\n        \n        self.brand_classes_dict = {i:0 for i in  self.label_brand_enc_.classes_}\n        print(\"Number of brands {}\".format(len(self.brand_classes_dict)))\n        \n        # Return the transformer\n        return self\n\n    def transform(self, df, y = None):\n        \"\"\" Using the fitted individual transformers, transform the data and \n        concatenate them into a special DTM\n        \n        Parameters\n        ----------\n        df : dataframe containing the required column names\n            The input samples.\n        Returns\n        -------\n        X_transformed : Custom Matrix with DTM + encoded non text data\n        \"\"\"\n        \n        ## Transforming text \n        text = (df[\"name\"] + \" | \" + df[\"item_description\"]).values         \n        text_dtm = self.text_vect_.transform(text)\n        \n        ## Transforming brands\n        \"\"\"\n        new_brands = df[\"brand_name\"].values\n        new_brands[np.isin(new_brands, self.label_brand_enc_.classes_, \n                           invert = True)] = \"unavailable\"\n        \"\"\"\n        new_brands = df[\"brand_name\"]\n        new_brands[~new_brands.isin(self.brand_classes_dict)] = \"unavailable\"\n        \n    \n        trans_brands = self.hot_brand_enc_.transform(self.label_brand_enc_.transform(new_brands).reshape(-1, 1))\n        \n        ## Transforming categories\n        \"\"\"\n        new_categories = df[\"category_name\"].values\n        new_categories[np.isin(new_categories, self.label_cat_enc_.classes_, \n                           invert = True)] = \"unavailable\"\n        \"\"\"\n        new_categories = df[\"category_name\"]\n        new_categories[~new_categories.isin(self.cat_classes_dict)] = \"unavailable\"\n        \n        \n        trans_categories = self.hot_cat_enc_.transform(self.label_cat_enc_.transform(new_categories).reshape(-1, 1))\n         \n        \n        ## Item Condition and Shipping\n        trans_item_condition = df[\"item_condition_id\"].values.reshape(-1, 1)\n        trans_shipping = df[\"shipping\"].values.reshape(-1, 1)\n        \n        \n        ## Sparse Vectors\n        sparse_trans_categories =  scipy.sparse.csr.csr_matrix(trans_categories)   \n        sparse_trans_brands =  scipy.sparse.csr.csr_matrix(trans_brands)   \n        sparse_trans_item_condition = scipy.sparse.csr.csr_matrix(trans_item_condition)\n        sparse_trans_shipping = scipy.sparse.csr.csr_matrix(trans_shipping)\n        \n        ## Stacked Sparse dataframe\n        return scipy.sparse.hstack([sparse_trans_categories, sparse_trans_brands, \n                                    sparse_trans_item_condition, sparse_trans_shipping, text_dtm])\n        \n       \n\n\n\n"},{"cell_type":"code","metadata":{"_cell_guid":"221fc03c-9fc2-4075-9110-ddc729c05749","_uuid":"d7e44ab497027ef6857ffe2a8b468978f9abca38"},"outputs":[],"execution_count":null,"source":"## Loading Model\ntrans  = joblib.load('../input/mercari-model/trained_transformer.pkl') \nreg_model  = joblib.load('../input/mercari-model/NN_100_relu_linear_output.pkl') "},{"cell_type":"code","metadata":{"_cell_guid":"a50898eb-849b-4b25-ab00-00e5dbc6fc34","_uuid":"e6e5380509ad4b6369b25da31e67b9a5cc3ef5be"},"outputs":[],"execution_count":null,"source":"## Transforming the features\nX_test =  df_test[[\"category_name\",\"brand_name\",\"item_condition_id\",\"shipping\",\"name\",\"item_description\"]]\nX_test_vector = trans.transform(X_test)\n\n## Making predictions using NN\ny_pred = reg_model.predict(X_test_vector)\n\n## Predicted dataframe\ndf_prediction = df_test[[\"test_id\"]]\ndf_prediction[\"price\"] = y_pred \n\n"},{"cell_type":"code","metadata":{"_cell_guid":"58122671-f49b-4130-8a55-488ff1e74a6c","collapsed":true,"_uuid":"ab85aae879579b967ec7030f41456243bbd107b0"},"outputs":[],"execution_count":null,"source":"## Saving the predictions\ndf_prediction.to_csv(\"sample_submission.csv\",\n                     index = False)\n"},{"cell_type":"code","metadata":{"_cell_guid":"dd7a9a4a-e5f2-45f3-a618-65a8ce06fa07","collapsed":true,"_uuid":"e638a59ed7b1dda1a2b2dd7a4373851b8320e843"},"outputs":[],"execution_count":null,"source":""}],"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"version":"3.6.3","pygments_lexer":"ipython3","file_extension":".py","mimetype":"text/x-python","nbconvert_exporter":"python","name":"python"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}}}