{"metadata":{"language_info":{"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","version":"3.6.3"},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"}},"nbformat_minor":1,"nbformat":4,"cells":[{"metadata":{"_uuid":"a310d0c74ea89b076e00d89264dd66906dc589aa","_cell_guid":"722432fc-69c1-434f-bd5d-1af6fa1945de"},"cell_type":"markdown","source":"In this simple notebook, we will use CatBoost to predict the price using only categorical features."},{"metadata":{"_uuid":"f45bc2bed9e9205110da41317e609416cd8cd271","collapsed":true,"_cell_guid":"6b7a283b-2e58-4359-a268-060abdcba95e"},"cell_type":"code","execution_count":null,"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport catboost as cboost\nimport gc\nfrom scipy.sparse import csr_matrix, hstack\nfrom sklearn.linear_model import Ridge\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split, cross_val_score\nimport xgboost as xgb\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.ensemble import RandomForestRegressor\n%matplotlib inline"},{"metadata":{"_uuid":"2dcaa7a5a34aa4608dfdfea3325e3026e6c2cec8","collapsed":true,"_cell_guid":"7b4aeeec-fee3-45f4-9e7a-9f7a4c876ec1"},"cell_type":"code","execution_count":null,"outputs":[],"source":"def handle_missing_inplace(dataset):\n    dataset['category_name'].fillna(value='missing', inplace=True)\n    dataset['brand_name'].fillna(value='missing', inplace=True)\n    dataset['item_description'].fillna(value='missing', inplace=True)\n\n\ndef cutting(dataset):\n    pop_brand = dataset['brand_name'].value_counts().loc[lambda x: x.index != 'missing'].index[:NUM_BRANDS]\n    dataset.loc[~dataset['brand_name'].isin(pop_brand), 'brand_name'] = 'missing'\n    pop_category = dataset['category_name'].value_counts().loc[lambda x: x.index != 'missing'].index[:NUM_BRANDS]\n    dataset.loc[~dataset['category_name'].isin(pop_category), 'category_name'] = 'missing'\n\n\ndef to_categorical(dataset):\n    dataset['category_name'] = dataset['category_name'].astype('category')\n    dataset['brand_name'] = dataset['brand_name'].astype('category')\n    dataset['item_condition_id'] = dataset['item_condition_id'].astype('category')"},{"metadata":{"_uuid":"271d00e091e2f488d916f7782a3581b79e7287f5","collapsed":true,"_cell_guid":"d99d8662-defd-4765-bcc4-896b8345329b"},"cell_type":"code","execution_count":null,"outputs":[],"source":"train = pd.read_table('../input/train.tsv', engine='c')\ntest = pd.read_table('../input/test.tsv', engine='c')\nnrow_train = train.shape[0]"},{"metadata":{"_uuid":"6dc9cd3410e7e5e0367fc33660017ca79b1ae390","collapsed":true,"_cell_guid":"b96100c8-f926-4ba4-98b9-c4bd2cbadffa"},"cell_type":"code","execution_count":null,"outputs":[],"source":"y = np.log1p(train[\"price\"])\nmerge: pd.DataFrame = pd.concat([train, test])\nsubmission: pd.DataFrame = test[['test_id']]"},{"metadata":{"_uuid":"4e0cb24a4301a61726ab77be2904f4b991a75dda","collapsed":true,"_cell_guid":"bc4bd951-74cd-49ca-858c-8c65c312def0"},"cell_type":"code","execution_count":null,"outputs":[],"source":"NUM_BRANDS = 4000\nNUM_CATEGORIES = 1000\nNAME_MIN_DF = 10\nMAX_FEATURES_ITEM_DESCRIPTION = 50000\nhandle_missing_inplace(merge)\ncutting(merge)\nto_categorical(merge)"},{"metadata":{"_uuid":"ea84261ba05dcaf9c297431b80e45819d0ee3a40","collapsed":true,"_cell_guid":"ada95393-c8ee-4ceb-954f-60f48b115c67"},"cell_type":"code","execution_count":null,"outputs":[],"source":"cv = CountVectorizer(min_df=NAME_MIN_DF)\nX_name = cv.fit_transform(merge['name'])\ncv = CountVectorizer()\nX_category = cv.fit_transform(merge['category_name'])\ntv = TfidfVectorizer(max_features=MAX_FEATURES_ITEM_DESCRIPTION,\n                         ngram_range=(1, 3),\n                         stop_words='english')\nX_description = tv.fit_transform(merge['item_description'])\nlb = LabelBinarizer(sparse_output=True)\nX_brand = lb.fit_transform(merge['brand_name'])\nX_dummies = csr_matrix(pd.get_dummies(merge[['item_condition_id', 'shipping']],\n                                          sparse=True).values)\nsparse_merge = hstack((X_dummies, X_description, X_brand, X_category, X_name)).tocsr()\nX = sparse_merge[:nrow_train]\nX_test = sparse_merge[nrow_train:]"},{"metadata":{"_uuid":"70041f428ae9bb8a7092457f27b0665ede5bb475","collapsed":true,"_cell_guid":"bf57d489-3901-4952-bd5a-53bfc2929eca"},"cell_type":"code","execution_count":null,"outputs":[],"source":"model = Ridge(solver=\"sag\", fit_intercept=True, random_state=205, alpha=3)\nmodel.fit(X, y)\npredsR = model.predict(X=X_test)\nmodel = Ridge(solver=\"lsqr\", fit_intercept=False, random_state=145, alpha = 3)\nmodel.fit(X, y)\npredsR2 = model.predict(X=X_test)\nmodel = Ridge(solver=\"sag\", fit_intercept=False, random_state=205, alpha = 3)\nmodel.fit(X, y)\npredsR3 = model.predict(X=X_test)"},{"metadata":{"_uuid":"5fab225b655dc8647acf655f5b6803f3878a1a90","collapsed":true,"_cell_guid":"34d10ae4-33f2-4888-95bf-6bdfe50471ec"},"cell_type":"code","execution_count":null,"outputs":[],"source":"model = RandomForestRegressor(max_features='log2', min_weight_fraction_leaf=0.1)\nmodel.fit(X, y)\npredsL = model.predict(X=X_test)\n# model = GaussianProcessRegressor(random_state=145, alpha = 3)\n# model.fit(X, y)\n# predsL2 = model.predict(X=X_test)\n"},{"metadata":{"_uuid":"95fda291e4ea580a20b1fdb5effb73d5486b2db3","collapsed":true,"_cell_guid":"b563168c-aac5-42dd-aaac-5e183a8ec4a6"},"cell_type":"code","execution_count":null,"outputs":[],"source":""},{"metadata":{"_uuid":"b636ea1afa4648e4db637cd54c24fb4932416d36","collapsed":true,"_cell_guid":"a8b7ad0f-a869-443c-baaa-a240db8f6174"},"cell_type":"code","execution_count":null,"outputs":[],"source":"# # Create train and test Pool of train\n# ptrain = cboost.Pool(pd.DataFrame(X.toarray()), y)\n# ptest = cboost.Pool(pd.DataFrame(X_test.toarray()))"},{"metadata":{"_uuid":"049ee092618c4a499e0f86c24b9e4b7e94b905e9","collapsed":true,"_cell_guid":"abf4f92f-5c9f-43e0-a248-ae780c8a5523"},"cell_type":"code","execution_count":null,"outputs":[],"source":"# # Tune your parameters here!\n# cboost_params = {\n#     'nan_mode': 'Min',\n#     'loss_function': 'RMSE',  # Try 'LogLinQuantile' as well\n#     'iterations': 500,\n#     'learning_rate': 0.76,\n#     'depth': 3,\n#     'verbose': True\n# }\n\n# cboost_params2 = {\n#     'nan_mode': 'Min',\n#     'loss_function': 'RMSE',  # Try 'LogLinQuantile' as well\n#     'iterations': 500,\n#     'learning_rate': 0.85,\n#     'depth': 3,\n#     'verbose': True\n# }\n# best_iter = cboost_params['iterations']  # Initial 'guess' it not using CV\n# best_iter2 = cboost_params2['iterations']\n# # cv_result = cboost.cv(cboost_params, ptrain_sub, fold_count=3)\n\n# # df_cv_result = pd.DataFrame({'train': cv_result['RMSE_train_avg'],\n# #                              'valid': cv_result['RMSE_test_avg']})\n\n# # # Best results\n# # print('Best results:')\n# # best_iter = df_cv_result.valid.argmin()+1\n# # df_cv_bestresult = df_cv_result.iloc[best_iter-1]\n# # print(df_cv_bestresult)\n\n# # fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n# # df_cv_result.plot(ax=ax[0])\n\n# # ax[1].plot(df_cv_result.train, df_cv_result.valid, 'o-')\n# # ax[1].scatter([df_cv_bestresult['train']], [df_cv_bestresult['valid']], c='red')\n# # ax[1].set_xlabel('train')\n# # ax[1].set_ylabel('valid')"},{"metadata":{"_uuid":"d752d3776f02dcd4bac7a7a8083b7e94dd4b39ea","collapsed":true,"_cell_guid":"3ded0fe6-e4a0-4f7d-bb18-aa4a675dfff7"},"cell_type":"code","execution_count":null,"outputs":[],"source":"# # Train model on full data\n# model = cboost.CatBoostRegressor(**dict(cboost_params, verbose=False, iterations=best_iter))\n# fit_model = model.fit(ptrain)\n# predsL = fit_model.predict(ptest).clip(0)\n# # Train model on full data\n# model = cboost.CatBoostRegressor(**dict(cboost_params2, verbose=False, iterations=best_iter2))\n# fit_model = model.fit(ptrain)\n# predsL2 = fit_model.predict(ptest).clip(0)"},{"metadata":{"_uuid":"c62c85b578b555883434834ddd45843d5bcaab1c","collapsed":true,"_cell_guid":"b26427ac-3910-46b3-a69f-92439eb5915d"},"cell_type":"code","execution_count":null,"outputs":[],"source":"# Predict test and save to .csv\npreds1 = np.expm1(predsR3*0.24 + predsR2*0.24 + predsR*0.52)\npreds2 = np.expm1(predsL) #+ predsL2*0.5)\nsubmission['price'] = preds1*0.75 + preds2*0.25\nsubmission.to_csv('submission.csv', index=False)"},{"metadata":{"_uuid":"381489c655f110e6c0d911d4614fe765f56619f4","collapsed":true,"_cell_guid":"fa9f74ae-ce84-4929-939d-a5e4d0f9c628"},"cell_type":"code","execution_count":null,"outputs":[],"source":"!head submission.csv"}]}