{"nbformat":4,"nbformat_minor":1,"cells":[{"cell_type":"markdown","source":"Inspired by https://www.kaggle.com/c/mercari-price-suggestion-challenge/discussion/45160, I seek to benchmark different solvers and alpha levels for the `Ridge` classifier in SKLearn.\n\nSome resources:\n\n* Read more about `Ridge`: http://scikit-learn.org/stable/modules/linear_model.html#ridge-regression\n* Read more about the individual solvers: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge\n* Here's a bit on how `alpha` works (higher `alpha` = lower model complexity = lower risk of overfitting): https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-ridge-lasso-regression-python/","metadata":{}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"import gc\nimport time\nimport numpy as np\nimport pandas as pd\n\nfrom scipy.sparse import csr_matrix, hstack\n\nfrom sklearn.linear_model import Ridge\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.preprocessing import LabelBinarizer, StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport lightgbm as lgb\n\nNUM_BRANDS = 4000\nNUM_CATS = 4000\nNAME_MIN_DF = 10\nMAX_FEATURES_ITEM_DESCRIPTION = 50000\n\n\ndef handle_missing_inplace(dataset):\n    dataset['category_name'].fillna(value='missing', inplace=True)\n    dataset['brand_name'].fillna(value='missing', inplace=True)\n    dataset['item_description'].fillna(value='missing', inplace=True)\n\ndef cutting(dataset):\n    pop_brand = dataset['brand_name'].value_counts().loc[lambda x: x.index != 'missing'].index[:NUM_BRANDS]\n    dataset.loc[~dataset['brand_name'].isin(pop_brand), 'brand_name'] = 'missing'\n    pop_category = dataset['category_name'].value_counts().loc[lambda x: x.index != 'missing'].index[:NUM_CATS]\n    dataset.loc[~dataset['category_name'].isin(pop_category), 'category_name'] = 'missing'\n\ndef to_categorical(dataset):\n    dataset['category_name'] = dataset['category_name'].astype('category')\n    dataset['brand_name'] = dataset['brand_name'].astype('category')\n    dataset['item_condition_id'] = dataset['item_condition_id'].astype('category')\n\nstart_time = time.time()\ntrain = pd.read_table('../input/train.tsv', engine='c')\ntest = pd.read_table('../input/test.tsv', engine='c')\nprint('[{}] Finished to load data'.format(time.time() - start_time))\n\nnrow_train = train.shape[0]\ny = np.log1p(train[\"price\"])\nmerge: pd.DataFrame = pd.concat([train, test])\nsubmission: pd.DataFrame = test[['test_id']]\ndel train\ndel test\ngc.collect()\n\nhandle_missing_inplace(merge)\nprint('[{}] Finished to handle missing'.format(time.time() - start_time))\ncutting(merge)\nprint('[{}] Finished to cut'.format(time.time() - start_time))\nto_categorical(merge)\nprint('[{}] Finished to convert categorical'.format(time.time() - start_time))\ncv = CountVectorizer(min_df=NAME_MIN_DF)\nX_name = cv.fit_transform(merge['name'])\nprint('[{}] Finished count vectorize `name`'.format(time.time() - start_time))\n\ncv = CountVectorizer()\nX_category = cv.fit_transform(merge['category_name'])\nprint('[{}] Finished count vectorize `category_name`'.format(time.time() - start_time))\n\ntv = TfidfVectorizer(max_features=MAX_FEATURES_ITEM_DESCRIPTION,\n                     ngram_range=(1, 3),\n                     stop_words='english')\nX_description = tv.fit_transform(merge['item_description'])\nprint('[{}] Finished TFIDF vectorize `item_description`'.format(time.time() - start_time))\n\nlb = LabelBinarizer(sparse_output=True)\nX_brand = lb.fit_transform(merge['brand_name'])\nprint('[{}] Finished label binarize `brand_name`'.format(time.time() - start_time))\n\nX_dummies = csr_matrix(pd.get_dummies(merge[['item_condition_id', 'shipping']],\n                                      sparse=True).values)\nprint('[{}] Finished to get dummies on `item_condition_id` and `shipping`'.format(time.time() - start_time))\n\nsparse_merge = hstack((X_dummies, X_description, X_brand, X_category, X_name)).tocsr()\nprint('[{}] Finished to create sparse merge'.format(time.time() - start_time))\n\nX = sparse_merge[:nrow_train]\nX_test = sparse_merge[nrow_train:]","metadata":{"_uuid":"8620e08a140638728b18fa4b22058d34d0c89e7d","scrolled":true,"_cell_guid":"20dd83b2-f62a-4ab6-8bed-d03bda4351de"}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"# Make a 20% holdout set so that we can benchmark our implementations.\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2, random_state = 144)\n# I've found that in practice that Public Leaderboard scores are about 0.003 better than holdout\n# scores (e.g., 0.468 in holdout will be about 0.465 on Public Leadearboard).\n#\n# I've also found locally on my laptop that the holdout score is very close to the 5-fold\n# CV score and that fold variance is quite low. Good for us!\n\ndef rmse(predicted, actual):\n    return np.sqrt(((predicted - actual) ** 2).mean())\n\ndef test_model(model):\n    start_time = time.time()\n    model.fit(X_train, y_train)\n    train_finished = time.time()\n    preds = model.predict(X_valid)\n    print('RMSLE %f, train in %.4f sec, predict in %.4f sec' % (rmse(preds, y_valid), (train_finished - start_time), (time.time() - train_finished)))\n\nfor solver in ['lsqr', 'sparse_cg', 'sag', 'saga']:\n    print('Solver =', solver)\n    intercept = True if solver == 'sag' else False # Sklearn says only sag can fit intercept. Maybe saga can too?\n    for alpha in [0.01, 0.03, 0.05, 0.1, 0.5, 1, 3, 5, 10]:\n        print('Alpha =', alpha)\n        model = Ridge(alpha=alpha, copy_X=True, fit_intercept=intercept, max_iter=100,\n                      normalize=False, random_state=101, solver=solver, tol=0.01)\n        test_model(model)","metadata":{}},{"execution_count":null,"cell_type":"code","outputs":[],"source":"# To be more precise, focus on the best alphas with lower tolerance and no iteration cap.\n\n# Though it looks like the same relationship between alpha and score does not hold, and that\n# scores are not actually guaranteed to be better!\n\nfor solver in ['lsqr', 'sag', 'saga']:\n    print('Solver =', solver)\n    intercept = True if solver == 'sag' else False\n    for alpha in [1, 3, 5]:\n        print('Alpha =', alpha)\n        model = Ridge(alpha=alpha, copy_X=True, fit_intercept=intercept, max_iter=None,\n                      normalize=False, random_state=101, solver=solver, tol=0.001)\n        test_model(model)\n    \n# Room for further improvement is left as an excercise for the reader. :D","metadata":{}}],"metadata":{"language_info":{"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.3","pygments_lexer":"ipython3"},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}}}