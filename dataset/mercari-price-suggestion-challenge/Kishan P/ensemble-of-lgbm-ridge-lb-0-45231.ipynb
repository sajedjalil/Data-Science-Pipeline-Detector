{"cells":[{"source":"**This is based off of great work by Bojan Tunguz and yliu **","cell_type":"markdown","metadata":{"_cell_guid":"7edabdf1-9013-43f2-9c42-e1c6f3766b47","_uuid":"e6c4bbe70fc34fd438be054d834ec2062a981758"}},{"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","outputs":[],"cell_type":"code","metadata":{"_cell_guid":"b9c998fe-3961-406f-bdf0-5b13b1a23a3a","_uuid":"5f7de64212a937614568b4b1cca6209862c58b5e","collapsed":true},"execution_count":null},{"source":"![](http://)**First Kernel done by Bojan Tunguz** https://www.kaggle.com/tunguz/lgbm-ridge-0-45529-lb/code","cell_type":"markdown","metadata":{"_cell_guid":"e9a74908-2918-4a7d-a145-c53b1ebd090e","_uuid":"407818d9469f1fd09b6c89af77bd55186526fb13"}},{"source":"import pandas as pd\nimport numpy as np\nimport scipy\n\nfrom sklearn.linear_model import Ridge, LogisticRegression\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.preprocessing import LabelBinarizer\nimport lightgbm as lgb\n\nimport gc","outputs":[],"cell_type":"code","metadata":{"_cell_guid":"7e550016-4892-4fbd-9983-959b0e56e0e2","_uuid":"0983360462c2018c61eac7aade1d7eedca808efb","collapsed":true},"execution_count":null},{"source":"NUM_BRANDS = 2500\nNAME_MIN_DF = 10\nMAX_FEAT_DESCP = 50000\n\nprint(\"Reading in Data\")\n\ndf_train = pd.read_csv('../input/train.tsv', sep='\\t')\ndf_test = pd.read_csv('../input/test.tsv', sep='\\t')\n\ndf = pd.concat([df_train, df_test], 0)\nnrow_train = df_train.shape[0]\ny_train = np.log1p(df_train[\"price\"])\n\ndel df_train\ngc.collect()\n\nprint(df.memory_usage(deep = True))","outputs":[],"cell_type":"code","metadata":{"_cell_guid":"a27cafef-2a4e-4c2f-97a9-ad46dbcaa6b2","_uuid":"87ebdfc95138a7389a802842cdebe0e8d182b3d1","collapsed":true},"execution_count":null},{"source":"df[\"category_name\"] = df[\"category_name\"].fillna(\"Other\").astype(\"category\")\ndf[\"brand_name\"] = df[\"brand_name\"].fillna(\"unknown\")\n\npop_brands = df[\"brand_name\"].value_counts().index[:NUM_BRANDS]\ndf.loc[~df[\"brand_name\"].isin(pop_brands), \"brand_name\"] = \"Other\"\n\ndf[\"item_description\"] = df[\"item_description\"].fillna(\"None\")\ndf[\"item_condition_id\"] = df[\"item_condition_id\"].astype(\"category\")\ndf[\"brand_name\"] = df[\"brand_name\"].astype(\"category\")\n\nprint(df.memory_usage(deep = True))","outputs":[],"cell_type":"code","metadata":{"_cell_guid":"72dc5d87-500b-41b5-be4a-370957dcf1c1","_uuid":"4d5750a44db184d5eb573990e21aab373a025293","collapsed":true},"execution_count":null},{"source":"print(\"Encodings\")\ncount = CountVectorizer(min_df=NAME_MIN_DF)\nX_name = count.fit_transform(df[\"name\"])\n\nprint(\"Category Encoders\")\nunique_categories = pd.Series(\"/\".join(df[\"category_name\"].unique().astype(\"str\")).split(\"/\")).unique()\ncount_category = CountVectorizer()\nX_category = count_category.fit_transform(df[\"category_name\"])\n\nprint(\"Descp encoders\")\ncount_descp = TfidfVectorizer(max_features = MAX_FEAT_DESCP, \n                              ngram_range = (1,3),\n                              stop_words = \"english\")\nX_descp = count_descp.fit_transform(df[\"item_description\"])\n\nprint(\"Brand encoders\")\nvect_brand = LabelBinarizer(sparse_output=True)\nX_brand = vect_brand.fit_transform(df[\"brand_name\"])\n\nprint(\"Dummy Encoders\")\nX_dummies = scipy.sparse.csr_matrix(pd.get_dummies(df[[\n    \"item_condition_id\", \"shipping\"]], sparse = True).values)","outputs":[],"cell_type":"code","metadata":{"_cell_guid":"a664b302-4ae6-46ab-b7ef-752e2622d9d0","_uuid":"9db335b1cd5f40772783f2fa80a4d61345259894","collapsed":true},"execution_count":null},{"source":"X = scipy.sparse.hstack((X_dummies, \n                         X_descp,\n                         X_brand,\n                         X_category,\n                         X_name)).tocsr()\n\nprint([X_dummies.shape, X_category.shape, \n       X_name.shape, X_descp.shape, X_brand.shape])\n\nX_train = X[:nrow_train]\nX_test = X[nrow_train:]","outputs":[],"cell_type":"code","metadata":{"_cell_guid":"57a4b628-1b2d-4a28-b566-6737c47f3a16","_uuid":"31cb38b826c2699e6450c79da04b123ccf4f5338","collapsed":true},"execution_count":null},{"source":"params = {\n    'learning_rate': 0.75,\n    'application': 'regression',\n    'max_depth': 3,\n    'num_leaves': 100,\n    'verbosity': -1,\n    'metric': 'RMSE',\n}\n\n\ntrain_X, valid_X, train_y, valid_y = train_test_split(X_train, y_train, test_size = 0.1, random_state = 144) \nd_train = lgb.Dataset(train_X, label=train_y, max_bin=8192)\nd_valid = lgb.Dataset(valid_X, label=valid_y, max_bin=8192)\nwatchlist = [d_train, d_valid]\n\nmodel = lgb.train(params, train_set=d_train, num_boost_round=2200, valid_sets=watchlist, \\\nearly_stopping_rounds=50, verbose_eval=100) \npreds = model.predict(X_test)\n\nmodel = Ridge(solver = \"lsqr\", fit_intercept=False)\n\nprint(\"Fitting Model\")\nmodel.fit(X_train, y_train)\n\npreds += model.predict(X_test)\npreds /= 2","outputs":[],"cell_type":"code","metadata":{"_cell_guid":"278b99c1-9cc1-4e78-b55f-03277b3e97e3","_uuid":"a8a5a355fd055e88ae1be84f9271c7e53ab01ce4","collapsed":true},"execution_count":null},{"source":"df_test[\"price\"] = np.expm1(preds)\ndf_test[[\"test_id\", \"price\"]].to_csv(\"submission_LGBM_Ridge_3.csv\", index = False)","outputs":[],"cell_type":"code","metadata":{"_cell_guid":"1104312d-f758-49a0-933d-89f6b6cdc24c","_uuid":"f1a98994a7733745eb53c01191073fd20b4fcaf1","collapsed":true},"execution_count":null},{"source":"**Including yliu's kernel now** https://www.kaggle.com/yliu9999/lightgbm-ridge-0-45704lb/notebook","cell_type":"markdown","metadata":{"_cell_guid":"06b3e9ae-f47e-4de6-8174-c182c80a6185","_uuid":"c227d45efad897e1ce3697eac1a8b923688ca3bd"}},{"source":"import numpy as np\nimport pandas as pd\nimport scipy\n\nfrom sklearn.linear_model import Ridge, LogisticRegression\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.preprocessing import LabelBinarizer\n\nimport gc\n\nNUM_BRANDS = 2500\nNAME_MIN_DF = 10\nMAX_FEAT_DESCP = 10000\n\nprint(\"Reading in Data\")\n\ndf_train2 = pd.read_csv('../input/train.tsv', sep='\\t')\ndf_test2 = pd.read_csv('../input/test.tsv', sep='\\t')\n\ndf = pd.concat([df_train2, df_test2], 0)\nnrow_train = df_train2.shape[0]\ny_train = np.log(df_train2[\"price\"]+1)\n\ndel df_train2\ngc.collect()\n\nprint(df.memory_usage(deep = True))\n\ndf[\"category_name\"] = df[\"category_name\"].fillna(\"Other\").astype(\"category\")\ndf[\"brand_name\"] = df[\"brand_name\"].fillna(\"unknown\")\n\npop_brands = df[\"brand_name\"].value_counts().index[:NUM_BRANDS]\ndf.loc[~df[\"brand_name\"].isin(pop_brands), \"brand_name\"] = \"Other\"\n\ndf[\"item_description\"] = df[\"item_description\"].fillna(\"None\")\ndf[\"item_condition_id\"] = df[\"item_condition_id\"].astype(\"category\")\ndf[\"brand_name\"] = df[\"brand_name\"].astype(\"category\")\n\nprint(df.memory_usage(deep = True))\n\nprint(\"Encodings\")\ncount = CountVectorizer(min_df=NAME_MIN_DF)\nX_name = count.fit_transform(df[\"name\"])\n\nprint(\"Category Encoders\")\nunique_categories = pd.Series(\"/\".join(df[\"category_name\"].unique().astype(\"str\")).split(\"/\")).unique()\ncount_category = CountVectorizer()\nX_category = count_category.fit_transform(df[\"category_name\"])\n\nprint(\"Descp encoders\")\ncount_descp = TfidfVectorizer(max_features = MAX_FEAT_DESCP, \n                              ngram_range = (1,3),\n                              stop_words = \"english\")\nX_descp = count_descp.fit_transform(df[\"item_description\"])\n\nprint(\"Brand encoders\")\nvect_brand = LabelBinarizer(sparse_output=True)\nX_brand = vect_brand.fit_transform(df[\"brand_name\"])\n\nprint(\"Dummy Encoders\")\nX_dummies = scipy.sparse.csr_matrix(pd.get_dummies(df[[\n    \"item_condition_id\", \"shipping\"]], sparse = True).values)\n\nX = scipy.sparse.hstack((X_dummies, \n                         X_descp,\n                         X_brand,\n                         X_category,\n                         X_name)).tocsr()\n\nprint([X_dummies.shape, X_category.shape, \n       X_name.shape, X_descp.shape, X_brand.shape])\n\nX_train = X[:nrow_train]\nmodel = Ridge(solver = \"lsqr\", fit_intercept=False)\n\nprint(\"Fitting Model\")\nmodel.fit(X_train, y_train)\n\nX_test = X[nrow_train:]\npreds1 = model.predict(X_test)\n\n#submission = df_test2#[[\"test_id\"]]\n#df_test2[\"price1\"] =preds1\n\n\n\ndf_test2[\"price1\"] = np.exp(preds1)-1\n\n\n\n#df_test2[[\"test_id\", \"price\"]].to_csv(\"submission_ridge.csv\", index = False)\n","outputs":[],"cell_type":"code","metadata":{"_cell_guid":"0cde15db-8182-4454-87f8-82597ffd8b6f","_uuid":"66fb8ee012f5c6c9e0601148e7582149a98138ae","collapsed":true},"execution_count":null},{"source":"type(X_test)","outputs":[],"cell_type":"code","metadata":{"_cell_guid":"6f851d55-7bd9-43bd-8b2c-3dddcea8371b","_uuid":"511a1df752a80d0380ec85a8d5c451a73dafd381","collapsed":true},"execution_count":null},{"source":"X=X_train \ny=y_train\n\ndef rmsle(predictions, targets):\n    predictions = np.exp(predictions) - 1\n    targets = np.exp(targets) - 1\n    return np.sqrt(((predictions - targets) ** 2).mean())\n\ndef rmsle_lgb(labels, preds):\n    return 'rmsle', rmsle(preds, labels), False\n\n","outputs":[],"cell_type":"code","metadata":{"_cell_guid":"85edd91d-8739-4754-92ec-30d5f3524ce7","_uuid":"08ac8a845c7649d9ec9a0b574a295cf9f4fc6289","collapsed":true},"execution_count":null},{"source":"print('Training model...')\nfrom sklearn.model_selection import train_test_split\n\nfrom lightgbm import LGBMRegressor\nX_train, X_test2, y_train, y_test2 = train_test_split(X, y, test_size=0.3, random_state=42)\nlgbm_params = {'n_estimators': 1000, 'learning_rate': 0.4, 'max_depth': 10,\n               'num_leaves': 31, 'subsample': 0.9, 'colsample_bytree': 0.8,\n               'min_child_samples': 50, 'n_jobs': 4}\nmodel = LGBMRegressor(**lgbm_params)\nmodel.fit(X_train, y_train,\n         eval_set=[(X_test2, y_test2)],\n         eval_metric=rmsle_lgb,\n         early_stopping_rounds=100,\n         verbose=True)\n\nprint('Generating submission...')\n\npreds2 = model.predict(X_test)\n","outputs":[],"cell_type":"code","metadata":{"_cell_guid":"6f6b2527-db1d-4626-91e6-81b9b2fda414","_uuid":"de252bf2119828858baa24a95fe1908bed403155","collapsed":true},"execution_count":null},{"source":"df_test2['price2']=np.exp(preds2) - 1\n\ndf_test2['price']=(df_test2['price2']+df_test2['price1'])/2\ndf_test2[[\"test_id\", \"price\"]].to_csv(\"submission.csv\", index = False)\n","outputs":[],"cell_type":"code","metadata":{"_cell_guid":"e81dc4d6-2422-4b3b-bf57-34c91d01df1e","_uuid":"64cf0c405e62e242f71fd9cc7cd5b3597eed9460","collapsed":true},"execution_count":null},{"source":"df_test[[\"test_id\", \"price\"]].head()","outputs":[],"cell_type":"code","metadata":{"_cell_guid":"135c8b6c-7e63-450e-b0c8-dd88ae480b2b","_uuid":"fd416fdfcbd114fa7e9a68993981804e614356b0","collapsed":true},"execution_count":null},{"source":"df_test2[[\"test_id\", \"price\"]].head()","outputs":[],"cell_type":"code","metadata":{"_cell_guid":"771a4d01-a8b8-4150-9a9a-cdf0dd692ed0","_uuid":"491697c36ebb049d7fdc3b2f0c8e33671c2434a5","collapsed":true},"execution_count":null},{"source":"new = df_test[[\"test_id\", \"price\"]].copy()\nnew.head()","outputs":[],"cell_type":"code","metadata":{"_cell_guid":"66a1579e-7a2a-4342-a8df-162962038a19","_uuid":"63edba67f0cfaa0eec5af6faf17dd6dbdc15d542","collapsed":true},"execution_count":null},{"source":"new2 = df_test2[[\"test_id\", \"price\"]].copy()\nnew2.head()","outputs":[],"cell_type":"code","metadata":{"_cell_guid":"651fa2a1-0393-46b1-bafd-5061a4c081c6","_uuid":"269f6495ed796f7e9e1447e28e105560099e6137","collapsed":true},"execution_count":null},{"source":"new['price'] = new2['price']*.6 + new['price']*.4\nnew.head()","outputs":[],"cell_type":"code","metadata":{"_cell_guid":"c8dcde07-4061-444f-85be-6a31c8ae2f38","_uuid":"9dbff41f48ef7ec94e180240622bef707c6a4d27","collapsed":true},"execution_count":null},{"source":"new.to_csv(\"lgbm_ridge_ensemble2.csv\", float_format='%.4f', index=None)","outputs":[],"cell_type":"code","metadata":{"_cell_guid":"1921abcd-82ac-4a35-a130-f571b4dd48e6","_uuid":"8a0b3820ca0a79f0b999416473f3986c3e57332c","collapsed":true},"execution_count":null}],"nbformat":4,"metadata":{"language_info":{"nbconvert_exporter":"python","mimetype":"text/x-python","version":"3.6.3","name":"python","file_extension":".py","pygments_lexer":"ipython3","codemirror_mode":{"version":3,"name":"ipython"}},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat_minor":1}