{"nbformat":4,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"version":"3.6.4","mimetype":"text/x-python","file_extension":".py","pygments_lexer":"ipython3","nbconvert_exporter":"python","name":"python"}},"nbformat_minor":1,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"metadata":{"_uuid":"aae51e97ef03c4384526ba0eeb3d24aa23953161","_cell_guid":"22c4fc8c-67b2-4b57-99aa-d0c65bfdd916"},"outputs":[]},{"cell_type":"code","source":"# Function for filling the NaN values in the dataframe\ndef transform_values(data):\n    data.fillna(value='missing', inplace = True)\n    return data","execution_count":null,"metadata":{"_uuid":"b3583176dc743359f3ddf830a412282f0baa7de4","_cell_guid":"a8808b08-ec44-410b-b142-aaab5c1fed60","collapsed":true},"outputs":[]},{"cell_type":"code","source":"# Read the datafiles\ndf_train = pd.read_csv('../input/train.tsv', sep='\\t') \ndf_test = pd.read_csv('../input/test.tsv', sep='\\t')\n\n# Fill the NaN values with \"missing\"\ndf_train = transform_values(df_train)\ndf_test = transform_values(df_test)","execution_count":null,"metadata":{"_uuid":"4da942fb29c047b7b8848701f5766c1bc4a5e748","_cell_guid":"c4ac516c-9d7d-4ae8-b74d-175cd1f8b23b","collapsed":true},"outputs":[]},{"cell_type":"code","source":"# Split the categories into a maincategory, subcategory 1 and subcategory 2\ndef transform_category_name(category_name):\n    # If there is a category split it\n    try:\n        main, sub1, sub2= category_name.split('/')\n        return main, sub1, sub2\n    # Else return three times \"missing\"\n    except:\n        return 'missing', 'missing', 'missing'\n\n# Splitting the catorgy name, removing the 0 price items and fill in the missing descriptions with \"missing\"\ndf_train['category_main'], df_train['category_sub1'], df_train['category_sub2'] = zip(*df_train['category_name'].apply(transform_category_name))\ndf_train[df_train.price != 0.0]\ndf_train[df_train.item_description != 'missing']\n\ndf_test['category_main'], df_test['category_sub1'], df_test['category_sub2'] = zip(*df_test['category_name'].apply(transform_category_name))\ndf_test[df_test.item_description != 'missing']","execution_count":null,"metadata":{"_uuid":"3953b60a83afe5922215479db0ce2e075b19cd6a","_cell_guid":"dcaecb72-ad7b-4911-9277-d02bba1cf0bd"},"outputs":[]},{"cell_type":"code","source":"# Name vectorizing with count vectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n#Initizializing the countVectorizer\ncv = CountVectorizer(ngram_range=(1,2), min_df=7, stop_words='english')\n\n# Making X-vectors for the name, train and test\nX_name_train = cv.fit_transform(df_train['name'])\nX_name_test = cv.transform(df_test['name'])\n\n","execution_count":null,"metadata":{"_uuid":"a0a4762919a22e442da809a7411d7bedb2fef77f","_cell_guid":"3da3643c-b963-4bc7-956c-5921e91569c6","collapsed":true},"outputs":[]},{"cell_type":"code","source":"# Categories vectorization\ncat_cv1 = CountVectorizer()\ncat_cv2 = CountVectorizer()\ncat_cv3 = CountVectorizer()\n\n# Vectorize the trainingscategories to count vectors\nX_catmain_train = cat_cv1.fit_transform(df_train['category_main'])\nX_catsub1_train = cat_cv2.fit_transform(df_train['category_sub1'])\nX_catsub2_train = cat_cv3.fit_transform(df_train['category_sub2'])\n\n# Vectorize the testcategories to count vectors\nX_catmain_test = cat_cv1.transform(df_test['category_main'])\nX_catsub1_test = cat_cv2.transform(df_test['category_sub1'])\nX_catsub2_test = cat_cv3.transform(df_test['category_sub2'])","execution_count":null,"metadata":{"_uuid":"7fd1aca883ed0b38d7e75004c14ac8e92df07de6","_cell_guid":"bcb8399f-e740-4852-8159-a8fe6b00b1df","collapsed":true},"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# create the vectorizer\nvectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=90000, strip_accents=\"ascii\",\n                             stop_words='english')\n# fit and transform the vectorizer for train\nX_description_train = vectorizer.fit_transform(df_train['item_description'])\n# fit and transform the vectorizer for test\nX_description_test = vectorizer.transform(df_test['item_description'])","execution_count":null,"metadata":{"_uuid":"6f4e69c88f3d7a9631470956cca360cf5aed4d85","_cell_guid":"a4c6411b-5c80-4aae-b8ec-1aa6d9982ce4","collapsed":true},"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelBinarizer\n#Brand name binary vectorization train and test set\nlb = LabelBinarizer()\nX_brand_train = lb.fit_transform(df_train['brand_name'])\nX_brand_test = lb.transform(df_test['brand_name'])","execution_count":null,"metadata":{"_uuid":"0ca10d4c4ec4bb69b4148c4b6a5cb72716ba4671","_cell_guid":"f95ffb5d-20be-4b86-8467-7d1f5aa2b1c1","collapsed":true},"outputs":[]},{"cell_type":"code","source":"# Shipping and item state converge to dummies trainingsset\nX_shipping_train = pd.get_dummies(df_train['shipping'])\nX_condition_train = pd.get_dummies(df_train['item_condition_id'])\n\n# Shipping and item state converge to dummies testset\nX_shipping_test = pd.get_dummies(df_test['shipping'])\nX_condition_test = pd.get_dummies(df_test['item_condition_id'])","execution_count":null,"metadata":{"_uuid":"9c3ee58a2040ac0e2f1ab038b5d7b5728603f840","_cell_guid":"2b24706f-6e08-4f3d-b9e6-019b05e6b7e3","collapsed":true},"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom scipy.sparse import hstack\n\n# Stack all the vectorized data together, trainingsset\nvectorized_data_train = hstack((X_name_train, X_catmain_train, X_catsub1_train, X_catsub2_train, \n                            X_description_train, X_shipping_train, X_condition_train))\n\n# Stack all the vectorized data together, testset\nvectorized_data_test = hstack((X_name_test, X_catmain_test, X_catsub1_test, X_catsub2_test, \n                            X_description_test, X_shipping_test, X_condition_test))\n","execution_count":null,"metadata":{"_uuid":"a5b4a001d4258ddff94996005cd82df83417ea76","_cell_guid":"b9ca87e3-9a32-4f8c-8122-9b46c2189108","collapsed":true},"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\n\nY_train = np.log1p(df_train['price']) #log1p because is nice\n\n# Training the ridge algorithm on the trainingsset\nclf = Ridge(alpha=5.3, fit_intercept=True, normalize=False, \n      copy_X=True, max_iter=None, tol=0.01, solver='auto', random_state=None)\nclf.fit(vectorized_data_train, Y_train)\n\nY_pred_test = clf.predict(vectorized_data_test)","execution_count":null,"metadata":{"_uuid":"ffff2114147934300b7ff6e05c2117936c539421","_cell_guid":"df0dc3f8-1ad0-4ee3-9c9e-0ba302d9d9f6"},"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame(data=df_test[['test_id']])\nsubmission['price'] = np.expm1(Y_pred_test)\nsubmission.to_csv(\"submission_ridge.csv\", index=False)","execution_count":null,"metadata":{"_uuid":"aa1336820f01e474d11d8132bb8ceb4513d18ebc","_cell_guid":"bc786ea5-8d5c-42e7-884a-c095272e0257","collapsed":true},"outputs":[]},{"cell_type":"code","source":"import math\n#A function to calculate Root Mean Squared Logarithmic Error (RMSLE)\ndef rmsle(y, y_pred):\n    assert len(y) == len(y_pred)\n    terms_to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n    return (sum(terms_to_sum) * (1.0/len(y))) ** 0.5\n\n\n#print(rmsle(np.expm1(Y_train_v), np.expm1(Y_pred)))","execution_count":null,"metadata":{"_uuid":"f3e72bbe12f77065edb7bd08d8d36f1996d91bdc","_cell_guid":"afacc796-989a-4f2b-8c41-fe2e6d659fb8","collapsed":true},"outputs":[]},{"cell_type":"markdown","source":"* alpha 5 = 0.45512\n* alpha 5.1 = 0.45513\n* alpha 5.2 = 0.45511\n* alpha 5.3 = 0.45510\n* alpha 5.4 = 0.45512\n* alpha 5.5 = 0.45511\n* alpha 0.5 = 0.461\n* alpha 0.6 = 0.460\n* alpha 15 = 0.458\n* alpha 100 = 0.481","metadata":{"_uuid":"9c6e28d9a2af656d12301919dd00c94bf36d9a00","_cell_guid":"da1f02c0-1850-42f2-9989-8dc1411f0e1f","collapsed":true}}]}