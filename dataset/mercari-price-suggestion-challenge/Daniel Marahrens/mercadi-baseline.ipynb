{"cells":[{"metadata":{"_cell_guid":"3e791291-b2c5-4f73-acc6-a5fe87073730","_uuid":"633c5c42c9143662fbeca904e7c4d393647d40ff"},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re, string\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LinearRegression,ElasticNet,Ridge\nfrom sklearn.model_selection import KFold\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\ntrain = pd.read_table('../input/train.tsv')\ntest = pd.read_table('../input/test.tsv')\ntrain_index = train.index\ntest_index = test.index\n\n# Any results you write to the current directory are saved as output.","outputs":[],"execution_count":10},{"metadata":{},"cell_type":"code","source":"def make_columns(df):\n    if 'price' in df:\n        df['logprice'] = np.log1p(df['price'])\n    df.loc[df['category_name'].isnull(),'category_name'] = 'NA/NA/NA'\n    df['cat0'] = df['category_name'].map(lambda x: x.split('/')[0])\n    df['cat1'] = df['category_name'].map(lambda x: x.split('/')[1])\n    df['cat2'] = df['category_name'].map(lambda x: x.split('/')[2])\n    pattern = re.compile('[^a-zA-Z0-9 ]+', re.UNICODE)\n    df['cleaned_name'] = df['name'].map(lambda x: ' '.join(filter(None,pattern.sub(' ', x.lower()).strip().split(' '))))","outputs":[],"execution_count":11},{"metadata":{"collapsed":true},"cell_type":"code","source":"make_columns(train)\nmake_columns(test)","outputs":[],"execution_count":12},{"metadata":{"collapsed":true},"cell_type":"code","source":"def bayes_average(data_ins,data_oos1,data_oos2,names,alpha):\n    sums = data_ins.groupby(names)['logprice'].sum()\n    counts = data_ins.groupby(names)['logprice'].count()\n    mean = data_ins['logprice'].mean()\n    m = (sums + alpha*mean)/(counts + alpha)\n    mean1 = data_ins.loc[data_ins.groupby(names)['logprice'].transform('count') == 1, 'logprice'].mean()\n    dd1 = data_oos1.join(m, how='left',on=names,rsuffix='_pred')\n    dd1.loc[dd1['logprice_pred'].isnull(),'logprice_pred'] = mean1\n    dd2 = data_oos2.join(m, how='left',on=names,rsuffix='_pred')\n    dd2.loc[dd2['logprice'].isnull(),'logprice'] = mean1\n    return dd1['logprice_pred'],dd2['logprice']","outputs":[],"execution_count":13},{"metadata":{},"cell_type":"code","source":"train1, train2 = np.split(train.sample(frac=1), [int(.7*len(train))])\nnames = ['brand_name','cleaned_name','category_name','cat1','cat2',['category_name','shipping','item_condition_id']]\nfor name in names:\n    alpha = 1\n    y_pred_validate, y_pred_test = bayes_average(train1,train2,test,name,alpha)\n    train2['_'.join(name)+'_pred'] = y_pred_validate\n    test['_'.join(name)+'_pred'] = y_pred_test\nlm = Ridge(alpha=1)\nX_val = train2[['_'.join(x)+'_pred' for x in names]]\ny_val = train2['logprice']\nlm.fit(X_val,y_val)\nX_test = test[['_'.join(x)+'_pred' for x in names]]\ny_pred = lm.predict(X_test)\ny_pred_exp = np.expm1(y_pred)\nsubmission = pd.DataFrame(y_pred_exp, columns=['price'])\nsubmission.to_csv('./submission.csv', index_label='test_id')","outputs":[],"execution_count":14},{"metadata":{"collapsed":true},"cell_type":"code","source":"","outputs":[],"execution_count":null}],"metadata":{"language_info":{"version":"3.6.4","pygments_lexer":"ipython3","mimetype":"text/x-python","file_extension":".py","nbconvert_exporter":"python","codemirror_mode":{"version":3,"name":"ipython"},"name":"python"},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"nbformat":4,"nbformat_minor":1}