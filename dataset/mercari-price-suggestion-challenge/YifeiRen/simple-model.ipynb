{"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"mimetype":"text/x-python","pygments_lexer":"ipython3","version":"3.6.3","name":"python","codemirror_mode":{"version":3,"name":"ipython"},"nbconvert_exporter":"python","file_extension":".py"}},"cells":[{"outputs":[],"metadata":{"_uuid":"41fd3b9c118c23267f85f7803124d95ffab1e6db","_cell_guid":"0ea9fdc2-8f46-4ff4-82eb-d98613fae4cd","collapsed":true},"cell_type":"code","execution_count":null,"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport gensim\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import linear_model\nfrom sklearn import ensemble\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import r2_score, average_precision_score, mean_squared_log_error\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output."},{"outputs":[],"metadata":{"_uuid":"948e53aca7aa3e8b6ad83169a146911b29f7192d","_cell_guid":"648140eb-6e53-4f30-ae3a-3894a82a988c","collapsed":true},"cell_type":"code","execution_count":null,"source":"submit = True"},{"outputs":[],"metadata":{"_uuid":"a20cd84c942c2f115d711d26395826857872dae0","_cell_guid":"9206de84-6785-4a7f-a84d-220ca167a278","collapsed":true},"cell_type":"code","execution_count":null,"source":"df = pd.read_csv(\"../input/train.tsv\", sep='\\t')\nif submit:\n    df_submit = pd.read_csv(\"../input/test.tsv\", sep='\\t')"},{"outputs":[],"metadata":{"_uuid":"6cc9997d8c66a3858a8895bcfeb8146667ec2bc6","_cell_guid":"0724b054-0e32-4139-a398-3cb4acd4633c","collapsed":true},"cell_type":"code","execution_count":null,"source":"df.head(10)"},{"outputs":[],"metadata":{"_uuid":"5694ee5c238a616cdb4eaff5f8b93c8c2288008c","_cell_guid":"4df9b63f-9a66-4a0b-94b5-4b40b7d8cabe","collapsed":true},"cell_type":"code","execution_count":null,"source":"df.info()"},{"outputs":[],"metadata":{"_uuid":"4c57398d70402e3bcc0ce43ec95ccd71f322c9a6","_cell_guid":"146468de-5206-4607-9af4-2507a43c7a83","collapsed":true},"cell_type":"code","execution_count":null,"source":"len(df.brand_name.unique())"},{"outputs":[],"metadata":{"_uuid":"60d6c7376db0964a3e0875f078223c16f8527100","_cell_guid":"7d51d4b5-0280-4cce-9497-d3e8beee01f6","collapsed":true},"cell_type":"code","execution_count":null,"source":"len(df.item_condition_id.unique())"},{"outputs":[],"metadata":{"_uuid":"39192c3921354d23fa2d06dc9ab5c43cadb9f8b0","_cell_guid":"62878003-a244-4bda-951a-6bff0f099d0a","collapsed":true},"cell_type":"code","execution_count":null,"source":"len(df.category_name.unique())"},{"outputs":[],"metadata":{"_uuid":"06aef9f960b8efa1da73c886ad9ca63f9bf96ad8","_cell_guid":"ab9cf453-65f7-416c-a783-4561d0127212","collapsed":true},"cell_type":"code","execution_count":null,"source":"# list top catogries\ndf[\"category_name\"].value_counts().head(20)"},{"outputs":[],"metadata":{"_uuid":"cd2efced0c24625e18eafe8c0e4572530805b920","_cell_guid":"9f97f11e-5c6a-41e4-9fd2-f5d55992784a","collapsed":true},"cell_type":"code","execution_count":null,"source":"# list top brands\ndf[\"brand_name\"].value_counts().head(20)"},{"outputs":[],"metadata":{"_uuid":"7a753d7920dd8d7632bae58b896d1ea0858475e7","_cell_guid":"77b46595-c262-4c97-902a-df94c651c6a5","collapsed":true},"cell_type":"code","execution_count":null,"source":"class Model:\n    def __init__(self, model):\n        self.model = model\n\n    def train(self, X, y):\n        self.model.fit(X, y)\n\n    def predict(self, test_X):\n        return self.model.predict(test_X)"},{"outputs":[],"metadata":{"_uuid":"54341f73368ba2f85e5ded64ce84abad9feead12","_cell_guid":"892a8d15-5690-4861-9092-261c9252649d","collapsed":true},"cell_type":"code","execution_count":null,"source":"# get top limit, mark the rest as other\ndef one_hot_encoding(df, col_name, limit=30):\n    top = df[col_name].isin(df[col_name].value_counts().index[:limit])\n    df_backup = df\n    df.loc[~top, col_name] = \"other\" + col_name\n    return pd.get_dummies(df, columns=[col_name])\n\ndef label_encoding(df, col_name):\n    df[col_name] = df[col_name].astype('category')\n    df[col_name] = df[col_name].cat.codes"},{"outputs":[],"metadata":{"_uuid":"a473b6ff39fa9b133691e346b1d4489b31276469","_cell_guid":"62acf15c-c4f7-4e18-a5c5-74261548657e","collapsed":true},"cell_type":"code","execution_count":null,"source":"# join train and test, then split them, so that they have the same encoding\nprice = df.pop('price')\ndf['is_submit'] = False\nif submit:\n    df_submit['is_submit'] = True\n    combine = pd.concat([df, df_submit],axis = 0)\nelse:\n    combine = df\nlabel_encoding(combine, 'brand_name')\n# label_encoding(combine, 'category_name')"},{"outputs":[],"metadata":{"_uuid":"c3c3a3112462551bbbf21e2aa2d415151523d9dd","_cell_guid":"6935cd14-5d15-4e1f-9f7d-f1e48d7b5785","collapsed":true},"cell_type":"code","execution_count":null,"source":"sentences = []\nfor name in combine[\"category_name\"].values:\n    if type(name) != float:\n        sentences.append(name.split(\"/\"))\nw2v_model = gensim.models.Word2Vec(sentences, size = 3, min_count=1, sg=1) # sg=1 use skip gram\nn = 3\nwv = [[] for i in range(0, n)] # shape 3 * n\nfor name in combine[\"category_name\"].values:\n    # initialize vector values\n    word_vector = [0.0 for i in range(0,n)]\n    if type(name) != float:\n        for split in name.split(\"/\"):\n            # add word vectors\n            word_vector += w2v_model[split]\n    for i in range(0, n):\n        wv[i].append(word_vector[i])\n    \nfor i in range(0, n):\n    col_name = \"cat_name_\" + str(i)\n    combine[col_name] = wv[i]"},{"metadata":{"_uuid":"252954ca44cd5b76cb8f343c21ea02cc65db8684","_cell_guid":"0dd27b7e-f2ca-4ac4-a348-f45d266eee85"},"cell_type":"markdown","source":"__process category and brand name__"},{"outputs":[],"metadata":{"_uuid":"0c2f6be133d096019a3397856ed2158f994b9682","_cell_guid":"7ecd2251-ba1b-4fe7-b445-03fce0fdcd56","collapsed":true},"cell_type":"code","execution_count":null,"source":"if submit:\n    df_submit = combine.loc[combine['is_submit']==True]\n    \ndf = combine.loc[combine['is_submit']==False]"},{"outputs":[],"metadata":{"_uuid":"e939e6eb7fb0458213f1839558cbe0cfce7a9eb4","_cell_guid":"a546fe37-d7b2-4ce4-8a8e-abc727e51c36","collapsed":true},"cell_type":"code","execution_count":null,"source":"# features = ['brand_name', 'shipping', 'item_condition_id', 'category_name']\nfeatures = ['brand_name', 'item_condition_id', 'cat_name_0', 'cat_name_1', 'cat_name_2']\ndef train_and_test(model, df, price, fit):\n    if not submit:\n        # do not split train, test if submit\n        X_train, X_test, y_train, y_test = train_test_split(df[features], price, test_size=0.25)\n    else:\n        X_train, y_train = df[features], price\n    \n    if fit: # for k nearest neghbour\n        model.fit(X_train, y_train)\n    else:\n        model.train(X_train, y_train)\n    if not submit:\n        predictions = model.predict(X_test)\n        print(np.sqrt(mean_squared_log_error(y_test.values, predictions)))"},{"outputs":[],"metadata":{"_uuid":"ca4ad325f45958c1c5d06e23ed9baa297541f700","_cell_guid":"aa877f7c-a81d-4da1-9685-62673a4cecea","collapsed":true},"cell_type":"code","execution_count":null,"source":"# model = Model(ensemble.RandomForestRegressor(n_estimators=10))\nkn_model = KNeighborsRegressor(n_neighbors = 10)\ntrain_and_test(kn_model, df, price, True)"},{"outputs":[],"metadata":{"_uuid":"6b6f04afd9ca679695b6446f749a703ad1319bc6","_cell_guid":"9f4c9677-8921-4ca0-8740-438408cf44ec","collapsed":true},"cell_type":"code","execution_count":null,"source":"if submit:\n    predictions = kn_model.predict(df_submit[features])\n    df_submit['test_id'] = df_submit['test_id'].astype(int)\n    df_submit['price'] = predictions\n    df_submit.to_csv('submit.csv', columns=[\"test_id\", \"price\"], index=False)"},{"metadata":{"_uuid":"5151cdf78eae12bed9f9d4de648605bc19b5ecb7","_cell_guid":"6e94bfc9-5c6e-4be7-93e2-979110ecc787"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"c9c2f270493e74c24643a6fa6b8450eea7f99f83","_cell_guid":"9da417bc-289c-41e8-8710-38259497313a"},"cell_type":"markdown","source":""}],"nbformat":4,"nbformat_minor":1}