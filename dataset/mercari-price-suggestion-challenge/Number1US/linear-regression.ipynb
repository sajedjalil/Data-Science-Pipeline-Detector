{"nbformat_minor":1,"cells":[{"metadata":{"_cell_guid":"d8f10ebd-b92a-4540-bf72-bfbbecd374aa","_uuid":"1d9bbe803d5addd64fb8f6817598d3ec7421cd46"},"source":"Does LInear Regression","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"collapsed":true},"source":"import pprint\nimport numpy as np\n# np.set_printoptions(threshold=np.inf)\n\n# entry[0] = itemid\n# entry[1] = name\n# entry[2] = condition_id\n# entry[3] = category_name\n# entry[4] = brand_name\n# entry[5] = price\n# entry[6] = shipping\n# entry[7] = description\n\n\nclass MercariAnalysis:\n    def __init__(self):\n        self.trainfn = ''\n        self.testfn = ''\n\n        self.data = {}\n\n        self.x_train = []\n        self.y_train = []\n        self.x_test = []\n        self.y_test = []\n\n        self.cpc = {}\n        self.cpbpc = {}\n\n        self.mu = 0\n        self.sigma = 0\n\n        self.predictions = []\n        self.theta = []\n        self.final_predictions = []\n\n    def print_data(self):\n        print('-----------------------')\n        print('-----------------------')\n        print('-----------------------')\n        pprint.pprint(self.x_train)\n        print('-----------------------')\n        print('-----------------------')\n        print('-----------------------')\n        pprint.pprint(self.y_train)\n        print('-----------------------')\n        print('-----------------------')\n        print('-----------------------')\n\n    def build_features(self):\n        # pprint.pprint(self.data['0'])\n        for entry in self.data:\n            feat = [1]\n            entry = self.data[entry]\n            self.y_train.append(float(entry[5]))\n            # build features\n            # brand weight per category\n            cpbpcavg = self.cpbpc[entry[3]][entry[4]]\n            cpcavg = self.cpc[entry[3]][0]\n            cpcstd = self.cpc[entry[3]][1]\n            if cpcstd == 0:\n                brand_weight = 0\n            else:\n                brand_weight = (cpbpcavg - cpcavg) / float(cpcstd)\n            # feat.append(brand_weight)\n\n            # condition\n            # cond = int(entry[2])\n            # feat.append(cond)\n\n            # shipping included or not\n            if entry[6] == 0:\n                shipping = -1\n            else:\n                shipping = 1\n            # feat.append(shipping)\n\n            feat = [1,\n                    brand_weight,\n                    brand_weight ** 2,\n                    brand_weight ** 3,\n                    shipping,\n                    shipping ** 2,\n                    shipping ** 3\n                    ]\n            # append to matrix\n            self.x_train.append(feat)\n\n        self.x_train = np.matrix(self.x_train)\n\n        # mu, sigma = self.normalize_features()\n        # self.mu = mu\n        # self.sigma = sigma\n        print(self.x_train)\n        # self.print_data()\n\n    def normalize_features(self):\n        mu = np.mean(self.x_train, axis=0)\n        sigma = np.std(self.x_train, axis=0)\n        # the slicing prevents normalizing the 1's column\n        # without slicing, it looks like: x = (x - mu) / sigma\n        self.x_train[:, 1:] = (self.x_train[:, 1:] - mu[:, 1:]) / sigma[:, 1:]\n        return mu, sigma\n\n    def normalize_parameters(self, mu, sigma):\n        # the slicing prevents normalizing the 1's column\n        # without slicing, it looks like: x = (x - mu) / sigma\n        self.x_test[:, 1:] = (self.x_test[:, 1:] - mu[:, 1:]) / sigma[:, 1:]\n        self.x_test[:, 0] = 1\n\n    def parse(self):\n        cpc = {}\n        cpbpc = {}\n        first_line = True\n        with open(self.trainfn) as tsv:\n            for line in tsv:\n                # parsing line by line from here\n                if first_line:\n                    first_line = False\n                    continue\n                entry = line.strip().split('\\t')\n                self.data[entry[0]] = entry\n\n                # getting weighted brand averages\n                if entry[3] in cpc:\n                    # cpc[entry[3]] = [cpc[entry[3]][0] + float(entry[5]), cpc[entry[3]][1] + 1]\n                    cpc[entry[3]].append(float(entry[5]))\n                else:\n                    cpc[entry[3]] = [float(entry[5])]\n\n                if entry[3] in cpbpc:\n                    if entry[4] in cpbpc[entry[3]]:\n                        # brand and category exist\n                        cpbpc[entry[3]][entry[4]] = \\\n                            [cpbpc[entry[3]][entry[4]][0] + float(entry[5]), cpbpc[entry[3]][entry[4]][1] + 1]\n                    else:\n                        # category exists, brand does not\n                        cpbpc[entry[3]][entry[4]] = [float(entry[5]), 1]\n                else:\n                    # cat does not exist\n                    cpbpc[entry[3]] = {entry[4]: [float(entry[5]), 1]}\n                # finished with weighted brand averages\n\n                # self.build_features(entry)\n\n            for entry in cpc:\n                mean = np.mean(cpc[entry])\n                std = np.std(cpc[entry])\n                cpc[entry] = [mean, std]\n            # pprint.pprint(cpc)\n            # pprint.pprint(cpbpc)\n            for cat in cpbpc:\n                for brand in cpbpc[cat]:\n                    cpbpc[cat][brand] = cpbpc[cat][brand][0] / float(cpbpc[cat][brand][1])\n            # pprint.pprint(cpbpc)\n            self.cpbpc = cpbpc\n            self.cpc = cpc\n\n    # vectorized gradient descent\n    def gradient_descent(self, alpha, num_iters):\n        x_np = np.matrix(self.x_train)\n        y_np = np.matrix(self.y_train).T\n        m = x_np.shape[0]\n        n = x_np.shape[1]\n        theta = np.zeros((n, 1))\n\n        for k in range(num_iters):\n            # print(k)\n            delta = np.zeros((x_np.shape[1], 1))\n            for i in range(m):\n                # in octave\n                # delta_it = ((X(i,:)*theta)-y(i,:))*X(i,:);\n                delta_it = ((x_np[i, :] * theta) - y_np[i, :]) * x_np[i, :]\n                delta = delta + delta_it.T\n            delta = (1 / float(m)) * delta\n            theta = theta - (alpha * delta)\n\n        # diff = x_np * theta - y_np.T\n        # diff_sq = [d ** 2 for d in diff.T.tolist()[0]]\n        # mse = np.mean(diff_sq)\n        # print(\"MSE for set: \" + str(mse))\n        # print(\"The MSE is crazy high because we're squaring big numbers.\")\n        # print(\"Predicted price for a 2 bedroom 2,000 sq ft home: \")\n        # feat_np = self.normalize_parameters(np.matrix([1, 2000, 2]), mu, sigma)\n        # predicted_value = feat_np * theta\n        # print(predicted_value[0, 0])\n\n        self.theta = theta\n        return theta\n\n    def normal_eqn(self):\n        x_np = np.matrix(self.x_train)\n        y_np = np.matrix(self.y_train)\n        theta = np.linalg.pinv(x_np.T * x_np) * x_np.T * y_np.T\n        print(\"theta from n_e: \")\n        print(theta)\n        self.theta = theta\n\n    def build_test_feat(self, entry):\n        feat = [1]\n        # entry = self.data[entry]\n        if entry[3] in self.cpbpc and entry[4] in self.cpbpc[entry[3]]:\n            cpbpcavg = self.cpbpc[entry[3]][entry[4]]\n            cpcavg = self.cpc[entry[3]][0]\n            cpcstd = self.cpc[entry[3]][1]\n\n            if cpcstd == 0:\n                brand_weight = 0\n            else:\n                brand_weight = (cpbpcavg - cpcavg) / float(cpcstd)\n        else:\n            brand_weight = 0\n        # feat.append(brand_weight)\n        # cond = int(entry[2])\n        # feat.append(cond)\n        if entry[5] == 0:\n            shipping = -1\n        else:\n            shipping = 1\n        # feat.append(shipping)\n        feat = [1,\n                brand_weight,\n                brand_weight ** 2,\n                brand_weight ** 3,\n                shipping,\n                shipping ** 2,\n                shipping ** 3,\n                ]\n        return feat\n\n    def make_predictions(self):\n        first_line = True\n        with open(self.testfn) as tsv:\n            for line in tsv:\n                if first_line:\n                    first_line = False\n                    continue\n                entry = line.strip().split('\\t')\n                self.x_test.append(self.build_test_feat(entry))\n\n        self.x_test = np.matrix(self.x_test)\n        # self.normalize_parameters(self.mu, self.sigma)\n        self.predictions = self.x_test * self.theta\n\n    def run(self, trainfn, testfn):\n        self.trainfn = trainfn\n        self.testfn = testfn\n        self.parse()\n        self.build_features()\n        self.normal_eqn()\n        # self.gradient_descent(.01, 1000)\n        self.make_predictions()\n        # pprint.pprint(self.predictions)\n        self.predictions = self.predictions.tolist()\n        for item in self.predictions:\n            if item[0] < 0:\n                self.final_predictions.append(0)\n            else:\n                self.final_predictions.append(item[0])\n        # pprint.pprint(self.final_predictions)\n\n\nma = MercariAnalysis()\n#ma.run(\"train.tsv\", \"test.tsv\")\nma.run(\"../input/train.tsv\", \"../input/test.tsv\")\n# ma.predictions = list youre looking for","cell_type":"code"},{"metadata":{"_cell_guid":"14a1fa1f-0ede-495a-94f4-44b4c6730230","_uuid":"969db0e4af320178ce69f491b4eea7ec01e6ef5b"},"source":"Okay, now let's read in the test data and generate our submission file.","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"3ac5e29b-192d-4e29-abac-f4eff0a18861","_uuid":"810bfc2601cef34d512ca0adf77ea93a9db18418","collapsed":true},"source":"import pandas as pd\ndf_test = pd.read_csv('../input/test.tsv', sep='\\t')\ndf_test.head()","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"7bfeba4b-a8dd-4fa9-85db-12b0c7d1626e","_uuid":"4b1f965ff8f86293e36380446d455824c44d051d","collapsed":true,"scrolled":true},"source":"df_test['item_description'].fillna('Missing', inplace=True)\ndf_test['price'] = ma.final_predictions\ndf_test.head()","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"75c3c83a-ad1e-4bea-98a9-0c377af0b1c7","_uuid":"f37d62ba2d7ec386847c9f29e3ad3eaa844112a3","collapsed":true},"source":"df_test[['test_id','price']].to_csv('output.csv', index=False)","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"a954b057-3078-4dfb-9f46-71791cf2ed1a","_uuid":"f7bbd557a7cf092688a692b63e7ce051117cd2d9","collapsed":true},"source":"","cell_type":"code"}],"metadata":{"language_info":{"nbconvert_exporter":"python","codemirror_mode":{"version":3,"name":"ipython"},"version":"3.6.3","pygments_lexer":"ipython3","name":"python","file_extension":".py","mimetype":"text/x-python"},"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"}},"nbformat":4}