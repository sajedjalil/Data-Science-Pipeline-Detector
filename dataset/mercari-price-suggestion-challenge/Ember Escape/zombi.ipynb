{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"nbconvert_exporter":"python","version":"3.6.4","pygments_lexer":"ipython3","mimetype":"text/x-python","name":"python","file_extension":".py","codemirror_mode":{"name":"ipython","version":3}}},"nbformat_minor":1,"nbformat":4,"cells":[{"metadata":{"_cell_guid":"0b6a6147-d940-41ee-ad4b-b40c26098274","_uuid":"933b922ce4709f1b03d2b8846f21fe3393cc71f9"},"outputs":[],"execution_count":null,"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\n"},{"metadata":{"collapsed":true,"_cell_guid":"4eace700-4e27-4dd1-9785-1d4622390cdf","_uuid":"caaaa3a6d98a71214fd6cceea3745f3fc4198e5c"},"outputs":[],"execution_count":null,"cell_type":"code","source":"train_X = pd.read_table('../input/train.tsv', engine='c')\ntrain_y = train_X[\"price\"]\ntrain_X.drop(['price'], axis=1,inplace=True)\ntest_X = pd.read_table('../input/test.tsv', engine='c')"},{"metadata":{"_cell_guid":"43a18ef4-8a3a-4e39-8a6a-97d0a7c3c168","_uuid":"0919ab252e8b77b6b79f8f4d21c519934edb24f5"},"outputs":[],"execution_count":null,"cell_type":"code","source":"print(train_X.head())"},{"metadata":{"collapsed":true,"_cell_guid":"0e841eb8-d040-4ffe-9bf7-5539c21e3cc5","_uuid":"c6bca26bf06afe6795cea09a0bac32a96a67bded"},"outputs":[],"execution_count":null,"cell_type":"code","source":"from sklearn.base import TransformerMixin, BaseEstimator, clone\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\nfrom sklearn.preprocessing import FunctionTransformer, LabelEncoder, Imputer, LabelBinarizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn_pandas import DataFrameMapper\nfrom IPython.display import display\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import Ridge"},{"metadata":{"collapsed":true,"_cell_guid":"c8b86e20-78f5-4919-bf33-f63fd5e86a6c","_uuid":"1c8e1b81cd6a9ea06e93b1384b0edc0d30631942"},"outputs":[],"execution_count":null,"cell_type":"code","source":"def cat_split(row):\n    try:\n        text = row\n        txt1, txt2, txt3 = text.split('/')\n        return txt1, txt2, txt3\n    except:\n        return \"none\", \"none\", \"none\""},{"metadata":{"collapsed":true,"_cell_guid":"a869418b-8530-4eee-9519-1f7fd86016a9","_uuid":"3c250ebc4a620c2efa04f69f211df3b7881bde7f"},"outputs":[],"execution_count":null,"cell_type":"code","source":"class SelectColumnsTransfomer(BaseEstimator, TransformerMixin):\n    def __init__(self, columns=[]):\n        self.columns = columns\n\n    def transform(self, X, y=None, **transform_params):\n        print(\"working\")\n        return X[self.columns].values\n\n    def fit(self, X, y=None, **fit_params):\n        print(\"working\")\n        return self\n\nclass To1DArrayTransfomer(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n\n    def transform(self, X, y=None, **transform_params):\n        return X.ravel() #ravel makes the shape (n,) we dont want (n,1)\n\n    def fit(self, X, y=None, **fit_params):\n        return self\n    \nclass CategorySplitingTransformer(BaseEstimator, TransformerMixin):\n    def transform(self, X, y=None, **transform_params):\n        X = pd.DataFrame(X)\n        X[\"cat_1\"], X[\"cat_2\"], X[\"cat_3\"] = zip(*X[0].apply(lambda val: cat_split(val)))\n        ans = []\n        ans.append(X[\"cat_1\"])\n        ans.append(X[\"cat_2\"])\n        ans.append(X[\"cat_3\"])\n        return np.array(ans)\n    \n    def fit(self, X, y=None, **fit_params):\n        return self\n\nclass removeNull(BaseEstimator, TransformerMixin):\n    def __init__(self, val=\"nan\"):\n        self.val = val\n\n    def transform(self, X, y=None, **transform_params):\n        X_df = pd.DataFrame(X)\n        X_df = X_df.fillna(self.val)\n        X = X_df.values\n        return X.ravel()\n\n    def fit(self,X, y=None, **fit_params):\n        return self\n    \nclass parseToDense(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    \n    def transform(self, X, y=None, **transform_params):\n        return X.toarray()\n\n    def fit(self, X, y=None, **fit_params):\n        return self\n\nclass LabelBinarizer_new(TransformerMixin, BaseEstimator):\n    def fit(self, X, y = 0):\n        self.encoder = None\n        return self\n    def transform(self, X, y = 0):\n        if(self.encoder is None):\n            print(\"Initializing encoder\")\n            self.encoder = LabelBinarizer();\n            result = self.encoder.fit_transform(X)\n        else:\n            result = self.encoder.transform(X)\n        return result;\n\nclass select_col(TransformerMixin, BaseEstimator):\n    def __init__(self,n=0):\n        self.n = n\n    def fit(self, X, y = 0):\n        return self\n    def transform(self, X, y = 0):\n        return X[self.n]"},{"metadata":{"collapsed":true,"_cell_guid":"7cb3cf32-1470-4a86-a9fb-cc5ab69d7cef","_uuid":"15f4c59776fde7bae5712cf96ce4c7a7d567d815"},"outputs":[],"execution_count":null,"cell_type":"code","source":"#settings, bump up the numbers for better accuracy\nn_comp_name = 5\nn_comp_description = 10\n#pipelines\nid_pipeline = Pipeline([\n    ('id_select',SelectColumnsTransfomer(['train_id']))\n])\nname_pipeline = Pipeline([\n    ('name_select',SelectColumnsTransfomer(['name'])),\n    ('To1DArrayTransfomer',To1DArrayTransfomer()),\n    ('TfidfVectorizer',TfidfVectorizer(stop_words='english')),\n    ('TruncatedSVD',TruncatedSVD(n_components=n_comp_name, algorithm='arpack'))\n])\nitem_description = Pipeline([\n    ('item_descriptione_select',SelectColumnsTransfomer(['item_description'])),\n    ('rvm_nans',removeNull(\"No decription\")),\n    ('To1DArrayTransfomer',To1DArrayTransfomer()),\n    ('TfidfVectorizer',TfidfVectorizer(stop_words='english')),\n    ('TruncatedSVD',TruncatedSVD(n_components=n_comp_description, algorithm='arpack'))\n])\ncategory_spliting_pipeline = Pipeline([\n    ('category_name_select',SelectColumnsTransfomer(['category_name'])),\n    ('category_spliting',CategorySplitingTransformer()),\n    #('to_labels',LabelBinarizer_new())\n])\ncat_0_pipeline = Pipeline([\n    ('category_spliting_pipeline',category_spliting_pipeline),\n    ('select_col',select_col(n=0)),\n    ('to_labels',LabelBinarizer_new())\n])\ncat_1_pipeline = Pipeline([\n    ('category_spliting_pipeline',category_spliting_pipeline),\n    ('select_col',select_col(n=1)),\n    ('to_labels',LabelBinarizer_new())\n])\ncat_2_pipeline = Pipeline([\n    ('category_spliting_pipeline',category_spliting_pipeline),\n    ('select_col',select_col(n=2)),\n    ('to_labels',LabelBinarizer_new())\n])\nitem_condition_id_pipeline = Pipeline([\n    ('item_condition_id_select',SelectColumnsTransfomer(['item_condition_id'])),\n    ('to_labels',LabelBinarizer_new())\n])\nbrand_name_pipeline = Pipeline([\n    ('brand_name_select',SelectColumnsTransfomer(['brand_name'])),\n    ('rvm_nans',removeNull(\"No brand\")),\n    ('to_labels',LabelBinarizer_new())\n])\nshipping_pipeline = Pipeline([\n    ('shipping_select',SelectColumnsTransfomer(['shipping']))\n])\n\n\nall_feature_pipeline = FeatureUnion([\n    #id_select', id_pipeline),\n    ('name_select', name_pipeline),\n    #('item_descriptione_select', item_description),\n    #('item_condition_id_select', item_condition_id_pipeline),\n    #('cat_0_select', cat_0_pipeline),\n    #('cat_1_select', cat_1_pipeline),\n    #('cat_2_select', cat_2_pipeline),\n    #('brand_name_select', brand_name_pipeline),\n    #('shipping_select', shipping_pipeline),\n    \n])\nfinal_pipeline = Pipeline([\n    ('all_feature_pipeline',all_feature_pipeline),\n    ('RandomForestRegressor', RandomForestRegressor(n_jobs=-1,min_samples_leaf=3,n_estimators=200))\n])"},{"metadata":{"_cell_guid":"c3cfd13b-7820-450f-9adf-5bce1ce69ddf","_uuid":"589a432a96c14bef5ea0008e1714d475250a9e91"},"outputs":[],"execution_count":null,"cell_type":"code","source":"#all_feature_pipeline.fit(train_X,train_y)\n#a1 = all_feature_pipeline.transform(train_X,train_y)\n# print(\"start fit\")\n# final_pipeline.fit(train_X,train_y)\n# print(\"end fit, start predict\")\n# a1 = final_pipeline.predict(test_X)\nprint(\"1\")\ndata_X = all_feature_pipeline.fit_transform(train_X)\nprint(\"2\")\ndata_test_X = all_feature_pipeline.transform(test_X)\nprint(\"3\")\nmodl = Ridge(solver = \"lsqr\", fit_intercept=False)\nprint(\"4\")\nmodl.fit(data_X,train_y)\nprint(\"5\")\nans = modl.predict(data_test_X)\nprint(\"6\")"},{"metadata":{"_cell_guid":"62410597-993a-4e94-a13f-b1faab918f15","_uuid":"768429cbfb12448a9bba2a7d8a583c4df1bd7a2c"},"outputs":[],"execution_count":null,"cell_type":"code","source":"print(ans)"},{"metadata":{"collapsed":true,"_cell_guid":"2a680d51-cd8f-4c5f-b2aa-b0a070d576a6","_uuid":"f44bfca3afc22af2f65c15fe77980f7c97fff5f8"},"outputs":[],"execution_count":null,"cell_type":"code","source":"ans1 = pd.DataFrame(ans)"},{"metadata":{"collapsed":true,"_cell_guid":"1eb89c57-d3da-4173-8609-27d197f97b22","_uuid":"bc801bc927b749a1dd7ac0fb4f1dab935fe17f91"},"outputs":[],"execution_count":null,"cell_type":"code","source":"ans1.columns = ['price']\nans1[\"test_id\"] = test_X[\"test_id\"]\nans1[\"price\"] = ans1[\"price\"]+1"},{"metadata":{"collapsed":true,"_cell_guid":"0a1998ac-eda1-44cd-9d26-e78e21a3bbc9","_uuid":"8bfedcd0a27d55a031f07346fdd658451b5dd9f0"},"outputs":[],"execution_count":null,"cell_type":"code","source":"\nans1.to_csv(\"output.csv\",index=False)"}]}