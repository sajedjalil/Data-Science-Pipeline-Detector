{"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","name":"python","version":"3.6.3","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py"}},"cells":[{"metadata":{"_cell_guid":"390315bc-fecf-489c-bc29-407fbe668c0d","_uuid":"ab034cbc2149bacffa3bd425178cb94d815fe406"},"cell_type":"markdown","source":"Here we explore the text normalization data with a primary focus on dicks.  We demonstrate that you can never have enough dicks.  Over 30 dicks are erected in this kegel notebook.  The strength and capability of a dick is truly impressive because they are solid, inflexible, and fast to finish (look ups).  We will use dicks to find the g-spot (g for google).  Some dicks are very long -- over 10 million in length!  Whether you like long or short dicks... this notebook is for you! \n\n1. (1)  **READ THE TRAIN SHIT FILE**\n1. (2)  **FIGURE OUT WHAT'S DIFFERENT**\n1. (3)  **LOOK AT NOT SAME SHIT**\n1. (4)  **FIGURE OUT WHICH SHIT IS THE SAME**\n1. (5)  **BUILD SOME DICKS**\n1. (6)  **FUCKING MISSING SHIT**\n1. (7)  **LOOK AT THE FUCKING MISSING SHIT**\n1. (8)  **BUILD SOME MORE DICKS**\n1. (9)  **FIGURE OUT WHERE NOT SAME SHIT HAS DIFFERENT SHIT**\n1. (10)  **LOOK AT THAT SHIT**\n1. (11)  **LOOK AT THAT SHIT AGAIN BUT DIFFERENT**\n1. (12)  **FIND WHERE THE AFTER PARTY HAS CAPITAL LETTERS AND FIGURE OUT WTF**\n\nUPDATE! \n1. (13)  **OMG KEGEL, G-SPOT. WT\n\n\n1. (13)  **THROW AN ERROR**"},{"metadata":{"_cell_guid":"371661d6-7455-40a6-b68e-d51dc4ce2b78","_uuid":"bd59c14c0d386e130c290a754e7174ea058f4b56"},"cell_type":"code","execution_count":null,"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","outputs":[]},{"metadata":{"_cell_guid":"e6c0d68f-b16f-498e-b784-e4d9a637a187","_uuid":"1b313b46af750b85f20c45c9359796681c4b81e1","collapsed":true},"cell_type":"code","execution_count":null,"source":"import re, string, collections\nfrom fuzzywuzzy import fuzz\nfrom tqdm import tqdm\nfrom IPython.display import display\n","outputs":[]},{"metadata":{"_cell_guid":"57dbd9e7-507c-4952-9552-c5fbb0a6ad23","_uuid":"0d0ad8fbf2f0cc34e3082835cdfe90c8138311ec"},"cell_type":"markdown","source":"1. **READ THE TRAIN SHIT FILE**"},{"metadata":{"_cell_guid":"20df103c-9ad0-4361-a1db-e99eb4e54f95","_uuid":"005127249e918318080fb183545ead30b0f3fa89"},"cell_type":"code","execution_count":null,"source":"# Read en_train.csv  file.\ntest_df = pd.read_csv(filepath_or_buffer=\"../input/en_test.csv\", encoding=\"utf-8\", dtype={'class':'category'})\ntrain_df = pd.read_csv(filepath_or_buffer=\"../input/en_train.csv\", encoding=\"utf-8\", dtype={'class':'category'})\ntrain_df.head()\n\n","outputs":[]},{"metadata":{"_cell_guid":"c9a2e89b-307e-4d4e-90e1-4065d4ba2eeb","_uuid":"206b04817343b36877db2eff0cda7adff8cd6017","collapsed":true},"cell_type":"code","execution_count":null,"source":"test_before = test_df['before'].tolist()\ntrain_after = train_df['after'].tolist()\ntrain_class = train_df['class'].tolist()\ntest_idx = test_df.index.tolist()\ntrain_before = train_df['before'].tolist()\ntrain_idx = train_df.index.tolist()\n\ntest_before_DICK = dict(zip(test_idx, test_before))\ntrain_idx_before_DICK = dict(zip(train_idx, train_before))\ntrain_idx_after_DICK = dict(zip(train_idx, train_after))\n\n\ntest_before_str_only = [(x,y) for x,y in zip(test_idx, test_before) if type(y) == type(str())]\ntest_before_str_only_idxs = [x[0] for x in test_before_str_only]\n\ntrain_before_str_only = [(x,y) for x,y in zip(train_idx, train_before) if type(y) == type(str())]\ntrain_before_str_only_idxs = [x[0] for x in train_before_str_only]","outputs":[]},{"metadata":{"_cell_guid":"34dd6db5-9f7b-43d1-a2b9-5cb6a161e108","_uuid":"2cdb0f65c6f0df686a5fdcf5775433083d32c59d"},"cell_type":"code","execution_count":null,"source":"#display(train_df[pd.isnull(train_df['after'])])\n#display(test_df[pd.isnull(test_df['before'])])\ntrb_nan_idx = train_df[pd.isnull(train_df['before'])].index.tolist()\n\ntrain_df.loc[trb_nan_idx, 'before'] = ' '\ntrain_df.loc[trb_nan_idx, 'after'] = ' ' \n\n#train_df['before'] = train_df['before'].fillna(' ')\n#train_df['after'] = train_df['after'].fillna(' ')\ntest_df['before'] = test_df['before'].fillna(' ')\n\ndisplay(train_df[pd.isnull(train_df['before'])])","outputs":[]},{"metadata":{"_cell_guid":"761690ab-883c-402e-89c0-a0150a3a3df9","_uuid":"ea2a785eb9684ffbde3e8f3e6d304fa17aee330d"},"cell_type":"markdown","source":"(2)  **FIGURE OUT WHAT'S DIFFERENT**"},{"metadata":{"_cell_guid":"db244dd9-f295-422a-853f-75c248991213","_uuid":"1e6031be57e0ac7cfaf3262a1a52f92f59d3c6aa"},"cell_type":"code","execution_count":null,"source":"#np.array(train_df['before'])\narr_after = np.array(train_df['after'])\n\nidx_not_same = list()\nfor each_after, each_beforeiter in zip(tqdm(arr_after), train_df['before'].iteritems()):\n    if each_after != each_beforeiter[1]:\n        idx_not_same.append(each_beforeiter[0])\n\nprint(str(len(idx_not_same)) + ' NOT SAME out of ' + str(len(train_df)) +' total (' + str(len(idx_not_same) / len(train_df)) + ' %)')","outputs":[]},{"metadata":{"_cell_guid":"d8eb37cb-41bd-4c9e-be4f-6dbca450f11e","_uuid":"5d6266f3323e142151d0e3756a2b7d261b3d1681"},"cell_type":"code","execution_count":null,"source":"#thing = \ncounter_notsame_class = collections.Counter(np.array(train_df.loc[idx_not_same, 'class']))\ndisplay(pd.DataFrame([(i, str(counter_notsame_class[i] / len(idx_not_same) * 100.0)[:5] + ' %') for i, count in counter_notsame_class.most_common()], columns=['classy', '%_of_notsame']))\n#tkeys, tvalues = zip(*thing.items())\n\ndisplay(train_df.loc[idx_not_same[:10]])","outputs":[]},{"metadata":{"_cell_guid":"bd3dff7f-86cf-4c21-92e3-38d565592378","_uuid":"5aeb71d19704b14e80f8ba1d5fbd971ac6c9c074"},"cell_type":"markdown","source":"(3)  **LOOK AT NOT SAME SHIT**"},{"metadata":{"_cell_guid":"c6dda98d-8d15-441f-ab2d-7d05ae74fed6","_uuid":"56c21ff84e255d578c5e1ee2a41221c86c332cb9"},"cell_type":"code","execution_count":null,"source":"for each_subdf in train_df.loc[idx_not_same].groupby(by=['class']):\n    display(each_subdf[1][:10])","outputs":[]},{"metadata":{"_cell_guid":"539ebd2c-f596-4c73-abe8-bfc09b0ccbc3","_uuid":"c733a19d0e5f6544c36db036543e5524de5308fd"},"cell_type":"markdown","source":"(4)  **FIGURE OUT WHICH SHIT IS THE SAME**"},{"metadata":{"_cell_guid":"b1b63844-9c37-4421-9389-cab16d2bf279","_uuid":"ef9931e3ea586878bc04928f90b97756179f900b"},"cell_type":"code","execution_count":null,"source":"idx_are_same = set(train_df.index) - set(idx_not_same)\nprint(str(len(idx_are_same)) + ' ARE SAME out of ' + str(len(train_df)) +' total (' + str(len(idx_are_same) / len(train_df)) + ' %)')","outputs":[]},{"metadata":{"_cell_guid":"52538678-2dc9-4317-8422-177d8b8a8fcc","_uuid":"3a3e05487117e9b474fa6b382791ee98300b9a57"},"cell_type":"markdown","source":"(5)  **BUILD SOME DICKS**"},{"metadata":{"_cell_guid":"4085412d-8ad7-4569-ab7a-9a83553ff9f0","_uuid":"f95a18cc2b9cb9c093397c234e9b8013d2323971"},"cell_type":"code","execution_count":null,"source":"# find rows where before is the same but after is different\n# find rows where after is the same but before is different\n# and class is different?\n#build a before dick\ntrain_df_idx = np.array(train_df.index)\narr_before = np.array(train_df['before'])\nbefore_DICK = dict()\nfor each_idx, each_before in zip(tqdm(train_df_idx), arr_before):\n    if each_before in before_DICK:\n        before_DICK[each_before].append(each_idx)\n    else:\n        before_DICK[each_before] = [each_idx]\n            \n","outputs":[]},{"metadata":{"_cell_guid":"2bf34f02-b1aa-40a0-ad34-e333ff3f8c20","_uuid":"ec6826e893ff26ab9cad1b085e584a6e1f4093a9"},"cell_type":"code","execution_count":null,"source":"# build a after dick\nafter_DICK = dict()\nfor each_idx, each_after in zip(tqdm(train_df_idx), arr_after):\n    if each_after in after_DICK:\n        after_DICK[each_after].append(each_idx)\n    else:\n        after_DICK[each_after] = [each_idx]","outputs":[]},{"metadata":{"_cell_guid":"179d017d-eaed-4deb-ab42-9635c01fbe50","_uuid":"b6f97bf6b0206f1109bb365b3f56a6bf55fb8f99"},"cell_type":"code","execution_count":null,"source":"# build a classy dick\narr_class = np.array(train_df['class'])\nclassy_DICK = dict()\nfor each_idx, each_class in zip(tqdm(train_df_idx), arr_class):\n    if each_class in classy_DICK:\n        classy_DICK[each_class].append(each_idx)\n    else:\n        classy_DICK[each_class] = [each_idx]","outputs":[]},{"metadata":{"_cell_guid":"f8faf3fa-80cc-4f0a-bf05-1ec66fff3e6f","_uuid":"5952c72a006ec0346dccdf738cdef07a9ea640ed"},"cell_type":"markdown","source":"**DICKS ERECTION**"},{"metadata":{"_cell_guid":"ab221cd3-380f-4d7b-bd88-b57b27c35c81","_uuid":"715704daece6aaccee1d3d5ddabf1c82a1f5147a"},"cell_type":"code","execution_count":null,"source":"train_class = train_df['class'].tolist()\ntr_sentID = train_df['sentence_id'].tolist()\nt_sentID = test_df['sentence_id'].tolist()\n\nbefore_DICK = dict()\nafter_DICK = dict()\nclassy_DICK = dict()\ntr_sentID_DICK = dict()\n#t_sentID_DICK = dict()\n\ntr_ba_diff = list()\n\nfor each_idx, each_before, each_after, each_class, each_tr_sID in zip(tqdm(train_idx), train_before, train_after, train_class, tr_sentID):\n    if each_before != each_after:\n        tr_ba_diff.append(each_idx)\n        \n    if each_before in before_DICK:\n        before_DICK[each_before].append(each_idx)\n    else:\n        before_DICK[each_before] = [each_idx]\n            \n    if each_after in after_DICK:\n        after_DICK[each_after].append(each_idx)\n    else:\n        after_DICK[each_after] = [each_idx]\n\n    if each_class in classy_DICK:\n        classy_DICK[each_class].append(each_idx)\n    else:\n        classy_DICK[each_class] = [each_idx] \n    \n    if each_tr_sID in tr_sentID_DICK:\n        tr_sentID_DICK[each_tr_sID].append(each_idx)\n    else:\n        tr_sentID_DICK[each_tr_sID] = [each_idx]\nprint('i done')        ","outputs":[]},{"metadata":{"_cell_guid":"16d78bda-6def-4cda-9006-77d2a800d8bc","_uuid":"9f432ba36faf37c084e9ebe04268a4692126ec66"},"cell_type":"markdown","source":"(6)  **FUCKING MISSING SHIT**"},{"metadata":{"_cell_guid":"0c7be710-bbfd-4fa0-9229-d1f7a9f4ebcf","_uuid":"6b0e4422882e4225f0aff6a24c5943395f154c6e"},"cell_type":"code","execution_count":null,"source":"print(len(before_DICK))\nprint(len(after_DICK))\nprint(len(classy_DICK))\n\n# fucking missing shit\nafter_dick_nan_idxs = after_DICK.pop(np.nan, None)\nbefore_dick_nan_idxs = before_DICK.pop(np.nan, None)\n","outputs":[]},{"metadata":{"_cell_guid":"be6897d8-94b6-43ca-9751-416cb524e888","_uuid":"b977cd537a67ca3e3258e5a9e7e57be5e423d857"},"cell_type":"markdown","source":"(7)  **LOOK AT THE FUCKING MISSING SHIT... LOOK AT IT!!!**"},{"metadata":{"_cell_guid":"57922e2e-8210-42cb-a31d-f773bae8c89e","_uuid":"166895d6ba3cbee962d84624b5cd70c955dd0088"},"cell_type":"code","execution_count":null,"source":"for key,val in classy_DICK.items():\n    #classy_letters = classy_DICK.get('LETTERS')\n    display(train_df.loc[set(val).intersection(before_dick_nan_idxs)])","outputs":[]},{"metadata":{"_cell_guid":"6a766822-6536-4111-a6c2-9c39b803bdf0","_uuid":"674b819332efff5b0a84197728df0578a9e3f408"},"cell_type":"code","execution_count":null,"source":"for key,val in classy_DICK.items():\n    #classy_letters = classy_DICK.get('LETTERS')\n    display(train_df.loc[set(val).intersection(after_dick_nan_idxs)])","outputs":[]},{"metadata":{"_cell_guid":"113bfb63-97a0-429c-8529-a4228f633ed2","_uuid":"94909b9af5a7dcc814a85c8601d9f709bf323b17"},"cell_type":"markdown","source":"(8)  **BUILD SOME MORE DICKS**"},{"metadata":{"_cell_guid":"0dd7faba-f7fc-4d46-a4bf-36894a87f588","_uuid":"232b21b01660135957b90807321d1340fbd4e34c","collapsed":true},"cell_type":"code","execution_count":null,"source":"# build index to after dick\nidx_after_DICK = dict(zip(np.array(train_df.index), np.array(train_df['after'])))","outputs":[]},{"metadata":{"_cell_guid":"8b758e40-ae0a-49ca-8eef-971dc6666c2e","_uuid":"727ef6da1609dac9b8c89b5d2a1524e034410787"},"cell_type":"markdown","source":"(9)  **FIGURE OUT WHERE NOT SAME SHIT HAS DIFFERENT SHIT**"},{"metadata":{"_cell_guid":"47c2c883-c832-40e3-9fc8-b7fb9b590169","_uuid":"e1f56f702159160f4ee04c498de8a8b44d3c54c0"},"cell_type":"code","execution_count":null,"source":"# find rows where before is the same but after is different\n# find rows where after is the same but before is different\n# and class is different?\nbefore_with_different_after = list()\nmost_common_after_of_before = list()\nwith tqdm(total=len(before_DICK)) as pbar:\n    for key, value in before_DICK.items():\n        #unique_afters_of_before = train_df.loc[value, 'after'].unique() #slow as shit\n        get_that_shit = [idx_after_DICK.get(x) for x in value]\n        cafters, ccounts = zip(*collections.Counter(get_that_shit).most_common())\n        most_common_after_of_before.append((key, cafters[0])) #before, after\n        unique_afters_of_before = set(get_that_shit)\n        pbar.update()\n        if len(unique_afters_of_before) != 1:\n            before_with_different_after.append((key, value, unique_afters_of_before))\n\nprint(len(before_with_different_after))","outputs":[]},{"metadata":{"_cell_guid":"5f609248-582e-40d6-8bbb-b0867f0bc87a","_uuid":"97b0e54387b1a549b1761f5305f1bd7e7b87e5e5"},"cell_type":"code","execution_count":null,"source":"# build me a quick DICK\n\nprint(len(most_common_after_of_before))","outputs":[]},{"metadata":{"_cell_guid":"989abf3d-7478-4036-8432-2e241b51efe5","_uuid":"d14a8516f06db390ace62783dd0812c8b7ab0bb3"},"cell_type":"markdown","source":"(10)  **LOOK AT THAT SHIT**"},{"metadata":{"_cell_guid":"bf7d0872-741d-4227-9771-1e387409ed99","_uuid":"d9ce4ae5a197fa4d487e7b1cc77bc4a0ada20673"},"cell_type":"code","execution_count":null,"source":"pd.DataFrame(before_with_different_after[:10])","outputs":[]},{"metadata":{"_cell_guid":"41715e39-3ad4-47d0-8631-baa6255f00b5","_uuid":"adf295f6ac0db7c8bf5bc13c124e3b28bcb12d06"},"cell_type":"code","execution_count":null,"source":"the_before_diff_after, some_idxs, _ = zip(*before_with_different_after)\nlist_after_idxs_not_matching = list()\nfor each_before, each_listidxs in zip(tqdm(the_before_diff_after), some_idxs):\n    after_idxs_not_matching = list()\n    seen_afters = set()\n    for each_after in each_listidxs:\n        some_after = idx_after_DICK.get(each_after)\n        if (each_before != some_after) & (some_after not in seen_afters):\n            seen_afters.add(some_after)\n            after_idxs_not_matching.append(each_after)\n    list_after_idxs_not_matching.append(after_idxs_not_matching)","outputs":[]},{"metadata":{"_cell_guid":"f88a0ac3-c8bf-49fc-90e9-1ab6316a6f04","_uuid":"60468a0a9d56a700b80602705812d36165fb7fef"},"cell_type":"markdown","source":"(11)  **LOOK AT THAT SHIT AGAIN BUT DIFFERENT**"},{"metadata":{"_cell_guid":"06b58660-91ab-4910-b7bf-931a5d239ef0","_uuid":"7fb042a87714b108f7e19f3a1297faa4f0b6f09c"},"cell_type":"code","execution_count":null,"source":"print(sum([len(x) for x in list_after_idxs_not_matching]))\nkeep_min = [min(x) for x in list_after_idxs_not_matching]\n#display(train_df.loc[keep_min[:10]])\n\nfor key,val in classy_DICK.items():\n    #classy_letters = classy_DICK.get('LETTERS')\n    display(train_df.loc[set(val).intersection(keep_min)].sort_values(by=['before','after']))","outputs":[]},{"metadata":{"_cell_guid":"9922b29e-37eb-49af-90d3-8d49a7e828c3","_uuid":"e8c67a97e17b4df58430e3cf6e2db89d0dfbe0eb"},"cell_type":"markdown","source":"(12)  **FIND WHERE THE AFTER PARTY HAS CAPITAL LETTERS AND FIGURE OUT WTF**"},{"metadata":{"_cell_guid":"4f405946-a55e-4cfe-bde4-98df9a79d7ef","_uuid":"7ff10dc8f628f0933a62aa289d5f68720f2ece86"},"cell_type":"code","execution_count":null,"source":"mixedcase_after = list()\nallcaps_after = list()\nwith tqdm(total=len(after_DICK)) as pbar:\n    for key, value in after_DICK.items():\n        if key.isupper():\n            allcaps_after.append((key, value))\n        elif key.lower() != key:\n            mixedcase_after.append((key, value))\n        pbar.update()\nprint(len(allcaps_after))\nprint(len(mixedcase_after))        ","outputs":[]},{"metadata":{"_cell_guid":"79ff4d6b-39af-42ac-8210-270f46d1380d","_uuid":"1d30d598105ea06f1315efd59634d10d91711432"},"cell_type":"code","execution_count":null,"source":"test_df = pd.read_csv(filepath_or_buffer=\"../input/en_test.csv\", encoding=\"utf-8\", dtype={'class':'category'})\n\nUNI_RANGES = [('CJK Ideographs Extension A', 13312, 19893, '3400', '4DB5'),\n ('CJK Ideographs', 19968, 40869, '4E00', '9FA5'),\n ('Hangul Syllables', 44032, 55203, 'AC00', 'D7A3'),\n ('Non-Private Use High Surrogates', 55296, 56191, 'D800', 'DB7F'),\n ('Private Use High Surrogates', 56192, 56319, 'DB80', 'DBFF'),\n ('Low Surrogates', 56320, 57343, 'DC00', 'DFFF'),\n ('The Private Use Area', 57344, 63743, 'E000', 'F8FF')]\nNAMED_RANGE = [(13312, 19893), (19968, 40869), (44032, 55203), (55296, 56191), (56192, 56319), (56320, 57343), (57344, 63743)]\n\n\ntest_before = test_df['before'].tolist()\ntrain_after = train_df['after'].tolist()\ntest_idx = test_df.index.tolist()\ntrain_before = train_df['before'].tolist()\ntrain_idx = train_df.index.tolist()\n\n\ntest_before_DICK = dict(zip(test_idx, test_before))\ntrain_idx_before_DICK = dict(zip(train_idx, train_before))\ntrain_idx_after_DICK = dict(zip(train_idx, train_after))\n\n\ntest_before_str_only = [(x,y) for x,y in zip(test_idx, test_before) if type(y) == type(str())]\ntest_before_str_only_idxs = [x[0] for x in test_before_str_only]\n\ntrain_before_str_only = [(x,y) for x,y in zip(train_idx, train_before) if type(y) == type(str())]\ntrain_before_str_only_idxs = [x[0] for x in train_before_str_only]\n\nprint(len(train_before_str_only))\nprint(len(test_before_str_only))\n\n\ntrain_crazy = ''.join([x[1] for x in tqdm(train_before_str_only)])\ntest_crazy = ''.join([x[1] for x in tqdm(test_before_str_only)])\ntrain_crazyset = set(train_crazy)\ntest_crazyset = set(test_crazy)\nprint(str(len(train_crazyset)))\nprint(str(len(test_crazyset)))\n\n\ntrain_not_in_test = sorted(list(train_crazyset - test_crazyset))\ncrazy_ords = [ord(x) for x in train_not_in_test]\n\nweird_ords = [y for y in crazy_ords if not any([True if (y <= x[1]) and (y >= x[0]) else False for x in NAMED_RANGE])]\n\nthingy = pd.DataFrame(weird_ords)\nthingy.plot()\n#display(pd.DataFrame(np.array(train_not_in_test[:1000]).reshape((50, 20))))\n\n\nlen(weird_ords)\ndisplay(pd.DataFrame(np.array([chr(x) for x in weird_ords + [34]*3]).reshape((20, 20))))\n\n\nt_alpha = [x for x in tqdm(test_before_str_only) if x[1].isalpha()]\nt_alnum = [x for x in tqdm(test_before_str_only) if x[1].isalnum() and not x[1].isalpha()]\nt_upper = [x for x in tqdm(test_before_str_only) if x[1].isupper()]\nt_lower = [x for x in tqdm(test_before_str_only) if x[1].islower()]\nt_numer = [x for x in tqdm(test_before_str_only) if x[1].isnumeric()]\nt_space_all = [x for x in tqdm(test_before_str_only) if x[1].isspace()]\nt_space_any = [x for x in tqdm(test_before_str_only) if any([y.isspace() for y in x[1]])]\nt_punct_all = [x for x in tqdm(test_before_str_only) if all([y in string.punctuation for y in x[1]])]\n#t_punct_any = [x for x in tqdm(test_before_str_only) if any([y in string.punctuation for y in x[1]])]\nt_punct_any = [x for x in tqdm(test_before_str_only) if (any([y in string.punctuation for y in x[1]]) and len(x[1]) != 1)]\n\n\ntr_alpha = [x for x in tqdm(train_before_str_only) if x[1].isalpha()]\ntr_alnum = [x for x in tqdm(train_before_str_only) if x[1].isalnum() and not x[1].isalpha()]\ntr_upper = [x for x in tqdm(train_before_str_only) if x[1].isupper()]\ntr_lower = [x for x in tqdm(train_before_str_only) if x[1].islower()]\ntr_numer = [x for x in tqdm(train_before_str_only) if x[1].isnumeric()]\ntr_space_all = [x for x in tqdm(train_before_str_only) if x[1].isspace()]\ntr_space_any = [x for x in tqdm(train_before_str_only) if any([y.isspace() for y in x[1]])]\ntr_punct_all = [x for x in tqdm(train_before_str_only) if all([y in string.punctuation for y in x[1]])]\ntr_punct_any = [x for x in tqdm(train_before_str_only) if (any([y in string.punctuation for y in x[1]]) and len(x[1]) != 1)]\n\n# FOR TEST\nthing = [len(x) for x in [t_alpha, t_alnum, t_upper, t_lower, t_numer, t_space_all, t_space_any, t_punct_all, t_punct_any]]\nthing2 = list(zip(['t_alpha', 't_alnum', 't_upper', 't_lower', 't_numer', 't_space_all', 't_space_any', 't_punct_all', 't_punct_any'], thing))\ndisplay(pd.DataFrame(thing2, columns=['type', 'howmany']))\n\n\n# FOR TRAIN\nthing = [len(x) for x in [tr_alpha, tr_alnum, tr_upper, tr_lower, tr_numer, tr_space_all, tr_space_any, tr_punct_all, tr_punct_any]]\nthing2 = list(zip(['tr_alpha', 'tr_alnum', 'tr_upper', 'tr_lower', 'tr_numer', 'tr_space_all', 'tr_space_any', 'tr_punct_all', 'tr_punct_any'], thing))\ndisplay(pd.DataFrame(thing2, columns=['type', 'howmany']))\n\n\nthing = [[y[1] for y in x[:30]] for x in [t_alpha, t_alnum, t_upper, t_lower, t_numer, t_space_all, t_space_any, t_punct_all, t_punct_any]]\nthing2 = pd.DataFrame(thing).T\nthing2.columns = ['t_alpha', 't_alnum', 't_upper', 't_lower', 't_numer', 't_space_all', 't_space_any', 't_punct_all', 't_punct_any']\ndisplay(thing2)\nprint(sum(thing))\nprint(len(train_before_str_only))\nprint(sum(thing))\nprint(len(test_before_str_only))\ntr_punct_any = [x for x in tqdm(train_before_str_only) if (any([y in string.punctuation for y in x[1]]) and len(x[1]) != 1)]\n\n\nidentified_test_idxs = [y[0] for x in [t_alpha, t_alnum, t_upper, t_lower, t_numer, t_space_all, t_space_any, t_punct_all, t_punct_any] for y in x ]\nunique_ID_test_idxs = set(identified_test_idxs)\nprint(len(unique_ID_test_idxs))\n\nmystery_test_idxs = set(test_before_str_only_idxs) - unique_ID_test_idxs\nprint(len(mystery_test_idxs))\n\nmystery_test_before = [test_before_DICK[x] for x in list(mystery_test_idxs)]\nunique_mystery_test_before = list(set(mystery_test_before))\nprint(len(unique_mystery_test_before))\ndisplay(pd.DataFrame(unique_mystery_test_before))\n#display(pd.DataFrame(np.array(unique_mystery_test_before[:240]).reshape((30, 8))))\n\n# FOR TEST\n#thing = [(x,y) for x,y in t_alpha if not all([z in string.ascii_letters for z in y])]\nthing = [y for x,y in t_alpha if not all([z in string.ascii_letters for z in y])]\nprint(len(thing))\nthing2 = list(set(thing))\nprint(len(thing2))\nthing3 = [x for x in thing2 if len(x) == 1]\nprint(len(thing3))\n\n#display(pd.DataFrame(np.array(thing2[:300]).reshape((30, 10))))\ndisplay(pd.DataFrame(np.array(thing3[:400]).reshape((20, 20))))\n\nthing4 = pd.DataFrame(sorted([ord(x) for x in thing3]))\n\nthing4.hist()\nthing4.plot()\n\n\n\n#FOR TRAIN\nthing = [y for x,y in tr_alpha if not all([z in string.ascii_letters for z in y])]\nprint(len(thing))\nthing2 = list(set(thing))\nprint(len(thing2))\nthing3 = [x for x in thing2 if len(x) == 1]\nprint(len(thing3))\n\nthing_b_a = [(y, train_idx_after_DICK[x]) for x,y in tr_alpha if (not all([z in string.ascii_letters for z in y])) and (len(y) == 1)]\nthing_b_a_unique = list(set(thing_b_a))\n#thing_b_a = list(zip(thing, thing_after))\n#display(pd.DataFrame(np.array(thing2[:300]).reshape((30, 10))))\nthingcols = ['b','a'] * 10\ndisplay(pd.DataFrame(np.array(thing_b_a_unique[:200]).reshape((20, 20)), columns=thingcols))\n\nthing4 = pd.DataFrame(sorted([ord(x) for x in thing3]))\nthing4.hist()\nthing4.plot()\n\n\n#np.array(train_df['before'])\narr_after = np.array(train_df['after'])\n\nidx_not_same = list()\nfor each_after, each_beforeiter in zip(tqdm(arr_after), train_df['before'].iteritems()):\n    if each_after != each_beforeiter[1]:\n        idx_not_same.append(each_beforeiter[0])\nprint(str(len(idx_not_same)) + ' NOT SAME out of ' + str(len(train_df)) +' total (' + str(len(idx_not_same) / len(train_df)) + ' %)')\n\nidx_are_same = set(train_df.index) - set(idx_not_same)\nprint(str(len(idx_are_same)) + ' ARE SAME out of ' + str(len(train_df)) +' total (' + str(len(idx_are_same) / len(train_df)) + ' %)')\n\n","outputs":[]},{"metadata":{"_cell_guid":"07c6853c-43f8-4d4d-bd2b-d374cbf0d6a8","_uuid":"5108e3c8dc2d0c828be76e4c0fbbdf66bae4478a","collapsed":true},"cell_type":"code","execution_count":null,"source":"# what is the most common \"type\" of before giving multiple afters? \n#after_wards, after_wards_n = zip(*[(y, len(x.split(' '))) for x in tqdm(train_after) for y in x.split(' ')])\n#after_wards = [y for i in tqdm(range(len(train_after))) for y in train_after[i].split(' ')]\nafter_wards = set()\nafter_wards_n = list()\nfor i in tqdm(range(len(train_after))):\n    spilt = train_after[i].split(' ')\n    after_wards_n.append(len(spilt))\n    after_wards.update(spilt)\n    #for x in spilt:\n        #after_wards.append(x)\nafter_wards = list(after_wards)\nprint(len(after_wards))\nprint(after_wards[:10])\n#unique_after_wards = list(set(after_wards))\n#print(len(unique_after_wards))","outputs":[]},{"metadata":{"_cell_guid":"317ec54b-f007-430e-abd7-4de806ca94d8","_uuid":"9ea1feb3acf9c67b86b60de36749c1bd69c09837","collapsed":true},"cell_type":"code","execution_count":null,"source":"print(np.argmax(after_wards_n))\nprint(max(after_wards_n))\n","outputs":[]},{"metadata":{"_cell_guid":"350cd629-5e7d-4835-a55c-d5a65b9cb57e","_uuid":"1b181e5276fcafa39bdc0ef29d6df8d4c3910277","collapsed":true},"cell_type":"code","execution_count":null,"source":"superlong = np.argmax(after_wards_n)\ndisplay(train_df.loc[superlong])\nprint(max(after_wards_n))\nprint(len(train_df['before'].loc[superlong]))\nprint(len(train_df['after'].loc[superlong]))\nprint(train_idx_before_DICK[superlong])\nprint(train_idx_after_DICK[superlong])","outputs":[]},{"metadata":{"_cell_guid":"7516b679-fbd2-427a-a947-06b94bfe56b2","_uuid":"89ece6cfb0081e0881b9c813d0b5af951dadb4b2","collapsed":true},"cell_type":"code","execution_count":null,"source":"#display(train_df.loc[list(range(superlong-10, superlong+10))])\ndisplay(train_df.loc[tr_sentID_DICK[670765]])\n\n' '.join([train_idx_before_DICK[x] for x in tr_sentID_DICK[670765]])","outputs":[]},{"metadata":{"_cell_guid":"d489fcfc-19a0-4b00-b2a6-a45884c94ee2","_uuid":"6cc098831c175e76fe814b73c8a67f17239ed4fb"},"cell_type":"markdown","source":"(13)  **THROW AN ERROR**"},{"metadata":{"_cell_guid":"ea5d9053-06f6-45ac-8913-b4b7249b6c19","_uuid":"f5d6f13db437dd392be01f6ac394518bfdac4334","collapsed":true},"cell_type":"code","execution_count":null,"source":"THROW AN ERROR","outputs":[]}],"nbformat":4,"nbformat_minor":1}