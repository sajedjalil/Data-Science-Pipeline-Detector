{"metadata":{"language_info":{"codemirror_mode":{"version":3,"name":"ipython"},"nbconvert_exporter":"python","file_extension":".py","version":"3.6.1","name":"python","pygments_lexer":"ipython3","mimetype":"text/x-python"},"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"}},"nbformat_minor":1,"cells":[{"metadata":{"_uuid":"ad0af0c65e910db974308d445fbe794ef4273dd3","scrolled":false,"_cell_guid":"e0f85e6a-50b1-4c6c-9a98-ad3506852598"},"outputs":[],"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1},{"metadata":{"_uuid":"789b173ba7193fb0818d2174b05ae060074656b5","_cell_guid":"95e119ec-5efe-4fbc-b941-1b030fa4693a"},"cell_type":"markdown","source":"# What do we have here?"},{"metadata":{"_uuid":"6fcefc356383a8ede2c92d1ef1ed0a5bdfebf9d0","_cell_guid":"0ecb0cb3-ea87-49b9-b1b7-4b19950f9300"},"cell_type":"markdown","source":"Before doing any serious programming, let's just check out what we have (i.e. inputs), and what might be the expected submission work (i.e. output)."},{"metadata":{"_uuid":"8ed97dd1726f9a15a432f35dd5322ebfc75f5981","_cell_guid":"bcfe3586-42d3-4e51-b030-779ea64bf6c2"},"cell_type":"markdown","source":"## Training Set - Quick Peek"},{"metadata":{"_uuid":"dc9b4ea5cdac3cdbeb9c7832c2e432f06cd548b6","_cell_guid":"5bc7596f-74a7-47b1-8f8d-c62f2e64cbf9"},"cell_type":"markdown","source":"Let's take a look at the training dataset"},{"metadata":{"_uuid":"d546a31c3e707f1c9b95a932d924460c0c7c80c9","collapsed":true,"_cell_guid":"22a6d38d-9892-4a96-9cf5-973931018276"},"outputs":[],"cell_type":"code","source":"df_train = pd.read_csv('../input/en_train.csv')","execution_count":2},{"metadata":{"_uuid":"6e82ab80a31e3441d51851011b9e6a24dd4c89bf","scrolled":false,"_cell_guid":"74a77724-a4d5-465d-8f86-5589ffee0859"},"outputs":[],"cell_type":"code","source":"print(repr(df_train.head(20)))","execution_count":3},{"metadata":{"_uuid":"61db6803ebdaaf91f810d5569597cfea97f50da3","_cell_guid":"ac581426-444e-4147-a9a5-f20fe5947368"},"cell_type":"markdown","source":"Turns out `class` is a Python reserved keyword. To make life easier a bit downstream, let's rename it to `token_class` for safety. (this turns out to be a good idea as things like `df.token_class` works, whereas `df.class` will spill out error)."},{"metadata":{"_uuid":"c174f8e19faf2d50f437aa7c729ad3748920cf9f","_cell_guid":"6035e3b7-f605-468f-90ab-ea036e61eeb3"},"outputs":[],"cell_type":"code","source":"df_train.columns = [\"sentence_id\", \"token_id\", \"token_class\", \"before\", \"after\"]\nprint(repr(df_train.head(20)))","execution_count":4},{"metadata":{"_uuid":"68cbd80f0dff53ac72c028eb2503b9aacddf5510","_cell_guid":"e8e76c43-1073-499a-8325-b5bf0ff2afb3"},"cell_type":"markdown","source":"For each sentence (`sentence_id`):\n\n- we read the written word (`before`) row-by-row.\n- we read the spoken word (`after`) row-by-row.\n\nFor example, the written word `2006` is spoken as `two thousand six`.\n\nEach word within a sentence is defined by `token_id`.\n\nEach `token_id` has an assigned class (e.g. `PLAIN` for normal English, `DATE` for date, `LETTERS` for acronyms, etc.)"},{"metadata":{"_uuid":"9280662378a06fbc39c28c5ee2488541e38d9458","_cell_guid":"4004e34a-0cbf-478b-9a74-8ea19393a7e1"},"cell_type":"markdown","source":"## Test Set - Quick Peek"},{"metadata":{"_uuid":"313f662fba5ab8adeec0bbc9fdb30a0ca588748d","_cell_guid":"54f6b570-1581-4aae-884c-34314083da68"},"cell_type":"markdown","source":"Let's take a look at the test dataset"},{"metadata":{"_uuid":"896adb954d7b5393ce9a90a83164ba8c9609528f","collapsed":true,"_cell_guid":"6c7d835c-5901-4cb8-b8c5-d46bba7d6814"},"outputs":[],"cell_type":"code","source":"df_test = pd.read_csv('../input/en_test.csv')","execution_count":5},{"metadata":{"_uuid":"aee141da4a7525d02f2902dfcd2d5be88829db74","_cell_guid":"eda57ec8-0b86-49bb-be48-22d1c1028952"},"outputs":[],"cell_type":"code","source":"print(repr(df_test.head(20)))","execution_count":6},{"metadata":{"_uuid":"d9132d186542d067157afa6b4937c885f7c1e715","_cell_guid":"1f820802-6c41-4589-a698-3806ca6de4ea"},"cell_type":"markdown","source":"Note that test set only contains `before` (written word). Ther there is no `after` (spoken word). We will need to predict what `after` is."},{"metadata":{"_uuid":"e4f47cc1c8da3336a18195ee5e218849e8aadb63","_cell_guid":"f473b60b-520c-476b-b637-b831711a6c0c"},"cell_type":"markdown","source":"## Sample Submission - Quick Peek"},{"metadata":{"_uuid":"59cf057689248b1896b010a552276496f99326b7","collapsed":true,"_cell_guid":"66f5f585-da18-4274-a152-005ef00363e2"},"outputs":[],"cell_type":"code","source":"df_sample_submission = pd.read_csv('../input/en_sample_submission.csv')","execution_count":7},{"metadata":{"_uuid":"6117662ca7e2ea647f036dbe3c3bd3d08cd158a6","_cell_guid":"176265e2-1e1b-427b-8943-6043fe9db6d8"},"outputs":[],"cell_type":"code","source":"print(repr(df_sample_submission.head(20)))","execution_count":8},{"metadata":{"_uuid":"b4dc8b6938f3182089e21124c2d8a1d1eec26300","_cell_guid":"e3a22c43-35cc-4d16-8214-381eb9d0f2a6"},"cell_type":"markdown","source":"Note that sample submission contains the `after` column (predicted spoken word), for the corresponding `before` column (written word) in the test set. The `id` column takes the syntax of `<sentence_id>_<token_id>`. e.g. second sentence, third token will have an `id` of `1_2`. (zero index)."},{"metadata":{"_uuid":"278d820672eed162f780a3bff4eacff1dd7db0c0","_cell_guid":"8eede727-2ca6-40b8-89ce-46485addde8c"},"cell_type":"markdown","source":"# Explore Training Set"},{"metadata":{"_uuid":"6c78726f71507a4c968cf5c960d7eedc2fc2e9f4","_cell_guid":"62dd47e1-86d6-4de9-bea4-d67f84afcbe2"},"cell_type":"markdown","source":"Now we know that our objective is to predict the `after` column (predicted spoken word), based on the `before` vs `after` mapping training data, let's get a high level overview of what we have in our training data set. For example:\n\n- How many unique sentences? (`sentence_id`)\n- How many unique `token_class`?\n- How many unique `before`? (token in written form)\n- How many unique `after`? (token in spoken form)\n- How many sentences per `token_class`?\n- etc."},{"metadata":{"_uuid":"4ce390eb10dced51c0d4537dba8064316503c9ac","scrolled":true,"_cell_guid":"767b79f1-ffb2-4b21-b3bc-787c6bc512cd"},"outputs":[],"cell_type":"code","source":"print(\"Unique sentences: {:,d}\".format(df_train.sentence_id.unique().size))\nprint(\"Unique token classes: {:,d}\".format(df_train.token_class.unique().size))\nprint(\"Unique before: {:,d}\".format(df_train.before.unique().size))\nprint(\"Unique after: {:,d}\".format(df_train.after.unique().size))","execution_count":9},{"metadata":{"_uuid":"6906c859236567198707bdc528fae306460a8238","_cell_guid":"4a09a54a-ec9a-43a4-8cdd-cfb3effe252e"},"outputs":[],"cell_type":"code","source":"print('sentences per class...')\nprint('======================')\nprint(repr(df_train.groupby(['token_class'])['sentence_id'].count()))","execution_count":10},{"metadata":{"_uuid":"f2bce7edd8d59d78068a0891c84d1aad3b036344","_cell_guid":"f975867f-26c6-489f-bb94-b13ccd2af102"},"cell_type":"markdown","source":"We have 16 unique token classes. Let's get a feel of what the tokens look like for each class. This is how we do a \"peek\" against one token class:"},{"metadata":{"_uuid":"25712470779bab230338174479ec8a53f00bc1bb","scrolled":true,"_cell_guid":"cd90c5b6-1065-4df5-855b-3b4e7be3f4f0"},"outputs":[],"cell_type":"code","source":"df_train[df_train['token_class'] == 'ADDRESS'].head(5)","execution_count":11},{"metadata":{"_uuid":"a7e2c8e66f83f58810db36aad681796df22bed6c","_cell_guid":"505a11db-7834-490b-9c83-1782b464d219"},"cell_type":"markdown","source":"To repeat this for all 16 token classes, we can write a simple function to do the job:"},{"metadata":{"_uuid":"77b5446a98e1b6df7c1309679be1ea6ba9c1b6c1","collapsed":true,"_cell_guid":"41ee841b-b0f7-4495-8634-896adc0734c0"},"outputs":[],"cell_type":"code","source":"def peek_tokens_by_class(token_classes, view_x):\n    for token_class in token_classes:\n        print(df_train[df_train['token_class'] == token_class].head(view_x))","execution_count":12},{"metadata":{"_uuid":"bf154d86499897583f18d8d76519d5c7a8b5830f","_cell_guid":"0039f02f-732b-468a-9f49-9eaff325309d"},"outputs":[],"cell_type":"code","source":"# Run it! Let's peak 10 samples from each token_class.\npeek_tokens_by_class(df_train.token_class.unique(), 10)","execution_count":13},{"metadata":{"_uuid":"6e71dace0063a1cde849145ec6b948bd8a326c3b","_cell_guid":"cbd9fd62-256c-484c-9a55-344d148e32db"},"cell_type":"markdown","source":"We have just learnt what the before (written form) vs after (spoken form) looks like for the 16 unique token classes. Notice that the `VERBATIM` class contains some non English characters (not sure what this is)."},{"metadata":{"_uuid":"6838135947fd1767bcb773f9b19c69a77c1bdffe","collapsed":true,"_cell_guid":"c40fa01d-9b23-4849-b032-5f4dbe4bf78f"},"cell_type":"markdown","source":"**Note to self** More analysis to come (work in progress)."},{"metadata":{"_uuid":"11837baa6c7bbdf9eccbc742dd1912ca3c343b4c","collapsed":true,"_cell_guid":"e7f82d72-db25-46fa-890c-dac44c34b09d"},"outputs":[],"cell_type":"code","source":"","execution_count":null},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","source":"","execution_count":null}],"nbformat":4}