{"cells":[{"outputs":[],"execution_count":null,"source":"import numpy as np\nfrom numpy import argmax\nimport pandas as pd\n\n# Keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import TimeDistributed\nfrom keras.layers import RepeatVector\nfrom keras.preprocessing.text import text_to_word_sequence","cell_type":"code","metadata":{"_uuid":"29199138dd9a3d6ecdc298050840941ea26171dd","_cell_guid":"ec342be6-7c0d-4717-8c85-b39f362a69c6"}},{"outputs":[],"execution_count":null,"source":"# Max columns for display\npd.options.display.max_columns = 999\n\n# Disable warning message\nimport warnings\nwarnings.filterwarnings('ignore')","cell_type":"code","metadata":{"_uuid":"e2b1f7610936c5cfee6109fd86d6f1b16023b2f0","collapsed":true,"_cell_guid":"818d16d8-f3e6-4508-b344-b4ff31bbcfe8"}},{"outputs":[],"execution_count":null,"source":"df = pd.read_csv(\"../input/en_train.csv\")","cell_type":"code","metadata":{"_uuid":"e30520ec064a2640ff4929791306ecc2b56f7188","collapsed":true,"_cell_guid":"e1fb3943-adde-40a1-a2b4-fbbed059cc18"}},{"outputs":[],"execution_count":null,"source":"# Refer to the ebook long_short_term_memory_networks_with_python\n\ndef integer_encode_X(X, vocabs, reverse_order=True, max_len=50, pad_default_char=' '):\n    char_to_int = dict((c, i) for i, c in enumerate(vocabs))\n    \n    Xenc = list()\n    for pattern in X:\n        pattern = pattern[:max_len]\n        pattern = pattern + (pad_default_char * (max_len - len(pattern)))\n        if reverse_order:\n            pattern = pattern[::-1]\n        integer_encoded = [char_to_int[char] for char in pattern]\n        Xenc.append(integer_encoded)\n    return Xenc\n\n\ndef text_to_word_sequence_fixed(text):\n    list_words = text_to_word_sequence(text)\n    return list_words if len(list_words) > 0 else [text]\n\n\ndef integer_encode_Y(y, vocabs, max_len=50, pad_default_char='PAD'):\n    idx_mapping = dict((c, i) for i, c in enumerate(vocabs))\n    \n    yenc = list()\n    for pattern in y:\n        pattern = text_to_word_sequence_fixed(pattern)[:max_len]\n        pattern = pattern + ([pad_default_char] * (max_len - len(pattern)))\n        integer_encoded = [idx_mapping[word] for word in pattern]\n        yenc.append(integer_encoded)\n    return yenc\n\ndef one_hot_encode(X, y, vec_size_x, vec_size_y):\n    Xenc = list()\n    for seq in X:\n        pattern = list()\n        for index in seq:\n            vector = [0 for _ in range(vec_size_x)]\n            vector[index] = 1\n            pattern.append(vector)\n        Xenc.append(pattern)\n    yenc = list()\n    for seq in y:\n        pattern = list()\n        for index in seq:\n            vector = [0 for _ in range(vec_size_y)]\n            vector[index] = 1\n            pattern.append(vector)\n        yenc.append(pattern)\n    return np.array(Xenc), np.array(yenc)\n\n\ndef invert(seq, vocabs, join_char=''):\n    idx_mapping = dict((i, c) for i, c in enumerate(vocabs))\n\n    strings = list()\n    for pattern in seq:\n        string = idx_mapping[argmax(pattern)]\n        strings.append(string)\n    return join_char.join(strings)\n\n\ndef make_transform_train_data(\n        df, X_vocabs, y_vocabs,\n        n_in_seq_length, n_out_seq_length,\n        n_in_terms, n_out_terms\n    ):\n    X_small = df['before']\n    y_small = df['after']\n    \n    x_transformed = integer_encode_X(X_small, X_vocabs, max_len=n_in_seq_length)\n    y_transformed = integer_encode_Y(y_small, y_vocabs, max_len=n_out_seq_length)\n    \n    return one_hot_encode(\n        x_transformed,\n        y_transformed,\n        n_in_terms,\n        n_out_terms\n    )","cell_type":"code","metadata":{"_uuid":"1c982a76123ef9c7aabf24f3ce4a4ebef5026d5b","collapsed":true,"_cell_guid":"006b4ec3-a8c7-4b4d-8ef9-894f4c5e942f"}},{"source":"### Prepare data","cell_type":"markdown","metadata":{"_uuid":"96ad9e006739d9ffe818e433d0380709c001a3d4","_cell_guid":"e87bde98-df08-4abd-987b-c90fe90d8818"}},{"outputs":[],"execution_count":null,"source":"# Only try out with the CARDINAL\ndf_filtered = df[df['class'] == 'CARDINAL']\ndf_filtered[['before', 'after']] = df_filtered[['before', 'after']].astype(str)","cell_type":"code","metadata":{"_uuid":"25cd86f3d796e0909c9a4aed8a6e81061d5923f8","collapsed":true,"_cell_guid":"30e46eb5-0669-4ee1-bbaa-6a4b207984ba"}},{"outputs":[],"execution_count":null,"source":"X = df_filtered['before']\ny = df_filtered['after']\n\nX_vocabs = set([' '])\nfor words in X:\n    X_vocabs.update(list(words))\nX_vocabs = [' '] + [X_vocab for X_vocab in list(X_vocabs) if X_vocab != ' ']\n\ny_vocabs = set()\nfor words in y:\n    y_vocabs.update(text_to_word_sequence_fixed(words))\ny_vocabs = ['PAD'] + list(y_vocabs)","cell_type":"code","metadata":{"_uuid":"03cd85bc81c2e17f1f5bd1299c375437503c6b1e","collapsed":true,"_cell_guid":"b1976dff-a991-4ac2-a3e3-3122b028c524"}},{"outputs":[],"execution_count":null,"source":"print('Index of empty word in X %s' % X_vocabs.index(' '))\nprint('Index of empty word in y %s' % y_vocabs.index('PAD'))","cell_type":"code","metadata":{"_uuid":"c124c0f55e583b68c5e1385dab7da99fee018d10","_cell_guid":"fc0b77f1-e107-4254-b7e0-51b1ead961ee"}},{"outputs":[],"execution_count":null,"source":"print('Size of vocabs X: %s' % len(X_vocabs))\nprint('Size of vocabs y: %s' % len(y_vocabs))","cell_type":"code","metadata":{"_uuid":"0b04805b428d2fdd52df5af4939c12a02fd97df7","_cell_guid":"dd29b943-ac85-492d-b380-9426e8d95f0e"}},{"outputs":[],"execution_count":null,"source":"n_in_seq_length = np.min([50, len(X_vocabs)])\nn_out_seq_length = np.min([50, len(y_vocabs)])\n\nn_in_terms = len(X_vocabs)\nn_out_terms = len(y_vocabs)","cell_type":"code","metadata":{"_uuid":"820456e145f444f37fbdc722048c402e16d9b921","collapsed":true,"_cell_guid":"c785aee0-8a5d-4ffa-880f-b819dc5f324b"}},{"source":"### Train model","cell_type":"markdown","metadata":{"_uuid":"933584148984096e2246f27c3998cb6b3851beb8","_cell_guid":"bf69ec60-6a54-4074-999d-6194ef10f806"}},{"outputs":[],"execution_count":null,"source":"model = Sequential()\nmodel.add(LSTM(75, input_shape=(n_in_seq_length, n_in_terms)))\nmodel.add(RepeatVector(n_out_seq_length))\nmodel.add(LSTM(50, return_sequences=True))\nmodel.add(TimeDistributed(Dense(n_out_terms, activation='softmax')))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nprint(model.summary())","cell_type":"code","metadata":{"_uuid":"8b725ba4a9eac8d24e4231623d255c6cc697e4fc","_cell_guid":"10850064-acf0-41af-b58b-09802d3a6735"}},{"outputs":[],"execution_count":null,"source":"%%time\nx_transformed, y_transformed = make_transform_train_data(\n    df_filtered, X_vocabs, y_vocabs,\n    n_in_seq_length, n_out_seq_length,\n    n_in_terms, n_out_terms\n)","cell_type":"code","metadata":{"_uuid":"b96b011a0bec1f1c3fa022dc04e97fd39180c65d","_cell_guid":"bd22432a-3172-4de5-b69d-072121d1c9c2"}},{"outputs":[],"execution_count":null,"source":"model.fit(x_transformed, y_transformed, epochs=1, batch_size=32)","cell_type":"code","metadata":{"_uuid":"76a911412240e8604539b79e90bb7b9709c6c0ca","_cell_guid":"92211b09-94fa-49c4-93d2-67cc7edbb95f"}},{"source":"### Evaluate","cell_type":"markdown","metadata":{"_uuid":"a2a87879e81839a306f95491f1ea7bea21c7ddcb","_cell_guid":"921f9ad1-d994-4dba-b6f4-5392cd142a26"}},{"outputs":[],"execution_count":null,"source":"# Get first 2000 rows for verify the model performance\nx_transformed_test, y_transformed_test = make_transform_train_data(\n    df_filtered.iloc[:2000], X_vocabs, y_vocabs,\n    n_in_seq_length, n_out_seq_length,\n    n_in_terms, n_out_terms\n)","cell_type":"code","metadata":{"_uuid":"fa733b6dfa176cf5fa19b35f3a3881307a91fe2e","collapsed":true,"_cell_guid":"5afbfd1a-ae24-4215-b8cb-4d6fc5c834ea"}},{"outputs":[],"execution_count":null,"source":"yhat = model.predict(x_transformed_test, verbose=0)","cell_type":"code","metadata":{"_uuid":"6e69fd77e00fded9ebae06fa00edbd14f355686e","collapsed":true,"_cell_guid":"7e2476b3-df7c-4793-ae9f-a22fe804d8c0"}},{"outputs":[],"execution_count":null,"source":"for idx, yh in enumerate(yhat[:50]):\n    yh_inverted = invert(yh, vocabs=y_vocabs, join_char=' ').replace(' PAD', '')\n    in_seq = invert(x_transformed_test[idx], X_vocabs).replace(' ', '')[::-1]\n    out_seq = invert(y_transformed_test[idx], y_vocabs, join_char=' ').replace(' PAD', '')\n    print('%s = %s (%s expect: %s)' % (in_seq, yh_inverted, ('TRUE' if out_seq == yh_inverted else \"FALSE\"), out_seq))","cell_type":"code","metadata":{"_uuid":"d7fd648eb019331f344aaebe757136c82181957b","_cell_guid":"6465008f-b023-4414-9eac-43d6ee738983"}}],"nbformat_minor":1,"nbformat":4,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"mimetype":"text/x-python","pygments_lexer":"ipython3","version":"3.6.3","file_extension":".py","name":"python","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3}}}}