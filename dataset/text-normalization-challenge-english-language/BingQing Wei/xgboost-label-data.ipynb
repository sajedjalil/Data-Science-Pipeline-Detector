{"nbformat_minor":1,"nbformat":4,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.1","nbconvert_exporter":"python","pygments_lexer":"ipython3","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python"}},"cells":[{"source":"*Author: BingQing Wei*\n\n**Introduction**\nI have tried using regex to solve labeling the data([my notebook](https://www.kaggle.com/alphasis/regex-label-data)), but I later found I just can't make it perfect.\nTherefore I turned once again to machine learning.\nAnd I decided to use XGboost as a starter, because I think decision trees might be the best in classifying this kind of data.\n\n**How I train it**\nI didn't use data lebeld as 'PLAIN', 'VERBATIM', 'LETTERS', 'PUNCT' to train the model.\nBecause for 'VERBATIM' and 'PUNCT' data, they can be labeled trivially.\nAnd 'PLAIN' and 'LETTERS' data can only be classified given the context. It's something RNN is good at but XGboost is not.\nSo I use the rest 12 classes to train XGboost model and only used 20,000 of them since I don't want to be kept waiting for too long.\n\n**Results**\nAccuracy 97.9% on validation data.\nThe output of this script consists of 3 files:\n\n*xgb_model*: the dumped model that we trained\n*pred.csv*: contains the validation data\n*errors.csv*: contains data that the model predicts wrong\n\nIf you look into the errors.csv, you will find the 0.021 error rate is reasonable:\n*Because some special 'CARDINAL' data are classified as 'DATE' *.\nAgian, it's something beyond XGBoost's ability.","cell_type":"markdown","metadata":{"_cell_guid":"bfaf187a-68f1-4676-b758-1d3b4eae5aa1","_uuid":"98c7fc065b0140cbe2b9426201dabf9368a94e35"}},{"source":"We begin by loading data and then drop those 'PLAIN', 'VERBATIM', 'LETTERS' or 'PUNCT' data","cell_type":"markdown","metadata":{"_cell_guid":"ebeba34b-b6ee-4e8f-a200-d8a4c2494aed","_uuid":"eeae200a3fec914ba72711676d02be4455d37b20"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"92829c18-c48d-4595-a52b-57ac9df3d334","_uuid":"7126147e58688273c17b506ee86baac4c1eb8199"},"source":"import pandas as pd\nimport numpy as np\nimport os\nimport pickle\n\nmax_num_features = 20\n\nout_path = r'.'\ndf = pd.read_csv(r'../input/en_train.csv')\nexclude_classes = ['PLAIN', 'VERBATIM', 'LETTERS', 'PUNCT']\ndf = df.loc[df['class'].isin(exclude_classes) == False]"},{"source":"To convert strings into numbers, I simply take their ASCII value then minus 'a'.\nThis, minusing 'a', I think is important.\nBecause I think **it distinguishes alphabets from numbers and some symbols**.\n*Since most alphabets in the data are lower-case, we don't consider upper-case here.*","cell_type":"markdown","metadata":{"_cell_guid":"f47024d2-f059-4ddc-8d9e-1ba434d41bd8","_uuid":"cf9bd6f66440b9d4b9114a2d8ae913a0e5545625"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"e3e22f7f-0c97-4c74-929a-5c39c516b4c4","_uuid":"1e60750e57da9c5aecfe96e3852bdeb63a441a6c"},"source":"max_size = 200000\nx_data = []\ny_data = pd.factorize(df['class'])\nlabels = y_data[1]\ny_data = y_data[0]\nfor x in df['before'].values:\n    x_row = np.zeros(max_num_features, dtype=int)\n    for xi, i in zip(list(str(x)), np.arange(max_num_features)):\n        x_row[i] = ord(xi) - ord('a')\n    x_data.append(x_row)\n\nprint('Total number of samples:', len(x_data))\nprint('Use: ', max_size)\n#x_data = np.array(x_data)\n#y_data = np.array(y_data)\nx_data = np.array(x_data[:max_size])\ny_data = np.array(y_data[:max_size])\n\nprint('x_data sample:')\nprint(x_data[0])\nprint('y_data sample:')\nprint(y_data[0])\nprint('labels:')\nprint(labels)\n\ndel df"},{"source":"Next we begin training the model.","cell_type":"markdown","metadata":{"_cell_guid":"657b7654-fa98-47ca-ada1-4d0d838d0b5f","_uuid":"b33b4d05198980def2b384267612526ff191a26d"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"a2fc1d8e-4f4f-4e8d-af01-f9f7ec1ca227","_uuid":"f06092db25b83dca29572abdfff0398b1cf50a1c"},"source":"import xgboost as xgb\nimport numpy as np\nimport pickle\nimport os\nimport re\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\nout_path = r'.'\n\nx_train = x_data\ny_train = y_data\ndel x_data\ndel y_data\n\nx_train, x_valid, y_train, y_valid= train_test_split(x_train, y_train,\n                                                      test_size=0.1, random_state=2017)\nnum_class = len(labels)\ndtrain = xgb.DMatrix(x_train, label=y_train)\ndvalid = xgb.DMatrix(x_valid, label=y_valid)\nwatchlist = [(dvalid, 'valid'), (dtrain, 'train')]\n\nparam = {'objective':'multi:softmax',\n         'eta':'0.3', 'max_depth':10,\n         'silent':1, 'nthread':-1,\n         'num_class':num_class,\n         'eval_metric':'merror'}\nmodel = xgb.train(param, dtrain, 60, watchlist, early_stopping_rounds=20,\n                  verbose_eval=10)"},{"source":"Next we take the predictions by the model of the validation data and save them into csv files.","cell_type":"markdown","metadata":{"_cell_guid":"e4692e0b-6288-435a-8145-8c5792681f1e","_uuid":"6013ea122858b6634199938fd4aca4108ba70577"}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{"collapsed":true,"_cell_guid":"9eebf1a6-6094-4187-bf9a-a10849179fc7","_uuid":"434c1aa323bb943a02f84af50613a707dff8499c"},"source":"pred = model.predict(dvalid)\npred = [labels[int(x)] for x in pred]\ny_valid = [labels[x] for x in y_valid]\nx_valid = [ [ chr(x + ord('a')) for x in y] for y in x_valid]\nx_valid = [''.join(x) for x in x_valid]\nx_valid = [re.sub('a+$', '', x) for x in x_valid]\n\ndf_pred = pd.DataFrame(columns=['data', 'predict', 'target'])\ndf_pred['data'] = x_valid\ndf_pred['predict'] = pred\ndf_pred['target'] = y_valid\ndf_pred.to_csv(os.path.join(out_path, 'pred.csv'))\n\ndf_errors = df_pred.loc[df_pred['predict'] != df_pred['target']]\ndf_errors.to_csv(os.path.join(out_path, 'errors.csv'))\n\nmodel.save_model(os.path.join(out_path, 'xgb_model'))"},{"source":"Since Kaggle Notebook doesn't provide the output of it, I gonna use another way.","cell_type":"markdown","metadata":{}},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{},"source":"df_pred[:10]"},{"outputs":[],"execution_count":null,"cell_type":"code","metadata":{},"source":"df_errors[:10]"}]}