{"nbformat":4,"nbformat_minor":1,"cells":[{"execution_count":null,"outputs":[],"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom keras.layers import Embedding\nfrom keras.layers import Dense, Dropout, Activation\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Masking\nfrom keras.optimizers import RMSprop\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom sklearn.model_selection import KFold\n\n### Make sure to install seq2seq from https://github.com/farizrahman4u/seq2seq\nfrom seq2seq import SimpleSeq2Seq, Seq2Seq, AttentionSeq2Seq","metadata":{"_kg_hide-output":true,"_cell_guid":"8e1e1f65-197a-4b95-b70a-1264a577be8f","collapsed":true,"_uuid":"208873bb70788869f28af3ae85eee4db4ad895dc"}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"df = pd.read_csv(\"../input/en_train.csv\")","metadata":{"_uuid":"85512c324ffa8317951d0c7d1d1ed767b3aa7612","_cell_guid":"abf26e22-e17c-4d6a-afde-318cfd85b819","collapsed":true}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"df.head(10)","metadata":{"_uuid":"22d076aae8e6a80a0944ef55aacfc7467324e6d6","_cell_guid":"e7f85eee-df86-4015-86b6-a029e21c905d","collapsed":true}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"df['class'].unique()","metadata":{"_uuid":"d7cdc9ffddb38a65898f57bc55a28eb373bd9a96","_cell_guid":"cb0bbad2-8b07-4877-b584-05570850fb3c","collapsed":true}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"df = df[df['class'] == 'DIGIT']\n\ndf['before'] = [word.lower() for word in df.before]\nprint (df.head())","metadata":{"_uuid":"5615305324467f17cf70173379dd90b959dc05c3","_cell_guid":"a0be27d6-6c0a-48ab-a313-a20bca889021","collapsed":true}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"chars = set()\nfor word in df.before:\n    #print chars\n    for char in list(str(word)):\n        chars.add(char)\n\nprint ('chars --', chars)      \nprint ('before len max =', max([len (word) for word in df.before]))\n\nwords = set(['__UNK__'])\nfor sentence in df.after:\n    for word in sentence.split():\n        words.add(word)\n\nprint ('after len max =', max([len(word.split()) for word in df.after]))\nprint ('words --', words)\n\n","metadata":{"_uuid":"d240870d958b4604725a1d4802b01213c0e0b09c","_cell_guid":"4af8453e-0786-429b-85e0-ca1bb72d0d61","collapsed":true}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"print ('df len = ', len(df))\n\nprint ('chars len = ', len(chars))\n\nchar_indices = dict((c, i) for i, c in enumerate(chars))\nindices_char = dict((i, c) for i, c in enumerate(chars))\n\nprint ('words  len = ', len(words))\n\n\nword_indices = dict((w, i) for i, w in enumerate(words))\nindices_word = dict((i, w) for i, w in enumerate(words))","metadata":{"_uuid":"ea8196ff5b69c66beaebc7a0a3efcd9a9113c974","_cell_guid":"679bae94-cf50-4890-9d76-58608025cb88","collapsed":true}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"input_length = 20\noutput_length = 20\n\nX = np.zeros((len(df.before), input_length, len(chars)), dtype=np.bool)\ny = np.zeros((len(df.before), output_length, len(words)), dtype=np.bool)\n\ni = 0\nfor index, row in df.iterrows():\n    for t, char in enumerate(str(row['before'])[:input_length]):\n        X[i, t, char_indices[char]] = 1\n    \n    \n    t = 0\n    for word in row['after'].split()[:output_length]:\n        \n        y[i, t, word_indices[word]] = 1\n        t += 1\n        \n    for t in range (t, output_length):\n        y[i, t, word_indices['__UNK__']] = 1\n    i += 1\n\nprint ('data loaded')","metadata":{"_uuid":"eabdac1c2ca0386509507071f40b167dcdd9c514","_cell_guid":"c3dfd9d4-6bed-46a1-8ad7-249d611996cf","collapsed":true}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"print (X.shape)\nprint (y.shape)","metadata":{"_uuid":"76b9af8b5682d2c223d8665d9d0d698ba710c833","_cell_guid":"6a60e9b4-20e3-470b-96c5-1f938be1900e","collapsed":true}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"input_dim = len(chars)\noutput_dim = len(words)\nhidden_dim = 64\n\n\n\n\nmodel = Sequential()\n\n\n\nmodel.add(AttentionSeq2Seq(output_dim=output_dim, hidden_dim=hidden_dim, \n                           output_length=output_length, \n                           input_shape=(input_length, input_dim)))\n\nmodel.add(Dense(len(words)))\nmodel.add(Activation('softmax'))\n#model.compile(loss='mse', optimizer='adam')\noptimizer = RMSprop(lr=0.01)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer)\nprint (model.summary())","metadata":{"_kg_hide-output":true,"_cell_guid":"65cee5ec-e791-4335-9b5c-39d151509e97","collapsed":true,"_uuid":"0487e840b883c3a3aa2dc1fff174fa13e04c36ac"}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"X1 = X[:-200]\ny1 = y[:-200]\n\nprint (X1.shape)\nprint (y1.shape)\n\n\n# checkpoint\nfilepath=\"weights.best.digit.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\nearly_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\ncallbacks_list = [checkpoint, early_stop]\n\nkf = KFold(n_splits=5)\n\nfor train_index, test_index in kf.split(X1):\n    X_train, X_test = X1[train_index], X1[test_index]\n    y_train, y_test = y1[train_index], y1[test_index]\n    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, callbacks=callbacks_list)\n    model.load_weights(\"weights.best.digit.hdf5\")\n\nprint ('training done')","metadata":{"_uuid":"bf423c3d4d7a451c126e207963dfaac6477f92fc","_cell_guid":"ab355eda-8a84-4c48-9655-3b362b15ec44","collapsed":true}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"X2 = X[-200:]\nmodel.load_weights(\"weights.best.digit.hdf5\")\ny2 = model.predict(X2)\n\n#print (y2)","metadata":{"_uuid":"e9586d77501b0bf3a383beb3589a1af303ca92cd","_cell_guid":"02bc5890-abc1-4993-a9a3-906289e34dc1","collapsed":true}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"predicted = []\nfor i in y2:\n    out = []\n    for j in i:\n        if (indices_word[np.argmax(j)] != '__UNK__'):\n            out.append(indices_word[np.argmax(j)])\n            out.append(\" \")\n    s =  \"\".join(out)\n    #print s\n    predicted.append(s)\n    ","metadata":{"_uuid":"cde2dbc33b4662c22765c547314a0aff2eebc8eb","_cell_guid":"c8786d0d-a376-4673-bd98-d096ed47b71b","collapsed":true}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"df['predicted'] = np.zeros(len(df))\ndf['predicted'][-200:] = predicted\n#print df[['before', 'after', 'predicted']][-200:]\n\ncount = 0\nprint ('######### Wrong prediction - ')\nfor index, row in df[-200:].iterrows():\n    #print row\n    \n    if row['after'].strip() != row['predicted'].strip():\n        print (row['before'], 'after = ', row['after'], 'predicted=', row['predicted'])\n        count +=1\n","metadata":{"_uuid":"8823fea2fb53b24dc0b618a17b2ca5e914b165d2","_cell_guid":"375b9be3-b052-446d-83d5-bf991b39beed","collapsed":true}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"print ('accuracy on test data - ', 1.0 - count/200.0)","metadata":{"_uuid":"4804a821241b348dd3ea77afb8b92464513483a8","_cell_guid":"fe3ae908-a772-4362-b566-53bb91c389ed","collapsed":true}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"","metadata":{"_uuid":"bd5d7a71715cb413c968b0895f19c5a6f8f1fd1a","_cell_guid":"433a1432-f3bf-4818-bfd8-057e81eaa4bf","collapsed":true}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"","metadata":{"_uuid":"0403c17055744e0922a163ba357f1df77148640f","_cell_guid":"90908b0c-67b8-43b7-94b0-4bf1eb083e1e","collapsed":true}}],"metadata":{"widgets":{"state":{},"version":"1.1.2"},"language_info":{"file_extension":".py","version":"3.6.1","nbconvert_exporter":"python","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}}}