{"cells":[{"metadata":{"_uuid":"b4d5dae278c7d7adab4f02e70dc2d8913c7e93a3"},"cell_type":"markdown","source":"The following single model scores 0.87169 on the private leaderboard, between 12th & 13th (private)."},{"metadata":{"trusted":true,"_uuid":"a4d426faf9813a95b4a5b7332e04a155aa51b1f7"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\nimport lightgbm as lgb\nfrom sklearn import metrics\nfrom sklearn.metrics import roc_auc_score\nimport pickle\nimport os\nimport gc\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\ngc.enable()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1285a4c7b101690357dca16cf3f0caa1b4ee7394"},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6dfa358d74d49e99de029cb6cf60fb87b1766974"},"cell_type":"code","source":"def pre_pro(df):\n    df = df.astype('float32')\n    col = df.columns\n    for i in range(len(col)):\n        m = df.loc[df[col[i]] != -np.inf, col[i]].min()\n        df[col[i]].replace(-np.inf,m,inplace=True)\n        M = df.loc[df[col[i]] != np.inf, col[i]].max()\n        df[col[i]].replace(np.inf,M,inplace=True)\n    \n    df.fillna(0, inplace = True)\n    return df ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a029941222fc7ddc4d33ec9b97de4313a512fcb5"},"cell_type":"code","source":"def feat_eng(df):\n    df.replace(0, 0.001)\n    \n    df['follower_diff'] = (df['A_follower_count'] > df['B_follower_count'])\n    df['following_diff'] = (df['A_following_count'] > df['B_following_count'])\n    df['listed_diff'] = (df['A_listed_count'] > df['B_listed_count'])\n    df['ment_rec_diff'] = (df['A_mentions_received'] > df['B_mentions_received'])\n    df['rt_rec_diff'] = (df['A_retweets_received'] > df['B_retweets_received'])\n    df['ment_sent_diff'] = (df['A_mentions_sent'] > df['B_mentions_sent'])\n    df['rt_sent_diff'] = (df['A_retweets_sent'] > df['B_retweets_sent'])\n    df['posts_diff'] = (df['A_posts'] > df['B_posts'])\n\n    df['A_pop_ratio'] = df['A_mentions_sent']/df['A_listed_count']\n    df['A_foll_ratio'] = df['A_follower_count']/df['A_following_count']\n    df['A_ment_ratio'] = df['A_mentions_sent']/df['A_mentions_received']\n    df['A_rt_ratio'] = df['A_retweets_sent']/df['A_retweets_received']\n    \n    df['B_pop_ratio'] = df['B_mentions_sent']/df['B_listed_count']\n    df['B_foll_ratio'] = df['B_follower_count']/df['B_following_count']\n    df['B_ment_ratio'] = df['B_mentions_sent']/df['B_mentions_received']\n    df['B_rt_ratio'] = df['B_retweets_sent']/df['B_retweets_received']\n    \n    df['A/B_foll_ratio'] = (df['A_foll_ratio'] > df['B_foll_ratio'])\n    df['A/B_ment_ratio'] = (df['A_ment_ratio'] > df['B_ment_ratio'])\n    df['A/B_rt_ratio'] = (df['A_rt_ratio'] > df['B_rt_ratio'])\n\n    df['nf1_diff'] = (df['A_network_feature_1'] > df['B_network_feature_1'])\n    df['nf2_diff'] = (df['A_network_feature_2'] > df['B_network_feature_2'])\n    df['nf3_diff'] = (df['A_network_feature_3'] > df['B_network_feature_3'])\n    \n    df['nf3_ratio'] = df['A_network_feature_3'] / df['B_network_feature_3']\n    df['nf2_ratio'] = df['A_network_feature_2'] / df['B_network_feature_2']\n    df['nf1_ratio'] = df['A_network_feature_1'] / df['B_network_feature_1']\n    \n    return(pre_pro(df))\n# # # # # # # # # # # # # # # # # # # # # #","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2078733544d0292ca3d8a8903a4f244db5a6eab6"},"cell_type":"code","source":"fe_train = feat_eng(train.copy())\nfe_test = feat_eng(test.copy())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b86af8bd1efea9023f71e565e2fc7880486f4f6f"},"cell_type":"code","source":"train_df = fe_train\ntest_df = fe_test\ny_train = np.array(train_df['Choice'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"519fd49d9fd1bfd34a2497a674ec1998d349ca00"},"cell_type":"code","source":"target = 'Choice'\npredictors = train_df.columns.values.tolist()[1:]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"105aedf75a51279694541a1b3dfc41774e27ab2c"},"cell_type":"markdown","source":"Parameters came from a Bayesian Optimized Parameter Search"},{"metadata":{"trusted":true,"_uuid":"518f24384373cfc38b62af3aa0e82f51a53c28f7"},"cell_type":"code","source":"bayesian_tr_index, bayesian_val_index  = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=1).split(train_df, train_df.Choice.values))[0]\n\ndef LGB_bayesian(\n     num_leaves,  # int\n     min_data_in_leaf,  # int\n     learning_rate,\n     min_sum_hessian_in_leaf,    # int  \n     feature_fraction,\n     lambda_l1,\n     lambda_l2,\n     min_gain_to_split,\n     max_depth):\n    \n     # LightGBM expects next three parameters need to be integer. So we make them integer\n     num_leaves = int(round(num_leaves))\n     min_data_in_leaf = int(round(min_data_in_leaf))\n     max_depth = int(round(max_depth))\n\n     assert type(num_leaves) == int\n     assert type(min_data_in_leaf) == int\n     assert type(max_depth) == int\n\n     param = {\n         'num_leaves': num_leaves,\n         'max_bin': 63,\n         'min_data_in_leaf': min_data_in_leaf,\n         'learning_rate': learning_rate,\n         'min_sum_hessian_in_leaf': min_sum_hessian_in_leaf,\n         'bagging_fraction': 1.0,\n         'bagging_freq': 5,\n         'feature_fraction': feature_fraction,\n         'lambda_l1': lambda_l1,\n         'lambda_l2': lambda_l2,\n         'min_gain_to_split': min_gain_to_split,\n         'max_depth': max_depth,\n         'save_binary': True, \n         'seed': 1337,\n         'feature_fraction_seed': 1337,\n         'bagging_seed': 1337,\n         'drop_seed': 1337,\n         'data_random_seed': 1337,\n         'objective': 'binary',\n         'boosting_type': 'gbdt',\n         'verbose': 1,\n         'metric': 'auc',\n         'is_unbalance': True,\n         'boost_from_average': False,   \n\n     }    \n    \n    \n     xg_train = lgb.Dataset(train_df.iloc[bayesian_tr_index][predictors].values,\n                            label=train_df.iloc[bayesian_tr_index][target].values,\n                            feature_name=predictors,\n                            free_raw_data = False\n                            )\n     xg_valid = lgb.Dataset(train_df.iloc[bayesian_val_index][predictors].values,\n                            label=train_df.iloc[bayesian_val_index][target].values,\n                            feature_name=predictors,\n                            free_raw_data = False\n                            )   \n\n     num_round = 5000\n     clf = lgb.train(param, xg_train, num_round, valid_sets = [xg_valid], verbose_eval=250, early_stopping_rounds = 50)\n    \n     predictions = clf.predict(train_df.iloc[bayesian_val_index][predictors].values, num_iteration=clf.best_iteration)   \n    \n     score = metrics.roc_auc_score(train_df.iloc[bayesian_val_index][target].values, predictions)\n    \n     return score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"03f7d6981394e0e4b8286f0133c1e6c605e34c7c"},"cell_type":"code","source":"# # Bounded region of parameter space\nbounds_LGB = {\n     'num_leaves': (2, 5), \n     'min_data_in_leaf': (1, 10),  \n     'learning_rate': (0.03, 0.07),\n     'min_sum_hessian_in_leaf': (0.1, 0.5),    \n     'feature_fraction': (0.2, 0.5),\n     'lambda_l1': (0, 1), \n     'lambda_l2': (0, 1), \n     'min_gain_to_split': (0.1, 1.0),\n     'max_depth':(2,10),\n }\n\nfrom bayes_opt import BayesianOptimization\n\nLGB_BO = BayesianOptimization(LGB_bayesian, bounds_LGB, random_state=13)\n\nprint(LGB_BO.space.keys)\n\ninit_points = 10\nn_iter = 10\n\ntarget = 'Choice'\npredictors = train_df.columns.values.tolist()[1:]\n\nprint('-' * 130)\n\nwith warnings.catch_warnings():\n    warnings.filterwarnings('ignore')\n    LGB_BO.maximize(init_points=init_points, n_iter=n_iter, acq='ucb', xi=0.0, alpha=1e-6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"72e3b66470c897cd84e78559e692c76fafe29eb7"},"cell_type":"code","source":" LGB_BO.max\n## used to updat first 9 parameters following","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37d771dab16e3f74e7703dbe5c5176c6268ba214"},"cell_type":"code","source":"param_lgb = {\n        'feature_fraction': 0.4647875434283183,\n        'lambda_l1': 0.14487098904632512,\n        'lambda_l2': 0.9546002933329684,\n        'learning_rate': 0.050592093295320606,\n        'max_depth': int(round(7.696194993998026)),\n        'min_data_in_leaf': int(round(9.879507661608065)),\n        'min_gain_to_split': 0.7998292013880356,\n        'min_sum_hessian_in_leaf': 0.24962103361366683,\n        'num_leaves': int(round(2.854239951949671)),\n        'max_bin': 63,\n        'bagging_fraction': 1.0, \n        'bagging_freq': 5, \n        'save_binary': True,\n        'seed': 1965,\n        'feature_fraction_seed': 1965,\n        'bagging_seed': 1965,\n        'drop_seed': 1965,\n        'data_random_seed': 1965,\n        'objective': 'binary',\n        'boosting_type': 'gbdt',\n        'verbose': 1,\n        'metric': 'auc',\n        'is_unbalance': True,\n        'boost_from_average': False}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"520df7acc791010023256697c57a4501dd1b8f7d"},"cell_type":"code","source":"nfold = 20\n\nskf = StratifiedKFold(n_splits=nfold, shuffle=True, random_state=2019)\n\noof = np.zeros(len(fe_train))\npredictions = np.zeros((len(fe_test),nfold))\n\ni = 1\nfor train_index, valid_index in skf.split(fe_train, fe_train.Choice.values):\n    print(\"\\nfold {}\".format(i))\n\n    xg_train = lgb.Dataset(fe_train.iloc[train_index][predictors].values,\n                           label=fe_train.iloc[train_index][target].values,\n                           feature_name=predictors,\n                           free_raw_data = False\n                           )\n    xg_valid = lgb.Dataset(fe_train.iloc[valid_index][predictors].values,\n                           label=fe_train.iloc[valid_index][target].values,\n                           feature_name=predictors,\n                           free_raw_data = False\n                           )   \n\n    \n    clf = lgb.train(param_lgb, xg_train, 10000000, valid_sets = [xg_valid], verbose_eval=250, early_stopping_rounds = 100)\n    oof[valid_index] = clf.predict(fe_train.iloc[valid_index][predictors].values, num_iteration=clf.best_iteration) \n    \n    predictions[:,i-1] += clf.predict(fe_test[predictors], num_iteration=clf.best_iteration)\n    i = i + 1\n\nprint(\"\\n\\nCV AUC: {:<0.8f}\".format(metrics.roc_auc_score(fe_train.Choice.values, oof)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2e6334b0ff1cf58f0a3b2bac43138fe164077867"},"cell_type":"code","source":"lgb_bay = []\n\nfor i in range(len(predictions)):\n    lgb_bay.append(predictions[i][-1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a336e0fd5bb9ac5a7fbb43fb9fee324679c93aa7"},"cell_type":"code","source":"submission = pd.read_csv('../input/sample_predictions.csv')\nsubmission['Choice'] = lgb_bay\nsubmission.to_csv('sub.csv', index = False, header = True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}