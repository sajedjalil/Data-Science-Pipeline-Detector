{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# Let's cook model\n\nLet's combine what we've found so far.\n\n- [What are ingredients?](https://www.kaggle.com/rejasupotaro/what-are-ingredients) (Preprocessing & Feature extraction)\n- [Representations for ingredients](https://www.kaggle.com/rejasupotaro/representations-for-ingredients)\n\nSteps are below.\n\n1. Load dataset\n2. Remove outliers\n3. Preprocess\n4. Create model\n5. Check local CV\n6. Train model\n7. Check predicted values\n8. Make submission"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import json\nimport re\nimport unidecode\nimport numpy as np\nimport pandas as pd\nfrom collections import defaultdict\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import make_pipeline, make_union\nfrom sklearn.preprocessing import FunctionTransformer, LabelEncoder\nfrom tqdm import tqdm\ntqdm.pandas()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e71a483cf5522143e6accc7f89a246dd2b84eac"},"cell_type":"markdown","source":"## 1. Load dataset"},{"metadata":{"trusted":true,"_uuid":"68cf27ffa9750f359ebeae70edf914a389697444"},"cell_type":"code","source":"train = pd.read_json('../input/train.json')\ntest = pd.read_json('../input/test.json')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa9226059c24efcaa31d78667aaaa3b9f1644cd8"},"cell_type":"markdown","source":"## 2. Remove outliers\n\nI saw weird recipes in the dataset .\n\n- water => Japanese\n- butter => Indian\n- butter => French\n\nLet's filter such single-ingredient recipes and see how it goes."},{"metadata":{"trusted":true,"_uuid":"048849307c7233eb2bea8ea4f289f49e02a517b8"},"cell_type":"code","source":"train['num_ingredients'] = train['ingredients'].apply(len)\ntrain = train[train['num_ingredients'] > 1]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7cf37767200798f40405dcfecf862f9eabe2a89b"},"cell_type":"markdown","source":"## 3. Preprocess\n\nCurrently, the preprocess is like below.\n\n- convert to lowercase\n- remove hyphen\n- remove numbers\n- remove words which consist of less than 2 characters\n- lemmatize\n\nThis process can be better."},{"metadata":{"trusted":true,"_uuid":"11919def05f043269b6ab823636468f29ae1651f"},"cell_type":"code","source":"lemmatizer = WordNetLemmatizer()\ndef preprocess(ingredients):\n    ingredients_text = ' '.join(ingredients)\n    ingredients_text = ingredients_text.lower()\n    ingredients_text = ingredients_text.replace('-', ' ')\n    words = []\n    for word in ingredients_text.split():\n        if re.findall('[0-9]', word): continue\n        if len(word) <= 2: continue\n        if '’' in word: continue\n        word = lemmatizer.lemmatize(word)\n        if len(word) > 0: words.append(word)\n    return ' '.join(words)\n\nfor ingredient, expected in [\n    ('Eggs', 'egg'),\n    ('all-purpose flour', 'all purpose flour'),\n    ('purée', 'purée'),\n    ('1% low-fat milk', 'low fat milk'),\n    ('half & half', 'half half'),\n    ('safetida (powder)', 'safetida (powder)')\n]:\n    actual = preprocess([ingredient])\n    assert actual == expected, f'\"{expected}\" is excpected but got \"{actual}\"'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9004a952dab3fdbbec867ba73c424b8d6da9aa99"},"cell_type":"code","source":"train['x'] = train['ingredients'].progress_apply(preprocess)\ntest['x'] = test['ingredients'].progress_apply(preprocess)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"55996a4fb96f4e25b43e63ba32b3fc903f19d0f6"},"cell_type":"markdown","source":"I need to tune the parameters of TfidfVectorizer later."},{"metadata":{"trusted":true,"_uuid":"c363f1fa47d92507bc4ea8cfee0736dc4e567769"},"cell_type":"code","source":"vectorizer = make_pipeline(\n    TfidfVectorizer(sublinear_tf=True),\n    FunctionTransformer(lambda x: x.astype('float16'), validate=False)\n)\n\nx_train = vectorizer.fit_transform(train['x'].values)\nx_train.sort_indices()\nx_test = vectorizer.transform(test['x'].values)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"751a78d993338727709d7d3f763b87fcb87a6131"},"cell_type":"markdown","source":"Encode cuisines to numeric values using LabelEncoder."},{"metadata":{"trusted":true,"_uuid":"6d98153f94dbe4129d51040062ce3127ae6aeef5"},"cell_type":"code","source":"label_encoder = LabelEncoder()\ny_train = label_encoder.fit_transform(train['cuisine'].values)\ndict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"032ff9e67221ccceeff64075b56d3b707558d1c1"},"cell_type":"markdown","source":"## 4. Create model\n\nI've tried LogisticRegression, GaussianProcessClassifier, GradientBoostingClassifier, MLPClassifier, LGBMClassifier, SGDClassifier, Keras but SVC works better so far.\n\nI need to take a look at models and the parameters more closely."},{"metadata":{"trusted":true,"_uuid":"356b6fc5fff859f83e8a1e351d762ff87f31b935"},"cell_type":"code","source":"estimator = SVC(\n    C=80,\n    kernel='rbf',\n    gamma=1.7,\n    coef0=1,\n    cache_size=500,\n)\nclassifier = OneVsRestClassifier(estimator, n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ab16cdc4478786de2ab6882a9685e9210c362c17"},"cell_type":"markdown","source":"## 5. Check local CV\n\nTRUST YOUR LOCAL CV. TRUST YOUR LOCAL CV. TRUST YOUR LOCAL CV. I repeated 3 times since this is the most important thing.\n\nTry different prprocesses and parameters while looking at the local CV."},{"metadata":{"trusted":true,"_uuid":"b2192ec84d4932493840abfd135960309989183b"},"cell_type":"code","source":"%%time\nscores = cross_validate(classifier, x_train, y_train, cv=3)\nscores['test_score'].mean()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cfbec2ac72ebecf900ffcf6524562785422aa581"},"cell_type":"markdown","source":"## 6. Train model\n\nIf I become to be confident in the model, I train it with the whole train data for submission."},{"metadata":{"trusted":true,"_uuid":"02d2775c4878fd70a6345c1605ea7e3abe9cb9cb"},"cell_type":"code","source":"%%time\nclassifier.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"695d33e429e0ab905e2609752a5e3e29ce09d458"},"cell_type":"markdown","source":"## 7. Check predicted values\n\nCheck if the model fitted enough."},{"metadata":{"trusted":true,"_uuid":"47de4da03da0f0b817e99095dcb7be8974e531ee"},"cell_type":"code","source":"y_pred = label_encoder.inverse_transform(classifier.predict(x_train))\ny_true = label_encoder.inverse_transform(y_train)\n\nprint(f'accuracy score on train data: {accuracy_score(y_true, y_pred)}')\n\ndef report2dict(cr):\n    rows = []\n    for row in cr.split(\"\\n\"):\n        parsed_row = [x for x in row.split(\"  \") if len(x) > 0]\n        if len(parsed_row) > 0: rows.append(parsed_row)\n    measures = rows[0]\n    classes = defaultdict(dict)\n    for row in rows[1:]:\n        class_label = row[0]\n        for j, m in enumerate(measures):\n            classes[class_label][m.strip()] = float(row[j + 1].strip())\n    return classes\nreport = classification_report(y_true, y_pred)\npd.DataFrame(report2dict(report)).T","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"16513d3d20bffed6319671539f261e23eda0f245"},"cell_type":"markdown","source":"## 6. Make submission\n\nIt seems to be working well. Let's make a submission."},{"metadata":{"trusted":true,"_uuid":"3bdf327cf64fac66819ec6a2bc1ce0c549aed73f"},"cell_type":"code","source":"y_pred = label_encoder.inverse_transform(classifier.predict(x_test))\ntest['cuisine'] = y_pred\ntest[['id', 'cuisine']].to_csv('submission.csv', index=False)\ntest[['id', 'cuisine']].head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8c0cfa299375fdd5bb6e785d82198c8dd9e4d696"},"cell_type":"markdown","source":"That's it! Don't trust what I've done here. The score can be better. Please let me know if you find a better approach."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}