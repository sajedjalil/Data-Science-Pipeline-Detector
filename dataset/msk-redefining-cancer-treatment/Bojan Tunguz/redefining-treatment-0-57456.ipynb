{"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"pygments_lexer":"ipython3","codemirror_mode":{"version":3,"name":"ipython"},"name":"python","version":"3.6.1","file_extension":".py","mimetype":"text/x-python","nbconvert_exporter":"python"}},"cells":[{"source":"Donated to Cancer Treatment\n=============================","metadata":{"_execution_state":"idle","_cell_guid":"43c38433-6d17-4b1e-9f2a-bca4f692489a","collapsed":false,"_uuid":"ea7d07e39f8c6160c05767de0c4f7f6489ebe8df"},"outputs":[],"execution_count":null,"cell_type":"markdown"},{"source":"from sklearn import *\nimport sklearn\nimport pandas as pd\nimport numpy as np\nimport xgboost as xgb\n\ntrain = pd.read_csv('../input/training_variants')\ntest = pd.read_csv('../input/test_variants')\ntrainx = pd.read_csv('../input/training_text', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\ntestx = pd.read_csv('../input/test_text', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\n\ntrain = pd.merge(train, trainx, how='left', on='ID').fillna('')\ny = train['Class'].values\ntrain = train.drop(['Class'], axis=1)\n\ntest = pd.merge(test, testx, how='left', on='ID').fillna('')\npid = test['ID'].values\n\ndf_all = pd.concat((train, test), axis=0, ignore_index=True)\ndf_all['Gene_Share'] = df_all.apply(lambda r: sum([1 for w in r['Gene'].split(' ') if w in r['Text'].split(' ')]), axis=1)\ndf_all['Variation_Share'] = df_all.apply(lambda r: sum([1 for w in r['Variation'].split(' ') if w in r['Text'].split(' ')]), axis=1)\n\n#commented for Kaggle Limits\n#for i in range(56):\n#    df_all['Gene_'+str(i)] = df_all['Gene'].map(lambda x: str(x[i]) if len(x)>i else '')\n#    df_all['Variation'+str(i)] = df_all['Variation'].map(lambda x: str(x[i]) if len(x)>i else '')\n\n\ngen_var_lst = sorted(list(train.Gene.unique()) + list(train.Variation.unique()))\nprint(len(gen_var_lst))\ngen_var_lst = [x for x in gen_var_lst if len(x.split(' '))==1]\nprint(len(gen_var_lst))\ni_ = 0\n#commented for Kaggle Limits\n#for gen_var_lst_itm in gen_var_lst:\n#    if i_ % 100 == 0: print(i_)\n#    df_all['GV_'+str(gen_var_lst_itm)] = df_all['Text'].map(lambda x: str(x).count(str(gen_var_lst_itm)))\n#    i_ += 1\n\nfor c in df_all.columns:\n    if df_all[c].dtype == 'object':\n        if c in ['Gene','Variation']:\n            lbl = preprocessing.LabelEncoder()\n            df_all[c+'_lbl_enc'] = lbl.fit_transform(df_all[c].values)  \n            df_all[c+'_len'] = df_all[c].map(lambda x: len(str(x)))\n            df_all[c+'_words'] = df_all[c].map(lambda x: len(str(x).split(' ')))\n        elif c != 'Text':\n            lbl = preprocessing.LabelEncoder()\n            df_all[c] = lbl.fit_transform(df_all[c].values)\n        if c=='Text': \n            df_all[c+'_len'] = df_all[c].map(lambda x: len(str(x)))\n            df_all[c+'_words'] = df_all[c].map(lambda x: len(str(x).split(' '))) \n\ntrain = df_all.iloc[:len(train)]\ntest = df_all.iloc[len(train):]\n\nclass cust_regression_vals(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin):\n    def fit(self, x, y=None):\n        return self\n    def transform(self, x):\n        x = x.drop(['Gene', 'Variation','ID','Text'],axis=1).values\n        return x\n\nclass cust_txt_col(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin):\n    def __init__(self, key):\n        self.key = key\n    def fit(self, x, y=None):\n        return self\n    def transform(self, x):\n        return x[self.key].apply(str)\n\nprint('Pipeline...')\nfp = pipeline.Pipeline([\n    ('union', pipeline.FeatureUnion(\n        n_jobs = -1,\n        transformer_list = [\n            ('standard', cust_regression_vals()),\n            ('pi1', pipeline.Pipeline([('Gene', cust_txt_col('Gene')), ('count_Gene', feature_extraction.text.CountVectorizer(analyzer=u'char', ngram_range=(1, 8))), ('tsvd1', decomposition.TruncatedSVD(n_components=20, n_iter=25, random_state=12))])),\n            ('pi2', pipeline.Pipeline([('Variation', cust_txt_col('Variation')), ('count_Variation', feature_extraction.text.CountVectorizer(analyzer=u'char', ngram_range=(1, 8))), ('tsvd2', decomposition.TruncatedSVD(n_components=20, n_iter=25, random_state=12))])),\n            #commented for Kaggle Limits\n            #('pi3', pipeline.Pipeline([('Text', cust_txt_col('Text')), ('tfidf_Text', feature_extraction.text.TfidfVectorizer(ngram_range=(1, 2))), ('tsvd3', decomposition.TruncatedSVD(n_components=50, n_iter=25, random_state=12))]))\n        ])\n    )])\n\ntrain = fp.fit_transform(train); print(train.shape)\ntest = fp.transform(test); print(test.shape)\n\ny = y - 1 #fix for zero bound array\n\ndenom = 0\nfold = 1 #Change to 5, 1 for Kaggle Limits\nfor i in range(fold):\n    params = {\n        'eta': 0.03333,\n        'max_depth': 4,\n        'objective': 'multi:softprob',\n        'eval_metric': 'mlogloss',\n        'num_class': 9,\n        'seed': i,\n        'silent': True\n    }\n    x1, x2, y1, y2 = model_selection.train_test_split(train, y, test_size=0.18, random_state=i)\n    watchlist = [(xgb.DMatrix(x1, y1), 'train'), (xgb.DMatrix(x2, y2), 'valid')]\n    model = xgb.train(params, xgb.DMatrix(x1, y1), 1000,  watchlist, verbose_eval=50, early_stopping_rounds=100)\n    score1 = metrics.log_loss(y2, model.predict(xgb.DMatrix(x2), ntree_limit=model.best_ntree_limit), labels = list(range(9)))\n    print(score1)\n    #if score < 0.9:\n    if denom != 0:\n        pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit+80)\n        preds += pred\n    else:\n        pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit+80)\n        preds = pred.copy()\n    denom += 1\n    submission = pd.DataFrame(pred, columns=['class'+str(c+1) for c in range(9)])\n    submission['ID'] = pid\n    submission.to_csv('submission_xgb_fold_'  + str(i) + '.csv', index=False)\npreds /= denom\nsubmission = pd.DataFrame(preds, columns=['class'+str(c+1) for c in range(9)])\nsubmission['ID'] = pid\nsubmission.to_csv('submission_xgb.csv', index=False)","metadata":{"trusted":false,"_execution_state":"busy","_cell_guid":"e99beda1-d7bb-4de3-916c-327d1f2d87e2","_uuid":"92a8330e090e0074e540f721894351f10a6946d6"},"outputs":[],"execution_count":null,"cell_type":"code"},{"source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nplt.rcParams['figure.figsize'] = (7.0, 7.0)\nxgb.plot_importance(booster=model); plt.show()","metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"56eb3035-949a-4129-a374-fcaff5142b90","collapsed":false,"_uuid":"0003d9e63a4d80882fcd8e015cf764332dc29eff"},"outputs":[],"execution_count":null,"cell_type":"code"}],"nbformat":4}