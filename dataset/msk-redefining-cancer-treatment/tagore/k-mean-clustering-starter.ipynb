{"nbformat":4,"nbformat_minor":1,"metadata":{"language_info":{"mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py","version":"3.6.1","name":"python"},"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"}},"cells":[{"execution_count":null,"outputs":[],"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_cell_guid":"2e8b808f-541e-4e08-bcd6-73b07fe7b1ef","_uuid":"ce7137a8d6db88085716ee92ce3c15450b975278"}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"train = pd.read_csv('../input/training_text', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])\ntest = pd.read_csv('../input/test_text', sep=\"\\|\\|\", engine='python', header=None, skiprows=1, names=[\"ID\",\"Text\"])","metadata":{"_cell_guid":"0db562de-c292-4f20-b172-bd6c20b642bb","collapsed":true,"_uuid":"54cc5545eda637ce548b34c9933827e1f8a6042a"}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"train.head()","metadata":{"_cell_guid":"247a694b-a558-4742-8b26-388d66577e07","_uuid":"ee81c7d87619bc03d59058ca3b14031cfa69f8f9"}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"len(train['Text'][0].split())","metadata":{"_cell_guid":"9a38e0d0-3005-424f-b562-c8853494e8d7","_uuid":"79f11f9e5b34712517d44474e4f268ab6297522f"}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"train['len_text'] = train['Text'].apply(lambda x: len(x.split()))","metadata":{"_cell_guid":"f8894fd2-ffd6-4506-a73e-919e2348c43d","collapsed":true,"_uuid":"c0c7e296acb59bce74e16509eea132a559a7b2e0"}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"import seaborn as sns\nsns.distplot(train['len_text'])","metadata":{"_cell_guid":"1a5f70ce-79b8-46bd-8ec0-0fe5500d85c1","_uuid":"443ac72113c2bda0639cb68a064a1f0469585d5f"}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nstopwords = set(stopwords.words('english'))","metadata":{"_cell_guid":"c19d2d5b-f906-4ed9-a8b8-2ab49b5076da","collapsed":true,"_uuid":"c00a5c7236cdffa58c7b1f057cb0e78d84457d7c"}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"train['Text'] = train['Text'].apply(lambda x : \" \".join([word for word in x.lower().split() if word not in stopwords]))","metadata":{"_cell_guid":"129e11c4-5d5c-4774-87f7-05126c58e619","collapsed":true,"_uuid":"5e2c6b09fc5dd2c5f622b601532a210379fa965a"}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nvect = TfidfVectorizer()\nX = vect.fit_transform(train['Text'])\n#X = vect.fit_transform(train['Text'][1:100])","metadata":{"_cell_guid":"18667d6c-ebcd-4d4c-9e42-40d6d8e85a5e","collapsed":true,"_uuid":"158042f2cabcb737eba07af804c7cec8b4c38e1e"}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"%time\nfrom sklearn.cluster import KMeans\nkm = KMeans(n_clusters=10)\nkm.fit(X)","metadata":{"_cell_guid":"95def740-040e-410e-9bf4-959d8a82c2d6","_uuid":"d5f3d8ee5e9003935a560543a485a1390c384e2e"}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"# https://stackoverflow.com/questions/27889873/clustering-text-documents-using-scikit-learn-kmeans-in-python\nprint(\"Top terms per cluster:\")\norder_centroids = km.cluster_centers_.argsort()[:, ::-1]\nterms = vect.get_feature_names()\nfor i in range(10):\n    print (\"Cluster %d:\" % i)\n    for ind in order_centroids[i, :20]:\n        print(' %s' % terms[ind])\n    print()","metadata":{"_cell_guid":"1fef8195-179d-4b37-ba8c-a1c0f9b300fe","_uuid":"36a363ed43d8f656e45e1c2fb12a502059995f81"}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"train_var = pd.read_csv('../input/training_variants')\ntrain_df = pd.merge(train, train_var, on='ID')","metadata":{"collapsed":true}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"train_df[km.labels_ == 0].groupby('Class').size()","metadata":{}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"train_df[km.labels_ == 1].groupby('Class').size()","metadata":{}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"train_df[km.labels_ == 2].groupby('Class').size()","metadata":{}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"train_df[km.labels_ == 3].groupby('Class').size()","metadata":{}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"train_df[km.labels_ == 4].groupby('Class').size()","metadata":{}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"train_df[km.labels_ == 5].groupby('Class').size()","metadata":{}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"train_df[km.labels_ == 6].groupby('Class').size()","metadata":{}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"train_df[km.labels_ == 7].groupby('Class').size()","metadata":{}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"train_df[km.labels_ == 8].groupby('Class').size()","metadata":{}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"train_df[km.labels_ == 9].groupby('Class').size()","metadata":{}},{"source":"So we can see that K-mean is able to cluster some classes e.g. check classes corresponding to labels 6 and 7 above while cluster for label 9 is not so good. I suspect that if we remove noisy and common occuring words, clustering could improve further","cell_type":"markdown","metadata":{}},{"execution_count":null,"outputs":[],"cell_type":"code","source":"","metadata":{"collapsed":true}}]}