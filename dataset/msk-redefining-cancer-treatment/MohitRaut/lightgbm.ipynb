{"cells":[{"metadata":{"collapsed":true,"_cell_guid":"59f6c310-712e-4828-afde-f71f0a1f6c47","_uuid":"f5345ce5641a69b6c32a6d998bc71f46d796ffb0"},"source":"from sklearn.pipeline import Pipeline\nimport lightgbm as lgb \nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"30f410bb-6307-4c43-9163-ed64a69043ef","_uuid":"1d78e8270556f3d5c583a9dac7c18d12cc069746"},"source":"train_merge = train_var.merge(train_text,left_on=\"ID\",right_on=\"ID\")\ntrain_merge.head(5)\n\ntest_merge = test_var.merge(test_text,left_on=\"ID\",right_on=\"ID\")\ntest_merge.head(5)\n","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"10742081-0769-416a-8938-3c3bcfece1ce","_uuid":"db0678e2f60653c4e7a313003cdedc20d0ec117c"},"source":"import missingno as msno\n%matplotlib inline\nmsno.bar(train_merge)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"1b39a655-f253-4eb4-bd81-a772b9b199bd","_uuid":"303a77690ffd0c75cc4bbf2f8257e1d7b42aa539"},"source":"import missingno as msno\n%matplotlib inline\nmsno.bar(test_merge)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"4358f16e-4fdc-400b-8823-5bba4d0525eb","_uuid":"045207976f005559a8e358f20d8e950b00bf9f94"},"source":"import regex as re\ndef textClean(text):\n    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n    text = text.lower().split()\n    stops = {'so', 'his', 't', 'y', 'ours', 'herself', \n             'your', 'all', 'some', 'they', 'i', 'of', 'didn', \n             'them', 'when', 'will', 'that', 'its', 'because', \n             'while', 'those', 'my', 'don', 'again', 'her', 'if',\n             'further', 'now', 'does', 'against', 'won', 'same', \n             'a', 'during', 'who', 'here', 'have', 'in', 'being', \n             'it', 'other', 'once', 'itself', 'hers', 'after', 're',\n             'just', 'their', 'himself', 'theirs', 'whom', 'then', 'd', \n             'out', 'm', 'mustn', 'where', 'below', 'about', 'isn',\n             'shouldn', 'wouldn', 'these', 'me', 'to', 'doesn', 'into',\n             'the', 'until', 'she', 'am', 'under', 'how', 'yourself',\n             'couldn', 'ma', 'up', 'than', 'from', 'themselves', 'yourselves',\n             'off', 'above', 'yours', 'having', 'mightn', 'needn', 'on', \n             'too', 'there', 'an', 'and', 'down', 'ourselves', 'each',\n             'hadn', 'ain', 'such', 've', 'did', 'be', 'or', 'aren', 'he', \n             'should', 'for', 'both', 'doing', 'this', 'through', 'do', 'had',\n             'own', 'but', 'were', 'over', 'not', 'are', 'few', 'by', \n             'been', 'most', 'no', 'as', 'was', 'what', 's', 'is', 'you', \n             'shan', 'between', 'wasn', 'has', 'more', 'him', 'nor',\n             'can', 'why', 'any', 'at', 'myself', 'very', 'with', 'we', \n             'which', 'hasn', 'weren', 'haven', 'our', 'll', 'only',\n             'o', 'before'}\n    ## I ketp getting errors on importing the stopwords and I have no clue why\n    #stops = set(stopwords.words(\"English\"))\n    text = [w for w in text if not w in stops]    \n    text = \" \".join(text)\n    text = text.replace(\".\",\" \").replace(\",\",\" \")\n    return(text)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"90b0f3c3-1655-4cf5-b848-fb0f23ad6e74","_uuid":"20b344d2fe16af80286db816169e0afa6d810b43"},"source":"trainText = []\nfor it in train_merge['Text']:\n    newT = textClean(it)\n    trainText.append(newT)\ntestText = []\nfor it in test_merge['Text']:\n    newT = textClean(it)\n    testText.append(newT)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"378b78a6-dd89-4ccd-a00d-556ae21dbd5d","_uuid":"214796ca24fd056908f44116a9cc4e3c5a83fb26"},"source":"train_merge['Clean_text']=trainText\ntest_merge['Clean_text']=testText\n\ntrain_merge=train_merge.drop('ID',axis=1)\ntrain_merge=train_merge.drop('Text',axis=1)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"d7090c6e-6f63-4eae-a040-3e68350110e4","_uuid":"245f6820aa54f7006845109a7ee44e558681b1cb"},"source":"test_merge=test_merge.drop(['ID','Text'],axis=1)\ntest_merge.head(5)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"f86bd84d-7a6b-44ad-a7ef-e29993cd2532","_uuid":"a19a3ad84fc8138ab38a3dbbf458ef6838827425"},"source":"from sklearn.model_selection import train_test_split\ntrain ,test = train_test_split(train_merge,test_size=0.2) \nnp.random.seed(0)\ntrain.head(5)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"56d52dee-4bee-46cc-a156-a8784ac05112","_uuid":"ec261955a1f0f98725e1105748fb3a8b22cff6dd"},"source":"x_train = train['Clean_text'].values\nx_test = test['Clean_text'].values\ny_train = train['Class'].values\ny_test = test['Class'].values","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"1fa6722d-c4d5-436d-a140-cefb15af8068","_uuid":"51e9536834c8f3d3ac7a87fd18053d7d92b74bf8"},"source":"def my_tokenizer(X):\n    newlist = []\n    for alist in X:\n        newlist.append(alist[0].split(' '))\n    return newlist\n\nmaxFeats=500 \n\ncvec = CountVectorizer(min_df=5, ngram_range=(1,3), max_features=maxFeats, \n                       strip_accents='unicode',\n                       lowercase =True, analyzer='word', token_pattern=r'\\w+',\n                       stop_words = 'english',tokenizer=my_tokenizer)\ntfidf = TfidfVectorizer(min_df=5, max_features=maxFeats, ngram_range=(1,3),\n                        strip_accents='unicode',\n                        lowercase =True, analyzer='word', token_pattern=r'\\w+',\n                        use_idf=True, smooth_idf=True, sublinear_tf=True, \n                        stop_words = 'english')","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"293ba359-4240-4f6d-9e55-b8887349aed7","_uuid":"9ccdcde5bc45d209c82c5c03df5264c7f9252440"},"source":"y_test=y_test-1\ny_train=y_train-1\n\ntrain_tran=tfidf.fit_transform(x_train)\ntest_tran=tfidf.fit_transform(x_test)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"9e9debbe-5453-4515-861b-e1d143032db4","_uuid":"bcd3cdf20b9710e81c80f71d4910031004579f7a"},"source":"d_train = lgb.Dataset(train_tran, label=y_train)\nd_val = lgb.Dataset(test_tran, label=y_test)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"6b33fc21-3279-41dc-97a1-4a0eca0fb355","_uuid":"f7e1b5ca5f7f6af1825bad9c900cb17fd1292fb6"},"source":"parms = {'task': 'train',\n    'boosting_type': 'gbdt',\n    'objective': 'multiclass',\n    'num_class': 9,\n    'metric': {'multi_logloss'},\n    'learning_rate': 0.05, \n    'max_depth': 5,\n    'num_iterations': 400, \n    'num_leaves': 95, \n    'min_data_in_leaf': 60, \n    'lambda_l1': 1.0,\n    'feature_fraction': 0.8, \n    'bagging_fraction': 0.8, \n    'bagging_freq': 5}\n\nrnds = 500\nmod = lgb.train(parms, train_set=d_train, num_boost_round=rnds,\n               valid_sets=[d_val], valid_names=['dval'], verbose_eval=20,early_stopping_rounds=20)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"a459a0af-b10e-4c57-9014-6f044ad615df","_uuid":"8be4b51172c492f273cf684a7b7f8dcfe77688bf"},"source":"import matplotlib.pyplot as plt\n%matplotlib inline\nlgb.plot_importance(mod, max_num_features=30, figsize=(14,10))","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"6c0e8f10-068a-423c-b1cf-d14ee8f80ffc","_uuid":"8d8f3997207e5026a9fe4d0fa82491ebfac23635"},"source":"test_data=test_merge['Clean_text']\ntest_data=tfidf.fit_transform(test_data)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"06f66f9e-ca59-4ed9-afdd-882e7d4b7059","_uuid":"d942b3ceccbd18738678c6f7c5b859658b7d745b"},"source":"pred = mod.predict(test_data)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"c5223024-d310-41fc-9418-2d704329dc4e","_uuid":"31deeb350a6f0a2a1fff902622fdbca2437b2eb1"},"source":"pred1=pred\npred1=(pred1 == pred1.max(axis=1)[:,None]).astype(int)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"9381f289-105f-4c51-b151-680d02940b17","_uuid":"e101b8236a92e10f7084c8ce5ae0b9d80059f55e"},"source":"submission=pd.DataFrame(pred1)\nsubmission['ID']=test_var['ID']\nsubmission.columns=[\"Class1\",\"Class2\",\"Class3\",\"Class4\",\"Class5\",\"Class6\",\"Class7\",\"Class8\",\"Class9\",\"ID\"]\nsubmission.head(5)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"b1468149-ec1f-4cbc-998b-9a2ffe929cff","_kg_hide-output":true,"_uuid":"e2d7a0b40fd668a4e0da4cbf6f94f07c105f92e3"},"source":"submission.to_csv('submission1.csv', index=False)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"8f74a113-b61c-413d-a640-91890bb7802d","_uuid":"b0da05484caab02d5934761886974756a2026be6"},"source":"import pandas as pd\ntemp=pd.read_csv(\"../input/submissionFile\")","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"_cell_guid":"e7a9d102-08cf-40b3-9f88-c479857ee91f","_uuid":"a3c6ee2990885372a4fee117afb6a708885446c2"},"source":"temp.to_csv(\"../output/result.csv\",index=False)","execution_count":null,"cell_type":"code","outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"01ee99cd-6a93-4114-8b70-fac21f40150e","_uuid":"eeae391e634639de8e25cf656df87949afcf9635"},"source":"","execution_count":null,"cell_type":"code","outputs":[]}],"nbformat":4,"metadata":{"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","name":"python","codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","version":"3.6.1"},"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"}},"nbformat_minor":1}