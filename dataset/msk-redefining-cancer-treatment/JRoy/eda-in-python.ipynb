{"metadata":{"language_info":{"nbconvert_exporter":"python","version":"3.6.1","file_extension":".py","pygments_lexer":"ipython3","mimetype":"text/x-python","name":"python","codemirror_mode":{"name":"ipython","version":3}},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"}},"nbformat_minor":2,"cells":[{"metadata":{"_execution_state":"idle","collapsed":false,"_cell_guid":"78013b3d-31ee-4ca2-882e-05f79cb47c12","_uuid":"67df4611a41a5d4e3a009e0128a9d53e08975db2"},"outputs":[],"cell_type":"markdown","source":"**Analyzing and cleaning up the data**","execution_count":null},{"metadata":{"trusted":false,"_execution_state":"idle","collapsed":true,"_cell_guid":"b7e107d8-e327-4e6d-b20b-3cd08b16037a","_uuid":"4ce2f30af2a531d7c115468b65881ef25efa651a"},"outputs":[],"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom bs4 import BeautifulSoup   \nimport re\nimport seaborn as sns\nfrom nltk.corpus import stopwords # Import the stop word list\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import svm\nfrom sklearn import preprocessing","execution_count":19},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"67fe0067-f789-4ad6-87d5-177d6b05d12f","_uuid":"1d1718f391ddcdfce813807aed3fe8d055988ce4"},"outputs":[],"cell_type":"code","source":"training_variants = pd.read_csv('../input/training_variants')\ntest_variants = pd.read_csv('../input/test_variants')\ntraining_text = pd.read_csv('../input/training_text',sep='\\|\\|',skiprows=1,engine='python',names=[\"ID\",\"text\"])\ntest_text = pd.read_csv('../input/test_text',sep='\\|\\|',skiprows=1,engine='python',names=[\"ID\",\"text\"])","execution_count":20},{"metadata":{"trusted":false,"scrolled":true,"_cell_guid":"4d6b2787-af0c-4ea9-a3f2-33557f388c11","_execution_state":"idle","_uuid":"682122b889d2f29172d953220c11c98a6cf5c941"},"outputs":[],"cell_type":"code","source":"training_text.head()","execution_count":21},{"metadata":{"trusted":false,"scrolled":false,"_cell_guid":"7da7c13a-d382-4c85-b705-0ec433335cc3","_execution_state":"idle","_uuid":"950036c1c7375bc56190e838bce771374dad50ff"},"outputs":[],"cell_type":"code","source":"training_variants.head()","execution_count":22},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"2aaf1b5c-c4f7-486e-866b-6d05f8bd74ea","_uuid":"3ea064978b5bd4b60eae3dbacc4a7206b56491dd"},"outputs":[],"cell_type":"code","source":"#First row\ntraining_text[\"text\"][0].split('.')[0:3]","execution_count":26},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"cb6a67a3-9377-40c0-b7b6-188f3b06f6f0","_uuid":"f16019d70f252c2d93bbec4b62cd59df22760def"},"outputs":[],"cell_type":"code","source":"training_variants.size","execution_count":27},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"6a80a81a-bbc7-4d32-ab79-27f33af97bb3","_uuid":"3c3e215176beeb8507293aa1bb46daf31a80842b"},"outputs":[],"cell_type":"code","source":"test_variants.size","execution_count":28},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"926329be-264a-4658-b0f5-6c414b93306f","_uuid":"e0ffed230c8e41dad7e302e93ef77aba918aca04"},"outputs":[],"cell_type":"code","source":"sns.set(style=\"whitegrid\", color_codes=True)\n\nplt.figure(figsize=(12,8))\nax = sns.countplot(x=\"Class\", data=training_variants,palette=\"GnBu_d\")\nplt.ylabel('Frequency')\nplt.xlabel('Class')\nplt.title('Frequency distribution of classes')\nplt.show()","execution_count":29},{"metadata":{"trusted":false,"_execution_state":"idle","collapsed":true,"_cell_guid":"b46cf36b-760a-4df0-b78c-5a93e5b5ab5b","_uuid":"466c5692818be6920f29f6abc9787728c4d26e7b"},"outputs":[],"cell_type":"code","source":"# Unique Genes\nunique_genes = list(training_variants.Gene.unique())","execution_count":31},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"e87516d8-6de3-4651-9990-b88705ffcc43","_uuid":"de9839de0397a368d9454aac8e164f77aeb8e22b"},"outputs":[],"cell_type":"code","source":"len(unique_genes)","execution_count":32},{"metadata":{"trusted":false,"_execution_state":"idle","collapsed":true,"_cell_guid":"7e67e6ba-df9a-4822-a6ce-d0bdbfe5a0ff","_uuid":"712ff54e5bdc460e3e8e7b208645db61a03ee65f"},"outputs":[],"cell_type":"code","source":"# Unique variation\nunique_variation = list(training_variants.Variation.unique())","execution_count":33},{"metadata":{"trusted":false,"scrolled":true,"_cell_guid":"e7644b3b-4151-4ec8-a2ca-aca0f1b4d1bf","_execution_state":"idle","_uuid":"1956b4c7d0ec3e93075e0430853b34e98fe36010"},"outputs":[],"cell_type":"code","source":"len(unique_variation)","execution_count":34},{"metadata":{"trusted":false,"_execution_state":"idle","collapsed":true,"_cell_guid":"cf2ba918-704d-44fb-867d-b9983a7ae5fc","_uuid":"c152a3bcb2456d40b0919bed99257ff426bc000b"},"outputs":[],"cell_type":"code","source":"num_classes = 9","execution_count":35},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"b2702322-404f-4788-a932-c8a38ed624a2","_uuid":"1c4d7c273ee5bedb33f71b0f2b50a1d0c2d3d6a5"},"outputs":[],"cell_type":"code","source":"y = training_variants[\"Class\"]","execution_count":36},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"bafdd30a-066e-488b-a075-77d60a2cf866","_uuid":"04d55e4147696321ee17a857e277bbac66680b3b"},"outputs":[],"cell_type":"code","source":"#training_variants=training_variants.drop(['Class'], axis=1)","execution_count":76},{"metadata":{"_execution_state":"idle","collapsed":false,"_uuid":"9f05cf9b6eb673631e1e97046d964d150f0c4896"},"outputs":[],"cell_type":"markdown","source":"**Cleaning the words to remove stop words and non relevant characters**","execution_count":null},{"metadata":{"trusted":false,"_execution_state":"idle","collapsed":true,"_cell_guid":"cd5888d1-2213-42ce-8fa0-6dc6bb358335","_uuid":"b5824f8f23a41e7801a6200ec45ae4d4252f892d"},"outputs":[],"cell_type":"code","source":"def cleaning_text( text ):\n    # 1. Remove non-letters        \n    letters_only = re.sub(\"[^a-zA-Z0-9.]\", \" \", text) \n    #\n    # 2. Convert to lower case, split into individual words\n    words = letters_only.lower().split()                             \n    #\n    # 3. stopwords\n    stops = set(stopwords.words(\"english\"))     \n    ls = ['no','not','nor','neither','none','negative','never']             \n    # \n    # 4. Remove stop words\n    meaningful_words = [w for w in words if (not w in stops or w in ls)]   \n    #print(meaningful_words)\n    #\n    # 5. Join the words back into one string separated by space, \n    # and return the result.\n    return( \" \".join( meaningful_words ))  ","execution_count":42},{"metadata":{"trusted":false,"_execution_state":"idle","collapsed":true,"_cell_guid":"b3e28108-6b6b-4685-ad52-e89b24b114ab","_uuid":"1fd5cab0c917220895a20c54de46ea34b6ee92ab"},"outputs":[],"cell_type":"code","source":"clean_text = cleaning_text( training_text[\"text\"][0] )","execution_count":43},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"d9df1bdf-6fb5-4bab-a564-93a534c4a432","_uuid":"8a14ecea3efad626b22bcd55336055fea3cbaa9a"},"outputs":[],"cell_type":"code","source":"clean_text.split('.')[0:3]","execution_count":44},{"metadata":{"trusted":false,"_execution_state":"idle","collapsed":true,"_cell_guid":"b2c3235d-c098-45d5-9ab9-e509bae1e0ce","_uuid":"b46b2dddd1f3c9ceebca23c97dbafc24d20f6dca"},"outputs":[],"cell_type":"code","source":"# Initialize an empty list to hold the clean text\nclean_train_text = []\nnum_reviews = training_text[\"text\"].size\nfor i in range(0, num_reviews):\n    try:\n        clean_train_text.append( cleaning_text( training_text[\"text\"][i] ))\n    except KeyError:\n        clean_train_text.append(\" 0 \")\n        print(\"Value not found\", i)","execution_count":47},{"metadata":{"trusted":false,"_execution_state":"idle","collapsed":true,"_cell_guid":"ae79c26c-090d-48c4-8e90-b5930f0f7663","_uuid":"74d78c5dde45b608d8c0dcb81d35654d6049be50"},"outputs":[],"cell_type":"code","source":"# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n# bag of words tool.  \nvectorizer = CountVectorizer(analyzer = \"word\",   \n                             tokenizer = None,    \n                             preprocessor = None, \n                             stop_words = None,   \n                             max_features = 100000) \n\n# fit_transform() does two functions: First, it fits the model\n# and learns the vocabulary; second, it transforms our training data\n# into feature vectors. The input to fit_transform should be a list of \n# strings.\ntrain_data_features = vectorizer.fit_transform(clean_train_text)","execution_count":49},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"50c31eb7-179b-46a9-bd2f-b61cf1b5b703","_uuid":"293c952945f95aa56f4d605234a234627cb54d1f"},"outputs":[],"cell_type":"code","source":"train_data_features.shape","execution_count":50},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"ef55b49c-21a8-4daa-8739-25f6d06da592","_uuid":"16fdb6dde027f549a24944f823cbc8edec0a1704"},"outputs":[],"cell_type":"code","source":"vocab = vectorizer.get_feature_names()\n#print( vocab)","execution_count":51},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"31ae0e9d-278a-4530-92b9-1c2787665c24","_uuid":"a647108d0fed54e008c069a3c6ebb6f506c379c8"},"outputs":[],"cell_type":"code","source":"genes = training_variants[training_variants.columns[1:2]]\n#print(genes)\nvariations = training_variants[training_variants.columns[2:3]]\n#print(variations)\n\n###   Label encoding for Gene column   ###\n\nlabelEncoderG = preprocessing.LabelEncoder()\nlabelEncoderG = labelEncoderG.fit(genes)\n#print(labelEncoderG.classes_)\ngenes_array = labelEncoderG.transform(genes)\n#print(genes_array)","execution_count":52},{"metadata":{"trusted":false,"_execution_state":"idle","_cell_guid":"dd1c8ad5-77e2-4013-92ec-bce65da43e56","_uuid":"765a47fb250a748ccd7969483422efb29a97489b"},"outputs":[],"cell_type":"code","source":" ###   Label encoding for Variation column   ###\n    \nlabelEncoderV = preprocessing.LabelEncoder()\nlabelEncoderV = labelEncoderV.fit(variations)\n#print(labelEncoderV.classes_)\nvariations_array = labelEncoderV.transform(variations)\n#print(variations_array)","execution_count":53}],"nbformat":4}