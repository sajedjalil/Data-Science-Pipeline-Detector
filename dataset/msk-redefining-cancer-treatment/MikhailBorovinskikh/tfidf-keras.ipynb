{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"version":"3.6.1","pygments_lexer":"ipython3","nbconvert_exporter":"python","name":"python","file_extension":".py","mimetype":"text/x-python"}},"nbformat_minor":1,"cells":[{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"40e61d60-c327-4480-b6e6-a6bc88bc10b3","_uuid":"a2cf61f8bd08737bf0db912aa6640be877524a19","collapsed":true},"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"521c959d-ac20-4611-8f86-3529c7006588","_uuid":"5dfde467ad051690b3c42c635ae61403759d9297","collapsed":true},"source":"%matplotlib inline\nimport pandas as pd\nimport numpy as np\n\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import log_loss, accuracy_score\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_extraction.text import TfidfTransformer\nimport nltk\nimport re\nfrom nltk.corpus import stopwords\nimport os","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"239282a6-4e44-4af3-8b1d-b85ff689f7e7","_uuid":"02c1e884ae657acf6a29f2f0962d9a7560deca04","collapsed":true},"source":"from random import shuffle\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, LSTM, Embedding, Input, RepeatVector\nfrom keras.utils import np_utils\nfrom keras.preprocessing import text, sequence","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"7a6ae9e0-8b2d-4f49-8713-964f364fc286","_uuid":"29209129b5b4388af57f4fbb3a58244ff8dea001","collapsed":true},"source":"df_train_txt = pd.read_csv('../input/training_text', sep='\\|\\|', header=None, skiprows=1, names=[\"ID\",\"Text\"])\ndf_train_var = pd.read_csv('../input/training_variants')\ndf_test_txt = pd.read_csv('../input/test_text', sep='\\|\\|', header=None, skiprows=1, names=[\"ID\",\"Text\"])\ndf_test_var = pd.read_csv('../input/test_variants')\ntraining_merge_df = df_train_var.merge(df_train_txt,left_on=\"ID\",right_on=\"ID\")\ntesting_merge_df = df_test_var.merge(df_test_txt,left_on=\"ID\",right_on=\"ID\")","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"9e5b667a-d686-41f8-8710-c94d0eec22f7","_uuid":"258e66236cc49724a017ff27959ebdd27ffe1a6b","collapsed":true},"source":"def textClean(text):\n    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n    text = text.lower().split()\n    stops = {'so', 'his', 't', 'y', 'ours', 'herself', \n             'your', 'all', 'some', 'they', 'i', 'of', 'didn', \n             'them', 'when', 'will', 'that', 'its', 'because', \n             'while', 'those', 'my', 'don', 'again', 'her', 'if',\n             'further', 'now', 'does', 'against', 'won', 'same', \n             'a', 'during', 'who', 'here', 'have', 'in', 'being', \n             'it', 'other', 'once', 'itself', 'hers', 'after', 're',\n             'just', 'their', 'himself', 'theirs', 'whom', 'then', 'd', \n             'out', 'm', 'mustn', 'where', 'below', 'about', 'isn',\n             'shouldn', 'wouldn', 'these', 'me', 'to', 'doesn', 'into',\n             'the', 'until', 'she', 'am', 'under', 'how', 'yourself',\n             'couldn', 'ma', 'up', 'than', 'from', 'themselves', 'yourselves',\n             'off', 'above', 'yours', 'having', 'mightn', 'needn', 'on', \n             'too', 'there', 'an', 'and', 'down', 'ourselves', 'each',\n             'hadn', 'ain', 'such', 've', 'did', 'be', 'or', 'aren', 'he', \n             'should', 'for', 'both', 'doing', 'this', 'through', 'do', 'had',\n             'own', 'but', 'were', 'over', 'not', 'are', 'few', 'by', \n             'been', 'most', 'no', 'as', 'was', 'what', 's', 'is', 'you', \n             'shan', 'between', 'wasn', 'has', 'more', 'him', 'nor',\n             'can', 'why', 'any', 'at', 'myself', 'very', 'with', 'we', \n             'which', 'hasn', 'weren', 'haven', 'our', 'll', 'only',\n             'o', 'before'}\n    text = [w for w in text if not w in stops]    \n    text = \" \".join(text)\n    text = text.replace(\".\",\" \").replace(\",\",\" \")\n    return(text)","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"efc7c780-2db2-47e8-9676-02a31004b238","_uuid":"56a8d29ef45b876959b9c8bfe06966cd0cbdf6df","collapsed":true},"source":"trainText = []\nfor it in training_merge_df['Text']:\n    newT = textClean(it)\n    trainText.append(newT)\ntestText = []\nfor it in testing_merge_df['Text']:\n    newT = textClean(it)\n    testText.append(newT)","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"9ac7d2ec-9f50-4050-9c88-4ef0573f7265","_uuid":"4f3c715d075d41e9bb62300dd870b92d09f6a550","collapsed":true},"source":"%%time\ncount_vectorizer = TfidfVectorizer(ngram_range=(1,1), max_df=0.65,\n                        tokenizer=nltk.word_tokenize,\n                        strip_accents='unicode',\n                        lowercase =True, analyzer='word', token_pattern=r'\\w+',\n                        use_idf=True, smooth_idf=True, sublinear_tf=False, \n                        stop_words = 'english')\nbag_of_words = count_vectorizer.fit_transform(trainText)\nprint(bag_of_words.shape)\nX_test = count_vectorizer.transform(testText)\nprint(X_test.shape)","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"7dc7750b-b3da-409c-ac6d-5a59625980bb","_uuid":"9e836bc8bfc202fab905c38b8b9e0b3b00861ac6","collapsed":true},"source":"%%time\ntransformer = TfidfTransformer(use_idf=True, smooth_idf=True, sublinear_tf=False)\ntransformer_bag_of_words = transformer.fit_transform(bag_of_words)\nX_test_transformer = transformer.transform(X_test)\nprint (transformer_bag_of_words.shape)\nprint (X_test_transformer.shape)","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"38ed39a8-24db-476b-8679-9f984e6af368","_uuid":"cf843f01a7eb9923178e57758c8ce947b6253016","collapsed":true},"source":"train_y = training_merge_df['Class'].values\nlabel_encoder = LabelEncoder()\nlabel_encoder.fit(train_y)\nencoded_y = np_utils.to_categorical((label_encoder.transform(train_y)))","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"77becdcc-db80-48d8-9b9c-e07ece3e156e","_uuid":"e6a37e8a4d097ee38bbecc70ce8530463384b05f","collapsed":true},"source":"one_hot_gene = pd.get_dummies( np.hstack((training_merge_df['Gene'].values,testing_merge_df['Gene'].values)))\none_hot_variation = pd.get_dummies( np.hstack((training_merge_df['Variation'].values,testing_merge_df['Variation'].values)))","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"f67381a9-1abc-44ae-8ed0-b46ba9f5ca9f","_uuid":"f9f6c055505d4b7716c8112f799464305488eaea","collapsed":true},"source":"from scipy.sparse import hstack","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"4f7b3853-3ccb-4ede-a985-5022afc5f2fb","_uuid":"b06ebb12eaa431f068eda0669d5321b106a094a1","collapsed":true},"source":"# define model\ndef baseline_model():\n    model = Sequential()\n    model.add(Dense(512, input_dim=transformer_bag_of_words.shape[1]+one_hot_gene.shape[1]+one_hot_variation.shape[1], init='normal', activation='relu'))\n    model.add(Dropout(0.15))\n    model.add(Dense(512, init='normal', activation='relu'))\n    model.add(Dropout(0.15))\n    model.add(Dense(512, init='normal', activation='relu'))\n    model.add(Dropout(0.15))\n    model.add(Dense(512, init='normal', activation='relu'))\n    model.add(Dense(256, init='normal', activation='relu'))\n    model.add(Dense(64, init='normal', activation='relu'))\n    model.add(Dense(9, init='normal', activation=\"softmax\"))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_crossentropy'])\n    return model\n\n\nestimator = KerasClassifier(build_fn=baseline_model, epochs=15, batch_size=64)\nestimator.fit(hstack((one_hot_gene[:training_merge_df.shape[0]], one_hot_variation[:training_merge_df.shape[0]], transformer_bag_of_words)).todense(), encoded_y, validation_split=0.05)","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"dfecfcf3-93f7-430d-8eb8-ebce45bf0d2e","_uuid":"03d028f81d04cc607423abd93ca3d0311e78da24","collapsed":true},"source":"%%time\nresults = estimator.predict_proba(hstack((one_hot_gene[training_merge_df.shape[0]:], one_hot_variation[training_merge_df.shape[0]:], X_test_transformer)).todense())","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"03a4ed07-d6a1-40da-a052-71559ef33dcb","_uuid":"1216aec8bedc4731cfcebccc3e63486f26a07174","collapsed":true},"source":"results_df = pd.read_csv(\"../input/submissionFile\")\nfor i in range(1,10):\n    results_df['class'+str(i)] = results.transpose()[i-1]\nresults_df.to_csv('output_tf_keras_version2',sep=',',header=True,index=None)\nresults_df.head()","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"25b23162-676d-441d-9af6-bc22e6ce7603","_uuid":"d98e95abde257056e9d36eee0e7c16c19efb89e6","collapsed":true},"source":"","outputs":[]},{"execution_count":null,"cell_type":"code","metadata":{"_cell_guid":"47e2b727-254e-42f8-89d8-8843388196b8","_uuid":"3e46176fd2249e84de710ec1cc1be7ca8742c87a","collapsed":true},"source":"","outputs":[]}],"nbformat":4}