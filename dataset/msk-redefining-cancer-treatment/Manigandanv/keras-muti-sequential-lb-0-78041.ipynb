{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.1","nbconvert_exporter":"python","pygments_lexer":"ipython3","mimetype":"text/x-python","file_extension":".py","codemirror_mode":{"name":"ipython","version":3}}},"cells":[{"metadata":{"_cell_guid":"3de21bc8-c1e6-40d0-ba79-705289367705","_execution_state":"idle","_uuid":"5acb21da6f1c23e6a1657eeac066011c774426cd"},"source":"Keras multi sequential model i.e 14 models merged to main model to produce output","cell_type":"markdown"},{"execution_count":null,"metadata":{"collapsed":true,"_cell_guid":"5601707e-fe0f-4220-99f8-f9d0b9025d2c","_execution_state":"busy","_uuid":"bcf5cd8c75a179306435200e3b7a8609d9760af2"},"source":"from sklearn import *\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.utils import np_utils\nfrom keras.layers import Dropout,Merge\nfrom sklearn.preprocessing import LabelEncoder\ntrain = pd.read_csv(\"../input/training_variants\")\ntest = pd.read_csv(\"../input/test_variants\")\ntrainx = pd.read_csv(\"../input/training_text\", sep=\"\\|\\|\", engine=\"python\", skiprows=1, names=[\"ID\", \"Text\"])\ntestx = pd.read_csv(\"../input/test_text\", sep=\"\\|\\|\", engine=\"python\", skiprows=1, names=[\"ID\", \"Text\"])\ntrain = pd.merge(train, trainx, how='left', on='ID')\ny = train['Class'].values\ntrain = train.drop('Class', axis=1)\ntest = pd.merge(test, testx, how='left', on='ID')\npid = test['ID'].values\nall_data=np.concatenate((train,test),axis=0)\nall_data=pd.DataFrame(all_data)\nall_data.columns=['ID','Gene','Variation','Text']\nsent=all_data['Text']\nvect=TfidfVectorizer(stop_words='english')\nsent_vectors=vect.fit_transform(sent)\nsvd=TruncatedSVD(200)\nsent_vectors1=svd.fit_transform(sent_vectors)\nsent_vectors2=svd.fit_transform(sent_vectors)\nsent_vectors3=svd.fit_transform(sent_vectors)\nsent_vectors4=svd.fit_transform(sent_vectors)\nsent_vectors5=svd.fit_transform(sent_vectors)\nsent_vectors6=svd.fit_transform(sent_vectors)\nsent_vectors7=svd.fit_transform(sent_vectors)\nsent_vectors8=svd.fit_transform(sent_vectors)\nsent_vectors9=svd.fit_transform(sent_vectors)\nsent_vectors10=svd.fit_transform(sent_vectors)\nsent_vectors11=svd.fit_transform(sent_vectors)\nsent_vectors12=svd.fit_transform(sent_vectors)\nsent_vectors13=svd.fit_transform(sent_vectors)\nsent_vectors14=svd.fit_transform(sent_vectors)\ndef baseline_model():\n    model=Sequential()\n    model.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n    model.add(Dropout(0.25))\n    lower_model=Sequential()\n    lower_model.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n    lower_model.add(Dropout(0.25))\n    lower_model1=Sequential()\n    lower_model1.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n    lower_model1.add(Dropout(0.25))\n    lower_model2=Sequential()\n    lower_model2.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n    lower_model2.add(Dropout(0.25))\n    lower_model3=Sequential()\n    lower_model3.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n    lower_model3.add(Dropout(0.25))\n    lower_model4=Sequential()\n    lower_model4.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n    lower_model4.add(Dropout(0.25))\n    lower_model5=Sequential()\n    lower_model5.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n    lower_model5.add(Dropout(0.25))\n    lower_model6=Sequential()\n    lower_model6.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n    lower_model6.add(Dropout(0.25))\n    lower_model7=Sequential()\n    lower_model7.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n    lower_model7.add(Dropout(0.25))\n    lower_model8=Sequential()\n    lower_model8.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n    lower_model8.add(Dropout(0.25))\n    lower_model9=Sequential()\n    lower_model9.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n    lower_model9.add(Dropout(0.25))\n    lower_model10=Sequential()\n    lower_model10.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n    lower_model10.add(Dropout(0.25))\n    lower_model11=Sequential()\n    lower_model11.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n    lower_model11.add(Dropout(0.25))\n    lower_model12=Sequential()\n    lower_model12.add(Dense(1024,input_dim=200,init='normal',activation='relu'))\n    lower_model12.add(Dropout(0.25))\n    merged_model=Merge([model,lower_model,lower_model1,lower_model2,lower_model3,lower_model4,lower_model5,lower_model6,lower_model7,lower_model8,lower_model9,lower_model10,lower_model11,lower_model12],mode='concat')\n    final_model=Sequential()\n    final_model.add(merged_model)\n    final_model.add(Dense(9,init='normal',activation='softmax'))\n    final_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n    return final_model\nencoder=LabelEncoder()\nencoder.fit(y)\nencoded_y=encoder.transform(y)\ndummy_y=np_utils.to_categorical(encoded_y)\nprint(dummy_y.shape)","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"collapsed":true},"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\nsubmission = pd.read_csv('../input/stage2_sample_submission.csv')\nstage1_test = pd.read_csv('../input/test_variants')\nstage2_test = pd.read_csv('../input/stage2_test_variants.csv')\nstage1_solution = pd.read_csv('../input/stage1_solution_filtered.csv')\n\nstage1_solution = stage1_solution.merge(stage1_test, how = 'left', on = 'ID')\n\nstage2_test.merge(\n        stage1_solution.drop('ID', axis = 1), \n        how = 'left', \n        on = ['Gene', 'Variation'])\\\n    .drop(['Gene', 'Variation'], axis = 1)\\\n    .fillna(1)\\\n    .to_csv('submission.csv', index = False)","cell_type":"code","outputs":[]},{"execution_count":null,"metadata":{"_cell_guid":"7ccea308-bbac-4fd8-a972-fcb33d2f8a73","_execution_state":"idle","_uuid":"e58b682573faff0a67597ca9a8ccece63f4cd04c"},"source":"","cell_type":"code","outputs":[]}],"nbformat_minor":1,"nbformat":4}