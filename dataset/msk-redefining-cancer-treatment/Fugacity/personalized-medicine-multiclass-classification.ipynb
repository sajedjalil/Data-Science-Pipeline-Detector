{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Preface\n\n### AIM:\nThe purpose of this kernel is to propose a ML medical solution for predicting cancer class based on information about Gene, it's Variation, and scientific literature.\n\n### BACKGROUND \nIterpretation of genetic variations is a time-consuming process that is currently done by pathalogiests in a manual fashion.\nTumors are typically classified based on the genetic markers as well as scientific literature. By developing a classification solution we aim to potentially\n\na) Accelerate the analysis\nb) Improve result accuaracy \nc) Decrease procedure's cost \nd) Identify medical treatment for a particular group of patients.  \n\n### METHOD:\n    1.Clean and preprocess data\n    2.Create random model and identify worst performance metrics \n    3.Evaluate distribution and predictive power of each feature\n    4.Evaluate performance of several ML models\n    5.Use the best performing model on the test set provided\n\nIf you find this kernel useful please click upvote :)"},{"metadata":{},"cell_type":"markdown","source":"[](http://)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# Loading all required packages\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport re\nimport time\nimport warnings\nimport numpy as np\nfrom nltk.corpus import stopwords\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.preprocessing import normalize\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.manifold import TSNE\nimport seaborn as sns\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics.classification import accuracy_score, log_loss\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import SGDClassifier\nfrom imblearn.over_sampling import SMOTE\nfrom collections import Counter\nfrom scipy.sparse import hstack\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import SVC\n#from sklearn.cross_validation import StratifiedKFold \nfrom collections import Counter, defaultdict\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nimport math\nfrom sklearn.metrics import normalized_mutual_info_score\nfrom sklearn.ensemble import RandomForestClassifier\nwarnings.filterwarnings(\"ignore\")\n\nfrom mlxtend.classifier import StackingClassifier\nfrom IPython.display import Image\n\n\n\nfrom sklearn import model_selection\nfrom sklearn.linear_model import LogisticRegression\n\n%matplotlib inline\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Data Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_variants = pd.read_csv('../input/msk-redefining-cancer-treatment/training_variants')\ndata_text =pd.read_csv(\"../input/msk-redefining-cancer-treatment/training_text\",sep=\"\\|\\|\",engine=\"python\",names=[\"ID\",\"TEXT\"],skiprows=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\n\ndef data_text_preprocess(total_text, ind, col):\n    # Remove int values from text data as that might not be imp\n    if type(total_text) is not int:\n        string = \"\"\n        # replacing all special char with space\n        total_text = re.sub('[^a-zA-Z0-9\\n]', ' ', str(total_text))\n        # replacing multiple spaces with single space\n        total_text = re.sub('\\s+',' ', str(total_text))\n        # bring whole text to same lower-case scale.\n        total_text = total_text.lower()\n        \n        for word in total_text.split():\n        # if the word is a not a stop word then retain that word from text\n            if not word in stop_words:\n                string += word + \" \"\n        \n        data_text[col][ind] = string","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for index, row in data_text.iterrows():\n    if type(row['TEXT']) is str:\n        data_text_preprocess(row['TEXT'], index, 'TEXT')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data = pd.merge(data_variants, data_text,on='ID', how='left')\nall_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\n\nplt.subplot(233)\nsns.countplot(y='Class',data=all_data)\nplt.gca().xaxis.tick_bottom()\nplt.title('Data count by Class')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def report_missing_data(df):\n    '''\n    IN: Dataframe \n    OUT: Dataframe with reported count of missing values, % missing per column and per total data\n    '''\n    \n    missing_count_per_column = df.isnull().sum()\n    missing_count_per_column = missing_count_per_column[missing_count_per_column>0]\n    total_count_per_column = df.isnull().count()\n    total_cells = np.product(df.shape)\n    \n    # Percent calculation\n    percent_per_columnn = 100*missing_count_per_column/total_count_per_column\n    percent_of_total = 100*missing_count_per_column/total_cells\n    \n    # Creating new dataframe for reporting purposes only\n    missing_data = pd.concat([missing_count_per_column,\n                              percent_per_columnn,\n                              percent_of_total], axis=1, keys=['Total_Missing', 'Percent_per_column','Percent_of_total'])\n        \n    missing_data = missing_data.dropna()\n    missing_data.index.names = ['Feature']\n    missing_data.reset_index(inplace=True)\n\n    \n    \n    return missing_data.sort_values(by ='Total_Missing',ascending=False)\n\nmissing_data = report_missing_data(all_data)\nmissing_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data[all_data.isnull().any(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding Variation column to TEXT\nall_data.loc[all_data['TEXT'].isnull(),'TEXT'] = all_data['Gene'] + ' ' + all_data['Variation'] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Image(\"../input/cancer-pics/pic11.png\",height=800 , width=600)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_true = all_data['Class'].values\nall_data['Gene']      = all_data['Gene'].str.replace('\\s+', '_')\nall_data['Variation'] = all_data['Variation'].str.replace('\\s+', '_')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Breaking up all data: 80 Train / 20 Test\nX_train, test_df, y_train, y_test = train_test_split(all_data, y_true, stratify = y_true, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Breaking up test data: 80 Train / 20 Validation\ntrain_df, cv_df, y_train, y_cv = train_test_split(X_train,y_train,stratify = y_train, test_size=0.2 )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Data points in train data:', train_df.shape[0])\nprint('Data points in test data:', test_df.shape[0])\nprint('Data points in cross validation data:', cv_df.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set = []\ncv_set = []\ntest_set = []\n\ntrain_class_distribution = train_df['Class'].value_counts()\ntest_class_distribution = test_df['Class'].value_counts()\ncv_class_distribution = cv_df['Class'].value_counts()\n\nsorted_train = np.argsort(-train_class_distribution.values)\nsorted_test = np.argsort(-test_class_distribution.values)\nsorted_cv = np.argsort(-cv_class_distribution.values)\n\nfor i in sorted_train:\n    train_set.append(np.round((train_class_distribution.values[i]/train_df.shape[0]*100), 3))\nfor i in sorted_test:\n    test_set.append(np.round((test_class_distribution.values[i]/test_df.shape[0]*100),3))\nfor i in sorted_cv:\n    cv_set.append(np.round((cv_class_distribution.values[i]/cv_df.shape[0]*100), 3))\n\ndistribution_per_set = pd.DataFrame(\n    {\n     'Train Set(%)': train_set,\n     'CV Set(%)': cv_set,\n     'Test Set(%)':test_set\n    })\n\n# Plotting Distribution per class \ndistribution_per_set.index = distribution_per_set.index + 1\ndistribution_per_set.plot.bar(figsize=(12,6))\nplt.xticks(rotation=0)\nplt.title('Distribution of data per set and class')\nplt.xlabel('Class')\nplt.ylabel('% Of total data')\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data is distributed quite evenly across sets"},{"metadata":{},"cell_type":"markdown","source":"# 2. Random Model Generation\nThe idea behind random model is to create a reference error value (True - Generated), based on randomly generated value\nThis reference error gives a sense of how well our build model performce against the randomly generated values\n\n\nHow we construct random model for our multiclassification case:\n\n- Generate series filled with random probabilities  \n- Probabilities a distribute randomly across classes (1-9) \n- Log_loss is used to measure the accuracy ( Submission requires log loss )"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data_len = test_df.shape[0]\ncv_data_len = cv_df.shape[0]\n\n# we create a output array that has exactly same size as the CV data\ncv_predicted_y = np.zeros((cv_data_len,9))\nfor i in range(cv_data_len):\n    rand_probs = np.random.rand(1,9)\n    cv_predicted_y[i] = ((rand_probs/rand_probs.sum())[0])\n\ncv_log_loss = round(log_loss(y_cv,cv_predicted_y, eps=1e-15),2)\n\nprint(\"Log loss on Cross Validation Data using Random Model\",cv_log_loss)\n\n# Test-Set error.\n#we create a output array that has exactly same as the test data\ntest_predicted_y = np.zeros((test_data_len,9))\nfor i in range(test_data_len):\n    rand_probs = np.random.rand(1,9)\n    test_predicted_y[i] = ((rand_probs/rand_probs.sum())[0])\ntest_log_loss = round(log_loss(y_test,test_predicted_y, eps=1e-15),2)\n\nprint(\"Log loss on Test Data using Random Model\",test_log_loss)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like **2.5** will be our reference point. The closer the log loss of our model gets to 2.5 the worse our model is !"},{"metadata":{},"cell_type":"markdown","source":"To evaluate the performance of random and later real ML models we will use the following matrices:\n\n### Confusion Matrix \n* Layman: Confusion matrix is used to get a sense of how accurate our model classifies data \n* If models performs well, cells arranged diaganally will have higher correlation\n\n### Recall Matrix \n* Layman: Can be thought as modelâ€™s ability to find all the data points of interest in a dataset\n* Mathematical: True Positive / ( True Positive + False Negative ) \n\n### Precision Matrix \n* Layman: Precision identifyies proportion of the data points model classifies as relavant to actually be relavant\n* Mathematical: True Positive / ( True positve + False Positive )"},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_y =np.argmax(test_predicted_y, axis=1)\n# Since class values vary for 0-8. And we have 1-9. Apply n+1 formula to make it 1-9 \npredicted_y = predicted_y+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_matrices(y_test,predicted_y):  \n\n    confusion = confusion_matrix(y_test, predicted_y)\n    precision =(confusion/confusion.sum(axis=0))\n    recall =(((confusion.T)/(confusion.sum(axis=1))).T)\n    \n    f,(ax1,ax2,ax3, axcb) = plt.subplots(1,4, \n                gridspec_kw={'width_ratios':[1,1,1,0.08]},figsize=(22,6))\n    \n    labels = [1,2,3,4,5,6,7,8,9]\n    \n    g1 = sns.heatmap(confusion,cbar=False,ax=ax1,annot=True, cmap=\"Blues\", fmt=\".3f\", xticklabels=labels, yticklabels=labels,)\n    g1.set_ylabel('Original Class')\n    g1.set_xlabel('Predicted Class')\n    g1.set_title('Confusion')\n    g2 = sns.heatmap(precision,cmap=\"Blues\",cbar=False,ax=ax2, annot=True,fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n    g2.set_ylabel('Original Class')\n    g2.set_xlabel('Predicted Class')\n    g2.set_yticks(labels)\n    g2.set_title('Precision')\n    g3 = sns.heatmap(recall,cmap=\"Blues\",ax=ax3, cbar_ax=axcb, annot=True, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n    g3.set_ylabel('Original Class')\n    g3.set_xlabel('Predicted Class')\n    g3.set_title('Recall')\n    g3.set_yticks(labels)\n    \n    for ax in [g1,g2,g3]:\n        tl = ax.get_xticklabels()\n        ax.set_xticklabels(tl, rotation=0)\n        tly = ax.get_yticklabels()\n        ax.set_yticklabels(tly, rotation=0)\n    \n    plt.show()\n\nplot_matrices(y_test,predicted_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ideally, we would expect to identity matrix ( high correlation between classes )  \nIt is pretty clear that random model is messy and does not show any classifications "},{"metadata":{},"cell_type":"markdown","source":"# 3. Feature Evaluation"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"Image(\"../input/cancer-pics/pic22.png\",height=800 , width=600)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define Evaluating Functions:\n\n#### Evaluation Model:\n* Stochastic Gradient Descent classifier\n* Logistic Regression (sigmoid)\n* Calibrated Classifier - Post Processing the model to improve probability estimates \n* Use onehotCoding \n* Penalty='l2'\n\n\nBelow are the functions that will help us with evaluating our features"},{"metadata":{"trusted":true},"cell_type":"code","source":"def eval_alpha_loss(alpha,train_feat_hotencode,cv_feat_hotencode):\n    \"\"\"\n    IN: Hyperparameter Alpha, Train_Feature_onehotencoded, CV_Feature_onehotencoded\n    OUT: Hyperparameter Tunning DataFrame \n    \"\"\"\n    cv_log_error_array=[]\n    for i in alpha:\n        clf = SGDClassifier(alpha=i, penalty='l2', loss='log', random_state=42)\n        clf.fit(train_feat_hotencode, y_train)\n        sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n    \n    # \n        sig_clf.fit(train_feat_hotencode, y_train)\n        predict_y = sig_clf.predict_proba(cv_feat_hotencode)\n    \n        cv_log_error_array.append(log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n\n    temp_df = pd.DataFrame(data={'alpha': np.round(alpha,5), \n                                 'cv_log_loss': np.round(cv_log_error_array,5)})\n    return temp_df\n\n\ndef eval_all_set(name,best_alpha,\n                 train_feat_hotencode,\n                 cv_feat_hotencode,\n                 test_feat_hotencode):\n    '''\n    IN: Feature name, Best Alpha, and All 3 OneHotEncoded Sets \n    OUT: Log-Loss Report data frame\n    '''\n    # Model\n    clf = SGDClassifier(alpha=best_alpha, penalty='l2', loss='log', random_state=42)\n    clf.fit(train_feat_hotencode, y_train)\n    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n    sig_clf.fit(train_feat_hotencode, y_train)\n    \n    train_predict_y = sig_clf.predict_proba(train_feat_hotencode)\n    train_log_loss = np.round(log_loss(y_train, train_predict_y, labels=clf.classes_, eps=1e-15),3)\n\n    cv_predict_y = sig_clf.predict_proba(cv_feat_hotencode)\n    cv_log_loss = np.round(log_loss(y_cv, cv_predict_y, labels=clf.classes_, eps=1e-15),3)\n    \n    test_predict_y = sig_clf.predict_proba(test_feat_hotencode)\n    test_log_loss = np.round(log_loss(y_test, test_predict_y, labels=clf.classes_, eps=1e-15),3)\n    \n    report_log_loss=[name,\n                     best_alpha,\n                     train_log_loss,\n                     cv_log_loss,\n                     test_log_loss]\n    \n    temp_df = pd.DataFrame([report_log_loss],columns=['Feature','best alpha','train_log_loss','cv_log_loss','test_log_loss' ])   \n    return temp_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.1 Evaluating Gene column\n\n* Look at words distribution \n* String data must be converted to numeric so ML algorithm can be be applied\n* Encoding Strategy: **Onehot Encoding** \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# How many unique values ? \nunique_gene = train_df['Gene'].value_counts()\nprint ('Number of unique Genes:',unique_gene.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_unique_values = sum(unique_gene.values);\npercent_per_total = unique_gene.values/total_unique_values;\ncumulative = np.cumsum(percent_per_total)\nplt.plot(cumulative,label='Cumulative distribution of Genes',)\n\nplt.grid()\nplt.axhline(0.75, color='k')\nplt.legend()\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like 75% of data consists of approximately 50 most common words.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vectorizing our 'Gene' feature\nvectorizer = CountVectorizer()\ntrain_gene_feature_onehotCoding =  vectorizer.fit_transform(train_df['Gene'])\ntest_gene_feature_onehotCoding  =  vectorizer.transform(test_df['Gene'])\ncv_gene_feature_onehotCoding    =  vectorizer.transform(cv_df['Gene'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Great. Our log loss better off than our Random Model (~2.50). \nLooks like the lowest error is occured when Alpha = 0.0001\n\nNow, let apply the same model to our testing dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluation Overalap\ntest_train_coverage=test_df[test_df['Gene'].isin(list(set(train_df['Gene'])))].shape[0]\ncv_train_coverage=cv_df[cv_df['Gene'].isin(list(set(train_df['Gene'])))].shape[0]\ntest_train_overlap = np.round(test_train_coverage*100/test_df.shape[0],1)\ncv_train_overlap =  np.round(cv_train_coverage*100/cv_df.shape[0],1)\n\noverlap= pd.DataFrame(data=[[test_train_overlap,cv_train_overlap]],columns=['Test-Train Data Overlap[%]','CV-Train Data Overlap[%]'])\n\n# Evaluating Gene Feature\nalpha = [10 ** x for x in range(-5, 1)]\n# Tunning Hyper Parameter (Alpha)\ntunning_df = eval_alpha_loss(alpha,train_gene_feature_onehotCoding,cv_gene_feature_onehotCoding)\n# Selecting Best Alpha\nbest_alpha = tunning_df.loc[tunning_df['cv_log_loss'] == tunning_df['cv_log_loss'].min(), 'alpha'].item()\n\n# Calculating Log_Loss for all test sets\ngene_feat = eval_all_set('Gene',best_alpha,\n                         train_gene_feature_onehotCoding,\n                         cv_gene_feature_onehotCoding,\n                         test_gene_feature_onehotCoding)\n\n# Combining Report\ngene_report=pd.concat([gene_feat,overlap],axis=1)\ngene_report","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.2 Evaluating Variation column"},{"metadata":{"trusted":true},"cell_type":"code","source":"# How many unique values \nunique_variation = train_df['Variation'].value_counts()\nprint ('Number of unique Variation:',unique_variation.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_unique_values = sum(unique_variation.values);\npercent_per_total = unique_variation.values/total_unique_values;\ncumulative = np.cumsum(percent_per_total)\nplt.plot(cumulative,label='Cumulative distribution of Genes',)\n\nplt.grid()\nplt.axhline(0.80, color='k')\nplt.legend()\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = CountVectorizer()\n\ntrain_variation_feature_onehotCoding =  vectorizer.fit_transform(train_df['Variation'])\ntest_variation_feature_onehotCoding  =  vectorizer.transform(test_df['Variation'])\ncv_variation_feature_onehotCoding    =  vectorizer.transform(cv_df['Variation'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_train_coverage=test_df[test_df['Variation'].isin(list(set(train_df['Variation'])))].shape[0]\ncv_train_coverage=cv_df[cv_df['Variation'].isin(list(set(train_df['Variation'])))].shape[0]\ntest_train_overlap = np.round(test_train_coverage*100/test_df.shape[0],1)\ncv_train_overlap =  np.round(cv_train_coverage*100/cv_df.shape[0],1)\n\noverlap= pd.DataFrame(data=[[test_train_overlap,cv_train_overlap]],columns=['Test-Train Data Overlap[%]','CV-Train Data Overlap[%]'])\n\n# Evaluating Gene Feature\nalpha = [10 ** x for x in range(-5, 1)]\n# Tunning Hyper Parameter (Alpha)\ntunning_df = eval_alpha_loss(alpha,train_gene_feature_onehotCoding,cv_gene_feature_onehotCoding)\n# Selecting Best Alpha\nbest_alpha = tunning_df.loc[tunning_df['cv_log_loss'] == tunning_df['cv_log_loss'].min(), 'alpha'].item()\n\n# Calculating Log_Loss for all test sets\nfeat_rep = eval_all_set('Variation',best_alpha,\n                         train_variation_feature_onehotCoding,\n                         cv_variation_feature_onehotCoding,\n                         test_variation_feature_onehotCoding)\n\n# Combining Report\nvariation_report=pd.concat([feat_rep,overlap],axis=1)\nvariation_report","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CV and Test log loss is much higher in comparison with train. Most likely the coverage of variation data is low. Lets see "},{"metadata":{},"cell_type":"markdown","source":"## 3.3 Evaluating Text column"},{"metadata":{"trusted":true},"cell_type":"code","source":"# building a CountVectorizer with all the words that occured minimum 3 times in train data\ntext_vectorizer = CountVectorizer(min_df=3)\ntrain_text_feature_onehotCoding = text_vectorizer.fit_transform(train_df['TEXT'])\n\n# getting all the feature names (words)\ntrain_text_features= text_vectorizer.get_feature_names()\nprint(\"Total number of unique words in train data :\", len(train_text_features))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalizing One_Hot_Encoding\n\n# we use the same vectorizer that was trained on train data\ntrain_text_feature_onehotCoding = normalize(train_text_feature_onehotCoding, axis=0)\n\ntest_text_feature_onehotCoding = text_vectorizer.transform(test_df['TEXT'])\ntest_text_feature_onehotCoding = normalize(test_text_feature_onehotCoding, axis=0)\n\ncv_text_feature_onehotCoding = text_vectorizer.transform(cv_df['TEXT'])\ncv_text_feature_onehotCoding = normalize(cv_text_feature_onehotCoding, axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below is code used to find an overal of words between sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_text_feature_onehotCoding.sum(axis=0).A1 will sum every row and returns (1*number of features) vector\n# .A1 turns(compresses) Matrix into Array\ntrain_text_fea_counts = train_text_feature_onehotCoding.sum(axis=0).A1\n\n# We will use it to check overlaps between data sets\ntext_fea_dict = dict(zip(list(train_text_features),train_text_fea_counts))\n\n# Sorting dictionary based on the value ( not key ) \nsorted_text_fea_dict = dict(sorted(text_fea_dict.items(), key=lambda x: x[1] , reverse=True))\nsorted_text_occur = np.array(list(sorted_text_fea_dict.values()))\n\ndef get_intersec_text(df):\n    df_text_vec = CountVectorizer(min_df=3)\n    df_text_fea = df_text_vec.fit_transform(df['TEXT'])\n    df_text_features = df_text_vec.get_feature_names()\n\n    df_text_fea_counts = df_text_fea.sum(axis=0).A1\n    df_text_fea_dict = dict(zip(list(df_text_features),df_text_fea_counts))\n    len1 = len(set(df_text_features))\n    len2 = len(set(train_text_features) & set(df_text_features))\n    return len1,len2\n\nlen1,len2 = get_intersec_text(test_df)\ntest_train_overlap =np.round((len2/len1)*100, 1)\nlen1,len2 = get_intersec_text(cv_df)\ncv_train_overlap = np.round((len2/len1)*100, 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"overlap= pd.DataFrame(data=[[test_train_overlap, cv_train_overlap]],columns=['Test-Train Data Overlap[%]','CV-Train Data Overlap[%]'])\n\n# Evaluating Gene Feature\nalpha = [10 ** x for x in range(-5, 1)]\n# Tunning Hyper Parameter (Alpha)\ntunning_df = eval_alpha_loss(alpha,train_gene_feature_onehotCoding,cv_gene_feature_onehotCoding)\n# Selecting Best Alpha\nbest_alpha = tunning_df.loc[tunning_df['cv_log_loss'] == tunning_df['cv_log_loss'].min(), 'alpha'].item()\n\n# Calculating Log_Loss for all test sets\nfeat_rep = eval_all_set('TEXT',best_alpha,\n                         train_text_feature_onehotCoding,\n                         cv_text_feature_onehotCoding,\n                         test_text_feature_onehotCoding)\n\n# Combining Report\ntext_report=pd.concat([feat_rep,overlap],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_features = pd.concat([gene_report,variation_report,text_report],axis=0)\nall_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Seems like Variation column can be an issues, since the there is a small overalap between data sets"},{"metadata":{},"cell_type":"markdown","source":"# 4. Feature Prepation for Machine Learning"},{"metadata":{"trusted":true},"cell_type":"code","source":"Image(\"../input/cancer-pics/pic31.png\",height=800 , width=600)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.1  Definning Model Evaluation Function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def report_log_loss(train_x, train_y, test_x, test_y,  clf):\n    clf.fit(train_x, train_y)\n    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n    sig_clf.fit(train_x, train_y)\n    sig_clf_probs = sig_clf.predict_proba(test_x)\n    return log_loss(test_y, sig_clf_probs, eps=1e-15)\n\n\n\n\ndef eval_alpha_model_loss(alpha,train_feat_hotencode,cv_feat_hotencode):\n    \"\"\"\n    IN: Hyperparameter Alpha, Train_Feature_onehotencoded, CV_Feature_onehotencoded\n    OUT: Hyperparameter Tunning DataFrame \n    \"\"\"\n    cv_log_error_array=[]\n    for i in alpha:\n        clf = SGDClassifier(alpha=i, penalty='l2', loss='log', random_state=42)\n        clf.fit(train_feat_hotencode, y_train)\n        sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n        sig_clf.fit(train_feat_hotencode, y_train)\n        predict_y = sig_clf.predict_proba(cv_feat_hotencode)\n    \n        cv_log_error_array.append(log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n\n    temp_df = pd.DataFrame(data={'alpha': np.round(alpha,5), \n                                 'cv_log_loss': np.round(cv_log_error_array,5)})\n    return temp_df\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_matrices(y_test,predicted_y):  \n\n    confusion = confusion_matrix(y_test, predicted_y)\n    precision =(confusion/confusion.sum(axis=0))\n    recall =(((confusion.T)/(confusion.sum(axis=1))).T)\n    \n    f,(ax1,ax2,ax3, axcb) = plt.subplots(1,4, \n                gridspec_kw={'width_ratios':[1,1,1,0.08]},figsize=(22,6))\n    \n    labels = [1,2,3,4,5,6,7,8,9]\n    \n    g1 = sns.heatmap(confusion,cbar=False,ax=ax1,annot=True, cmap=\"Blues\", fmt=\".3f\", xticklabels=labels, yticklabels=labels,)\n    g1.set_ylabel('Class')\n    g1.set_xlabel('Class')\n    g1.set_title('Confusion')\n    g2 = sns.heatmap(precision,cmap=\"Blues\",cbar=False,ax=ax2, annot=True,fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n    g2.set_ylabel('Class')\n    g2.set_xlabel('Class')\n    g2.set_yticks(labels)\n    g2.set_title('Precision')\n    g3 = sns.heatmap(recall,cmap=\"Blues\",ax=ax3, cbar_ax=axcb, annot=True, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n    g3.set_ylabel('Class')\n    g3.set_xlabel('Class')\n    g3.set_title('Recall')\n    g3.set_yticks(labels)\n    \n    for ax in [g1,g2,g3]:\n        tl = ax.get_xticklabels()\n        ax.set_xticklabels(tl, rotation=0)\n        tly = ax.get_yticklabels()\n        ax.set_yticklabels(tly, rotation=0)  \n    plt.show()   \n\ndef predict_and_plot_confusion_matrix(train_x, train_y,test_x, test_y, clf):\n    clf.fit(train_x, train_y)\n    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n    sig_clf.fit(train_x, train_y)\n    pred_y = sig_clf.predict(test_x)\n\n    # for calculating log_loss we willl provide the array of probabilities belongs to each class\n    # calculating the number of data points that are misclassified\n    plot_matrices(test_y, pred_y)    \n\ndef model_performance(name,clf,best_alpha,\n                 train_X_hotencode,\n                 cv_X_hotencode,\n                 test_X_hotencode):\n    '''\n    IN: Model name, Classifier, Best Alpha, and All 3 OneHotEncoded Sets \n    OUT: Log-Loss Report data frame\n    '''\n    # Model\n    clf = clf\n    clf.fit(train_X_hotencode, train_y)\n    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n    sig_clf.fit(train_X_hotencode, train_y)\n    \n    train_predict_y = sig_clf.predict_proba(train_X_hotencode)\n    train_log_loss = np.round(log_loss(y_train, train_predict_y, labels=clf.classes_, eps=1e-15),3)\n\n    cv_predict_y = sig_clf.predict_proba(cv_X_hotencode)\n    cv_log_loss = np.round(log_loss(y_cv, cv_predict_y, labels=clf.classes_, eps=1e-15),3)\n    \n    test_predict_y = sig_clf.predict_proba(test_X_hotencode)\n    test_log_loss = np.round(log_loss(y_test, test_predict_y, labels=clf.classes_, eps=1e-15),3)\n    \n    pred_y = sig_clf.predict(test_X_hotencode)\n    \n    miss_class = np.count_nonzero((pred_y- test_y))/test_y.shape[0]\n    \n    \n    report_log_loss=[name,\n                     best_alpha,\n                     train_log_loss,\n                     cv_log_loss,\n                     test_log_loss,\n                     miss_class]\n    \n    temp_df = pd.DataFrame([report_log_loss],columns=['Model','best alpha','train_log_loss','cv_log_loss','test_log_loss','Miss_classified(%)' ])   \n    return temp_df\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.2 Feature Stacking\n\nAll three hot encoded features are stacked together"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gene_var_onehotCoding = hstack((train_gene_feature_onehotCoding,train_variation_feature_onehotCoding))\ntest_gene_var_onehotCoding = hstack((test_gene_feature_onehotCoding,test_variation_feature_onehotCoding))\ncv_gene_var_onehotCoding = hstack((cv_gene_feature_onehotCoding,cv_variation_feature_onehotCoding))\n\ntrain_x_onehotCoding = hstack((train_gene_var_onehotCoding, train_text_feature_onehotCoding)).tocsr()\ntrain_y = np.array(list(train_df['Class']))\n\ntest_x_onehotCoding = hstack((test_gene_var_onehotCoding, test_text_feature_onehotCoding)).tocsr()\ntest_y = np.array(list(test_df['Class']))\n\ncv_x_onehotCoding = hstack((cv_gene_var_onehotCoding, cv_text_feature_onehotCoding)).tocsr()\ncv_y = np.array(list(cv_df['Class']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Model Evaluation"},{"metadata":{},"cell_type":"markdown","source":"## 5.1 Naive Bayse"},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha = [0.00001, 0.0001, 0.001, 0.1, 1, 10, 100,1000]\ncv_log_error_array = []\nfor i in alpha:\n    #print(\"for alpha =\", i)\n    clf = MultinomialNB(alpha=i)\n    clf.fit(train_x_onehotCoding, train_y)\n    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n    sig_clf.fit(train_x_onehotCoding, train_y)\n    sig_clf_probs = sig_clf.predict_proba(cv_x_onehotCoding)\n    \n    # to avoid rounding error while multiplying probabilites we use log-probability estimates\n    cv_log_error_array.append(log_loss(cv_y, sig_clf_probs, labels=clf.classes_, eps=1e-15))\n    \n    \ntemp_df = pd.DataFrame(data={'alpha': np.round(alpha,5), 'cv_log_error': np.round(cv_log_error_array,5)})\ntemp_df.sort_values(by ='cv_log_error',ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_alpha = temp_df.loc[temp_df['cv_log_error'] == temp_df['cv_log_error'].min(), 'alpha'].item()\n\n# Model \nclf = MultinomialNB(alpha=best_alpha)\n\n# Calculating Log_Loss for all test sets\nNB_report = model_performance('Naive Bayes',\n                             clf,\n                             best_alpha,\n                         train_x_onehotCoding,\n                         cv_x_onehotCoding,\n                         test_x_onehotCoding)\nNB_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print ('Naive Bayse')\npredict_and_plot_confusion_matrix(train_x_onehotCoding, train_y, cv_x_onehotCoding, cv_y, clf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.2 Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha = [10 ** x for x in range(-6, 3)]\ncv_log_error_array = []\nfor i in alpha:\n    clf = SGDClassifier(class_weight='balanced', alpha=i, penalty='l2', loss='log', random_state=42)\n    clf.fit(train_x_onehotCoding, train_y)\n    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n    sig_clf.fit(train_x_onehotCoding, train_y)\n    sig_clf_probs = sig_clf.predict_proba(cv_x_onehotCoding)\n    \n    # to avoid rounding error while multiplying probabilites we use log-probability estimates\n    cv_log_error_array.append(log_loss(cv_y, sig_clf_probs, labels=clf.classes_, eps=1e-15))\n    \n    \ntemp_df = pd.DataFrame(data={'alpha': np.round(alpha,5), 'cv_log_error': np.round(cv_log_error_array,3)})\ntemp_df.sort_values(by ='cv_log_error',ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_alpha = temp_df.loc[temp_df['cv_log_error'] == temp_df['cv_log_error'].min(), 'alpha'].item()\n\n\nclf = SGDClassifier(class_weight='balanced', alpha=best_alpha, penalty='l2', loss='log', random_state=42)\n\nLR_report = model_performance('Logistic Regression',\n                             clf,\n                             best_alpha,\n                         train_x_onehotCoding,\n                         cv_x_onehotCoding,\n                         test_x_onehotCoding)\nLR_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_and_plot_confusion_matrix(train_x_onehotCoding, train_y, cv_x_onehotCoding, cv_y, clf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.3 Logistic Regression without class balancing:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha = [10 ** x for x in range(-6, 3)]\ncv_log_error_array = []\nfor i in alpha:\n    clf = SGDClassifier(class_weight=None, alpha=i, penalty='l2', loss='log', random_state=42)\n    clf.fit(train_x_onehotCoding, train_y)\n    sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n    sig_clf.fit(train_x_onehotCoding, train_y)\n    sig_clf_probs = sig_clf.predict_proba(cv_x_onehotCoding)\n    \n    # to avoid rounding error while multiplying probabilites we use log-probability estimates\n    cv_log_error_array.append(log_loss(cv_y, sig_clf_probs, labels=clf.classes_, eps=1e-15))\n    \n    \ntemp_df = pd.DataFrame(data={'alpha': np.round(alpha,5), 'cv_log_error': np.round(cv_log_error_array,3)})\ntemp_df.sort_values(by ='cv_log_error',ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_alpha = temp_df.loc[temp_df['cv_log_error'] == temp_df['cv_log_error'].min(), 'alpha'].item()\n\n\nclf = SGDClassifier(class_weight=None,alpha=best_alpha, penalty='l2', loss='log', random_state=42, )\n\nLR_NoBal_report = model_performance('Logistic Regression (No Weight Balance)',\n                             clf,\n                             best_alpha,\n                         train_x_onehotCoding,\n                         cv_x_onehotCoding,\n                         test_x_onehotCoding)\nLR_NoBal_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_and_plot_confusion_matrix(train_x_onehotCoding, train_y, cv_x_onehotCoding, cv_y, clf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.4 Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha = [100,200,500,1000,1500]\nmax_depth = [5, 10]\n\ncv_log_error_array = []\nn_estimators=[]\ndepth=[]\nfor i in alpha:\n    for j in max_depth:\n        clf = RandomForestClassifier(n_estimators=i, criterion='gini', max_depth=j, random_state=42, n_jobs=-1)\n        clf.fit(train_x_onehotCoding, train_y)\n        sig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\n        sig_clf.fit(train_x_onehotCoding, train_y)\n        sig_clf_probs = sig_clf.predict_proba(cv_x_onehotCoding)\n        cv_log_error_array.append(log_loss(cv_y, sig_clf_probs, labels=clf.classes_, eps=1e-15))\n        depth.append(j)\n        n_estimators.append(i)\n        \ntemp_df = pd.DataFrame(data={'n_estimators': np.round(n_estimators), 'max_depth': np.round(depth),'cv_log_error': np.round(cv_log_error_array,5)})\ntemp_df.sort_values(by ='cv_log_error',ascending=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_estimator = temp_df.loc[temp_df['cv_log_error'] == temp_df['cv_log_error'].min(), 'n_estimators'].item()\nbest_depth = temp_df.loc[temp_df['cv_log_error'] == temp_df['cv_log_error'].min(), 'max_depth'].item()\nbest_alpha ='n_estimators=',str(best_estimator),'max depth=',str(best_depth)\nbest_alpha","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_alpha ='n_estimators=',str(best_estimator),'max depth=',str(best_depth)\nbest_alpha\n\n\nclf = RandomForestClassifier(n_estimators=best_estimator, \n                             max_depth=best_depth,\n                             criterion='gini',\n                             random_state=42,\n                             n_jobs=-1)\n\nRF_report = model_performance('Random Forest',\n                             clf,\n                             best_alpha,\n                         train_x_onehotCoding,\n                         cv_x_onehotCoding,\n                         test_x_onehotCoding)\nRF_report","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_and_plot_confusion_matrix(train_x_onehotCoding, train_y, cv_x_onehotCoding, cv_y, clf)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.5 Stacked Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Naive Bayse\nclf1 = MultinomialNB(alpha=0.1)\nclf1.fit(train_x_onehotCoding, train_y)\nsig_clf1 = CalibratedClassifierCV(clf1, method=\"sigmoid\")\n#Logistic Regression\nclf2 = SGDClassifier(alpha=0.001, class_weight='balanced',  penalty='l2', loss='log', random_state=42)\nclf2.fit(train_x_onehotCoding, train_y)\nsig_clf2 = CalibratedClassifierCV(clf2, method=\"sigmoid\")\n# Random Forest\nclf3 = RandomForestClassifier(n_estimators=best_estimator,max_depth=best_depth, criterion='gini',random_state=42,n_jobs=-1)\nclf3.fit(train_x_onehotCoding, train_y)\nsig_clf3 = CalibratedClassifierCV(clf3, method=\"sigmoid\")\n\nsig_clf1.fit(train_x_onehotCoding, train_y)\nsig_clf2.fit(train_x_onehotCoding, train_y)\nsig_clf3.fit(train_x_onehotCoding, train_y)\n\nalpha = [0.0001,0.001,0.01,0.1,1,10] \ncv_log_error_array=[]\nfor i in alpha:\n    lr = LogisticRegression(C=i)\n    sclf = StackingClassifier(classifiers=[sig_clf1, sig_clf2, sig_clf3], meta_classifier=lr, use_probas=True)\n    sclf.fit(train_x_onehotCoding, train_y)\n    cv_log_error_array.append(log_loss(cv_y, sclf.predict_proba(cv_x_onehotCoding)))\n    \n    \n    \ntemp_df = pd.DataFrame(data={'alpha': np.round(alpha,5), 'cv_log_error': np.round(cv_log_error_array,3)})\ntemp_df.sort_values(by ='cv_log_error',ascending=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_alpha = temp_df.loc[temp_df['cv_log_error'] == temp_df['cv_log_error'].min(), 'alpha'].item()\n\nlr = LogisticRegression(C=best_alpha)\nsclf = StackingClassifier(classifiers=[sig_clf1, sig_clf2, sig_clf3], meta_classifier=lr, use_probas=True)\nsclf.fit(train_x_onehotCoding, train_y)\n\ntrain_log_error = log_loss(train_y, sclf.predict_proba(train_x_onehotCoding))\ncv_log_error = log_loss(cv_y, sclf.predict_proba(cv_x_onehotCoding))\ntest_log_error = log_loss(test_y, sclf.predict_proba(test_x_onehotCoding))\n\nmiss_class = np.count_nonzero((sclf.predict(test_x_onehotCoding)- test_y))/test_y.shape[0]\n\nname = \"Stacked (NB,LG,RF)\"\n\n\nreport_log_loss=[name,\n                     best_alpha,\n                     train_log_error,\n                     cv_log_error,\n                     test_log_error,\n                     miss_class]\n    \nstacked_report = pd.DataFrame([report_log_loss],columns=['Model','best alpha','train_log_loss','cv_log_loss','test_log_loss','Miss_classified(%)' ])   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_models = pd.concat([NB_report,\n                        LR_report,\n                        LR_NoBal_report,\n                        RF_report,\n                        stacked_report])\n\nall_models = all_models.sort_values(by ='Miss_classified(%)',ascending=True)\nprint(all_models.to_string())\n\nplt.figure(figsize=(10,6))\nsns.barplot(y='Model',x='Miss_classified(%)',data=all_models, alpha=0.7)\nplt.title('ML Model Performance')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_text = pd.read_csv('../input/msk-redefining-cancer-treatment/stage2_test_text.csv',sep=\"\\|\\|\",engine=\"python\",names=[\"ID\",\"TEXT\"],skiprows=1)\nsubmission_var =  pd.read_csv('../input/msk-redefining-cancer-treatment/stage2_test_variants.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submiss_data = pd.merge(submission_var, submission_text,on='ID', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gene_old_onehotCoding =  vectorizer.fit_transform(train_df['Gene'])\ngene_onehotCoding =  vectorizer.transform(submiss_data['Gene'])\n\nvariation_old_onehotCoding =  vectorizer.fit_transform(train_df['Variation'])\nvariation_onehotCoding =  vectorizer.transform(submiss_data['Variation'])\n\ntext_old_onehotCoding =  text_vectorizer.fit_transform(train_df['TEXT'])\ntext_onehotCoding = text_vectorizer.transform(submiss_data['TEXT'])\n\ntext_old_onehotCoding = normalize(text_old_onehotCoding, axis=0)\ntext_onehotCoding = normalize(text_onehotCoding, axis=0)\n\nold_gene_var_onehotCoding = hstack((gene_old_onehotCoding,variation_old_onehotCoding))\nold_onehotCoding = hstack((old_gene_var_onehotCoding, text_old_onehotCoding)).tocsr()\n\nsub_test_gene_var_onehotCoding = hstack((gene_onehotCoding,variation_onehotCoding))\nsub_test_onehotCoding = hstack((sub_test_gene_var_onehotCoding, text_onehotCoding)).tocsr()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_alpha = 0.001\n\n\nclf = SGDClassifier(class_weight='balanced', alpha=best_alpha, penalty='l2', loss='log', random_state=42)\n\nLR_report = model_performance('Logistic Regression',\n                             clf,\n                             best_alpha,\n                         train_x_onehotCoding,\n                         cv_x_onehotCoding,\n                         test_x_onehotCoding)\nLR_report","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 6.1 Logistic Regression showed the best score, hence we will use it"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = SGDClassifier(class_weight='balanced', alpha=best_alpha, penalty='l2', loss='log', random_state=42)\nclf.fit(old_onehotCoding, train_y)\nsig_clf = CalibratedClassifierCV(clf, method=\"sigmoid\")\nsig_clf.fit(old_onehotCoding, train_y)\n\nresult = sig_clf.predict_proba(sub_test_onehotCoding)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_df = pd.DataFrame(result,columns=['Class1','Class2','Class3','Class4','Class5',\n                                        'Class6','Class7','Class8','Class9'])\nresult_df['ID'] = submiss_data['ID']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = result_df.columns.tolist()\ncols = cols[-1:] + cols[:-1]\nresult_df = result_df[cols]\nresult_df.to_csv('personalized_med_submission.csv',index=False)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 7. Conclusion:\n\nWe were able to devlope solution for cancer-defining multiclass classification problem. Models are designed to assign probability to a particular class of cancer based on the Gene,Variation, and Text columns. Models were evaluated based on Confusion, Recall, and Precision matrices.\nBest model is chosen based on % Misclassified classes, as well as the train / test log losses. \n\nObservation:\n\n    1. Gene column shows best predictive power \n    2. Class 8 shows bad correlations across all three evaluations matrices\n    3. Logistic regression shows best predictive power \n    \nNext Steps:\n    1. Identify reasons for Class 8 predictions anamoly\n    2. Develope model interpretation method"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}