{"nbformat":4,"nbformat_minor":1,"cells":[{"cell_type":"code","outputs":[],"execution_count":null,"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\n#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.\ntrain_variants = pd.read_csv('../input/training_variants')\ntest_variants = pd.read_csv('../input/test_variants')\ntrain_text = pd.read_csv('../input/training_text', sep=\"\\|\\|\", engine='python', \n                         header=None, skiprows=1, names=[\"ID\",\"Text\"])\ntest_text = pd.read_csv('../input/test_text', sep=\"\\|\\|\", engine='python', \n                        header=None, skiprows=1, names=[\"ID\",\"Text\"])\n\ntrain_combined = pd.merge(train_variants, train_text, how='left', on='ID').fillna('')\ntest_combined = pd.merge(test_variants, test_text, how='left', on='ID').fillna('')","metadata":{"_uuid":"e401da9f8496ec6ba47717795f061ed569362765","_cell_guid":"9784c7df-e083-459e-a229-1a276d2c4eb5","collapsed":true}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"import numpy as np\nimport pandas as pd\nfrom xgboost import XGBClassifier\nfrom sklearn.pipeline import FeatureUnion, Pipeline\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\nfrom sklearn.feature_extraction import DictVectorizer\nfrom sklearn.utils.extmath import randomized_svd\nfrom sklearn.decomposition import TruncatedSVD, PCA\nfrom sklearn.preprocessing import LabelEncoder\nfrom scipy import sparse\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.cross_validation import train_test_split\n#import mca\nimport xgboost as xgb\nfrom xgboost import XGBClassifier, plot_importance\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.metrics import log_loss, accuracy_score","metadata":{"_uuid":"38862db87dd200e73c5b119e2ff92efe88d959e6","_cell_guid":"5f1cd55f-1769-4c9a-be2b-8e47c5816275"}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"class ColumnSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, key):\n        self.key = key\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X): \n        return X[self.key]\n    \nclass DummyMCA(BaseEstimator, TransformerMixin):\n    def __init__(self, n_factors):\n        self.n_factors = n_factors\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        mca_obj = mca.MCA(pd.get_dummies(X), TOL=1e-2)\n        factors = pd.DataFrame(mca_obj.fs_r(N=self.n_factors), columns= ['mca_factor' + str(x) for x in range(self.n_factors)])\n        cosines = pd.DataFrame(mca_obj.fs_r(N=self.n_factors), columns= ['mca_cosine' + str(x) for x in range(self.n_factors)])\n        mca_df = pd.concat([factors, cosines], axis =1)\n        return mca_df\n\nclass GetDummies(BaseEstimator, TransformerMixin):\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X): \n        dummy_df = pd.get_dummies(X[self.key])\n        return dummy_df\n\npipeline = Pipeline(steps=[\n    ('union', FeatureUnion(\n        transformer_list=[\n            ('transform_text',\n             Pipeline([\n                 ('select_column', ColumnSelector(key='Text')),\n                 ('tfidf', TfidfVectorizer(analyzer='word', max_df=0.9, stop_words='english', norm='l2',\n                                           sublinear_tf=True, use_idf=True)),\n                 ('svd', TruncatedSVD(algorithm='randomized', n_components=100)),\n             ]),\n             ),\n            \"\"\"\n            ('transform_categories',\n             Pipeline([\n                 ('select_columns', ColumnSelector(key=['Gene', 'Variation'])),\n                 ('dummy_mca', DummyMCA(n_factors=207)),\n             ]),\n             ),\n             \"\"\"\n            ('transform_categories',\n             Pipeline([\n                 ('select_columns', ColumnSelector(key=['Gene', 'Variation'])),\n                 ('get_dummy', GetDummies()),\n                 #('svd', TruncatedSVD(algorithm='randomized', n_components=207)),\n             ]),\n             ),\n        ],\n    )),\n    ('xgb', XGBClassifier(learning_rate=0.13,\n                  n_estimators=55,\n                  max_depth=5,\n                  min_child_weight=8,\n                  gamma=0,\n                  subsample=0.9,\n                  colsample_bytree=0.6,\n                  objective='multi:softprob',\n                  nthread=4,\n                  scale_pos_weight=1,\n                  reg_alpha=0.0001,\n                  seed=7)),\n])","metadata":{"_uuid":"c5dd8f57305270c97bbe0952b3f8e563e3b4f610","_cell_guid":"4d8f93a9-8012-4992-98c0-9ebc13c17bd5"}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"features_train = train_combined[['Gene', 'Variation', 'Text']]\ntarget_train = lbe.fit_transform(train_combined['Class'])\n\nfeatures_test = test_combined[['Gene', 'Variation', 'Text']]\n\n\npipeline.fit(features_train, target_train)\npred = pipeline.predict_proba(features_test)","metadata":{"_uuid":"c3ad4a98ab98cceba363b78bf301b2dad47a670f","_cell_guid":"810e0e54-3da9-43c9-8481-c922dff78ae7","collapsed":true}},{"cell_type":"code","outputs":[],"execution_count":null,"source":"submission_df = pd.DataFrame(pred, columns=['class_'+str(c+1) for c in range(9)])\nsubmission_df['ID'] = test_combined['ID']\nsubmission_df.head()","metadata":{"_uuid":"704c0f5e8712dd0aceb29a3c343ef55047db188e","_cell_guid":"74f24606-d6aa-46ce-afed-4079966db057","collapsed":true}}],"metadata":{"language_info":{"nbconvert_exporter":"python","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.3","name":"python","mimetype":"text/x-python","pygments_lexer":"ipython3"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}}}