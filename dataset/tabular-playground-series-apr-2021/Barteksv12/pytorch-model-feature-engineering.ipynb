{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os, tqdm, warnings\nfrom itertools import chain, combinations\nwarnings.simplefilter('ignore')\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\n\nfrom category_encoders.cat_boost import CatBoostEncoder","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/tabular-playground-series-apr-2021/train.csv')\ntest_df = pd.read_csv('../input/tabular-playground-series-apr-2021/test.csv')\nsample_sub = pd.read_csv('../input/tabular-playground-series-apr-2021/sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device =  'cuda' if torch.cuda.is_available() else 'cpu'\n\nbatch_size = 32 \nlr = 0.001\nepochs = 200\nes = 7\nlr_reduce = es - 3\npath = './model_best'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_df['Ticket'].fillna('X', inplace=True)\n# train_df['Ticket'] = train_df['Ticket'].apply(lambda x: x.split())\n# types = set([x[0] for x in train_df['Ticket'].to_numpy() if len(x) > 1])\n# len(list(types))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['Cabin'].fillna('X-1', inplace=True)\n# types = set()\nnumbers = list()\nfor i in train_df['Cabin']:\n    numbers.append(int(i[1:]))\nprint(np.min(numbers))\nprint(np.max(numbers))\nprint(np.std(numbers))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Engineering\n* ['Cabin_letter'] get cabin letter\n* ['Cabin_num'] get ticket type\n* ['Ticket_type'] get cabin number // 1000 , eg C1534 = 2, A.9875 = 10 // didn't work\n* interactions between numerical columns","metadata":{}},{"cell_type":"code","source":"to_oh = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', 'Cabin_letter', 'Ticket_type', 'Cabin_num']\nto_interact = ['Pclass','Age','SibSp','Parch','Fare']\n\ndef normalize(col):\n    return (col - col.mean()) / col.std()\n\ndef feature_engineering(train, test):\n    df = pd.concat([test, train], axis=0)\n    \n    df['Age'].fillna(df['Age'].mean(), inplace=True)\n    df['Fare'].fillna(df['Fare'].mean(), inplace=True)\n    df['Embarked'].fillna('X', inplace=True)\n    df['Cabin'].fillna('X-1', inplace=True)\n    df['Ticket'].fillna('X', inplace=True)\n    \n    for i in combinations(to_interact, 2):\n        new_col = i[0] + '_' + i[1]\n        df[new_col] = df[i[0]] * df[i[1]]\n        df[new_col] = normalize(df[new_col])\n    \n    \n    df['Cabin_letter'] = df['Cabin'].apply(lambda x: x[0])\n    df['Cabin_num'] = df['Cabin'].apply(lambda x: int(x[1:]) // 1000)\n    df['Ticket_type'] = df['Ticket'].apply(lambda x: x[0])\n    \n    df['Age'] = normalize(df['Age'])\n    df['Fare'] = normalize(df['Fare'])\n#     df['Cabin_num'] = normalize(df['Cabin_num'])\n    \n    df = df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'Ticket'], axis=1)\n    df = pd.concat([pd.get_dummies(df[to_oh]), df.drop(to_oh, axis=1)], axis=1)\n\n    new_train = df[len(train):]\n    new_test = df[:len(train)]\n    \n    return new_train, new_test.drop(['Survived'], axis=1)\ntrain_df, test_df = feature_engineering(train_df, test_df)\nINPUT_SHAPE = len(test_df.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TitanicDataset():\n    def __init__(self, data, target = None):\n        self.data = data.values\n        if target is not None:\n            self.target = target.values\n        else:\n            self.target = None\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        x = self.data[idx, :]\n        x = torch.tensor(x, dtype=torch.float32)\n        \n        if self.target is not None:\n            y = self.target[idx]\n            return x, torch.tensor([y], dtype=torch.float32)\n        else:\n            return x\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TitanicModel(nn.Module):\n    def __init__(self, input_shape=INPUT_SHAPE):\n        super().__init__()\n        self.fc1 = nn.Linear(input_shape, 32)\n        self.bn1 = nn.BatchNorm1d(32)\n        self.drop1 = nn.Dropout(0.3)\n        self.fc2 = nn.Linear(32, 32)\n        self.bn2 = nn.BatchNorm1d(32)\n        self.drop2 = nn.Dropout(0.3)\n        self.out = nn.Linear(32, 1)\n        \n    def forward(self, inp):\n        x = self.fc1(inp)\n        x = self.bn1(x)\n        x = F.relu(x)\n        x = self.drop1(x)\n        \n        x = self.fc2(x)\n        x = self.bn2(x)\n        x = F.relu(x)\n        x = self.drop2(x)\n        \n        out = self.out(x)\n        \n        return out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(model, train_dl, optimizer, criterion):\n    model.train()\n    epoch_loss = []\n    for (X, y) in train_dl:\n        X = X.to(device)\n        y = y.to(device)\n        optimizer.zero_grad()\n        preds = model(X)\n        loss = criterion(preds, y)\n        loss.backward()\n        optimizer.step()\n        epoch_loss.append(loss.item())\n    return np.mean(epoch_loss)\n\ndef validate(model, valid_dl, criterion):\n    model.eval()\n    valid_loss = []\n    with torch.no_grad():\n        for (X, y) in valid_dl:\n            X = X.to(device)\n            y = y.to(device)\n            preds = model(X)\n            loss = criterion(preds, y)\n            valid_loss.append(loss.item())\n    return np.mean(valid_loss)\n\n\ndef train():\n    best_loss = 10e10\n    es_count = 0\n    global lr\n    \n    X_train, X_test, y_train, y_test = train_test_split(\n        train_df.drop(['Survived'], axis=1),\n        train_df['Survived'],\n        stratify=train_df['Survived']\n    )\n    \n    train_dl = DataLoader(\n        TitanicDataset(X_train, y_train),\n        batch_size=batch_size,\n        shuffle=True\n    )\n    valid_dl = DataLoader(\n        TitanicDataset(X_test, y_test),\n        batch_size=8*batch_size\n    )\n    \n    criterion = nn.BCEWithLogitsLoss()\n    model = TitanicModel().to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr)\n    \n    pbar = tqdm.tqdm(range(epochs))\n    for epoch in pbar:\n        train_loss = train_one_epoch(model, train_dl, optimizer, criterion)\n        valid_loss = validate(model, valid_dl, criterion)\n        \n        print(f\"{epoch + 1} epoch, train loss = {train_loss:.6f}, valid_loss = {valid_loss:.6f}\")\n        if valid_loss < best_loss:\n            best_loss = valid_loss\n            torch.save(model.state_dict(), path)\n            es_count = 0\n        else:\n            es_count += 1\n        \n        if es_count == es:\n            break\n        if es_count == lr_reduce:\n            lr *= 0.5\ntrain()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict():\n    valid_dl = DataLoader(\n        TitanicDataset(test_df),\n        batch_size=8*batch_size\n    )\n    model = TitanicModel()\n    model.load_state_dict(torch.load(path))\n    model.eval()\n    preds = []\n    \n    with torch.no_grad():\n        for X in valid_dl:\n            y = F.sigmoid(model(X))\n            preds.append(y.detach().numpy())\n            \n    return preds\n\npreds = predict()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub['Survived'] = np.where(np.vstack(preds).squeeze() >= 0.5, 1, 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}