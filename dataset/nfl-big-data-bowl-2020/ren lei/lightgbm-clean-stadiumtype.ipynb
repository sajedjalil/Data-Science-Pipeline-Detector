{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tqdm\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\nimport xgboost\nimport gc\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Config Test env\n\nStores your predictions for the current rushing play. Expects the same format as you saw in sample_prediction_df returned from the iter_test generator"},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle.competitions import nflrush\nenv = nflrush.make_env()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# You can only iterate through a result from `env.iter_test()` once\n# so be careful not to lose it once you start iterating.\niter_test = env.iter_test()\ntype(iter_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data=pd.read_csv(\"../input/nfl-big-data-bowl-2020/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 特征提取"},{"metadata":{},"cell_type":"markdown","source":"#### 数据清洗"},{"metadata":{"trusted":true},"cell_type":"code","source":"# object dtype columns.\nfor c in train_data.columns:\n    if train_data[c].dtype==\"object\":\n        print(c, \"is object dtype.\",\"  lenght=\",len(train_data[c].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#StadiumType\ntrain_data[\"StadiumType\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from https://www.kaggle.com/bgmello/neural-networks-feature-engineering-for-the-win/output\n# clean StadiumType\ndef clean_StadiumType(txt):\n    if pd.isna(txt):\n        return np.nan\n    txt=txt.lower()# lower case\n    txt=txt.strip()# return a copy\n    txt=txt.replace(\"outdoors\",\"outdoor\")\n    txt=txt.replace(\"oudoor\",\"outdoor\")\n    txt=txt.replace(\"ourdoor\",\"outdoor\")\n    txt=txt.replace(\"outdor\",\"outdoor\")\n    txt=txt.replace(\"outddors\",\"outdoor\")\n    txt=txt.replace(\"outside\",\"outdoor\")\n    txt=txt.replace(\"indoors\",\"indoor\")\n    txt=txt.replace(\"retractable \",\"retr\")\n#     txt=txt.replace(\" \",\"\")\n    return txt\ntrain_data[\"StadiumType\"]=train_data[\"StadiumType\"].apply(clean_StadiumType)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def transform_StadiumType(txt):\n    if pd.isna(txt):\n        return np.nan\n    if 'outdoor' in txt or 'open' in txt:\n        return 1\n    if 'indoor' in txt or 'closed' in txt:\n        return 0\n    \n    return np.nan\ntrain_data[\"StadiumType\"]=train_data[\"StadiumType\"].apply(transform_StadiumType)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# # author : ryancaldwell\n# # Link : https://www.kaggle.com/ryancaldwell/location-eda\n# def create_features(df, deploy=False):\n#     def new_X(x_coordinate, play_direction):\n#         if play_direction == 'left':\n#             return 120.0 - x_coordinate\n#         else:\n#             return x_coordinate\n\n#     def new_line(rush_team, field_position, yardline):\n#         if rush_team == field_position:\n#             # offense starting at X = 0 plus the 10 yard endzone plus the line of scrimmage\n#             return 10.0 + yardline\n#         else:\n#             # half the field plus the yards between midfield and the line of scrimmage\n#             return 60.0 + (50 - yardline)\n\n#     def new_orientation(angle, play_direction):\n#         if play_direction == 'left':\n#             new_angle = 360.0 - angle\n#             if new_angle == 360.0:\n#                 new_angle = 0.0\n#             return new_angle\n#         else:\n#             return angle\n\n#     def euclidean_distance(x1,y1,x2,y2):\n#         x_diff = (x1-x2)**2\n#         y_diff = (y1-y2)**2\n\n#         return np.sqrt(x_diff + y_diff)\n\n#     def back_direction(orientation):\n#         if orientation > 180.0:\n#             return 1\n#         else:\n#             return 0\n\n#     def update_yardline(df):\n#         new_yardline = df[df['NflId'] == df['NflIdRusher']]\n#         new_yardline['YardLine'] = new_yardline[['PossessionTeam','FieldPosition','YardLine']].apply(lambda x: new_line(x[0],x[1],x[2]), axis=1)\n#         new_yardline = new_yardline[['GameId','PlayId','YardLine']]\n\n#         return new_yardline\n\n#     def update_orientation(df, yardline):\n#         df['X'] = df[['X','PlayDirection']].apply(lambda x: new_X(x[0],x[1]), axis=1)\n#         df['Orientation'] = df[['Orientation','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n#         df['Dir'] = df[['Dir','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n\n#         df = df.drop('YardLine', axis=1)\n#         df = pd.merge(df, yardline, on=['GameId','PlayId'], how='inner')\n\n#         return df\n\n#     def back_features(df):\n#         carriers = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','NflIdRusher','X','Y','Orientation','Dir','YardLine']]\n#         carriers['back_from_scrimmage'] = carriers['YardLine'] - carriers['X']\n#         carriers['back_oriented_down_field'] = carriers['Orientation'].apply(lambda x: back_direction(x))\n#         carriers['back_moving_down_field'] = carriers['Dir'].apply(lambda x: back_direction(x))\n#         carriers = carriers.rename(columns={'X':'back_X',\n#                                             'Y':'back_Y'})\n#         carriers = carriers[['GameId','PlayId','NflIdRusher','back_X','back_Y','back_from_scrimmage','back_oriented_down_field','back_moving_down_field']]\n\n#         return carriers\n\n#     def features_relative_to_back(df, carriers):\n#         player_distance = df[['GameId','PlayId','NflId','X','Y']]\n#         player_distance = pd.merge(player_distance, carriers, on=['GameId','PlayId'], how='inner')\n#         player_distance = player_distance[player_distance['NflId'] != player_distance['NflIdRusher']]\n#         player_distance['dist_to_back'] = player_distance[['X','Y','back_X','back_Y']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n\n#         player_distance = player_distance.groupby(['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field'])\\\n#                                          .agg({'dist_to_back':['min','max','mean','std']})\\\n#                                          .reset_index()\n#         player_distance.columns = ['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field',\n#                                    'min_dist','max_dist','mean_dist','std_dist']\n\n#         return player_distance\n\n#     def defense_features(df):\n#         rusher = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','Team','X','Y']]\n#         rusher.columns = ['GameId','PlayId','RusherTeam','RusherX','RusherY']\n\n#         defense = pd.merge(df,rusher,on=['GameId','PlayId'],how='inner')\n#         defense = defense[defense['Team'] != defense['RusherTeam']][['GameId','PlayId','X','Y','RusherX','RusherY']]\n#         defense['def_dist_to_back'] = defense[['X','Y','RusherX','RusherY']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n\n#         defense = defense.groupby(['GameId','PlayId'])\\\n#                          .agg({'def_dist_to_back':['min','max','mean','std']})\\\n#                          .reset_index()\n#         defense.columns = ['GameId','PlayId','def_min_dist','def_max_dist','def_mean_dist','def_std_dist']\n\n#         return defense\n\n#     def static_features(df):\n#         static_features = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','X','Y','S','A','Dis','Orientation','Dir',\n#                                                             'YardLine','Quarter','Down','Distance','DefendersInTheBox']].drop_duplicates()\n#         static_features['DefendersInTheBox'] = static_features['DefendersInTheBox'].fillna(np.mean(static_features['DefendersInTheBox']))\n\n#         return static_features\n    \n#     def split_personnel(s):\n#         splits = s.split(',')\n#         for i in range(len(splits)):\n#             splits[i] = splits[i].strip()\n\n#         return splits\n\n#     def defense_formation(l):\n#         dl = 0\n#         lb = 0\n#         db = 0\n#         other = 0\n\n#         for position in l:\n#             sub_string = position.split(' ')\n#             if sub_string[1] == 'DL':\n#                 dl += int(sub_string[0])\n#             elif sub_string[1] in ['LB','OL']:\n#                 lb += int(sub_string[0])\n#             else:\n#                 db += int(sub_string[0])\n\n#         counts = (dl,lb,db,other)\n\n#         return counts\n\n#     def offense_formation(l):\n#         qb = 0\n#         rb = 0\n#         wr = 0\n#         te = 0\n#         ol = 0\n\n#         sub_total = 0\n#         qb_listed = False\n#         for position in l:\n#             sub_string = position.split(' ')\n#             pos = sub_string[1]\n#             cnt = int(sub_string[0])\n\n#             if pos == 'QB':\n#                 qb += cnt\n#                 sub_total += cnt\n#                 qb_listed = True\n#             # Assuming LB is a line backer lined up as full back\n#             elif pos in ['RB','LB']:\n#                 rb += cnt\n#                 sub_total += cnt\n#             # Assuming DB is a defensive back and lined up as WR\n#             elif pos in ['WR','DB']:\n#                 wr += cnt\n#                 sub_total += cnt\n#             elif pos == 'TE':\n#                 te += cnt\n#                 sub_total += cnt\n#             # Assuming DL is a defensive lineman lined up as an additional line man\n#             else:\n#                 ol += cnt\n#                 sub_total += cnt\n\n#         # If not all 11 players were noted at given positions we need to make some assumptions\n#         # I will assume if a QB is not listed then there was 1 QB on the play\n#         # If a QB is listed then I'm going to assume the rest of the positions are at OL\n#         # This might be flawed but it looks like RB, TE and WR are always listed in the personnel\n#         if sub_total < 11:\n#             diff = 11 - sub_total\n#             if not qb_listed:\n#                 qb += 1\n#                 diff -= 1\n#             ol += diff\n\n#         counts = (qb,rb,wr,te,ol)\n\n#         return counts\n    \n#     def personnel_features(df):\n#         personnel = df[['GameId','PlayId','OffensePersonnel','DefensePersonnel']].drop_duplicates()\n#         personnel['DefensePersonnel'] = personnel['DefensePersonnel'].apply(lambda x: split_personnel(x))\n#         personnel['DefensePersonnel'] = personnel['DefensePersonnel'].apply(lambda x: defense_formation(x))\n#         personnel['num_DL'] = personnel['DefensePersonnel'].apply(lambda x: x[0])\n#         personnel['num_LB'] = personnel['DefensePersonnel'].apply(lambda x: x[1])\n#         personnel['num_DB'] = personnel['DefensePersonnel'].apply(lambda x: x[2])\n\n#         personnel['OffensePersonnel'] = personnel['OffensePersonnel'].apply(lambda x: split_personnel(x))\n#         personnel['OffensePersonnel'] = personnel['OffensePersonnel'].apply(lambda x: offense_formation(x))\n#         personnel['num_QB'] = personnel['OffensePersonnel'].apply(lambda x: x[0])\n#         personnel['num_RB'] = personnel['OffensePersonnel'].apply(lambda x: x[1])\n#         personnel['num_WR'] = personnel['OffensePersonnel'].apply(lambda x: x[2])\n#         personnel['num_TE'] = personnel['OffensePersonnel'].apply(lambda x: x[3])\n#         personnel['num_OL'] = personnel['OffensePersonnel'].apply(lambda x: x[4])\n\n#         # Let's create some features to specify if the OL is covered\n#         personnel['OL_diff'] = personnel['num_OL'] - personnel['num_DL']\n#         personnel['OL_TE_diff'] = (personnel['num_OL'] + personnel['num_TE']) - personnel['num_DL']\n#         # Let's create a feature to specify if the defense is preventing the run\n#         # Let's just assume 7 or more DL and LB is run prevention\n#         personnel['run_def'] = (personnel['num_DL'] + personnel['num_LB'] > 6).astype(int)\n\n#         personnel.drop(['OffensePersonnel','DefensePersonnel'], axis=1, inplace=True)\n        \n#         return personnel\n\n#     def combine_features(relative_to_back, defense, static, personnel, deploy=deploy):\n#         df = pd.merge(relative_to_back,defense,on=['GameId','PlayId'],how='inner')\n#         df = pd.merge(df,static,on=['GameId','PlayId'],how='inner')\n#         df = pd.merge(df,personnel,on=['GameId','PlayId'],how='inner')\n\n#         if not deploy:\n#             df = pd.merge(df, outcomes, on=['GameId','PlayId'], how='inner')\n\n#         return df\n    \n#     yardline = update_yardline(df)\n#     df = update_orientation(df, yardline)\n#     back_feats = back_features(df)\n#     rel_back = features_relative_to_back(df, back_feats)\n#     def_feats = defense_features(df)\n#     static_feats = static_features(df)\n#     personnel = personnel_features(df)\n#     basetable = combine_features(rel_back, def_feats, static_feats, personnel, deploy=deploy)\n#     return basetable\n# outcomes = train_data[['GameId','PlayId','Yards']].drop_duplicates()\n# train_data = create_features(train_data, False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# # from https://www.kaggle.com/c/nfl-big-data-bowl-2020/discussion/112681#latest-649087\n# # prove 0.002\n# Turf = {'Field Turf':'Artificial', 'A-Turf Titan':'Artificial', 'Grass':'Natural',\n#         'UBU Sports Speed S5-M':'Artificial', 'Artificial':'Artificial', \n#         'DD GrassMaster':'Artificial', 'Natural Grass':'Natural',\n#         'UBU Speed Series-S5-M':'Artificial', 'FieldTurf':'Artificial', \n#         'FieldTurf 360':'Artificial', 'Natural grass':'Natural', 'grass':'Natural', \n#         'Natural':'Natural', 'Artifical':'Artificial', 'FieldTurf360':'Artificial', \n#         'Naturall Grass':'Natural', 'Field turf':'Artificial', 'SISGrass':'Artificial', \n#         'Twenty-Four/Seven Turf':'Artificial', 'natural grass':'Natural'}\n# train_data['Turf'] = train_data['Turf'].map(Turf)\n# train_data['Turf'] = train_data['Turf'] == 'Natural'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unused_columns = [\"GameId\",\"PlayId\",\"Team\",\"Yards\",\"TimeHandoff\",\"TimeSnap\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"## Possession Team\n# train_data[(train_data['PossessionTeam']!=train_data['HomeTeamAbbr']) & (train_data['PossessionTeam']!= \\\n#         train_data['VisitorTeamAbbr'])][['PossessionTeam', 'HomeTeamAbbr', 'VisitorTeamAbbr']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_columns=[]\nfor c in train_data.columns:\n    if c not in unused_columns+[\"PlayerBirthDate\"] and len(set(train_data[c][:11]))!=1:\n        unique_columns.append(c)\n        print(c,\"is unique!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_columns=[]\nfor c in train_data.columns:\n    if c not in unique_columns+unused_columns+[\"GameClock\",\"DefensePersonnel\",\"PlayerBirthDate\"]:\n        all_columns.append(c)\n        \nall_columns.extend([\"DL\",\"LB\",\"DB\",\"BirthY\"])\nfor c in unique_columns:\n    for i in range(22):\n        all_columns.append(c+str(i))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lbl_dict={}\nfor c in train_data.columns:\n    if c==\"DefensePersonnel\":\n        DL,LB,DB=[],[],[]\n        for line in train_data[c]:\n            features=line.split(\", \")\n            DL.append(int(features[0][0]))\n            LB.append(int(features[1][0]))\n            DB.append(int(features[2][0]))\n        train_data[\"DL\"],train_data[\"LB\"],train_data[\"DB\"]=DL,LB,DB\n    elif c==\"GameClock\":\n        ClockSecond=[]\n        for line in train_data[c]:\n            features=line.split(\":\")\n            ClockSecond.append(features[0]*60*60+features[1]*60+features[2])\n        train_data[\"GameClock\"]=ClockSecond\n    elif c==\"PlayerBirthDate\":\n        BirthY=[]\n        for line in train_data[c]:\n            features=line.split(\"/\")\n            BirthY.append(int(features[-1]))\n        train_data[\"BirthY\"]=BirthY\n    elif train_data[c].dtype==\"object\" and c not in unused_columns:\n        lbl=LabelEncoder()\n        lbl.fit(list(train_data[c].values))\n        lbl_dict[c]=lbl\n        train_data[c]=lbl.transform(list(train_data[c].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ntrain=len(train_data.index)\nTrain_data=np.zeros(((ntrain-1)//22+1,len(all_columns)))\nfor ix in tqdm.tqdm(range(0,ntrain,22)):\n    count=0\n    for c in all_columns:\n        if c in train_data.columns:\n            Train_data[ix//22][count]=train_data[c][ix]\n            count+=1\n        if c in unique_columns:\n            for j in range(22):\n                Train_data[ix//22][count]=train_data[c][ix+j]\n                count+=1     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=pd.DataFrame(data=Train_data,columns=all_columns)\ny_train=np.array([train_data[\"Yards\"][i] for i in range(0,ntrain,22)],dtype=np.int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=[0]*199\nfor y in y_train:\n    data[y]+=1\nplt.figure()\nplt.plot([ix-99 for ix in range(199)],data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### y_train Normalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"Scaler=StandardScaler()\nScaler.fit(y_train.reshape(-1,1))\nY_train=Scaler.transform(y_train.reshape(-1,1)).flatten()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape,Y_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### KFold 交叉验证"},{"metadata":{"trusted":true},"cell_type":"code","source":"folds=10\nseed=22\nkf=KFold(n_splits=folds,shuffle=True,random_state=seed)\ny_val_pred=np.zeros(((ntrain-1)//22+1))\nmodels=[]\nfor tr_idx,val_idx in kf.split(X_train,Y_train):\n    x_tr,y_tr=X_train.iloc[tr_idx,:],Y_train[tr_idx]\n    x_val,y_val=X_train.iloc[val_idx,:],Y_train[val_idx]\n    clf = lgb.LGBMRegressor(n_estimators=200,learning_rate=0.01)\n#     clf=xgboost.XGBRegressor(n_estimators=100,learning_rate=0.1,objective='reg:squarederror',n_jobs=-1)\n    clf.fit(x_tr,y_tr,eval_set=[(x_val,y_val)],\n           early_stopping_rounds=20,verbose=False)\n    y_val_pred[val_idx]+=clf.predict(x_val, num_iteration=clf.best_iteration_)\n#     y_val_pred[val_idx]+=clf.predict(x_val)\n    models.append(clf)\n    \ngc.collect()  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred=np.zeros(((ntrain-1)//22+1,199))\nY_ans=np.zeros(((ntrain-1)//22+1,199))\nfor ix,p in enumerate(np.round(Scaler.inverse_transform(y_val_pred))):\n    p+=99\n    for j in range(199):\n        if j>=(p+10):\n            Y_pred[ix][j]=1.0\n        elif j>=(p-10):\n            Y_pred[ix][j]=(j+10-p)*0.05\n            \nfor ix,p in enumerate(Scaler.inverse_transform(Y_train)):\n    p+=99\n    for j in range(199):\n        if j>=p:\n            Y_ans[ix][j]=1.0\n\nprint(\"validation score:\",np.mean(np.power(Y_pred-Y_ans,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(all_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  test_df:DataFrame with player and game observations for the next rushing play.\n#  sample_prediction_df: DataFrame with an example yardage prediction. \n#   Intended to be filled in and passed back to the predict function.\nindex=0\nfor (test_df, sample_prediction_df) in tqdm.tqdm(env.iter_test()):\n    for c in test_df.columns:\n        if c==\"DefensePersonnel\":\n            try:\n                for ix,line in enumerate(test_df[c]):\n                    features=line.split(\", \")\n                    test_df[\"DL\"][ix]=int(features[0][0])\n                    test_df[\"LB\"][ix]=int(features[1][0])\n                    test_df[\"DB\"][ix]=int(features[2][0])\n            except:\n                test_df[\"DL\"]=[np.nan for _ in range(22) ]\n                test_df[\"LB\"]=[np.nan for _ in range(22) ]\n                test_df[\"DB\"]=[np.nan for _ in range(22) ]\n                    \n\n        elif c==\"GameClock\":\n            try:\n                for ix,line in enumerate(test_df[c]):\n                    features=line.split(\":\")\n                    test_df[\"GameHour\"][ix]=int(features[0]*60*60+features[1]*60+features[2])\n            except:\n                test_df[\"GameHour\"]=[np.nan for _ in range(22) ]\n        elif c==\"PlayerBirthDate\":\n            try:\n                for ix,line in enumerate(test_df[c]):\n                    features=line.split(\"/\")\n                    test_df[\"BirthY\"][ix]=int(features[-1])\n            except:\n                test_df[\"BirthY\"]=[np.nan for _ in range(22) ]\n        elif c in lbl_dict and test_df[c].dtype==\"object\" and c not in unused_columns\\\n            and not pd.isnull(test_df[c]).any():\n            try:\n                test_df[c]=lbl_dict[c].transform(list(test_df[c].values))\n            except:\n                test_df[c]=np.nan\n    count=0\n    test_data=np.zeros((len(all_columns)))\n    for c in all_columns:\n        if c in test_df.columns:\n            try:\n                test_data[count]=test_df[c][index]\n            except:\n                test_data[count]=np.nan\n            count+=1\n#     for c in unique_columns:\n        if c in unique_columns:\n            for j in range(22):\n                try:\n                    test_data[count]=test_df[c][index+j]\n                except:\n                    test_data[count]=[np.nan for _ in range(22)]\n                count+=1\n    Y_pred=np.zeros((199))\n    Y_pred_p=np.sum(np.round(Scaler.inverse_transform([model.predict(test_data.reshape(1,-1))[0] for model in models])))/folds\n    Y_pred_p+=99\n    for j in range(199):\n        if j>=Y_pred_p+10:\n            Y_pred[j]=1.0\n        elif j>=Y_pred_p-10:\n            Y_pred[j]=(j+10-Y_pred_p)*0.05\n    env.predict(pd.DataFrame(data=[Y_pred],columns=sample_prediction_df.columns))\n    index+=22","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## write_submission_file function"},{"metadata":{"trusted":true},"cell_type":"code","source":"env.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}