{"cells":[{"metadata":{},"cell_type":"markdown","source":"# NFL Big Data Bowl Physics Model\n\nThis kernel is based on the one that finished 36th out of 2038 entries on the public leader board of the NFL Big Data Bowl Competition. It's mostly a physics model, utilizing relative player positions, momentum, etc. All hyperparameter tuning was done using Weights and Biases visualizations and tools."},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install wandb","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import wandb\nfrom wandb.keras import WandbCallback\n\nimport numpy as np # linear algebra\nimport numpy.matlib\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport tensorflow as tf\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport gc\nimport sys\n\n# Any results you write to the current directory are saved as output.\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.optimizers import SGD\nfrom  keras.losses import categorical_crossentropy\nfrom keras.regularizers import l2\nimport keras.backend as K\nK.set_floatx('float32')\n\nfrom kaggle.competitions import nflrush","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Cleansing Functions\n\nThese functions fix errors in the database and reorganize the data such that the offense, defense and the runningback himself are in proper row position."},{"metadata":{"trusted":true},"cell_type":"code","source":"def error_correcting_codes(df):\n    df = df.replace('BLT', 'BAL')\n    df = df.replace('HST', 'HOU')\n    df = df.replace('ARZ', 'ARI')\n    df = df.replace('CLV', 'CLE')\n    return df\n  \n\ndef organize_positions(df):\n    return (df.loc[(df['PossessionTeam']==df['HomeTeamAbbr'])&(df['Team']=='away') | (df['PossessionTeam']==df['VisitorTeamAbbr'])&(df['Team']=='home')].copy().reset_index(),\n      df.loc[((df['PossessionTeam']==df['HomeTeamAbbr'])&(df['Team']=='home') | (df['PossessionTeam']==df['VisitorTeamAbbr'])&(df['Team']=='away'))&(df['NflId']!=df['NflIdRusher'])].copy().reset_index(),\n      df.loc[df['NflId']==df['NflIdRusher']].copy().reset_index())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Doubling Functions\n\nThese functions perform the \"doubling\" operations. Because most of the data columns are player-specific, and because the order of the defensive and offensive players in the dataset is largely irrelevant, the model can learn much better if we increase the size of the dataset by randomly shuffling the defensive and offensive player columns. More on this later.****"},{"metadata":{"trusted":true},"cell_type":"code","source":"def doubledown(X, doublings=1):\n    np.random.seed(3)\n    for w in range(doublings):\n        X_dupe2 = np.concatenate((X.copy(), X.copy()), axis=0)\n        for i in range(X.shape[0]):\n            X_dupe2[2*i, :] = X[i, :]\n            X_dupe2[2*i+1, :] = X[i, :]\n        X = X_dupe2\n    return X\n\n\ndef physics_doubledown(X, doublings, width):\n    np.random.seed(3)\n    for w in range(doublings):\n        X_dupe = X.copy()\n        X_dupe2 = np.concatenate((X.copy(), X.copy()), axis=0)\n        zwinger = np.arange(11)\n        np.random.shuffle(zwinger)\n        for (i,j) in enumerate(zwinger):\n            X_dupe[:, width*i:width*i+width] = X[:, width*j:width*j+width]\n        zwinger = np.arange(10)\n        np.random.shuffle(zwinger)\n        for (i,j) in enumerate(zwinger):\n            X_dupe[:, width*(i+11):width*(i+12)] = X[:, width*(j+11):width*(j+12)]\n        for i in range(X.shape[0]):\n            X_dupe2[2*i, :] = X[i, :]\n            X_dupe2[2*i+1, :] = X_dupe[i, :]\n        X = X_dupe2\n    return X","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Physics Functions\n\nThese functions define the \"physics\" data from which comprise most of the dataset. The most interesting physics is:\n- a pseudo-gravity term, which is proportional to the mass of the player and inversely proportional to the player's distance to the running back (makes sense, sort of, that it's not inverse square, as the field is 2D)\n- a pseudo-angular-momentum term, which is proportional to the dot-product of a player's momentum with the inverse distance to the running back. Real angular momentum uses the cross-product of momentum with distance, but that makes no sense here\n- future projections: using the players' position, velocity and acceleration, we can predict where they all will be in the near future"},{"metadata":{"trusted":true},"cell_type":"code","source":"def physics_init(df):\n    way = -2*(df['PlayDirection']=='left') + 1\n    theta = way*df['Dir']*np.pi/180\n    df['X'] = (df['PlayDirection']=='right')*df['X'] + (df['PlayDirection']=='left')*(120 - df['X'])\n    df['Sx'] = np.sin(theta)*df['S']\n    df['Sy'] = np.cos(theta)*df['S']\n    df['Ax'] = np.sin(theta)*df['A']\n    df['Ay'] = np.cos(theta)*df['A']\n    df['EquivYardLine'] = (df['PossessionTeam']==df['FieldPosition'])*(df['YardLine']+10) + (df['PossessionTeam']!=df['FieldPosition'])*(110-df['YardLine'])\n\n    defn, off, RBs = organize_positions(df)\n\n    defn['X'] -= RBs.loc[[i//11 for i in defn.index], 'X'].values\n    defn['Y'] -= RBs.loc[[i//11 for i in defn.index], 'Y'].values\n    defn = defn.loc[:, ('PlayId', 'PlayerWeight', 'Sx', 'Sy', 'Ax', 'Ay', 'X', 'Y')]\n    defn.fillna(0, inplace=True)\n    defn['Infl'] = defn['PlayerWeight']/(np.square(defn['X']) + np.square(defn['Y']))**0.5\n    defn['AngularMomentum'] = -defn['PlayerWeight']*(defn['X']*defn['Sx'] + defn['Y']*defn['Sy'])/(np.square(defn['X']) + np.square(defn['Y']))\n\n    off['X'] -= RBs.loc[[i//10 for i in off.index], 'X'].values\n    off['Y'] -= RBs.loc[[i//10 for i in off.index], 'Y'].values\n    off = off.loc[:, ('PlayId', 'PlayerWeight', 'Sx', 'Sy', 'Ax', 'Ay', 'X', 'Y')]\n    off.fillna(0, inplace=True)\n    off['Infl'] = off['PlayerWeight']/(np.square(off['X']) + np.square(off['Y']))**0.5\n    off['AngularMomentum'] = -off['PlayerWeight']*(off['X']*off['Sx'] + off['Y']*off['Sy'])/(np.square(off['X']) + np.square(off['Y']))\n\n    RBs['YardsBehindScrimmage'] = RBs['EquivYardLine'] - RBs['X']\n    RBs['X'] = 0\n    RBs['Y'] = 0\n    RBs = RBs.loc[:, ('PlayId', 'YardsBehindScrimmage', 'PlayerWeight', 'Sx', 'Sy', 'Ax', 'Ay', 'X', 'Y')]\n    RBs.fillna(0, inplace=True)\n    \n    return defn, off, RBs\n\n\ndef action(defn, off, RBs, timestep=0.1):\n    t = 0.0\n    while t<timestep:\n        for X in (defn, off, RBs):\n            X['X'] += X['Sx']*0.01 +X['Ax']*0.01**2/2\n            X['Y'] += X['Sy']*0.01 +X['Ay']*0.01**2/2\n            X['Sx'] += X['Ax']*0.01\n            X['Sy'] += X['Ay']*0.01\n            X['Ax'] *= 0.99\n            X['Ay'] *= 0.99\n        t += 0.01\n\n        defn['X'] -= RBs.loc[[i//11 for i in defn.index], 'X'].values\n        defn['Y'] -= RBs.loc[[i//11 for i in defn.index], 'Y'].values\n        defn['Infl'] = defn['PlayerWeight']/(np.square(defn['X']) + np.square(defn['Y']))**0.5\n        defn['AngularMomentum'] = -defn['PlayerWeight']*(defn['X']*defn['Sx'] + defn['Y']*defn['Sy'])/(np.square(defn['X']) + np.square(defn['Y']))\n\n        off['X'] -= RBs.loc[[i//10 for i in off.index], 'X'].values\n        off['Y'] -= RBs.loc[[i//10 for i in off.index], 'Y'].values\n        off['Infl'] = off['PlayerWeight']/(np.square(off['X']) + np.square(off['Y']))**0.5\n        off['AngularMomentum'] = -off['PlayerWeight']*(off['X']*off['Sx'] + off['Y']*off['Sy'])/(np.square(off['X']) + np.square(off['Y']))\n\n        RBs['X'] = 0\n        RBs['Y'] = 0\n\n    return defn, off, RBs\n\ndef generate_physics(df, forward_action=0, timestep=0.1, doublings=0):\n    d, o, r = physics_init(df)\n    df = None\n\n    defn = [d.copy()]\n    off = [o.copy()]\n    RBs = [r.copy()]\n\n    for a in range(forward_action):\n        d, o, r = action(d, o, r, timestep)\n        defn.append(d.copy())\n        off.append(o.copy())\n        RBs.append(r.copy())\n    d, o, r = None, None, None\n\n    for X in (defn, off, RBs):\n        for i in range(len(defn)):\n            X[i]['Px'] = X[i]['Sx']*X[i]['PlayerWeight']\n            X[i]['Py'] = X[i]['Sy']*X[i]['PlayerWeight']\n            X[i]['Fx'] = X[i]['Ax']*X[i]['PlayerWeight']\n            X[i]['Fy'] = X[i]['Ay']*X[i]['PlayerWeight']\n\n    for i in range(len(defn)):\n        if i==0:\n            bigD = defn[i].loc[:, ('Px', 'Py', 'X', 'Y', 'Infl', 'AngularMomentum')].astype(np.float32)\n            bigO = off[i].loc[:, ('Px', 'Py', 'X', 'Y', 'Infl', 'AngularMomentum')].astype(np.float32)\n            backs = RBs[i].loc[:, ('YardsBehindScrimmage', 'Px', 'Py', 'Fx', 'Fy')].astype(np.float32)\n            inst = np.concatenate((np.reshape(bigD.copy().values, (bigD.shape[0]//11, 11*6)), \n                                            np.reshape(bigO.copy().values, (bigO.shape[0]//10, 10*6)), \n                                            backs.copy().values), axis=1)\n            summary = physics_doubledown(inst, doublings, 6)\n        else:\n            bigD = defn[i].loc[:, ('Infl', 'AngularMomentum')].astype(np.float32)\n            bigO = off[i].loc[:, ('Infl', 'AngularMomentum')].astype(np.float32)\n            inst = np.concatenate((np.reshape(bigD.copy().values, (bigD.shape[0]//11, 11*2)), \n                                            np.reshape(bigO.copy().values, (bigO.shape[0]//10, 10*2))), axis=1)\n            summary = np.concatenate((summary, physics_doubledown(inst, doublings, 2)), axis=1)\n    defn, off, RBs = None, None, None\n\n    return summary","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Down Functions\n\nWhat down is it? That matters. If it's 4th and inches, you probably shouldn't expect a 20-yard gain"},{"metadata":{"trusted":true},"cell_type":"code","source":"def down_situation(df):\n    X = df.loc[::22, ('Down', 'Distance')].copy().astype(np.float32)\n    X.fillna(-1, inplace=True)\n    framer = pd.DataFrame(columns=(1.0, 2.0, 3.0, 4.0, 'Distance'), dtype=np.float32)\n    concatenation = pd.concat((pd.get_dummies(X['Down']), X['Distance']), axis=1, join='outer')\n    concatenation = pd.concat((framer, concatenation), axis=0, join='outer')\n    concatenation.fillna(0, inplace=True)\n    return concatenation.values","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Statistical Functions\n\nNeeded for PCA."},{"metadata":{"trusted":true},"cell_type":"code","source":"def stats(array):\n    return array.mean(axis=0), array.std(axis=0)\n\n\ndef normalize(array, mn, stand):\n    return (array - mn) / stand","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Target Functions\n\nExtract the actual yardage from the raw data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_yardudge(df):\n    Y = np.zeros((df.shape[0]//22, 199))\n    for (i, yerds) in enumerate(df['Yards'][::22]):\n        Y[i, yerds+99] = 1\n    return Y.astype(np.float32)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Scoring Function\n\nThe official score is tabulated using Continuous Ranked Probability Score cost function:\n\n$$ \\frac 1 {199M} \\sum_{m=1}^M \\sum_{n=-99}^{99} \\left( P_m(y \\le n) - H(n - Y_m) \\right)^2 $$\n\nwhere $Y_m$ is the actual yardage gained and [](http://)$ H(x) = 1$ if $x \\ge 0$ else $0$."},{"metadata":{"trusted":true},"cell_type":"code","source":"def chirps(y_true, y_pred):\n    Y = np.reshape(np.argmax(y_true, axis=1) - 99, (-1,1))\n    P = np.zeros((y_pred.shape[0], y_pred.shape[1]))\n    stuff = np.zeros(y_pred.shape[0])\n    for i in range(199):\n        stuff += y_pred[:, i]\n        P[:,i] = stuff\n    H = (np.reshape(np.array(range(-99,100)), (1, 199)) - Y) >= 0\n    CRPS = K.square(P - H)\n    return K.mean(CRPS)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Extraction\n\nThis is where we generate the dataset. We do 8 forward projections at 0.1s intervals and 6 data doublings (i.e., a 64-fold increase in data--that's all the alloted RAM can accomodate).\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"global meen, sigma, PCs, doublings, forward_actions, timestep\n\ntrain_df = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2020/train.csv', low_memory=False)\n\ndoublings = 6\nforward_actions = 8\ntimestep = 0.1\n\nY = doubledown(generate_yardudge(train_df), doublings)\n\ntrain_df = error_correcting_codes(train_df)\nX = np.concatenate(\n                (doubledown(down_situation(train_df), doublings), \n                 generate_physics(train_df, forward_actions, timestep, doublings)), \n            axis=1)\ntrain_df = None\n\nmeen, sigma = stats(X)\nX = normalize(X, meen, sigma)\n\nPCs = np.linalg.eig(np.dot(np.transpose(X), X))[1]\nX = np.dot(X, PCs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"create training and test sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"Xtrain = X[0:int(7/8*X.shape[0]), :]\nYtrain = Y[0:int(7/8*Y.shape[0]), :]\nXtest = X[int(7/8*X.shape[0]):, :]\nYtest = Y[int(7/8*Y.shape[0]):, :]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build Model\n\nThis is a standard neural network with three hidden layers and dropout after each. The optimizer uses stochastic gradient descent with nesterov momentum. Additional regularization is with maxnorm/clipnorm."},{"metadata":{"trusted":true},"cell_type":"code","source":"wandb.init(anonymous='allow', project=\"kaggle\")\n\nwandb.config.learning_rate = 0.01541\nwandb.config.decay = 0.00000173\nwandb.config.beta = 0.8858\nwandb.config.clipse = 0.3867\nwandb.config.dropout_rate = 0.6044\nwandb.config.epochs = 14\nwandb.config.batch_size = 180\nwandb.config.hidden_layer1_size = 1024\nwandb.config.hidden_layer2_size = 512\nwandb.config.hidden_layer3_size = 256\n\nnp.random.seed(1729)\nmodel = Sequential()\nmodel.add(Dense(units=wandb.config.hidden_layer1_size, activation='relu'))\nmodel.add(Dropout(wandb.config.dropout_rate))\nmodel.add(Dense(units=wandb.config.hidden_layer2_size, activation='relu'))\nmodel.add(Dropout(wandb.config.dropout_rate))\nmodel.add(Dense(units=wandb.config.hidden_layer3_size, activation='relu'))\nmodel.add(Dropout(wandb.config.dropout_rate))\nmodel.add(Dense(units=199, activation='softmax'))\nmodel.compile(loss=categorical_crossentropy, optimizer=SGD(lr=wandb.config.learning_rate, decay=wandb.config.decay, \n                                                                       momentum=wandb.config.beta, nesterov=True, clipnorm=wandb.config.clipse))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Run Model\n\nlog critical data using Weights&Biases and visualize"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%wandb\n\n# for epoch in range(wandb.config.epochs):\n#     hist = model.fit(Xtrain, Ytrain, epochs=1, batch_size=wandb.config.batch_size, validation_data=(Xtest, Ytest))\n#     Ptrain = model.predict(Xtrain)\n#     Ptest = model.predict(Xtest)\n#     loss = hist.history['loss']\n#     val_loss = hist.history['val_loss']\n#     CRPS = chirps(Ytrain, Ptrain)\n#     val_CRPS = chirps(Ytest, Ptest)\n#     wandb.log({'epoch': epoch, 'loss': loss, 'val_loss':val_loss, 'CRPS':CRPS, 'val_CRPS':val_CRPS}, step=epoch)\n        \n        \n        \nmodel.fit(X, Y, epochs=wandb.config.epochs, batch_size=wandb.config.batch_size, validation_split=0.1, callbacks=[WandbCallback()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}