{"cells":[{"metadata":{},"cell_type":"markdown","source":"**CREDITS**\n\nSome categorical/etc. features (PlayerAge, TimeDelta, OF_FORMATION, etc.) were used from:\n\nhttps://www.kaggle.com/bgmello/neural-networks-feature-engineering-for-the-win\n\nSome distance-based features (Distance_to_YardLine, Distance_to_Quarterback, etc.) were used from:\n\nhttps://www.kaggle.com/c/nfl-big-data-bowl-2020/discussion/113698"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport tqdm\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\ntrain_df = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2020/train.csv', low_memory=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_stadium_type(df_col):\n    replacements = {\n        'Outdoors': 'Outdoor',\n        'Oudoor': 'Outdoor',\n        'Outddors': 'Outdoor',\n        'Outdor': 'Outdoor',\n        'Ourdoor': 'Outdoor',\n        'Outside': 'Outdoor',\n        'Indoors': 'Indoor',\n        'Retractable': 'Retr.',\n        'closed': 'Closed',\n        'open': 'Open',\n        'Closed Dome': 'Domed, Closed',\n        'Dome, Closed': 'Domed, Closed',\n        'Domed': 'Dome',\n        ' - ': ' ',\n        '-': ' '\n    }\n\n    # fix stadium description\n    for replaced, replacing in replacements.items():\n        df_col = df_col.str.replace(replaced, replacing)\n\n    df_col = pd.factorize(df_col)[0]\n    return df_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_stadium_turf(df_col):\n    df_col = df_col.str.lower()\n\n    replacements = {\n        'natural grass': 'grass',\n        'natural': 'grass',\n        'naturall grass': 'grass',\n        'fieldturf': 'field turf',\n        'fieldturf 360': 'fieldturf360',\n        'artifical': 'artificial'\n    }\n\n    # fix staidum turf types\n    df_col = df_col.replace(replacements)\n    df_col = pd.factorize(df_col)[0]\n    return df_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_game_weather(df_col):\n    df_col = df_col.str.lower()\n\n    fixes = {\n        ' skies': '',\n        'coudy': 'cloudy',\n        'clouidy': 'cloudy',\n        'party': 'partly'\n    }\n\n    # fix stadium descriptions\n    for replaced, replacing in fixes.items():\n        df_col = df_col.str.replace(replaced, replacing)\n\n    weather_coeffs = {\n        'sunny': 2.5, \n        'clear': 2.5, \n        'warm': 1.5, \n        'cold': -1.5,\n        'hazy': -1.5,\n        'cloud': -2.5, \n        'rain': -2.5, \n        'snow': -5.0\n    }\n\n    replacements = {}\n    for weather_description_raw in df_col.unique():\n        weather_description = str(weather_description_raw)\n        weather = 0.0\n        for weather_type, weather_coeff in weather_coeffs.items():\n            if weather_type in weather_description:\n                weather += weather_coeffs[weather_type]\n        if 'partly' in weather_description:\n            weather *= 0.5\n        replacements[weather_description] = weather\n\n    df_col = df_col.replace(replacements)\n    return df_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_wind_speed(df_col):\n    df_col = df_col.astype(str)\n    df_col = df_col.replace('15 gusts up to 25', '20')  # replace expression with average ;)\n    df_col = df_col.str.replace(r'[^0-9\\-]', '')  # remove all non-digits except a range sign\n    df_col = df_col.replace('', '0')  # replace empty with zero\n\n    range_vals = {}\n\n    for range_val in [x for x in df_col.unique() if '-' in str(x)]:\n        min_val = int(range_val.split('-')[0])\n        max_val = int(range_val.split('-')[1])\n        aver_val = int(min_val + (max_val - min_val) / 2)\n        range_vals[range_val] = aver_val\n\n    df_col = df_col.replace(range_vals)  # replace range expression with average value\n    df_col = df_col.replace(np.nan, 0)  # replace nans with zero\n    df_col = df_col.astype(np.int64)\n    return df_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_wind_direction(df_col):\n    direction_signs = {\n        'north': 'N',\n        'east': 'E',\n        'south': 'S',\n        'west': 'W'\n    }\n\n    df_col = df_col.astype(str)\n    df_col = df_col.str.lower()\n\n    # replace long direction signs to short ones\n    for replaced, replacing in direction_signs.items():\n        df_col = df_col.str.replace(replaced, replacing)\n\n    df_col = df_col.str.upper()\n    df_col = df_col.str.replace(r'[^WNSE]', '')  # remove all unnecessary characters\n    df_col = df_col.replace(np.nan, 0.0)  # replace nans with zero\n    df_col = df_col.replace('', 0.0)  # replace empty with zero\n\n    compass_rose = {\n        'N': 0.0, 'NNE': 22.5, 'NE': 45.0, 'ENE': 67.5,\n        'E': 90.0, 'ESE': 112.5, 'SE': 135, 'SSE': 157.5,\n        'S': 180.0, 'SSW': 202.5, 'SW': 225.0, 'WSW': 247.5,\n        'W': 270.0, 'WNW': 292.5, 'NW': 315.0, 'NNW': 337.5\n    }\n\n    df_col = df_col.apply(lambda x: x if x == np.string_ else 'N')  # replace non-string with N\n    df_col = df_col.replace(compass_rose)  # replace wind signs with angles by the compass rose\n    return df_col","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To make information about Offense/Defense Personnels more understandable, they are divided into the following features:\n* DB = a defensive back,\n* DL = a defensive line,\n* LB = a linebacker,\n* OL = an offensive line,\n* QB = a quaterback,\n* RB = a running back,\n* TE = a tight end,\n* WR = a wide receiver."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_personnel_by_positions(df_col, unique_positions):\n    df_col = df_col.str.replace(', ', ',')  # remove spaces after commas\n    unique_personnels = df_col.unique().tolist()\n    unique_personnels_indexed = {}\n\n    for unique_personnel in unique_personnels:\n        index_positions = unique_personnel.split(',')\n        indexes = [0] * len(unique_positions)\n\n        for index_position in index_positions:\n            index = int(index_position.split(' ')[0])\n            unique_position = index_position.split(' ')[1]\n            \n            if unique_position in unique_positions:\n                position = unique_positions.index(unique_position)\n                indexes[position] = index\n\n        result = 0\n\n        for index, position in enumerate(indexes):\n            result += (10 ** index) * position\n\n        unique_personnels_indexed[unique_personnel] = result\n\n    df_col = df_col.replace(unique_personnels_indexed).astype(np.int64)\n    return df_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_index_by_position(df_col):\n    positions = {\n        'QB': 0, 'CB': 1, 'WR': 2, 'G': 3, 'T': 4, 'DE': 5, 'DT': 6, 'OLB': 7,\n        'TE': 8, 'FS': 9, 'C': 10,'RB': 11, 'SS': 12, 'ILB': 13, 'MLB': 14, 'NT': 15,\n        'LB': 16, 'OT': 17, 'FB': 18, 'OG': 19, 'DB': 20, 'S': 21, 'HB': 22, 'SAF': 23,\n        'DL': 24, '0': 25\n    }\n    df_col = df_col.replace(positions)\n    return df_col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"player_num = 22\n\ndef feature_engineering(df, is_trained=False):\n    df_len = len(df.index)\n    df_len_final = df_len // player_num\n\n    df = df.fillna('0')\n    df['GameClock'] = df['GameClock'].apply(lambda x: (int(x.split(':')[0]) * 60 + int(x.split(':')[1])) // 60)\n    df['PossessionTeam'] = df['PossessionTeam'].replace({'ARI': 'ARZ', 'BAL': 'BLT', 'CLE': 'CLV', 'HOU': 'HST'})\n    df['HomeTeamAbbr'] = df['HomeTeamAbbr'].replace({'ARI': 'ARZ', 'BAL': 'BLT', 'CLE': 'CLV', 'HOU': 'HST'})\n    df['VisitorTeamAbbr'] = df['VisitorTeamAbbr'].replace({'ARI': 'ARZ', 'BAL': 'BLT', 'CLE': 'CLV', 'HOU': 'HST'})\n    df['OffensePersonnel'] = get_personnel_by_positions(df['OffensePersonnel'], ['OL', 'QB', 'RB', 'TE', 'WR'])\n    df['DefensePersonnel'] = get_personnel_by_positions(df['DefensePersonnel'], ['DB', 'DL', 'LB'])\n    df['PlayDirection'] = (df['PlayDirection'] == 'right').astype(np.uint8)\n    df['TimeSnap'] = pd.to_datetime(df['TimeSnap'], format='%Y-%m-%dT%H:%M:%S.000Z')\n    df['TimeHandoff'] = pd.to_datetime(df['TimeHandoff'], format='%Y-%m-%dT%H:%M:%S.000Z')\n    df['PlayerHeight'] = df['PlayerHeight'].apply(lambda x: 12 * int(x.split('-')[0]) + int(x.split('-')[1]))\n    df['PlayerBirthDate'] = pd.to_datetime(df['PlayerBirthDate'], format='%m/%d/%Y')\n    df['PlayerCollegeName'] = pd.factorize(df['PlayerCollegeName'])[0]\n    df['Position'] = get_index_by_position(df['Position'])\n    df['Stadium'] = pd.factorize(df['Stadium'])[0]\n    df['Turf'] = get_stadium_turf(df['Turf'])\n    df['GameWeather'] = get_game_weather(df['GameWeather'])\n    df['Location'] = pd.factorize(df['Location'])[0]\n    df['StadiumType'] = get_stadium_type(df['StadiumType'])\n    df['WindSpeed'] = get_wind_speed(df['WindSpeed'])\n    df['WindDirection'] = get_wind_direction(df['WindDirection'])\n    \n    df['WindDirection'] = df['WindDirection'].astype(np.int)\n    df['WindDirection_COS'] = np.cos(np.deg2rad(df['WindDirection']))\n    df['WindDirection_SIN'] = np.sin(np.deg2rad(df['WindDirection']))\n\n    for i, offense_column in enumerate(['Offense_OL', 'Offense_QB', 'Offense_RB', 'Offense_TE', 'Offense_WR']):\n        df[offense_column] = ((df['OffensePersonnel'] % (10 ** (i + 1)) - df['OffensePersonnel'] % (10 ** i)) / (10 ** i)).astype(np.int64)\n    for i, defense_column in enumerate(['Defense_DB', 'Defense_DL', 'Defense_LB']):\n        df[defense_column] = ((df['DefensePersonnel'] % (10 ** (i + 1)) - df['DefensePersonnel'] % (10 ** i)) / (10 ** i)).astype(np.int64)\n    for i, offense_form_column in enumerate(['OF_SHOTGUN', 'OF_SINGLEBACK', 'OF_JUMBO', 'OF_PISTOL', 'OF_I_FORM', 'OF_ACE', 'OF_WILDCAT', 'OF_EMPTY']):\n        df[offense_form_column] = (df['OffenseFormation'] == offense_form_column.split('_')[-1]).astype(np.int64)\n\n    df['QuarterGameClock'] = df['GameClock'] % (15 * 60)\n    df['TimeDelta'] = (df['TimeHandoff'] - df['TimeSnap']).dt.total_seconds()\n    \n    # Player features\n    df['PlayerAge'] = ((df['TimeHandoff'] - df['PlayerBirthDate']).dt.total_seconds() / (60 * 60 * 24 * 365)).astype(np.int64)\n    df['IsRusher'] = (df['NflId'] == df['NflIdRusher']).astype(np.uint8)\n    df['IsOffense'] = ((df['PossessionTeam'] == df['HomeTeamAbbr']) & (df['Team'] == 'home')) | ((df['PossessionTeam'] == df['VisitorTeamAbbr']) & (df['Team'] == 'away'))\n    df['Team'] = (df['Team'] == 'home').astype(np.uint8)\n\n    df['OffenseX_mean'] = df[df['IsOffense'] == True].groupby(['PlayId'])['X'].mean().values.repeat(22)\n    df['OffenseY_mean'] = df[df['IsOffense'] == True].groupby(['PlayId'])['Y'].mean().values.repeat(22)\n    df['DefenseX_mean'] = df[df['IsOffense'] == False].groupby(['PlayId'])['X'].mean().values.repeat(22)\n    df['DefenseY_mean'] = df[df['IsOffense'] == False].groupby(['PlayId'])['Y'].mean().values.repeat(22)\n\n    df['OffenseX_std'] = df[df['IsOffense'] == True].groupby(['PlayId'])['X'].std().values.repeat(22)\n    df['OffenseY_std'] = df[df['IsOffense'] == True].groupby(['PlayId'])['Y'].std().values.repeat(22)\n    df['DefenseX_std'] = df[df['IsOffense'] == False].groupby(['PlayId'])['X'].std().values.repeat(22)\n    df['DefenseY_std'] = df[df['IsOffense'] == False].groupby(['PlayId'])['Y'].std().values.repeat(22)\n\n    df['RusherX'] = df[df['IsRusher'] == True]['X'].values.repeat(22)\n    df['RusherY'] = df[df['IsRusher'] == True]['Y'].values.repeat(22)\n\n    df['QuaterbackX'] = df[df['Position'] == 0]['X'].values[:df_len_final].repeat(22)\n    df['QuaterbackY'] = df[df['Position'] == 0]['Y'].values[:df_len_final].repeat(22)\n    \n    # Plauer features\n    df['Dir'] = df['Dir'].astype(np.int)\n    df['Dir_COS'] = np.cos(np.deg2rad(df['Dir']))\n    df['Dir_SIN'] = np.sin(np.deg2rad(df['Dir']))\n\n    df['Orientation'] = df['Orientation'].astype(np.int)\n    df['Orientation_COS'] = np.cos(np.deg2rad(df['Orientation']))\n    df['Orientation_SIN'] = np.sin(np.deg2rad(df['Orientation']))\n\n    df['S_horizontal'] = df['S'] * df['Dir_COS']\n    df['S_vertical'] = df['S'] * df['Dir_SIN']\n\n    df['A_horizontal'] = df['A'] * df['Dir_COS']\n    df['A_vertical'] = df['A'] * df['Dir_SIN']\n\n    df['Distance_to_YardLine'] = abs(df['X'] - df['YardLine'])\n    df['Distance_to_Offense'] = np.sqrt((df['X'] - df['OffenseX_mean']) ** 2 + (df['Y'] - df['OffenseY_mean']) ** 2)\n    df['Distance_to_Defense'] = np.sqrt((df['X'] - df['DefenseX_mean']) ** 2 + (df['Y'] - df['DefenseY_mean']) ** 2)\n    df['Distance_to_Rusher'] = np.sqrt((df['X'] - df['RusherX']) ** 2 + (df['Y'] - df['RusherY']) ** 2)\n    df['Distance_to_Quarterback'] = np.sqrt((df['X'] - df['QuaterbackX']) ** 2 + (df['Y'] - df['QuaterbackY']) ** 2)\n\n    df = df.drop(columns=['GameId', 'PlayId', 'DisplayName', 'PossessionTeam', 'FieldPosition',\n                          'OffenseFormation', 'OffensePersonnel', 'DefensePersonnel', 'TimeHandoff', 'TimeSnap',\n                          'PlayerBirthDate', 'HomeTeamAbbr', 'VisitorTeamAbbr', 'NflId', 'NflIdRusher',\n                          'WindDirection', 'Dir', 'Orientation'])\n    \n    player_columns = [\n        'X', 'Y', 'S', 'A', 'Dir_COS', 'Dir_SIN',\n        'Orientation_COS', 'Orientation_SIN',\n        'S_horizontal', 'S_vertical', 'A_horizontal', 'A_vertical',\n        'Distance_to_YardLine', 'Distance_to_Offense', 'Distance_to_Defense',\n        'Distance_to_Rusher', 'Distance_to_Quarterback',\n        'Dis', 'JerseyNumber', 'PlayerHeight', 'PlayerWeight',\n        'PlayerCollegeName', 'Position', 'PlayerAge',\n        'Team', 'IsOffense', 'IsRusher'\n    ]\n\n    common_columns = [col for col in df.columns if col not in player_columns]\n    if is_trained:\n        common_columns.pop(common_columns.index('Yards'))\n    \n    cols = list(df.columns.values)\n    cols_to_end = []\n    \n    if is_trained:\n        cols.pop(cols.index('Yards'))\n\n    for column_name in player_columns:\n        cols_to_end.append(column_name)\n        cols.pop(cols.index(column_name))\n\n    if is_trained:\n        cols_to_end.append('Yards')\n\n    df = df[cols + cols_to_end]\n    return df, common_columns, player_columns\n\ntrain_df, common_features, player_features = feature_engineering(train_df, is_trained=True)\npd.set_option('display.max_columns', 100)\ntrain_df.head(n=22)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\ncommon_feature_num = len(common_features)\nplayer_feature_num = len(player_features)\n\ndef make_dataset(scaler, df, is_trained=False):\n    df_numpy_arr = df.to_numpy()\n\n    all_row_length = len(df.index)\n    X_row_len = all_row_length // player_num\n    X_col_len = common_feature_num + player_feature_num * player_num\n    X_train = np.zeros((X_row_len, X_col_len), dtype=np.float)\n    \n    for i in range(X_row_len):\n        X_train[i, :common_feature_num] = df_numpy_arr[i * player_num, :common_feature_num]\n\n        for j in range(player_num):\n            np_y_left = common_feature_num + j * player_feature_num\n            np_y_right = common_feature_num + (j + 1) * player_feature_num\n            df_y_left = common_feature_num\n            df_y_right = common_feature_num + player_feature_num\n            X_train[i, np_y_left: np_y_right] = df_numpy_arr[i * player_num + j, df_y_left: df_y_right]\n\n    X_train = np.nan_to_num(X_train)\n\n    if is_trained:\n        scaler.fit(X_train)\n    \n    X_train = scaler.transform(X_train)\n    \n    if is_trained:\n        Y_train = np.zeros((X_row_len, 199), dtype=np.float)\n\n        for i in range(X_row_len):\n            yard = int(df_numpy_arr[i * player_num, -1])\n            Y_train[i, yard + 99:] = np.ones(shape=(1, 100 - yard))\n\n        return X_train, Y_train\n    else:\n        return X_train, None\n\nprint('Index\\t{0}\\t{1:24}\\t{2}\\t\\t{3}'.format('Dtype', 'Column name', '1st value', 'Is equal by play'))\nfor i, column_name in enumerate(train_df.columns):\n    print('{0}\\t{1}\\t{2:24}\\t{3:16}\\t{4}'.format(i, train_df.dtypes[i], column_name, str(train_df[column_name][0]), column_name in player_features))\n\nscaler = StandardScaler()\nX_train, Y_train = make_dataset(scaler, train_df, is_trained=True)\nprint('X_train: {}'.format(X_train.shape))\nprint('Y_train: {}'.format(Y_train.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import display\n\n# List of [common] and [player] feature masks, extracted by genetic programming\nmasks = [\n    [[1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0],\n     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]],\n    [[0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0],\n     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]],\n    [[0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]],\n    [[1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0],\n     [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]],\n    [[0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0],\n     [0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0]],\n    [[0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0],\n     [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]],\n    [[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0],\n     [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]],\n    [[0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0],\n     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]],\n    [[0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0],\n     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]],\n    [[0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0],\n     [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]]\n]\n\ndef generate_input_mask(common_feature_mask, player_feature_mask):\n    return np.concatenate([common_feature_mask, np.tile(player_feature_mask, player_num)])\n\nfeature_count = len(masks)\ninput_masks = [generate_input_mask(masks[i][0], masks[i][1]) for i in range(feature_count)]\n\ndef get_input_now(X_train, input_mask):\n    non_zero_inds = np.where(input_mask != 0.0)[0]\n    X_train_now = X_train[:, non_zero_inds]\n    return X_train_now\n\nhamming_distance = np.zeros((feature_count, feature_count), dtype=np.int)\nfor i in range(feature_count):\n    for j in range(feature_count):\n        distance_0 = np.count_nonzero(np.logical_xor(masks[i][0], masks[j][0]))\n        distance_1 = np.count_nonzero(np.logical_xor(masks[i][1], masks[j][1]))\n        hamming_distance[i, j] = distance_0 + distance_1\n        \nhd = pd.DataFrame(data=hamming_distance,\n                  index=['{}'.format(i) for i in range(feature_count)],\n                  columns=['{}'.format(i) for i in range(feature_count)])\ndisplay(hd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import *\n\ndef build_model(input_dim):\n    inputs = Input(shape=(input_dim,))\n    \n    x = Dense(384, activation=None)(inputs)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.05)(x)\n    x = Dropout(0.35)(x)\n    \n    x = Dense(256, activation=None)(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.05)(x)\n    x = Dropout(0.35)(x)\n    \n    x = Dense(192, activation=None)(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(alpha=0.05)(x)\n    x = Dropout(0.35)(x)\n    \n    outputs = Dense(199, activation='sigmoid')(x)\n    model = Model(inputs, outputs)\n    model.compile(optimizer='adam', loss='mse')\n    return model\n\ntest_model = build_model(input_dim=X_train.shape[1])\ntest_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n\nmodels = []\nval_loss = []\n\nVERBOSE_MODE = 0\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=5, min_lr=1e-6, mode='min',\n                              verbose=VERBOSE_MODE)\nearly_stopping = EarlyStopping(monitor='val_loss', min_delta=1e-6, patience=8, mode='min',\n                               restore_best_weights=True, verbose=VERBOSE_MODE)\n\nfor i in range(feature_count):\n    print('Feature Index: {}'.format(i))\n    print('Common Features: {}'.format(masks[i][0]))\n    print('Player Features: {}'.format(masks[i][1]))\n    X_train_now = get_input_now(X_train, input_masks[i])\n    model = build_model(input_dim=X_train_now.shape[1])\n    history = model.fit(X_train_now, Y_train,\n                        validation_split=0.15, batch_size=64, epochs=32,\n                        callbacks=[reduce_lr, early_stopping], verbose=VERBOSE_MODE)\n    models.append(model)\n    val_loss.append(history.history['val_loss'])\n    print('Validation Loss: {:.6} (epochs: {})\\n'.format(min(history.history['val_loss']), len(history.history['val_loss'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfor i in range(feature_count):\n    plt.plot(val_loss[i])\n\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle.competitions import nflrush\nenv = nflrush.make_env()\n\nfor (test_df, sample_prediction_df) in tqdm.tqdm(env.iter_test()):\n    test_df, _, _ = feature_engineering(test_df)\n    X_test, _ = make_dataset(scaler, test_df)\n    \n    y_preds = []\n    for i in range(feature_count):\n        X_test_now = get_input_now(X_test, input_masks[i])\n        y_pred_now = models[i].predict(X_test_now)\n        y_preds.append(y_pred_now)\n    y_pred = np.mean(y_preds, axis=0)\n    \n    for pred in y_pred:\n        prev = 0\n        for i in range(len(pred)):\n            if pred[i] < prev:\n                pred[i] = prev\n            prev = pred[i]\n\n    y_pred[:, -1] = np.ones(shape=(y_pred.shape[0], 1))\n    y_pred[:, 0] = np.zeros(shape=(y_pred.shape[0], 1))\n    env.predict(pd.DataFrame(data=y_pred, columns=sample_prediction_df.columns))\n\nenv.write_submission_file()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}