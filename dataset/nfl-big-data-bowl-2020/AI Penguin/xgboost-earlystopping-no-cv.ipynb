{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import Libraries and loading Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle.competitions import nflrush\nimport pandas as pd\nimport numpy as np\nimport xgboost as xgb\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom time import time\nimport pickle\nimport datetime as dt\nfrom imblearn.over_sampling import RandomOverSampler\nfrom scipy.sparse import csc_matrix\nimport matplotlib.pyplot as plt\nimport scipy.stats\n\npd.set_option('display.max_rows', 200)\npd.set_option('display.max_columns', 200)\n\ntrain = pd.read_csv('/kaggle/input/nfl-big-data-bowl-2020/train.csv', low_memory=False)\ntrain_df = train.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define columns to discard"},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_columns_train = [\n                'GameId', 'PlayId','NflId','DisplayName', 'JerseyNumber',\n                'GameClock','PossessionTeam', 'FieldPosition', 'NflIdRusher',\n                'OffenseFormation','OffensePersonnel','DefensePersonnel','TimeHandoff',\n                'TimeSnap','PlayerHeight','PlayerBirthDate','PlayerCollegeName',\n                'HomeTeamAbbr','VisitorTeamAbbr', 'Stadium','Location','Turf',\n                'GameWeather','StadiumType','WindDirection', 'WindSpeed',\n    \n                'Yards'   # TARGET\n          \n                ]\n\ndrop_columns_test = [\n                'GameId','PlayId','NflId','DisplayName','JerseyNumber','GameClock',\n                'PossessionTeam', 'FieldPosition','NflIdRusher','OffenseFormation',\n                'OffensePersonnel','DefensePersonnel','TimeHandoff','TimeSnap',\n                'PlayerHeight','PlayerBirthDate','PlayerCollegeName','HomeTeamAbbr',\n                'VisitorTeamAbbr','Stadium','Location','Turf','GameWeather',\n                'StadiumType','WindDirection','WindSpeed',\n\n                ]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Simple Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nlbl = preprocessing.LabelEncoder()\n\ndef preprocessing(data, drop_columns):\n    \n    data = data.fillna(-999)\n    \n    month_list = [int(str(A)[4:6]) for A in data['GameId']]\n    day_list = [int(str(A)[6:8]) for A in data['GameId']]\n    game_list = [int(str(A)[-2:]) for A in data['GameId']]\n    GameClock_list = [int(A[:2])*60 + int(A[3:5]) for A in data['GameClock']]\n    age_list = [2020-int(str(A)[-4:]) for A in data['PlayerBirthDate']]\n    \n    data['month'] = month_list\n    data['day'] = day_list\n    data['game'] = game_list\n    data['GameTimeRemain'] = GameClock_list\n    data['PlayerAge'] = age_list\n    \n    height_list = []\n    for A in data['PlayerHeight']:\n        if len(A) == 3:\n            height = round((int(A[0])*30.48+int(A[2])*2.54),3)\n        else:\n            height = round((int(A[0])*30.48+int(A[-2:])*2.54),3)\n        height_list.append(height)\n    \n    data['PlayerHeight_cm'] = height_list\n  \n    data = data.drop(columns= drop_columns)\n    \n    for f in data.columns:\n        if data[f].dtype=='object':\n            lbl.fit(data[f].values)\n            data[f] = lbl.transform(data[f].values)\n    \n    data['DefendersInTheBox'] =  data['DefendersInTheBox'].astype('int64')\n    data['Temperature'] =  data['Temperature'].astype('int64')\n    data['Humidity'] =  data['Humidity'].astype('int64')\n\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = train_df.Yards.values\n\ntarget = y[np.arange(0, len(train_df), 22)]\ntrain_df_processed = preprocessing(train_df,drop_columns_train)\ntrain_df_processed = train_df_processed.iloc[np.arange(0, len(train_df_processed), 22)]\n\n# define the standard deviation\nstandard_deviation = np.std(target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Simple Train Test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(train_df_processed,target, \n                                                      test_size = 0.15,random_state = 666)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XGboost Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = xgb.XGBRegressor(\n                            \n                        n_estimators=500,\n                        min_child_weight = 2,\n                        max_depth=6,\n                        verbosity = 1,\n                        n_jobs=8,                                              \n                        scale_pos_weight=1.025,\n                        tree_method='exact',\n                        objective = 'reg:squarederror',\n                        predictor='cpu_predictor',\n                        colsample_bytree = 0.66,\n                        subsample = 1,\n                        gamma = 0,\n                        learning_rate=0.15,\n                        num_parallel_tree = 1 \n                       )\n\n\nclf.fit(X_train, y_train, eval_metric=\"rmse\", early_stopping_rounds=50,\n                    eval_set=[(X_train, y_train), (X_valid, y_valid)],verbose=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Making prediction using normal distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"env = nflrush.make_env()\niter_test = env.iter_test()\n\nbatch_no = 0\nfor (test_df, sample_prediction_df) in iter_test:\n    \n    #print(f'Predicting Batch Number {batch_no}')\n    test_df_processed = preprocessing(test_df, drop_columns_test)\n    y_pred = clf.predict(test_df_processed)\n    y_pred_first = y_pred[0]\n    pred_df = np.zeros((1, 199))\n    \n    for A in range(len(pred_df[0])):\n        current_cdf = scipy.stats.norm(loc = y_pred_first, scale = standard_deviation).cdf(A-99)\n        pred_df[0][A] = current_cdf\n        \n    pred_df[0][:80] = 0\n\n    final_pred_df = pd.DataFrame(data=pred_df, columns=sample_prediction_df.columns)\n    env.predict(final_pred_df)\n    batch_no += 1\n\nenv.write_submission_file()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}