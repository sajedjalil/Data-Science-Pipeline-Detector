{"cells":[{"metadata":{},"cell_type":"markdown","source":"** In this notebook I'd like to share my approach to feature engineering and feature encoding **\n\nHope you can find it usefull not only for this competition. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\nimport datetime\nfrom kaggle.competitions import nflrush\nimport tqdm\nimport re\nfrom string import punctuation\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Reshape, Dropout, Add, Embedding, Concatenate\n\nfrom sys import getsizeof\nfrom sklearn.model_selection import KFold, GroupKFold\n\nsns.set_style('darkgrid')\nmpl.rcParams['figure.figsize'] = [15,10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Read the data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_FOLDER = '../input/nfl-big-data-bowl-2020'\nARRAYS_FOLDER = '../files/ndarrays'\nMODEL_FOLDER = '../files/models'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(DATA_FOLDER+'/train.csv', low_memory = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For feature engineering I've slighlty modified the appraoch I found in another notebook. Unfortunately I haven't kept the record, so if you find this code similar - please notify me."},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"MAX_DATE = '2018-12-31'\n\noutdoor = ['Outdoor', 'Outdoors', 'Cloudy', 'Heinz Field', 'Outdor', 'Ourdoor', \n           'Outside', 'Outddors','Outdoor Retr Roof-Open', 'Oudoor', 'Bowl']\n\nindoor_closed = ['Indoors', 'Indoor', 'Indoor, Roof Closed', 'Indoor, Roof Closed', 'Retractable Roof',\n                 'Retr. Roof-Closed', 'Retr. Roof - Closed', 'Retr. Roof Closed']\n\nindoor_open   = ['Indoor, Open Roof', 'Open', 'Retr. Roof-Open', 'Retr. Roof - Open']\ndome_closed   = ['Dome', 'Domed, closed', 'Closed Dome', 'Domed', 'Dome, closed']\ndome_open     = ['Domed, Open', 'Domed, open']\n\nrain = ['Rainy', 'Rain Chance 40%', 'Showers','Cloudy with periods of rain, thunder possible. Winds shifting to WNW, 10-20 mph.',\n        'Scattered Showers', 'Cloudy, Rain', 'Rain shower', 'Light Rain', 'Rain']\n\novercast = ['Cloudy, light snow accumulating 1-3\"', 'Party Cloudy', 'Cloudy, chance of rain',\n            'Coudy', 'Cloudy, 50% change of rain', 'Rain likely, temps in low 40s.',\n            'Cloudy and cold', 'Cloudy, fog started developing in 2nd quarter',\n            'Partly Clouidy', '30% Chance of Rain', 'Mostly Coudy', 'Cloudy and Cool',\n            'cloudy', 'Partly cloudy', 'Overcast', 'Hazy', 'Mostly cloudy', 'Mostly Cloudy',\n            'Partly Cloudy', 'Cloudy']\n\nclear = ['Partly clear', 'Sunny and clear', 'Sun & clouds', 'Clear and Sunny',\n        'Sunny and cold', 'Sunny Skies', 'Clear and Cool', 'Clear and sunny',\n        'Sunny, highs to upper 80s', 'Mostly Sunny Skies', 'Cold',\n        'Clear and warm', 'Sunny and warm', 'Clear and cold', 'Mostly sunny',\n        'T: 51; H: 55; W: NW 10 mph', 'Clear Skies', 'Clear skies', 'Partly sunny',\n        'Fair', 'Partly Sunny', 'Mostly Sunny', 'Clear', 'Sunny', 'Sunny, Windy']\n\nsnow  = ['Heavy lake effect snow', 'Snow']\n\nnone  = ['N/A Indoor', 'Indoors', 'Indoor', 'N/A (Indoors)', 'Controlled Climate']\n\n\nnorth = ['N','From S','North']\nsouth = ['S','From N','South','s']\nwest = ['W','From E','West']\neast = ['E','From W','from W','EAST','East']\nnorth_east = ['FROM SW','FROM SSW','FROM WSW','NE','NORTH EAST','North East','East North East','NorthEast','Northeast','ENE','From WSW','From SW']\nnorth_west = ['E','From ESE','NW','NORTHWEST','N-NE','NNE','North/Northwest','W-NW','WNW','West Northwest','Northwest','NNW','From SSE']\nsouth_east = ['E','From WNW','SE','SOUTHEAST','South Southeast','East Southeast','Southeast','SSE','From SSW','ESE','From NNW']\nsouth_west = ['E','From ENE','SW','SOUTHWEST','W-SW','South Southwest','West-Southwest','WSW','SouthWest','Southwest','SSW','From NNE']\nno_wind = ['clear','Calm']\nnan = ['1','8','13']\n\nnatural_grass = ['natural grass','Naturall Grass','Natural Grass']\ngrass = ['Grass']\nfieldturf = ['FieldTurf','Field turf','FieldTurf360','Field Turf']\nartificial = ['Artificial','Artifical']\n\n\ndef feature_engineering(data_frame, features_to_convert, convert_null_variables=True):\n    df = data_frame.copy()\n    \n    def strtoseconds(txt):\n        txt = txt.split(':')\n        ans = int(txt[0])*60 + int(txt[1]) + int(txt[2])/60\n        return ans\n    \n    def convert_jn_to_position(df):\n        jn = df['JerseyNumber']\n        if jn < 10:\n            df['QB'] = 1\n            df['KP'] = 1\n        elif jn >= 10 and jn < 20:\n            df['QB'] = 1\n            df['WR'] = 1\n            df['KP'] = 1\n        elif jn >= 20 and jn < 40:\n            df['RB'] = 1\n            df['DB'] = 1\n        elif jn >= 40 and jn < 50:\n            df['RB'] = 1\n            df['LB'] = 1\n            df['DB'] = 1\n            df['TE'] = 1\n        elif jn >= 50 and jn < 60:\n            df['OL'] = 1\n            df['DL'] = 1\n            df['LB'] = 1\n        elif jn >= 60 and jn < 80:\n            df['OL'] = 1\n            df['DL'] = 1\n        elif jn >= 80 and jn < 90:\n            df['WR'] = 1\n            df['TE'] = 1\n        elif jn >= 90 and jn < 100:\n            df['DL'] = 1\n            df['LB'] = 1\n\n        return df\n    \n    def clean_wind_speed(windspeed):\n        nan = ['nan','E','SE','Calm','SSW', 'SSE']\n        \n        def avg_list(temp_list):\n            int_temp_list = [int(x) for x in temp_list]\n            return sum(int_temp_list)/len(temp_list)    \n\n        ws = str(windspeed)\n        if ws in nan:\n            return np.nan\n        else:\n            matches = re.findall('(\\d+)', ws, re.DOTALL)\n            return avg_list(matches)\n    \n    #event data\n    if 'TimeHandoff' in features_to_convert:\n        df['Month'] = df['TimeHandoff'].apply(lambda x : int(x[5:7]))\n        df['Year'] = df['TimeHandoff'].apply(lambda x : int(x[0:4]))\n        df['Morning'] = df['TimeHandoff'].apply(lambda x : 1 if (int(x[11:13]) >=0 and int(x[11:13]) <12) else 0)\n        df['Afternoon'] = df['TimeHandoff'].apply(lambda x : 1 if (int(x[11:13]) <18 and int(x[11:13]) >=12) else 0)\n        df['Evening'] = df['TimeHandoff'].apply(lambda x : 1 if (int(x[11:13]) >= 18 and int(x[11:13]) < 24) else 0)\n        df['Month_Snap'] = df['TimeSnap'].apply(lambda x : int(x[5:7]))\n        df['Year_Snap'] = df['TimeSnap'].apply(lambda x : int(x[0:4]))\n        df.drop(['TimeHandoff'], axis=1,inplace=True)\n\n    if 'TimeSnap' in features_to_convert:\n        df['Morning_Snap'] = df['TimeSnap'].apply(lambda x : 1 if (int(x[11:13]) >=0 and int(x[11:13]) <12) else 0)\n        df['Afternoon_Snap'] = df['TimeSnap'].apply(lambda x : 1 if (int(x[11:13]) <18 and int(x[11:13]) >=12) else 0)\n        df['Evening_Snap'] = df['TimeSnap'].apply(lambda x : 1 if (int(x[11:13]) >= 18 and int(x[11:13]) < 24) else 0)\n        df['GameClock'] = df['GameClock'].apply(strtoseconds)\n        df.drop(['TimeSnap'], axis=1, inplace=True)\n    \n    if 'JerseyNumber' in features_to_convert:\n        l = ['QB', 'KP', 'WR', 'RB', 'DB', 'LB', 'DB', 'TE', 'OL', 'DL']\n        d = dict.fromkeys(l, 0)\n        df = df.assign(**d).apply(convert_jn_to_position, axis=1)\n        df.drop(['JerseyNumber'], axis=1, inplace=True)\n    \n    if 'PlayerHeight' in features_to_convert:\n        df[\"HeightFt\"] = df[\"PlayerHeight\"].str.split('-', expand=True)[0].astype(int)\n        df[\"HeightIn\"] = df[\"PlayerHeight\"].str.split('-', expand=True)[1].astype(int)\n        df[\"HeightCm\"] = df[\"HeightFt\"]*30.48 + df[\"HeightIn\"]*2.54\n        df.drop(['PlayerHeight','HeightIn', 'HeightFt'], axis=1,inplace=True)\n\n    if 'PlayerWeight' in features_to_convert:\n        df[\"WeightKg\"] = df[\"PlayerWeight\"]*0.45359237\n        df.drop(['PlayerWeight'], axis=1,inplace=True)\n    \n    if 'PlayerBirthDate' in features_to_convert:\n        df['BirthDate'] = df['PlayerBirthDate'].astype('datetime64[ns]')\n        df['Age'] = round((pd.to_datetime(MAX_DATE) - df['BirthDate'])/np.timedelta64(1,'D')/365.25,1)\n        df.drop(['BirthDate', 'PlayerBirthDate'], axis = 1, inplace=True)\n    \n    if 'StadiumType' in features_to_convert:\n        #stadium data\n        df['StadiumType'] = df['StadiumType'].replace(outdoor,'outdoor')\n        df['StadiumType'] = df['StadiumType'].replace(indoor_closed,'indoor_closed')\n        df['StadiumType'] = df['StadiumType'].replace(indoor_open,'indoor_open')\n        df['StadiumType'] = df['StadiumType'].replace(dome_closed,'dome_closed')\n        df['StadiumType'] = df['StadiumType'].replace(dome_open,'dome_open')\n        df['StadiumType'] = df['StadiumType'].replace(np.nan,'no_data')\n\n        df['GameWeather'] = df['GameWeather'].replace(outdoor,'outdoor')\n        df['GameWeather'] = df['GameWeather'].replace(indoor_closed,'indoor_closed')\n        df['GameWeather'] = df['GameWeather'].replace(indoor_open,'indoor_open')\n        df['GameWeather'] = df['GameWeather'].replace(dome_closed,'dome_closed')\n        df['GameWeather'] = df['GameWeather'].replace(dome_open,'dome_open')\n        df['Turf'] = df['Turf'].replace(natural_grass,'natural_grass')\n        df['Turf'] = df['Turf'].replace(grass,'grass')\n        df['Turf'] = df['Turf'].replace(fieldturf,'fieldturf')\n        df['Turf'] = df['Turf'].replace(artificial,'artificial')\n    \n    if 'WindSpeed' in features_to_convert:\n        #weather speed\n        df['WindSpeed'] = df['WindSpeed'].apply(clean_wind_speed)\n    \n    if 'WindDirection' in features_to_convert:\n        df['WindDirection'] = df['WindDirection'].replace(north,'north')\n        df['WindDirection'] = df['WindDirection'].replace(south,'south')\n        df['WindDirection'] = df['WindDirection'].replace(west,'west')\n        df['WindDirection'] = df['WindDirection'].replace(east,'east')\n        df['WindDirection'] = df['WindDirection'].replace(north_east,'north_east')\n        df['WindDirection'] = df['WindDirection'].replace(north_west,'north_west')\n        df['WindDirection'] = df['WindDirection'].replace(south_east,'clear')\n        df['WindDirection'] = df['WindDirection'].replace(south_west,'south_west')\n        df['WindDirection'] = df['WindDirection'].replace(no_wind,'no_wind')\n        df['WindDirection'] = df['WindDirection'].replace(nan,np.nan)\n    \n    df['IsRusher'] = (df['NflId'] == df['NflIdRusher']).astype(int)\n    \n    if 'OffensePersonnel' in features_to_convert:\n        df = pd.concat([df, df['OffensePersonnel'].str.get_dummies(sep=',').add_prefix('Offence_')], axis=1)\n        df.drop(['OffensePersonnel'], axis=1, inplace=True)\n    if 'DefensePersonnel' in features_to_convert:\n        df = pd.concat([df, df['DefensePersonnel'].str.get_dummies(sep=',').add_prefix('Defence_')], axis=1)\n        df.drop(['DefensePersonnel'], axis=1, inplace=True)\n    \n    if convert_null_variables:\n        null_columns = df.columns[df.isna().any()].tolist()\n        num_null_columns = df[null_columns].select_dtypes(exclude='object')\n        object_null_cloumns = df[null_columns].select_dtypes(include='object')\n        for column in num_null_columns:\n            df[column].fillna((df[column].median()), inplace=True)\n\n        for column in object_null_cloumns:\n            df[column].fillna(('NaN'), inplace=True)\n            \n    return df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For some modeling it could be crucial to divide columns by type"},{"metadata":{"trusted":true},"cell_type":"code","source":"def columns(df, treshold):\n    cat_cols = []\n    dense_cols = []\n    cat_cols_to_shrink = []\n\n    for i, column in enumerate(df.columns):\n        if (str(df[column].dtype)==\"object\" or str(df[column].dtype)==\"category\") :\n            cat_cols.append(column)\n            if df[column].nunique()>treshold:\n                cat_cols_to_shrink.append(column)   \n        else:\n            dense_cols.append(column)\n\n    return (cat_cols, dense_cols, cat_cols_to_shrink)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Target encoding**\n\n[Reference](https://brendanhasz.github.io/2019/03/04/target-encoding)"},{"metadata":{"trusted":true},"cell_type":"code","source":"class TargetEncoder(BaseEstimator, TransformerMixin):\n    \"\"\"Target encoder.\n    \n    Replaces categorical column(s) with the mean target value for\n    each category.\n\n    \"\"\"\n    \n    def __init__(self, cols=None):\n        \"\"\"Target encoder\n        \n        Parameters\n        ----------\n        cols : list of str\n            Columns to target encode.  Default is to target \n            encode all categorical columns in the DataFrame.\n        \"\"\"\n        if isinstance(cols, str):\n            self.cols = [cols]\n        else:\n            self.cols = cols\n        \n        \n    def fit(self, X, y):\n        \"\"\"Fit target encoder to X and y\n        \n        Parameters\n        ----------\n        X : pandas DataFrame, shape [n_samples, n_columns]\n            DataFrame containing columns to encode\n        y : pandas Series, shape = [n_samples]\n            Target values.\n            \n        Returns\n        -------\n        self : encoder\n            Returns self.\n        \"\"\"\n        \n        # Encode all categorical cols by default\n        if self.cols is None:\n            self.cols = [col for col in X \n                         if str(X[col].dtype)=='object']\n\n        # Check columns are in X\n        for col in self.cols:\n            if col not in X:\n                raise ValueError('Column \\''+col+'\\' not in X')\n\n        # Encode each element of each column\n        self.maps = dict() #dict to store map for each column\n        for col in self.cols:\n            tmap = dict()\n            uniques = X[col].unique()\n            for unique in uniques:\n                target_mean = y[X[col]==unique].mean()\n                tmap[unique] = target_mean\n            self.maps[col] = tmap\n            \n        return self\n\n        \n    def transform(self, X, y=None):\n        \"\"\"Perform the target encoding transformation.\n        \n        Parameters\n        ----------\n        X : pandas DataFrame, shape [n_samples, n_columns]\n            DataFrame containing columns to encode\n            \n        Returns\n        -------\n        pandas DataFrame\n            Input DataFrame with transformed columns\n        \"\"\"\n        Xo = X.copy()\n        for col, tmap in self.maps.items():\n            vals = np.full(X.shape[0], np.nan)\n            for val, mean_target in tmap.items():\n                vals[X[col]==val] = mean_target\n            Xo[col] = vals\n        return Xo\n            \n            \n    def fit_transform(self, X, y=None):\n        \"\"\"Fit and transform the data via target encoding.\n        \n        Parameters\n        ----------\n        X : pandas DataFrame, shape [n_samples, n_columns]\n            DataFrame containing columns to encode\n        y : pandas Series, shape = [n_samples]\n            Target values (required!).\n\n        Returns\n        -------\n        pandas DataFrame\n            Input DataFrame with transformed columns\n        \"\"\"\n        return self.fit(X, y).transform(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Label encoding**\n\nApply label encoding for categorical values. [Reference](https://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn)."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nclass MultiColumnLabelEncoder:\n    \"\"\"Multicolumns label encoder.\n    \n    Wrapper for Label Encoder over multiple columns\n\n    \"\"\"\n    def __init__(self,columns = None):\n        \"\"\"Target encoder\n        \n        Parameters\n        ----------\n        columns : list of str\n            Columns to label encode.  Default is to target \n            encode all categorical columns in the DataFrame.\n        \"\"\"\n        self.columns = columns # array of column names to encode\n        \n    def fit(self,X,y):\n        return self\n    \n\n    def transform(self,X):\n        \"\"\"Perform the label encoding transformation for multiple columns.\n        \n        Parameters\n        ----------\n        X : pandas DataFrame, shape [n_samples, n_columns]\n            DataFrame containing columns to encode\n            \n        Returns\n        -------\n        pandas DataFrame\n            Input DataFrame with transformed columns\n        \"\"\"\n        output = X.copy()\n        if self.columns is not None:\n            for col in self.columns:\n                output[col] = LabelEncoder().fit_transform(output[col])\n        else:\n            for colname,col in output.iteritems():\n                output[colname] = LabelEncoder().fit_transform(col)\n        return output\n\n    def fit_transform(self,X,y=None):\n        \"\"\"Fit and transform the data via label encoding.\n        \n        Parameters\n        ----------\n        X : pandas DataFrame, shape [n_samples, n_columns]\n            DataFrame containing columns to encode\n        y : pandas Series, shape = [n_samples]\n            Target values (required!).\n\n        Returns\n        -------\n        pandas DataFrame\n            Input DataFrame with transformed columns\n        \"\"\"\n        return self.fit(X,y).transform(X)\n    \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Neural network encoding**\n\nThe main goal of entity embedding is to map similar categories close to each other in the embedding space. You can adjust the percentage of initial data to fit the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"class NeuralNetworkEncoder:\n    \"\"\"Cat2vec encoder.\n    \n    Deep embedding's for categorical variables\n\n    \"\"\"\n    \n    def __init__(self, cat_cols, treshold):\n        \"\"\"Cat2vec encoder\n        \n        Parameters\n        ----------\n        cat_cls : list of str\n            Columns to label encode.  Default is WIP\n        \"\"\"\n        self.columns = cat_cols\n        self.max_emb_size = treshold\n\n    def fit(self, X, y):\n        X_cat = [X[col].values for col in self.columns]\n        y_ = np.zeros((y.shape[0], 199))\n        for idx, val in enumerate(list(y)):\n            y_[idx][99 + val] = 1\n\n        inputs = []\n        embeddings = []\n\n        for col in self.columns:\n            #as we itereate over columns so the shape = (1,) \n            input_ = Input(shape=(1,))   \n\n            no_of_unique_cat = X[col].nunique()\n            embedding_size = int(min(np.ceil((no_of_unique_cat+1)/2), self.max_emb_size))\n            input_emb_dim = no_of_unique_cat\n            emb_input_length = 1\n\n            embedding = Embedding(input_emb_dim, embedding_size, input_length=emb_input_length)(input_)\n            embedding = Reshape(target_shape=(embedding_size,))(embedding)\n            inputs.append(input_)\n            embeddings.append(embedding)\n\n\n        x = Concatenate()(embeddings)\n        x = Dense(256, activation='relu')(x)\n        x = Dense(128, activation='relu')(x)\n        x = Dropout(0.5)(x)\n        output = Dense(199, activation='softmax')(x)\n        model = Model(inputs, output)\n        model.compile(loss='binary_crossentropy', optimizer='adam')\n\n        model.fit(X_cat, y_)\n        self.model = model\n        return self\n    \n    def transform(self, X):\n        \"\"\"Perform the cat2vec encoding transformation for multiple columns.\n        \n        Parameters\n        ----------\n        X : pandas DataFrame, shape [n_samples, n_columns]\n            DataFrame containing columns to encode\n            \n        Returns\n        -------\n        pandas DataFrame\n            Input DataFrame with transformed columns\n        \"\"\"\n        df = X.copy()\n        trained_embedings = self.model.layers[len(self.columns):2*len(self.columns)]\n\n        for i,cat in enumerate(self.columns):\n            cat_emb_df = pd.DataFrame(trained_embedings[i].get_weights()[0])\n            cat_emb_df.columns = [cat + '_' + str(col) + '_emb' for col in cat_emb_df.columns]\n            X = X.merge(cat_emb_df, left_on = cat, right_index=True)\n            X.drop(cat, axis=1, inplace=True)\n    \n        return df\n    \n    def fit_transform(self, X, y=None):\n        return self.fit(X, y).transform(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Pipeline**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#implicitly specify the columns we to transform\nfeatures_to_transform = ['TimeHandoff', 'TimeSnap', 'JerseyNumber', 'PlayerHeight', \\\n                       'PlayerWeight', 'PlayerBirthDate', 'StadiumType' \\\n                      'OffensePersonnel', 'DefensePersonnel']\n\n\nclass DataFrameEncoder:\n    \n    def __init__(self, features_to_convert, shrink_treshold):\n        \"\"\"Dataframe encoder\n        \n        Parameters\n        ----------\n        features_to_convert : list \n            Columns to encode.  Default is not set yet\n        shrink_treshold : int\n            A threshold that specify N the top-N value counts columns\n        \"\"\"\n        \n        self.features_to_convert = features_to_convert\n        self.shrink_treshold = shrink_treshold\n    \n    def fit_transform(self, df, target):\n        df_ = df.copy()\n        df_ = feature_engineering(df_, self.features_to_convert, convert_null_variables=True)\n        self.cat_cols, self.dense_cols, self.cat_cols_to_shrink = columns(df_, self.shrink_treshold)\n\n        #define encoders\n        if len(self.cat_cols_to_shrink) != 0:\n            print(\"---Start target encoding---\")\n            self.te = TargetEncoder(cols = self.cat_cols_to_shrink)\n            df_ = self.te.fit_transform(df_, target)\n            self.dense_cols = self.dense_cols + self.cat_cols_to_shrink\n            print(\"---Successfully finished target encoding---\")\n        \n        print(\"---Start label encoding---\")\n        self.mle = MultiColumnLabelEncoder(columns = self.cat_cols)\n        df_ = self.mle.fit_transform(df_)\n        print(\"---Successfully finished label encoding---\")\n\n        print(\"---Start neural network encoding---\")\n        self.nne = NeuralNetworkEncoder(cat_cols = self.cat_cols, treshold = self.shrink_treshold)\n        \n        df_ = self.nne.fit_transform(df_, target)\n        print(\"---Successfully finished network encoding---\")\n\n        self.columns = df_.columns\n    \n        return df_\n    \n    def transform(self, df):\n        df_ = df.copy()\n        df_ = feature_engineering(df_, self.features_to_convert, convert_null_variables=True)\n        \n        df_ = self.te.transform(df_)\n        df_ = self.mle.transform(df_)\n        df_ = self.nne.transform(df_)\n        \n        #if some of the train columns doesn't exist in test\n        not_exsit_in_test_columns = list(set(self.columns) - set(df_.columns))\n        d = dict.fromkeys(not_exsit_in_test_columns, 0)\n        df_ = df_.assign(**d)\n        \n        not_exist_in_train_columns = list(set(df_.columns)-set(self.columns))\n        df_.drop(not_exist_in_train_columns, axis=1, inplace=True)\n        return df_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_transfromer = DataFrameEncoder(features_to_transform, 70)\ndf_train_transformed = df_transfromer.fit_transform(train_df.drop(['Yards'], axis=1), train_df['Yards'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**One Hot encoding with frequency threshold**\n\nTarget encdoing + cat2vec works beeter"},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_df_transformed_ohe = train_df_transformed.where(train_df_transformed.apply(lambda x: x.map(x.value_counts()))>=200, \"other\")\n# cat_train_ohe = np.array(pd.get_dummies(train_df_transformed_ohe[cat_cols],sparse=True))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**LightGBM**\n\nTest the code with a simple Light GBM model. Credits goes to this [kernel](https://www.kaggle.com/zero92/best-lbgm-new-features)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = df_train_transformed.drop(['GameId', 'PlayId'], axis=1)\ny_train = train_df['Yards']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best_params_lgb = {'lambda_l1': 0.13413394854686794, \n'lambda_l2': 0.0009122197743451751, \n'num_leaves': 44, \n'feature_fraction': 0.4271070738920401, \n'bagging_fraction': 0.9999128827046064, \n'bagging_freq': 3, \n\"learning_rate\": 0.005,\n'min_child_samples': 43, \n'objective': 'regression', \n'metric': 'mae', \n'verbosity': -1, \n'boosting_type': 'gbdt', \n\"boost_from_average\" : False,\n'random_state': 42}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import GroupKFold\nnfold = 5\nfolds = KFold(n_splits=nfold, shuffle=False, random_state=42)\n\ngroups = df_train_transformed['PlayId']\ngkf = GroupKFold(n_splits=nfold)\n\nprint('-'*20)\nprint(str(nfold) + ' Folds training...')\nprint('-'*20)\n\noof = np.zeros(len(X_train))\n#y_valid_pred = np.zeros(X_train.shape[0])\nfeature_importance_df = pd.DataFrame()\n\ntr_mae = []\nval_mae = []\nmodels = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for fold_, (trn_idx, val_idx) in enumerate(gkf.split(X_train, y_train, groups=groups)):\n    strLog = \"fold {}\".format(fold_)\n    print(strLog)\n    \n    \n    X_tr, X_val = X_train.iloc[trn_idx], X_train.iloc[val_idx]\n    train_y, y_val = y_train[trn_idx], y_train[val_idx]\n    \n    model = lgb.LGBMRegressor(**best_params_lgb, n_estimators = 300, n_jobs = -1,early_stopping_rounds = 100)\n    model.fit(X_tr, \n              train_y, \n              eval_set=[(X_tr, train_y), (X_val, y_val)], \n              eval_metric='mae',\n              verbose=10\n              )\n    oof[val_idx] = model.predict(X_val)\n    val_score = mean_absolute_error(y_val, oof[val_idx])\n    val_mae.append(val_score)\n    tr_score = mean_absolute_error(train_y, model.predict(X_tr))\n    tr_mae.append(tr_score)\n    models.append(model)\n    \n    \n    # Feature importance\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"Feature\"] = X_tr.columns\n    fold_importance_df[\"importance\"] = model.feature_importances_[:len(X_tr.columns)]\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_mae_tr = np.mean(tr_mae)\nstd_mae_tr =  np.std(tr_mae)\n\nmean_mae_val =  np.mean(val_mae)\nstd_mae_val =  np.std(val_mae)\n\nall_mae = mean_absolute_error(oof,y_train)\n\nprint('-'*20)\nprint(\"Train's Score\")\nprint('-'*20,'\\n')\nprint(\"Mean mae: %.5f, std: %.5f.\" % (mean_mae_tr, std_mae_tr),'\\n')\n\nprint('-'*20)\nprint(\"Validation's Score\")\nprint('-'*20,'\\n')\nprint(\"Mean mae: %.5f, std: %.5f.\" % (mean_mae_val, std_mae_val),'\\n')\n\nprint(\"All mae: %.5f.\" % (all_mae))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_imp = (feature_importance_df[[\"Feature\", \"importance\"]]\n        .groupby(\"Feature\")\n        .mean()\n        .sort_values(by=\"importance\", ascending=False)[:50].index)\nbest_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols_imp)]\n\nplt.figure(figsize=(14,26))\nsns.barplot(x=\"importance\", y=\"Feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\nplt.title('LightGBM Features (averaged over folds)')\nplt.tight_layout()\nplt.savefig('lgbm_importances.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Submission**"},{"metadata":{"trusted":true},"cell_type":"code","source":"env = nflrush.make_env()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.options.mode.chained_assignment = None\nfor (df_test, sample_prediction_df) in tqdm.tqdm(env.iter_test()):\n    df_test_transfromed = df_transfromer.transform(df_test)\n    df_test_transfromed.drop(['GameId', 'PlayId'], axis=1, inplace=True)\n    \n    y_pred = np.zeros(199)        \n    y_pred_p = np.mean([model.predict(df_test_transfromed)[0] for model in models])\n    y_pred_p += 99\n    for j in range(199):\n        if j>=y_pred_p+10:\n            y_pred[j]=1.0\n        elif j>=y_pred_p-10:\n            y_pred[j]=(j+10-y_pred_p)*0.05\n            \n    env.predict(pd.DataFrame(data=[y_pred],columns=sample_prediction_df.columns))\nenv.write_submission_file()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}