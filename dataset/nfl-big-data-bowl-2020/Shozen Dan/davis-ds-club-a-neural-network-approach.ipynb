{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Introduction\n<p>Hello, and welcome to this notebook. Just a few notes before we begin. This is a notebook for beginners like me to get started with this tournament. I created this notebook in the hopes that, people can use the functions and objects I implemented to save time and energy. Although some methods are of my own creation, most of this notebook is based on other peoples' work and I have included the links to those notebooks in the descriptions. This notebook is a work in progress and will likely be updated as I myself learn more and more.</p>"},{"metadata":{},"cell_type":"markdown","source":"### Libraries"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport math\nimport matplotlib.pyplot as plt\nimport datetime\nfrom kaggle.competitions import nflrush\nimport tqdm\nimport re\nfrom string import punctuation\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport keras\nimport keras.backend as K","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env = nflrush.make_env()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/nfl-big-data-bowl-2020/train.csv\", dtype={'WindSpeed': 'object'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## I. Preprocessing\n1. Implementing a Data Parsing Class\n2. Implementing a Feature Engineering Class\n3. Implementing a Function to Reshape Data for Neural Network Input"},{"metadata":{},"cell_type":"markdown","source":"### 1. Data Parsing\n<p>\n    This class parses the raw data into something more useful through a process of, fixing typos, creating dummy varaibles, and creating numerical maps. I will not go into detail what each of the method does in the description but if you want to implement your own cleaning method, feel free to copy this class and alter it.\n</p>\n<p>**Input**: The original pandas DataFrame</p>\n<p>**Output**: A cleaned version of the DataFrame</p>\n<p>**References**: (Wonderful notebooks, please check them out!)\n    <ol>\n        <li>https://www.kaggle.com/prashantkikani/nfl-starter-lgb-feature-engg</li>\n        <li>https://www.kaggle.com/bgmello/neural-networks-feature-engineering-for-the-win</li>\n    </ol>\n</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataParser:\n\n    def __init__(self, data, predict=False, encoders={}):\n        self.data = data\n        self.predict = predict\n        self.encoders = encoders\n\n    def cleanWindSpeed(self, x):\n        x = str(x)\n        x = x.lower()\n        if '-' in x:\n            x = (int(x.split('-')[0]) + int(x.split('-')[1])) / 2\n        elif ' gusts up to 25 ' in x:\n            x = (int(x.split(' gusts up tp 25 ')))\n        try:\n            return float(x)\n        except:\n            return -1\n\n    def cleanGameWeather(self, x):\n        x = str(x).lower()\n        if 'sunny' in x or 'clear' in x or 'fair' in x:\n            return 'sunny'\n        elif 'cloud' in x or 'coudy' in x or 'clouidy' in x or 'hazy' in x or 'sun & clouds' in x or 'overcast' in x:\n            return 'cloudy'\n        elif 'rain' in x or 'shower' in x or 'rainy' in x:\n            return 'rainy'\n        elif 'controlled climate' in x or 'indoor' in x:\n            return 'indoor'\n        elif 'snow' in x:\n            return 'snowy'\n        return 'missing'\n        \n    def mapGameWeather(self, txt):\n        ans = 1\n        if pd.isna(txt):\n            return 0\n        if 'partly' in txt:\n            ans*=0.5\n        if 'climate controlled' in txt or 'indoor' in txt:\n            return ans*3\n        if 'sunny' in txt or 'sun' in txt:\n            return ans*2\n        if 'clear' in txt:\n            return ans\n        if 'cloudy' in txt:\n            return -ans\n        if 'rain' in txt or 'rainy' in txt:\n            return -2*ans\n        if 'snow' in txt:\n            return -3*ans\n        return 0\n\n    def cleanStadiumType(self, txt):  # Fixes the typo\n        if pd.isna(txt):\n            return np.nan\n        txt = txt.lower()\n        txt = ''.join([c for c in txt if c not in punctuation])\n        txt = re.sub(' +', ' ', txt)\n        txt = txt.strip()\n        txt = txt.replace('outside', 'outdoor')\n        txt = txt.replace('outdor', 'outdoor')\n        txt = txt.replace('outddors', 'outdoor')\n        txt = txt.replace('outdoors', 'outdoor')\n        txt = txt.replace('oudoor', 'outdoor')\n        txt = txt.replace('indoors', 'indoor')\n        txt = txt.replace('ourdoor', 'outdoor')\n        txt = txt.replace('retractable', 'rtr.')\n        return txt\n\n    # Focuses only on the words: outdoor, indoor, closed and open.\n    def cleanStadiumType2(self, txt):\n        if pd.isna(txt):\n            return np.nan\n        if 'outdoor' in txt or 'open' in txt:\n            return 1\n        if 'indoor' in txt or 'closed' in txt:\n            return 0\n        return np.nan\n\n    def cleanDefencePersonnel(self):\n        arr = [[int(s[0]) for s in t.split(', ')]\n               for t in self.data['DefensePersonnel']]\n        self.data['DL'] = pd.Series([int(a[0]) for a in arr])\n        self.data['LB'] = pd.Series([int(a[1]) for a in arr])\n        self.data['DB'] = pd.Series([int(a[2]) for a in arr])\n        self.data = self.data.drop(labels=[\"DefensePersonnel\"], axis=1)\n\n    def cleanOffencePersonnel(self):\n        arr = [[int(s[0]) for s in t.split(\", \")]\n               for t in self.data[\"OffensePersonnel\"]]\n        self.data[\"RB\"] = pd.Series([int(a[0]) for a in arr])\n        self.data[\"TE\"] = pd.Series([int(a[1]) for a in arr])\n        self.data[\"WR\"] = pd.Series([int(a[2]) for a in arr])\n        self.data = self.data.drop(labels=[\"OffensePersonnel\"], axis=1)\n\n    def cleanOffenseFormation(self):\n        self.data['OffenseFormation'].fillna('missing', inplace=True)\n        if(not self.predict):\n            le = LabelEncoder()\n            le.fit(self.data['OffenseFormation'])\n            self.encoders['OffenseFormation'] = le\n        self.data['OffenseFormation'] = self.encoders['OffenseFormation'].transform(self.data['OffenseFormation'])\n        \n    def cleanHeight(self):\n        \"\"\"\n        Parses the PlayerHeight column and converts height into inches\n        \"\"\"\n        self.data['PlayerHeight'] = self.data['PlayerHeight'].apply(\n            lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n\n    def cleanTimeHandoff(self):\n        self.data['TimeHandoff'] = self.data['TimeHandoff'].apply(\n            lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n\n    def cleanTimeSnap(self):\n        self.data['TimeSnap'] = self.data['TimeSnap'].apply(\n            lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n\n    def cleanGameClock(self):\n        arr = [[int(s[0]) for s in t.split(\":\")]\n               for t in self.data[\"GameClock\"]]\n        self.data[\"GameHour\"] = [int(a[0]) for a in arr]\n        self.data[\"GameMinute\"] = [int(a[1]) for a in arr]\n        self.data = self.data.drop(labels=['GameClock'], axis=1)\n\n    def cleanTurf(self):\n        # from https://www.kaggle.com/c/nfl-big-data-bowl-2020/discussion/112681#latest-649087\n        Turf = {'Field Turf': 'Artificial', 'A-Turf Titan': 'Artificial', 'Grass': 'Natural', 'UBU Sports Speed S5-M': 'Artificial',\n                'Artificial': 'Artificial', 'DD GrassMaster': 'Artificial', 'Natural Grass': 'Natural',\n                'UBU Speed Series-S5-M': 'Artificial', 'FieldTurf': 'Artificial', 'FieldTurf 360': 'Artificial', 'Natural grass': 'Natural', 'grass': 'Natural',\n                'Natural': 'Natural', 'Artifical': 'Artificial', 'FieldTurf360': 'Artificial', 'Naturall Grass': 'Natural', 'Field turf': 'Artificial',\n                'SISGrass': 'Artificial', 'Twenty-Four/Seven Turf': 'Artificial', 'natural grass': 'Natural'}\n\n        self.data['Turf'] = self.data['Turf'].map(Turf)\n        self.data['Turf'] = self.data['Turf'] == 'Natural'\n\n    def cleanPossessionTeam(self):  # fixes problem in team name encoding\n        map_abbr = {'ARI': 'ARZ', 'BAL': 'BLT', 'CLE': 'CLV', 'HOU': 'HST'}\n        for abb in self.data['PossessionTeam'].unique():\n            map_abbr[abb] = abb\n        self.data['PossessionTeam'] = self.data['PossessionTeam'].map(\n            map_abbr)\n        self.data['HomeTeamAbbr'] = self.data['HomeTeamAbbr'].map(map_abbr)\n        self.data['VisitorTeamAbbr'] = self.data['VisitorTeamAbbr'].map(\n            map_abbr)\n\n    def cleanPlayerBirthDate(self):\n        self.data['PlayerBirthDate'] = self.data['PlayerBirthDate'].apply(\n            lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n\n    def cleanWindDirection(self, txt):\n        if pd.isna(txt):\n            return np.nan\n        txt = txt.lower()\n        txt = ''.join([c for c in txt if c not in punctuation])\n        txt = txt.replace('from', '')\n        txt = txt.replace(' ', '')\n        txt = txt.replace('north', 'n')\n        txt = txt.replace('south', 's')\n        txt = txt.replace('west', 'w')\n        txt = txt.replace('east', 'e')\n        return txt\n    \n    def mapWindDirection(self, txt):\n        windDirectionMap = {\n            'n': 0,'nne': 1/8,'nen': 1/8,'ne': 2/8,\n            'ene': 3/8,'nee': 3/8,'e': 4/8,'ese': 5/8,\n            'see': 5/8,'se': 6/8,'ses': 7/8,'sse': 7/8,\n            's': 1,'ssw': 9/8,'sws': 9/8,'sw': 10/8,\n            'sww': 11/8,'wsw': 11/8,'w': 12/8,'wnw': 13/8,\n            'nw': 14/8,'nwn': 15/8,'nnw': 15/8\n        }\n        try:\n            return windDirectionMap[txt]\n        except:\n            return np.nan\n\n    def cleanPlayDirection(self):\n        \"\"\"\n        1 if play direction if right, 0 if play direction is left.\n        \"\"\"\n        self.data['PlayDirection'] = self.data['PlayDirection'].apply(\n            lambda x: x.strip() == 'right')\n\n    def cleanTeam(self):\n        \"\"\"\n        1 if home team, 0 if away team\n        \"\"\"\n        self.data['Team'] = self.data['Team'].apply(\n            lambda x: x.strip() == 'home')\n        \n    def isRusher(self):\n        self.data['isRusher'] = self.data['NflId'] == self.data['NflIdRusher']\n        temp = self.data[self.data['isRusher']][['Team', 'PlayId']].rename(columns={'Team':'RusherTeam'})\n        self.data = self.data.merge(temp, on = 'PlayId')\n        self.data['isRusherTeam'] = self.data['Team'] == self.data['RusherTeam']\n        self.data.drop(['NflId', 'NflIdRusher'], axis=1, inplace=True)\n        \n    def parse(self):\n        self.data['WindSpeed'] = self.data['WindSpeed'].apply(self.cleanWindSpeed)\n        self.data['GameWeather'] = self.data['GameWeather'].apply(self.cleanGameWeather)\n        self.data['GameWeather'] = self.data['GameWeather'].apply(self.mapGameWeather)\n        self.data['StadiumType'] = self.data['StadiumType'].apply(self.cleanStadiumType)\n        self.data['StadiumType'] = self.data['StadiumType'].apply(self.cleanStadiumType2)\n        self.data['WindDirection'] = self.data['WindDirection'].apply(self.cleanWindDirection)\n        self.data['WindDirection'] = self.data['WindDirection'].apply(self.mapWindDirection)\n        self.cleanOffenseFormation()\n        self.cleanOffencePersonnel()\n        self.cleanDefencePersonnel()\n        self.cleanHeight()\n        self.cleanTimeHandoff()\n        self.cleanTimeSnap()\n        self.cleanTurf()\n        self.cleanPossessionTeam()\n        self.cleanPlayerBirthDate()\n        self.cleanPlayDirection()\n        self.cleanTeam()\n        self.isRusher()\n        \n        if(not self.predict):\n            return self.data, self.encoders\n        return self.data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parser = DataParser(train)\ntrain, encoders = parser.parse()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2. Feature Engineering\n<p>\n    This class takes the cleaned data from the parser and engineers it through a combination of methods I found in other notebooks and my own inventions. I will not go into detail what each of the method does in the description but if you want to implement your own engineering methods, feel free to copy this class and alter it.\n</p>\n<ul>\n    <li><b>Input</b>: The parsed pandas DataFrame</li>\n    <li><b>Output</b>: An engineered version of the DataFrame</li>\n    <li><b>References</b>: (Wonderful notebooks, please check them out!)\n        <ol>\n            <li>https://www.kaggle.com/prashantkikani/nfl-starter-lgb-feature-engg</li>\n            <li>https://www.kaggle.com/bgmello/neural-networks-feature-engineering-for-the-win</li>\n        </ol>\n    </li>\n</ul>\n<h4>Engineered Features</h4>\n<ul>\n    <li><b>normalizeX</b>: Normalizes X</li>\n    <li><b>normalizeOrientation</b>: Normalize runners orientation: 0 = full offence, 180 = full retreat.\n        Makes it easier to compute horizontal speed: compute speed*cos(theta). References: #from https://www.kaggle.com/scirpus/hybrid-gp-and-nn</li>\n    <li><b>engineerFieldEqPossesion</b>:</li>\n</ul>\n<h4>Update 11/27</h4>\n<ul>\n    <li>engineerIsRusher moved to DataParser Class as it is not exactly an engineering feature.</li>\n</ul>\n\n</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"class FeatureEngine:\n\n    def __init__(self, data, exclude=[], deploy=False):\n        self.data = data  # Clean data from the parser\n        self.exclude = exclude  # Pass a list of processes to exclude\n        self.include = ['isRusher',\n                        'HorizontalSandA',\n                        'HomeField',\n                        'FieldEqPossession',\n                        'PlayerAge',\n                        'HandSnapDelta',\n                        'YardsLeft',\n                        'BMI',\n                        'DefendersInTheBox_vs_Distance']\n        self.deploy = deploy\n\n    ### Helper Functions ###\n    def normalizeX(self, x_coordinate, play_direction):\n        if play_direction == 1:\n            return 120 - x_coordinate\n        else:\n            return x_coordinate\n\n    def normalizeOrientation(self, angle, play_direction):\n        if play_direction == 0:\n            new_angle = 360.0 - angle\n            if new_angle == 360.0:\n                new_angle = 0.0\n            return new_angle\n        else:\n            return angle\n    \n    def newLine(self, rush_team, field_position, yardline):\n        if rush_team == field_position:\n            return 10.0 + yardline\n        else:\n            return 60.0 + (50 - yardline)\n        \n    def euclideanDistance(self, x1, y1, x2, y2):\n        x_diff = (x1-x2)**2\n        y_diff = (y1-y2)**2\n        return np.sqrt(x_diff + y_diff)\n    \n    def backDirection(self, orientation):\n        if orientation > 180.0:\n            return 1\n        else:\n            return 0\n    \n    def updateYardline(self, df):\n        new_yardline = df[df['isRusher']]\n        new_yardline['YardLine'] = new_yardline[['PossessionTeam','FieldPosition','YardLine']].apply(lambda x: self.newLine(x[0],x[1],x[2]), axis=1)\n        new_yardline = new_yardline[['GameId', 'PlayId', 'YardLine']]\n        return new_yardline\n    \n    def updateOrientation(self, df, yardline):\n        df['X'] = df[['X','PlayDirection']].apply(lambda x: self.normalizeX(x[0],x[1]), axis=1)\n        df['Orientation'] = df[['Orientation','PlayDirection']].apply(lambda x: self.normalizeOrientation(x[0],x[1]), axis=1)\n        df = df.drop('YardLine', axis=1)\n        df = pd.merge(df, yardline, on=['GameId', 'PlayId'], how='inner')\n        return df\n    \n    def backFeatures(self, df):\n        carriers = df[df['isRusher']][['GameId','PlayId','X','Y','Orientation','Dir','YardLine']]\n        carriers['back_from_scrimmage'] = carriers['YardLine'] - carriers['X']\n        carriers['back_oriented_down_field'] = carriers['Orientation'].apply(lambda x: self.backDirection(x))\n        carriers['back_moving_down_field'] = carriers['Dir'].apply(lambda x: self.backDirection(x))\n        carriers = carriers.rename(columns={'X':'back_X',\n                                            'Y':'back_Y'})\n        carriers = carriers[['GameId','PlayId','back_X','back_Y', 'back_from_scrimmage', 'back_oriented_down_field', 'back_moving_down_field']]\n        return carriers\n    \n    def featuresRelativeToBack(self, df, carriers):\n        player_distance = df[['GameId','PlayId','X','Y','isRusher']]\n        player_distance = pd.merge(player_distance, carriers, on=['GameId','PlayId'], how='inner')\n        player_distance = player_distance[player_distance['isRusher'] == 0]\n        player_distance['dist_to_back'] = player_distance[['X','Y','back_X','back_Y']].apply(lambda x: self.euclideanDistance(x[0],x[1],x[2],x[3]), axis=1)\n        player_distance = player_distance.groupby(['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field'])\\\n                                         .agg({'dist_to_back':['min','max','mean','std']})\\\n                                         .reset_index()\n        player_distance.columns = ['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field',\n                                   'min_dist','max_dist','mean_dist','std_dist']\n        return player_distance\n    \n    def defenseFeatures(self, df):\n        rusher = df[df['isRusher']][['GameId','PlayId','Team','X','Y']]\n        rusher.columns = ['GameId','PlayId','RusherTeam','RusherX','RusherY']\n\n        defense = pd.merge(df,rusher,on=['GameId','PlayId'],how='inner')\n        defense = defense[defense['isRusherTeam'] != True][['GameId','PlayId','X','Y','RusherX','RusherY']]\n        defense['def_dist_to_back'] = defense[['X','Y','RusherX','RusherY']].apply(lambda x: self.euclideanDistance(x[0],x[1],x[2],x[3]), axis=1)\n        defense = defense.groupby(['GameId','PlayId'])\\\n                         .agg({'def_dist_to_back':['min','max','mean','std']})\\\n                         .reset_index()\n        defense.columns = ['GameId','PlayId','def_min_dist','def_max_dist','def_mean_dist','def_std_dist']\n        return defense\n    \n    def rusherFeatures(self, df): \n        rusher = df[df['isRusher']][['GameId','PlayId','Dir', 'S', 'A', 'X', 'Y']]\n        rusher.columns = ['GameId','PlayId', 'RusherDir', 'RusherS', 'RusherA', 'RusherX', 'RusherY']\n    \n        radian_angle = (90 - rusher['RusherDir']) * np.pi / 180.0\n        v_horizontal = np.abs(rusher['RusherS'] * np.cos(radian_angle))\n        v_vertical = np.abs(rusher['RusherS'] * np.sin(radian_angle)) \n    \n        rusher['v_horizontal'] = v_horizontal\n        rusher['v_vertical'] = v_vertical\n        \n        rusher.columns = ['GameId','PlayId', 'RusherDir', 'RusherS','RusherA','RusherX', 'RusherY','v_horizontal', 'v_vertical']\n        \n        return rusher\n    \n    ### Engineering Functions ###\n    def engineerFieldEqPossession(self):\n        self.data['FieldEqPossession'] = self.data['FieldPosition'] == self.data['PossessionTeam']\n\n    def engineerHomeField(self):\n        self.data['HomeField'] = self.data['FieldPosition'] == self.data['HomeTeamAbbr']\n    \n    def engineerHandoffSnapDelta(self):\n        self.data['TimeDelta'] = self.data.apply(lambda row: (\n            row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n        self.data = self.data.drop(['TimeHandoff', 'TimeSnap'], axis=1)\n\n    def engineerYardsLeft(self):\n        \"\"\"\n        Computes yards left from end-zone\n\n        Note\n        ----\n        Requires variable HomeField (must execute engineerHomeField before execution)\n        \"\"\"\n        self.data['YardsLeft'] = self.data.apply(\n            lambda row: 100-row['YardLine'] if row['HomeField'] else row['YardLine'], axis=1)\n        self.data['YardsLeft'] = self.data.apply(\n            lambda row: row['YardsLeft'] if row['PlayDirection'] else 100-row['YardsLeft'], axis=1)\n        \n    def engineerBMI(self):\n        \"\"\"\n        Computes the BMI of a player from height and weight\n        \"\"\"\n        self.data['PlayerBMI'] = 703 * \\\n            (self.data['PlayerWeight']/(self.data['PlayerHeight'])**2)\n\n    def engineerPlayerAge(self):\n        \"\"\"\n        Computes the age of the player from TimeHandoff\n        \"\"\"\n        seconds_in_year = 60*60*24*365.25\n        self.data['PlayerAge'] = self.data.apply(lambda row: (\n            row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()/seconds_in_year, axis=1)\n        self.data = self.data.drop(['PlayerBirthDate'], axis=1)\n\n    def engineerDefendersInTheBox_vs_Distance(self):\n        dfInBox_mode = self.data['DefendersInTheBox'].mode()\n        self.data['DefendersInTheBox'].fillna(\n            dfInBox_mode.iloc[0], inplace=True)\n        self.data['DefendersInTheBox_vs_Distance'] = self.data['DefendersInTheBox'] / \\\n            self.data['Distance']\n        \n    def combineFeatures(self, relative_to_back, defense,rushing, static):\n        df = pd.merge(relative_to_back,defense,on=['GameId','PlayId'],how='inner')\n        df = pd.merge(df,rushing,on=['GameId','PlayId'],how='inner')\n        df = pd.merge(df,static,on=['GameId','PlayId'],how='inner')\n\n        return df\n\n    ### Outputs clean and engineered DataFrame ###\n    def engineer(self):\n        yardline = self.updateYardline(self.data)\n        self.data = self.updateOrientation(self.data, yardline)\n        back_feats = self.backFeatures(self.data)\n        rel_back = self.featuresRelativeToBack(self.data, back_feats)\n        def_feats = self.defenseFeatures(self.data)\n        rush_feats = self.rusherFeatures(self.data)\n        \n        for c in self.include:\n\n            if c in self.exclude:\n                continue\n\n            elif c == 'FieldEqPossession':\n                self.engineerFieldEqPossession()\n\n            elif c == 'HomeField':\n                self.engineerHomeField()\n\n            elif c == 'YardsLeft':\n                self.engineerYardsLeft()\n\n            elif c == 'PlayerAge':\n                self.engineerPlayerAge()\n\n            elif c == 'HandSnapDelta':\n                self.engineerHandoffSnapDelta()\n\n            elif c == 'BMI':\n                self.engineerBMI()\n\n            elif c == 'DefendersInTheBox_vs_Distance':\n                self.engineerDefendersInTheBox_vs_Distance()\n                \n        self.data = self.combineFeatures(rel_back, def_feats, rush_feats, self.data)\n        self.data = self.data.drop_duplicates()\n\n        return self.data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"engine = FeatureEngine(train.copy())\ntrain = engine.engineer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3. Reshaping Data\n<p>\n    In the final stage of the preprocessing pipeline, we must reformat the data into a shape that the neural network can take as input, in this case, tensors as we are using Keras and Tensorflow. This function is based on the steps provided in the following notebook: https://www.kaggle.com/bgmello/neural-networks-feature-engineering-for-the-win\n</p>\n**Input and Parameters**\n<ul>\n    <li>**data**: The cleaned and engineered DataFrame</li>\n    <li>**predict**: This parameter is needed because of the way I implemented the prediction function. In the prediction stage, the column \"Yards\" is not included in the training set(for obvious reasons), and thus, I needed to disable a feature that uses \"Yards\" for the prediction process.</li>\n    <li>**playersCol**: This parameter is also needed for the prediction stage. When the predict parameter is False, this function will return a set of column names containing variables that are unique to each player(eg. height and weight). Pass the list you obtained to this function in the prediction stage.</li>\n</ul>\n**Output**\n<ul>\n    <li>X_train, y_train, players_col (predict=False)\n    <li>X_train, y_train (predict=True)\n</ul>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def DataReshaper2(data, predict=False, playersCol = []):\n    \"\"\"\n    Takes the parsed and feature engineered data and outputs X_train and y_train\n    vectors that are compatible for neural networks and machine learning algorithms\n\n    Parameters:\n    -----------\n    data: parsed and feature engineered data (pandas dataframe format)\n    predict: must be true in the prediction stage\n    playersCol: pass the players_col created in the training stage\n\n    Returns:\n    --------\n    X_train: a 2 dimentional vector housing all predictor variables\n    y_train: a 1 dimentional vector housing all response variable\n    players_col: The names of variables that are unique to each player (ex: height and weight)\n\n    Note:\n    -----\n    Requires Standard Scalar from the scikit learn library\n    \n    References\n    ----------\n    https://www.kaggle.com/bgmello/neural-networks-feature-engineering-for-the-win\n    \"\"\"\n    \n    ### Dropping Unnecessary Columns and Filling NAs ###\n    data = data.sort_values(by=['PlayId', 'Team', 'isRusher', 'JerseyNumber']).reset_index()\n    data.drop(['GameId', 'PlayId', 'index', 'isRusher', 'Team'], axis=1, inplace=True)\n\n    drop_col = []\n    for c in data.columns:\n            if data[c].dtype == 'object':\n                drop_col.append(c)\n    data.drop(drop_col, axis=1, inplace=True)\n    \n    data.fillna(-999, inplace=True)\n    \n    ### Creating One Large Row ###\n    players_col = playersCol\n    if(not predict):\n        for col in data.columns:\n            if data[col][:22].std() != 0:\n                players_col.append(col)  # this measure is taken to avoid repeating data\n    \n    X_train = np.array(data[players_col]).reshape(-1, len(players_col)*22)\n\n    if(not predict):\n        play_col = data.drop(players_col + ['Yards'], axis=1).columns\n    else:\n        play_col = data.drop(players_col, axis=1).columns\n\n    X_play_col = np.zeros(shape=(X_train.shape[0], len(play_col)))\n    for i, col in enumerate(play_col):\n            X_play_col[:, i] = data[col][::22]\n\n    X_train = np.concatenate([X_train, X_play_col], axis=1)\n    \n    ### Reshaping y_train(only for training stage) ###\n    if(not predict):\n        y_train = np.zeros(shape=(X_train.shape[0], 199))\n        for i, yard in enumerate(train['Yards'][::22]):\n            y_train[i, yard+99:] = np.ones(shape=(1, 100-yard))\n\n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X_train)\n                            \n    if(not predict):\n        return X_train, y_train, players_col\n    return X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, y_train, players_col = DataReshaper2(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## II. Neural Network\n<p>Now that we have gone through the preprocessing process, we will now construct and train the neural network.</p>\n<ol>\n    <li>Model Architecture</li>\n    <li>Callbacks</li>\n    <li>Training the Model</li>\n</ol>"},{"metadata":{},"cell_type":"markdown","source":"### Import Keras Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Dense,Input,Dropout,BatchNormalization,LeakyReLU,PReLU,GaussianNoise\nfrom keras.models import Model\nimport keras.backend as K\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint\nfrom keras.optimizers import Adam\nfrom keras.losses import binary_crossentropy\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, Callback","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model Architecture\n<p>I am still in the initial stages of developing my neural network. We will start off with a very simple model, consisting of Dense, Dropout, and BatchNormalization layers. The Dropout and Batch Normalization are mainly there to restrict overfitting. Without them, even a shallow model with very few neurons will overfit very fast. With them, I can deepen the network.</p>\n<ul>\n    <li><b>Optimizer</b>: I initially used rmsprop but adam sees to be more popular. About whether it will increase accuracy or not.</li>\n    <li><b>Loss Function</b>: I shifted throught the various notebooks created by other participants and it seems that for this type of implementation(using softmax as a activation function for the last layer), <b>Categorical Crossentropy</b> seems to work the best.</li>\n</ul>\n<h4>Update 11/27</h4>\n<ul>\n    <li><b>Gaussian Noise Layer</b>: I had a lot of trouble with overfitting, so I added the Gaussian Noise Layer, which adds random noise with a Gaussian Distribution, to mitigate overfitting.</li>\n    <li><b>Loss Function</b>: When I used Categorical Crossentropy as a loss function, the loss kept increasing, thus I reverted to the original crps_loss function.</li>\n</ul>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    input_tensor = Input(shape=(X_train.shape[1],))\n    x = Dense(1024, activation='relu')(input_tensor)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    x = GaussianNoise(0.15)(x)\n    x = Dense(512, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    x = GaussianNoise(0.15)(x)\n    x = Dense(256, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    x = GaussianNoise(0.15)(x)\n    output_tensor = Dense(199, activation='softmax')(x)\n    \n    model = Model(input_tensor, output_tensor)\n    model.compile(optimizer='adam', loss=crps_loss, metrics=[])\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Callbacks\n<p>Usually, the training of a network will only end when the number of epochs have reached the amount specified before hand. This is not helpful, as models may overfit after only a handful of epochs. However by using the <b>Early Stopping Callback</b>, we can stop the training once the validation score no longer improves. We can also set the Early Stopping Callback so that it will resore the best weights once it has stopped the training process.</p>\n<ul>\n    <li><b>monitor</b>: Which value to monitor</li>\n    <li><b>restore_best_weights</b>: If True, Keras will restore the weights with the best score.</li>\n    <li><b>patience</b>: How many epochs more to train when score no longer improves.</li>\n</ul>"},{"metadata":{"trusted":true},"cell_type":"code","source":"ES = EarlyStopping(monitor='CRPS_score_val',\n                   mode='min',\n                   restore_best_weights=True,\n                   patience=3\n                  )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### CRPS Callback\n<p>This callback logs the <b>CRPS score</b> to the metrics during the training process. It is based completely off of: https://www.kaggle.com/gogo827jz/blending-nn-and-lgbm-rf</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CRPSCallback(Callback):\n    def __init__(self, validation, predict_batch_size=1024, include_on_batch=False):\n        super(CRPSCallback, self).__init__()\n        self.validation = validation\n        self.predict_batch_size = predict_batch_size\n        self.include_on_batch = include_on_batch\n        \n    def on_batch_begin(self, batch, logs={}):\n        pass\n    \n    def on_train_begin(self, logs={}):\n        if not ('CRPS_score_val' in self.params['metrics']):\n            self.params['metrics'].append('CRPS_score_val')\n            \n    def on_batch_end(self, batch, logs={}):\n        if (self.include_on_batch):\n            logs['CRPS_score_val'] = float('-inf')\n            \n    def on_epoch_end(self, epoch, logs={}):\n        logs['CRPS_score_val'] = float('-inf')\n        if(self.validation):\n            X_valid, y_valid = self.validation[0], self.validation[1]\n            y_pred = self.model.predict(X_valid)\n            y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n            y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n            val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * X_valid.shape[0])\n            val_s = np.round(val_s, 6)\n            logs['CRPS_score_val'] = val_s","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate CRPS score\ndef crps_score(y_prediction, y_valid, shape=X_train.shape[0]):\n    y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n    y_pred = np.clip(np.cumsum(y_prediction, axis=1), 0, 1)\n    val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * shape)\n    crps = np.round(val_s, 6)\n    \n    return crps","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from https://www.kaggle.com/davidcairuz/nfl-neural-network-w-softmax\ndef crps_loss(y_true, y_pred):\n    return K.mean(K.square(y_true - K.cumsum(y_pred, axis=1)), axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training the Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS = 200\nBATCH_SIZE = 1024\ndef train_model(X_train, y_train, X_val, y_val):\n    model = build_model()\n    model.fit(X_train, y_train,\n              validation_data=(X_val, y_val),\n              epochs=EPOCHS,\n              batch_size=BATCH_SIZE,\n              callbacks=[CRPSCallback(validation = (X_val, y_val)), ES],\n              verbose=1)\n    \n    y_pred = model.predict(X_val)\n    y_valid = y_val\n    crps = crps_score(y_pred, y_valid, shape=X_val.shape[0])\n    \n    return model, crps","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Repeated K Fold Validation\n<p>What Repeated K Fold does is pretty self explanatory. It will conduct K Fold validation n times, each time randomly selecting subsets. This method takes a while to run, so before executing it, make sure every input is properly processed and you have finalized your model architechture.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\nN_SPLITS = 3\nN_REPEATS = 2\n\nnn_crps = []\nmodels = []\n\nfor n in range(N_REPEATS):\n    kf = KFold(N_SPLITS, random_state= 21 + n, shuffle = True)\n    for k_fold, (tr_idx, vl_idx) in enumerate(kf.split(y_train)):\n        print(\"-----------\")\n        print(f'Loop {n+1}/{N_REPEATS}' + f' Fold {k_fold+1}/{N_SPLITS}')\n        print(\"-----------\")\n        x_tr, y_tr = X_train[tr_idx], y_train[tr_idx]\n        x_vl, y_vl = X_train[vl_idx], y_train[vl_idx]\n\n        model, crps = train_model(x_tr, y_tr, x_vl, y_vl)\n        models.append(model)\n        print(\"the %d fold crps (NN) is %f\"%((k_fold+1), crps))\n        nn_crps.append(crps)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## III. Prediction and Submission\n<p>Now that we have trained the model we can use the make_pred function to submit our predictions.</p>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_pred(df, sample, env, models):\n    parser = DataParser(df, predict=True, encoders=encoders)\n    df = parser.parse()\n    \n    engine = FeatureEngine(df)\n    df = engine.engineer()\n    \n    X = DataReshaper2(df, predict=True, playersCol=players_col)\n    y_pred = np.mean([np.cumsum(model.predict(X), axis=1) for model in models], axis=0)\n    yardsleft = np.array(df['YardsLeft'][::22])\n    \n    for i in range(len(yardsleft)):\n        y_pred[i, :int(yardsleft[i]-1)] = 0\n        y_pred[i, int(yardsleft[i]+100):] = 1\n    env.predict(pd.DataFrame(data=y_pred.clip(0,1),columns=sample.columns))\n    return y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for test, sample in tqdm.tqdm(env.iter_test()):\n     make_pred(test, sample, env, models)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### End\nThis kernel is still in its development stages. Please feel free to make improvement and upvote if you find anything useful!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}