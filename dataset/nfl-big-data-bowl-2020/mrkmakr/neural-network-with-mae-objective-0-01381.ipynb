{"cells":[{"metadata":{},"cell_type":"markdown","source":"### v4 : try different architecture, Invariant to player's order\n### v3 : add name to nodes of neural network model"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\nimport datetime\nfrom kaggle.competitions import nflrush\nimport tqdm\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nimport keras\n\nfrom tqdm import tqdm_notebook\nimport warnings\nwarnings.filterwarnings('ignore')\n\nsns.set_style('darkgrid')\nmpl.rcParams['figure.figsize'] = [15,10]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/nfl-big-data-bowl-2020/train.csv', dtype={'WindSpeed': 'object'})\n# train = train[:2200]\nprint(train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://www.kaggle.com/rooshroosh/fork-of-neural-networks-different-architecture\ndef strtoseconds(txt):\n    txt = txt.split(':')\n    ans = int(txt[0])*60 + int(txt[1]) + int(txt[2])/60\n    return ans\n\ndef strtofloat(x):\n    try:\n        return float(x)\n    except:\n        return -1\n\ndef map_weather(txt):\n    ans = 1\n    if pd.isna(txt):\n        return 0\n    if 'partly' in txt:\n        ans*=0.5\n    if 'climate controlled' in txt or 'indoor' in txt:\n        return ans*3\n    if 'sunny' in txt or 'sun' in txt:\n        return ans*2\n    if 'clear' in txt:\n        return ans\n    if 'cloudy' in txt:\n        return -ans\n    if 'rain' in txt or 'rainy' in txt:\n        return -2*ans\n    if 'snow' in txt:\n        return -3*ans\n    return 0\n\ndef OffensePersonnelSplit(x):\n    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0, 'QB' : 0, 'RB' : 0, 'TE' : 0, 'WR' : 0}\n    for xx in x.split(\",\"):\n        xxs = xx.split(\" \")\n        dic[xxs[-1]] = int(xxs[-2])\n    return dic\n\ndef DefensePersonnelSplit(x):\n    dic = {'DB' : 0, 'DL' : 0, 'LB' : 0, 'OL' : 0}\n    for xx in x.split(\",\"):\n        xxs = xx.split(\" \")\n        dic[xxs[-1]] = int(xxs[-2])\n    return dic\n\ndef orientation_to_cat(x):\n    x = np.clip(x, 0, 360 - 1)\n    try:\n        return str(int(x/15))\n    except:\n        return \"nan\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(train):\n    ## GameClock\n    train['GameClock_sec'] = train['GameClock'].apply(strtoseconds)\n    train[\"GameClock_minute\"] = train[\"GameClock\"].apply(lambda x : x.split(\":\")[0]).astype(\"object\")\n\n    ## Height\n    train['PlayerHeight_dense'] = train['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n\n    ## Time\n    train['TimeHandoff'] = train['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n    train['TimeSnap'] = train['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n\n    train['TimeDelta'] = train.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n    train['PlayerBirthDate'] = train['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n\n    ## Age\n    seconds_in_year = 60*60*24*365.25\n    train['PlayerAge'] = train.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()/seconds_in_year, axis=1)\n    train[\"PlayerAge_ob\"] = train['PlayerAge'].astype(np.int).astype(\"object\")\n\n    ## WindSpeed\n    train['WindSpeed_ob'] = train['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n    train['WindSpeed_ob'] = train['WindSpeed_ob'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n    train['WindSpeed_ob'] = train['WindSpeed_ob'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n    train['WindSpeed_dense'] = train['WindSpeed_ob'].apply(strtofloat)\n\n    ## Weather\n    train['GameWeather_process'] = train['GameWeather'].str.lower()\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: \"indoor\" if not pd.isna(x) and \"indoor\" in x else x)\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n    train['GameWeather_dense'] = train['GameWeather_process'].apply(map_weather)\n\n    ## Rusher\n    train['IsRusher'] = (train['NflId'] == train['NflIdRusher'])\n    train['IsRusher_ob'] = (train['NflId'] == train['NflIdRusher']).astype(\"object\")\n    temp = train[train[\"IsRusher\"]][[\"Team\", \"PlayId\"]].rename(columns={\"Team\":\"RusherTeam\"})\n    train = train.merge(temp, on = \"PlayId\")\n    train[\"IsRusherTeam\"] = train[\"Team\"] == train[\"RusherTeam\"]\n\n    ## dense -> categorical\n    train[\"Quarter_ob\"] = train[\"Quarter\"].astype(\"object\")\n    train[\"Down_ob\"] = train[\"Down\"].astype(\"object\")\n    train[\"JerseyNumber_ob\"] = train[\"JerseyNumber\"].astype(\"object\")\n    train[\"YardLine_ob\"] = train[\"YardLine\"].astype(\"object\")\n    # train[\"DefendersInTheBox_ob\"] = train[\"DefendersInTheBox\"].astype(\"object\")\n    # train[\"Week_ob\"] = train[\"Week\"].astype(\"object\")\n    # train[\"TimeDelta_ob\"] = train[\"TimeDelta\"].astype(\"object\")\n\n\n    ## Orientation and Dir\n    train[\"Orientation_ob\"] = train[\"Orientation\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n    train[\"Dir_ob\"] = train[\"Dir\"].apply(lambda x : orientation_to_cat(x)).astype(\"object\")\n\n    train[\"Orientation_sin\"] = train[\"Orientation\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n    train[\"Orientation_cos\"] = train[\"Orientation\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n    train[\"Dir_sin\"] = train[\"Dir\"].apply(lambda x : np.sin(x/360 * 2 * np.pi))\n    train[\"Dir_cos\"] = train[\"Dir\"].apply(lambda x : np.cos(x/360 * 2 * np.pi))\n\n    ## diff Score\n    train[\"diffScoreBeforePlay\"] = train[\"HomeScoreBeforePlay\"] - train[\"VisitorScoreBeforePlay\"]\n    train[\"diffScoreBeforePlay_binary_ob\"] = (train[\"HomeScoreBeforePlay\"] > train[\"VisitorScoreBeforePlay\"]).astype(\"object\")\n\n    ## Turf\n    Turf = {'Field Turf':'Artificial', 'A-Turf Titan':'Artificial', 'Grass':'Natural', 'UBU Sports Speed S5-M':'Artificial', 'Artificial':'Artificial', 'DD GrassMaster':'Artificial', 'Natural Grass':'Natural', 'UBU Speed Series-S5-M':'Artificial', 'FieldTurf':'Artificial', 'FieldTurf 360':'Artificial', 'Natural grass':'Natural', 'grass':'Natural', 'Natural':'Natural', 'Artifical':'Artificial', 'FieldTurf360':'Artificial', 'Naturall Grass':'Natural', 'Field turf':'Artificial', 'SISGrass':'Artificial', 'Twenty-Four/Seven Turf':'Artificial', 'natural grass':'Natural'} \n    train['Turf'] = train['Turf'].map(Turf)\n\n    ## OffensePersonnel\n    temp = train[\"OffensePersonnel\"].iloc[np.arange(0, len(train), 22)].apply(lambda x : pd.Series(OffensePersonnelSplit(x)))\n    temp.columns = [\"Offense\" + c for c in temp.columns]\n    temp[\"PlayId\"] = train[\"PlayId\"].iloc[np.arange(0, len(train), 22)]\n    train = train.merge(temp, on = \"PlayId\")\n\n    ## DefensePersonnel\n    temp = train[\"DefensePersonnel\"].iloc[np.arange(0, len(train), 22)].apply(lambda x : pd.Series(DefensePersonnelSplit(x)))\n    temp.columns = [\"Defense\" + c for c in temp.columns]\n    temp[\"PlayId\"] = train[\"PlayId\"].iloc[np.arange(0, len(train), 22)]\n    train = train.merge(temp, on = \"PlayId\")\n\n    ## sort\n#     train = train.sort_values(by = ['X']).sort_values(by = ['Dis']).sort_values(by=['PlayId', 'Team', 'IsRusher']).reset_index(drop = True)\n    train = train.sort_values(by = ['X']).sort_values(by = ['Dis']).sort_values(by=['PlayId', 'IsRusherTeam', 'IsRusher']).reset_index(drop = True)\n    return train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain = preprocess(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## DisplayName remove Outlier\nv = train[\"DisplayName\"].value_counts()\nmissing_values = list(v[v < 5].index)\ntrain[\"DisplayName\"] = train[\"DisplayName\"].where(~train[\"DisplayName\"].isin(missing_values), \"nan\")\n\n## PlayerCollegeName remove Outlier\nv = train[\"PlayerCollegeName\"].value_counts()\nmissing_values = list(v[v < 10].index)\ntrain[\"PlayerCollegeName\"] = train[\"PlayerCollegeName\"].where(~train[\"PlayerCollegeName\"].isin(missing_values), \"nan\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.to_pickle(train, \"train.pkl\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def drop(train):\n    drop_cols = [\"GameId\", \"GameWeather\", \"NflId\", \"Season\", \"NflIdRusher\"] \n    drop_cols += ['TimeHandoff', 'TimeSnap', 'PlayerBirthDate']\n    drop_cols += [\"Orientation\", \"Dir\", 'WindSpeed', \"GameClock\"]\n    # drop_cols += [\"DefensePersonnel\",\"OffensePersonnel\"]\n    train = train.drop(drop_cols, axis = 1)\n    return train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = drop(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features = []\ndense_features = []\nfor col in train.columns:\n    if train[col].dtype =='object':\n        cat_features.append(col)\n        print(\"*cat*\", col, len(train[col].unique()))\n    else:\n        dense_features.append(col)\n        print(\"!dense!\", col, len(train[col].unique()))\ndense_features.remove(\"PlayId\")\ndense_features.remove(\"Yards\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## categorical"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cat = train[cat_features]\ncategories = []\nmost_appear_each_categories = {}\nfor col in tqdm_notebook(train_cat.columns):\n    train_cat.loc[:,col] = train_cat[col].fillna(\"nan\")\n    train_cat.loc[:,col] = col + \"__\" + train_cat[col].astype(str)\n    most_appear_each_categories[col] = list(train_cat[col].value_counts().index)[0]\n    categories.append(train_cat[col].unique())\ncategories = np.hstack(categories)\nprint(len(categories))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\nle.fit(categories)\nfor col in tqdm_notebook(train_cat.columns):\n    train_cat.loc[:, col] = le.transform(train_cat[col])\nnum_classes = len(le.classes_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dense"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dense = train[dense_features]\nsss = {}\nmedians = {}\nfor col in tqdm_notebook(train_dense.columns):\n    print(col)\n    medians[col] = np.nanmedian(train_dense[col])\n    train_dense.loc[:, col] = train_dense[col].fillna(medians[col])\n    ss = StandardScaler()\n    train_dense.loc[:, col] = ss.fit_transform(train_dense[col].values[:,None])\n    sss[col] = ss","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Divide features into groups"},{"metadata":{"trusted":true},"cell_type":"code","source":"## dense features for play\ndense_game_features = train_dense.columns[train_dense[:22].std() == 0]\n## dense features for each player\ndense_player_features = train_dense.columns[train_dense[:22].std() != 0]\n## categorical features for play\ncat_game_features = train_cat.columns[train_cat[:22].std() == 0]\n## categorical features for each player\ncat_player_features = train_cat.columns[train_cat[:22].std() != 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dense_game = train_dense[dense_game_features].iloc[np.arange(0, len(train), 22)].reset_index(drop = True).values\ntrain_dense_game = np.hstack([train_dense_game, train_dense[dense_player_features][train_dense[\"IsRusher\"] > 0]]) ## with rusher player feature\n\ntrain_dense_players = [train_dense[dense_player_features].iloc[np.arange(k, len(train), 22)].reset_index(drop = True) for k in range(22)]\ntrain_dense_players = np.stack([t.values for t in train_dense_players]).transpose(1, 0, 2)\n\ntrain_cat_game = train_cat[cat_game_features].iloc[np.arange(0, len(train), 22)].reset_index(drop = True).values\ntrain_cat_game = np.hstack([train_cat_game, train_cat[cat_player_features][train_dense[\"IsRusher\"] > 0]]) ## with rusher player feature\n\ntrain_cat_players = [train_cat[cat_player_features].iloc[np.arange(k, len(train), 22)].reset_index(drop = True) for k in range(22)]\ntrain_cat_players = np.stack([t.values for t in train_cat_players]).transpose(1, 0, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def return_step(x):\n    temp = np.zeros(199)\n    temp[x + 99:] = 1\n    return temp\n\ntrain_y_raw = train[\"Yards\"].iloc[np.arange(0, len(train), 22)].reset_index(drop = True)\ntrain_y = np.vstack(train_y_raw.apply(return_step).values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dense_game.shape, train_dense_players.shape, train_cat_game.shape, train_cat_players.shape, train_y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras import backend as K\nfrom keras import regularizers\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keras.backend.clear_session()\ndef crps(y_true, y_pred):\n    loss = K.mean((K.cumsum(y_pred, axis = 1) - y_true)**2)\n    return loss\n\ndef get_model(batch_size = 32, epochs = 10):\n    \n    ## inputs\n    input_dense_game = keras.layers.Input(shape=(train_dense_game.shape[1],), name = \"numerical_general_inputs\")\n    input_dense_players = keras.layers.Input(shape=(train_dense_players.shape[1],train_dense_players.shape[2]), name = \"numerical_players_inputs\")\n    input_cat_game = keras.layers.Input(shape=(train_cat_game.shape[1], ), name = \"categorical_general_inputs\")\n    input_cat_players = keras.layers.Input(shape=(train_cat_players.shape[1], train_cat_players.shape[2]), name = \"categorical_players_input\")\n    \n    ## embedding\n    embedding = keras.layers.Embedding(num_classes, 4, embeddings_regularizer=regularizers.l2(1e-4))\n    emb_cat_game = embedding(input_cat_game)\n    emb_cat_game = keras.layers.Flatten()(emb_cat_game)\n    emb_cat_players = embedding(input_cat_players)\n    emb_cat_players = keras.layers.Reshape((int(emb_cat_players.shape[1]), int(emb_cat_players.shape[2]) * int(emb_cat_players.shape[3])))(emb_cat_players)\n    \n    ## general game features\n    game = keras.layers.Concatenate(name = \"general_features\")([input_dense_game, emb_cat_game])\n    game = keras.layers.Dense(32, activation=\"relu\")(game)\n    game = keras.layers.Dropout(0.5)(game)\n    \n    ## players features\n    players = keras.layers.Concatenate(name = \"players_features\")([input_dense_players, emb_cat_players])\n    n_unit = 16\n    players_aves = []\n    for k in range(3):\n        players = keras.layers.Dense(16, activation=None)(players)\n        players_aves.append(keras.layers.GlobalAveragePooling1D()(players))\n        players = keras.layers.Activation(\"relu\")(players)\n    players = keras.layers.Concatenate(name = \"deep_players_features\")(players_aves)\n    players = keras.layers.Dropout(0.5)(players)\n\n    ### concat all\n    x_concat = keras.layers.Concatenate(name = \"general_and_players\")([game, players])\n    x_concats = []\n    n_unit = 128\n    decay_rate = 0.5\n    for k in range(3):\n        x_concat = keras.layers.Dense(n_unit, activation=\"relu\")(x_concat)\n        x_concats.append(x_concat)\n        n_unit = int(n_unit * decay_rate)\n    x_concat = keras.layers.Concatenate(name = \"deep_features\")(x_concats)\n    x_concat = keras.layers.Dropout(0.5)(x_concat)\n    \n    ## concat\n    x_concat = keras.layers.Concatenate(name = \"all_concat\")([game, players, x_concat])\n    out_soft = keras.layers.Dense(199, activation=\"softmax\", name = \"out_soft\")(x_concat)\n    out_reg = keras.layers.Dense(1, activation=None, name = \"out_reg\")(x_concat)\n    model = keras.models.Model(inputs = [input_dense_game, input_dense_players, input_cat_game, input_cat_players],\n                               outputs = [out_soft, out_reg])\n\n    ## compile\n    model.compile(loss=[crps, keras.losses.mae],\n                  loss_weights=[1.0, 0.01],\n                  optimizer=keras.optimizers.Adam(learning_rate=0.002, decay = 1e-4))\n\n    ## train\n    tr_x = [train_dense_game[tr_inds], train_dense_players[tr_inds], train_cat_game[tr_inds], train_cat_players[tr_inds]]\n    tr_y = [train_y[tr_inds], train_y_raw[tr_inds]/100]\n    val_x = [train_dense_game[val_inds], train_dense_players[val_inds], train_cat_game[val_inds], train_cat_players[val_inds]]\n    val_y = [train_y[val_inds], train_y_raw[val_inds]/100]\n    model.fit(tr_x,\n              tr_y,\n              batch_size=batch_size,\n              epochs=epochs,\n              verbose=1,\n              validation_data=(val_x, val_y))\n    loss = model.history.history[\"val_out_soft_loss\"][-1]\n    return model, loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, KFold\nlosses = []\nmodels = []\nfor k in range(2):\n    kfold = KFold(5, random_state = 42 + k, shuffle = True)\n    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(train_y)):\n        print(\"-----------\")\n        print(\"-----------\")\n        model, loss = get_model(32, 20)\n        models.append(model)\n        print(k_fold, loss)\n        losses.append(loss)\nprint(\"-------\")\nprint(losses)\nprint(np.mean(losses))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import plot_model\nplot_model(model, to_file='model.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(losses)\nprint(np.mean(losses))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_pred(test, sample, env, model):\n    test = preprocess(test)\n    test = drop(test)\n\n    ### categorical\n    test_cat = test[cat_features]\n    for col in (test_cat.columns):\n        test_cat.loc[:,col] = test_cat[col].fillna(\"nan\")\n        test_cat.loc[:,col] = col + \"__\" + test_cat[col].astype(str)\n        isnan = ~test_cat.loc[:,col].isin(categories)\n        if np.sum(isnan) > 0:\n#             print(\"------\")\n#             print(\"test have unseen label : col\")\n            if not ((col + \"__nan\") in categories):\n#                 print(\"not nan in train : \", col)\n                test_cat.loc[isnan,col] = most_appear_each_categories[col]\n            else:\n#                 print(\"nan seen in train : \", col)\n                test_cat.loc[isnan,col] = col + \"__nan\"\n    for col in (test_cat.columns):\n        test_cat.loc[:, col] = le.transform(test_cat[col])\n\n    ### dense\n    test_dense = test[dense_features]\n    for col in (test_dense.columns):\n        test_dense.loc[:, col] = test_dense[col].fillna(medians[col])\n        test_dense.loc[:, col] = sss[col].transform(test_dense[col].values[:,None])\n\n    ### divide\n    test_dense_players = [test_dense[dense_player_features].iloc[np.arange(k, len(test), 22)].reset_index(drop = True) for k in range(22)]\n    test_dense_players = np.stack([t.values for t in test_dense_players]).transpose(1,0, 2)\n\n    test_dense_game = test_dense[dense_game_features].iloc[np.arange(0, len(test), 22)].reset_index(drop = True).values\n    test_dense_game = np.hstack([test_dense_game, test_dense[dense_player_features][test_dense[\"IsRusher\"] > 0]])\n    \n    test_cat_players = [test_cat[cat_player_features].iloc[np.arange(k, len(test), 22)].reset_index(drop = True) for k in range(22)]\n    test_cat_players = np.stack([t.values for t in test_cat_players]).transpose(1,0, 2)\n\n    test_cat_game = test_cat[cat_game_features].iloc[np.arange(0, len(test), 22)].reset_index(drop = True).values\n    test_cat_game = np.hstack([test_cat_game, test_cat[cat_player_features][test_dense[\"IsRusher\"] > 0]])\n\n    test_inp = [test_dense_game, test_dense_players, test_cat_game, test_cat_players]\n    \n    ## pred\n    pred = 0\n    for model in models:\n        _pred = model.predict(test_inp)[0]\n        _pred = np.cumsum(_pred, axis = 1)\n        pred += _pred\n    pred /= len(models)\n    pred = np.clip(pred, 0, 1)\n    env.predict(pd.DataFrame(data=pred,columns=sample.columns))\n    return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env = nflrush.make_env()\npreds = []\nfor test, sample in tqdm_notebook(env.iter_test()):\n    pred = make_pred(test, sample, env, models)\n    preds.append(pred)\nenv.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = np.vstack(preds)\n## check whether prediction is submittable\nprint(np.mean(np.diff(preds, axis = 1) >= 0) == 1.0)\nprint(np.mean(preds > 1) == 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(losses)\nprint(np.mean(losses))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}