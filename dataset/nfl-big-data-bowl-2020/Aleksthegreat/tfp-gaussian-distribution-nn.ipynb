{"cells":[{"metadata":{},"cell_type":"markdown","source":"Inspiration from these 2:\nhttps://www.kaggle.com/coolcoder22/nn-19-features\nhttps://www.kaggle.com/kenmatsu4/nn-outputs-gaussian-distribution-directly"},{"metadata":{},"cell_type":"markdown","source":"Mixed the kernals together and added a couple TFP layers to the model!"},{"metadata":{"trusted":true},"cell_type":"code","source":"#update gast to correct version\n#!pip install gast==0.2.2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For TFP to work, we need to use TensorFlow.Keras"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import math as m\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\nimport datetime\nfrom kaggle.competitions import nflrush\nimport tqdm\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n\nimport tensorflow as tf\nfrom tensorflow.python.keras.layers import Lambda\nimport tensorflow.keras as keras\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras import regularizers\n\nfrom tqdm import tqdm_notebook\nimport warnings\nwarnings.filterwarnings('ignore')\n\nsns.set_style('darkgrid')\nmpl.rcParams['figure.figsize'] = [15,10]\n\nimport matplotlib\nfrom matplotlib import font_manager\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nfrom matplotlib import rc\n\nfrom matplotlib import animation as ani\nfrom IPython.display import Image\n\nplt.rcParams[\"patch.force_edgecolor\"] = True\n#rc('text', usetex=True)\nfrom IPython.display import display # Allows the use of display() for DataFrames\nimport seaborn as sns\nsns.set(style=\"whitegrid\", palette=\"muted\", color_codes=True)\nsns.set_style(\"whitegrid\", {'grid.linestyle': '--'})\nred = sns.xkcd_rgb[\"light red\"]\ngreen = sns.xkcd_rgb[\"medium green\"]\nblue = sns.xkcd_rgb[\"denim blue\"]\n\n# pandas formatting\npd.set_option(\"display.max_colwidth\", 100)\npd.set_option(\"display.max_rows\", None)\npd.set_option(\"display.max_columns\", None)\npd.options.display.float_format = '{:,.5f}'.format\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature engineering"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def preprocess(train):\n    ## GameClock\n    train['GameClock_sec'] = train['GameClock'].apply(strtoseconds)\n    train[\"GameClock_minute\"] = train[\"GameClock\"].apply(lambda x : x.split(\":\")[0]).astype(\"object\")\n\n    ## Height\n    train['PlayerHeight_dense'] = train['PlayerHeight'].apply(lambda x: 12*int(x.split('-')[0])+int(x.split('-')[1]))\n\n    ## Time\n    train['TimeHandoff'] = train['TimeHandoff'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n    train['TimeSnap'] = train['TimeSnap'].apply(lambda x: datetime.datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S.%fZ\"))\n\n    train['TimeDelta'] = train.apply(lambda row: (row['TimeHandoff'] - row['TimeSnap']).total_seconds(), axis=1)\n    train['PlayerBirthDate'] = train['PlayerBirthDate'].apply(lambda x: datetime.datetime.strptime(x, \"%m/%d/%Y\"))\n\n    ## Age\n    seconds_in_year = 60*60*24*365.25\n    train['PlayerAge'] = train.apply(lambda row: (row['TimeHandoff']-row['PlayerBirthDate']).total_seconds()/seconds_in_year, axis=1)\n    train[\"PlayerAge_ob\"] = train['PlayerAge'].astype(np.int).astype(\"object\")\n\n    ## WindSpeed\n    train['WindSpeed_ob'] = train['WindSpeed'].apply(lambda x: x.lower().replace('mph', '').strip() if not pd.isna(x) else x)\n    train['WindSpeed_ob'] = train['WindSpeed_ob'].apply(lambda x: (int(x.split('-')[0])+int(x.split('-')[1]))/2 if not pd.isna(x) and '-' in x else x)\n    train['WindSpeed_ob'] = train['WindSpeed_ob'].apply(lambda x: (int(x.split()[0])+int(x.split()[-1]))/2 if not pd.isna(x) and type(x)!=float and 'gusts up to' in x else x)\n    train['WindSpeed_dense'] = train['WindSpeed_ob'].apply(strtofloat)\n\n    ## Weather\n    train['GameWeather_process'] = train['GameWeather'].str.lower()\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: \"indoor\" if not pd.isna(x) and \"indoor\" in x else x)\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('coudy', 'cloudy').replace('clouidy', 'cloudy').replace('party', 'partly') if not pd.isna(x) else x)\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('clear and sunny', 'sunny and clear') if not pd.isna(x) else x)\n    train['GameWeather_process'] = train['GameWeather_process'].apply(lambda x: x.replace('skies', '').replace(\"mostly\", \"\").strip() if not pd.isna(x) else x)\n    train['GameWeather_dense'] = train['GameWeather_process'].apply(map_weather)\n\n    ## Rusher\n    train['IsRusher'] = (train['NflId'] == train['NflIdRusher'])\n    train['IsRusher_ob'] = (train['NflId'] == train['NflIdRusher']).astype(\"object\")\n    temp = train[train[\"IsRusher\"]][[\"Team\", \"PlayId\"]].rename(columns={\"Team\":\"RusherTeam\"})\n    train = train.merge(temp, on = \"PlayId\")\n    train[\"IsRusherTeam\"] = train[\"Team\"] == train[\"RusherTeam\"]\n\n    ## dense -> categorical\n    train[\"Quarter_ob\"] = train[\"Quarter\"].astype(\"object\")\n    train[\"Down_ob\"] = train[\"Down\"].astype(\"object\")\n    train[\"JerseyNumber_ob\"] = train[\"JerseyNumber\"].astype(\"object\")\n    train[\"YardLine_ob\"] = train[\"YardLine\"].astype(\"object\")\n    # train[\"DefendersInTheBox_ob\"] = train[\"DefendersInTheBox\"].astype(\"object\")\n    # train[\"Week_ob\"] = train[\"Week\"].astype(\"object\")\n    # train[\"TimeDelta_ob\"] = train[\"TimeDelta\"].astype(\"object\")\n\n    ## diff Score\n    train[\"diffScoreBeforePlay\"] = train[\"HomeScoreBeforePlay\"] - train[\"VisitorScoreBeforePlay\"]\n    train[\"diffScoreBeforePlay_binary_ob\"] = (train[\"HomeScoreBeforePlay\"] > train[\"VisitorScoreBeforePlay\"]).astype(\"object\")\n\n    ## Turf\n    Turf = {'Field Turf':'Artificial', 'A-Turf Titan':'Artificial', 'Grass':'Natural', 'UBU Sports Speed S5-M':'Artificial', 'Artificial':'Artificial', 'DD GrassMaster':'Artificial', 'Natural Grass':'Natural', 'UBU Speed Series-S5-M':'Artificial', 'FieldTurf':'Artificial', 'FieldTurf 360':'Artificial', 'Natural grass':'Natural', 'grass':'Natural', 'Natural':'Natural', 'Artifical':'Artificial', 'FieldTurf360':'Artificial', 'Naturall Grass':'Natural', 'Field turf':'Artificial', 'SISGrass':'Artificial', 'Twenty-Four/Seven Turf':'Artificial', 'natural grass':'Natural'} \n    train['Turf'] = train['Turf'].map(Turf)\n\n    ## sort\n#     train = train.sort_values(by = ['X']).sort_values(by = ['Dis']).sort_values(by=['PlayId', 'Team', 'IsRusher']).reset_index(drop = True)\n    train = train.sort_values(by = ['X']).sort_values(by = ['Dis']).sort_values(by=['PlayId', 'IsRusherTeam', 'IsRusher']).reset_index(drop = True)\n    return train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_features(df, deploy=False):\n    def new_X(x_coordinate, play_direction):\n        if play_direction == 'left':\n            return 120.0 - x_coordinate\n        else:\n            return x_coordinate\n\n    def new_line(rush_team, field_position, yardline):\n        if rush_team == field_position:\n            # offense starting at X = 0 plus the 10 yard endzone plus the line of scrimmage\n            return 10.0 + yardline\n        else:\n            # half the field plus the yards between midfield and the line of scrimmage\n            return 60.0 + (50 - yardline)\n\n    def new_orientation(angle, play_direction):\n        if play_direction == 'left':\n            new_angle = 360.0 - angle\n            if new_angle == 360.0:\n                new_angle = 0.0\n            return new_angle\n        else:\n            return angle\n\n    def euclidean_distance(x1,y1,x2,y2):\n        x_diff = (x1-x2)**2\n        y_diff = (y1-y2)**2\n\n        return np.sqrt(x_diff + y_diff)\n\n    def back_direction(orientation):\n        if orientation > 180.0:\n            return 1\n        else:\n            return 0\n\n    def update_yardline(df):\n        new_yardline = df[df['NflId'] == df['NflIdRusher']]\n        new_yardline['YardLine'] = new_yardline[['PossessionTeam','FieldPosition','YardLine']].apply(lambda x: new_line(x[0],x[1],x[2]), axis=1)\n        new_yardline = new_yardline[['GameId','PlayId','YardLine']]\n\n        return new_yardline\n\n    def update_orientation(df, yardline):\n        df['X'] = df[['X','PlayDirection']].apply(lambda x: new_X(x[0],x[1]), axis=1)\n        df['Orientation'] = df[['Orientation','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n        df['Dir'] = df[['Dir','PlayDirection']].apply(lambda x: new_orientation(x[0],x[1]), axis=1)\n\n        df = df.drop('YardLine', axis=1)\n        df = pd.merge(df, yardline, on=['GameId','PlayId'], how='inner')\n\n        return df\n\n    def back_features(df):\n        carriers = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','NflIdRusher','X','Y','Orientation','Dir','YardLine']]\n        carriers['back_from_scrimmage'] = carriers['YardLine'] - carriers['X']\n        carriers['back_oriented_down_field'] = carriers['Orientation'].apply(lambda x: back_direction(x))\n        carriers['back_moving_down_field'] = carriers['Dir'].apply(lambda x: back_direction(x))\n        carriers = carriers.rename(columns={'X':'back_X',\n                                            'Y':'back_Y'})\n        carriers = carriers[['GameId','PlayId','NflIdRusher','back_X','back_Y','back_from_scrimmage','back_oriented_down_field','back_moving_down_field']]\n\n        return carriers\n\n    def features_relative_to_back(df, carriers):\n        player_distance = df[['GameId','PlayId','NflId','X','Y']]\n        player_distance = pd.merge(player_distance, carriers, on=['GameId','PlayId'], how='inner')\n        player_distance = player_distance[player_distance['NflId'] != player_distance['NflIdRusher']]\n        player_distance['dist_to_back'] = player_distance[['X','Y','back_X','back_Y']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n\n        player_distance = player_distance.groupby(['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field'])\\\n                                         .agg({'dist_to_back':['min','max','mean','std']})\\\n                                         .reset_index()\n        player_distance.columns = ['GameId','PlayId','back_from_scrimmage','back_oriented_down_field','back_moving_down_field',\n                                   'min_dist','max_dist','mean_dist','std_dist']\n\n        return player_distance\n\n    def defense_features(df):\n        rusher = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','Team','X','Y']]\n        rusher.columns = ['GameId','PlayId','RusherTeam','RusherX','RusherY']\n\n        defense = pd.merge(df,rusher,on=['GameId','PlayId'],how='inner')\n        defense = defense[defense['Team'] != defense['RusherTeam']][['GameId','PlayId','X','Y','RusherX','RusherY']]\n        defense['def_dist_to_back'] = defense[['X','Y','RusherX','RusherY']].apply(lambda x: euclidean_distance(x[0],x[1],x[2],x[3]), axis=1)\n\n        defense = defense.groupby(['GameId','PlayId'])\\\n                         .agg({'def_dist_to_back':['min','max','mean','std']})\\\n                         .reset_index()\n        defense.columns = ['GameId','PlayId','def_min_dist','def_max_dist','def_mean_dist','def_std_dist']\n\n        return defense\n\n    def static_features(df):\n        static_features = df[df['NflId'] == df['NflIdRusher']][['GameId','PlayId','X','Y','S','A','Dis','Orientation','Dir',\n                                                            'YardLine','Quarter','Down','Distance','DefendersInTheBox']].drop_duplicates()\n        static_features['DefendersInTheBox'] = static_features['DefendersInTheBox'].fillna(np.mean(static_features['DefendersInTheBox']))\n\n        return static_features\n    \n    def split_personnel(s):\n        splits = s.split(',')\n        for i in range(len(splits)):\n            splits[i] = splits[i].strip()\n\n        return splits\n\n    def defense_formation(l):\n        dl = 0\n        lb = 0\n        db = 0\n        other = 0\n\n        for position in l:\n            sub_string = position.split(' ')\n            if sub_string[1] == 'DL':\n                dl += int(sub_string[0])\n            elif sub_string[1] in ['LB','OL']:\n                lb += int(sub_string[0])\n            else:\n                db += int(sub_string[0])\n\n        counts = (dl,lb,db,other)\n\n        return counts\n\n    def offense_formation(l):\n        qb = 0\n        rb = 0\n        wr = 0\n        te = 0\n        ol = 0\n\n        sub_total = 0\n        qb_listed = False\n        for position in l:\n            sub_string = position.split(' ')\n            pos = sub_string[1]\n            cnt = int(sub_string[0])\n\n            if pos == 'QB':\n                qb += cnt\n                sub_total += cnt\n                qb_listed = True\n            # Assuming LB is a line backer lined up as full back\n            elif pos in ['RB','LB']:\n                rb += cnt\n                sub_total += cnt\n            # Assuming DB is a defensive back and lined up as WR\n            elif pos in ['WR','DB']:\n                wr += cnt\n                sub_total += cnt\n            elif pos == 'TE':\n                te += cnt\n                sub_total += cnt\n            # Assuming DL is a defensive lineman lined up as an additional line man\n            else:\n                ol += cnt\n                sub_total += cnt\n\n        # If not all 11 players were noted at given positions we need to make some assumptions\n        # I will assume if a QB is not listed then there was 1 QB on the play\n        # If a QB is listed then I'm going to assume the rest of the positions are at OL\n        # This might be flawed but it looks like RB, TE and WR are always listed in the personnel\n        if sub_total < 11:\n            diff = 11 - sub_total\n            if not qb_listed:\n                qb += 1\n                diff -= 1\n            ol += diff\n\n        counts = (qb,rb,wr,te,ol)\n\n        return counts\n    \n    def personnel_features(df):\n        personnel = df[['GameId','PlayId','OffensePersonnel','DefensePersonnel']].drop_duplicates()\n        personnel['DefensePersonnel'] = personnel['DefensePersonnel'].apply(lambda x: split_personnel(x))\n        personnel['DefensePersonnel'] = personnel['DefensePersonnel'].apply(lambda x: defense_formation(x))\n        personnel['num_DL'] = personnel['DefensePersonnel'].apply(lambda x: x[0])\n        personnel['num_LB'] = personnel['DefensePersonnel'].apply(lambda x: x[1])\n        personnel['num_DB'] = personnel['DefensePersonnel'].apply(lambda x: x[2])\n\n        personnel['OffensePersonnel'] = personnel['OffensePersonnel'].apply(lambda x: split_personnel(x))\n        personnel['OffensePersonnel'] = personnel['OffensePersonnel'].apply(lambda x: offense_formation(x))\n        personnel['num_QB'] = personnel['OffensePersonnel'].apply(lambda x: x[0])\n        personnel['num_RB'] = personnel['OffensePersonnel'].apply(lambda x: x[1])\n        personnel['num_WR'] = personnel['OffensePersonnel'].apply(lambda x: x[2])\n        personnel['num_TE'] = personnel['OffensePersonnel'].apply(lambda x: x[3])\n        personnel['num_OL'] = personnel['OffensePersonnel'].apply(lambda x: x[4])\n\n        # Let's create some features to specify if the OL is covered\n        personnel['OL_diff'] = personnel['num_OL'] - personnel['num_DL']\n        personnel['OL_TE_diff'] = (personnel['num_OL'] + personnel['num_TE']) - personnel['num_DL']\n        # Let's create a feature to specify if the defense is preventing the run\n        # Let's just assume 7 or more DL and LB is run prevention\n        personnel['run_def'] = (personnel['num_DL'] + personnel['num_LB'] > 6).astype(int)\n\n        personnel.drop(['OffensePersonnel','DefensePersonnel'], axis=1, inplace=True)\n        \n        return personnel\n    \n    def process_two(t_):\n        t_['fe1'] = pd.Series(np.sqrt(np.absolute(np.square(t_.X.values) - np.square(t_.Y.values))))\n        t_['fe5'] = np.square(t_['S'].values) + 2 * t_['A'].values * t_['Dis'].values  # N\n        t_['fe7'] = np.arccos(np.clip(t_['X'].values / t_['Y'].values, -1, 1))  # N\n        t_['fe8'] = t_['S'].values / np.clip(t_['fe1'].values, 0.6, None)\n        radian_angle = (90 - t_['Dir']) * np.pi / 180.0\n        t_['fe10'] = np.abs(t_['S'] * np.cos(radian_angle))\n        t_['fe11'] = np.abs(t_['S'] * np.sin(radian_angle))\n        return t_\n\n    def combine_features(relative_to_back, defense, static, personnel, deploy=deploy):\n        df = pd.merge(relative_to_back,defense,on=['GameId','PlayId'],how='inner')\n        df = pd.merge(df,static,on=['GameId','PlayId'],how='inner')\n        df = pd.merge(df,personnel,on=['GameId','PlayId'],how='inner')\n\n        if not deploy:\n            df = pd.merge(df, outcomes, on=['GameId','PlayId'], how='inner')\n\n        return df\n    \n    df.loc[df['Season'] == 2017, 'S'] = (df['S'][df['Season'] == 2017] - 2.4355) / 1.2930 * 1.4551 + 2.7570\n    yardline = update_yardline(df)\n    df = update_orientation(df, yardline)\n    back_feats = back_features(df)\n    rel_back = features_relative_to_back(df, back_feats)\n    def_feats = defense_features(df)\n    static_feats = static_features(df)\n    personnel = personnel_features(df)\n    basetable = combine_features(rel_back, def_feats, static_feats, personnel, deploy=deploy)\n    basetable = process_two(basetable)\n    basetable = basetable.drop(['X','Y','S','A','Dis','Orientation','Dir','Yards','YardLine',\n           'Quarter','Down','Distance','DefendersInTheBox'], axis=1)\n    \n    return basetable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#https://www.kaggle.com/rooshroosh/fork-of-neural-networks-different-architecture\ndef strtoseconds(txt):\n    txt = txt.split(':')\n    ans = int(txt[0])*60 + int(txt[1]) + int(txt[2])/60\n    return ans\n\ndef strtofloat(x):\n    try:\n        return float(x)\n    except:\n        return -1\n\ndef map_weather(txt):\n    ans = 1\n    if pd.isna(txt):\n        return 0\n    if 'partly' in txt:\n        ans*=0.5\n    if 'climate controlled' in txt or 'indoor' in txt:\n        return ans*3\n    if 'sunny' in txt or 'sun' in txt:\n        return ans*2\n    if 'clear' in txt:\n        return ans\n    if 'cloudy' in txt:\n        return -ans\n    if 'rain' in txt or 'rainy' in txt:\n        return -2*ans\n    if 'snow' in txt:\n        return -3*ans\n    return 0\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"%%time\ndf = pd.read_csv('../input/nfl-big-data-bowl-2020/train.csv', dtype={'WindSpeed': 'object'})\noutcomes = df[['GameId','PlayId','Yards']].drop_duplicates()\n\ntrain_gametable = preprocess(df)\ntrain_basetable = create_features(df, False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"join_by = ['GameId','PlayId']\ntrain = pd.merge(train_gametable, train_basetable, on=(join_by), how='left')\nprint(train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"## DisplayName remove Outlier\nv = train[\"DisplayName\"].value_counts()\nmissing_values = list(v[v < 5].index)\ntrain[\"DisplayName\"] = train[\"DisplayName\"].where(~train[\"DisplayName\"].isin(missing_values), \"nan\")\n\n## PlayerCollegeName remove Outlier\nv = train[\"PlayerCollegeName\"].value_counts()\nmissing_values = list(v[v < 10].index)\ntrain[\"PlayerCollegeName\"] = train[\"PlayerCollegeName\"].where(~train[\"PlayerCollegeName\"].isin(missing_values), \"nan\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#join_by = ['DisplayName','Team','Quarter_ob']\n#agg_history = train.groupby(join_by, as_index=False)['Yards'].agg('mean')\n#agg_history.reset_index(inplace=True, drop=True)\n#agg_history.columns = ['avg_' + c if c == 'Yards' else c for c in agg_history.columns.values]\n#agg_history = agg_history.replace(np.nan, 0)\n\n#agg_history.reset_index(inplace=True, drop=True)\n#agg_history.columns = ['avg_' + c if c == 'Yards' else c for c in agg_history.columns.values]\n#agg_history = agg_history.replace(np.nan, 0)\n\n#train = pd.merge(train, agg_history, on=(join_by), how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def drop(df):\n    drop_cols = [\"GameId\", \"GameWeather\", \"NflId\", \"Season\", \"NflIdRusher\",'JerseyNumber'] \n    drop_cols += ['TimeHandoff', 'TimeSnap', 'PlayerBirthDate','PlayerHeight','diffScoreBeforePlay_binary_ob']\n    drop_cols += ['Team','DisplayName','GameClock','PossessionTeam']\n    drop_cols += ['PlayerCollegeName','Position','HomeTeamAbbr','FieldPosition']\n    drop_cols += ['VisitorTeamAbbr','Stadium','Location','StadiumType','JerseyNumber_ob']\n    drop_cols += ['PlayId','Yards','RusherTeam','YardLine_ob','WindSpeed','GameClock_minute']\n\n    df = df.drop(drop_cols, axis = 1)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train = drop(train)\npd.to_pickle(train, \"train.pkl\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"cat_features = []\ndense_features = []\nfor col in train.columns:\n    if train[col].dtype =='object':\n        cat_features.append(col)\n        print(\"*cat*\", col, len(train[col].unique()))\n    else:\n        dense_features.append(col)\n        print(\"!dense!\", col, len(train[col].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## categorical"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train_cat = train[cat_features]\ncategories = []\nmost_appear_each_categories = {}\nfor col in tqdm_notebook(train_cat.columns):\n    print(col)\n    train_cat.loc[:,col] = train_cat[col].fillna(\"nan\")\n    train_cat.loc[:,col] = col + \"__\" + train_cat[col].astype(str)\n    most_appear_each_categories[col] = list(train_cat[col].value_counts().index)[0]\n    categories.append(train_cat[col].unique())\ncategories = np.hstack(categories)\nprint(len(categories))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"le = LabelEncoder()\nle.fit(categories)\nfor col in tqdm_notebook(train_cat.columns):\n    train_cat.loc[:, col] = le.transform(train_cat[col])\nnum_classes = len(le.classes_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dense"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train_dense = train[dense_features]\nsss = {}\nmedians = {}\nfor col in tqdm_notebook(train_dense.columns):\n    print(col)\n    medians[col] = np.nanmedian(train_dense[col])\n    train_dense.loc[:, col] = train_dense[col].fillna(medians[col])\n    ss = StandardScaler()\n    train_dense.loc[:, col] = ss.fit_transform(train_dense[col].values[:,None])\n    sss[col] = ss","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Divide features into groups"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"## dense features for play\ndense_game_features = train_dense.columns[train_dense[:22].std() == 0]\n## dense features for each player\ndense_player_features = train_dense.columns[train_dense[:22].std() != 0]\n## categorical features for play\ncat_game_features = train_cat.columns[train_cat[:22].std() == 0]\n## categorical features for each player\ncat_player_features = train_cat.columns[train_cat[:22].std() != 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train_dense_game = train_dense[dense_game_features].iloc[np.arange(0, len(train), 22)].reset_index(drop = True).values\ntrain_dense_game = np.hstack([train_dense_game, train_dense[dense_player_features][train_dense[\"IsRusher\"] > 0]]) ## with rusher player feature\n\ntrain_dense_players = [train_dense[dense_player_features].iloc[np.arange(k, len(train), 22)].reset_index(drop = True) for k in range(22)]\ntrain_dense_players = np.stack([t.values for t in train_dense_players]).transpose(1, 0, 2)\n\ntrain_cat_game = train_cat[cat_game_features].iloc[np.arange(0, len(train), 22)].reset_index(drop = True).values\ntrain_cat_game = np.hstack([train_cat_game, train_cat[cat_player_features][train_dense[\"IsRusher\"] > 0]]) ## with rusher player feature\n\ntrain_cat_players = [train_cat[cat_player_features].iloc[np.arange(k, len(train), 22)].reset_index(drop = True) for k in range(22)]\ntrain_cat_players = np.stack([t.values for t in train_cat_players]).transpose(1, 0, 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def return_step(x):\n    temp = np.zeros(199)\n    temp[x + 99:] = 1\n    return temp\n\n#train_y_raw = train[\"Yards\"].iloc[np.arange(0, len(train), 22)].reset_index(drop = True)\ntrain_y_raw = outcomes['Yards']\ntrain_y = np.vstack(outcomes['Yards'].apply(return_step).values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dense_game.shape, train_dense_players.shape, train_cat_game.shape, train_cat_players.shape, train_y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import Callback\nclass CRPSCallback(Callback):\n    \n    def __init__(self,validation, predict_batch_size=20, include_on_batch=False):\n        super(CRPSCallback, self).__init__()\n        self.validation = validation\n        self.predict_batch_size = predict_batch_size\n        self.include_on_batch = include_on_batch\n        \n        print('validation shape',len(self.validation))\n\n    def on_batch_begin(self, batch, logs={}):\n        pass\n\n    def on_train_begin(self, logs={}):\n        if not ('CRPS_score_val' in self.params['metrics']):\n            self.params['metrics'].append('CRPS_score_val')\n\n    def on_batch_end(self, batch, logs={}):\n        if (self.include_on_batch):\n            logs['CRPS_score_val'] = float('-inf')\n\n    def on_epoch_end(self, epoch, logs={}):\n        logs['CRPS_score_val'] = float('-inf')\n            \n        if (self.validation):\n            X_valid, y_valid = self.validation[0], self.validation[1]\n            y_pred = self.model.predict(X_valid)\n            y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n            y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n            val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * pd.DataFrame(X_valid).shape[0])\n            val_s = np.round(val_s, 6)\n            logs['CRPS_score_val'] = val_s\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def crps(y_true, y_pred):\n    loss = K.mean((y_pred - y_true)**2)\n    return loss\n\n# get the newest model file within a directory\ndef getNewestModel(model, dirname):\n    from glob import glob\n    target = os.path.join(dirname, '*')\n    files = [(f, os.path.getmtime(f)) for f in glob(target)]\n    if len(files) == 0:\n        return model\n    else:\n        newestModel = sorted(files, key=lambda files: files[1])[-1]\n        model.load_weights(newestModel[0])\n        return model\n    \ndef l1_reg(weight_matrix):\n    return 0.01 * K.sum(K.abs(weight_matrix))\n\ndef posterior_mean_field(kernel_size, bias_size=0, dtype=None):\n      n = kernel_size + bias_size\n      c = np.log(np.expm1(1.))\n      return tf.keras.Sequential([\n          tfp.layers.VariableLayer(2 * n, dtype=dtype),\n          tfp.layers.DistributionLambda(lambda t: tfd.Independent(  # pylint: disable=g-long-lambda\n              tfd.Normal(loc=t[..., :n],\n                         scale=1e-5 + tf.nn.softplus(c + t[..., n:])),\n              reinterpreted_batch_ndims=1)),])\n\ndef prior_trainable(kernel_size, bias_size=0, dtype=None):\n      n = kernel_size + bias_size\n      return tf.keras.Sequential([\n          tfp.layers.VariableLayer(n, dtype=dtype),\n          tfp.layers.DistributionLambda(\n              lambda t: tfd.Independent(tfd.Normal(loc=t, scale=1),  # pylint: disable=g-long-lambda\n                                        reinterpreted_batch_ndims=1)),])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Metric(Callback):\n    def __init__(self, model, callbacks, data):\n        super().__init__()\n        self.model = model\n        self.callbacks = callbacks\n        self.data = data\n\n    def on_train_begin(self, logs=None):\n        for callback in self.callbacks:\n            callback.on_train_begin(logs)\n\n    def on_train_end(self, logs=None):\n        for callback in self.callbacks:\n            callback.on_train_end(logs)\n\n    def on_epoch_end(self, batch, logs=None):\n        X_train, y_train = self.data[0][0], self.data[0][1]\n        y_pred = self.model.predict(X_train)\n        y_true = np.clip(np.cumsum(y_train, axis=1), 0, 1)\n        y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n        tr_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * X_train[-1].shape[0])\n        tr_s = np.round(tr_s, 6)\n        logs['tr_CRPS'] = tr_s\n\n        X_valid, y_valid = self.data[1][0], self.data[1][1]\n\n        y_pred = self.model.predict(X_valid)\n        y_true = np.clip(np.cumsum(y_valid, axis=1), 0, 1)\n        y_pred = np.clip(np.cumsum(y_pred, axis=1), 0, 1)\n        val_s = ((y_true - y_pred) ** 2).sum(axis=1).sum(axis=0) / (199 * X_valid[-1].shape[0])\n        val_s = np.round(val_s, 6)\n        logs['val_CRPS'] = val_s\n        print('tr CRPS', tr_s, 'val CRPS', val_s)\n\n        for callback in self.callbacks:\n            callback.on_epoch_end(batch, logs)\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model(batch_size = 32, epochs = 10):\n    keras.backend.clear_session()\n    \n    ## inputs\n    input_dense_game = keras.layers.Input(shape=(train_dense_game.shape[1],), name = \"numerical_general_inputs\")\n    input_dense_players = keras.layers.Input(shape=(train_dense_players.shape[1],train_dense_players.shape[2]), name = \"numerical_players_inputs\")\n    input_cat_game = keras.layers.Input(shape=(train_cat_game.shape[1], ), name = \"categorical_general_inputs\")\n    input_cat_players = keras.layers.Input(shape=(train_cat_players.shape[1], train_cat_players.shape[2]), name = \"categorical_players_input\")\n    \n    ## embedding\n    embedding = keras.layers.Embedding(num_classes, 4, embeddings_regularizer=regularizers.l2(1e-4))\n    emb_cat_game = embedding(input_cat_game)\n    emb_cat_game = keras.layers.Flatten()(emb_cat_game)\n    emb_cat_players = embedding(input_cat_players)\n    emb_cat_players = keras.layers.Reshape((int(emb_cat_players.shape[1]), int(emb_cat_players.shape[2]) * int(emb_cat_players.shape[3])))(emb_cat_players)\n    \n    ## general game features\n    game = keras.layers.Concatenate(name = \"general_features\")([input_dense_game, emb_cat_game])\n    game = keras.layers.Dense(1024, activation=\"relu\")(game)\n    game = keras.layers.Dropout(0.5)(game)\n    \n    ## players features\n    players = keras.layers.Concatenate(name = \"players_features\")([input_dense_players, emb_cat_players])\n    n_unit = 256\n    players_aves = []\n    for k in range(3):\n        players = keras.layers.Dense(n_unit, activation=\"relu\")(players)\n        players_aves.append(keras.layers.GlobalAveragePooling1D()(players))\n    players = keras.layers.Concatenate(name = \"deep_players_features\")(players_aves)\n\n    ### concat all\n    x_concat = keras.layers.Concatenate(name = \"general_and_players\")([game, players])\n    x_concats = []\n    n_unit = 128\n    decay_rate = 0.5\n    for k in range(3):\n        x_concat = keras.layers.Dense(n_unit, activation=\"relu\")(x_concat)\n        x_concats.append(x_concat)\n        n_unit = int(n_unit * decay_rate)\n    x_concat = keras.layers.Concatenate(name = \"deep_features\")(x_concats)\n    x_concat = keras.layers.Dropout(0.5)(x_concat)\n\n    out_soft = keras.layers.Dense(199, activation=\"softmax\", name = \"out_soft\")(x_concat)\n    model = keras.models.Model(inputs = [input_dense_game, input_dense_players, input_cat_game, input_cat_players],\n                               outputs = out_soft)\n    ## compile\n    model.compile(optimizer=keras.optimizers.Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999), loss=crps, metrics=[])\n\n    ## train\n    tr_x = [train_dense_game[tr_inds], train_dense_players[tr_inds], train_cat_game[tr_inds], train_cat_players[tr_inds]]\n    tr_y = train_y[tr_inds]\n    val_x = [train_dense_game[val_inds], train_dense_players[val_inds], train_cat_game[val_inds], train_cat_players[val_inds]]\n    val_y = train_y[val_inds]\n    \n    es = EarlyStopping(monitor='val_CRPS', \n                   mode='min',\n                   restore_best_weights=True, \n                   verbose=1, \n                   patience=15)\n\n    es.set_model(model)\n    metric = Metric(model, [es], [(tr_x,tr_y), (val_x, val_y)])\n    model.fit(tr_x,\n              tr_y,\n              batch_size=32,\n              callbacks=[metric],\n              epochs=epochs,\n              verbose=1)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, KFold\ntf.keras.backend.clear_session()\nimport tensorflow_probability as tfp\ntfd = tfp.distributions\nfrom tensorflow.keras.layers import Concatenate, Layer\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n\nlosses = []\nmodels = []\nfor k in range(2):\n    kfold = KFold(5, random_state = 420 + k, shuffle = True)\n    for k_fold, (tr_inds, val_inds) in enumerate(kfold.split(train_y)):\n        print(\"-----------\")\n        print(\"-----------\")\n        model, loss = get_model(1024, 200)\n        models.append(model)\n        print(k_fold, loss)\n        losses.append(loss)\nprint(\"-------\")\nprint(losses)\nprint(np.mean(losses))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\nplot_model(model, to_file='model.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(losses)\nprint(np.mean(losses))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_pred(test, sample, env, model):    \n    test_gametable = preprocess(test)\n    test_basetable = create_features(test, False)\n\n    test = pd.merge(test_gametable, test_basetable, on=(join_by), how='left')\n    #test = pd.merge(test, agg_history, on=join_by, how='left')\n    test = drop(test)\n\n    ### categorical\n    test_cat = test[cat_features]\n    for col in (test_cat.columns):\n        test_cat.loc[:,col] = test_cat[col].fillna(\"nan\")\n        test_cat.loc[:,col] = col + \"__\" + test_cat[col].astype(str)\n        isnan = ~test_cat.loc[:,col].isin(categories)\n        if np.sum(isnan) > 0:\n#             print(\"------\")\n#             print(\"test have unseen label : col\")\n            if not ((col + \"__nan\") in categories):\n#                 print(\"not nan in train : \", col)\n                test_cat.loc[isnan,col] = most_appear_each_categories[col]\n            else:\n#                 print(\"nan seen in train : \", col)\n                test_cat.loc[isnan,col] = col + \"__nan\"\n    for col in (test_cat.columns):\n        test_cat.loc[:, col] = le.transform(test_cat[col])\n\n    ### dense\n    test_dense = test[dense_features]\n    for col in (test_dense.columns):\n        test_dense.loc[:, col] = test_dense[col].fillna(medians[col])\n        test_dense.loc[:, col] = sss[col].transform(test_dense[col].values[:,None])\n\n    ### divide\n    test_dense_players = [test_dense[dense_player_features].iloc[np.arange(k, len(test), 22)].reset_index(drop = True) for k in range(22)]\n    test_dense_players = np.stack([t.values for t in test_dense_players]).transpose(1,0, 2)\n\n    test_dense_game = test_dense[dense_game_features].iloc[np.arange(0, len(test), 22)].reset_index(drop = True).values\n    test_dense_game = np.hstack([test_dense_game, test_dense[dense_player_features][test_dense[\"IsRusher\"] > 0]])\n    \n    test_cat_players = [test_cat[cat_player_features].iloc[np.arange(k, len(test), 22)].reset_index(drop = True) for k in range(22)]\n    test_cat_players = np.stack([t.values for t in test_cat_players]).transpose(1,0, 2)\n\n    test_cat_game = test_cat[cat_game_features].iloc[np.arange(0, len(test), 22)].reset_index(drop = True).values\n    test_cat_game = np.hstack([test_cat_game, test_cat[cat_player_features][test_dense[\"IsRusher\"] > 0]])\n\n    test_inp = [test_dense_game, test_dense_players, test_cat_game, test_cat_players]\n    \n    ## pred\n    pred = 0\n    for model in models:\n        _pred = model.predict(test_inp)\n        #_pred = np.cumsum(_pred, axis = 1)\n        pred += _pred\n    pred /= len(models)\n    pred = np.clip(pred, 0, 1)\n    #pred = np.where(pred > 0.93,1,pred)\n    env.predict(pd.DataFrame(data=pred,columns=sample.columns))\n    return pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"env = nflrush.make_env()\npreds = []\nfor test, sample in tqdm_notebook(env.iter_test()):\n    pred = make_pred(test, sample, env, models)\n    preds.append(pred)\nenv.write_submission_file()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = np.vstack(preds)\n## check whether prediction is submittable\nprint(np.mean(np.diff(preds, axis = 1) >= 0) == 1.0)\nprint(np.mean(preds > 1) == 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(losses)\nprint(np.mean(losses))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}