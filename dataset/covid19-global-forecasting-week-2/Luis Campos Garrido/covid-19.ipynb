{"cells":[{"metadata":{},"cell_type":"markdown","source":"# COVID-19 Forecasting Competition\n\nIn the context of the global COVID-19 pandemic, Kaggle has launched several challenges in order to provide useful insights that may answer some of the open scientific questions about the virus. This is the case of the [COVID19 Global Forecasting](https://www.kaggle.com/c/covid19-global-forecasting-week-1), in which participants are encouraged to fit worldwide data in order to predict the pandemic evolution, hopefully helping to determine which factors impact the transmission behavior of COVID-19.\n\n**TABLE OF CONTENTS**\n\n1. [Exploratory data analysis (EDA)](#section1)\n\n   \n2. [Data enrichment](#section2)\n\n    2.1. [Join data, filter dates and clean missings](#section21)\n    \n    2.2. [Compute lags and trends](#section22)\n    \n    2.3. [Add country details](#section23)\n    \n    \n3. [Predictions with machine learning](#section3)\n\n    3.1. [Linear Regression for one country](#section31)\n    \n    3.2. [Logistic Regression for all countries (method 1)](#section32)\n    \n    3.3. [Logistic Regression for all countries (method 2)](#section33)\n    \n    3.4. [Logistic regression with lags](#section34)\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing\nimport time\nfrom datetime import datetime\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ML libraries\nimport lightgbm as lgb\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Exploratory data analysis (EDA) <a id=\"section1\"></a>\n\nFirst of all, let's take a look on the data structure:"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"submission_example = pd.read_csv(\"../input/covid19-global-forecasting-week-2/submission.csv\")\ntest = pd.read_csv(\"../input/covid19-global-forecasting-week-2/test.csv\")\ntrain = pd.read_csv(\"../input/covid19-global-forecasting-week-2/train.csv\")\nfor data in [train, test]:\n    data.rename(\n        columns={\n            \"Id\": \"id\",\n            \"ForecastId\": \"forecast_id\",\n            \"Date\": \"date\",\n            \"Country_Region\": \"country\",\n            \"Province_State\": \"city\",\n            \"ConfirmedCases\": \"positives\",\n            \"Fatalities\": \"deaths\"},\n        inplace=True\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(train.head(5))\ndisplay(test.head(5))\ndisplay(train.describe())\nprint(\"Number of countries: \", train['country'].nunique())\nprint(\"Dates go from day\", min(train['date']), \"to day\", max(train['date']), \", a total of\", train['date'].nunique(), \"days\")\nprint(\"Countries with area information: \", train[~train['city'].isna()]['country'].unique())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The dataset covers 163 countries and almost 2 full months from 2020, which is enough data to get some clues about the pandemic. Let's see a few plots of the worldwide tendency to see if we can extract some insights:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Total by date\ntotal_by_date = train.groupby(\"date\").sum().drop(\"id\", axis=1)\ntotal_by_date.plot()\n\n# Total by date and country\ntotal_by_date_country = train.groupby([\"date\", \"country\"]).sum().drop(\"id\", axis=1)\n#total_by_date_country.plot()\n\n\n# Maximun by country\nmax_by_country = total_by_date_country.groupby(\"country\").max().sort_values(by=\"positives\", ascending=False)\nn_countries = 10\ntop_countries = max_by_country.index[:n_countries].to_list()\nmax_by_country.head(n_countries).plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As a fraction of the total population of each country:"},{"metadata":{},"cell_type":"markdown","source":"In order to compare the 4 countries, it's also interesting to see the evolution of the infections from the first confirmed case:"},{"metadata":{},"cell_type":"markdown","source":"# 2. Data enrichment <a id=\"section2\"></a>\n\n1. Join data, filter dates and clean missings\n2. Compute lags and trends\n3. Add country details\n"},{"metadata":{},"cell_type":"markdown","source":"## 2.1. Join data, filter dates and clean missings <a id=\"section31\"></a>\n\nFirst of all, we perform some pre-processing prepare the dataset, consisting on:\n\n* **Join data**. Join train/test to facilitate data transformations\n* **Filter dates**. According to the challenge conditions, remove ConfirmedCases and Fatalities post 2020-03-12. Create additional date columns\n* **Missings**. Analyze and fix missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge train and test, exclude overlap\ndates_overlap = ['2020-03-19','2020-03-20','2020-03-21','2020-03-22','2020-03-23', '2020-03-24', '2020-03-25', '2020-03-26', '2020-03-27']\ntrain2 = train.loc[~train['date'].isin(dates_overlap)]\nall_data = pd.concat([train2, test], axis = 0, sort=False)\n\n# Double check that there are no informed ConfirmedCases and Fatalities after 2020-03-11\nall_data.loc[all_data['date'] >= '2020-03-19', 'positives'] = np.nan\nall_data.loc[all_data['date'] >= '2020-03-19', 'deaths'] = np.nan\nall_data['date'] = pd.to_datetime(all_data['date'])\n\n# Create date columns\npositives_by_date_country = all_data.groupby([\"date\", \"country\"])[\"positives\"].sum().reset_index()\npositives_by_date_country[\"counter\"] = positives_by_date_country[\"positives\"] > 0\npositives_by_date_country[\"counter\"] = positives_by_date_country.groupby([\"country\"])[\"counter\"].cumsum().astype(int)\nall_data = all_data.merge(positives_by_date_country)\nall_data['day'] = all_data['date'].dt.day\nall_data['month'] = all_data['date'].dt.month\nall_data['year'] = all_data['date'].dt.year\n\ndisplay(all_data[all_data[\"country\"]==\"Germany\"].head(50))\n#display(all_data.loc[all_data['date'] == '2020-03-19'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.2. Compute lags and trends <a id=\"section32\"></a>\n\nEnriching a dataset is key to obtain good results. In this case we will apply 2 different transformations:\n\n**Lag**. Lags are a way to compute the previous value of a column, so that the lag 1 for ConfirmedCases would inform the this column from the previous day. The lag 3 of a feature X is simply:\n$$X_{lag3}(t) = X(t-3)$$\n\n\n**Trend**. Transformig a column into its trend gives the natural tendency of this column, which is different from the raw value. The definition of trend I will apply is: \n$$Trend_{X} = {X(t) - X(t-1) \\over X(t-1)}$$\n\nThe backlog of lags I'll apply is 14 days, while for trends is 7 days.  For ConfirmedCases and Fatalities:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_trend(df, lag_list, column):\n    for lag in lag_list:\n        trend_column_lag = column + \"_trend_\" + str(lag)\n        df[trend_column_lag] = (df[column]-df[column].shift(lag, fill_value=-999))/df[column].shift(lag, fill_value=0)\n    return df\n\n\ndef calculate_lag(df, lag_list, column):\n    for lag in lag_list:\n        column_lag = column + \"_lagged_\" + str(lag)\n        df[column_lag] = df[column].shift(lag, fill_value=0)\n    return df\n\n\nall_data = calculate_lag(all_data, range(1,7), 'positives')\nall_data = calculate_lag(all_data, range(1,7), 'deaths')\nall_data = calculate_trend(all_data, range(1,7), 'positives')\nall_data = calculate_trend(all_data, range(1,7), 'deaths')\nall_data.replace([np.inf, -np.inf], 0, inplace=True)\nall_data.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data[all_data['country']=='Spain'].iloc[40:50]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.3. Add country details <a id=\"section33\"></a>\n\nVariables like the total population of a country, the average age of citizens or the fraction of peoople living in cities may strongly impact on the COVID-19 transmission behavior. Hence, it's important to consider these factors. I'm using [Tanu's dataset](https://www.kaggle.com/tanuprabhu/population-by-country-2020) based on Web Scrapping for this purpose."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load countries data file\nworld_population = pd.read_csv(\"/kaggle/input/population-by-country-2020/population_by_country_2020.csv\")\n\n# Select desired columns and rename some of them\nworld_population = world_population[['Country (or dependency)', 'Population (2020)', 'Density (P/Km²)', 'Land Area (Km²)', 'Med. Age', 'Urban Pop %']]\nworld_population.columns = ['country', 'population', 'density', 'land_area', 'age', 'population_urban']\n\n# Replace United States by US\nworld_population.loc[world_population['country']=='United States', 'country'] = 'US'\n# Remove the % character from Urban Pop values\nworld_population['population_urban'] = world_population['population_urban'].str.rstrip('%')\n# Replace Urban Pop and Med Age \"N.A\" by their respective modes, then transform to int\nworld_population.loc[world_population['population_urban']=='N.A.', 'population_urban'] = int(world_population.loc[world_population['population_urban']!='N.A.', 'population_urban'].mode()[0])\nworld_population['population_urban'] = world_population['population_urban'].astype('int16')\nworld_population.loc[world_population['age']=='N.A.', 'age'] = int(world_population.loc[world_population['age']!='N.A.', 'age'].mode()[0])\nworld_population['age'] = world_population['age'].astype('int16')\n\nprint(\"Cleaned country details dataset\")\ndisplay(world_population)\n\n# Now join the dataset to our previous DataFrame and clean missings (not match in left join)- label encode cities\nprint(\"Joined dataset\")\nall_data = all_data.merge(world_population, left_on='country', right_on='country', how='left')\nall_data[['population', 'density', 'land_area', 'age', 'population_urban']] = all_data[['population', 'density', 'land_area', 'age', 'population_urban']].fillna(0)\ndisplay(all_data)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Predictions with machine learning <a id=\"section4\"></a>\n\nOur obective in this section consists on  predicting the evolution of the expansion from a data-centric perspective, like any other regression problem. To do so, remember that the challenge specifies that submissions on the public LB shouldn only contain data previous to 2020-03-12.\n\nModels to apply:\n1. Linear Regression for one country\n2. Linear Regression for all countries (method 1)\n3. Linear Regression for all countries (method 2)"},{"metadata":{},"cell_type":"markdown","source":"## 4.1. Linear Regression for one country <a id=\"section41\"></a>\n\nSince we are interested into predicting the future time evolution of the pandemic, our first approach consists on a simple Linear Regression. However, remind that the evolution is not linear but exponential (only in the beginning of the infection), so that a preliminar log transformation is needed. \n\nVisual comparison of both cases for Spain and with data from last 10 days informed, starting on March 1st:"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n\n# Day_num = 38 is March 1st\ny1 = all_data[(all_data['Country_Region']==country_dict['Spain']) & (all_data['Day_num']>39) & (all_data['Day_num']<=49)][['ConfirmedCases']]\nx1 = range(0, len(y1))\nax1.plot(x1, y1, 'bo--')\nax1.set_title(\"Spain ConfirmedCases between days 39 and 49\")\nax1.set_xlabel(\"Days\")\nax1.set_ylabel(\"ConfirmedCases\")\n\ny2 = all_data[(all_data['Country_Region']==country_dict['Spain']) & (all_data['Day_num']>39) & (all_data['Day_num']<=49)][['ConfirmedCases']].apply(lambda x: np.log(x))\nx2 = range(0, len(y2))\nax2.plot(x2, y2, 'bo--')\nax2.set_title(\"Spain Log ConfirmedCases between days 39 and 49\")\nax2.set_xlabel(\"Days\")\nax2.set_ylabel(\"Log ConfirmedCases\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you see, the log transformation results in a fancy straight-like line, which is awesome for Linear Regression. However, let me clarify two important points:\n\n* This \"roughly exponential behavior\" is only true for the initial infection stages of the pandemic (the initial increasing of infections on the SIR model), but that's exactly the point where most countries are at the moment.\n\n* Why do I only extract the last 10 days of data? For three reasons:\n    1. In order to capture exactly the very short term component of the evolution\n    2. To prevent the effects of certain variables that have been impacting the transmition speed (quarantine vs free circulation)\n    3. To prevent differences on criteria when confirming cases (remember that weird slope on the China plot?)"},{"metadata":{},"cell_type":"markdown","source":"This first model is very simple, and only elemental features will be considered: Country/Region, date information, Long and Lat. Lags. Engineered columns like lags, trends and country details are not introduced as an input. Finally, the workflow for the Basic Linear Regression model is:\n1. **Features**. Select features\n2. **Dates**. Filter train data from 2020-03-01 to 2020-03-18\n2. **Log transformation**. Apply log transformation to ConfirmedCases and Fatalities\n3. **Infinites**. Replace infinites from the logarithm with 0. Given the asymptotic behavior of the logarithm for log(0),this implies that when applying the inverse transformation (exponential) a 1 will be returned instead of a 0. This problem does not impact many countries, but still needs to be tackled sooner or later in order to obtain a clean solution.\n4. **Train/test split**. Split into train/valid/test\n5. **Prediction**. Linear Regression, training country by country and joining data\n6. **Submit**. Submit results in the correct format, and applying exponential to reverse log transformation "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filter selected features\ndata = all_data.copy()\nfeatures = ['Id', 'ForecastId', 'Country_Region', 'Province_State', 'ConfirmedCases', 'Fatalities', \n       'Day_num', 'Day', 'Month', 'Year']\ndata = data[features]\n\n# Apply log transformation to all ConfirmedCases and Fatalities columns, except for trends\ndata[['ConfirmedCases', 'Fatalities']] = data[['ConfirmedCases', 'Fatalities']].astype('float64')\ndata[['ConfirmedCases', 'Fatalities']] = data[['ConfirmedCases', 'Fatalities']].apply(lambda x: np.log(x))\n\n# Replace infinites\ndata.replace([np.inf, -np.inf], 0, inplace=True)\n\n\n# Split data into train/test\ndef split_data(data):\n    \n    # Train set\n    x_train = data[data.ForecastId == -1].drop(['ConfirmedCases', 'Fatalities'], axis=1)\n    y_train_1 = data[data.ForecastId == -1]['ConfirmedCases']\n    y_train_2 = data[data.ForecastId == -1]['Fatalities']\n\n    # Test set\n    x_test = data[data.ForecastId != -1].drop(['ConfirmedCases', 'Fatalities'], axis=1)\n\n    # Clean Id columns and keep ForecastId as index\n    x_train.drop('Id', inplace=True, errors='ignore', axis=1)\n    x_train.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n    x_test.drop('Id', inplace=True, errors='ignore', axis=1)\n    x_test.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n    \n    return x_train, y_train_1, y_train_2, x_test\n\n\n# Linear regression model\ndef lin_reg(X_train, Y_train, X_test):\n    # Create linear regression object\n    regr = linear_model.LinearRegression()\n\n    # Train the model using the training sets\n    regr.fit(X_train, Y_train)\n\n    # Make predictions using the testing set\n    y_pred = regr.predict(X_test)\n    \n    return regr, y_pred\n\n\n# Submission function\ndef get_submission(df, target1, target2):\n    \n    prediction_1 = df[target1]\n    prediction_2 = df[target2]\n\n    # Submit predictions\n    prediction_1 = [int(item) for item in list(map(round, prediction_1))]\n    prediction_2 = [int(item) for item in list(map(round, prediction_2))]\n    \n    submission = pd.DataFrame({\n        \"ForecastId\": df['ForecastId'].astype('int32'), \n        \"ConfirmedCases\": prediction_1, \n        \"Fatalities\": prediction_2\n    })\n    submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's try to see results when training with a single country:\n\n* **Spain**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select train (real) data from March 1 to March 22nd\ndates_list = ['2020-03-01', '2020-03-02', '2020-03-03', '2020-03-04', '2020-03-05', '2020-03-06', '2020-03-07', '2020-03-08', '2020-03-09', \n                 '2020-03-10', '2020-03-11','2020-03-12','2020-03-13','2020-03-14','2020-03-15','2020-03-16','2020-03-17','2020-03-18',\n                 '2020-03-19','2020-03-20','2020-03-21','2020-03-22','2020-03-23', '2020-03-24', '2020-03-25', '2020-03-26', '2020-03-27']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.loc[all_data['Country_Region']==country_dict['Spain']][45:65]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filter Spain, run the Linear Regression workflow\ncountry_name = \"Spain\"\nday_start = 39\ndata_country = data[data['Country_Region']==country_dict[country_name]]\ndata_country = data_country.loc[data_country['Day_num']>=day_start]\nX_train, Y_train_1, Y_train_2, X_test = split_data(data_country)\nmodel, pred = lin_reg(X_train, Y_train_1, X_test)\n\n# Create a df with both real cases and predictions (predictions starting on March 12th)\nX_train_check = X_train.copy()\nX_train_check['Target'] = Y_train_1\n\nX_test_check = X_test.copy()\nX_test_check['Target'] = pred\n\nX_final_check = pd.concat([X_train_check, X_test_check])\n\n# Select predictions from March 1st to March 25th\npredicted_data = X_final_check.loc[(X_final_check['Day_num'].isin(list(range(day_start, day_start+len(dates_list)))))].Target\nreal_data = train.loc[(train['Country_Region']==country_name) & (train['Date'].isin(dates_list))]['ConfirmedCases']\ndates_list_num = list(range(0,len(dates_list)))\n\n# Plot results\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n\nax1.plot(dates_list_num, np.exp(predicted_data))\nax1.plot(dates_list_num, real_data)\nax1.axvline(17, linewidth=2, ls = ':', color='grey', alpha=0.5)\nax1.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\nax1.set_xlabel(\"Day count (from March 1st to March 25th)\")\nax1.set_ylabel(\"Confirmed Cases\")\n\nax2.plot(dates_list_num, predicted_data)\nax2.plot(dates_list_num, np.log(real_data))\nax2.axvline(17, linewidth=2, ls = ':', color='grey', alpha=0.5)\nax2.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\nax2.set_xlabel(\"Day count (from March 1st to March 25th)\")\nax2.set_ylabel(\"Log Confirmed Cases\")\n\nplt.suptitle((\"ConfirmedCases predictions based on Log-Lineal Regression for \"+country_name))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Italy**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filter Italy, run the Linear Regression workflow\ncountry_name = \"Italy\"\nday_start = 39\ndata_country = data[data['Country_Region']==country_dict[country_name]]\ndata_country = data_country.loc[data_country['Day_num']>=day_start]\nX_train, Y_train_1, Y_train_2, X_test = split_data(data_country)\nmodel, pred = lin_reg(X_train, Y_train_1, X_test)\n\n# Create a df with both real cases and predictions (predictions starting on March 12th)\nX_train_check = X_train.copy()\nX_train_check['Target'] = Y_train_1\n\nX_test_check = X_test.copy()\nX_test_check['Target'] = pred\n\nX_final_check = pd.concat([X_train_check, X_test_check])\n\n# Select predictions from March 1st to March 24th\npredicted_data = X_final_check.loc[(X_final_check['Day_num'].isin(list(range(day_start, day_start+len(dates_list)))))].Target\nreal_data = train.loc[(train['Country_Region']==country_name) & (train['Date'].isin(dates_list))]['ConfirmedCases']\ndates_list_num = list(range(0,len(dates_list)))\n\n# Plot results\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n\nax1.plot(dates_list_num, np.exp(predicted_data))\nax1.plot(dates_list_num, real_data)\nax1.axvline(17, linewidth=2, ls = ':', color='grey', alpha=0.5)\nax1.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\nax1.set_xlabel(\"Day count (from March 1st to March 22nd)\")\nax1.set_ylabel(\"Confirmed Cases\")\n\nax2.plot(dates_list_num, predicted_data)\nax2.plot(dates_list_num, np.log(real_data))\nax2.axvline(17, linewidth=2, ls = ':', color='grey', alpha=0.5)\nax2.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\nax2.set_xlabel(\"Day count (from March 1st to March 22nd)\")\nax2.set_ylabel(\"Log Confirmed Cases\")\n\nplt.suptitle((\"ConfirmedCases predictions based on Log-Lineal Regression for \"+country_name))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Germany**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filter Germany, run the Linear Regression workflow\ncountry_name = \"Germany\"\nday_start = 39\ndata_country = data[data['Country_Region']==country_dict[country_name]]\ndata_country = data_country.loc[data_country['Day_num']>=day_start]\nX_train, Y_train_1, Y_train_2, X_test = split_data(data_country)\nmodel, pred = lin_reg(X_train, Y_train_1, X_test)\n\n# Create a df with both real cases and predictions (predictions starting on March 12th)\nX_train_check = X_train.copy()\nX_train_check['Target'] = Y_train_1\n\nX_test_check = X_test.copy()\nX_test_check['Target'] = pred\n\nX_final_check = pd.concat([X_train_check, X_test_check])\n\n\n# Select predictions from March 1st to March 24th\npredicted_data = X_final_check.loc[(X_final_check['Day_num'].isin(list(range(day_start, day_start+len(dates_list)))))].Target\nreal_data = train.loc[(train['Country_Region']==country_name) & (train['Date'].isin(dates_list))]['ConfirmedCases']\ndates_list_num = list(range(0,len(dates_list)))\n\n# Plot results\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n\nax1.plot(dates_list_num, np.exp(predicted_data))\nax1.plot(dates_list_num, real_data)\nax1.axvline(17, linewidth=2, ls = ':', color='grey', alpha=0.5)\nax1.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\nax1.set_xlabel(\"Day count (from March 1st to March 22nd)\")\nax1.set_ylabel(\"Confirmed Cases\")\n\nax2.plot(dates_list_num, predicted_data)\nax2.plot(dates_list_num, np.log(real_data))\nax2.axvline(17, linewidth=2, ls = ':', color='grey', alpha=0.5)\nax2.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\nax2.set_xlabel(\"Day count (from March 1st to March 22nd)\")\nax2.set_ylabel(\"Log Confirmed Cases\")\n\nplt.suptitle((\"ConfirmedCases predictions based on Log-Lineal Regression for \"+country_name))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Albania**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filter Albania, run the Linear Regression workflow\ncountry_name = \"Albania\"\nday_start = 39\ndata_country = data[data['Country_Region']==country_dict[country_name]]\ndata_country = data_country.loc[data_country['Day_num']>=day_start]\nX_train, Y_train_1, Y_train_2, X_test = split_data(data_country)\nmodel, pred = lin_reg(X_train, Y_train_1, X_test)\n\n# Create a df with both real cases and predictions (predictions starting on March 12th)\nX_train_check = X_train.copy()\nX_train_check['Target'] = Y_train_1\n\nX_test_check = X_test.copy()\nX_test_check['Target'] = pred\n\nX_final_check = pd.concat([X_train_check, X_test_check])\n\n# Select predictions from March 1st to March 24th\npredicted_data = X_final_check.loc[(X_final_check['Day_num'].isin(list(range(day_start, day_start+len(dates_list)))))].Target\nreal_data = train.loc[(train['Country_Region']==country_name) & (train['Date'].isin(dates_list))]['ConfirmedCases']\ndates_list_num = list(range(0,len(dates_list)))\n\n# Plot results\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n\nax1.plot(dates_list_num, np.exp(predicted_data))\nax1.plot(dates_list_num, real_data)\nax1.axvline(17, linewidth=2, ls = ':', color='grey', alpha=0.5)\nax1.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\nax1.set_xlabel(\"Day count (from March 1st to March 22nd)\")\nax1.set_ylabel(\"Confirmed Cases\")\n\nax2.plot(dates_list_num, predicted_data)\nax2.plot(dates_list_num, np.log(real_data))\nax2.axvline(17, linewidth=2, ls = ':', color='grey', alpha=0.5)\nax2.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\nax2.set_xlabel(\"Day count (from March 1st to March 22nd)\")\nax2.set_ylabel(\"Log Confirmed Cases\")\n\nplt.suptitle((\"ConfirmedCases predictions based on Log-Lineal Regression for \"+country_name))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Andorra**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filter Andorra, run the Linear Regression workflow\ncountry_name = \"Andorra\"\nday_start = 39\ndata_country = data[data['Country_Region']==country_dict[country_name]]\ndata_country = data_country.loc[data_country['Day_num']>=day_start]\nX_train, Y_train_1, Y_train_2, X_test = split_data(data_country)\nmodel, pred = lin_reg(X_train, Y_train_1, X_test)\n\n# Create a df with both real cases and predictions (predictions starting on March 12th)\nX_train_check = X_train.copy()\nX_train_check['Target'] = Y_train_1\n\nX_test_check = X_test.copy()\nX_test_check['Target'] = pred\n\nX_final_check = pd.concat([X_train_check, X_test_check])\n\n# Select predictions from March 1st to March 24th\npredicted_data = X_final_check.loc[(X_final_check['Day_num'].isin(list(range(day_start, day_start+len(dates_list)))))].Target\nreal_data = train.loc[(train['Country_Region']==country_name) & (train['Date'].isin(dates_list))]['ConfirmedCases']\ndates_list_num = list(range(0,len(dates_list)))\n\n# Plot results\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n\nax1.plot(dates_list_num, np.exp(predicted_data))\nax1.plot(dates_list_num, real_data)\nax1.axvline(17, linewidth=2, ls = ':', color='grey', alpha=0.5)\nax1.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\nax1.set_xlabel(\"Day count (from March 1st to March 22nd)\")\nax1.set_ylabel(\"Confirmed Cases\")\n\nax2.plot(dates_list_num, predicted_data)\nax2.plot(dates_list_num, np.log(real_data))\nax2.axvline(17, linewidth=2, ls = ':', color='grey', alpha=0.5)\nax2.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\nax2.set_xlabel(\"Day count (from March 1st to March 22nd)\")\nax2.set_ylabel(\"Log Confirmed Cases\")\n\nplt.suptitle((\"ConfirmedCases predictions based on Log-Lineal Regression for \"+country_name))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observations**:\n\n* The general evolution is captured despite the simplicity of the model\n* With training data starting on March 1st, predictions for the first 5 test days tend to be accurate\n* Estimations are increasingly worse as time passes (harder to extrapolate)\n* Countries that recently confirmed their first contagions are difficult to predict (less data points) \n* Countries with 0 cases in the whole training dataset are predicted as non-infected (no datapoints)\n\n** Questions to tackle in next subsections**:\n* How to obtain the full submission set? \n* What to do for countries with different Provinces/State informed?\n* Is there any alternative to manually setting the size of the train data? "},{"metadata":{},"cell_type":"markdown","source":"## 4.2 Logistic Regression for all countries (method 1) <a id=\"section42\"></a>\n\nWe've recently discovered that when fitting only with 10 historical datapoints some problematic scenarios appear, that impact the performance of our Linear Regressor. Let's generalize the model for all countries to verify if it's an unavoidable problem. Steps to run for all countries:\n\n1. Loop for each country\n2. Compute provinces list\n3. If there are provinces, run the Linear Regressor for each of them\n4. Otherwise just run the Linear Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\n\nday_start = 39\ndata2 = data.loc[data.Day_num >= day_start]\n\n# Set the dataframe where we will update the predictions\ndata_pred = data[data.ForecastId != -1][['Country_Region', 'Province_State', 'Day_num', 'ForecastId']]\ndata_pred = data_pred.loc[data_pred['Day_num']>=day_start]\ndata_pred['Predicted_ConfirmedCases'] = [0]*len(data_pred)\ndata_pred['Predicted_Fatalities'] = [0]*len(data_pred)\n    \nprint(\"Currently running Logistic Regression for all countries\")\n\n# Main loop for countries\nfor c in data2['Country_Region'].unique():\n    \n    # List of provinces\n    provinces_list = data2[data2['Country_Region']==c]['Province_State'].unique()\n        \n    # If the country has several Province/State informed\n    if len(provinces_list)>1:\n        for p in provinces_list:\n            data_cp = data2[(data2['Country_Region']==c) & (data2['Province_State']==p)]\n            X_train, Y_train_1, Y_train_2, X_test = split_data(data_cp)\n            model_1, pred_1 = lin_reg(X_train, Y_train_1, X_test)\n            model_2, pred_2 = lin_reg(X_train, Y_train_2, X_test)\n            data_pred.loc[((data_pred['Country_Region']==c) & (data2['Province_State']==p)), 'Predicted_ConfirmedCases'] = pred_1\n            data_pred.loc[((data_pred['Country_Region']==c) & (data2['Province_State']==p)), 'Predicted_Fatalities'] = pred_2\n\n    # No Province/State informed\n    else:\n        data_c = data2[(data2['Country_Region']==c)]\n        X_train, Y_train_1, Y_train_2, X_test = split_data(data_c)\n        model_1, pred_1 = lin_reg(X_train, Y_train_1, X_test)\n        model_2, pred_2 = lin_reg(X_train, Y_train_2, X_test)\n        data_pred.loc[(data_pred['Country_Region']==c), 'Predicted_ConfirmedCases'] = pred_1\n        data_pred.loc[(data_pred['Country_Region']==c), 'Predicted_Fatalities'] = pred_2\n\n# Aplly exponential transf. and clean potential infinites due to final numerical precision\ndata_pred[['Predicted_ConfirmedCases', 'Predicted_Fatalities']] = data_pred[['Predicted_ConfirmedCases', 'Predicted_Fatalities']].apply(lambda x: np.exp(x))\ndata_pred.replace([np.inf, -np.inf], 0, inplace=True) \n\nget_submission(data_pred, 'Predicted_ConfirmedCases', 'Predicted_Fatalities')\n\nprint(\"Process finished in \", round(time.time() - ts, 2), \" seconds\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The final score based on the [LMSE metric](https://medium.com/analytics-vidhya/root-mean-square-log-error-rmse-vs-rmlse-935c6cc1802a) of this model for the week 1 competition was 1.10954. "},{"metadata":{},"cell_type":"markdown","source":"## 4.3 Logistic Regression for all countries (method 2) <a id=\"section43\"></a>\n\nAn alternative method to setting the number of days for the training step is to simply keep all data for each country since the first case was confirmed. However, since there are certain countries were the initial outbreak was very smooth (i.e. in Spain there was only one confirmed case for 7 days in a row), predictions may be biased by these initial periods."},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\n\n# Set the dataframe where we will update the predictions\ndata_pred2 = data[data.ForecastId != -1][['Country_Region', 'Province_State', 'Day_num', 'ForecastId']]\ndata_pred2['Predicted_ConfirmedCases'] = [0]*len(data_pred2)\ndata_pred2['Predicted_Fatalities'] = [0]*len(data_pred2)\nhow_many_days = test.Date.nunique()\n    \nprint(\"Currently running Logistic Regression for all countries\")\n\n# Main loop for countries\nfor c in data['Country_Region'].unique():\n    \n    # List of provinces\n    provinces_list = data2[data2['Country_Region']==c]['Province_State'].unique()\n        \n    # If the country has several Province/State informed\n    if len(provinces_list)>1:\n        \n        for p in provinces_list:\n            # Only fit starting from the first confirmed case in the country\n            train_countries_no0 = data.loc[(data['Country_Region']==c) & (data['Province_State']==p) & (data.ConfirmedCases!=0) & (data.ForecastId==-1)]\n            test_countries_no0 = data.loc[(data['Country_Region']==c) & (data['Province_State']==p) &  (data.ForecastId!=-1)]\n            data2 = pd.concat([train_countries_no0, test_countries_no0])\n\n            # If there are no previous cases, predict 0\n            if len(train_countries_no0) == 0:\n                data_pred2.loc[((data_pred2['Country_Region']==c) & (data_pred2['Province_State']==p)), 'Predicted_ConfirmedCases'] = [0]*how_many_days\n                data_pred2.loc[((data_pred2['Country_Region']==c) & (data_pred2['Province_State']==p)), 'Predicted_Fatalities'] = [0]*how_many_days\n                \n            # Else run LinReg\n            else: \n                data_cp = data2[(data2['Country_Region']==c) & (data2['Province_State']==p)]\n                X_train, Y_train_1, Y_train_2, X_test = split_data(data_cp)\n                model_1, pred_1 = lin_reg(X_train, Y_train_1, X_test)\n                model_2, pred_2 = lin_reg(X_train, Y_train_2, X_test)\n                data_pred2.loc[((data_pred2['Country_Region']==c) & (data_pred2['Province_State']==p)), 'Predicted_ConfirmedCases'] = pred_1\n                data_pred2.loc[((data_pred2['Country_Region']==c) & (data_pred2['Province_State']==p)), 'Predicted_Fatalities'] = pred_2\n\n    # No Province/State informed\n    else:\n        # Only fit starting from the first confirmed case in the country\n        train_countries_no0 = data.loc[(data['Country_Region']==c) & (data.ConfirmedCases!=0) & (data.ForecastId==-1)]\n        test_countries_no0 = data.loc[(data['Country_Region']==c) &  (data.ForecastId!=-1)]\n        data2 = pd.concat([train_countries_no0, test_countries_no0])\n\n        # If there are no previous cases, predict 0\n        if len(train_countries_no0) == 0:\n            data_pred2.loc[((data_pred2['Country_Region']==c)), 'Predicted_ConfirmedCases'] = [0]*how_many_days\n            data_pred2.loc[((data_pred2['Country_Region']==c)), 'Predicted_Fatalities'] = [0]*how_many_days\n        \n        # Else, run LinReg\n        else:\n            data_c = data2[(data2['Country_Region']==c)]\n            X_train, Y_train_1, Y_train_2, X_test = split_data(data_c)\n            model_1, pred_1 = lin_reg(X_train, Y_train_1, X_test)\n            model_2, pred_2 = lin_reg(X_train, Y_train_2, X_test)\n            data_pred2.loc[(data_pred2['Country_Region']==c), 'Predicted_ConfirmedCases'] = pred_1\n            data_pred2.loc[(data_pred2['Country_Region']==c), 'Predicted_Fatalities'] = pred_2\n\n# Aplly exponential transf. and clean potential infinites due to final numerical precision\ndata_pred2[['Predicted_ConfirmedCases', 'Predicted_Fatalities']] = data_pred2[['Predicted_ConfirmedCases', 'Predicted_Fatalities']].apply(lambda x: np.exp(x))\ndata_pred2.replace([np.inf, -np.inf], 0, inplace=True) \n\nprint(\"Process finished in \", round(time.time() - ts, 2), \" seconds\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From my experiments, this apporach is not suitable for our linear regression model. In many cases there are strong transitional periods at the beginning, which frequently biases the regression. Hence, I will not submit this case, but you are welcome to use it for any other purposes."},{"metadata":{},"cell_type":"markdown","source":"## 4.4. Logistic regression with lags <a id=\"section44\"></a>\n\nWith all the previous results in mind, I quite believe that Linear Regression is a good approach for the early stages of the COVID-19 spread. Of course, this is only true for the initial outbreak we are analysing, and there's no way our model could predict when the number of new infections is going to decrease. But for short-term prediction purposes everything is fine, and we are in disposition to try to improve the results.\n\nRemember those lagged variables we computed some sections before? Now it's time to use them, but first there's a problem to solve. If we use our dataset to predict the next following days of contagions, for the first day all the lags will be reported (from the previous days), but what about the next days? **Many of the lags will be unknown** (flagged as 0), since the number of ConfirmedCases is only known for the train subset. The most simple approach to overcome this is:\n\n1. Begin with the train dataset, with all cases and lags reported\n2. Forecast only the following day, through the Linear Regression\n3. Set the new prediction as a confirmed case\n4. Recompute lags\n5. Repeat from step 2 to step 4 for all remaining days\n\nAs usual, I'll start training on single countries in order to analyze the behavior of the model with these new features."},{"metadata":{"trusted":true},"cell_type":"code","source":"# New split function, for one forecast day\ndef split_data_one_day(data, d):\n    \n    #Train\n    x_train = data[data.Day_num<d]\n    y_train_1 = x_train.ConfirmedCases\n    y_train_2 = x_train.Fatalities\n    x_train.drop(['ConfirmedCases', 'Fatalities'], axis=1, inplace=True)\n    \n    #Test\n    x_test = data[data.Day_num==d]\n    x_test.drop(['ConfirmedCases', 'Fatalities'], axis=1, inplace=True)\n    \n    # Clean Id columns and keep ForecastId as index\n    x_train.drop('Id', inplace=True, errors='ignore', axis=1)\n    x_train.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n    x_test.drop('Id', inplace=True, errors='ignore', axis=1)\n    x_test.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n    \n    return x_train, y_train_1, y_train_2, x_test\n\n\ndef plot_real_vs_prediction_country(data, train, country_name, day_start, dates_list):\n\n    # Select predictions from March 1st to March 25th\n    predicted_data = data.loc[(data['Day_num'].isin(list(range(day_start, day_start+len(dates_list)))))].ConfirmedCases\n    real_data = train.loc[(train['Country_Region']==country_name) & (train['Date'].isin(dates_list))]['ConfirmedCases']\n    dates_list_num = list(range(0,len(dates_list)))\n\n    # Plot results\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n\n    ax1.plot(dates_list_num, np.exp(predicted_data))\n    ax1.plot(dates_list_num, real_data)\n    ax1.axvline(17, linewidth=2, ls = ':', color='grey', alpha=0.5)\n    ax1.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n    ax1.set_xlabel(\"Day count (starting on March 1st)\")\n    ax1.set_ylabel(\"Confirmed Cases\")\n\n    ax2.plot(dates_list_num, predicted_data)\n    ax2.plot(dates_list_num, np.log(real_data))\n    ax2.axvline(17, linewidth=2, ls = ':', color='grey', alpha=0.5)\n    ax2.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n    ax2.set_xlabel(\"Day count (starting on March 1st)\")\n    ax2.set_ylabel(\"Log Confirmed Cases\")\n\n    plt.suptitle((\"ConfirmedCases predictions based on Log-Lineal Regression for \"+country_name))\n    \n    \ndef plot_real_vs_prediction_country_fatalities(data, train, country_name, day_start, dates_list):\n\n    # Select predictions from March 1st to March 25th\n    predicted_data = data.loc[(data['Day_num'].isin(list(range(day_start, day_start+len(dates_list)))))].Fatalities\n    real_data = train.loc[(train['Country_Region']==country_name) & (train['Date'].isin(dates_list))]['Fatalities']\n    dates_list_num = list(range(0,len(dates_list)))\n\n    # Plot results\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n\n    ax1.plot(dates_list_num, np.exp(predicted_data))\n    ax1.plot(dates_list_num, real_data)\n    ax1.axvline(17, linewidth=2, ls = ':', color='grey', alpha=0.5)\n    ax1.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n    ax1.set_xlabel(\"Day count (starting on March 1st)\")\n    ax1.set_ylabel(\"Fatalities Cases\")\n\n    ax2.plot(dates_list_num, predicted_data)\n    ax2.plot(dates_list_num, np.log(real_data))\n    ax2.axvline(17, linewidth=2, ls = ':', color='grey', alpha=0.5)\n    ax2.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n    ax2.set_xlabel(\"Day count (starting on March 1st)\")\n    ax2.set_ylabel(\"Log Fatalities Cases\")\n\n    plt.suptitle((\"Fatalities predictions based on Log-Lineal Regression for \"+country_name))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Spain**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to compute the Linear Regression predictions with lags, for a certain Country/Region\ndef lin_reg_with_lags_country(all_data, country_name, day_start, lag_size, country_dict):\n    \n    ts = time.time()\n    \n    # Filter country and features from all_data (dataset without data leaking)\n    data = all_data.copy()\n    features = ['Id', 'Province_State', 'Country_Region',\n           'ConfirmedCases', 'Fatalities', 'ForecastId', 'Day_num']\n    data = data[features]\n\n    # Select country an data start (all days)\n    data = data[data['Country_Region']==country_dict[country_name]]\n    data = data.loc[data['Day_num']>=day_start]\n\n    # Lags\n    data = calculate_lag(data, range(1,lag_size), 'ConfirmedCases')\n    data = calculate_lag(data, range(1,8), 'Fatalities')\n\n    filter_col_confirmed = [col for col in data if col.startswith('Confirmed')]\n    filter_col_fatalities= [col for col in data if col.startswith('Fataliti')]\n    filter_col = np.append(filter_col_confirmed, filter_col_fatalities)\n    \n    # Apply log transformation\n    data[filter_col] = data[filter_col].apply(lambda x: np.log(x))\n    data.replace([np.inf, -np.inf], 0, inplace=True)\n    data.fillna(0, inplace=True)\n\n\n    # Start/end of forecast\n    start_fcst = all_data[all_data['Id']==-1].Day_num.min()\n    end_fcst = all_data[all_data['Id']==-1].Day_num.max()\n\n    for d in list(range(start_fcst, end_fcst+1)):\n        X_train, Y_train_1, Y_train_2, X_test = split_data_one_day(data, d)\n        model_1, pred_1 = lin_reg(X_train, Y_train_1, X_test)\n        data.loc[(data['Country_Region']==country_dict[country_name]) \n                 & (data['Day_num']==d), 'ConfirmedCases'] = pred_1[0]\n        model_2, pred_2 = lin_reg(X_train, Y_train_2, X_test)\n        data.loc[(data['Country_Region']==country_dict[country_name]) \n                 & (data['Day_num']==d), 'Fatalities'] = pred_2[0]\n\n        # Recompute lags \n        data = calculate_lag(data, range(1,lag_size), 'ConfirmedCases')\n        data = calculate_lag(data, range(1,8), 'Fatalities')\n        data.replace([np.inf, -np.inf], 0, inplace=True)\n        data.fillna(0, inplace=True)\n\n    #print(\"Process for \", country_name, \"finished in \", round(time.time() - ts, 2), \" seconds\")\n    \n    return data\n\n\n# Function to compute the Linear Regression predictions with lags, for a certain Country/Region and State/province\ndef lin_reg_with_lags_country_province(all_data, country_name, province_name, day_start, lag_size, country_dict):\n    \n    ts = time.time()\n    \n    # Filter country and features from all_data (dataset without data leaking)\n    data = all_data.copy()\n    features = ['Id', 'Province_State', 'Country_Region',\n           'ConfirmedCases', 'Fatalities', 'ForecastId', 'Day_num']\n    data = data[features]\n\n    # Select country an data start (all days)\n    data = data[(data['Country_Region']==country_dict[country_name]) & (data['Province_State']==province_dict[province_name])]\n    data = data.loc[data['Day_num']>=day_start]\n\n    # Lags\n    data = calculate_lag(data, range(1,lag_size), 'ConfirmedCases')\n    data = calculate_lag(data, range(1,lag_size), 'Fatalities')\n\n    # Apply log transformation\n    filter_col_confirmed = [col for col in data if col.startswith('Confirmed')]\n    filter_col_fatalities= [col for col in data if col.startswith('Fataliti')]\n    filter_col = np.append(filter_col_confirmed, filter_col_fatalities)\n    data[filter_col] = data[filter_col].apply(lambda x: np.log(x))\n    data.replace([np.inf, -np.inf], 0, inplace=True)\n    data.fillna(0, inplace=True)\n\n    # Start/end of forecast\n    start_fcst = all_data[all_data['Id']==-1].Day_num.min()\n    end_fcst = all_data[all_data['Id']==-1].Day_num.max()\n\n    for d in list(range(start_fcst, end_fcst+1)):\n        X_train, Y_train_1, Y_train_2, X_test = split_data_one_day(data, d)\n        model_1, pred_1 = lin_reg(X_train, Y_train_1, X_test)\n        data.loc[(data['Country_Region']==country_dict[country_name]) & (data['Province_State']==province_dict[province_name]) \n                 & (data['Day_num']==d), 'ConfirmedCases'] = pred_1[0]\n        model_2, pred_2 = lin_reg(X_train, Y_train_2, X_test)\n        data.loc[(data['Country_Region']==country_dict[country_name]) & (data['Province_State']==province_dict[province_name])\n                 & (data['Day_num']==d), 'Fatalities'] = pred_2[0]\n\n        # Recompute lags \n        data = calculate_lag(data, range(1,lag_size), 'ConfirmedCases')\n        data = calculate_lag(data, range(1,lag_size), 'Fatalities')\n        data.replace([np.inf, -np.inf], 0, inplace=True)\n        data.fillna(0, inplace=True)\n\n    #print(\"Process for \", country_name, \"/\", province_name, \"finished in \", round(time.time() - ts, 2), \" seconds\")\n    \n    return data\n\n\n# Run the model for Spain\ncountry_name = 'Spain'\nday_start = 35 \nlag_size = 30\n\ndata = lin_reg_with_lags_country(all_data, country_name, day_start, lag_size, country_dict)\nplot_real_vs_prediction_country(data, train, country_name, 39, dates_list)\nplot_real_vs_prediction_country_fatalities(data, train, country_name, 39, dates_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Italy**"},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\n\n# Inputs\ncountry_name = \"Italy\"\nday_start = 35 \nlag_size = 30\n\ndata = lin_reg_with_lags_country(all_data, country_name, day_start, lag_size, country_dict)\nplot_real_vs_prediction_country(data, train, country_name, 39, dates_list)\nplot_real_vs_prediction_country_fatalities(data, train, country_name, 39, dates_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Germany**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inputs\ncountry_name = \"Germany\"\nday_start = 35 \nlag_size = 30\n\ndata = lin_reg_with_lags_country(all_data, country_name, day_start, lag_size, country_dict)\nplot_real_vs_prediction_country(data, train, country_name, 39, dates_list)\nplot_real_vs_prediction_country_fatalities(data, train, country_name, 39, dates_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Albania**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inputs\ncountry_name = \"Albania\"\nday_start = 35 \nlag_size = 30\n\ndata = lin_reg_with_lags_country(all_data, country_name, day_start, lag_size, country_dict)\nplot_real_vs_prediction_country(data, train, country_name, 39, dates_list)\nplot_real_vs_prediction_country_fatalities(data, train, country_name, 39, dates_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Andorra**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inputs\ncountry_name = \"Andorra\"\nday_start = 35 \nlag_size = 30\n\ndata = lin_reg_with_lags_country(all_data, country_name, day_start, lag_size, country_dict)\nplot_real_vs_prediction_country(data, train, country_name, 39, dates_list)\nplot_real_vs_prediction_country_fatalities(data, train, country_name, 39, dates_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Observations**:\n* **Parameters**. Two full weeks of training used (from February 26th to March 11th), with their previous 30 lags\n* **Enough data**. (Spain, Italy, Germany). For countries with several ConfirmedCases!=0 in the train dataset (prior to March 11th), predictions are very precise and similar to actual confirmed data\n* **Poor data**. (Algeria). Countries with a small number of datapoints in the train dataset show a potentially disastrous prediction. Given the small number of cases, the log transformation followed by a Linear Regression is not able to capture the future behavior\n* **No data**. (Andorra). When the number of confirmed cases is 0 (or negligible) in the train dataset, the model predicts always 0 infections\n* **Fatalities**. As we clarified in [section 4.1](#section41)., filling negative infinities by 0 impacts the inverse transformation of the logarithm. Values that should be 0 are now 1 ($e^0$), and that's the reason of the \"weird\" (see Andorra) plots for countries that have no fatalities in the training dataset"},{"metadata":{},"cell_type":"markdown","source":"Let's generalize the model with lags for training each country day by day:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inputs\nday_start = 35 \nlag_size = 30\n\nresults_df = pd.DataFrame()\n\ntp = time.time()\n\n# Main loop for countries\nfor country_name in train['Country_Region'].unique():\n\n    # List of provinces\n    provinces_list = all_data[all_data['Country_Region']==country_name]['Province_State'].unique()\n        \n    # If the country has several Province/State informed\n    if len(provinces_list)>1:\n        for province_name in provinces_list:\n            pred_province = lin_reg_with_lags_country_province(all_data, country_name, province_name, day_start, lag_size, country_dict)\n            results_df = pd.concat([results_df, pred_province])\n\n    else:\n        pred_country = lin_reg_with_lags_country(all_data, country_name, day_start, lag_size, country_dict)\n        results_df = pd.concat([results_df, pred_country])\n        \n#get_submission(results_df, 'ConfirmedCases', 'Fatalities')\nprint(\"Complete process finished in \", time.time()-tp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Nice, extending the model for all countries and days has been quite easy, but a tricky part needs to be addressed. As we saw when analyzing the results for certain countries, some of them have too few training datapoints different from 0, and these scenarios sometimes end up with the regression algorithm predicting absurd values.  \n\nFor the sake of simplicity, my proposal to overcome this problem consists on mixing the current results with those from [section 4.2.](#section42), where we trained the model for all countries without lags. All countries with too few confirmed cases in the training dataset will be predicted with results from section 4.2."},{"metadata":{"trusted":true},"cell_type":"code","source":"results_df_2 = results_df.copy()\n\nday_num_test = 57\n\n# Main loop for countries\nfor country_name in train['Country_Region'].unique():\n\n    # List of provinces\n    provinces_list = all_data[all_data['Country_Region']==country_name]['Province_State'].unique()\n        \n    # Countries with several Province_State informed\n    if len(provinces_list)>1:\n        for province_name in provinces_list:\n            tmp_index = results_df_2.index[(results_df_2['Country_Region']==country_dict[country_name]) & \n                           (results_df_2['Province_State']==province_dict[province_name]) & \n                           (results_df_2['Day_num']<day_num_test) & \n                           (results_df_2['ConfirmedCases']!=0)]\n\n            # When there is not enough data\n            if len(tmp_index) < 30:\n                # ConfirmedCases\n                results_df_2.loc[((results_df_2['Country_Region']==country_dict[country_name]) & \n                                  (results_df_2['Province_State']==province_dict[province_name]) &\n                                  (results_df_2['Day_num']>=day_num_test)), 'ConfirmedCases'] = data_pred.loc[((data_pred['Country_Region']==country_dict[country_name]) & \n                                  (data_pred['Province_State']==province_dict[province_name]) & \n                                  (data_pred['Day_num']>=day_num_test)), 'Predicted_ConfirmedCases'].apply(lambda x: np.log(x))\n                \n                #Fatalities\n                results_df_2.loc[((results_df_2['Country_Region']==country_dict[country_name]) & \n                                  (results_df_2['Province_State']==province_dict[province_name]) &\n                                  (results_df_2['Day_num']>=day_num_test)), 'Fatalities'] = data_pred.loc[((data_pred['Country_Region']==country_dict[country_name]) & \n                                  (data_pred['Province_State']==province_dict[province_name]) & \n                                  (data_pred['Day_num']>=day_num_test)), 'Predicted_Fatalities'].apply(lambda x: np.log(x))\n\n    # Countries without Province_State\n    else:\n        tmp_index = results_df_2.index[(results_df_2['Country_Region']==country_dict[country_name]) & \n                           (results_df_2['Day_num']<day_num_test) & \n                           (results_df_2['ConfirmedCases']!=0)]\n\n        # When there is not enough data\n        if len(tmp_index) < 30:\n            \n            #Confirmed Cases\n            results_df_2.loc[((results_df_2['Country_Region']==country_dict[country_name]) & \n                            (results_df_2['Day_num']>=day_num_test)), 'ConfirmedCases'] = data_pred.loc[((data_pred['Country_Region']==country_dict[country_name]) & \n                            (data_pred['Day_num']>=day_num_test)), 'Predicted_ConfirmedCases'].apply(lambda x: np.log(x))\n            \n            results_df_2.loc[((results_df_2['Country_Region']==country_dict[country_name]) & \n                            (results_df_2['Day_num']>=day_num_test)), 'Fatalities'] = data_pred.loc[((data_pred['Country_Region']==country_dict[country_name]) & \n                            (data_pred['Day_num']>=day_num_test)), 'Predicted_Fatalities'].apply(lambda x: np.log(x))\n            \nresults_df_2 = results_df_2.loc[results_df_2['Day_num']>=day_num_test]\n# get_submission(results_df_2, 'ConfirmedCases', 'Fatalities')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}