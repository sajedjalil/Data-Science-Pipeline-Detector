{"cells":[{"metadata":{},"cell_type":"markdown","source":"\nThis notebook can be used to calibrate a simplistic 'SIR' model including the effect of an intervention to flatten the curve.\n\nThe model needs to be given:\n* the size of the population of interest;\n* the cumulative number of positive cases and fatalities over time.\n\nAnd the code will automatically adjust the following parameters:\n* the number of people that were initially infected;\n* beta: the rate of infection of susceptible people by infected people (daily new cases = beta * susceptible * infected * population);\n* gamma: the rate of recovery of infected people;\n* death rate: the percentage of infected people who eventually die;\n* intervention start: the day intervention started to reduce the transmission rate;\n* intervention lag: the number of days it took for intervention measures to reach full effect;\n* intervention effect: the percentage reduction of the initial infection rate achieved by the intervention\n* detection rate: the percentage of infectious people reported as positives\n\nThe code prints the results, along with charts to compare model vs. data. \nIt also runs a long range forecast to estimate the peak of daily fatalities and the final cumulative fatalities.\n\nThe implementation of the SIR model also includes a mixing factor and an exponential decay to the beta parameter, to capture sub-exponential growth. Calibration results are not\nconclusive yet, but it is likely that initial growth is sub-exponential and could be best captured by a mixing factor dI = beta . S . I^mixing . dt\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom scipy.optimize import curve_fit\n\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nimport matplotlib.ticker as mtick\nfrom matplotlib.ticker import FuncFormatter\n\nimport seaborn as sns\n\nimport datetime\nfrom datetime import timedelta  \n\nimport math\n\n#formatting functions for charts\ndef millions(x, pos):\n    'The two args are the value and tick position'\n    return '%1.1fM' % (x * 1e-6)\n\n#formatting functions for charts\ndef thousands(x, pos):\n    'The two args are the value and tick position'\n    return '%1.1fT' % (x * 1e-3)\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\ntrain = pd.read_csv(\"../input/covid19-global-forecasting-week-2/train.csv\")\ndisplay(train.head())\n\ntest = pd.read_csv(\"../input/covid19-global-forecasting-week-2/test.csv\")\ndisplay(test.head())\n\nsubmission = pd.read_csv(\"../input/covid19-global-forecasting-week-2/submission.csv\")\ndisplay(submission.head())\n'''","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/covid19-global-forecasting-week-4/train.csv\")\ntrain['Date'] = train['Date'].apply(lambda x: (datetime.datetime.strptime(x, '%Y-%m-%d')))\n\ntrain['NewFatalities'] = train['Fatalities'].diff(1)/1\ntrain['NewCases'] = train['ConfirmedCases'].diff(1)/1\n\n#display(train.head(5))\n\nprint(\"Count of Country_Region: \", train['Country_Region'].nunique())\nprint(\"Countries with Province/State: \", train[train['Province_State'].isna()==False]['Country_Region'].unique())\nprint(\"Date range: \", min(train['Date']), \" - \", max(train['Date']))\n\ndisplay(train.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create two new columns: 'Region' and 'State' to bring European countries into a single region. \n#All other Country_Regions with Province_State are also captured in these two columns Region, State\n\n#EU data from https://www.google.com/publicdata/explore?ds=mo4pjipima872_&met_y=population&idim=country_group:eu&hl=en&dl=en#!ctype=l&strail=false&bcs=d&nselm=h&met_y=population&scale_y=lin&ind_y=false&rdim=country_group&idim=country_group:eu&idim=country:ea18:at:be:bg&ifdim=country_group&hl=en_US&dl=en&ind=false\n#US States from https://worldpopulationreview.com/states/#statesTable\n\nEurope=[\n    'Albania',\n    'Armenia',\n    'Azerbaijan',\n    'Austria', \n    'Belgium', \n    'Bulgaria',\n    'Croatia',\n    'Cyprus',\n    'Czechia',\n    'Denmark',\n    'Estonia',\n    'Finland', \n    'France', \n    'Germany', \n    'Greece', \n    'Hungary',\n    'Iceland', \n    'Ireland', \n    'Italy',\n    'Latvia',\n    'Lichtenstein',\n    'Lithuania',\n    'Luxembourg',\n    'Malta',\n    'Montenegro',\n    'Netherlands',\n    'North Macedonia',\n    'Norway', \n    'Poland',\n    'Portugal',\n    'Romania',\n    'Slovakia',\n    'Slovenia',\n    'Spain', \n    'Sweden', \n    'Switzerland', \n    'United Kingdom'\n]\n\ntrain['Province_State'].fillna('',inplace=True)\n\ntrain['State'] = train['Province_State']\ntrain['Region'] = train['Country_Region']\n\ntrain.loc[train['Country_Region'].isin(Europe),'Region']='EU'\ntrain.loc[train['Country_Region'].isin(Europe),'State']=train.loc[train['Country_Region'].isin(Europe),'Country_Region']\n\n#census populations\n#add entries to this table in order to run simulations\nPopulation = {\n    'China-': 1386e6,\n    'US-': 327e6,\n    'EU-': 512e6 + (10+9+5+3+3+2+0.5+0.4)*1e6,\n\n    'US-California':39937489,\n    'US-Texas':29472295,\n    'US-Florida':21992985,\n    'US-New York':19440469,\n    'US-Pennsylvania':12820878,\n    'US-Illinois':12659682,\n    'US-Ohio':11747694,\n    'US-Georgia':10736059,\n    'US-North Carolina':10611862,\n    'US-Michigan':10045029,\n    'US-New Jersey':8936574,\n    'US-Virginia':8626207,\n    'US-Washington':7797095,\n    'US-Arizona':7378494,\n    'US-Massachusetts':6976597,\n    'US-Tennessee':6897576,\n    'US-Indiana':6745354,\n    'US-Missouri':6169270,\n    'US-Maryland':6083116,\n    'US-Wisconsin':5851754,\n    'US-Colorado':5845526,\n    'US-Minnesota':5700671,\n    'US-South Carolina':5210095,\n    'US-Alabama':4908621,\n    'US-Louisiana':4645184,\n    'US-Kentucky':4499692,\n    'US-Oregon':4301089,\n    'US-Oklahoma':3954821,\n    'US-Connecticut':3563077,\n    'US-Utah':3282115,\n    'US-Iowa':3179849,\n    'US-Nevada':3139658,\n    'US-Arkansas':3038999,\n    'US-Puerto Rico':3032165,\n    'US-Mississippi':2989260,\n    'US-Kansas':2910357,\n    'US-New Mexico':2096640,\n    'US-Nebraska':1952570,\n    'US-Idaho':1826156,\n    'US-West Virginia':1778070,\n    'US-Hawaii':1412687,\n    'US-New Hampshire':1371246,\n    'US-Maine':1345790,\n    'US-Montana':1086759,\n    'US-Rhode Island':1056161,\n    'US-Delaware':982895,\n    'US-South Dakota':903027,\n    'US-North Dakota':761723,\n    'US-Alaska':734002,\n    'US-District of Columbia':720687,\n    'US-Vermont':628061,\n    'US-Wyoming':567025,\n    \n    'EU-Vatican City':801,\n    'EU-United Kingdom':67886011,\n    'EU-Ukraine':43733762,\n    'EU-Turkey':84339067,\n    'EU-Switzerland':8654622,\n    'EU-Sweden':10099265,\n    'EU-Spain':46754778,\n    'EU-Slovenia':2078938,\n    'EU-Slovakia':5459642,\n    'EU-Serbia':8737371,\n    'EU-San Marino':33931,\n    'EU-Russia':145934462,\n    'EU-Romania':19237691,\n    'EU-Portugal':10196709,\n    'EU-Poland':37846611,\n    'EU-Norway':5421241,\n    'EU-Netherlands':17134872,\n    'EU-Montenegro':628066,\n    'EU-Monaco':39242,\n    'EU-Moldova':4033963,\n    'EU-Malta':441543,\n    'EU-Luxembourg':625978,\n    'EU-Lithuania':2722289,\n    'EU-Liechtenstein':38128,\n    'EU-Latvia':1886198,\n    'EU-Kazakhstan':18776707,\n    'EU-Italy':60461826,\n    'EU-Ireland':4937786,\n    'EU-Iceland':341243,\n    'EU-Hungary':9660351,\n    'EU-Greece':10423054,\n    'EU-Germany':83783942,\n    'EU-Georgia':3989167,\n    'EU-France':65273511,\n    'EU-Finland':5540720,\n    'EU-Faroe Islands':48863,\n    'EU-Estonia':1326535,\n    'EU-Denmark':5792202,\n    'EU-Czech Republic':10708981,\n    'EU-Cyprus':1207359,\n    'EU-Croatia':4105267,\n    'EU-Bulgaria':6948445,\n    'EU-Bosnia and Herzegovina':3280819,\n    'EU-Belgium':11589623,\n    'EU-Belarus':9449323,\n    'EU-Azerbaijan':10139177,\n    'EU-Austria':9006398,\n    'EU-Armenia':2963243,\n    'EU-Andorra':77265,\n    'EU-Albania':2877797,\n    \n    'China-Hubei':59e6, #wuhan=11, hubei=59 59e6\n    'Singapore-': 5.6e6, #not enough data to calibrate\n    'Japan-': 127e6\n}\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#######################################################\n# SIR model with INTERVENTION\n#------------------------------------------------------\n# params:\n#\n# x          : array of number of days since inception (not used except to size output); in the calibration below, inception starts on the first day reported fatalities reach a CUTOFF threshold\n# i0         : initial percentage of infected population, for 1 per million: i0 = 1e-6\n# beta       : initial daily rate of transmission by infected people to susceptible people, for R0=2.7 and gamma=1/21: beta=R0*gamma=2.7/21 \n# gamma      : daily rate of recovery or death of infected people, for a 21 day speed of recovery or death: gamma = 1/21\n# death_rate : daily death rate of infected people (assuming 1% of infected people die about 3 weeks after infection: death_rate=0.01/21)\n#\n# intervention_day : number of days after inception for intervention to start to reduce the initial transmission rate (beta)\n# intervention_lag : number of days it takes for intervention to reach full effect (linear interp)\n# intervention_effect : percentage reduction of initial transmission  rate, 0.25 for 25% reduction of initial beta after full intervention takes effect\n########################################################\n\n#-------------------------------------------------------\n#the number returned by this function will be multiplied with the initial beta in order to estimate the transmission rate each day of the simulation\ndef intervention(day, day0, lag=5, effect=0.25):\n    if day>day0+lag:\n        return 1.0 - effect\n    if day>day0:\n        return 1.0 - effect * (day-day0)/lag\n    return 1.0\n\n'''\ndays = np.arange(300)\neffects = np.zeros(300)\nfor d in days:\n    effects[d] = intervention(d, 200, 3, 0.75)\nplt.plot(days, effects)\nplt.show()\n'''\n\n#-------------------------------------------------------\n# basic daily integration of a classic SIR model with a time-variable beta parameter=beta*intervention(day)\n# the function returns a numpy matrix, with a row per day and the following columns (cumulative results since day of inception)\ncS  = 0  #Susceptible people\ncI  = 1  #Infected people\ncR  = 2  #Recovered people\ncF  = 3  #Fatalities\ncP  = 4  #Positive cases (recovered people are not included)\n\ndef SIR4(x, population, i0, mixing, beta, phi, q, gamma, death_rate, intervention_day, intervention_lag, intervention_effect, detection_rate):\n    \n    y = np.zeros((x.size,5))\n\n    for i in range(0,x.size):\n        \n        if i==0:\n            #initial conditions\n            infected = i0\n            susceptible = population - i0\n            recovered = 0.0\n            positives = detection_rate * i0\n            fatalities = gamma / (beta-gamma) * death_rate / detection_rate * positives\n          \n        else:\n            #compute daily variations           \n            rate = beta * intervention(i, intervention_day, intervention_lag, intervention_effect)\n            rate = rate *((1-phi)*math.exp(-i*q)+phi)\n            \n            d_fatalities = death_rate * infected\n            d_recovered = (gamma - death_rate) * infected\n            \n            newlyinfected = rate * susceptible * pow(infected,mixing) / population  #newly infected people\n            d_infected = newlyinfected - gamma * infected \n            d_susceptible = - newlyinfected\n            d_positives = detection_rate * newlyinfected\n            \n            #integrate and store in result array\n            susceptible += d_susceptible\n            positives += d_positives\n            infected += d_infected\n            recovered += d_recovered\n            fatalities += d_fatalities\n            \n        y[i,cS] = susceptible\n        y[i,cI] = infected\n        y[i,cR] = recovered\n        y[i,cF] = fatalities\n        y[i,cP] = positives  #cumul of infected, does not come down on recovery. assuming all newly infected people are immediately detected\n            \n    return y\n\n\nx = np.arange(300)\n\n#plot number of fatalities \n#in a population on 1 million people, with one person initially infected, \n#assuming 3 weeks recovery rate, intial R0=5 and 1% death rate for infected people\npopulation = 1e6  \n\n#baseline: intervention has no effect in reducing initial transmission rate\ny0 = SIR4(x, population=population, i0=1, mixing=1, beta=5/21, phi=1, q=1, gamma=1.0/21, death_rate=0.01/21, \n         intervention_day = 0, intervention_lag = 3, intervention_effect = 0, detection_rate=1)\n\n# intervention starts on day 100 and results in 80% reduction of initial transmission rate 3 days later\ny = SIR4(x, population=population, i0=1, mixing=1, beta=5/21, phi=1, q=1, gamma=1.0/21, death_rate=0.01/21, \n         intervention_day = 60, intervention_lag = 3, intervention_effect = 0.30, detection_rate=1)\n\n\nfig,axs = plt.subplots(2,1, figsize=[8,8])\n\nplt.subplot(211)\nplt.title('Daily Fatalities')\nplt.plot(x[1:], np.diff(y[:,cF]),'r-',label='daily fatalities (intervention)')\nplt.plot(x[1:], np.diff(y0[:,cF]),'k-',label='daily fatalities (baseline)')\nplt.legend()\n\nplt.subplot(212)\nplt.title('Cumulative Fatalities')\nplt.plot(x, y[:,cF],'r-',label='Fatalities (intervention)')\nplt.plot(x, y0[:,cF],'k-',label='Fatalities (baseline)')\nplt.legend()\n\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.arange(200)\n\n#plot number of fatalities \n#in a population on 1 million people, with one person initially infected, \n#assuming 3 weeks recovery rate, intial R0=5 and 1% death rate for infected people\npopulation = 1e6  \ni0=100\ngamma = 1/14\nR0 = 3\nbeta = R0 * gamma\ndeath_rate = 0.01 * gamma\n\ny25 = SIR4(x, population=population, i0=i0, mixing=1, beta=2.5*gamma, phi=1, q=1, gamma=gamma, death_rate=death_rate, intervention_day = 0, intervention_lag = 0, intervention_effect = 0, detection_rate=1)\ny30 = SIR4(x, population=population, i0=i0, mixing=1, beta=3.0*gamma, phi=1, q=1, gamma=gamma, death_rate=death_rate, intervention_day = 0, intervention_lag = 0, intervention_effect = 0, detection_rate=1)\ny35 = SIR4(x, population=population, i0=i0, mixing=1, beta=3.5*gamma, phi=1, q=1, gamma=gamma, death_rate=death_rate, intervention_day = 0, intervention_lag = 0, intervention_effect = 0, detection_rate=1)\n\nfig,axs = plt.subplots(1,2, figsize=[12,6])\nax = plt.subplot(121)\nplt.title('Daily Fatalities')\nplt.plot(x[1:], np.diff(y25[:,cF]),'b-',label='R0=2.5')\nplt.plot(x[1:], np.diff(y30[:,cF]),'r-',label='R0=3.0')\nplt.plot(x[1:], np.diff(y35[:,cF]),'k-',label='R0=3.5')\nax.yaxis.set_major_formatter(FuncFormatter(lambda x, p: format(int(x), ',')))\nplt.xlabel('days since inception')\nplt.legend()\nplt.grid()\n\nax = plt.subplot(122)\nplt.title('Cumulative Fatalities')\nplt.plot(x, y25[:,cF],'b-',label='R0=2.5')\nplt.plot(x, y30[:,cF],'r-',label='R0=3.0')\nplt.plot(x, y35[:,cF],'k-',label='R0=3.5')\nax.yaxis.set_major_formatter(FuncFormatter(lambda x, p: format(int(x), ',')))\nplt.legend()\nplt.xlabel('days since inception')\nplt.grid()\n\ncaption = 'Daily and cumulative fatalities over time for a population of 1 million, 100 individuals are initially infected, \\n14 days to recovery, 1% fatality rate\\nR0 indicates the percentage of still susceptible people each infectious person will contaminate during their illness'\nfig.text(.5, 1, caption, ha='center')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.arange(150)\n\n#plot number of fatalities \n#in a population on 1 million people, with one person initially infected, \n#assuming 3 weeks recovery rate, intial R0=5 and 1% death rate for infected people\npopulation = 1e6  \ni0=100\ngamma = 1/14\nR0 = 2\nbeta = R0 * gamma\ndeath_rate = 0.01 * gamma\n\ny1 = SIR4(x, population=population, i0=i0, mixing=1, beta=beta, phi=1, q=1, gamma=gamma, death_rate=death_rate, intervention_day = 0, intervention_lag = 0, intervention_effect = 0, detection_rate=1)\ny95 = SIR4(x, population=population, i0=i0, mixing=0.95, beta=beta, phi=1, q=1, gamma=gamma, death_rate=death_rate, intervention_day = 0, intervention_lag = 0, intervention_effect = 0, detection_rate=1)\ny90 = SIR4(x, population=population, i0=i0, mixing=0.90, beta=beta, phi=1, q=1, gamma=gamma, death_rate=death_rate, intervention_day = 0, intervention_lag = 0, intervention_effect = 0, detection_rate=1)\n\nfig,axs = plt.subplots(1,2, figsize=[12,6])\nax = plt.subplot(121)\nplt.title('Daily Fatalities')\nplt.plot(x[1:], np.diff(y1[:,cF]),'b-',label='mixing=1.00')\nplt.plot(x[1:], np.diff(y95[:,cF]),'r-',label='mixing=0.95')\nplt.plot(x[1:], np.diff(y90[:,cF]),'k-',label='mixing=0.90')\nax.yaxis.set_major_formatter(FuncFormatter(lambda x, p: format(int(x), ',')))\nplt.yscale('log')\nplt.xlabel('days since inception')\nplt.legend()\nplt.grid()\n\nax = plt.subplot(122)\nplt.title('Cumulative Fatalities')\nplt.plot(x, y1[:,cF],'b-',label='mixing=1.00')\nplt.plot(x, y95[:,cF],'r-',label='mixing=0.95')\nplt.plot(x, y90[:,cF],'k-',label='mixing=0.90')\nax.yaxis.set_major_formatter(FuncFormatter(lambda x, p: format(int(x), ',')))\nplt.yscale('log')\nplt.legend()\nplt.xlabel('days since inception')\nplt.grid()\n\ncaption = 'Daily and cumulative fatalities over time for a population of 1 million, 100 individuals are initially infected, \\n14 days to recovery, 1% fatality rate\\nR0 indicates the percentage of still susceptible people each infectious person will contaminate during their illness'\nfig.text(.5, 1, caption, ha='center')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.arange(200)\n\n#plot number of fatalities \n#in a population on 1 million people, with one person initially infected, \n#assuming 3 weeks recovery rate, intial R0=5 and 1% death rate for infected people\npopulation = 1e6  \ni0=100\nmixing=1\ngamma = 1/14\nR0 = 3\nbeta = R0 * gamma\nphi=1\nq=1\ndeath_rate = 0.01 * gamma\n\ny0 = SIR4(x, population=population, i0=i0, mixing=1, beta=3.0*gamma, phi=1, q=1, gamma=gamma, death_rate=death_rate, intervention_day = 0, intervention_lag = 0, intervention_effect = 0, detection_rate=1)\ny1 = SIR4(x, population=population, i0=i0, mixing=1, beta=3.0*gamma, phi=1, q=1, gamma=gamma, death_rate=death_rate, intervention_day = 20, intervention_lag = 1, intervention_effect = 0.3, detection_rate=1)\n\nfig,axs = plt.subplots(1,2, figsize=[12,6])\nax = plt.subplot(121)\nplt.title('Daily Fatalities')\nplt.plot(x[1:], np.diff(y0[:,cF]),'r-',label='no intervention')\nplt.plot(x[1:], np.diff(y1[:,cF]),'k-',label='with intervention')\nax.yaxis.set_major_formatter(FuncFormatter(lambda x, p: format(int(x), ',')))\nplt.xlabel('days since inception')\nplt.legend()\nplt.grid()\n\nax = plt.subplot(122)\nplt.title('Cumulative Fatalities')\nplt.plot(x, y0[:,cF],'r-',label='no intervention')\nplt.plot(x, y1[:,cF],'k-',label='with intervention')\nax.yaxis.set_major_formatter(FuncFormatter(lambda x, p: format(int(x), ',')))\nplt.legend()\nplt.xlabel('days since inception')\nplt.grid()\n\ncaption = 'Daily and cumulative fatalities over time for a population of 1 million, 100 individuals are initially infected, \\n14 days to recovery, 1% fatality rate\\ninitial R0=3.0 is the percentage of still susceptible people each infectious person will contaminate during their illness, before intervention \\n intervention starts on day 20 and reaches full effect 1 day after, intervention reduces R0 by 30%'\nfig.text(.5, 1, caption, ha='center')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#extract the data for the given region or state and prepare it for the calibration\ndef prep_data(data, region='US', state='New York', cutoff=1, truncate=0):\n    \n    c = data[data['Region']==region]\n    if state != '':\n        c = c[c['State']==state]\n    \n    c = c.groupby(['Date']).sum().reset_index()\n    \n    state = region + '-' + state\n    c['State'] = state\n\n    #find the first date when the fatalities cutoff was reached by this STATE, and keep only these days for calibration\n    minDate = c[c['Fatalities']>cutoff]['Date'].min()\n    \n    s1 = c[c['Date']>minDate].copy()  #keep only the records after the given number of fatalities have been reached\n    if truncate>0:\n        s1 = s1[:truncate].copy()  #keep only the given number of days\n\n    #calculate the number of days since the first day fatalities exceeded the cutoff\n    s1['Days'] = (s1['Date'] - minDate) / np.timedelta64(1, 'D')\n\n    return minDate, s1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef earlygrowth(data, region, state, cutoff):\n    \n    def growthmodel(x, **kwargs):  \n        r = kwargs['r']\n        a = kwargs['a']\n        return np.exp(a * x) * r\n\n    #https://arxiv.org/abs/1709.00973  \n    #solution of sub-exponential growth of the form df/dt = r.f(t)^a\n    def subgrowthmodel(x, a, b, r):\n        if a==1:\n            return b * np.exp(r*x)\n        else:\n            return (r*(1-a)*x + b**(1-a))**(1/(1-a))\n\n    minDate, s1 = prep_data(data, region=region, state=state, cutoff=cutoff, truncate=0)\n    population = Population[region + '-' + state]\n\n    s1['NewFatalities'] = s1['Fatalities'].diff()\n    s1['NewCases'] = s1['ConfirmedCases'].diff()\n\n    x = s1['Days'].copy()\n\n    fig, axs=  plt.subplots(1,3, figsize=(12,6))\n\n    ax = plt.subplot(131)\n    plt.plot(s1['Days'],s1['NewFatalities'], label='new fatalities')\n    plt.plot(s1['Days'],s1['Fatalities'], label='fatalities')\n    plt.plot(s1['Days'],s1['ConfirmedCases'], label='positives')\n    plt.yscale('log')\n    plt.legend()\n\n    ax = plt.subplot(132)\n    plt.plot(s1['Days'],s1['ConfirmedCases'], 'ko', label='positives')\n    print(\"{}-{} positives:\".format(region,state))\n    z = s1['ConfirmedCases'].copy()\n    for n in range(5, min(15,x.shape[0])):\n        popt, pcov = curve_fit(subgrowthmodel,x[:n], z[:n]/population, bounds=((0.6,0,0),(1,1,1)), p0=(0.9,1e-9,2/14))\n        print(popt)\n        y1 = population * subgrowthmodel(x, a=popt[0], b=popt[1], r=popt[2])\n        plt.plot(s1['Days'][:n],y1[:n], label='{} - {:.2f}'.format(n, popt[0]))\n    plt.yscale('log')\n    plt.legend()\n\n    ax = plt.subplot(133)\n    plt.plot(s1['Days'],s1['Fatalities'], 'ko', label='deaths')\n    print(\"{}-{} fatalities:\".format(region,state))\n    z = s1['Fatalities'].copy()\n    for n in range(5, min(10,x.shape[0])):\n        popt, pcov = curve_fit(subgrowthmodel,x[:n], z[:n]/population, bounds=((0.6,0,0),(1,1,1)), p0=(0.9,1e-9,2/14))\n        print(popt)\n        y1 = population * subgrowthmodel(x, a=popt[0], b=popt[1], r=popt[2])\n        plt.plot(s1['Days'][:n],y1[:n], label='{} - {:.2f}'.format(n, popt[0]))\n    plt.yscale('log')\n    plt.legend()\n\n    plt.show()\n\nregion=\"EU\"\nstate=\"Italy\"\nearlygrowth(train, region=region, state=state, cutoff=10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###############################################\n####### CALIBRATION TO reported Fatalities\n####### with intervention\n###############################################\n\n\n\n#STATE = 'Italy'\n#STATE = 'France'\n#STATE = 'New York'\n#STATE = 'California'\n#STATE = 'Hubei'\n#STATE = 'North Dakota'\n#STATE = 'Florida'\n\n#Decide whether to calibrate the model on reported cumulative fatalities, or on daily new fatalities\n#0: calibrate on Fatalities; \n#1: calibrate on daily new fatalities\nCALIB_DIFF = 0\n\n\n\n\n#Function called by scipy.curve_fit to calibrate the model parameters \n#This function calls the SIR model to simulate on the current guess parameters, and formats the results for use by curve_fit()\n#note: SIR3() returns percentage of population, whereas reported data is absolute number of people, hence the need to use a total population number\n#note: this function calibrates the final death rate (eg 1% of infected people eventually die, rather than the instantaneous death rate)\ndef SIR4_calib(x, i0, mixing, beta, phi, q, gamma, death_rate,\n                    intervention_day, intervention_lag, intervention_effect, detection_rate, population, missing_data, scale_p):\n    \n    y = SIR4(x, population=population, i0=i0, mixing=mixing, beta=beta, phi=phi, q=q, gamma=gamma, death_rate = death_rate * gamma,\n            intervention_day = intervention_day, intervention_lag = intervention_lag, intervention_effect=intervention_effect, detection_rate=detection_rate)\n    \n    if CALIB_DIFF==1:\n        p = np.diff(y[:,cP])     #calculate the new daily positives\n        p = np.insert(p,0,0)\n\n        f = np.diff(y[:,cF])     #calculate the new daily fatatlies\n        f = np.insert(f,0,0)\n        \n        ret = np.append(p * scale_p, f)    #positive counts are rescaled to same order of magnitude as death count for calibration algorithm - see prep_data()\n        \n        ret = np.where(missing_data, 0, ret)\n\n        return ret\n    \n    else:\n        ret = np.append(y[:,cP] * scale_p, y[:,cF])    #positive counts are rescaled to same order of magnitude as death count for calibration algorithm - see prep_data()\n        ret = np.where(missing_data, 0, ret)\n        return ret\n\n#--------------------------\n#This function calibrates and shows the results for one State\n#data - DataFrame in the same format as train.csv but with Region and State columns added\n#output - boolean, True to print results and charts\n#cutoff - start simulation on the first day reported fatalities reach the cutoff level\n#truncate - keep only this number of days of dato calibrate \n#forecast - forecast for this number of days\n#\ndef calibrate(data, output=True, region='US', state='New York', cutoff=1, truncate=0, forecast=365):\n\n    if output:\n        print('-----------------')\n        print(region,'-',state)\n        print('-----------------')\n        print('')\n\n    population = Population[region + '-' + state]\n\n    #Bounds and initial guess for calibration algorithm scipy.curve_fit\n    I0_min = 1\n    I0_max = 1e6\n    Mixing_min = 0.8\n    Mixing_max = 1\n    Gamma_min = 1/14\n    Gamma_max = 1/4\n    Beta_min = 1.1 * Gamma_min\n    Beta_max = 6 * Gamma_max\n    Phi_min = 0.01 #0.9999\n    Phi_max = 1\n    Q_min = 1/(1e11)\n    Q_max = 1\n    DeathRate_min = 0.005\n    DeathRate_max = 0.05\n    InterventionDay_min = 1\n    InterventionDay_max = 25\n    InterventionLag_min = 1\n    InterventionLag_max = 100\n    InterventionEffect_min = 0\n    InterventionEffect_max = 0.95 \n    DetectionRate_min = 0\n    DetectionRate_max = 1\n\n    initial_guess = [I0_min, \n#                     Mixing_max,\n                     Beta_min,\n#                     Phi_max,\n#                     Q_min,\n                     Gamma_min,\n                     DeathRate_min, \n                     InterventionDay_max,  \n                     InterventionLag_min,\n                     InterventionEffect_min,\n                     DetectionRate_max]\n\n#    bounds = ((I0_min, Mixing_min, Beta_min, Phi_min, Q_min, Gamma_min, DeathRate_min, InterventionDay_min, InterventionLag_min, InterventionEffect_min, DetectionRate_min),\n#              (I0_max, Mixing_max, Beta_max, Phi_max, Q_max, Gamma_max, DeathRate_max, InterventionDay_max, InterventionLag_max, InterventionEffect_max, DetectionRate_max))\n\n    bounds = ((I0_min, Beta_min, Gamma_min, DeathRate_min, InterventionDay_min, InterventionLag_min, InterventionEffect_min, DetectionRate_min),\n              (I0_max, Beta_max, Gamma_max, DeathRate_max, InterventionDay_max, InterventionLag_max, InterventionEffect_max, DetectionRate_max))\n    \n\n    #study the early growth to figure out whether it is exponential or sub-exponential\n    if output:\n        earlygrowth(data, region=region, state=state, cutoff=10)\n    \n    #prepare the calibration data\n    #----------------------------\n   \n    #get the relevant data from the overall set\n    \n    minDate, s1 = prep_data(data, region=region, state=state, cutoff=cutoff, truncate=truncate)\n    x = s1['Days']\n    if output:\n        print(cutoff, \"Reported fatalities reached {} on {:%Y-%m-%d}\".format(cutoff, minDate))\n        print('')\n\n    \n    #calibrate on reported cumulative positives and fatalities, or on daily values\n    \n    calib_p = s1['ConfirmedCases'].copy()\n    scale_p = calib_p.max()\n\n    calib_f = s1['Fatalities'].copy()\n    scale_f = calib_f.max()\n\n    scale_p = scale_f / scale_p\n    \n    if CALIB_DIFF==1:\n        #calibrate on daily fatality numbers\n        z = calib_p.diff() * scale_p\n        z = z.append(calib_f.diff())\n        missing_data = np.isnan(z) #record where we do not have data, for use by SEIR_calib to ignore these points during the calibration\n        \n    else:\n        #calibrate on reported cumulative fatalities\n        z = calib_p * scale_p\n        z = z.append(calib_f)\n        missing_data = np.isnan(z) #record where we do not have data, for use by SEIR_calib to ignore these points during the calibration\n\n    z = np.nan_to_num(z)\n        \n    #calibrate the model\n    #use a lambda to pass the population when running a simulation on guess parametes, but this is not a calibrated param\n    #-------------------\n\n#    popt, pcov = curve_fit(lambda x, i0, mixing, beta, phi, q, gamma, death_rate, intervention_day, intervention_lag, intervention_effect, detection_rate :\n#                               SIR4_calib(x, i0, mixing, beta, phi, q, gamma, death_rate, intervention_day, intervention_lag, intervention_effect, detection_rate, population, missing_data, scale_p),\n#                           x, z, bounds=bounds, p0=initial_guess)\n\n    calib_Mixing = 1\n\n    def simpleSIR(x, i0, beta, gamma, death_rate, intervention_day, intervention_lag, intervention_effect, detection_rate):\n        return SIR4_calib(x, i0=i0, mixing=calib_Mixing, beta=beta, phi=1, q=1, gamma=gamma, death_rate=death_rate, intervention_day=intervention_day, intervention_lag=intervention_lag, intervention_effect=intervention_effect, detection_rate=detection_rate, population=population, missing_data=missing_data, scale_p=scale_p)        \n    \n\n    popt, pcov = curve_fit(simpleSIR,x, z, bounds=bounds, p0=initial_guess)\n\n    calib_I0                 = popt[0]\n    calib_Mixing             = calib_Mixing\n    calib_Beta               = popt[1]\n    calib_Phi                = 1\n    calib_Q                  = 1\n    calib_Gamma              = popt[2]\n    calib_DeathRate          = popt[3]\n    calib_InterventionDay    = popt[4]\n    calib_InterventionLag    = popt[5]\n    calib_InterventionEffect = popt[6]\n    calib_DetectionRate      = popt[7]\n\n    if output:\n        print(\"SIR model fit\")\n        print(\"-------------\")\n        print(\"{} has a population of {:,.0f}\".format(state, population))\n        print(\"current fatalities are {:,.0f}\".format(s1['Fatalities'].iloc[-1]))\n        print(\"I0 = {:,.0f} per million, or {:,.0f} persons initially infected\".format(calib_I0/population*1e6, calib_I0))\n        print(\"MIXING = {:.2f}\".format(calib_Mixing))\n        print(\"BETA = {:.3f}\".format(calib_Beta))\n        print(\"PHI = {:.3f}\".format(calib_Phi))\n        print(\"Q = {:.3f}\".format(1/calib_Q))\n        print(\"GAMMA = {:.3f}, or {:.1f} days to recover\".format(calib_Gamma, 1/calib_Gamma))\n        print(\"DEATH RATE = {:.3%} infected people die\".format(calib_DeathRate))\n        print(\"Ro = {:.2f}\".format(calib_Beta/calib_Gamma))\n        print(\"Intervention Day = detected {:.0f} days after the cutoff, on {:%Y-%m-%d}\".format(calib_InterventionDay, minDate+timedelta(days=calib_InterventionDay)))\n        print(\"Intervention Lag = detected {:.0f} days for full intervention effect\".format(calib_InterventionLag))\n        print(\"Intervention Effect = detected {:.0%} reduction of initial transmission rate\".format(calib_InterventionEffect))\n        print(\"Detection Rate = {:.0%} infectious cases are reported as positives\".format(calib_DetectionRate))\n        #display(popt)\n\n    #compute model numbers for the calibration period\n    #------------------------------------------------\n\n    y = SIR4(x,population=population, i0=calib_I0, mixing=calib_Mixing, beta=calib_Beta, phi=calib_Phi, q=calib_Q, gamma=calib_Gamma, death_rate=calib_Gamma*calib_DeathRate,\n                         intervention_day = calib_InterventionDay, intervention_lag=calib_InterventionLag, intervention_effect = calib_InterventionEffect, detection_rate=calib_DetectionRate)\n\n    s1['fit Fatalities (SIR)'] = y[:,cF]  #reported stats are about new cases, they do not seem to account for people having recovered\n    s1['fit NewFatalities (SIR)'] = s1['fit Fatalities (SIR)'].diff()\n\n    s1['fit Cases (SIR)'] = y[:,cP]  #reported positive stats are about new cases, they do not seem to account for people having recovered\n    s1['fit NewCases (SIR)'] = s1['fit Cases (SIR)'].diff()\n\n    #display(s1.sort_values(by='Date',ascending=False))\n\n    #plot the model in comparison with calibrating data\n    #--------------------------------------------------\n\n    if output:\n        fig,axs = plt.subplots(nrows=3, ncols=2,figsize=[16,16])\n\n        plt.subplot(321)\n        plt.title(state + ' Fatalities')\n        plt.plot(x, s1['Fatalities'],'ko-',label='Actual')\n        plt.plot(x, s1['fit Fatalities (SIR)'],'r-',label='SIR')\n        plt.legend()\n        plt.grid()\n        #plt.yscale('log')\n\n        ax = plt.subplot(322)\n        plt.title(state + ' New Fatalities')\n        plt.plot(x, s1['NewFatalities'],'ko-',label='Actual')\n        plt.plot(x, s1['fit NewFatalities (SIR)'],'r-',label='SIR')\n        plt.legend()\n        plt.grid()\n        #plt.yscale('log')\n\n        ax = plt.subplot(323)\n        plt.title(state + ' Confirmed Cases')\n        plt.plot(x, s1['ConfirmedCases'],'ko-',label='Actual')\n        plt.plot(x, s1['fit Cases (SIR)'],'b-',label='SIR')\n        plt.legend()\n        plt.grid()\n        plt.yscale('log')\n        ax.yaxis.set_major_formatter(FuncFormatter(thousands))\n\n        ax = plt.subplot(324)\n        plt.title(state + ' New Cases')\n        plt.plot(x, s1['NewCases'],'ko-',label='Actual')\n        plt.plot(x, s1['fit NewCases (SIR)'],'b-',label='SIR')\n        plt.legend()\n        plt.grid()\n        plt.yscale('log')\n        ax.yaxis.set_major_formatter(FuncFormatter(thousands))\n\n    #long range forecast\n    #-------------------\n\n    xx = np.arange(forecast)\n    y = SIR4(xx, population=population, i0=calib_I0, mixing=calib_Mixing, beta=calib_Beta, phi=calib_Phi, q=calib_Q, gamma=calib_Gamma, death_rate=calib_Gamma*calib_DeathRate,\n                          intervention_day = calib_InterventionDay, intervention_lag=calib_InterventionLag, intervention_effect = calib_InterventionEffect, detection_rate=calib_DetectionRate)\n\n\n    idx = np.argmax( np.diff(y[:,cF])).item()   #peak daily fatalities\n    max_dailyfatalities_day = minDate+timedelta(days=idx)\n    max_dailyfatalities_rate = np.diff(y[:,cF])[idx]\n    total_fatalities = y[-1,cF]\n\n    if output:\n        print(\"\")\n        print(\"SIR long range forecast\")\n        print(\"-----------------------\")\n        print(\"Daily New Fatalities would peak day {:,}, on {:%Y-%m-%d}, at {:,.0f} fatalities per day\".format(idx,max_dailyfatalities_day, max_dailyfatalities_rate))\n        print(\"Cumulative Fatalities would reach {:,.0f} after one year\".format(total_fatalities))\n\n        ax = plt.subplot(325)\n        plt.title(state + ' Forecast')\n        #plt.plot(xx, y[:,0],'g-',label='Susceptible')\n        plt.plot(xx, y[:,cI],'r-',label='Infected')\n        plt.plot(xx, y[:,cR],'b-',label='Recovered')\n        plt.plot(xx[1:], np.diff(y[:,cI]),'m-',label='Daily New Infections')\n        ax.yaxis.set_major_formatter(FuncFormatter(millions))\n        plt.legend()\n        plt.grid()\n        #plt.yscale('log')\n\n        ax = plt.subplot(326)\n        plt.title(state + ' Forecast')\n        lns2 = plt.plot(xx, y[:,cF],'c-',label='Fatalities (lhs)')\n        ax.yaxis.set_major_formatter(FuncFormatter(thousands))\n\n        ax2 = ax.twinx() #instantiate second y axis, share same x axis\n        lns3 = plt.plot(xx[1:], np.diff(y[:,cF]),'m-',label='Daily Fatalities (rhs)')\n        ax2.yaxis.set_major_formatter(FuncFormatter(thousands))\n\n        lns = lns2+lns3\n        labs = [l.get_label() for l in lns]\n        ax.legend(lns, labs, loc=0)\n        ax.grid()\n        #plt.yscale('log')\n\n        plt.show()\n    \n    result = {}\n    result['state'] = region + '-' + state\n    result['curr fatalities'] = s1['Fatalities'].iloc[-1]\n    result['population'] = population\n    result['cutoff'] = minDate\n    result['i0'] = calib_I0\n    result['mixing'] = calib_Mixing\n    result['phi'] = calib_Phi\n    result['q'] = calib_Q\n    result['gamma/d'] = 1/calib_Gamma\n    result['R0'] = calib_Beta / calib_Gamma\n    result['death rate'] = calib_DeathRate\n    result['interv'] = calib_InterventionDay\n    result['lag'] = calib_InterventionLag\n    result['effect'] = calib_InterventionEffect\n    result['detection'] = calib_DetectionRate\n    result['peak day'] = max_dailyfatalities_day\n    result['peak fatalities'] = max_dailyfatalities_rate\n    result['cum fatalities'] = total_fatalities\n\n    #print(result)\n    \n    return result, y\n    \n    \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#try to calibrate perfect data\n\nfrom datetime import datetime, timedelta\npopulation=Population['US-New York']\ni0=1\nmixing=1\ngamma=1/14\nbeta=2*gamma\nphi=1\nq=1\ndeath_rate=gamma*0.01\nintervention_day = 0\nintervention_lag=1\nintervention_effect = 0\ndetection_rate=0.3\n\nn=200\nx = np.arange(0,n)\ny0 =  SIR4(x, population=population, i0=i0, mixing=mixing, beta=beta, phi=phi, q=q, gamma=gamma, death_rate=death_rate,\n                  intervention_day=intervention_day, intervention_lag=intervention_lag, intervention_effect=intervention_effect, detection_rate=detection_rate)\n\ntest = pd.DataFrame(y0[:,cF], columns=['Fatalities'])\ntest['ConfirmedCases'] = y0[:,cP]\ntest['NewFatalities'] = test['Fatalities'].diff(1)/1\ntest['NewCases'] = test['ConfirmedCases'].diff(1)/1\ntest['Date'] = datetime(2020,1,1) + np.arange(n) * timedelta(days=1)\ntest['Region']='US'\ntest['State']='New York'\n\ntest['I'] = y0[:,cI]\n\n\ndisplay(test.tail())\n\n#########\nminDate, s1 = prep_data(test, region='US', state='New York', cutoff=10, truncate=0)\n\nn=5\nfrom scipy import stats\nslopeI, interceptI, r_value, p_value, std_err = stats.linregress(x[:n], np.log(s1['I'][:n]))        #np.log(y[:n,cI]))\nprint(\"beta-gamma: %.3f true beta-gamma:  %.3f   I0: %f\" % (slopeI, beta-gamma, np.exp(interceptI)))\n\nslopeR, interceptR, r_value, p_value, std_err = stats.linregress(x[:n], np.log(s1['Fatalities'][:n]))\nprint(\"beta-gamma: %.3f true beta-gamma:  %.3f   intercept: %f\" % (slopeR, beta-gamma, np.exp(interceptR)))\n\n\n########\nres, y = calibrate(test,output=True, region='US', state='New York', cutoff=1, truncate=0, forecast=365)\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nstudies = [\n    ['China',''],\n    ['US',''],\n    ['EU',''],\n    ['EU','France'],\n    ['EU', 'Italy'],\n    ['EU', 'Spain'],\n    ['EU', 'United Kingdom'],\n    ['US', 'New York'],\n    ['US', 'California']]\n\n\nfig,ax = plt.subplots(figsize=[8,8])\nplt.title('')\nplt.legend()\n\nres = []\nfor s in studies:\n    try:\n        state = '{}-{}'.format(s[0],s[1])\n        r,y = calibrate(train, output=False, region=s[0], state=s[1], cutoff=1, truncate=0, forecast=365)\n        res. append(r)\n        plt.plot(np.diff(y[:,cF]),'k-',label=state)\n    except:\n        print(state, \" failed to calibrate\")\n\n    \nres2 = pd.DataFrame(res)\n\nformat_dict = {'population':'{:,.0f}', \n               'curr fatalities': '{:,.0f}',\n               'cutoff':'{:%Y-%m-%d}',\n               'i0/m': '{:.0f}',\n               'gamma/d': '{:.0f}',\n               'R0': '{:.1f}',\n               'death rate': '{:.1%}',\n               'interv': '{:.0f}',\n               'lag': '{:.0f}',\n               'effect': '{:.0%}',\n               'detection': '{:.0%}',\n               'peak day':'{:%Y-%m-%d}',\n               'peak fatalities': '{:,.0f}',\n               'cum fatalities': '{:,.0f}',\n              }\n\ndisplay(res2.style.format(format_dict).hide_index())\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"USStates = train[train['Region']=='US']['State'].unique()\n\nres = []\n\nfig,ax = plt.subplots(figsize=[8,8])\nplt.title('')\nplt.legend()\n\nfor s in USStates:\n    try:\n        r,y = calibrate(train, output=False, region='US', state=s, cutoff=1, truncate=0, forecast=365)\n        res. append(r)\n        plt.plot(np.diff(y[:,cF]),'k-',label=state)\n    except:\n        print(s, \" failed to calibrate\")\n        \nres2 = pd.DataFrame(res)\n\nprint('total fatalities could be {:,.0f}'.format(res2['cum fatalities'].sum()))\n\ndisplay(res2.sort_values(by='curr fatalities', ascending=False).style.format(format_dict).hide_index())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"region = 'EU'  \ndisplay(train[train['Region']==region]['State'].unique())\n\nr = calibrate(train, output=True, region=region, state='Italy', cutoff=1, truncate=0, forecast=365)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"region = 'EU'  \ndisplay(train[train['Region']==region]['State'].unique())\n\nr = calibrate(train, output=True, region=region, state='France', cutoff=1, truncate=0, forecast=365)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"region = 'EU'  \ndisplay(train[train['Region']==region]['State'].unique())\n\nr = calibrate(train, output=True, region=region, state='United Kingdom', cutoff=1, truncate=0, forecast=365)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"region = 'EU'  \ndisplay(train[train['Region']==region]['State'].unique())\n\nr = calibrate(train, output=True, region=region, state='Spain', cutoff=1, truncate=0, forecast=365)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"region = 'EU'  \ndisplay(train[train['Region']==region]['State'].unique())\n\nr = calibrate(train, output=True, region=region, state='Sweden', cutoff=1, truncate=0, forecast=365)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"region = 'US'    #US, China\ndisplay(train[train['Region']==region]['State'].unique())\n\nr = calibrate(train, output=True, region=region, state='New York', cutoff=1, truncate=0, forecast=365)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"region = 'US'  \ndisplay(train[train['Region']==region]['State'].unique())\n\nr = calibrate(train, output=True, region=region, state='California', cutoff=1, truncate=0, forecast=365)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"region = 'US'  \ndisplay(train[train['Region']==region]['State'].unique())\n\nr = calibrate(train, output=True, region=region, state='Connecticut', cutoff=1, truncate=0, forecast=365)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"region = 'US'   \ndisplay(train[train['Region']==region]['State'].unique())\n\nr = calibrate(train, output=True, region=region, state='Illinois', cutoff=1, truncate=0, forecast=365)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"region = 'China'    #US, China\ndisplay(train[train['Region']==region]['State'].unique())\n\nr = calibrate(train, output=True, region=region, state='Hubei', cutoff=1, truncate=0, forecast=365)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train['Country_Region'].unique()\n#train['Province_State'].unique()\n\nregion = 'Japan'   \ndisplay(train[train['Region']==region]['State'].unique())\n\nr = calibrate(train, output=True, region=region, state='', cutoff=1, truncate=0, forecast=365)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#study the stability of the calibration on the China timeseries\n#run the calibration as it would have been performed every day in the past on data then available, and plot the results\n\n\n\ndef backtest(data, region, state):\n\n    minDate, s1 = prep_data(data, region=region, state=state, cutoff=1, truncate=0)\n    start_run = 14  #start running the calibration 2 weeks after the report of one fatality\n    end_run = s1.shape[0] - start_run #run the calibration every day until today\n    print(start_run, end_run)\n\n    #run the latest calibration as benchmark, and get the most accurate estimate for the timing of gov. intervention\n    r,y = calibrate(data, output=True, region=region, state=state, cutoff=1, truncate=0, forecast=250)\n    interv = r['interv']\n    effect = r['effect']\n\n    res = []\n\n    fig,ax = plt.subplots(figsize=[8,8])\n    plt.title('')\n    plt.yscale('log')\n\n\n    for d in range(start_run, end_run):\n        try:\n            r,y = calibrate(data, output=False, region=region, state=state, cutoff=1, truncate=d, forecast=250)\n            r['truncated'] = d  #record the day for which this calibration would have been done\n            res. append(r)\n\n            if d>interv:  #we are running a calibration with data published after the intervention\n                if r['effect'] < 0.5 * effect:  #has the effect been detected yet\n                    style = 'g-'  #calibration after intervention but effect is not detected \n                else:\n                    style = 'b-'  #calibration after intervention and effect is detected\n            else:\n                style = 'r-'  #calibration with data prior intervention\n\n            plt.plot(np.diff(y[:,cF]),style,label=d)\n        except:\n            print(d, \" failed to calibrate\")\n\n    plt.show()\n\n    res2 = pd.DataFrame(res)\n\n    fig, axs = plt.subplots(3,1,figsize=(12,6))\n\n    ax = plt.subplot(311)\n    plt.plot(res2['cum fatalities'],'ko-')\n    plt.plot(res2['peak fatalities'], 'b*-')\n    plt.yscale('log')\n    plt.legend()\n\n    ax = plt.subplot(312)\n    plt.plot(res2['gamma/d'],'ko-')\n    plt.plot(res2['death rate']*100, 'r*-')\n    plt.legend()\n    res2 = pd.DataFrame(res)\n\n    ax = plt.subplot(313)\n    plt.plot(res2['R0'], 'b*-')\n    plt.legend()\n\n    plt.show()\n\n    format_dict2 = {'population':'{:,.0f}', \n                   'curr fatalities': '{:,.0f}',\n                   'cutoff':'{:%Y-%m-%d}',\n                   'i0/m': '{:.0f}',\n                   'gamma/d': '{:.0f}',\n                   'R0': '{:.1f}',\n                   'death rate': '{:.1%}',\n                   'interv': '{:.0f}',\n                   'lag': '{:.0f}',\n                   'effect': '{:.0%}',\n                   'peak day':'{:%Y-%m-%d}',\n                   'peak fatalities': '{:,.0f}',\n                   'cum fatalities': '{:,.0f}',\n                  }\n\n    display(res2.style.format(format_dict2).hide_index())        \n        \n\nregion = 'China' \nstate  = 'Hubei'\nbacktest(train, region, state)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"backtest(test,'US','California')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#--------------------------\n#This function calibrates and shows the results for one State\n#data - DataFrame in the same format as train.csv but with Region and State columns added\n#output - boolean, True to print results and charts\n#cutoff - start simulation on the first day reported fatalities reach the cutoff level\n#truncate - keep only this number of days of dato calibrate \n#forecast - forecast for this number of days\n#\ndef calibrate2(data, output=True, region='US', state='New York', mixing=1, gamma=1/14, death_rate = 0.01, cutoff=1, truncate=0, forecast=365):\n\n    if output:\n        print('-----------------')\n        print(region,'-',state)\n        print('-----------------')\n        print('')\n\n    population = Population[region + '-' + state]\n\n    #Bounds and initial guess for calibration algorithm scipy.curve_fit\n\n    Beta_min = 0.5 * gamma\n    Beta_max = 5 * gamma\n    InterventionDay_min = 1\n    InterventionDay_max = 25\n    InterventionEffect_min = 0\n    InterventionEffect_max = 1\n    DetectionRate_min = 0\n    DetectionRate_max = 1\n\n    initial_guess = [Beta_min,\n                     InterventionDay_max,  \n                     InterventionEffect_min,\n                     DetectionRate_max]\n\n    bounds = ((Beta_min, InterventionDay_min, InterventionEffect_min, DetectionRate_min),\n              (Beta_max, InterventionDay_max, InterventionEffect_max, DetectionRate_max))\n    \n\n    #study the early growth to figure out whether it is exponential or sub-exponential\n#    if output:\n#        earlygrowth(data, region=region, state=state, cutoff=10)\n    \n    #prepare the calibration data\n    #----------------------------\n   \n    #get the relevant data from the overall set\n    \n    minDate, s1 = prep_data(data, region=region, state=state, cutoff=cutoff, truncate=truncate)\n    x = s1['Days']\n    if output:\n        print(cutoff, \"Reported fatalities reached {} on {:%Y-%m-%d}\".format(cutoff, minDate))\n        print('')\n\n    \n    #calibrate on reported cumulative positives and fatalities, or on daily values\n    \n    calib_p = s1['ConfirmedCases'].copy()\n    scale_p = calib_p.max()\n\n    calib_f = s1['Fatalities'].copy()\n    scale_f = calib_f.max()\n\n    scale_p = scale_f / scale_p\n    \n    #calibrate on reported cumulative fatalities\n    z = calib_p * scale_p\n    z = z.append(calib_f)\n    missing_data = np.isnan(z) #record where we do not have data, for use by SEIR_calib to ignore these points during the calibration\n\n    z = np.nan_to_num(z)\n        \n    #calibrate the model\n    #use a lambda to pass the population when running a simulation on guess parametes, but this is not a calibrated param\n    #-------------------\n    \n    currPos = s1['ConfirmedCases'].iloc[0]\n\n    def simpleSIR(x, beta, intervention_day, intervention_effect, detection_rate):\n        return SIR4_calib(x, i0=currPos, mixing=mixing, beta=beta, phi=1, q=1, gamma=gamma, death_rate=death_rate, intervention_day=intervention_day, intervention_lag=1, intervention_effect=intervention_effect, detection_rate=detection_rate, population=population, missing_data=missing_data, scale_p=scale_p)        \n    \n\n    popt, pcov = curve_fit(simpleSIR,x, z, bounds=bounds, p0=initial_guess)\n\n    \n    calib_Mixing             = mixing\n    calib_Beta               = popt[0]\n    calib_Phi                = 1\n    calib_Q                  = 1\n    calib_Gamma              = gamma\n    calib_DeathRate          = death_rate\n    calib_InterventionDay    = popt[1]\n    calib_InterventionLag    = 1\n    calib_InterventionEffect = popt[2]\n    calib_DetectionRate      = popt[3]\n    calib_I0                 = currPos / calib_DetectionRate\n\n    if output:\n        print(\"SIR model fit\")\n        print(\"-------------\")\n        print(\"{} has a population of {:,.0f}\".format(state, population))\n        print(\"current fatalities are {:,.0f}\".format(s1['Fatalities'].iloc[-1]))\n        print(\"I0 = {:,.0f} per million, or {:,.0f} persons initially infected\".format(calib_I0/population*1e6, calib_I0))\n        print(\"MIXING = {:.2f}\".format(calib_Mixing))\n        print(\"BETA = {:.3f}\".format(calib_Beta))\n        print(\"PHI = {:.3f}\".format(calib_Phi))\n        print(\"Q = {:.3f}\".format(1/calib_Q))\n        print(\"GAMMA = {:.3f}, or {:.1f} days to recover\".format(calib_Gamma, 1/calib_Gamma))\n        print(\"DEATH RATE = {:.3%} infected people die\".format(calib_DeathRate))\n        print(\"Ro = {:.2f}\".format(calib_Beta/calib_Gamma))\n        print(\"Intervention Day = detected {:.0f} days after the cutoff, on {:%Y-%m-%d}\".format(calib_InterventionDay, minDate+timedelta(days=calib_InterventionDay)))\n        print(\"Intervention Lag = detected {:.0f} days for full intervention effect\".format(calib_InterventionLag))\n        print(\"Intervention Effect = detected {:.0%} reduction of initial transmission rate\".format(calib_InterventionEffect))\n        print(\"Detection Rate = {:.0%} infectious cases are reported as positives\".format(calib_DetectionRate))\n        #display(popt)\n\n    #compute model numbers for the calibration period\n    #------------------------------------------------\n\n    y = SIR4(x,population=population, i0=calib_I0, mixing=calib_Mixing, beta=calib_Beta, phi=calib_Phi, q=calib_Q, gamma=calib_Gamma, death_rate=calib_Gamma*calib_DeathRate,\n                         intervention_day = calib_InterventionDay, intervention_lag=calib_InterventionLag, intervention_effect = calib_InterventionEffect, detection_rate=calib_DetectionRate)\n\n    s1['fit Fatalities (SIR)'] = y[:,cF]  #reported stats are about new cases, they do not seem to account for people having recovered\n    s1['fit NewFatalities (SIR)'] = s1['fit Fatalities (SIR)'].diff()\n\n    s1['fit Cases (SIR)'] = y[:,cP]  #reported positive stats are about new cases, they do not seem to account for people having recovered\n    s1['fit NewCases (SIR)'] = s1['fit Cases (SIR)'].diff()\n\n    #display(s1.sort_values(by='Date',ascending=False))\n\n    #plot the model in comparison with calibrating data\n    #--------------------------------------------------\n\n    if output:\n        fig,axs = plt.subplots(nrows=3, ncols=2,figsize=[16,16])\n\n        plt.subplot(321)\n        plt.title(state + ' Fatalities')\n        plt.plot(x, s1['Fatalities'],'ko-',label='Actual')\n        plt.plot(x, s1['fit Fatalities (SIR)'],'r-',label='SIR')\n        plt.legend()\n        plt.grid()\n        #plt.yscale('log')\n\n        ax = plt.subplot(322)\n        plt.title(state + ' New Fatalities')\n        plt.plot(x, s1['NewFatalities'],'ko-',label='Actual')\n        plt.plot(x, s1['fit NewFatalities (SIR)'],'r-',label='SIR')\n        plt.legend()\n        plt.grid()\n        #plt.yscale('log')\n\n        ax = plt.subplot(323)\n        plt.title(state + ' Confirmed Cases')\n        plt.plot(x, s1['ConfirmedCases'],'ko-',label='Actual')\n        plt.plot(x, s1['fit Cases (SIR)'],'b-',label='SIR')\n        plt.legend()\n        plt.grid()\n        plt.yscale('log')\n        ax.yaxis.set_major_formatter(FuncFormatter(thousands))\n\n        ax = plt.subplot(324)\n        plt.title(state + ' New Cases')\n        plt.plot(x, s1['NewCases'],'ko-',label='Actual')\n        plt.plot(x, s1['fit NewCases (SIR)'],'b-',label='SIR')\n        plt.legend()\n        plt.grid()\n        plt.yscale('log')\n        ax.yaxis.set_major_formatter(FuncFormatter(thousands))\n\n    #long range forecast\n    #-------------------\n\n    xx = np.arange(forecast)\n    y = SIR4(xx, population=population, i0=calib_I0, mixing=calib_Mixing, beta=calib_Beta, phi=calib_Phi, q=calib_Q, gamma=calib_Gamma, death_rate=calib_Gamma*calib_DeathRate,\n                          intervention_day = calib_InterventionDay, intervention_lag=calib_InterventionLag, intervention_effect = calib_InterventionEffect, detection_rate=calib_DetectionRate)\n\n\n    idx = np.argmax( np.diff(y[:,cF])).item()   #peak daily fatalities\n    max_dailyfatalities_day = minDate+timedelta(days=idx)\n    max_dailyfatalities_rate = np.diff(y[:,cF])[idx]\n    total_fatalities = y[-1,cF]\n\n    if output:\n        print(\"\")\n        print(\"SIR long range forecast\")\n        print(\"-----------------------\")\n        print(\"Daily New Fatalities would peak day {:,}, on {:%Y-%m-%d}, at {:,.0f} fatalities per day\".format(idx,max_dailyfatalities_day, max_dailyfatalities_rate))\n        print(\"Cumulative Fatalities would reach {:,.0f} after one year\".format(total_fatalities))\n\n        ax = plt.subplot(325)\n        plt.title(state + ' Forecast')\n        #plt.plot(xx, y[:,0],'g-',label='Susceptible')\n        plt.plot(xx, y[:,cI],'r-',label='Infected')\n        plt.plot(xx, y[:,cR],'b-',label='Recovered')\n        plt.plot(xx[1:], np.diff(y[:,cI]),'m-',label='Daily New Infections')\n        ax.yaxis.set_major_formatter(FuncFormatter(millions))\n        plt.legend()\n        plt.grid()\n        #plt.yscale('log')\n\n        ax = plt.subplot(326)\n        plt.title(state + ' Forecast')\n        lns2 = plt.plot(xx, y[:,cF],'c-',label='Fatalities (lhs)')\n        ax.yaxis.set_major_formatter(FuncFormatter(thousands))\n\n        ax2 = ax.twinx() #instantiate second y axis, share same x axis\n        lns3 = plt.plot(xx[1:], np.diff(y[:,cF]),'m-',label='Daily Fatalities (rhs)')\n        ax2.yaxis.set_major_formatter(FuncFormatter(thousands))\n\n        lns = lns2+lns3\n        labs = [l.get_label() for l in lns]\n        ax.legend(lns, labs, loc=0)\n        ax.grid()\n        #plt.yscale('log')\n\n        plt.show()\n    \n    result = {}\n    result['state'] = region + '-' + state\n    result['curr fatalities'] = s1['Fatalities'].iloc[-1]\n    result['population'] = population\n    result['cutoff'] = minDate\n    result['i0'] = calib_I0\n    result['mixing'] = calib_Mixing\n    result['phi'] = calib_Phi\n    result['q'] = calib_Q\n    result['gamma/d'] = 1/calib_Gamma\n    result['R0'] = calib_Beta / calib_Gamma\n    result['death rate'] = calib_DeathRate\n    result['interv'] = calib_InterventionDay\n    result['lag'] = calib_InterventionLag\n    result['effect'] = calib_InterventionEffect\n    result['detection'] = calib_DetectionRate\n    result['peak day'] = max_dailyfatalities_day\n    result['peak fatalities'] = max_dailyfatalities_rate\n    result['cum fatalities'] = total_fatalities\n\n    #print(result)\n    \n    return result, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calibrate2(train, output=True, region='US', state='California', mixing=1, gamma=1/14, death_rate=0.05, cutoff=1, truncate=0, forecast=365)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"region = 'EU'\nstate = 'Italy'\ncutoff=100\nmixing=1\n\nminDate, s1 = prep_data(train, region=region, state=state, cutoff=cutoff, truncate=0)\n\nfig, axs = plt.subplots(2,3, figsize=(16,8))\nfig.autofmt_xdate()\n\nn1 = 365 #forecast range from cutoff day\nn2 = 50 #plot range\nx = minDate + np.arange(n1) * timedelta(days=1)\n\nres = []\ncol=0\nfor gamma in [4, 7, 10]:\n\n    for death in [0.5, 1, 3, 5, 10]:\n        try:\n            r, y = calibrate2(train, output=False, region=region, state=state, mixing=mixing, gamma=1/gamma, death_rate = death/100, cutoff=cutoff, truncate=0, forecast=n1)\n            res.append(r)\n\n            plt.subplot(axs[0][col])\n            plt.plot(x[1:n2], np.diff(y[:n2,cF]),label='{}-{:.1%}'.format(gamma, death/100))\n\n            plt.subplot(axs[1][col])\n            plt.plot(x[:n2], y[:n2,cF],label='{}-{:.1%}'.format(gamma, death/100))\n        except:\n            print('{}-{:.1%} failed'.format(gamma,death/100))\n\n    col=col + 1\n    \nformat_dict2 = {'population':'{:,.0f}', \n               'curr fatalities': '{:,.0f}',\n               'cutoff':'{:%Y-%m-%d}',\n               'i0': '{:,.0f}',\n               'gamma/d': '{:.0f}',\n               'R0': '{:.1f}',\n               'death rate': '{:.1%}',\n               'detection': '{:.1%}',\n               'interv': '{:.0f}',\n               'lag': '{:.0f}',\n               'effect': '{:.0%}',\n               'peak day':'{:%Y-%m-%d}',\n               'peak fatalities': '{:,.0f}',\n               'cum fatalities': '{:,.0f}',\n              }\n\nres2 = pd.DataFrame(res)\ndisplay(res2.style.format(format_dict2).hide_index())        \n\nfor col in range(0,3):\n    ax = plt.subplot(axs[0][col])\n    plt.plot(s1['Date'][:n2], s1['NewFatalities'][:n2], 'k*')\n    plt.legend()\n    plt.grid()\n    plt.yscale('log')\n    plt.ylim((0, 1e4))   # set the ylim to bottom, top\n    ax.xaxis.set_major_formatter(mdates.DateFormatter('%B-%d'))\n\n    ax = plt.subplot(axs[1][col])\n    plt.plot(s1['Date'][:n2], s1['Fatalities'][:n2], 'k*')\n    plt.legend()\n    plt.grid()\n    plt.yscale('log')\n    plt.ylim((0, 1e6))   # set the ylim to bottom, top\n    ax.xaxis.set_major_formatter(mdates.DateFormatter('%B-%d'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}