{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Covid-19 Interactive EDA & SEIR-D Model ** <br>\nTeYang<br>\nCreated: 20/3/2020<br>\nLast update: 28/3/2020<br>\n\n<img src=\"https://www.tvw.org/wp-content/uploads/2020/03/COVID-19_image.jpg\" width=\"1000\" height=\"300\" align=\"center\"/>\n\nThis kernel provides some exploratory analysis of the trajectory of the Covid-19 spread throughout the world using interactive plots from Plotly. As of now, data is still limited with few features but hopefully, that will improve when more people and organizations share their data to help fight the pandemic. \n\nIn addition, I used an extension of the popular basic epidemiology **SIR** model, called **SEIR-D**. Briefly, the SIR model consists of 3 compartments, **S** for **Susceptible**, **I** for the number of **Infected** people, and **R** for the number of **Recovered or Deceased**. These 3 variables vary as a function of time, and sums up to the total population at every time point. The SEIR model adds an **E** for **Exposed** compartment, to differentiate between those who were in contact with the virus but still latent, from those who develop symptoms. One drawback of this model is that it does not distinguish between the recovered and fatalities, which is important information as the lethality of the virus will influence government healthcare policy and legislation. Therefore, an additional **D** for **Deceased** is added to the model.\n\nThis is my first time doing modelling on real data and I am still new to the field. As such, I had to do much research and readings to get me started on this competition/project. Below are the list of notebooks, articles, and websites that I took inspiration and code snippets from. All the credits go to them!!!: \n\n* [COVID-19 data with SIR model](https://www.kaggle.com/lisphilar/covid-19-data-with-sir-model) by Lisphilar\n\n* [COVID-19 Global Forecast : SEIR + Visualize](https://www.kaggle.com/super13579/covid-19-global-forecast-seir-visualize) by funkyboy\n\n* [Phase-adjusted estimation of the number of Coronavirus Disease 2019 cases in Wuhan, China](https://www.nature.com/articles/s41421-020-0148-0) (Wang et al. 2020) Cell Discovery, 6,10\n\n* [CoronaTracker: World-wide COVID-19 Outbreak Data: Analysis and Prediction](https://www.who.int/bulletin/online_first/20-255695.pdf) (Hamzah et al. 2020) \n\n* [SEIR Model with intervention (Final)](https://www.kaggle.com/anjum48/seir-model-with-intervention-final) by datasaurus\n\n* [The Coronavirus Curve - Numberphile](https://www.youtube.com/watch?v=k6nLfCbAzgo&t=739s) by Numberphile\n\n* [Epidemic Calculator](http://gabgoh.github.io/COVID/index.html) by Gabriel Goh\n\n* [Social Distancing to Slow the Coronavirus](https://towardsdatascience.com/social-distancing-to-slow-the-coronavirus-768292f04296) by Christian Hubbs\n\n* [COVID-19 Complete Dataset (Updated every 24hrs)](https://www.kaggle.com/imdevskp/corona-virus-report#covid_19_clean_complete.csv) by Devakumar kp\n\n* [Cleaned Population of Countries and States](https://www.kaggle.com/dgrechka/covid19-global-forecasting-locations-population) by DmitryA. Grechka\n\n\n### What's in this kernel:\n1. [Data Loading and Cleaning](#Data_loading_structure)\n2. [Confirmed Cases and Deaths Across Countries/Cities](#Frequencies)\n3. [Time Series Plots Per Country](#Line_Plots)\n4. [Interactive Time Series Map](#Map_Data)\n5. [SEIR-D Modelling](#SEIRD)\n"},{"metadata":{},"cell_type":"markdown","source":"<a id='Data_loading_structure'></a>\n## **1. Data Loading and Cleaning** ##"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n\ntrain = pd.read_csv('/kaggle/input/corona-virus-report/covid_19_clean_complete.csv')\ntest = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-2/test.csv')\n\ncountry_data = pd.read_csv('/kaggle/input/covid19-global-forecasting-locations-population/locations_population.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rename columns\ntrain = train.rename(columns={'Province/State': 'Province_State', 'Country/Region': 'Country_Region', 'ConfirmedCases':'Confirmed', 'Fatalities':'Deaths'}).sort_values(['Country_Region','Province_State']).reset_index().drop('index',axis=1)\ntrain['Date'] = pd.to_datetime(train['Date']).astype('str')\ntest = test.rename(columns={'Province/State': 'Province_State', 'Country/Region': 'Country_Region', 'ConfirmedCases':'Confirmed', 'Fatalities':'Deaths'})\ncountry_data = country_data.rename(columns={'Province.State': 'Province_State', 'Country.Region': 'Country_Region'}).drop('Provenance',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Date'].min(), train['Date'].max(), test['Date'].min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove the overlapping train and test data\n\nvalid = train[train['Date'] >= test['Date'].min()] # set as validation data\ntrain = train[train['Date'] < test['Date'].min()]\ntrain.shape, valid.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Date'].min(), train['Date'].max(), test['Date'].min(), test['Date'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.merge(country_data, on=['Country_Region','Province_State'], how = 'left')\nvalid = valid.merge(country_data, on=['Country_Region','Province_State'], how = 'left')\ntest = test.merge(country_data, on=['Country_Region','Province_State'], how = 'left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Province_State'] = train['Province_State'].fillna(train['Country_Region']) # replace NaN States with country name\nvalid['Province_State'] = valid['Province_State'].fillna(valid['Country_Region']) # replace NaN States with country name\ntest['Province_State'] = test['Province_State'].fillna(test['Country_Region']) # replace NaN States with country name","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='Frequencies'></a>\n## **2. Confirmed Cases and Deaths Across Countries/Cities** ##"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Standard plotly imports\n#import chart_studio.plotly as py\nimport plotly.graph_objs as go\nimport plotly.express as px\nimport plotly.io as pio\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import iplot, init_notebook_mode, plot\n# Using plotly + cufflinks in offline mode\nimport cufflinks\ncufflinks.go_offline(connected=True)\ninit_notebook_mode(connected=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_total = train.groupby(['Country_Region','Province_State'],as_index=False).agg({'Confirmed': 'max', 'Deaths': 'max', 'Recovered': 'max'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pio.renderers.default = 'vscode'\npio.renderers.default = 'kaggle'\n\nfig = px.treemap(train_total.sort_values(by='Confirmed', ascending=False).reset_index(drop=True), \n                 path=[\"Country_Region\", \"Province_State\"], values=\"Confirmed\", height=700, width=900,\n                 title='Number of Confirmed Cases',\n                 color_discrete_sequence = px.colors.qualitative.Prism)\nfig.data[0].textinfo = 'label+text+value'\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.treemap(train_total.sort_values(by='Deaths', ascending=False).reset_index(drop=True), \n                 path=[\"Country_Region\", \"Province_State\"], values=\"Deaths\", height=700, width=900,\n                 title='Number of Deaths',\n                 color_discrete_sequence = px.colors.qualitative.Prism)\nfig.data[0].textinfo = 'label+text+value'\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.treemap(train_total.sort_values(by='Recovered', ascending=False).reset_index(drop=True), \n                 path=[\"Country_Region\", \"Province_State\"], values=\"Recovered\", height=700, width=900,\n                 title='Number of Recovered',\n                 color_discrete_sequence = px.colors.qualitative.Prism)\nfig.data[0].textinfo = 'label+text+value'\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='Line_Plots'></a>\n## **3. Time Series Plots Per Continent and Country** ##"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sum countries with states, not dealing with states for now\ntrain_agg= train[['Country_Region','Date','Confirmed','Deaths', 'Recovered']].groupby(['Country_Region','Date'],as_index=False).agg({'Confirmed': 'sum', 'Deaths': 'sum', 'Recovered': 'sum'})\n# France will sum all its colonies, so it will be higher\n\n# change to datetime format\ntrain_agg['Date'] = pd.to_datetime(train_agg['Date']) \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Time Series Bar Chart of Cases per Continent ###"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"! pip install pycountry\n! pip install pycountry_convert\nimport pycountry_convert as pc\nimport pycountry\n# function for getting the iso code through fuzzy search\ndef do_fuzzy_search(country):\n    try:\n        result = pycountry.countries.search_fuzzy(country)\n    except Exception:\n        return np.nan\n    else:\n        return result[0].alpha_2\n\ntrain_continent = train_agg\n# manually change name of some countries\ntrain_continent.loc[train_continent['Country_Region'] == 'Korea, South', 'Country_Region'] = 'Korea, Republic of'\ntrain_continent.loc[train_continent['Country_Region'] == 'Taiwan*', 'Country_Region'] = 'Taiwan'\n# create iso mapping for countries in df\niso_map = {country: do_fuzzy_search(country) for country in train_continent['Country_Region'].unique()}\n# apply the mapping to df\ntrain_continent['iso'] = train_continent['Country_Region'].map(iso_map)\n#train_continent['Continent'] = [pc.country_alpha2_to_continent_code(iso) for iso in train_continent['iso']]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def alpha2_to_continent(iso):\n    try: cont = pc.country_alpha2_to_continent_code(iso)\n    except: cont = float('NaN')\n    return cont\n\ntrain_continent['Continent'] = train_continent['iso'].apply(alpha2_to_continent) # get continent code\ntrain_continent.loc[train_continent['iso'] == 'CN', 'Continent'] = 'CN' # Replace China's continent value as we want to keep it separate\n\ntrain_continent = train_continent[['Continent','Date','Confirmed','Deaths', 'Recovered']].groupby(['Continent','Date'],as_index=False).agg({'Confirmed':'sum','Deaths':'sum','Recovered':'sum'})\ntrain_continent['Continent'] = train_continent['Continent'].map({'AF':'Africa','AS':'Asia','CN':'China','EU':'Europe','NA':'North America','OC':'Oceania','SA':'South America'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"long = pd.melt(train_continent, id_vars=['Continent','Date'], value_vars=['Confirmed','Deaths','Recovered'], var_name='Case', value_name='Count').sort_values(['Date','Count'])\nlong['Date'] = long['Date'].astype('str')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"long.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pio.renderers.default = 'browser' # does not work on vscode\n\n# color palette\ncnf = '#393e46' # confirmed - grey\ndth = '#ff2e63' # death - red\nrec = '#21bf73' # recovered - cyan\n# act = '#fe9801' # active case - yellow\n\nfig = px.bar(long, y='Continent', x='Count', color='Case', barmode='group', orientation='h', text='Count', title='Counts by Continent', animation_frame='Date',\n             color_discrete_sequence= [dth,cnf,rec], range_x=[0, 100000])\nfig.update_traces(textposition='outside')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Time Series Bar Chart of Cases per Country ###"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Interactive time series plot of confirmed cases\nfig = px.line(train_agg, x='Date', y='Confirmed', color=\"Country_Region\", hover_name=\"Country_Region\")\nfig.update_layout(autosize=False,width=1000,height=500,title='Confirmed Cases Over Time for Each Country')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Interactive time series plot of fatalities\nfig = px.line(train_agg, x='Date', y='Deaths', color=\"Country_Region\", hover_name=\"Country_Region\")\nfig.update_layout(autosize=False,width=1000,height=500,title='Deaths Over Time for Each Country')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Interactive time series plot of recovered\nfig = px.line(train_agg, x='Date', y='Recovered', color=\"Country_Region\", hover_name=\"Country_Region\")\nfig.update_layout(autosize=False,width=1000,height=500,title='Deaths Over Time for Each Country')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='Map_Data'></a>\n## **4. Interactive Time Series Map** ##"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Load Natural Earth Map Data\n\nimport geopandas as gpd # for reading vector-based spatial data format\nshapefile = '/kaggle/input/natural-earth-maps/ne_110m_admin_0_countries.shp'\n#shapefile = r'C:\\Users\\TeYan\\OneDrive\\Work\\Kaggle\\COVID19\\110m_cultural\\ne_110m_admin_0_countries.shp'\n\n# Read shapefile using Geopandas\n#gdf = gpd.read_file(shapefile)[['ADMIN', 'ADM0_A3', 'geometry']]\ngdf = gpd.read_file(shapefile)\n\n# Drop row corresponding to 'Antarctica'\ngdf = gdf.drop(gdf.index[159])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Get the ISO 3166-1 alpha-3 Country Codes\n\n# function for getting the iso code through fuzzy search\ndef do_fuzzy_search(country):\n    try:\n        result = pycountry.countries.search_fuzzy(country)\n    except Exception:\n        return np.nan\n    else:\n        return result[0].alpha_3\n\n# manually change name of some countries\ntrain_agg.loc[train_agg['Country_Region'] == 'South Korea', 'Country_Region'] = 'Korea, Republic of'\ntrain_agg.loc[train_agg['Country_Region'] == 'Taiwan*', 'Country_Region'] = 'Taiwan'\ntrain_agg.loc[train_agg['Country_Region'] == 'Burma', 'Country_Region'] = 'Myanmar'\ntrain_agg.loc[train_agg['Country_Region'] == 'Congo (Kinshasa)', 'Country_Region'] = 'Congo, The Democratic Republic of the'\ntrain_agg.loc[train_agg['Country_Region'] == 'Congo (Brazzaville)', 'Country_Region'] = 'Congo'\ntrain_agg.loc[train_agg['Country_Region'] == 'Laos', 'Country_Region'] = \"Lao People's Democratic Republic\"\n\n# create iso mapping for countries in df\niso_map = {country: do_fuzzy_search(country) for country in train_agg['Country_Region'].unique()}\n# apply the mapping to df\ntrain_agg['iso'] = train_agg['Country_Region'].map(iso_map)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"noiso = train_agg[train_agg['iso'].isna()]['Country_Region'].unique()\nnoiso","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # function for getting the better country name through fuzzy search\n# def do_fuzzy_search_country(country):\n#     try:\n#         result = pycountry.countries.search_fuzzy(country)\n#     except Exception:\n#         return np.nan\n#     else:\n#         return result[0].name\n\n# country_map = {country: do_fuzzy_search_country(country) for country in train_agg['Country_Region'].unique()}\n# # apply the mapping to df\n# train_agg['Country_Region'] = train_agg['Country_Region'].map(country_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change date to string, not sure why plotly cannot accept datetime format\ntrain_agg['Date'] = train_agg['Date'].dt.strftime('%Y-%m-%d')\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"# apply log10 so that color changes are more prominent\nimport numpy as np\ntrain_agg['Confirmed_log10'] = np.log10(train_agg['Confirmed']).replace(-np.inf, 0) # log10 changes 0 to -inf so change back\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Interactive Map of Confirmed Cases Over Time\n\n#pio.renderers.default = 'browser' # does not work on vscode\n# pio.renderers.default = 'kaggle'\nfig = px.choropleth(train_agg, locations='iso', color='Confirmed_log10', hover_name='Country_Region', animation_frame='Date', color_continuous_scale='reds')\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that the virus originated in China, and spread across neighbouring Asia and Oceania in the beginning, followed by Europe and the Americas. It would be good to have travel and flight data to visualize how that influences the spread of the virus. Some countries/regions such as the Middle East were lagging perhaps due to the lack of proper virus detection measures. Much of Africa does not have sufficient data at the moment."},{"metadata":{},"cell_type":"markdown","source":"<a id='SEIRD'></a>\n## **5. SEIR-D Modelling** ##\n"},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://sqraea.bn.files.1drv.com/y4mk7A3nwlp4uUgy3iYk2K2YO0cLr14A8nzCg1Okaa6SvOqjKN5MVqQH0e1-fsvZ093TCf5dIyEkvJohvaM_EKQ4xTOQJvrHnzfst6NWk5E4tdScd6wC5EiH5wNAnxN7u8PiRbMdkiqpo8j0HUlB0kIoQVfwvMMrW7csDviuVtFHQrfBRXmTzCZer2B3yrNMpIK4bJZfzTyNOY9jXzTsiGzow?width=1706&height=609&cropmode=none\" width=\"1000\" height=\"350\" align=\"center\"/>"},{"metadata":{},"cell_type":"markdown","source":"The SEIR-D model has 5 ordinary differential equation that corresponds to each compartment's progression to the next stage. In simpler terms, it just models the rate of change of each component, as what changes in one component must go into another component, since the model assumes the population is constant. "},{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://svrfea.bn.files.1drv.com/y4m8gOXBX_vQ_GqvW56t881K_5gp8XIxXU1Mmy4859_GGXdWOB6pN-qTQ8MYDsbXAGn2hh8uTCgTieIhOjOJUD5XfET-RscNtZhgPtAmQ472WeG-E3-GwuQ5FPicYWcEWbygCLfUWz5ZBNLSz5fYdFpY_m9_4dXLQonJ7PDrKldOXa795SkFd_6H9-GeWe5us_mDoNUHpOUTAOuQG0g2cmplg?width=1107&height=691&cropmode=none\" width=\"650\" height=\"350\" align=\"center\"/>"},{"metadata":{},"cell_type":"markdown","source":"The S,E,I,R,D in the equations represent the initial values of the respective compartments at time=0, which can be a specific time of year, or the day of first confirmed case. \n\nEquation 1 computes the rate of change of the susceptibles. It depends on the transmission rate (1 / infection duration), beta, multipled by how many susceptibles there are as well as how many infected there are, and it subtracts this from the susceptibles component. These people are exposed to the virus and are thus added to Equation 2.\n\nEquation 2 computes the rate of change of the exposed. It adds in the people who are exposed and subtract those who are infected, which is calculated by the incubation rate (1 / incubation duration), sigma, multiplied by the number of exposed people, and these people who are infected are added to Equation 3.\n\nEquation 3 computes the rate of change of the infected. It adds in the people who are infected, and subtract those who are recovered or died from the virus, which is calculated by the sum of recovery (gamma) and death (alpha) rate multipled by the number of infected people, which are then added individually to Equation 4 (Recovery rate of change), and Equation 5 (Death rate of change). "},{"metadata":{"trusted":true},"cell_type":"code","source":"#train.Province_State.fillna(train.Country_Region, inplace=True) # replace Nan Province_State to Country Name\ntrain['idx'] = train.groupby(['Country_Region','Province_State']).cumcount() # add days from start of series","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.integrate import solve_ivp\nfrom scipy.optimize import minimize\nfrom datetime import timedelta, datetime\n\n# function to get the initial SIR values and their time series values\ndef getSEIRD(df,country,state):\n    SIRD_TS = df[(df['Country_Region']==country) & (df['Province_State']==state)][['idx','Population','Confirmed','Recovered','Deaths']]\n    start_idx = next((i for i, x in enumerate(SIRD_TS.Confirmed) if x), None) # start index of 1st infected\n    I_ts = SIRD_TS.Confirmed # infected timeseries\n    R_ts = SIRD_TS['Recovered'] # recovered time series\n    D_ts = SIRD_TS.Deaths # deceased time series\n    S_ts = SIRD_TS['Population'] - I_ts - R_ts - D_ts # susceptible = total population - infected - recovered - deceased (time series)\n    N = SIRD_TS['Population'].iloc[0] # population size \n    try:\n        mortality = D_ts.iloc[-1] / I_ts.iloc[-1] # use country's last day to estimate mortality rate\n    except:\n        mortality = 0 # if divide by 0 will cause error, set is as 0 for countries with no confirmed cases to date\n    \n\n    # SEIRD = [S_ts.iloc[start_idx], I_ts.iloc[start_idx]*20, I_ts.iloc[start_idx], R_ts.iloc[start_idx], D_ts.iloc[start_idx]] # initial values for SIR; exposed is set to 20x infected \n    SEIRD = [S_ts.iloc[start_idx], 0, I_ts.iloc[start_idx], R_ts.iloc[start_idx], D_ts.iloc[start_idx]] # initial values for SIR; exposed is set to 20x infected \n    timespan = len(I_ts) - start_idx # length of time series\n    return SIRD_TS, SEIRD, start_idx, N, timespan, mortality\n\n# function to calculate the derivative or rate of changes for the SEIRD components\ndef deriv(t,SEIRD,N,R_0,gamma,T_inc,mortality):\n    \n    if callable(R_0): R_t = R_0(t)\n    else: R_t = R_0\n\n    beta = gamma*R_t # transmission rate\n    S=SEIRD[0]; E = SEIRD[1]; I=SEIRD[2]; R=SEIRD[3]; D=SEIRD[4] # get initial values\n    dS = -beta * S * I / N # change in susceptible = transmission rate * how many susceptible there are as well as infected there are (this is -ve change)\n    dE = (beta * S * I / N) - ((T_inc**-1) * E) # change in exposed = transmission rate * how many susceptible there are as well as infected there are, minus incubation rate * how many exposed there are\n    dI = (T_inc**-1) * E - (gamma + mortality) * I # change in infected = those who were exposed becoming infected (plus as added to infected) minus change in recovered/deceased (minus as moved to recovered)\n    dR = gamma * I # change in recovered = recovery rate * how many infected there are (this is +ve change)\n    dD = mortality * I # change in death = mortality rate * how many infected there are\n    return dS, dE, dI, dR, dD\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function for plotting out SEIRD model prediction and fit to actual data\ndef plot_predict_model(solution, df, timespan, start_idx, N, state):\n    # first plot - SEIRD model predictions\n    sus,exp,inf,rec,dea = solution.y # get the predicted values for components\n    f = plt.figure(figsize=(16,5))\n    ax = f.add_subplot(1,2,1)\n    #ax.plot(sus, 'b', label='Susceptible');\n    ax.plot(exp/N, 'orange', label='Exposed')\n    ax.plot(inf/N, 'r', label='Infected');\n    #ax.plot(rec/N, 'c', label='Recovered');\n    ax.plot(dea/N, 'black', label='Deceased');\n    plt.title('SEIRD Model')\n    plt.xlabel(\"Days\", fontsize=10);\n    plt.ylabel(\"Fraction of population\", fontsize=10);\n    plt.legend(loc='best');\n\n    # second plot - SEIRD model fit to actual data\n    # plot only confirmed and deaths\n    ax2 = f.add_subplot(1,2,2)\n    preds = inf + rec + dea # get back actual counts from proportion\n    predD = dea\n    # ax2.plot(range(timespan),preds[:len(SIRD_TS)],label = 'Predicted Confirmed Cases')\n    ax2.plot(range(timespan),preds[:timespan],label = 'Predicted Confirmed Cases')\n    ax2.plot(range(timespan),df['Confirmed'][start_idx:],label = 'Actual Confirmed Cases')\n    ax2.plot(range(timespan),predD[:timespan],label = 'Predicted Deaths')\n    ax2.plot(range(timespan),df['Deaths'][start_idx:],label = 'Actual Deaths')\n    plt.title('Model predict and data')\n    plt.ylabel(\"Population\", fontsize=10);\n    plt.xlabel(\"Days\", fontsize=10);\n    plt.legend(loc='best');\n    plt.suptitle(state,size=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\n# function for applying SEIRD to individual country\ndef SEIRD_by_country(df,country,forecast_days,params,decay=True,state=''):\n    state = country if state == '' else state # account for some countries having same state names\n    SEIRD_TS,SEIRD,start_idx,N,timespan,mortality=getSEIRD(df,country,state)\n    forecast_days = forecast_days # days to forecast ahead\n\n    if decay: # apply decay\n        L = params[3]; k = params[4]\n        def decaying_reproduction(t):       \n            return params[0] / (1 + (t/L)**k)\n    else: decaying_reproduction = params[0] # don't apply decay\n\n\n    # solve for ordinary differential equations\n    solution = solve_ivp(deriv, [0,timespan+forecast_days], [SEIRD[0],SEIRD[1],SEIRD[2],SEIRD[3],SEIRD[4]], \n        args=(N,decaying_reproduction,params[1],params[2],mortality), t_eval=np.arange(0, timespan+forecast_days, 1))\n    #np.add(solution.y[2], solution.y[3], solution.y[4]) # Confirmed = Infected + Recovered + Deceased, have to do so because original data is cumulative counts\n    plot_predict_model(solution, SEIRD_TS, timespan, start_idx, N, state)\n    return solution","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, we allow the reproduction rate (R_0) to decay as a function of time, known as R_t, to represent what happens in the real world as the R_0 rate does not stay constant. In fact, different countries, locations, and factors might influence the R_0 value, and people will start to intervene to fight the virus after an initial slow start during the epidemic incubation period. For example, governments start imposing lockdown and social distancing to prevent further spreading of the virus, and vaccinations and immunity might surface.\n\nBelow is a plot generated from [Desmos](https://www.desmos.com/calculator) showing the L and k parameters for the hill decaying function. It takes the from 1/1+(t/L)^k and has an almost similar shape to a flipped sigmoid curve. \n\nFrom what I understand from playing around with the parameters, L determines the time point of the inflection point of the curve (6 for left red line, 10 for purple line), whereas k controls the steepness of the curve (8 for left red, 4 for right red). I was initially trying to create an inverted sigmoid function but chose this instead as it closely resembles it. "},{"metadata":{},"cell_type":"markdown","source":"\n\n<img src=\"https://sqqqea.bn.files.1drv.com/y4mHCjrf5mxEOGfP2aLaW2Dqvfar8FG-gN-4WRGYlalx1PmfYU5Q-G2B50EdvYv1WpQuyydj8jyBIq7W2OIWAnZhTgo3fbZbrpUP3GAiakEHD-2GDBT0798sNvIh-ZPEnT-RFFctA4xEzXc9-utxAFjPD6Wl_G4TFeKV-tLsPDPOhqCnvySrtJsWDYeqmzyZrPYZNK_-1TVYbrsfIEhodENGg?width=1348&height=924&cropmode=none\" width=\"600\" height=\"400\" align=\"center\"/>"},{"metadata":{},"cell_type":"markdown","source":"## Applying the model to some countries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nR_0 = 2.7 # reproduction number\nbeta = 2.75 # transmission rate\nT_inc = 3.3 # incubation duration\nL = 10 # time of inflection point \nk = 2 # steepness of decaying curve\nparams = [R_0, beta, T_inc, L, k]\n\nsolution = SEIRD_by_country(train,'China',100,params,decay=True,state='Hubei')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"R_0 = 2 # reproduction number\nbeta = 1.6 # transmission rate\nT_inc = 3.6 # incubation duration\nL = 5 # time of inflection point \nk = 2 # steepness of decaying curve\nparams = [R_0, beta, T_inc, L, k]\n\nsolution = SEIRD_by_country(train,'Italy',100,params,decay=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"R_0 = 1.9 # reproduction number\nbeta = 2 # transmission rate\n#gamma = 4.6 # recovery rate\nT_inc = 2 # incubation duration\nL = 10 # time of inflection point \nk = 3 # steepness of decaying curve\nparams = [R_0, beta, T_inc, L, k]\n\nsolution = SEIRD_by_country(train,'Iran',100,params,decay=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"R_0 = 2.75 # reproduction number\nbeta = 2.8 # transmission rate\n#gamma = 4.6 # recovery rate\nT_inc = 6 # incubation duration\nL = 20 # time of inflection point \nk = 1 # steepness of decaying curve\nparams = [R_0, beta, T_inc, L, k]\n\nsolution = SEIRD_by_country(train,'Singapore',100,params,decay=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Notice that for some countries, the SEIRD Model curve display a higher death count than exposed (black line is higher than red line). This is because the curve is not cumulative. People who are exposed (red line) can recover and move into the recovered compartment, and thats why the exposed line does not keep increasing. However, people who are deceased stay in the same compartment.\n\nWhile the model currently works quite well for Hubei and Italy in terms of confirmed cases, it does not do so well for Iran and Singapore. Somehow I just cannot get the confirmed cases for Iran to rise up quickly and steadily enough. For Singapore, it does quite well for the first 20+ days, but then experienced a slow down followed by a faster increase towards the end, possibly due to a sudden increase in Malaysia's cluster that was attributed to the Sri Petaling tabligh gathering.\n\nOur model also keep consistently underpredicting the number of fatalities. Right now I am just putting the mortality rate as the ratio of deaths to confirmed cases during the last day of the training time series as this is the most accurate estimate as of that day. Perhaps some better way to do it might be more appropriate."},{"metadata":{},"cell_type":"markdown","source":"### To Do\n* Error Metric\n* Optimizing parameters for best fit\n* Dealing with countries with 0 cases all the way\n\n### Considerations\n* Weightings for parameters for different countries\n    * E.g., adding population density of country to influence transmission rate\n* Adding V component for vaccinations (only when vaccinations are discovered)"},{"metadata":{},"cell_type":"markdown","source":"I hope that this notebook has been useful. I am still learning time series modelling and any advice is appreciated. **Please give this notebook an upvote if you like it!**\n\nStay safe everyone!"}],"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.4-final"},"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3,"kernelspec":{"name":"python37464bitbasecondab242d5e5f8174bf28be86f1d44ad44ad","display_name":"Python 3.7.4 64-bit ('base': conda)"}},"nbformat":4,"nbformat_minor":4}