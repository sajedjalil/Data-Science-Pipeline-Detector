{"cells":[{"metadata":{},"cell_type":"markdown","source":"# [COVID19 Global Forecasting (Week 2)](https://www.kaggle.com/c/covid19-global-forecasting-week-2)"},{"metadata":{},"cell_type":"markdown","source":"# Acknowledgements\n\n\n* Very GOOD kernel: [COVID Global Forecast: SIR model + ML regressions](https://www.kaggle.com/saga21/covid-global-forecast-sir-model-ml-regressions)\n* That kernel \"COVID Global Forecast: SIR model + ML regressions\" used dataset [Population by Country - 2020](https://www.kaggle.com/tanuprabhu/population-by-country-2020)\n* [BOD prediction in river - 15 regression models](https://www.kaggle.com/vbmokin/bod-prediction-in-river-15-regression-models)\n* [Automatic selection from 20 classifier models](https://www.kaggle.com/vbmokin/automatic-selection-from-20-classifier-models)"},{"metadata":{},"cell_type":"markdown","source":"# My upgrade 1\n\n## Ridge model instead of Lin_reg"},{"metadata":{},"cell_type":"markdown","source":"# My upgrade 2\n\n## RidgeCV model instead of Lin_reg"},{"metadata":{},"cell_type":"markdown","source":"\n**TABLE OF CONTENTS**\n\n1. [Exploratory data analysis (EDA)](#section1)\n\n    1.1. [COVID-19 global tendency excluding China](#section11)\n    \n    1.2. [COVID-19 tendency in China](#section12)\n    \n    1.3. [Italy, Spain, UK and Singapore](#section13)\n    \n2. [SIR model](#section2)\n\n    2.1. [Implementing the SIR model](#section21)\n    \n    2.2. [Fit SIR parameters to real data](#section22)\n    \n3. [Data enrichment](#section3)\n\n    3.1. [Join data, filter dates and clean missings](#section31)\n    \n    3.2. [Compute lags and trends](#section32)\n    \n    3.3. [Add country details](#section33)\n    \n4. [Predictions with machine learning](#section4)\n\n    4.1. [Ridge Regression for one country](#section41)\n    \n    4.2. [Ridge Regression for all countries (method 1)](#section42)\n    \n    4.3. [Ridge Regression for all countries (method 2)](#section43)\n    \n    4.4. [Ridge regression with lags](#section44)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import preprocessing\nimport time\nfrom datetime import datetime\nfrom scipy import integrate, optimize\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ML libraries\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import Ridge, RidgeCV","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Exploratory data analysis (EDA) <a id=\"section1\"></a>"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"submission_example = pd.read_csv(\"../input/covid19-global-forecasting-week-2/submission.csv\")\ntest = pd.read_csv(\"../input/covid19-global-forecasting-week-2/test.csv\")\ntrain = pd.read_csv(\"../input/covid19-global-forecasting-week-2/train.csv\")\ndisplay(train.head(5))\ndisplay(train.describe())\nprint(\"Number of Country_Region: \", train['Country_Region'].nunique())\nprint(\"Dates go from day\", max(train['Date']), \"to day\", min(train['Date']), \", a total of\", train['Date'].nunique(), \"days\")\nprint(\"Countries with Province/State informed: \", train[train['Province_State'].isna()==False]['Country_Region'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#confirmed_country = train.groupby(['Country/Region', 'Province/State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country = train.groupby(['Country/Region', 'Province/State']).agg({'Fatalities':['sum']})\nconfirmed_total_date = train.groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date = train.groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date = confirmed_total_date.join(fatalities_total_date)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,7))\ntotal_date.plot(ax=ax1)\nax1.set_title(\"Global confirmed cases\", size=13)\nax1.set_ylabel(\"Number of cases\", size=13)\nax1.set_xlabel(\"Date\", size=13)\nfatalities_total_date.plot(ax=ax2, color='orange')\nax2.set_title(\"Global deceased cases\", size=13)\nax2.set_ylabel(\"Number of cases\", size=13)\nax2.set_xlabel(\"Date\", size=13)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.1. COVID-19 global tendency excluding China <a id=\"section11\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#confirmed_country_noChina = train[train['Country_Region']!='China'].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_noChina = train[train['Country_Region']!='China'].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_noChina = train[train['Country_Region']!='China'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_noChina = train[train['Country_Region']!='China'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_noChina = confirmed_total_date_noChina.join(fatalities_total_date_noChina)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\ntotal_date_noChina.plot(ax=ax1)\nax1.set_title(\"Global confirmed cases excluding China\", size=13)\nax1.set_ylabel(\"Number of cases\", size=13)\nax1.set_xlabel(\"Date\", size=13)\nfatalities_total_date_noChina.plot(ax=ax2, color='orange')\nax2.set_title(\"Global deceased cases excluding China\", size=13)\nax2.set_ylabel(\"Number of cases\", size=13)\nax2.set_xlabel(\"Date\", size=13)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.2. COVID-19 tendency in China <a id=\"section12\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#confirmed_country_China = train[train['Country_Region']=='China'].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_China = train[train['Country_Region']=='China'].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_China = train[train['Country_Region']=='China'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_China = train[train['Country_Region']=='China'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_China = confirmed_total_date_China.join(fatalities_total_date_China)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\ntotal_date_China.plot(ax=ax1)\nax1.set_title(\"China confirmed cases\", size=13)\nax1.set_ylabel(\"Number of cases\", size=13)\nax1.set_xlabel(\"Date\", size=13)\nfatalities_total_date_China.plot(ax=ax2, color='orange')\nax2.set_title(\"China deceased cases\", size=13)\nax2.set_ylabel(\"Number of cases\", size=13)\nax2.set_xlabel(\"Date\", size=13)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.3. Italy, Spain, UK and Singapore <a id=\"section13\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#confirmed_country_Italy = train[train['Country_Region']=='Italy'].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_Italy = train[train['Country_Region']=='Italy'].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_Italy = train[train['Country_Region']=='Italy'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_Italy = train[train['Country_Region']=='Italy'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_Italy = confirmed_total_date_Italy.join(fatalities_total_date_Italy)\n\n#confirmed_country_Spain = train[train['Country_Region']=='Spain'].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_Spain = train[train['Country_Region']=='Spain'].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_Spain = train[train['Country_Region']=='Spain'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_Spain = train[train['Country_Region']=='Spain'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_Spain = confirmed_total_date_Spain.join(fatalities_total_date_Spain)\n\n#confirmed_country_UK = train[train['Country_Region']=='United Kingdom'].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_UK = train[train['Country_Region']=='United Kingdom'].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_UK = train[train['Country_Region']=='United Kingdom'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_UK = train[train['Country_Region']=='United Kingdom'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_UK = confirmed_total_date_UK.join(fatalities_total_date_UK)\n\n#confirmed_country_Australia = train[train['Country_Region']=='Australia'].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_Australia = train[train['Country_Region']=='Australia'].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_Australia = train[train['Country_Region']=='Australia'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_Australia = train[train['Country_Region']=='Australia'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_Australia = confirmed_total_date_Australia.join(fatalities_total_date_Australia)\n\n#confirmed_country_Singapore = train[train['Country_Region']=='Singapore'].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_Singapore = train[train['Country_Region']=='Singapore'].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_Singapore = train[train['Country_Region']=='Singapore'].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_Singapore = train[train['Country_Region']=='Singapore'].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_Singapore = confirmed_total_date_Singapore.join(fatalities_total_date_Singapore)\n\nplt.figure(figsize=(15,10))\nplt.subplot(2, 2, 1)\ntotal_date_Italy.plot(ax=plt.gca(), title='Italy')\nplt.ylabel(\"Confirmed infection cases\", size=13)\n\nplt.subplot(2, 2, 2)\ntotal_date_Spain.plot(ax=plt.gca(), title='Spain')\n\nplt.subplot(2, 2, 3)\ntotal_date_UK.plot(ax=plt.gca(), title='United Kingdom')\nplt.ylabel(\"Confirmed infection cases\", size=13)\n\nplt.subplot(2, 2, 4)\ntotal_date_Singapore.plot(ax=plt.gca(), title='Singapore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pop_italy = 60486683.\npop_spain = 46749696.\npop_UK = 67784927.\npop_singapore = 5837230.\n\ntotal_date_Italy.ConfirmedCases = total_date_Italy.ConfirmedCases/pop_italy*100.\ntotal_date_Italy.Fatalities = total_date_Italy.ConfirmedCases/pop_italy*100.\ntotal_date_Spain.ConfirmedCases = total_date_Spain.ConfirmedCases/pop_spain*100.\ntotal_date_Spain.Fatalities = total_date_Spain.ConfirmedCases/pop_spain*100.\ntotal_date_UK.ConfirmedCases = total_date_UK.ConfirmedCases/pop_UK*100.\ntotal_date_UK.Fatalities = total_date_UK.ConfirmedCases/pop_UK*100.\ntotal_date_Singapore.ConfirmedCases = total_date_Singapore.ConfirmedCases/pop_singapore*100.\ntotal_date_Singapore.Fatalities = total_date_Singapore.ConfirmedCases/pop_singapore*100.\n\nplt.figure(figsize=(15,10))\nplt.subplot(2, 2, 1)\ntotal_date_Italy.ConfirmedCases.plot(ax=plt.gca(), title='Italy')\nplt.ylabel(\"Fraction of population infected\")\nplt.ylim(0, 0.06)\n\nplt.subplot(2, 2, 2)\ntotal_date_Spain.ConfirmedCases.plot(ax=plt.gca(), title='Spain')\nplt.ylim(0, 0.06)\n\nplt.subplot(2, 2, 3)\ntotal_date_UK.ConfirmedCases.plot(ax=plt.gca(), title='United Kingdom')\nplt.ylabel(\"Fraction of population infected\")\nplt.ylim(0, 0.005)\n\nplt.subplot(2, 2, 4)\ntotal_date_Singapore.ConfirmedCases.plot(ax=plt.gca(), title='Singapore')\nplt.ylim(0, 0.005)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#confirmed_country_Italy = train[(train['Country_Region']=='Italy') & train['ConfirmedCases']!=0].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_Italy = train[(train['Country_Region']=='Italy') & train['ConfirmedCases']!=0].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_Italy = train[(train['Country_Region']=='Italy') & train['ConfirmedCases']!=0].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_Italy = train[(train['Country_Region']=='Italy') & train['ConfirmedCases']!=0].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_Italy = confirmed_total_date_Italy.join(fatalities_total_date_Italy)\n\n#confirmed_country_Spain = train[(train['Country_Region']=='Spain') & (train['ConfirmedCases']!=0)].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_Spain = train[(train['Country_Region']=='Spain') & (train['ConfirmedCases']!=0)].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_Spain = train[(train['Country_Region']=='Spain') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_Spain = train[(train['Country_Region']=='Spain') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_Spain = confirmed_total_date_Spain.join(fatalities_total_date_Spain)\n\n#confirmed_country_UK = train[(train['Country_Region']=='United Kingdom') & (train['ConfirmedCases']!=0)].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_UK = train[(train['Country_Region']=='United Kingdom') & (train['ConfirmedCases']!=0)].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_UK = train[(train['Country_Region']=='United Kingdom') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_UK = train[(train['Country_Region']=='United Kingdom') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_UK = confirmed_total_date_UK.join(fatalities_total_date_UK)\n\n#confirmed_country_Australia = train[(train['Country_Region']=='Australia') & (train['ConfirmedCases']!=0)].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_Australia = train[(train['Country_Region']=='Australia') & (train['ConfirmedCases']!=0)].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_Australia = train[(train['Country_Region']=='Australia') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_Australia = train[(train['Country_Region']=='Australia') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_Australia = confirmed_total_date_Australia.join(fatalities_total_date_Australia)\n\n#confirmed_country_Singapore = train[(train['Country_Region']=='Singapore') & (train['ConfirmedCases']!=0)].groupby(['Country_Region', 'Province_State']).agg({'ConfirmedCases':['sum']})\n#fatalities_country_Singapore = train[(train['Country_Region']=='Singapore') & (train['ConfirmedCases']!=0)].groupby(['Country_Region', 'Province_State']).agg({'Fatalities':['sum']})\nconfirmed_total_date_Singapore = train[(train['Country_Region']=='Singapore') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'ConfirmedCases':['sum']})\nfatalities_total_date_Singapore = train[(train['Country_Region']=='Singapore') & (train['ConfirmedCases']!=0)].groupby(['Date']).agg({'Fatalities':['sum']})\ntotal_date_Singapore = confirmed_total_date_Singapore.join(fatalities_total_date_Singapore)\n\nitaly = [i for i in total_date_Italy.ConfirmedCases['sum'].values]\nitaly_30 = italy[0:50] \nspain = [i for i in total_date_Spain.ConfirmedCases['sum'].values]\nspain_30 = spain[0:50] \nUK = [i for i in total_date_UK.ConfirmedCases['sum'].values]\nUK_30 = UK[0:50] \nsingapore = [i for i in total_date_Singapore.ConfirmedCases['sum'].values]\nsingapore_30 = singapore[0:50] \n\n\n# Plots\nplt.figure(figsize=(12,6))\nplt.plot(italy_30)\nplt.plot(spain_30)\nplt.plot(UK_30)\nplt.plot(singapore_30)\nplt.legend([\"Italy\", \"Spain\", \"UK\", \"Singapore\"], loc='upper left')\nplt.title(\"COVID-19 infections from the first confirmed case\", size=15)\nplt.xlabel(\"Days\", size=13)\nplt.ylabel(\"Infected cases\", size=13)\nplt.ylim(0, 60000)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. SIR model <a id=\"section2\"></a>"},{"metadata":{},"cell_type":"markdown","source":"## 2.1. Implementing the SIR model <a id=\"section21\"></a>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Susceptible equation\ndef fa(N, a, b, beta):\n    fa = -beta*a*b\n    return fa\n\n# Infected equation\ndef fb(N, a, b, beta, gamma):\n    fb = beta*a*b - gamma*b\n    return fb\n\n# Recovered/deceased equation\ndef fc(N, b, gamma):\n    fc = gamma*b\n    return fc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Runge-Kutta method of 4rth order for 3 dimensions (susceptible a, infected b and recovered r)\ndef rK4(N, a, b, c, fa, fb, fc, beta, gamma, hs):\n    a1 = fa(N, a, b, beta)*hs\n    b1 = fb(N, a, b, beta, gamma)*hs\n    c1 = fc(N, b, gamma)*hs\n    ak = a + a1*0.5\n    bk = b + b1*0.5\n    ck = c + c1*0.5\n    a2 = fa(N, ak, bk, beta)*hs\n    b2 = fb(N, ak, bk, beta, gamma)*hs\n    c2 = fc(N, bk, gamma)*hs\n    ak = a + a2*0.5\n    bk = b + b2*0.5\n    ck = c + c2*0.5\n    a3 = fa(N, ak, bk, beta)*hs\n    b3 = fb(N, ak, bk, beta, gamma)*hs\n    c3 = fc(N, bk, gamma)*hs\n    ak = a + a3\n    bk = b + b3\n    ck = c + c3\n    a4 = fa(N, ak, bk, beta)*hs\n    b4 = fb(N, ak, bk, beta, gamma)*hs\n    c4 = fc(N, bk, gamma)*hs\n    a = a + (a1 + 2*(a2 + a3) + a4)/6\n    b = b + (b1 + 2*(b2 + b3) + b4)/6\n    c = c + (c1 + 2*(c2 + c3) + c4)/6\n    return a, b, c","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def SIR(N, b0, beta, gamma, hs):\n    \n    \"\"\"\n    N = total number of population\n    beta = transition rate S->I\n    gamma = transition rate I->R\n    k =  denotes the constant degree distribution of the network (average value for networks in which \n    the probability of finding a node with a different connectivity decays exponentially fast\n    hs = jump step of the numerical integration\n    \"\"\"\n    \n    # Initial condition\n    a = float(N-1)/N -b0\n    b = float(1)/N +b0\n    c = 0.\n\n    sus, inf, rec= [],[],[]\n    for i in range(10000): # Run for a certain number of time-steps\n        sus.append(a)\n        inf.append(b)\n        rec.append(c)\n        a,b,c = rK4(N, a, b, c, fa, fb, fc, beta, gamma, hs)\n\n    return sus, inf, rec","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Parameters of the model\nN = 7800*(10**6)\nb0 = 0\nbeta = 0.7\ngamma = 0.2\nhs = 0.1\n\nsus, inf, rec = SIR(N, b0, beta, gamma, hs)\n\nf = plt.figure(figsize=(8,5)) \nplt.plot(sus, 'b.', label='susceptible');\nplt.plot(inf, 'r.', label='infected');\nplt.plot(rec, 'c.', label='recovered/deceased');\nplt.title(\"SIR model\")\nplt.xlabel(\"time\", fontsize=10);\nplt.ylabel(\"Fraction of population\", fontsize=10);\nplt.legend(loc='best')\nplt.xlim(0,1000)\nplt.savefig('SIR_example.png')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2. Fit SIR parameters to real data <a id=\"section22\"></a>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"population = float(46750238)\ncountry_df = pd.DataFrame()\ncountry_df['ConfirmedCases'] = train.loc[train['Country_Region']=='Spain'].ConfirmedCases.diff().fillna(0)\ncountry_df = country_df[10:]\ncountry_df['day_count'] = list(range(1,len(country_df)+1))\n\nydata = [i for i in country_df.ConfirmedCases]\nxdata = country_df.day_count\nydata = np.array(ydata, dtype=float)\nxdata = np.array(xdata, dtype=float)\n\nN = population\ninf0 = ydata[0]\nsus0 = N - inf0\nrec0 = 0.0\n\ndef sir_model(y, x, beta, gamma):\n    sus = -beta * y[0] * y[1] / N\n    rec = gamma * y[1]\n    inf = -(sus + rec)\n    return sus, inf, rec\n\ndef fit_odeint(x, beta, gamma):\n    return integrate.odeint(sir_model, (sus0, inf0, rec0), x, args=(beta, gamma))[:,1]\n\npopt, pcov = optimize.curve_fit(fit_odeint, xdata, ydata)\nfitted = fit_odeint(xdata, *popt)\n\nplt.plot(xdata, ydata, 'o')\nplt.plot(xdata, fitted)\nplt.title(\"Fit of SIR model for Spain infected cases\")\nplt.ylabel(\"Population infected\")\nplt.xlabel(\"Days\")\nplt.show()\nprint(\"Optimal parameters: beta =\", popt[0], \" and gamma = \", popt[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Data enrichment <a id=\"section3\"></a>\n"},{"metadata":{},"cell_type":"markdown","source":"## 3.1. Join data, filter dates and clean missings <a id=\"section31\"></a>\n\nFirst of all, we perform some pre-processing prepare the dataset, consisting on:\n\n* **Join data**. Join train/test to facilitate data transformations\n* **Filter dates**. According to the challenge conditions, remove ConfirmedCases and Fatalities post 2020-03-12. Create additional date columns\n* **Missings**. Analyze and fix missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Merge train and test, exclude overlap\ndates_overlap = ['2020-03-19','2020-03-20','2020-03-21','2020-03-22','2020-03-23', '2020-03-24', '2020-03-25', \n                 '2020-03-26', '2020-03-27', '2020-03-28', '2020-03-29', '2020-03-30', '2020-03-31']\ntrain2 = train.loc[~train['Date'].isin(dates_overlap)]\nall_data = pd.concat([train2, test], axis = 0, sort=False)\n\n# Double check that there are no informed ConfirmedCases and Fatalities after 2020-03-11\nall_data.loc[all_data['Date'] >= '2020-03-19', 'ConfirmedCases'] = np.nan\nall_data.loc[all_data['Date'] >= '2020-03-19', 'Fatalities'] = np.nan\nall_data['Date'] = pd.to_datetime(all_data['Date'])\n\n# Create date columns\nle = preprocessing.LabelEncoder()\nall_data['Day_num'] = le.fit_transform(all_data.Date)\nall_data['Day'] = all_data['Date'].dt.day\nall_data['Month'] = all_data['Date'].dt.month\nall_data['Year'] = all_data['Date'].dt.year\n\n# Fill null values given that we merged train-test datasets\nall_data['Province_State'].fillna(\"None\", inplace=True)\nall_data['ConfirmedCases'].fillna(0, inplace=True)\nall_data['Fatalities'].fillna(0, inplace=True)\nall_data['Id'].fillna(-1, inplace=True)\nall_data['ForecastId'].fillna(-1, inplace=True)\n\ndisplay(all_data)\ndisplay(all_data.loc[all_data['Date'] == '2020-03-19'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"missings_count = {col:all_data[col].isnull().sum() for col in all_data.columns}\nmissings = pd.DataFrame.from_dict(missings_count, orient='index')\nprint(missings.nlargest(30, 0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.2. Compute lags and trends <a id=\"section32\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_trend(df, lag_list, column):\n    for lag in lag_list:\n        trend_column_lag = \"Trend_\" + column + \"_\" + str(lag)\n        df[trend_column_lag] = (df[column]-df[column].shift(lag, fill_value=-999))/df[column].shift(lag, fill_value=0)\n    return df\n\n\ndef calculate_lag(df, lag_list, column):\n    for lag in lag_list:\n        column_lag = column + \"_\" + str(lag)\n        df[column_lag] = df[column].shift(lag, fill_value=0)\n    return df\n\n\nts = time.time()\nall_data = calculate_lag(all_data, range(1,7), 'ConfirmedCases')\nall_data = calculate_lag(all_data, range(1,7), 'Fatalities')\nall_data = calculate_trend(all_data, range(1,7), 'ConfirmedCases')\nall_data = calculate_trend(all_data, range(1,7), 'Fatalities')\nall_data.replace([np.inf, -np.inf], 0, inplace=True)\nall_data.fillna(0, inplace=True)\nprint(\"Time spent: \", time.time()-ts)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As you see, the process is really fast. An example of some of the lag/trend columns for Spain:"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data[all_data['Country_Region']=='Spain'].iloc[40:50][['Id', 'Province_State', 'Country_Region', 'Date',\n       'ConfirmedCases', 'Fatalities', 'ForecastId', 'Day_num', 'ConfirmedCases_1',\n       'ConfirmedCases_2', 'ConfirmedCases_3', 'Fatalities_1', 'Fatalities_2',\n       'Fatalities_3']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.3. Add country details <a id=\"section33\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load countries data file\nworld_population = pd.read_csv(\"/kaggle/input/population-by-country-2020/population_by_country_2020.csv\")\n\n# Select desired columns and rename some of them\nworld_population = world_population[['Country (or dependency)', 'Population (2020)', 'Density (P/Km²)', 'Land Area (Km²)', 'Med. Age', 'Urban Pop %']]\nworld_population.columns = ['Country (or dependency)', 'Population (2020)', 'Density', 'Land Area', 'Med Age', 'Urban Pop']\n\n# Replace United States by US\nworld_population.loc[world_population['Country (or dependency)']=='United States', 'Country (or dependency)'] = 'US'\n\n# Remove the % character from Urban Pop values\nworld_population['Urban Pop'] = world_population['Urban Pop'].str.rstrip('%')\n\n# Replace Urban Pop and Med Age \"N.A\" by their respective modes, then transform to int\nworld_population.loc[world_population['Urban Pop']=='N.A.', 'Urban Pop'] = int(world_population.loc[world_population['Urban Pop']!='N.A.', 'Urban Pop'].mode()[0])\nworld_population['Urban Pop'] = world_population['Urban Pop'].astype('int16')\nworld_population.loc[world_population['Med Age']=='N.A.', 'Med Age'] = int(world_population.loc[world_population['Med Age']!='N.A.', 'Med Age'].mode()[0])\nworld_population['Med Age'] = world_population['Med Age'].astype('int16')\n\nprint(\"Cleaned country details dataset\")\ndisplay(world_population)\n\n# Now join the dataset to our previous DataFrame and clean missings (not match in left join)- label encode cities\nprint(\"Joined dataset\")\nall_data = all_data.merge(world_population, left_on='Country_Region', right_on='Country (or dependency)', how='left')\nall_data[['Population (2020)', 'Density', 'Land Area', 'Med Age', 'Urban Pop']] = all_data[['Population (2020)', 'Density', 'Land Area', 'Med Age', 'Urban Pop']].fillna(0)\ndisplay(all_data)\n\nprint(\"Encoded dataset\")\n# Label encode countries and provinces. Save dictionary for exploration purposes\nall_data.drop('Country (or dependency)', inplace=True, axis=1)\nall_data['Country_Region'] = le.fit_transform(all_data['Country_Region'])\nnumber_c = all_data['Country_Region']\ncountries = le.inverse_transform(all_data['Country_Region'])\ncountry_dict = dict(zip(countries, number_c)) \nall_data['Province_State'] = le.fit_transform(all_data['Province_State'])\nnumber_p = all_data['Province_State']\nprovince = le.inverse_transform(all_data['Province_State'])\nprovince_dict = dict(zip(province, number_p)) \ndisplay(all_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Predictions<a id=\"section4\"></a>\n\nOur obective in this section consists on  predicting the evolution of the expansion from a data-centric perspective, like any other regression problem. To do so, remember that the challenge specifies that submissions on the public LB shouldn only contain data previous to 2020-03-12.\n\nModels to apply:\n1. Ridge Regression for one country\n2. Ridge Regression for all countries (method 1)\n3. Ridge Regression for all countries (method 2)"},{"metadata":{},"cell_type":"markdown","source":"## 4.1. Ridge Regression for one country <a id=\"section41\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n\n# Day_num = 38 is March 1st\ny1 = all_data[(all_data['Country_Region']==country_dict['Spain']) & (all_data['Day_num']>39) & (all_data['Day_num']<=49)][['ConfirmedCases']]\nx1 = range(0, len(y1))\nax1.plot(x1, y1, 'bo--')\nax1.set_title(\"Spain ConfirmedCases between days 39 and 49\")\nax1.set_xlabel(\"Days\")\nax1.set_ylabel(\"ConfirmedCases\")\n\ny2 = all_data[(all_data['Country_Region']==country_dict['Spain']) & (all_data['Day_num']>39) & (all_data['Day_num']<=49)][['ConfirmedCases']].apply(lambda x: np.log(x))\nx2 = range(0, len(y2))\nax2.plot(x2, y2, 'bo--')\nax2.set_title(\"Spain Log ConfirmedCases between days 39 and 49\")\nax2.set_xlabel(\"Days\")\nax2.set_ylabel(\"Log ConfirmedCases\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filter selected features\ndata = all_data.copy()\nfeatures = ['Id', 'ForecastId', 'Country_Region', 'Province_State', 'ConfirmedCases', 'Fatalities', \n       'Day_num']\ndata = data[features]\n\n# Apply log transformation to all ConfirmedCases and Fatalities columns, except for trends\ndata[['ConfirmedCases', 'Fatalities']] = data[['ConfirmedCases', 'Fatalities']].astype('float64')\ndata[['ConfirmedCases', 'Fatalities']] = data[['ConfirmedCases', 'Fatalities']].apply(lambda x: np.log1p(x))\n\n# Replace infinites\ndata.replace([np.inf, -np.inf], 0, inplace=True)\n\n\n# Split data into train/test\ndef split_data(data):\n    \n    # Train set\n    x_train = data[data.ForecastId == -1].drop(['ConfirmedCases', 'Fatalities'], axis=1)\n    y_train_1 = data[data.ForecastId == -1]['ConfirmedCases']\n    y_train_2 = data[data.ForecastId == -1]['Fatalities']\n\n    # Test set\n    x_test = data[data.ForecastId != -1].drop(['ConfirmedCases', 'Fatalities'], axis=1)\n\n    # Clean Id columns and keep ForecastId as index\n    x_train.drop('Id', inplace=True, errors='ignore', axis=1)\n    x_train.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n    x_test.drop('Id', inplace=True, errors='ignore', axis=1)\n    x_test.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n    \n    return x_train, y_train_1, y_train_2, x_test\n\n\n# Ridge replace of the Linear regression model\ndef ridge_reg(X_train, Y_train, X_test):\n    # Create Ridge regression object\n    #regr = Ridge()        # commit 2\n    #regr = RidgeCV(cv=5)  # commit 4\n    #regr = Ridge(alpha=10) # commit 5\n    regr = Ridge(alpha=10) # now\n\n    # Train the model using the training sets\n    regr.fit(X_train, Y_train)\n\n    # Make predictions using the testing set\n    y_pred = regr.predict(X_test)\n    \n    return regr, y_pred\n\n\n# Submission function\ndef get_submission(s, df, target1, target2):\n    \n    prediction_1 = df[target1]\n    prediction_2 = df[target2]\n\n    # Submit predictions\n    prediction_1 = [int(item) for item in list(map(round, prediction_1))]\n    prediction_2 = [int(item) for item in list(map(round, prediction_2))]\n    \n    submission = pd.DataFrame({\n        \"ForecastId\": df['ForecastId'].astype('int32'), \n        \"ConfirmedCases\": prediction_1, \n        \"Fatalities\": prediction_2\n    })\n    submission.to_csv(s + '.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's try to see results when training with a single country:\n\n* **Spain**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select train (real) data from March 1 to March 22nd\ndates_list = ['2020-03-01', '2020-03-02', '2020-03-03', '2020-03-04', '2020-03-05', '2020-03-06', '2020-03-07', '2020-03-08', '2020-03-09', \n                 '2020-03-10', '2020-03-11','2020-03-12','2020-03-13','2020-03-14','2020-03-15','2020-03-16','2020-03-17','2020-03-18',\n                 '2020-03-19','2020-03-20','2020-03-21','2020-03-22','2020-03-23', '2020-03-24', '2020-03-25', '2020-03-26', '2020-03-27', \n                 '2020-03-28', '2020-03-29', '2020-03-30', '2020-03-31']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_data.loc[all_data['Country_Region']==country_dict['Spain']][40:65]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_rreg_basic_country(data, country_name, dates_list, day_start, shift):\n    \n    data_country = data[data['Country_Region']==country_dict[country_name]]\n    data_country = data_country.loc[data_country['Day_num']>=day_start]\n    X_train, Y_train_1, Y_train_2, X_test = split_data(data_country)\n    model, pred = ridge_reg(X_train, Y_train_1, X_test)\n\n    # Create a df with both real cases and predictions (predictions starting on March 12th)\n    X_train_check = X_train.copy()\n    X_train_check['Target'] = Y_train_1\n\n    X_test_check = X_test.copy()\n    X_test_check['Target'] = pred\n\n    X_final_check = pd.concat([X_train_check, X_test_check])\n\n    # Select predictions from March 1st to March 25th\n    predicted_data = X_final_check.loc[(X_final_check['Day_num'].isin(list(range(day_start, day_start+len(dates_list)))))].Target\n    real_data = train.loc[(train['Country_Region']==country_name) & (train['Date'].isin(dates_list))]['ConfirmedCases']\n    dates_list_num = list(range(0,len(dates_list)))\n\n    # Plot results\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n\n    ax1.plot(dates_list_num, np.expm1(predicted_data))\n    ax1.plot(dates_list_num, real_data)\n    ax1.axvline(17-shift, linewidth=2, ls = ':', color='grey', alpha=0.5)\n    ax1.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n    ax1.set_xlabel(\"Day count (from March \" + str(1+shift) + \" to March 25th)\")\n    ax1.set_ylabel(\"Confirmed Cases\")\n\n    ax2.plot(dates_list_num, predicted_data)\n    ax2.plot(dates_list_num, np.log1p(real_data))\n    ax2.axvline(17-shift, linewidth=2, ls = ':', color='grey', alpha=0.5)\n    ax2.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n    ax2.set_xlabel(\"Day count (from March \" + str(1+shift) + \" to March 30th)\")\n    ax2.set_ylabel(\"Log Confirmed Cases\")\n\n    plt.suptitle((\"ConfirmedCases predictions based on Log-Lineal Regression for \"+country_name))\n    \n    \n    \n# Filter Spain, run the Linear Regression workflow\ncountry_name = \"Spain\"\nmarch_day = 0\nday_start = 39+march_day\ndates_list2 = dates_list[march_day:]\nplot_rreg_basic_country(data, country_name, dates_list2, day_start, march_day)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filter Spain, run the Linear Regression workflow\ncountry_name = \"Spain\"\nmarch_day = 15\nday_start = 39+march_day\ndates_list2 = dates_list[march_day:]\nplot_rreg_basic_country(data, country_name, dates_list2, day_start, march_day)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Italy**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filter Italy, run the Linear Regression workflow\ncountry_name = \"Italy\"\nmarch_day = 0\nday_start = 39+march_day\ndates_list2 = dates_list[march_day:]\nplot_rreg_basic_country(data, country_name, dates_list2, day_start, march_day)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filter Italy, run the Linear Regression workflow\ncountry_name = \"Italy\"\nmarch_day = 15\nday_start = 39+march_day\ndates_list2 = dates_list[march_day:]\nplot_rreg_basic_country(data, country_name, dates_list2, day_start, march_day)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Germany**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filter Germany, run the Linear Regression workflow\ncountry_name = \"Germany\"\nmarch_day = 0\nday_start = 39+march_day\ndates_list2 = dates_list[march_day:]\nplot_rreg_basic_country(data, country_name, dates_list2, day_start, march_day)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filter Germany, run the Linear Regression workflow\ncountry_name = \"Germany\"\nmarch_day = 15\nday_start = 39+march_day\ndates_list2 = dates_list[march_day:]\nplot_rreg_basic_country(data, country_name, dates_list2, day_start, march_day)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Albania**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filter Albania, run the Linear Regression workflow\ncountry_name = \"Albania\"\nmarch_day = 0\nday_start = 39+march_day\ndates_list2 = dates_list[march_day:]\nplot_rreg_basic_country(data, country_name, dates_list2, day_start, march_day)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filter Albania, run the Linear Regression workflow\ncountry_name = \"Albania\"\nmarch_day = 15\nday_start = 39+march_day\ndates_list2 = dates_list[march_day:]\nplot_rreg_basic_country(data, country_name, dates_list2, day_start, march_day)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Andorra**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filter Andorra, run the Linear Regression workflow\ncountry_name = \"Andorra\"\nshift = 0\nday_start = 39+shift\ndates_list2 = dates_list[shift:]\nplot_rreg_basic_country(data, country_name, dates_list2, day_start, shift)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filter Andorra, run the Linear Regression workflow\ncountry_name = \"Andorra\"\nshift = 7\nday_start = 39+shift\ndates_list2 = dates_list[shift:]\nplot_rreg_basic_country(data, country_name, dates_list2, day_start, shift)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.2 Ridge Regression for all countries (method 1) <a id=\"section42\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"ts = time.time()\n\ndef ridge_reg_basic_all_countries(data, day_start):\n    \n    data2 = data.loc[data.Day_num >= day_start]\n\n    # Set the dataframe where we will update the predictions\n    data_pred = data[data.ForecastId != -1][['Country_Region', 'Province_State', 'Day_num', 'ForecastId']]\n    data_pred = data_pred.loc[data_pred['Day_num']>=day_start]\n    data_pred['Predicted_ConfirmedCases'] = [0]*len(data_pred)\n    data_pred['Predicted_Fatalities'] = [0]*len(data_pred)\n\n    print(\"Currently running Logistic Regression for all countries\")\n\n    # Main loop for countries\n    for c in data2['Country_Region'].unique():\n\n        # List of provinces\n        provinces_list = data2[data2['Country_Region']==c]['Province_State'].unique()\n\n        # If the country has several Province/State informed\n        if len(provinces_list)>1:\n            for p in provinces_list:\n                data_cp = data2[(data2['Country_Region']==c) & (data2['Province_State']==p)]\n                X_train, Y_train_1, Y_train_2, X_test = split_data(data_cp)\n                model_1, pred_1 = ridge_reg(X_train, Y_train_1, X_test)\n                model_2, pred_2 = ridge_reg(X_train, Y_train_2, X_test)\n                data_pred.loc[((data_pred['Country_Region']==c) & (data2['Province_State']==p)), 'Predicted_ConfirmedCases'] = pred_1\n                data_pred.loc[((data_pred['Country_Region']==c) & (data2['Province_State']==p)), 'Predicted_Fatalities'] = pred_2\n\n        # No Province/State informed\n        else:\n            data_c = data2[(data2['Country_Region']==c)]\n            X_train, Y_train_1, Y_train_2, X_test = split_data(data_c)\n            model_1, pred_1 = ridge_reg(X_train, Y_train_1, X_test)\n            model_2, pred_2 = ridge_reg(X_train, Y_train_2, X_test)\n            data_pred.loc[(data_pred['Country_Region']==c), 'Predicted_ConfirmedCases'] = pred_1\n            data_pred.loc[(data_pred['Country_Region']==c), 'Predicted_Fatalities'] = pred_2\n\n    # Apply exponential transf. and clean potential infinites due to final numerical precision\n    data_pred[['Predicted_ConfirmedCases', 'Predicted_Fatalities']] = data_pred[['Predicted_ConfirmedCases', 'Predicted_Fatalities']].apply(lambda x: np.expm1(x))\n    data_pred.replace([np.inf, -np.inf], 0, inplace=True) \n    \n    return data_pred\n\n\nday_start = 52\ndata_pred = ridge_reg_basic_all_countries(data, day_start)\nget_submission('submission', data_pred, 'Predicted_ConfirmedCases', 'Predicted_Fatalities')\n\nprint(\"Process finished in \", round(time.time() - ts, 2), \" seconds\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.3 Ridge Regression for all countries (method 2) <a id=\"section43\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ts = time.time()\n\n# # Set the dataframe where we will update the predictions\n# data2 = data.loc[data.Day_num >= day_start]\n# data_pred3 = data[data.ForecastId != -1][['Country_Region', 'Province_State', 'Day_num', 'ForecastId']]\n# data_pred3['Predicted_ConfirmedCases'] = [0]*len(data_pred3)\n# data_pred3['Predicted_Fatalities'] = [0]*len(data_pred3)\n# how_many_days = test.Date.nunique()\n    \n# print(\"Currently running Logistic Regression for all countries\")\n\n# # Main loop for countries\n# for c in data['Country_Region'].unique():\n    \n#     # List of provinces\n#     provinces_list = data2[data2['Country_Region']==c]['Province_State'].unique()\n        \n#     # If the country has several Province/State informed\n#     if len(provinces_list)>1:\n        \n#         for p in provinces_list:\n#             # Only fit starting from the first confirmed case in the country\n#             train_countries_no0 = data.loc[(data['Country_Region']==c) & (data['Province_State']==p) & (data.ConfirmedCases!=0) & (data.ForecastId==-1)]\n#             test_countries_no0 = data.loc[(data['Country_Region']==c) & (data['Province_State']==p) &  (data.ForecastId!=-1)]\n#             data2 = pd.concat([train_countries_no0, test_countries_no0])\n\n#             # If there are no previous cases, predict 0\n#             if len(train_countries_no0) == 0:\n#                 data_pred3.loc[((data_pred2['Country_Region']==c) & (data_pred3['Province_State']==p)), 'Predicted_ConfirmedCases'] = [0]*how_many_days\n#                 data_pred3.loc[((data_pred2['Country_Region']==c) & (data_pred3['Province_State']==p)), 'Predicted_Fatalities'] = [0]*how_many_days\n                \n#             else: \n#                 data_cp = data2[(data2['Country_Region']==c) & (data2['Province_State']==p)]\n#                 X_train, Y_train_1, Y_train_2, X_test = split_data(data_cp)\n#                 model_1, pred_1 = ridge_reg(X_train, Y_train_1, X_test)\n#                 model_2, pred_2 = ridge_reg(X_train, Y_train_2, X_test)\n#                 data_pred3.loc[((data_pred3['Country_Region']==c) & (data_pred3['Province_State']==p)), 'Predicted_ConfirmedCases'] = pred_1\n#                 data_pred3.loc[((data_pred3['Country_Region']==c) & (data_pred3['Province_State']==p)), 'Predicted_Fatalities'] = pred_2\n\n#     # No Province/State informed\n#     else:\n#         # Only fit starting from the first confirmed case in the country\n#         train_countries_no0 = data.loc[(data['Country_Region']==c) & (data.ConfirmedCases!=0) & (data.ForecastId==-1)]\n#         test_countries_no0 = data.loc[(data['Country_Region']==c) &  (data.ForecastId!=-1)]\n#         data2 = pd.concat([train_countries_no0, test_countries_no0])\n\n#         # If there are no previous cases, predict 0\n#         if len(train_countries_no0) == 0:\n#             data_pred3.loc[((data_pred3['Country_Region']==c)), 'Predicted_ConfirmedCases'] = [0]*how_many_days\n#             data_pred3.loc[((data_pred3['Country_Region']==c)), 'Predicted_Fatalities'] = [0]*how_many_days\n        \n#         else:\n#             data_c = data2[(data2['Country_Region']==c)]\n#             X_train, Y_train_1, Y_train_2, X_test = split_data(data_c)\n#             model_1, pred_1 = ridge_reg(X_train, Y_train_1, X_test)\n#             model_2, pred_2 = ridge_reg(X_train, Y_train_2, X_test)\n#             data_pred3.loc[(data_pred3['Country_Region']==c), 'Predicted_ConfirmedCases'] = pred_1\n#             data_pred3.loc[(data_pred3['Country_Region']==c), 'Predicted_Fatalities'] = pred_2\n\n# # Aplly exponential transf. and clean potential infinites due to final numerical precision\n# data_pred3[['Predicted_ConfirmedCases', 'Predicted_Fatalities']] = data_pred3[['Predicted_ConfirmedCases', 'Predicted_Fatalities']].apply(lambda x: np.expm1(x))\n# data_pred3.replace([np.inf, -np.inf], 0, inplace=True) \n\n# get_submission('sub0', data_pred3, 'Predicted_ConfirmedCases', 'Predicted_Fatalities')\n\n# print(\"Process finished in \", round(time.time() - ts, 2), \" seconds\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.4. Ridge regression with lags <a id=\"section44\"></a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # New split function, for one forecast day\n# def split_data_one_day(data, d):\n    \n#     #Train\n#     x_train = data[data.Day_num<d]\n#     y_train_1 = x_train.ConfirmedCases\n#     y_train_2 = x_train.Fatalities\n#     x_train.drop(['ConfirmedCases', 'Fatalities'], axis=1, inplace=True)\n    \n#     #Test\n#     x_test = data[data.Day_num==d]\n#     x_test.drop(['ConfirmedCases', 'Fatalities'], axis=1, inplace=True)\n    \n#     # Clean Id columns and keep ForecastId as index\n#     x_train.drop('Id', inplace=True, errors='ignore', axis=1)\n#     x_train.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n#     x_test.drop('Id', inplace=True, errors='ignore', axis=1)\n#     x_test.drop('ForecastId', inplace=True, errors='ignore', axis=1)\n    \n#     return x_train, y_train_1, y_train_2, x_test\n\n\n# def plot_real_vs_prediction_country(data, train, country_name, day_start, dates_list, march_day):\n\n#     # Select predictions from March 1st to March 25th\n#     predicted_data = data.loc[(data['Day_num'].isin(list(range(day_start, day_start+len(dates_list)))))].ConfirmedCases\n#     real_data = train.loc[(train['Country_Region']==country_name) & (train['Date'].isin(dates_list))]['ConfirmedCases']\n#     dates_list_num = list(range(0,len(dates_list)))\n\n#     # Plot results\n#     fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n\n#     ax1.plot(dates_list_num, np.expm1(predicted_data))\n#     ax1.plot(dates_list_num, real_data)\n#     ax1.axvline(17-march_day, linewidth=2, ls = ':', color='grey', alpha=0.5)\n#     ax1.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n#     ax1.set_xlabel(\"Day count (starting on March \" + str(march_day) + \"))\")\n#     ax1.set_ylabel(\"Confirmed Cases\")\n\n#     ax2.plot(dates_list_num, predicted_data)\n#     ax2.plot(dates_list_num, np.log1p(real_data))\n#     ax2.axvline(17-march_day, linewidth=2, ls = ':', color='grey', alpha=0.5)\n#     ax2.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n#     ax2.set_xlabel(\"Day count (starting on March \" + str(march_day) + \")\")\n#     ax2.set_ylabel(\"Log Confirmed Cases\")\n\n#     plt.suptitle((\"ConfirmedCases predictions based on Log-Lineal Regression for \"+country_name))\n    \n    \n# def plot_real_vs_prediction_country_fatalities(data, train, country_name, day_start, dates_list, march_day):\n\n#     # Select predictions from March 1st to March 25th\n#     predicted_data = data.loc[(data['Day_num'].isin(list(range(day_start, day_start+len(dates_list)))))].Fatalities\n#     real_data = train.loc[(train['Country_Region']==country_name) & (train['Date'].isin(dates_list))]['Fatalities']\n#     dates_list_num = list(range(0,len(dates_list)))\n\n#     # Plot results\n#     fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,6))\n\n#     ax1.plot(dates_list_num, np.expm1(predicted_data))\n#     ax1.plot(dates_list_num, real_data)\n#     ax1.axvline(17-march_day, linewidth=2, ls = ':', color='grey', alpha=0.5)\n#     ax1.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n#     ax1.set_xlabel(\"Day count (starting on March \" + str(march_day) + \")\")\n#     ax1.set_ylabel(\"Fatalities Cases\")\n\n#     ax2.plot(dates_list_num, predicted_data)\n#     ax2.plot(dates_list_num, np.log1p(real_data))\n#     ax2.axvline(17-march_day, linewidth=2, ls = ':', color='grey', alpha=0.5)\n#     ax2.legend(['Predicted cases', 'Actual cases', 'Train-test split'], loc='upper left')\n#     ax2.set_xlabel(\"Day count (starting on March \" + str(march_day) + \")\")\n#     ax2.set_ylabel(\"Log Fatalities Cases\")\n\n#     plt.suptitle((\"Fatalities predictions based on Log-Lineal Regression for \"+country_name))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Spain**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Function to compute the Linear Regression predictions with lags, for a certain Country/Region\n# def ridge_reg_with_lags_country(all_data, country_name, day_start, lag_size, country_dict):\n    \n#     ts = time.time()\n    \n#     # Filter country and features from all_data (dataset without data leaking)\n#     data = all_data.copy()\n#     features = ['Id', 'Province_State', 'Country_Region',\n#            'ConfirmedCases', 'Fatalities', 'ForecastId', 'Day_num']\n#     data = data[features]\n\n#     # Select country an data start (all days)\n#     data = data[data['Country_Region']==country_dict[country_name]]\n#     data = data.loc[data['Day_num']>=day_start]\n\n#     # Lags\n#     data = calculate_lag(data, range(1,lag_size), 'ConfirmedCases')\n#     data = calculate_lag(data, range(1,8), 'Fatalities')\n\n#     filter_col_confirmed = [col for col in data if col.startswith('Confirmed')]\n#     filter_col_fatalities= [col for col in data if col.startswith('Fataliti')]\n#     filter_col = np.append(filter_col_confirmed, filter_col_fatalities)\n    \n#     # Apply log transformation\n#     data[filter_col] = data[filter_col].apply(lambda x: np.log1p(x))\n#     data.replace([np.inf, -np.inf], 0, inplace=True)\n#     data.fillna(0, inplace=True)\n\n\n#     # Start/end of forecast\n#     start_fcst = all_data[all_data['Id']==-1].Day_num.min()\n#     end_fcst = all_data[all_data['Id']==-1].Day_num.max()\n\n#     for d in list(range(start_fcst, end_fcst+1)):\n#         X_train, Y_train_1, Y_train_2, X_test = split_data_one_day(data, d)\n#         model_1, pred_1 = ridge_reg(X_train, Y_train_1, X_test)\n#         data.loc[(data['Country_Region']==country_dict[country_name]) \n#                  & (data['Day_num']==d), 'ConfirmedCases'] = pred_1[0]\n#         model_2, pred_2 = ridge_reg(X_train, Y_train_2, X_test)\n#         data.loc[(data['Country_Region']==country_dict[country_name]) \n#                  & (data['Day_num']==d), 'Fatalities'] = pred_2[0]\n\n#         # Recompute lags \n#         data = calculate_lag(data, range(1,lag_size), 'ConfirmedCases')\n#         data = calculate_lag(data, range(1,8), 'Fatalities')\n#         data.replace([np.inf, -np.inf], 0, inplace=True)\n#         data.fillna(0, inplace=True)\n\n#     #print(\"Process for \", country_name, \"finished in \", round(time.time() - ts, 2), \" seconds\")\n    \n#     return data\n\n\n# # Function to compute the Linear Regression predictions with lags, for a certain Country/Region and State/province\n# def ridge_reg_with_lags_country_province(all_data, country_name, province_name, day_start, lag_size, country_dict):\n    \n#     ts = time.time()\n    \n#     # Filter country and features from all_data (dataset without data leaking)\n#     data = all_data.copy()\n#     features = ['Id', 'Province_State', 'Country_Region',\n#            'ConfirmedCases', 'Fatalities', 'ForecastId', 'Day_num']\n#     data = data[features]\n\n#     # Select country an data start (all days)\n#     data = data[(data['Country_Region']==country_dict[country_name]) & (data['Province_State']==province_dict[province_name])]\n#     data = data.loc[data['Day_num']>=day_start]\n\n#     # Lags\n#     data = calculate_lag(data, range(1,lag_size), 'ConfirmedCases')\n#     data = calculate_lag(data, range(1,lag_size), 'Fatalities')\n\n#     # Apply log transformation\n#     filter_col_confirmed = [col for col in data if col.startswith('Confirmed')]\n#     filter_col_fatalities= [col for col in data if col.startswith('Fataliti')]\n#     filter_col = np.append(filter_col_confirmed, filter_col_fatalities)\n#     data[filter_col] = data[filter_col].apply(lambda x: np.log1p(x))\n#     data.replace([np.inf, -np.inf], 0, inplace=True)\n#     data.fillna(0, inplace=True)\n\n#     # Start/end of forecast\n#     start_fcst = all_data[all_data['Id']==-1].Day_num.min()\n#     end_fcst = all_data[all_data['Id']==-1].Day_num.max()\n\n#     for d in list(range(start_fcst, end_fcst+1)):\n#         X_train, Y_train_1, Y_train_2, X_test = split_data_one_day(data, d)\n#         model_1, pred_1 = ridge_reg(X_train, Y_train_1, X_test)\n#         data.loc[(data['Country_Region']==country_dict[country_name]) & (data['Province_State']==province_dict[province_name]) \n#                  & (data['Day_num']==d), 'ConfirmedCases'] = pred_1[0]\n#         model_2, pred_2 = ridge_reg(X_train, Y_train_2, X_test)\n#         data.loc[(data['Country_Region']==country_dict[country_name]) & (data['Province_State']==province_dict[province_name])\n#                  & (data['Day_num']==d), 'Fatalities'] = pred_2[0]\n\n#         # Recompute lags \n#         data = calculate_lag(data, range(1,lag_size), 'ConfirmedCases')\n#         data = calculate_lag(data, range(1,lag_size), 'Fatalities')\n#         data.replace([np.inf, -np.inf], 0, inplace=True)\n#         data.fillna(0, inplace=True)\n\n#     #print(\"Process for \", country_name, \"/\", province_name, \"finished in \", round(time.time() - ts, 2), \" seconds\")\n    \n#     return data\n\n\n\n# # Run the model for Spain\n# country_name = 'Spain'\n# march_day = 0\n# day_start = 39 + march_day\n# dates_list2 = dates_list[march_day:]\n# lag_size = 30\n\n# data_c = ridge_reg_with_lags_country(all_data, country_name, day_start, lag_size, country_dict)\n# plot_real_vs_prediction_country(data_c, train, country_name, day_start, dates_list2, march_day)\n# plot_real_vs_prediction_country_fatalities(data_c, train, country_name, day_start, dates_list2, march_day)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Italy**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# ts = time.time()\n\n# # Inputs\n# country_name = \"Italy\"\n# march_day = 0\n# day_start = 39 + march_day\n# dates_list2 = dates_list[march_day:]\n# lag_size = 30\n\n# data_c = ridge_reg_with_lags_country(all_data, country_name, day_start, lag_size, country_dict)\n# plot_real_vs_prediction_country(data_c, train, country_name, day_start, dates_list2, march_day)\n# plot_real_vs_prediction_country_fatalities(data_c, train, country_name, day_start, dates_list2, march_day)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Germany**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Inputs\n# country_name = \"Germany\"\n# march_day = 0\n# day_start = 39 + march_day\n# dates_list2 = dates_list[march_day:]\n# lag_size = 30\n\n# data_c = ridge_reg_with_lags_country(all_data, country_name, day_start, lag_size, country_dict)\n# plot_real_vs_prediction_country(data_c, train, country_name, day_start, dates_list2, march_day)\n# plot_real_vs_prediction_country_fatalities(data_c, train, country_name, day_start, dates_list2, march_day)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Albania**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Inputs\n# country_name = \"Albania\"\n# march_day = 10\n# day_start = 39 + march_day\n# dates_list2 = dates_list[march_day:]\n# lag_size = 7\n\n# data_c = ridge_reg_with_lags_country(all_data, country_name, day_start, lag_size, country_dict)\n# plot_real_vs_prediction_country(data_c, train, country_name, day_start, dates_list2, march_day)\n# plot_real_vs_prediction_country_fatalities(data_c, train, country_name, day_start, dates_list2, march_day)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* **Andorra**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Inputs\n# country_name = \"Andorra\"\n# march_day = 5\n# day_start = 39 + march_day\n# dates_list2 = dates_list[march_day:]\n# lag_size = 1\n\n# data_c = ridge_reg_with_lags_country(all_data, country_name, day_start, lag_size, country_dict)\n# plot_real_vs_prediction_country(data_c, train, country_name, day_start, dates_list2, march_day)\n# plot_real_vs_prediction_country_fatalities(data_c, train, country_name, day_start, dates_list2, march_day)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Inputs\n# day_start = 39 \n# lag_size = 30\n\n# train3 = train.copy()\n# train3.Province_State.fillna(\"None\", inplace=True)\n\n# results_df = pd.DataFrame()\n\n# tp = time.time()\n\n# # Main loop for countries\n# for country_name in train3['Country_Region'].unique():\n\n#     # List of provinces\n#     provinces_list = train3[train3['Country_Region']==country_name]['Province_State'].unique()\n        \n#     # If the country has several Province/State informed\n#     if len(provinces_list)>1:\n#         for province_name in provinces_list:\n#             pred_province = ridge_reg_with_lags_country_province(all_data, country_name, province_name, day_start, lag_size, country_dict)\n#             results_df = pd.concat([results_df, pred_province])\n\n#     else:\n#         pred_country = ridge_reg_with_lags_country(all_data, country_name, day_start, lag_size, country_dict)\n#         results_df = pd.concat([results_df, pred_country])\n        \n# results_df_submit = results_df.copy()\n# results_df_submit['ConfirmedCases'] = results_df_submit['ConfirmedCases'].apply(lambda x: np.expm1(x))\n# results_df_submit['Fatalities'] = results_df_submit['Fatalities'].apply(lambda x: np.expm1(x))\n        \n# get_submission('sub1',results_df_submit.loc[results_df_submit['ForecastId']!=-1], 'ConfirmedCases', 'Fatalities')\n# print(\"Complete process finished in \", time.time()-tp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# results_df_2 = results_df.copy()\n\n# day_start = 39\n# data_pred2 = ridge_reg_basic_all_countries(data, day_start)\n# day_num_test = 57    # Day 2020-04-18\n\n\n# # Main loop for countries\n# for country_name in train3['Country_Region'].unique():\n\n#     # List of provinces\n#     provinces_list = train3[train3['Country_Region']==country_name]['Province_State'].unique()\n\n#     # Countries with several Province_State informed\n#     if len(provinces_list)>1:\n#         for province_name in provinces_list:\n        \n#             tmp_index = all_data.index[(all_data['Country_Region']==country_dict[country_name]) & \n#                            (all_data['Province_State']==province_dict[province_name]) & \n#                            (all_data['Day_num']<day_num_test) & \n#                            (all_data['ConfirmedCases']!=0)]\n\n#             # When there is not enough data\n#             if len(tmp_index) < 30:\n                \n#                 # ConfirmedCases\n#                 results_df_2.loc[((results_df_2['Country_Region']==country_dict[country_name]) & \n#                                   (results_df_2['Province_State']==province_dict[province_name]) &\n#                                   (results_df_2['Day_num']>=day_num_test)), 'ConfirmedCases'] = data_pred2.loc[((data_pred2['Country_Region']==country_dict[country_name]) & \n#                                   (data_pred2['Province_State']==province_dict[province_name]) & \n#                                   (data_pred2['Day_num']>=day_num_test)), 'Predicted_ConfirmedCases'].apply(lambda x: np.log1p(x))\n                \n#                 #Fatalities\n#                 results_df_2.loc[((results_df_2['Country_Region']==country_dict[country_name]) & \n#                                   (results_df_2['Province_State']==province_dict[province_name]) &\n#                                   (results_df_2['Day_num']>=day_num_test)), 'Fatalities'] = data_pred2.loc[((data_pred2['Country_Region']==country_dict[country_name]) & \n#                                   (data_pred2['Province_State']==province_dict[province_name]) & \n#                                   (data_pred2['Day_num']>=day_num_test)), 'Predicted_Fatalities'].apply(lambda x: np.log1p(x))\n                \n#     # Countries without Province_State\n#     else:\n#         tmp_index = all_data.index[(all_data['Country_Region']==country_dict[country_name]) & \n#                            (all_data['Day_num']<day_num_test) & \n#                            (all_data['ConfirmedCases']!=0)]\n\n#         # When there is not enough data\n#         if len(tmp_index) < 30:\n            \n#             #Confirmed Cases\n#             results_df_2.loc[((results_df_2['Country_Region']==country_dict[country_name]) & \n#                             (results_df_2['Day_num']>=day_num_test)), 'ConfirmedCases'] = data_pred2.loc[((data_pred2['Country_Region']==country_dict[country_name]) & \n#                             (data_pred2['Day_num']>=day_num_test)), 'Predicted_ConfirmedCases'].apply(lambda x: np.log1p(x))\n            \n#             results_df_2.loc[((results_df_2['Country_Region']==country_dict[country_name]) & \n#                             (results_df_2['Day_num']>=day_num_test)), 'Fatalities'] = data_pred2.loc[((data_pred2['Country_Region']==country_dict[country_name]) & \n#                             (data_pred2['Day_num']>=day_num_test)), 'Predicted_Fatalities'].apply(lambda x: np.log1p(x))\n            \n# results_df_2 = results_df_2.loc[results_df_2['Day_num']>=day_num_test]\n# results_df_2[['ConfirmedCases', 'Fatalities']] = results_df_2[['ConfirmedCases', 'Fatalities']].apply(lambda x: np.expm1(x))\n# get_submission('sub2',results_df_2, 'ConfirmedCases', 'Fatalities')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}