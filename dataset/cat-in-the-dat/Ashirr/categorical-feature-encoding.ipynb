{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import DecisionTreeClassifier \n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\ndf_train = pd.read_csv('../input/cat-in-the-dat/train.csv')\ndf_test = pd.read_csv('../input/cat-in-the-dat/test.csv')\ndf_SS = pd.read_csv('../input/cat-in-the-dat/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LogisticRegressionCV\nfrom sklearn.preprocessing import OneHotEncoder \nfrom sklearn import preprocessing \nfrom sklearn.metrics import confusion_matrix \nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.tree import export_graphviz\nfrom sklearn.externals.six import StringIO  \nfrom IPython.display import Image  \n\n\n\n\nfrom xgboost import XGBClassifier\n\nfrom sklearn import svm\n\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[\"target\"].value_counts()#No missing values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#encoding categorical columns\ndf_train_bin= df_train.iloc[:,1:6]\n\n#USING CUSTOM MAP FOR BIN_3 AND BIN_4\nbin_3_mapper = {'F':0, \n                'T':1}\n\ndf_train_bin['bin_3C'] = df_train_bin['bin_3'].replace(bin_3_mapper)\n\nbin_4_mapper = {'N':0, \n                'Y':1}\n\ndf_train_bin['bin_4C'] = df_train_bin['bin_4'].replace(bin_4_mapper)\ndf_train_bin_cleaned=  df_train_bin.iloc[:,[0,1,2,5,6]]\n\n#USING ONE HOT ENCODING FOR NOMINAL FEATURES\ndf_train_nom=df_train.iloc[:,6:16]\n\nonehotencoder = OneHotEncoder() \n  \ndf_train_nom_cleaned = pd.get_dummies(df_train_nom.iloc[:,[0,1,2,3,4,5,6,7,8,9]])  ##col 5,6,7,8,9 removed\n\n#df_train_nom_cleaned['nom_7C'] = label_encoder.fit_transform(df_train_nom['nom_7'])  \n#df_train_nom_cleaned['nom_8C'] = label_encoder.fit_transform(df_train_nom['nom_8'])  \n#df_train_nom_cleaned['nom_9C'] = label_encoder.fit_transform(df_train_nom['nom_9'])  \ndf_train_nom_cleaned\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#USING CUSTOM MAP LABELS FOR ORDINAL FEATURES\ndf_train_ord_time = df_train.iloc[:,16:24]\n\n#ord_1 mapping\nord_1_mapper = {'Novice':0, \n                'Contributor':1,\n               'Expert':2,\n                'Master':3,\n               'Grandmaster':4}\n\ndf_train_ord_time['ord_1C'] = df_train_ord_time['ord_1'].replace(ord_1_mapper)\n\n#ord_2 mapping\nord_2_mapper = {'Freezing':0, \n                'Cold':1,\n               'Warm':2,\n                'Hot':3,\n               'Boiling Hot':4,\n                'Lava Hot':5\n               }\n\ndf_train_ord_time['ord_2C'] = df_train_ord_time['ord_2'].replace(ord_2_mapper)\n\n#ord_3 mapping\nord_3_mapper = {'a':0, 'b':1,'c':2,'d':3,'e':4,'f':5,'g':6,'h':7,'i':8,'j':9,'k':10,'l':11,'m':12,'n':13,'o':14\n               }\n\ndf_train_ord_time['ord_3C'] = df_train_ord_time['ord_3'].replace(ord_3_mapper)\n\n#ord_4 mapping\ndf_train_ord_time['ord_4C'] = df_train_ord_time['ord_4'].apply(lambda x: ord(x)-65)\n\n#ord_5 mapping\nlabel_encoder = preprocessing.LabelEncoder() \ndf_train_ord_time['ord_5C'] = label_encoder.fit_transform(df_train_ord_time['ord_5'])   \n\ndf_train_ord_time_cleaned = df_train_ord_time.iloc[:,[0,6,7,8,9,10,11,12]]#6,7 time\n\ndf_train_all =  pd.concat([df_train_bin_cleaned,df_train_ord_time_cleaned], axis=1) #, df_train_nom_cleaned\n\ndf_train_all\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df_train_all,df_train.iloc[:,24].values , test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision trees"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train1= X_train.iloc[0:1000,:] # (240000, 13)\ny_train1=y_train[0:1000]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = DecisionTreeClassifier()\n\n# Train Decision Tree Classifer\nclf = clf.fit(X_train1,y_train1)\n\n#Predict the response for test dataset\ny_pred = clf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import graphviz\n\ndata = export_graphviz(clf,out_file=None,feature_names=X_train.columns,class_names=['0','1'],   \n                         filled=True, rounded=True,  \n                         special_characters=True)\ngraph = graphviz.Source(data)\ngraph","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"# Logistic regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"#create an instance and fit the model \nlogmodel = LogisticRegression(C=0.1338,\n                        solver=\"lbfgs\",\n                        tol=0.0003,\n                        max_iter=5000)# cv: if integer then it is the numbe\nlogmodel.fit(X_train, y_train)\ny_pred = logmodel.predict_proba(X_test)\nroc_auc_score(y_test,y_pred[:, 1]) #7830551086693487 ,0.7829327708379799\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"ogistic = LogisticRegression()\n# Create regularization penalty space\npenalty = ['l1', 'l2']\n\n# Create regularization hyperparameter space\nC = np.logspace(0, 4, 2)\n\n# Create hyperparameter options\nhyperparameters = dict(C=C, penalty=penalty)\n\n# Create grid search using 5-fold cross validation\nclf = GridSearchCV(logistic, hyperparameters, cv=2, verbose=1,scoring='roc_auc')\n\nbest_model = clf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"p=best_model.predict_proba(X_test)\nroc_auc_score(y_test,p[:, 1]) #0.7831027261785495","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"logit_roc_auc = roc_auc_score(y_test,y_pred )\nfpr, tpr, thresholds = roc_curve(y_test, logmodel.predict_proba(X_test))\nplt.figure()\nplt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()\"\"\"\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# XG BOOST"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nmodel_xg = XGBClassifier(show_progress=True,verbose_eval=50,silent =1)\nmodel_xg.fit(X_train, y_train)\ny_pred_xg = model_xg.predict_proba(X_test)\nroc_auc_score(y_test,y_pred_xg[:, 1])\"\"\"\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"SVC_model = svm.SVC(kernel='linear', C = 1.0)\nSVC_model.fit(X_train, y_train)\n\ny_pred_svc = SVC_model.predict_proba(X_test)\nroc_auc_score(y_test,y_pred_svc[:, 1])\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DEEP"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"from keras import Sequential\nfrom keras.layers import Dense\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"classifier = Sequential()\n#First Hidden Layer\nclassifier.add(Dense(8, activation='relu', kernel_initializer='random_normal', input_dim=13))\n#Second  Hidden Layer\nclassifier.add(Dense(8, activation='relu', kernel_initializer='random_normal'))\n#3  Hidden Layer\nclassifier.add(Dense(8, activation='relu', kernel_initializer='random_normal'))\n#4  Hidden Layer\nclassifier.add(Dense(8, activation='relu', kernel_initializer='random_normal'))\n#5  Hidden Layer\nclassifier.add(Dense(8, activation='relu', kernel_initializer='random_normal'))\n#6  Hidden Layer\nclassifier.add(Dense(8, activation='relu', kernel_initializer='random_normal'))\n#Output Layer\nclassifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n\nclassifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"classifier.fit(X_train,y_train, batch_size=10, epochs=2) # 0.7261\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"pred_neural = classifier.predict(X_test)\n\nroc_auc_score(y_test,pred_neural) #0.7831027261785495","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predicting values\n\"\"\"\n#encoding categorical columns\ndf_test_bin= df_test.iloc[:,1:6]\n\n#USING CUSTOM MAP FOR BIN_3 AND BIN_4\n\n\ndf_test_bin['bin_3C'] = df_test_bin['bin_3'].replace(bin_3_mapper)\n\n\n\ndf_test_bin['bin_4C'] = df_test_bin['bin_4'].replace(bin_4_mapper)\ndf_test_bin_cleaned=  df_test_bin.iloc[:,[0,1,2,5,6]]\n\n#USING ONE HOT ENCODING FOR NOMINAL FEATURES\ndf_test_nom=df_test.iloc[:,6:16]\n\nonehotencoder = OneHotEncoder() \n  \ndf_test_nom_cleaned = pd.get_dummies(df_test_nom.iloc[:,[0,1,2,3,4,5,6]] )  ##col 7,8,9 removed\n\n#USING CUSTOM MAP LABELS FOR ORDINAL FEATURES\ndf_test_ord_time = df_test.iloc[:,16:24]\n\n#ord_1 mapping\n\n\ndf_test_ord_time['ord_1C'] = df_test_ord_time['ord_1'].replace(ord_1_mapper)\n\n#ord_2 mapping\n\n\ndf_test_ord_time['ord_2C'] = df_test_ord_time['ord_2'].replace(ord_2_mapper)\n\n#ord_3 mapping\n\ndf_test_ord_time['ord_3C'] = df_test_ord_time['ord_3'].replace(ord_3_mapper)\n\n#ord_4 mapping\ndf_test_ord_time['ord_4C'] = df_test_ord_time['ord_4'].apply(lambda x: ord(x)-65)\n\n#ord_5 mapping\nlabel_encoder = preprocessing.LabelEncoder() \ndf_test_ord_time['ord_5C'] = label_encoder.fit_transform(df_test_ord_time['ord_5'])   \n\ndf_test_ord_time_cleaned = df_test_ord_time.iloc[:,[0,6,7,8,9,10,11,12]]\n\ndf_test_all =  pd.concat([df_test_bin_cleaned,df_test_nom_cleaned,df_test_ord_time_cleaned], axis=1) \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"y_pred_actual = logmodel.predict_proba(df_test_all)\ny_pred_actual ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"Id =  pd.DataFrame(df_test['id'] , columns=['id'])\npredictions_Log  = pd.DataFrame(y_pred_actual[:,1]  , columns=['target']) \nid_predictions_Log = pd.concat([Id,predictions_Log],axis=1)\nid_predictions_Log.head()\npd.DataFrame(id_predictions_Log, columns=['id','target']).to_csv('id_predictions_Log.csv',index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}