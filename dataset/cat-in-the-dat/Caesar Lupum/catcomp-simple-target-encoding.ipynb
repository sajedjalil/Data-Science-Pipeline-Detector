{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Categorical Feature Encoding Challenge WITH PYTHON\n[CrislÃ¢nio MacÃªdo](https://medium.com/sapere-aude-tech) -  December, 31th, 2019\n\n ðŸ± CatComp - Simple Target Encoding : [ ðŸ± CatComp - Simple Target Encoding ](https://www.kaggle.com/caesarlupum/catcomp-simple-target-encoding)\n\n----------\n----------"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"## About this Competition\n\n![](https://imgflip.com/s/meme/Smiling-Cat.jpg)\n\n> #### In this competition, you will be predicting the probability [0, 1] of a binary target column.\n\nThe data contains binary features (bin_*), nominal features (nom_*), ordinal features (ord_*) as well as (potentially cyclical) day (of the week) and month features. The string ordinal features ord_{3-5} are lexically ordered according to string.ascii_letters.\nSince the purpose of this competition is to explore various encoding strategies, the data has been simplified in that (1) there are no missing values, and (2) the test set does not contain any unseen feature values (See this). (Of course, in real-world settings both of these factors are often important to consider!)\n\n#### Files\n- train.csv - the training set\n- test.csv - the test set; you must make predictions against this data\n- sample_submission.csv - a sample submission file in the correct format"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"#### Target encodingâ€”as implemented in contrib.scikit-learn.org/categorical-encodingâ€”can prove powerful especially to encode high cardinality categorical features. \n> This implementation assumes that the target is ordinal (which is the case here as it is a binary outcome, but for many multiclass classification that is often not the case).\n\nHere we use it for all features as a starting point, but many of those features might better contribute to the overall predictive power when encoded with alternative techniques.\n\nWe use k-fold to mitigate data leaks that would otherwise almost certainly lead to overfitting. Alternatively, we could split the train set, but given the small size of it, a resampling technique sounds preferable.\n\n\n<html>\n<body>\n\n<p><font size=\"5\" color=\"Blue\">\nIf you find this kernel useful or interesting, please don't forget to upvote the kernel =)\n</font></p>\n\n</body>\n</html>\n\n"},{"metadata":{},"cell_type":"markdown","source":"## Import libs"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport category_encoders as ce\nimport lightgbm as lgb\nfrom sklearn import linear_model\nfrom sklearn.model_selection import StratifiedKFold\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Suppress warnings \nimport warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nfrom IPython.display import HTML\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read datasets"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train = pd.read_csv('../input/cat-in-the-dat/train.csv')\ntest = pd.read_csv('../input/cat-in-the-dat/test.csv')\nprint(train.target.value_counts()[0]/300000, train.target.value_counts()[1]/300000, )\ntrain.sort_index(inplace=True)\ntrain_y = train['target']\ntest_id = test['id']\ntrain.drop(['target', 'id'], axis=1, inplace=True)\ntest.drop('id', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Encoding the Features"},{"metadata":{},"cell_type":"markdown","source":"## Target encoding\n \t\t\nTarget-based encoding is numerization of categorical variables via target. In this method, we replace the categorical variable with just one new numerical variable and replace each category of the categorical variable with its corresponding probability of the target (if categorical) or average of the target (if numerical). The main drawbacks of this method are its dependency to the distribution of the target, and its lower predictability power compare to the binary encoding method.\n\nfor example,\n![](http://www.renom.jp/notebooks/tutorial/preprocessing/category_encoding/renom_cat_target.png)\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"# Encoding Categories"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"HTML('<iframe width=\"680\" height=\"620\" src=\"https://www.youtube.com/embed/8odLEbSGXoI\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\ncat_feat_to_encode = train.columns.tolist()\n# target =0  0.69412%, target =1 0.30588\nsmoothing=0.50\n\noof = pd.DataFrame([])\nfor tr_idx, oof_idx in StratifiedKFold(n_splits=5, random_state=1, shuffle=True).split(train, train_y):\n    \n    ce_target_encoder = ce.TargetEncoder(cols = cat_feat_to_encode, smoothing=smoothing)\n    ce_target_encoder.fit(train.iloc[tr_idx, :], train_y.iloc[tr_idx])\n    oof = oof.append(ce_target_encoder.transform(train.iloc[oof_idx, :]), ignore_index=False)\n\n    \n    \n    \nce_target_encoder = ce.TargetEncoder(cols = cat_feat_to_encode, smoothing=smoothing)\nce_target_encoder.fit(train, train_y)\ntrain = oof.sort_index() \ntest = ce_target_encoder.transform(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic Regression"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"glm = linear_model.LogisticRegression(\n  random_state=1, solver='lbfgs', max_iter=2019, fit_intercept=True, \n  penalty='none', verbose=0)\n\nglm.fit(train, train_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## predict proba"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from datetime import datetime\npd.DataFrame({'id': test_id, 'target': glm.predict_proba(test)[:,1]}).to_csv(\n    'sub_' + str(datetime.now().strftime('%Y-%m-%d_%H-%M-%S')) + '.csv', \n    index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# General Findings"},{"metadata":{},"cell_type":"markdown","source":"### Categorical Material\nhttps://www.kaggle.com/c/cat-in-the-dat/discussion/110924#latest-638837\n\nhttps://www.kaggle.com/c/cat-in-the-dat/discussion/105512#latest-656503\n\nhttps://www.kaggle.com/c/cat-in-the-dat/discussion/111930#latest-666056\n\nhttps://www.kaggle.com/c/cat-in-the-dat/discussion/113213#latest-666299\n\n### Cyclic features\nhttps://www.kaggle.com/c/cat-in-the-dat/discussion/106630#latest-648493\n\nhttps://www.kaggle.com/c/cat-in-the-dat/discussion/105610#latest-647944\n\nhttps://www.kaggle.com/c/cat-in-the-dat/discussion/108805#latest-629677\n\n\n### Techniques to handle categorical variables\n\nhttps://www.kaggle.com/c/cat-in-the-dat/discussion/108805#latest-629677\n\nhttps://www.kaggle.com/c/cat-in-the-dat/discussion/108805#latest-629677\n\n"},{"metadata":{},"cell_type":"markdown","source":"\n<html>\n<body>\n\n<p><font size=\"5\" color=\"blue\">If you like my kernel please consider upvoting it</font></p>\n<p><font size=\"4\" color=\"purple\">Remember the upvote button is next to the fork button, and it's free too! ;)</font></p>\n\n</body>\n</html>\n"},{"metadata":{},"cell_type":"markdown","source":"# Final"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}