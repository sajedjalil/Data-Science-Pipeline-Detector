{"cells":[{"metadata":{"_cell_guid":"8c7b3825-1d60-479a-8a64-1b2887ff8dae","_uuid":"a82e2ad6a19c9ce75530f0b3a3c4a21c8c82a006"},"cell_type":"markdown","source":"This tutorial provides an overview of the DonorsChoose data set, as well as a quick-start guide to building your first model in TensorFlow and submitting your entry to Kaggle. \n\nFor a refresher on machine learning fundamentals, check out [Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/). For more practice building models in TensorFlow, check out the [companion exercises](https://developers.google.com/machine-learning/crash-course/exercises#programming)."},{"metadata":{"_cell_guid":"fa3052cd-3b4c-4ba7-b9d2-d18959163aea","_uuid":"2c2fb7b184624a65c9f7481225c5b1eeff3fe402"},"cell_type":"markdown","source":"# About the DonorsChoose Data Set\n\nThe goal of the DonorsChoose competition is to build a model that can accurately predict whether a teacher's project proposal was accepted, based on the data they provided in their application. The `train.csv` data set provided by DonorsChoose contains the following features:\n\nFeature | Description | Data Type\n----------|---------------|------------\n**`project_id`** | A unique identifier for the proposed project. **Example:** `p036502`   | string\n**`project_title`**    | Title of the project. **Examples:**<br><ul><li><code>Art Will Make You Happy!</code></li><li><code>First Grade Fun</code></li></ul> | string\n**`project_grade_category`** | Grade level of students for which the project is targeted. One of the following enumerated values: <br/><ul><li><code>Grades PreK-2</code></li><li><code>Grades 3-5</code></li><li><code>Grades 6-8</code></li><li><code>Grades 9-12</code></li></ul>  | string\n **`project_subject_categories`** | One or more (comma-separated) subject categories for the project from the following enumerated list of values:  <br/><ul><li><code>Applied Learning</code></li><li><code>Care &amp; Hunger</code></li><li><code>Health &amp; Sports</code></li><li><code>History &amp; Civics</code></li><li><code>Literacy &amp; Language</code></li><li><code>Math &amp; Science</code></li><li><code>Music &amp; The Arts</code></li><li><code>Special Needs</code></li><li><code>Warmth</code></li></ul><br/> **Examples:** <br/><ul><li><code>Music &amp; The Arts</code></li><li><code>Literacy &amp; Language, Math &amp; Science</code></li>  | string\n  **`school_state`** | State where school is located ([Two-letter U.S. postal code](https://en.wikipedia.org/wiki/List_of_U.S._state_abbreviations#Postal_codes)). **Example:** `WY`| string\n**`project_subject_subcategories`** | One or more (comma-separated) subject subcategories for the project. **Examples:** <br/><ul><li><code>Literacy</code></li><li><code>Literature &amp; Writing, Social Sciences</code></li></ul> | string\n**`project_resource_summary`** | An explanation of the resources needed for the project. **Example:** <br/><ul><li><code>My students need hands on literacy materials to manage sensory needs!</code</li></ul> | string\n**`project_essay_1`**    | First application essay<sup>*</sup>  | string\n**`project_essay_2`**    | Second application essay<sup>*</sup> | string\n**`project_essay_3`**    | Third application essay<sup>*</sup> | string\n**`project_essay_4`**    | Fourth application essay<sup>*</sup> | string\n**`project_submitted_datetime`** | Datetime when project application was submitted. **Example:** `2016-04-28 12:43:56.245`   | int64\n**`teacher_id`** | A unique identifier for the teacher of the proposed project. **Example:** `bdf8baa8fedef6bfeec7ae4ff1c15c56`  | string\n**`teacher_prefix`** | Teacher's title. One of the following enumerated values: <br/><ul><li><code>nan</code></li><li><code>Dr.</code></li><li><code>Mr.</code></li><li><code>Mrs.</code></li><li><code>Ms.</code></li><li><code>Teacher.</code></li></ul>  | string\n**`teacher_number_of_previously_posted_projects`** | Number of project applications previously submitted by the same teacher. **Example:** `2` | int64\n\n<sup>*</sup> See the section <b>Notes on the Essay Data</b> for more details about these features.\n\nAdditionally, the `resources.csv` data set provides more data about the resources required for each project. Each line in this file represents a resource required by a project:\n\nFeature | Description | Data Type\n----------|---------------|------------\n**`id`** | A `project_id` value from the `train.csv` file.  **Example:** `p036502`   | string\n**`description`** | Desciption of the resource. **Example:** `Tenor Saxophone Reeds, Box of 25`   | string\n**`quantity`** | Quantity of the resource required. **Example:** `3`   | string\n**`price`** | Price of the resource required. **Example:** `9.95`   | string\n\n**Note:** Many projects require multiple resources. The `id` value corresponds to a `project_id` in train.csv, so you use it as a key to retrieve all resources needed for a project:\n\nThe data set contains the following label (the value you will attempt to predict):\n\nLabel | Description | Data Type\n----------|---------------|------------\n`project_is_approved` | A binary flag indicating whether DonorsChoose approved the project. A value of `0` indicates the project was not approved, and a value of `1` indicates the project was approved. | int64"},{"metadata":{"_uuid":"154f0907b0ce9cbacd7125d72ee0a32c9e2df7b6"},"cell_type":"markdown","source":"## Notes on the Essay Data\n\nPrior to May 17, 2016, the prompts for the essays were as follows:\n\n* **`project_essay_1`**: \"Introduce us to your classroom\"\n* **`project_essay_2`**: \"Tell us more about your students\"\n* **`project_essay_3`**: \"Describe how your students will use the materials you're requesting\"\n* **`project_essay_4`**: \"Close by sharing why your project will make a difference\"\n\nStarting on May 17, 2016, the number of essays was reduced from 4 to 2, and the prompts for the first 2 essays were changed to the following:\n\n* **`project_essay_1`**: \"Describe your students: What makes your students special? Specific details about their background, your neighborhood, and your school are all helpful.\"\n* **`project_essay_2`**: \"About your project: How will these materials make a difference in your students' learning and improve their school lives?\"\n\nFor all projects with `project_submitted_datetime` of 2016-05-17 and later, the values of **project_essay_3** and **project_essay_4** will be `NaN`.\n"},{"metadata":{"_cell_guid":"b19a0e22-beb7-41fa-9f5b-a64bb7098731","_uuid":"66c4d0182b4651c30127ff56914a01ecdcc808db"},"cell_type":"markdown","source":"## Explore the DonorsChoose Data\n\nLet's explore our data using [pandas](https://pandas.pydata.org/), an open source Python data analysis library. (For more practice using pandas, see the  [Quick Introduction to pandas](https://colab.research.google.com/notebooks/mlcc/intro_to_pandas.ipynb) workbook. We'll also import [matplotlib](https://matplotlib.org/) to do some data visualizations.\n\nFirst, run the following cell to import pandas and matplotlib:"},{"metadata":{"_cell_guid":"6496b8ea-0669-4060-8e74-9781a3b83990","collapsed":true,"_uuid":"6be9c6287dc01cd729308266b16a5ef61c999923","trusted":false},"cell_type":"code","source":"import pandas as pd\nfrom matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f5ada641-2a72-473b-85e6-8bdfc53233ca","_uuid":"2e7c9da2bb8e57e7d3d6300ef4a6c7362e1a10d4"},"cell_type":"markdown","source":"Next, read the DonorsChoose training data into a `DataFrame`:"},{"metadata":{"_cell_guid":"98fcf917-cda3-4596-b538-3df27f9f5f0e","collapsed":true,"_uuid":"0889eefe3df46fff71f8442d6607ee52e8f491f9","trusted":false},"cell_type":"code","source":"# Filepath to main training dataset.\ntrain_file_path = '../input/train.csv'\n\n# Read data and store in DataFrame.\ntrain_data = pd.read_csv(train_file_path, sep=',')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"0aec80ec-9bdb-476f-b002-311bc9e2adc6","_uuid":"06a16246878db2b231650de036e89fca65c5ee09"},"cell_type":"markdown","source":"List all the fields in the data set:"},{"metadata":{"_cell_guid":"98dbc86c-316f-4b0e-b78e-617b35f2da98","collapsed":true,"_uuid":"790077ba2f255af655d17b33b767d30c5a66a224","trusted":false},"cell_type":"code","source":"train_data.columns","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"56a1d80d-5d37-4a80-a23f-bca5ebe7e4db","_uuid":"3ec8da52fd1edce18862905e624747acad2a6aed"},"cell_type":"markdown","source":"Retrieve the first three examples:"},{"metadata":{"_cell_guid":"465ba7bc-f80c-440a-8f47-16c404cd2187","collapsed":true,"_uuid":"fb44ce4af7d24d6cee0ef95f54e6a05eda7e3e57","trusted":false},"cell_type":"code","source":"train_data.head(3)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f297bfa3-fd11-4cd8-9600-fc1cb26e82a9","_uuid":"e68fbacc7118bf981c2510b4f3f6e36894fe2c42"},"cell_type":"markdown","source":"Let's take a closer look at our one numeric feature, `teacher_number_of_previously_posted_projects`. Print some key stats using the  `describe()` method:"},{"metadata":{"_cell_guid":"e390e904-3ce4-436c-8d6a-2d4fc2511f8c","collapsed":true,"_uuid":"f77ce659218fbdc0faf25d5cd485ddb9a5c3e919","trusted":false},"cell_type":"code","source":"# Describe data set and retrieve data for teacher_number_of_previously_posted_projects\ntrain_data.describe()[\"teacher_number_of_previously_posted_projects\"]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"358086a1-a3e1-40de-96da-b2ad68827b90","_uuid":"e94c8fd19bf6637e1fcd3d7c6d7285af15f6c29c"},"cell_type":"markdown","source":"We can see that the minumum number of previously posted projects for a teacher is 0, the maximum number is 451, and the mean (average) number is 11.23. Let's visualize the distribution using a histogram, to get a better sense of the spread."},{"metadata":{"_cell_guid":"9c9550e1-c071-4087-9c26-f0a680eba26f","collapsed":true,"_uuid":"6c05409387f112fd1e3ea016583a408f2a8e097a","trusted":false},"cell_type":"code","source":"# Plot histogram with 45 bins; each bin representing a range of 10\nplt.hist(train_data[\"teacher_number_of_previously_posted_projects\"], bins=45)\nplt.xticks(range(0, 500, 50))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"131cfeaf-316f-4497-98b3-0e1539dc74c5","_uuid":"dc317c7818e43c18058b9610c6a13064a8cdacef"},"cell_type":"markdown","source":"We can see that the vast majority of examples have a `teacher_number_previously_posted_projects` value between 0 and 10, with a sharp dropoff thereafter. However, if we rebucket our data into two bins (&lt; 10 and &ge; 10), we can see that there's a substantial long tail of examples with previously-posted-project values greater than 10:"},{"metadata":{"_cell_guid":"1759ab1f-6cfc-4d59-ab66-0d21040bf955","collapsed":true,"_uuid":"2b00fb5cc71d2f09c7c65727b092cc1496e47dad","trusted":false},"cell_type":"code","source":"# Plot histogram with 45 bins; each bin representing a range of 10\nplt.hist(train_data[\"teacher_number_of_previously_posted_projects\"], bins=[0, 10, 450])\nplt.xticks(range(0, 500, 50))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d40d917a-405e-446a-88c5-ff843c071c67","_uuid":"78839e4e8e5b045b74d036f77fc457a13c9b3703"},"cell_type":"markdown","source":"## Build an Initial Linear Classification Model\n\nPerhaps `teacher_number_of_previously_posted_projects` might provide a good signal as to whether a DonorsChoose application will be accepted? We can hypothesize that teachers who have submitted a large number of previous projects may be more familiar with the ins and outs of the application process and less likely to make errors that would lead to a rejection.\n\nLet's test that theory by building a simple linear classification model that predicts the `project_is_approved` value solely from the `teacher_number_of_previously_posted_projects` feature. We'll build our model in TensorFlow using a `LinearClassifier` from the high-level [Estimators API](https://www.tensorflow.org/programmers_guide/estimators). \n\n**NOTE:** For more practice in building TensorFlow models with `Estimator`s, see the Machine Learning Crash Course [companion exercises](https://developers.google.com/machine-learning/crash-course/exercises#programming). \n\nFirst, import the modules we'll use, which include TensorFlow, the TensorFlow [Datasets API](https://www.tensorflow.org/get_started/datasets_quickstart), [numpy](http://www.numpy.org/), and [scikit-learn](http://scikit-learn.org/) (for some convenience functions for metrics):"},{"metadata":{"_cell_guid":"e3c45ba3-a75e-4a45-b155-37802e9c0fbc","collapsed":true,"_uuid":"1e27554fb69de6781ce4c7d94141fd23f4273aca","trusted":false},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.python.data import Dataset\nimport numpy as np\nimport sklearn.metrics as metrics","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6a360330-0e71-4758-95a9-2a647bcbfdda","_uuid":"54cc1d8081817f9d9c0f73d0b18a0765042984fe"},"cell_type":"markdown","source":"If you didn't import the DonorsChoose training data above, do so now:"},{"metadata":{"_cell_guid":"db507783-fad3-484c-86a9-2b971a2da955","collapsed":true,"_uuid":"7f2ddeae8035bf8c0bd8c9389f6e047a02572e38","trusted":false},"cell_type":"code","source":"import pandas as pd\n\n# Filepath to main training dataset.\ntrain_file_path = '../input/train.csv'\n\n# Read data and store in DataFrame.\ntrain_data = pd.read_csv(train_file_path, sep=',')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"015ce368-dcc7-4429-b52c-b3c56335cee5","_uuid":"1944287a177b1cf23d21e3d098cbc2282ae7dab3"},"cell_type":"markdown","source":"Next, define the feature (`teacher_number_of_previously_posted_projects`) and label (`project_is_approved`):"},{"metadata":{"_cell_guid":"5f8b0af9-1269-4246-b9ec-14505d0778cd","collapsed":true,"_uuid":"fcf4bf7f41d76540be09af3f402946b1e2a2b568","trusted":false},"cell_type":"code","source":"# Define predictor feature(s); start with a simple example with one feature.\nmy_feature_name = 'teacher_number_of_previously_posted_projects'\nmy_feature = train_data[[my_feature_name]]\n\n# Specify the label to predict.\nmy_target_name = 'project_is_approved'","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c1dad132-7ed5-45ec-8182-9c3e7dcdf956","_uuid":"2c2e671984d51a1c726149645c95d66fa4659dbf"},"cell_type":"markdown","source":"Then split the data into training and validation sets:"},{"metadata":{"_cell_guid":"c26689d6-1d0d-4afb-9414-6c5b716a9c38","collapsed":true,"_uuid":"cd56bb7fbf648a21a90c4a9175d567d0811c5d78","trusted":false},"cell_type":"code","source":"# Prepare training and validation sets.\nN_TRAINING = 160000\nN_VALIDATION = 100000\n\n# Choose examples and targets for training.\ntraining_examples = train_data.head(N_TRAINING)[[my_feature_name]].copy()\ntraining_targets = train_data.head(N_TRAINING)[[my_target_name]].copy()\n\n# Choose examples and targets for validation.\nvalidation_examples = train_data.tail(N_VALIDATION)[[my_feature_name]].copy()\nvalidation_targets = train_data.tail(N_VALIDATION)[[my_target_name]].copy()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e0fe0bf5-bbc7-4c09-b073-be937d8f3ebd","_uuid":"3f89a2ed6e3517854791ab266e5681d7aa7c07ba"},"cell_type":"markdown","source":"Then set up the input function to feed data into the model using the [Datasets API](https://www.tensorflow.org/get_started/datasets_quickstart):"},{"metadata":{"_cell_guid":"bcb3e9f3-5403-400a-8f09-39783ec88f79","collapsed":true,"_uuid":"66434d85cfecbdcf67c191acc2f39bbd42282df6","trusted":false},"cell_type":"code","source":"def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n    \"\"\"Trains a linear regression model of one feature.\n  \n    Args:\n      features: pandas DataFrame of features\n      targets: pandas DataFrame of targets\n      batch_size: Size of batches to be passed to the model\n      shuffle: True or False. Whether to shuffle the data.\n      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely\n    Returns:\n      Tuple of (features, labels) for next data batch\n    \"\"\"\n    \n    # Convert pandas data into a dict of np arrays.\n    features = {key:np.array(value) for key,value in dict(features).items()}                                           \n \n    # Construct a dataset, and configure batching/repeating\n    ds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\n    ds = ds.batch(batch_size).repeat(num_epochs)\n    \n    # Shuffle the data, if specified\n    if shuffle:\n      # Shuffle with a buffer size of 10000\n      ds = ds.shuffle(10000)\n    \n    # Return the next batch of data\n    features, labels = ds.make_one_shot_iterator().get_next()\n    return features, labels","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"50c2c0f9-9d2b-4d9f-90f0-7008ffff2471","_uuid":"87794482c969cf79a656a2738b3a90012a96ae84"},"cell_type":"markdown","source":"Next, construct the `LinearClassifier`:"},{"metadata":{"_cell_guid":"a14e210f-ebf6-49de-ac4d-5320cb7abc9d","collapsed":true,"_uuid":"b80465e3ca528f7f7d7f0337e8ac4fd9033b86c5","trusted":false},"cell_type":"code","source":"# Learning rate for training.\nlearning_rate = 0.00001\n\n# Function for constructing feature columns from input features\ndef construct_feature_columns(input_features):\n  \"\"\"Construct the TensorFlow Feature Columns.\n  Args:\n    input_features: The names of the numerical input features to use.\n  Returns:\n    A set of feature columns\n  \"\"\"\n  return set([tf.feature_column.numeric_column(my_feature)\n              for my_feature in input_features])\n\n# Create a linear classifier object.\nmy_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n# Set a clipping ratio of 5.0\nmy_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)  \nlinear_classifier = tf.estimator.LinearClassifier(\n    feature_columns=construct_feature_columns(training_examples),\n    optimizer=my_optimizer\n)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"5d4ac88b-c9c7-4bf4-b8a8-7a66b6a8edf3","_uuid":"539ae2d007b484f026fd9f636432b7a6291c0aaf"},"cell_type":"markdown","source":"Create input functions for training the model, predicting on the prediction data, and predicting on the validation data:"},{"metadata":{"_cell_guid":"131694ac-5538-4d3f-913c-07217af970c2","collapsed":true,"_uuid":"296e8531a15de6b433654f9782c034d154ff2d58","trusted":false},"cell_type":"code","source":"batch_size = 10\n\n# Create input function for training\ntraining_input_fn = lambda: my_input_fn(training_examples, \n                                        training_targets[my_target_name],\n                                        batch_size=batch_size)\n\n# Create input function for predicting on training data\npredict_training_input_fn = lambda: my_input_fn(training_examples,\n                                                training_targets[my_target_name],\n                                                num_epochs=1, \n                                                shuffle=False)\n\n# Create input function for predicting on validation data\npredict_validation_input_fn = lambda: my_input_fn(validation_examples,\n                                                  validation_targets[my_target_name],\n                                                  num_epochs=1, \n                                                  shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ddd78749-3264-44a0-9692-20c4db287284","_uuid":"93bb6e339a7c98f9b542d07efdf75820c56325d8"},"cell_type":"markdown","source":"Finally, train the model. This may take a few minutes. When training is complete, the training and validation log losses will be output:"},{"metadata":{"_cell_guid":"dc2fe166-20ca-452d-8def-570b1d09846b","collapsed":true,"_uuid":"d504895bbc171585c764173e9d3d3157ad844492","trusted":false},"cell_type":"code","source":"# Train for 200 steps\nlinear_classifier.train(\n  input_fn=training_input_fn,\n  steps=200\n)\n\n# Compute predictions.    \ntraining_probabilities = linear_classifier.predict(\n    input_fn=predict_training_input_fn)\ntraining_probabilities = np.array(\n      [item['probabilities'] for item in training_probabilities])\n    \nvalidation_probabilities = linear_classifier.predict(\n    input_fn=predict_validation_input_fn)\nvalidation_probabilities = np.array(\n    [item['probabilities'] for item in validation_probabilities])\n    \ntraining_log_loss = metrics.log_loss(\n    training_targets, training_probabilities)\nvalidation_log_loss = metrics.log_loss(\n    validation_targets, validation_probabilities)\n  \n# Print the training and validation log loss.\nprint(\"Training Loss: %0.2f\" % training_log_loss)\nprint(\"Validation Loss: %0.2f\" % validation_log_loss)\n\nauc = metrics.auc","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"18052754-7207-4a94-a648-5685bfdcc485","_uuid":"7b9bf9c7d30be5969464a01cefa21b5cae3e8034"},"cell_type":"markdown","source":"Next, let's calculate the [AUC (area under the curve)](https://developers.google.com/machine-learning/glossary#AUC), which is the metric this competition uses to assess the accuracy of prediction. This may take a few minutes. When calculation is complete, the training and validation AUC values will be output:"},{"metadata":{"_cell_guid":"e2efa7b9-2108-4a62-bf35-de6e555a8314","collapsed":true,"_uuid":"2cd1d81085ac1ddd60f54c2ffd032873ef2d1127","trusted":false},"cell_type":"code","source":"training_metrics = linear_classifier.evaluate(input_fn=predict_training_input_fn)\nvalidation_metrics = linear_classifier.evaluate(input_fn=predict_validation_input_fn)\n\nprint(\"AUC on the training set: %0.2f\" % training_metrics['auc'])\nprint(\"AUC on the validation set: %0.2f\" % validation_metrics['auc'])","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"47634480-fc44-4054-bc3b-aa4d9295e35f","collapsed":true,"_uuid":"615410917a05455fb83e3f375008b0d512d7ec81"},"cell_type":"markdown","source":"We've achieved AUC values of 0.56, which is slightly better than random. This is a good start, but can you improve the model to achieve better results?"},{"metadata":{"_cell_guid":"9ac45f65-1fb3-4e99-803e-e48109b17a89","_uuid":"d98cae3eb1cf7b4681fcc76b41460134f4ccca0b"},"cell_type":"markdown","source":"## What to Try Next\n\nA couple ideas for model refinements you can try to see if you can improve model accuracy:\n\n* Try adjusting the `learning_rate` and `steps` hyperparameters on the existing model.\n* Try adding some text features to the model, such as the content of the project essays (`project_essay_1`, `project_essay_2`, `project_essay_3`, `project_essay_4`). You may want to try building a vocabulary from these strings; see the Machine Learning Crash Course [Intro to Sparse Data and Embeddings exercise](https://colab.research.google.com/notebooks/mlcc/intro_to_sparse_data_and_embeddings.ipynb) for some practice on working with text data and vocabularies.  "},{"metadata":{"_cell_guid":"6ddce170-e244-4500-9698-df592b33269c","_uuid":"c7b2493328aed953d41e5a3bdd82290bfa34b938"},"cell_type":"markdown","source":"## Submitting a Kaggle Entry\n\nOnce you're satisfied with your model performance, you can make predictions on the test set as follows (this may take a few minutes to run):"},{"metadata":{"_cell_guid":"6841ed06-9490-4cc2-8b8d-8737ff445d74","collapsed":true,"_uuid":"1b10151e274bbae0d29d436f478e718d3c452c24","trusted":false},"cell_type":"code","source":"# Filepath to main test dataset.\ntest_file_path = '../input/test.csv'\n\n# Read data and store in DataFrame.\ntest_data = pd.read_csv(test_file_path, sep=',')\n\nmy_feature_name = 'teacher_number_of_previously_posted_projects'\n\n# Get test features\ntest_examples = test_data[[my_feature_name]].copy()\n\n# No labels in data set, so generate some placeholder values\nplaceholder_label_vals = [0 for i in range(0, 78035)]\ntest_labels = pd.DataFrame({\"project_is_approved\": placeholder_label_vals})\n\npredict_test_input_fn = lambda: my_input_fn(test_examples,\n                                            test_labels, # unused for prediction\n                                            num_epochs=1, \n                                            shuffle=False)\n\n# Make predictions\npredictions_generator = linear_classifier.predict(input_fn=predict_test_input_fn)\npredictions_list = list(predictions_generator)\n\n# Extract probabilities\nprobabilities = [p[\"probabilities\"][1] for p in predictions_list]\nprint(\"Done extracting probabilities\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"00359193-3d73-4581-83d3-0719d96327fc","_uuid":"f80792ff0418734b93c365b1c464367e3f164d89"},"cell_type":"markdown","source":"We want to format our submission as a CSV with two fields for each example: `id` and our prediction for `project_is_approved`, e.g.:"},{"metadata":{"_cell_guid":"48f2793c-7491-46a5-b1ed-ed33fb5e4b93","_uuid":"05d72bb9c705bf49b608ce709880c9ac4062f60b"},"cell_type":"markdown","source":"```\nid,project_is_approved\np233245,0.54\np096795,0.14\np236235,0.94\n```"},{"metadata":{"_cell_guid":"3d26533e-8da6-4a8b-a42a-ed3f8f8bb863","_uuid":"72a0a86fac985490c1f60856c69f132005724a8d"},"cell_type":"markdown","source":"Run the following code to create a `DataFrame` in the required format:"},{"metadata":{"_cell_guid":"f581f01c-310c-477d-9fcc-9e27d49dc40b","collapsed":true,"_uuid":"1f6c30bf8029a37e3aa70e0d12d9f819d3c43b59","trusted":false},"cell_type":"code","source":"my_submission = pd.DataFrame({'id': test_data[\"id\"], 'project_is_approved': probabilities})\nprint(my_submission.values)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"4676bc39-1d6b-4bbe-be44-ac4365a41aa4","_uuid":"b6ef81d70456f42ec3f73ee73a8c4dc06d44e980"},"cell_type":"markdown","source":"Then write your output to CSV:"},{"metadata":{"_cell_guid":"a2780929-98b9-4548-bdd6-c69223fe2cb8","collapsed":true,"_uuid":"20f77cdd51262a69babd7cf13c9c639250b3c3eb","trusted":false},"cell_type":"code","source":"my_submission.to_csv('my_submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"cc951577-4e91-48b8-bbfd-b5afbcfae7de","_uuid":"a182f503abc4b5923ec66f87049cd1f81340bbb1"},"cell_type":"markdown","source":"Next, click the **Commit & Run** button to execute the entire Kaggle kernel. This will take ~10 minutes to run. \n\nWhen it's finished, you'll see the navigation bar at the top of your screen has an **Output** tab. Click on the **Output** tab, and click on the **Submit to Competition** button to submit to Kaggle."}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}