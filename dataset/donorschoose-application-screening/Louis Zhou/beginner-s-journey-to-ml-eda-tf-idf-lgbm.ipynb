{"cells":[{"metadata":{"_cell_guid":"79d262c0-1ff7-43cc-928d-68967c018b76","_uuid":"d8368dde63940d66176759d320a772f6b54d32f7"},"cell_type":"markdown","source":"# Introduction\n\n### Welcome to my Notebook for [DonorsChoose.org Application Screening](https://www.kaggle.com/c/donorschoose-application-screening).\n\n### Please note that this is my first attempt at a ML model. I would love to learn from the Kaggle veterans, so all comments and critism are welcome!\n\n### Before I start, I would like to shout out to  [Heads or Tails](https://www.kaggle.com/headsortails/an-educated-guess-update-feature-engineering), [Andrew Lukyanenko](https://www.kaggle.com/artgor/eda-feature-engineering-and-xgb-lgb), and [Peter](https://www.kaggle.com/hoonkeng/how-to-get-81-gru-att-lgbm-tf-idf-eda) for sharing their notebooks. I truly learned a great deal from reading your well-written notebooks, and they helped set me off on the right footing on my journey in Machine Learning.\n\nI used a lot of the analysis from the notebooks referenced above. For brevity, I will not repeat them here. If you are interested, please check out their notebooks.\n\nIn this notebook, I will be looking at the LightGBM model. I obtained similar results using XGBoost in virtually every step in building the model, and ultimately chose to use LGBM in the final model because of its faster running time.\n"},{"metadata":{"_cell_guid":"f0c74981-ac63-4eed-9a60-51993b332175","_uuid":"7ab4a376e133e2d0e5bbde0cb45ae007c58d92f8"},"cell_type":"markdown","source":"# Table of Contents\n### 1. Data Preparation\n* 1.1 - Importing libraries\n* 1.2 - Preparing and cleaning data\n\n### 2. Exploratory Data Analysis (my analysis in reference to other notebooks)\n* 2.1 - Teacher experience\n* 2.2 - Features from resource data\n* 2.3 - Text features\n\n### 3. Feature Engineering\n* 3.1 - Selecting features\n* 3.2 - Target encode features\n* 3.3 - Splitting Training and Validation Sets\n* 3.4 - Term frequency–inverse document frequency\n\n### 4. Train Model\n\n### 5. Results"},{"metadata":{"_cell_guid":"dc4c0a7e-572b-41c8-8245-ad77d4e8bffa","_uuid":"a9b6d6706c483f1fed08d90ca19235122cd494f6"},"cell_type":"markdown","source":""},{"metadata":{"_cell_guid":"42160670-a3c0-4a03-8251-79ebda2b35cc","_uuid":"cc4c6d25e43db8eebec4d31d4e7d764d2ceb94c9"},"cell_type":"markdown","source":"# 1. Data Preparation\n\n### 1.1 - Importing libraries used in this model.\nI included some extra libraries because of I did a lot of experimenting. I will try to take out unnessary ones in future editions."},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_kg_hide-input":false,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# import libraries\nimport os\n\nimport math\nimport datetime\n\nimport tensorflow as tf\nfrom tensorflow.python.data import Dataset\n\nfrom scipy import stats\nfrom scipy.sparse import hstack, csr_matrix\nfrom mlxtend.preprocessing import minmax_scaling\nimport seaborn as sns\n\nfrom IPython import display\nfrom matplotlib import cm\nfrom matplotlib import gridspec\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport pandas_profiling as pp\n\nfrom sklearn import metrics\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom nltk.corpus import stopwords\nstop = set(stopwords.words('english'))\nfrom textblob import TextBlob\n\nimport xgboost as xgb\nimport lightgbm as lgb\n\ntf.logging.set_verbosity(tf.logging.ERROR)\npd.options.display.max_rows = 10\npd.options.display.float_format = '{:.1f}'.format","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-output":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# read CSV files\ntrain = pd.read_csv(\"../input/train.csv\", sep=\",\", parse_dates=['project_submitted_datetime'])\nresources = pd.read_csv(\"../input/resources.csv\", sep=\",\")\ntest = pd.read_csv(\"../input/test.csv\", sep=\",\", parse_dates=['project_submitted_datetime'])","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"004a789c-ab02-4511-bf47-20b86e6b9a68","_uuid":"ba85339c92b90b99c94353a446f294acb35d8e88"},"cell_type":"markdown","source":""},{"metadata":{"_cell_guid":"642500f9-ab05-40ee-9d64-588586fc36f3","_uuid":"79ee33f30fc528ea745f13087c6135cdefd5367c"},"cell_type":"markdown","source":"### 1.2 - Preparing and cleaning the data.\n\nLike [Andrew](https://www.kaggle.com/artgor/eda-feature-engineering-and-xgb-lgb) has done, I extracted information from resources.csv (unique items, total quantity of items, mean cost of project, and total cost of project) and I merged with train and test dataframes on ID. I chose not to use boxcox transformation, and will be binning them instead (discussed more later).\n\nFor proposals submitted prior to the May 7, 2017 change, I combined essays 1 + 2 into the new essay 1, and essays 3 + 4 into the new essay 2. Then, I did a little cleaning of symbols that appeared due to formatting (ie, \"\\\\r\" and \"\\\\n\")"},{"metadata":{"_cell_guid":"b675313d-b8d4-4647-9001-80cb5625b656","collapsed":true,"_uuid":"a62f2b8f0597811227a3f58e7fa459c4c2efbd38","trusted":true},"cell_type":"code","source":"# extract features from resource data and merge with train and test\nresources['cost'] = resources['quantity'] * resources['price']\nresources_aggregated = resources.groupby('id').agg({'description': ['nunique'], 'quantity': ['sum'], 'cost': ['mean', 'sum']})\nresources_aggregated.columns = ['unique_items', 'total_quantity', 'mean_cost', 'total_cost']\nresources_aggregated.reset_index(inplace=True)\n\ntrain = pd.merge(train, resources_aggregated, how='left', on='id')\ntest = pd.merge(test, resources_aggregated, how='left', on='id')","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"d246c25f-382a-4f5e-b7b8-c212bf93e396","collapsed":true,"_uuid":"da35a1d3a012e3cd6e96c3ebf948828c4f09f9df","trusted":true},"cell_type":"code","source":"# combine essay1+2, essay 3+4 for proposals before May 7, 2017\ntrain.loc[train.project_submitted_datetime.dt.date < datetime.date(2016, 5, 7), 'project_essay_1'] = train.loc[train.project_submitted_datetime.dt.date < datetime.date(2016, 5, 7), 'project_essay_1'] + ' ' + train.loc[train.project_submitted_datetime.dt.date < datetime.date(2016, 5, 7), 'project_essay_2']\ntrain.loc[train.project_submitted_datetime.dt.date < datetime.date(2016, 5, 7), 'project_essay_2'] = train.loc[train.project_submitted_datetime.dt.date < datetime.date(2016, 5, 7), 'project_essay_3'] + ' ' + train.loc[train.project_submitted_datetime.dt.date < datetime.date(2016, 5, 7), 'project_essay_4']\ntrain.drop(['project_essay_3', 'project_essay_4'], axis=1, inplace=True)\n\ntest.loc[test.project_submitted_datetime.dt.date < datetime.date(2016, 5, 7), 'project_essay_1'] = test.loc[test.project_submitted_datetime.dt.date < datetime.date(2016, 5, 7), 'project_essay_1'] + ' ' + test.loc[test.project_submitted_datetime.dt.date < datetime.date(2016, 5, 7), 'project_essay_2']\ntest.loc[test.project_submitted_datetime.dt.date < datetime.date(2016, 5, 7), 'project_essay_2'] = test.loc[test.project_submitted_datetime.dt.date < datetime.date(2016, 5, 7), 'project_essay_3'] + ' ' + test.loc[test.project_submitted_datetime.dt.date < datetime.date(2016, 5, 7), 'project_essay_4']\ntest.drop(['project_essay_3', 'project_essay_4'], axis=1, inplace=True)\n\n# replacing symbols which appeared due to formatting\ntrain['project_essay_1'] = train['project_essay_1'].apply(lambda x: x.replace('\\\\r', ' ').replace('\\\\n', ' ').replace('  ', ' '))\ntrain['project_essay_2'] = train['project_essay_2'].apply(lambda x: x.replace('\\\\r', ' ').replace('\\\\n', ' ').replace('  ', ' '))\n\ntest['project_essay_1'] = test['project_essay_1'].apply(lambda x: x.replace('\\\\r', ' ').replace('\\\\n', ' ').replace('  ', ' '))\ntest['project_essay_2'] = test['project_essay_2'].apply(lambda x: x.replace('\\\\r', ' ').replace('\\\\n', ' ').replace('  ', ' '))\n\n# replacing symbols in title and summary\ntrain['project_resource_summary'] = train['project_resource_summary'].apply(lambda x: x.replace('\\\\r', ' ').replace('\\\\n', ' ').replace('  ', ' '))\ntrain['project_title'] = train['project_title'].apply(lambda x: x.replace('\\\\r', ' ').replace('\\\\n', ' ').replace('  ', ' '))\n\ntest['project_resource_summary'] = test['project_resource_summary'].apply(lambda x: x.replace('\\\\r', ' ').replace('\\\\n', ' ').replace('  ', ' '))\ntest['project_title'] = test['project_title'].apply(lambda x: x.replace('\\\\r', ' ').replace('\\\\n', ' ').replace('  ', ' '))","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"a4407114-f68c-4b60-b816-7c6b75c084c7","_uuid":"b0e4c8115ffaf5646e56572c66d18e7896257658"},"cell_type":"markdown","source":""},{"metadata":{"_cell_guid":"492aa562-6a46-420d-972f-90276eb886f5","_uuid":"6c58bca52dfbab93d899a1739c939f31d3fcfadc"},"cell_type":"markdown","source":"# 2. Exploratory Data Analysis (EDA)\n\nAs mentioned before, since this is my first attempt at ML modeling, I drew heavily on the analysis provided in the referenced notebooks. I used approaches from each of them that made sense to me, and made adjustments based on my take on the data.\n\n### 2.1 - Teacher Experience\n\nThe first feature that caught my attention was \"teacher_number_of_previously_posted_projects\". Like [Heads or Tails](https://www.kaggle.com/headsortails/an-educated-guess-update-feature-engineering), I created the categories \"high experience\" and \"low experience\" for this variable. However, it did not make sense to me to leave out all the proposals that had values in between, so I created an additional category, \"medium experience\".\n\nThe following graph shows the difference in approval rates between experience levels: 1-low, 2-med, 3-high. We see that there is a significant difference in approval rates between high and low experience. Medium experience does not have overlapping error bars with the other two, proving that it is meaningful to include this category as well."},{"metadata":{"scrolled":true,"_cell_guid":"a6af39a0-20d1-4c62-93f2-b8fa4ba24241","_kg_hide-output":false,"_kg_hide-input":true,"_uuid":"716b6bfa766a0f0e34c7ab581f0c29bce973fd1d","trusted":true},"cell_type":"code","source":"# define bins and graph binned experience\nbins = [0., 2., 10.,]\ntrain[\"experience\"] = np.digitize(train['teacher_number_of_previously_posted_projects'], bins=bins)\n\nfig, ax1 = plt.subplots(figsize=(8, 4))\nplt.title(\"Experience vs Approval\")\nsns.pointplot(x=\"experience\", y=\"project_is_approved\", data=train, ci=95, ax=ax1)\nax1.set_ylabel('Approval rate')","execution_count":54,"outputs":[]},{"metadata":{"_cell_guid":"dcb125d7-08c1-4ef7-b029-762439c6e874","_uuid":"4827e2da9e9c0df0664f554f43db115df8ef780d"},"cell_type":"markdown","source":""},{"metadata":{"_cell_guid":"9a032eba-c42e-43ba-9942-7f39f023228e","_uuid":"8d729cc7d8b2b68445b62daade0be1a658976b26"},"cell_type":"markdown","source":"### 2.2 - Features from Resource Data\n\nThe reason I did not use boxcox transformation is that the data is way too noisy to see any trends. Normalizing it does not solve the issue, and therefore they will be poor feature to use as is. I decided to use a different approach, and bin the data by quantiles (as seen in the notebook by  [Heads or Tails](https://www.kaggle.com/headsortails/an-educated-guess-update-feature-engineering)). Doing so instantly produces visible trends:\n* Increasing unique item counts per project correlates to ***lower*** approval rates\n* Increasing total item quantity per project correlates to ***lower*** approval rates\n* Increasing mean item cost per project correlates to ***higher*** approval rates\n* Increasing total item cost per project correlates to ***lower*** approval rates\n\nThe third trend is particularly interesting, potentially indicating that requesting a **few complex/good quality** resources rather than **many cheap** resources gives an advantage to being approved."},{"metadata":{"_cell_guid":"01eab5ea-697f-45a8-bd25-4afbc94dce76","collapsed":true,"_uuid":"c789d5f5278af8c681c0edda66428c54a07fa7e1","trusted":true},"cell_type":"code","source":"# define quantile function\ndef get_quantile_based_boundaries(feature_values, num_buckets):\n  boundaries = np.arange(1.0, num_buckets) / num_buckets\n  quantiles = feature_values.quantile(boundaries)\n  return [quantiles[q] for q in quantiles.keys()]","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"c51f6c27-8332-44f4-95ed-874ca948e0db","_uuid":"3726d1aa5e5ed823ea5801d60f8fbe09320a4b53","trusted":true},"cell_type":"code","source":"# transform unique_items to quantile number and graph\nquantiles = get_quantile_based_boundaries(train['unique_items'], 6)\ntrain[\"unique_items_binned\"] = np.digitize(train['unique_items'], bins=quantiles)\nfig, ax1 = plt.subplots(figsize=(8, 4))\nplt.title(\"unique_items vs Approval\")\nsns.pointplot(x=\"unique_items_binned\", y=\"project_is_approved\", data=train, ci=95, ax=ax1)\nax1.set_ylabel('Approval rate')","execution_count":55,"outputs":[]},{"metadata":{"_cell_guid":"1ded718b-e595-4963-87f6-3c53446114ae","_uuid":"8bb1e1335fd64022ac46b6a0dc893eccb519a8aa","trusted":true},"cell_type":"code","source":"# transform total_quantity to quantile number and graph\nquantiles = get_quantile_based_boundaries(train['total_quantity'], 6)\ntrain[\"total_quantity_binned\"] = np.digitize(train['total_quantity'], bins=quantiles)\nfig, ax1 = plt.subplots(figsize=(8, 4))\nplt.title(\"total_quantity vs Approval\")\nsns.pointplot(x=\"total_quantity_binned\", y=\"project_is_approved\", data=train, ci=95, ax=ax1)\nax1.set_ylabel('Approval rate')","execution_count":56,"outputs":[]},{"metadata":{"_cell_guid":"9f5476b1-501c-4e73-be05-c80c1894e67a","_uuid":"ced374ba5a7b1c5240407759a250ba63ed595f04","trusted":true},"cell_type":"code","source":"# transform mean_cost to quantile number and graph\nquantiles = get_quantile_based_boundaries(train['mean_cost'], 6)\ntrain[\"mean_cost_binned\"] = np.digitize(train['mean_cost'], bins=quantiles)\nfig, ax1 = plt.subplots(figsize=(8, 4))\nplt.title(\"mean_cost vs Approval\")\nsns.pointplot(x=\"mean_cost_binned\", y=\"project_is_approved\", data=train, ci=95, ax=ax1)\nax1.set_ylabel('Approval rate')","execution_count":57,"outputs":[]},{"metadata":{"_cell_guid":"9faa2187-ad1f-44ea-ab8d-5b29ad3501a9","_uuid":"986aaeebe9210e056951d2024bca9e49e948c78a","trusted":true},"cell_type":"code","source":"# transform total_cost to quantile number and graph\nquantiles = get_quantile_based_boundaries(train['total_cost'], 6)\ntrain[\"total_cost_binned\"] = np.digitize(train['total_cost'], bins=quantiles)\nfig, ax1 = plt.subplots(figsize=(8, 4))\nplt.title(\"total_cost vs Approval\")\nsns.pointplot(x=\"total_cost_binned\", y=\"project_is_approved\", data=train, ci=95, ax=ax1)\nax1.set_ylabel('Approval rate')","execution_count":58,"outputs":[]},{"metadata":{"_cell_guid":"e0254964-7c7f-4052-8078-89000a04d295","_uuid":"a4a48178ea3d5a3cad4efbc099f64da3e728e22a"},"cell_type":"markdown","source":""},{"metadata":{"_cell_guid":"0593ad2e-710a-4c07-987c-56c56000250a","_uuid":"7142594cdf580e6307ef7d7fa84a1be15728a4db"},"cell_type":"markdown","source":"### 2.3 - Text Features\n\nMany in-depth analyses have been done on the text features. From my understanding, both TF-IDF of the texts and Sentiment Analysis of the essays have predictive power for approval rates, and thus are good features to include.\n\nAt this time, no additional analysis came to mind, but as I expand my knowledge in ML, I may revisit this section in a future version."},{"metadata":{"_cell_guid":"2f3c12e5-0a0b-444e-981b-69eca610157f","collapsed":true,"_uuid":"5a2fa31ed9ff13d68691a06387bf1b1bebdd9e63"},"cell_type":"markdown","source":""},{"metadata":{"_cell_guid":"4357317d-b1fb-4acd-af97-acd4f3375fb3","_uuid":"e48fadb4d597c58bd38c12693177e8fc319b0e78"},"cell_type":"markdown","source":"# 3. Feature Engineering\n\n### 3.1 - Selecting Features\n\nAs shown by the EDA, binned features from the resource data and binned experience (function of previous number of proposals) are good features to include.\n\nBased on the analyses from the referenced notebooks, the following features have very weak to no correlation to approval rates, and are therefore excluded:\n* teacher_prefix: no difference if you isolate by teacher experience\n* school_state: difference between states is more due to a function of proposal volumes and teacher experience\n* project_submitted_datetime: In my opinion, it is difficult to form conclusions with data from only one year. Logically, the date of submission should not be a determinant of approval\n* project_grade_category: no difference if you isolate by subject category or teacher experience\n\nI will target encode subject categories, and vectorize all the different text data. I will also use the sentiment analysis of the essays. (As seen in notebook by [Peter](https://www.kaggle.com/hoonkeng/how-to-get-81-gru-att-lgbm-tf-idf-eda))."},{"metadata":{"_cell_guid":"69f889cd-956f-417a-acd5-26aaa172c083","collapsed":true,"_uuid":"687cdd8098f5ba2a57feb0eca3867e401fb66acf","trusted":true},"cell_type":"code","source":"# repeat binning process in test data\nbins = [0., 2., 10.,]\ntest[\"experience\"] = np.digitize(test['teacher_number_of_previously_posted_projects'], bins=bins)\n\nquantiles = get_quantile_based_boundaries(test['unique_items'], 6)\ntest[\"unique_items_binned\"] = np.digitize(test['unique_items'], bins=quantiles)\nquantiles = get_quantile_based_boundaries(test['total_quantity'], 6)\ntest[\"total_quantity_binned\"] = np.digitize(test['total_quantity'], bins=quantiles)\nquantiles = get_quantile_based_boundaries(test['mean_cost'], 6)\ntest[\"mean_cost_binned\"] = np.digitize(test['mean_cost'], bins=quantiles)\nquantiles = get_quantile_based_boundaries(test['total_cost'], 6)\ntest[\"total_cost_binned\"] = np.digitize(test['total_cost'], bins=quantiles)","execution_count":59,"outputs":[]},{"metadata":{"_cell_guid":"04063baf-2caa-46b2-9b22-4fcda878b3ba","collapsed":true,"_uuid":"1d6bd751433815b47ff363d4640310b1ba384a88","trusted":true},"cell_type":"code","source":"# define functions for selected features and target\ndef preprocess_features(df):\n  selected_features = df[\n  [\"project_subject_categories\",\n   \"project_subject_subcategories\",\n   \"project_title\",\n   \"project_resource_summary\",\n   \"project_essay_1\",\n   \"project_essay_2\",\n   \"experience\",\n   \"unique_items_binned\",\n   \"total_quantity_binned\",\n   \"mean_cost_binned\",\n   \"total_cost_binned\",\n   \"encoded_category\",\n   \"encoded_subcategory\"]]\n  return selected_features\n\ndef preprocess_targets(df):\n  output_targets = df[\"project_is_approved\"]\n  return output_targets","execution_count":60,"outputs":[]},{"metadata":{"_cell_guid":"6b3e3f04-6755-4193-9699-d25ecaa19e71","_uuid":"bb2ff5520567d0ca09f1ae1ad1027daddb5f4e4b"},"cell_type":"markdown","source":""},{"metadata":{"_cell_guid":"5be0d926-4bae-48ff-99f3-05d45a3548da","_uuid":"7148d6ac0b3d7ae5e601d62484db0f89260131aa"},"cell_type":"markdown","source":"### 3.2 - Target Encode\n\nTarget encoding is used to transform numeric categories into more meanful values for ML. As demonstrated by [Andrew](https://www.kaggle.com/artgor/eda-feature-engineering-and-xgb-lgb), target encoding works better than one-hot encoding because it does not generate a huge amount of new features."},{"metadata":{"_cell_guid":"7c6716f4-212a-4254-a09e-32ab0b4e9755","collapsed":true,"_uuid":"119fde722a9d29fc2d17a875746ffb3288c27d65","trusted":true},"cell_type":"code","source":"# define target encode function\ndef target_encode(trn_series=None, \n                  tst_series=None, \n                  target=None, \n                  min_samples_leaf=1, \n                  smoothing=1,\n                  noise_level=0):\n\n    assert len(trn_series) == len(target)\n    assert trn_series.name == tst_series.name\n    temp = pd.concat([trn_series, target], axis=1)\n    # Compute target mean \n    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n    # Compute smoothing\n    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n    # Apply average function to all target data\n    prior = target.mean()\n    # The bigger the count the less full_avg is taken into account\n    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n    # Apply averages to trn and tst series\n    ft_trn_series = pd.merge(\n        trn_series.to_frame(trn_series.name),\n        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n        on=trn_series.name,\n        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n    # pd.merge does not keep the index so restore it\n    ft_trn_series.index = trn_series.index \n    ft_tst_series = pd.merge(\n        tst_series.to_frame(tst_series.name),\n        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n        on=tst_series.name,\n        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n    # pd.merge does not keep the index so restore it\n    ft_tst_series.index = tst_series.index\n    return ft_trn_series, ft_tst_series","execution_count":13,"outputs":[]},{"metadata":{"_cell_guid":"4c033d08-b8a5-411e-904e-ffba46437018","_uuid":"34f2300405f900a9baa7de55a14ea1614f48b994","trusted":true},"cell_type":"code","source":"# target encode features\ntrain['encoded_category'], test['encoded_category'] = target_encode(train['project_subject_categories'], test['project_subject_categories'], train['project_is_approved'])\ntrain['encoded_subcategory'], test['encoded_subcategory'] = target_encode(train['project_subject_subcategories'], test['project_subject_subcategories'], train['project_is_approved'])","execution_count":61,"outputs":[]},{"metadata":{"_cell_guid":"88e0265e-c208-4d2f-8dfe-025d4ba22767","_uuid":"6b42cb63d579838abbb35e9c5a49ac09d1a7f694"},"cell_type":"markdown","source":""},{"metadata":{"_cell_guid":"fc016731-7e72-4fb5-a67f-5bd1753178e6","_uuid":"7b85785920c57c79bb7c935df34094a4dbe8ab04"},"cell_type":"markdown","source":"### 3.3 - Splitting Training and Validation Sets\n\nThe train data is split into two sets; one for training, and one for validation. The train data is first reindexed randomly to ensure randomized sampling. Approximately two-thirds of the data is used for training, and one-third is used for validating."},{"metadata":{"_cell_guid":"7ebf504b-0ff0-460b-8790-6a2894ec6aa3","collapsed":true,"_uuid":"d2423104cc0cf00b64d88ad2e217b78e9348fc68","trusted":true},"cell_type":"code","source":"# randomize train data before splitting validation set\ntrain = train.reindex(\n    np.random.permutation(train.index))","execution_count":15,"outputs":[]},{"metadata":{"_cell_guid":"4535e86e-318d-46ec-b252-4d6692b29b54","_uuid":"36839a9a86346154e040cc279a6f013090988da7","trusted":true},"cell_type":"code","source":"# Choose the first n examples for training.\ntraining_examples = preprocess_features(train.head(122080))\ntraining_targets = preprocess_targets(train.head(122080))\n\n# Choose the last n examples for validation.\nvalidation_examples = preprocess_features(train.tail(60000))\nvalidation_targets = preprocess_targets(train.tail(60000))\n\n# Process features for test\ntest_examples = preprocess_features(test.copy())","execution_count":62,"outputs":[]},{"metadata":{"_cell_guid":"9e1da713-9448-42be-b290-262e49d76e58","_uuid":"098cfc40d063e46e0ad8367ec86b94cad68bb330"},"cell_type":"markdown","source":""},{"metadata":{"_cell_guid":"d43130af-194b-449b-904f-3c926255ab0d","_uuid":"71d815e582da4219e18d84ff06d8a404e6dc7dc5"},"cell_type":"markdown","source":"### 3.4 - Term frequency–inverse document frequency (TF-IDF)\nAll text data are vectorized. Sentiment analysis is also performed on the essays. (As seen in notebook by [Peter](https://www.kaggle.com/hoonkeng/how-to-get-81-gru-att-lgbm-tf-idf-eda))."},{"metadata":{"_cell_guid":"e010a026-41ab-4f46-9a36-54807c2482aa","collapsed":true,"_uuid":"a2660408aa4c873be8f66f3eee00c9d8e2ce4722","trusted":true},"cell_type":"code","source":"# Vectorize subject categories\nvectorizer=TfidfVectorizer(stop_words=stop)\nvectorizer.fit(train['project_subject_categories'])\ntrain_project_subject_categories = vectorizer.transform(training_examples['project_subject_categories'])\nvalidation_project_subject_categories = vectorizer.transform(validation_examples['project_subject_categories'])\ntest_project_subject_categories = vectorizer.transform(test_examples['project_subject_categories'])\n\n# Vectorize subject sub-categories\nvectorizer.fit(train['project_subject_subcategories'])\ntrain_project_subject_subcategories = vectorizer.transform(training_examples['project_subject_subcategories'])\nvalidation_project_subject_subcategories = vectorizer.transform(validation_examples['project_subject_subcategories'])\ntest_project_subject_subcategories = vectorizer.transform(test_examples['project_subject_subcategories'])","execution_count":17,"outputs":[]},{"metadata":{"_cell_guid":"4064ef5a-682c-42f0-912a-66b564434039","collapsed":true,"_uuid":"8d4eda3842d9346a2a7c5d10a3974bd9c1e5616a","trusted":true},"cell_type":"code","source":"# Vectorize project title\nvectorizer=TfidfVectorizer(stop_words=stop, ngram_range=(1, 2), max_df=0.9, min_df=5, max_features=2000)\nvectorizer.fit(train['project_title'])\ntrain_project_title = vectorizer.transform(training_examples['project_title'])\nvalidation_project_title = vectorizer.transform(validation_examples['project_title'])\ntest_project_title = vectorizer.transform(test_examples['project_title'])\n\n# Vectorize project summary\nvectorizer.fit(train['project_resource_summary'])\ntrain_project_resource_summary = vectorizer.transform(training_examples['project_resource_summary'])\nvalidation_project_resource_summary = vectorizer.transform(validation_examples['project_resource_summary'])\ntest_project_resource_summary = vectorizer.transform(test_examples['project_resource_summary'])","execution_count":18,"outputs":[]},{"metadata":{"_cell_guid":"cc622c95-347f-42d6-88d5-8b5a92859bf4","collapsed":true,"_uuid":"b629e4c434de069c82288265271eec5f4d64000d","trusted":true},"cell_type":"code","source":"# Vectorize essays\nvectorizer=TfidfVectorizer(stop_words=stop, ngram_range=(1, 3), max_df=0.9, min_df=5, max_features=2000)\nvectorizer.fit(train['project_essay_1'])\ntrain_project_essay_1 = vectorizer.transform(training_examples['project_essay_1'])\nvalidation_project_essay_1 = vectorizer.transform(validation_examples['project_essay_1'])\ntest_project_essay_1 = vectorizer.transform(test_examples['project_essay_1'])\n\nvectorizer.fit(train['project_essay_2'])\ntrain_project_essay_2 = vectorizer.transform(training_examples['project_essay_2'])\nvalidation_project_essay_2 = vectorizer.transform(validation_examples['project_essay_2'])\ntest_project_essay_2 = vectorizer.transform(test_examples['project_essay_2'])","execution_count":19,"outputs":[]},{"metadata":{"_cell_guid":"5a2261a2-dfed-4c95-81bf-54d7860f1bc2","collapsed":true,"_uuid":"4c67f1923ac1254219791557c6c14cd2f3058964","trusted":true},"cell_type":"code","source":"# Define Sentiment Analysis functions\n\ndef get_polarity(text):\n    textblob = TextBlob(text)\n    pol = textblob.sentiment.polarity\n    return round(pol,3)\n\ndef get_subjectivity(text):\n    textblob = TextBlob(text)\n    subj = textblob.sentiment.subjectivity\n    return round(subj,3)","execution_count":20,"outputs":[]},{"metadata":{"scrolled":true,"_cell_guid":"8f10164e-2677-44e6-8f52-687b050b6505","collapsed":true,"_uuid":"7136c4b9a48d15de5f971216d2d6c9c200b74520","trusted":true},"cell_type":"code","source":"# Sentiment Analysis in training\n\ntraining_examples['polarity1'] = training_examples['project_essay_1'].apply(get_polarity)\ntraining_examples['subjectivity1'] = training_examples['project_essay_1'].apply(get_subjectivity)\ntraining_examples['polarity2'] = training_examples['project_essay_2'].apply(get_polarity)\ntraining_examples['subjectivity2'] = training_examples['project_essay_2'].apply(get_subjectivity)","execution_count":21,"outputs":[]},{"metadata":{"_cell_guid":"bff064f4-4f0b-4088-adb8-a9b184360d4c","collapsed":true,"_uuid":"bb40daec3441832e94bd2afe875f75e71abcb0fa","trusted":true},"cell_type":"code","source":"# Sentiment Analysis in validation\n\nvalidation_examples['polarity1'] = validation_examples['project_essay_1'].apply(get_polarity)\nvalidation_examples['subjectivity1'] = validation_examples['project_essay_1'].apply(get_subjectivity)\nvalidation_examples['polarity2'] = validation_examples['project_essay_2'].apply(get_polarity)\nvalidation_examples['subjectivity2'] = validation_examples['project_essay_2'].apply(get_subjectivity)","execution_count":23,"outputs":[]},{"metadata":{"_cell_guid":"fc80fc9d-75f4-4d49-9145-2e56ca3157e5","collapsed":true,"_uuid":"3290c1002ed66d1e281ec4fc6c131ca8617149ce","trusted":true},"cell_type":"code","source":"# Sentiment Analysis in test\n\ntest_examples['polarity1'] = test_examples['project_essay_1'].apply(get_polarity)\ntest_examples['subjectivity1'] = test_examples['project_essay_1'].apply(get_subjectivity)\ntest_examples['polarity2'] = test_examples['project_essay_2'].apply(get_polarity)\ntest_examples['subjectivity2'] = test_examples['project_essay_2'].apply(get_subjectivity)","execution_count":22,"outputs":[]},{"metadata":{"_cell_guid":"26070e37-c907-4138-8aa4-86254b3ddb8d","_uuid":"7377d9bdc8c789c3f6556f9b4140d59e37858662","trusted":true,"collapsed":true},"cell_type":"code","source":"# Drop unnecessary columns\nto_drop = ['project_subject_categories', 'project_subject_subcategories', 'project_title', 'project_essay_1', 'project_essay_2', 'project_resource_summary']\nfor col in to_drop:\n    training_examples.drop([col], axis=1, inplace=True)\n    validation_examples.drop([col], axis=1, inplace=True)\n    test_examples.drop([col], axis=1, inplace=True)","execution_count":63,"outputs":[]},{"metadata":{"_cell_guid":"c89c2b3d-92e5-4e74-81ff-7cb63a459338","_uuid":"9905fde882950fba2b3278a3179edf069a9dc2b6","trusted":true},"cell_type":"code","source":"# Combine all features\ntraining_features = csr_matrix(hstack([training_examples.values, train_project_subject_categories, train_project_subject_subcategories, train_project_title, train_project_resource_summary, train_project_essay_1, train_project_essay_2]))\nvalidation_features = csr_matrix(hstack([validation_examples.values, validation_project_subject_categories, validation_project_subject_subcategories, validation_project_title, validation_project_resource_summary, validation_project_essay_1, validation_project_essay_2]))\ntest_features = csr_matrix(hstack([test_examples.values, test_project_subject_categories, test_project_subject_subcategories, test_project_title, test_project_resource_summary, test_project_essay_1, test_project_essay_2]))","execution_count":64,"outputs":[]},{"metadata":{"_cell_guid":"007cb8d9-6de1-486c-b03b-c24a5a24bb64","_uuid":"b56b87b7dbd93d7d511fb4d180a19dd92616024d"},"cell_type":"markdown","source":""},{"metadata":{"_cell_guid":"78f1de15-891a-4bee-9f3d-e6a3fcd9b370","_uuid":"675c10deee0bd9a0f640c3526950bddc5050177c"},"cell_type":"markdown","source":"# 4 - Train Model\nWhile building the model step by step, I used both XGBoost and LightGBM models. I found that the AUC and prediction results were very similar between the two models, with LGBM having the advantage of running in less time. Therefore, I decided to use LGBM as the final model of choice.\n\nFor the final LGBM, I used the hyper-parameters indicated in the notebook by [Peter](https://www.kaggle.com/hoonkeng/how-to-get-81-gru-att-lgbm-tf-idf-eda)."},{"metadata":{"_cell_guid":"5fbc6dd6-9d67-4792-93b5-75e5f1d5c619","collapsed":true,"_uuid":"88de74548dc7eefa515c5318f203f89436d0d757","trusted":false},"cell_type":"code","source":"# XGBoost\n\n#params = {'eta': 0.025, 'max_depth': 16, 'objective': 'binary:logistic', 'eval_metric': 'auc', 'silent': False, 'colsample':0.9}\n#watchlist = [(xgb.DMatrix(training_features, training_targets2), 'train'), (xgb.DMatrix(validation_features, validation_targets2), 'valid')]\n#model = xgb.train(params, xgb.DMatrix(training_features, training_targets2), 1000,  watchlist, verbose_eval=10, early_stopping_rounds=20)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3c3de8a9-018b-4f62-aa93-27a3896eefb9","_uuid":"7917cab238c8272a9ae386ab4caedce56d1621f4","trusted":true},"cell_type":"code","source":"# LightGBM\n\nparams = {\n         'boosting_type': 'gbdt',\n         'objective': 'binary',\n         'metric': 'auc',\n         'max_depth': 16,\n         'num_leaves': 31,\n         'learning_rate': 0.025,\n         'feature_fraction': 0.85,\n         'bagging_fraction': 0.85,\n         'bagging_freq': 5,\n         'verbose': 0,\n         'num_threads': 1,\n         'lambda_l2': 1,\n         'min_gain_to_split': 0,\n         }  \n\nmodel2 = lgb.train(\n    params,\n    lgb.Dataset(training_features, training_targets),\n    num_boost_round=10000,\n    valid_sets=[lgb.Dataset(validation_features, validation_targets)],\n    verbose_eval=100,\n    early_stopping_rounds=100\n    )","execution_count":65,"outputs":[]},{"metadata":{"_cell_guid":"bac34ca5-4fd6-47c1-9bdd-17e62ba1c41a","_uuid":"78ff5e70d5a9b3247077326efd36801712ff17ba"},"cell_type":"markdown","source":""},{"metadata":{"_cell_guid":"3536652c-5402-4a42-9090-b46405fffcc1","_uuid":"71d99035a14f0b318463c1e71737f93f18bd13d4"},"cell_type":"markdown","source":"# 5 - Results\n\nOverall, I am very pleased with the AUC achieved by my first model. Some ideas to help myself improve are:\n* Hyper-parameter tuning: I am still very new to decision tree models. I am constantly trying to add to my knowledge, and definitely open to suggestions.\n* Optimizing current features: I am always looking for ways to optimize the features being inputted into the model. In future versions, I may remove features that do not work well for the model\n* Feature crosses: Something that I am exploring. Especially after reading the notebook by Heads or Tails, I have a lot of ideas about how features would interact with each other.\n\nIf you have any questions or suggestions, please comment!"},{"metadata":{"_uuid":"0e53b88ba91d8f1023b4c85d85bb934113372e6d","_cell_guid":"8809ccf5-ef74-4598-b1e8-9e00afd3b244","_kg_hide-output":false,"_kg_hide-input":false,"collapsed":true,"trusted":true},"cell_type":"code","source":"# Submission CSV\n\nsubmission = pd.DataFrame()\nsubmission['id'] = test['id']\nsubmission['project_is_approved'] = model2.predict(test_features, num_iteration=model2.best_iteration)\nsubmission.to_csv('submission.csv', index=False)","execution_count":27,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}